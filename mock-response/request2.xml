<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2024-01-30T08:20:31Z</responseDate>
<request verb="ListRecords" resumptionToken="6965856|1001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:2103.09226</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SymPKF: a symbolic and computational toolbox for the design of
  parametric Kalman filter dynamics</dc:title>
 <dc:creator>Pannekoucke, Olivier</dc:creator>
 <dc:creator>Arbogast, Philippe</dc:creator>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Recent researches in data assimilation lead to the introduction of the
parametric Kalman filter (PKF): an implementation of the Kalman filter, where
the covariance matrices are approximated by a parameterized covariance model.
In the PKF, the dynamics of the covariance during the forecast step relies on
the prediction of the covariance parameters. Hence, the design of the parameter
dynamics is crucial while it can be tedious to do this by hand. This
contribution introduces a python package, SymPKF, able to compute PKF dynamics
for univariate statistics and when the covariance model is parameterized from
the variance and the local anisotropy of the correlations. The ability of
SymPKF to produce the PKF dynamics is shown on a non-linear diffusive advection
(Burgers equation) over a 1D domain and the linear advection over a 2D domain.
The computation of the PKF dynamics is performed at a symbolic level, but an
automatic code generator is also introduced to perform numerical simulations. A
final multivariate example illustrates the potential of SymPKF to go beyond the
univariate case.
</dc:description>
 <dc:date>2021-03-16</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.09226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.09330</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-Task Instance Representation Interactions and Label Dependencies
  for Joint Information Extraction with Graph Convolutional Networks</dc:title>
 <dc:creator>Van Nguyen, Minh</dc:creator>
 <dc:creator>Lai, Viet Dac</dc:creator>
 <dc:creator>Nguyen, Thien Huu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Existing works on information extraction (IE) have mainly solved the four
main tasks separately (entity mention recognition, relation extraction, event
trigger detection, and argument extraction), thus failing to benefit from
inter-dependencies between tasks. This paper presents a novel deep learning
model to simultaneously solve the four tasks of IE in a single model (called
FourIE). Compared to few prior work on jointly performing four IE tasks, FourIE
features two novel contributions to capture inter-dependencies between tasks.
First, at the representation level, we introduce an interaction graph between
instances of the four tasks that is used to enrich the prediction
representation for one instance with those from related instances of other
tasks. Second, at the label level, we propose a dependency graph for the
information types in the four IE tasks that captures the connections between
the types expressed in an input sentence. A new regularization mechanism is
introduced to enforce the consistency between the golden and predicted type
dependency graphs to improve representation learning. We show that the proposed
model achieves the state-of-the-art performance for joint IE on both
monolingual and multilingual learning settings with three different languages.
</dc:description>
 <dc:description>Comment: Accepted at NAACL-HLT 2021</dc:description>
 <dc:date>2021-03-16</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.09330</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.09408</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>WheatNet: A Lightweight Convolutional Neural Network for High-throughput
  Image-based Wheat Head Detection and Counting</dc:title>
 <dc:creator>Khaki, Saeed</dc:creator>
 <dc:creator>Safaei, Nima</dc:creator>
 <dc:creator>Pham, Hieu</dc:creator>
 <dc:creator>Wang, Lizhi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  For a globally recognized planting breeding organization, manually-recorded
field observation data is crucial for plant breeding decision making. However,
certain phenotypic traits such as plant color, height, kernel counts, etc. can
only be collected during a specific time-window of a crop's growth cycle. Due
to labor-intensive requirements, only a small subset of possible field
observations are recorded each season. To help mitigate this data collection
bottleneck in wheat breeding, we propose a novel deep learning framework to
accurately and efficiently count wheat heads to aid in the gathering of
real-time data for decision making. We call our model WheatNet and show that
our approach is robust and accurate for a wide range of environmental
conditions of the wheat field. WheatNet uses a truncated MobileNetV2 as a
lightweight backbone feature extractor which merges feature maps with different
scales to counter image scale variations. Then, extracted multi-scale features
go to two parallel sub-networks for simultaneous density-based counting and
localization tasks. Our proposed method achieves an MAE and RMSE of 3.85 and
5.19 in our wheat head counting task, respectively, while having significantly
fewer parameters when compared to other state-of-the-art methods. Our
experiments and comparisons with other state-of-the-art methods demonstrate the
superiority and effectiveness of our proposed method.
</dc:description>
 <dc:description>Comment: 14 pages, 5 figures</dc:description>
 <dc:date>2021-03-16</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.09408</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.09444</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid Precoding for mmWave V2X Doubly-Selective Multiuser MIMO Systems</dc:title>
 <dc:creator>Balti, Elyes</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  Millimeter wave (mmWave) is a practical solution to provide high data rate
for the vehicle-to-everything (V2X) communications. This enables the future
autonomous vehicles to exchange big data with the base stations (BSs) such as
the velocity and the location to improve the awareness of the advanced driving
assistance system (ADAS). In this context, we consider a single-cell multiuser
doubly-selective system wherein the BS simultaneously serves multiple vehicles.
To accomplish this requirement, the BS is implemented in hybrid architecture to
support multiple spatial streams while the vehicles have analog-only
structures. In this work, we develop a low-complexity hybrid precoding
algorithm wherein the design of the hybrid precoder at the BS and the analog
combiner at the vehicles require small training and feedback overhead. We
propose a two-stage hybrid precoding algorithm wherein the first stage designs
the analog beamformers as in single user scenario while the second stage
designs the multiuser digital precoder at the BS. In the second stage, we
derive closed-form digital precoders such as Maximum Ratio Transmission (MRT),
Zero-Forcing (ZF) and Minimum Mean Square Error (MMSE) as a first variant while
we propose iterative digital precoder as a second variant. The design of the
digital precoders for the two variants requires the limited feedback sent from
the vehicles to BS. We refer to the random vector quantization (RVQ) and the
beamsteering codebooks to quantize the feedbacks for variants I and II,
respectively, since the perfect feedback requires long overhead and large
training. We evaluate the rate loss incurred by the quantization of the digital
and analog codebooks against the perfect channel state information at the
transmitter (CSIT).
</dc:description>
 <dc:date>2021-03-17</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.09444</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.09479</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Disentangled Cycle Consistency for Highly-realistic Virtual Try-On</dc:title>
 <dc:creator>Ge, Chongjian</dc:creator>
 <dc:creator>Song, Yibing</dc:creator>
 <dc:creator>Ge, Yuying</dc:creator>
 <dc:creator>Yang, Han</dc:creator>
 <dc:creator>Liu, Wei</dc:creator>
 <dc:creator>Luo, Ping</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image virtual try-on replaces the clothes on a person image with a desired
in-shop clothes image. It is challenging because the person and the in-shop
clothes are unpaired. Existing methods formulate virtual try-on as either
in-painting or cycle consistency. Both of these two formulations encourage the
generation networks to reconstruct the input image in a self-supervised manner.
However, existing methods do not differentiate clothing and non-clothing
regions. A straight-forward generation impedes virtual try-on quality because
of the heavily coupled image contents. In this paper, we propose a Disentangled
Cycle-consistency Try-On Network (DCTON). The DCTON is able to produce
highly-realistic try-on images by disentangling important components of virtual
try-on including clothes warping, skin synthesis, and image composition. To
this end, DCTON can be naturally trained in a self-supervised manner following
cycle consistency learning. Extensive experiments on challenging benchmarks
show that DCTON outperforms state-of-the-art approaches favorably.
</dc:description>
 <dc:description>Comment: Accepted by CVPR2021</dc:description>
 <dc:date>2021-03-17</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.09479</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.09492</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mathematical Modeling of Sediments in the Filter and Improvement of the
  Filter Construction</dc:title>
 <dc:creator>Troshchiev, Yuri</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>76-10</dc:subject>
 <dc:subject>J.2.4</dc:subject>
 <dc:subject>J.2.8</dc:subject>
 <dc:subject>J.2.9</dc:subject>
 <dc:description>  The filters work in many areas of technology. There constructions are
different and substances under filtration are different. It is necessary in
some cases to take into account forming of sediments on the walls of the filter
since they can change properties of the filter or blind the filtering apertures
at all. I construct a mathematical model of sedimentation growth on the walls
of the porous filter in this article. Analytical investigation is present in
the article and numeric results too. There are formulas for dependencies of
concentration near the walls on inner concentration in liquid in the article.
Flow speed, calculated time of work, purification efficiency and other
parameters proved to be important factors. Differing of radiuses of apertures
from membrane to membrane can make contamination equal along the filter.
Numerical results show importance of preliminary calculation of the filter for
the purpose it will serve. Forming of calcic sediment is an investigated
example of chemical reaction.
</dc:description>
 <dc:description>Comment: 19 pages, 5 figures, the license is changed, one typo is corrected</dc:description>
 <dc:date>2021-03-17</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.09492</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.09662</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Physics-Informed Neural Network Method for Solving One-Dimensional
  Advection Equation Using PyTorch</dc:title>
 <dc:creator>Vadyala, Shashank Reddy</dc:creator>
 <dc:creator>Betgeri, Sai Nethra</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>68Txx</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>G.1.7</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:subject>G.1.9</dc:subject>
 <dc:description>  Numerical solutions to the equation for advection are determined using
different finite-difference approximations and physics-informed neural networks
(PINNs) under conditions that allow an analytical solution. Their accuracy is
examined by comparing them to the analytical solution. We used a machine
learning framework like PyTorch to implement PINNs. PINNs approach allows
training neural networks while respecting the PDEs as a strong constraint in
the optimization as apposed to making them part of the loss function. In
standard small-scale circulation simulations, it is shown that the conventional
approach incorporates a pseudo diffusive effect that is almost as large as the
effect of the turbulent diffusion model; hence the numerical solution is
rendered inconsistent with the PDEs. This oscillation causes inaccuracy and
computational uncertainty. Of all the schemes tested, only the PINNs
approximation accurately predicted the outcome. We assume that the PINNs
approach can transform the physics simulation area by allowing real-time
physics simulation and geometry optimization without costly and time-consuming
simulations on large supercomputers.
</dc:description>
 <dc:description>Comment: 15 pages, 6 figures</dc:description>
 <dc:date>2021-03-15</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.09662</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.09853</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast AC Steady-State Power Grid Simulation and Optimization Using Prior
  Knowledge</dc:title>
 <dc:creator>Agarwal, Aayushya</dc:creator>
 <dc:creator>Pandey, Amritanshu</dc:creator>
 <dc:creator>Pileggi, Larry</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Fast and accurate optimization and simulation is widely becoming a necessity
for large scale transmission resiliency and planning studies such as N-1 SCOPF,
batch contingency solvers, and stochastic power flow. Current commercial tools,
however, prioritize speed of convergence over accuracy by relying on initial
conditions that are taken from the steady state solution of similar network
configurations that are not guaranteed to lie within a convex region of a valid
solution. In this paper we introduce a globally convergent algorithm to
facilitate fast and accurate AC steady state simulation and optimization based
on prior knowledge from similar networks. The approach uses a homotopy method
that gradually and efficiently translates a previously known network
configuration to the current network configuration. The proposed formulation is
highly scalable, and its efficacy is demonstrated for resiliency study and
optimization of large networks up to 70k buses.
</dc:description>
 <dc:description>Comment: Accepted for publication in Proceedings of PES General Meeting,
  Washington DC, 2021</dc:description>
 <dc:date>2021-03-17</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.09853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.09905</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>&quot;I Don't Know Too Much About It&quot;: On the Security Mindsets of Computer
  Science Students</dc:title>
 <dc:creator>Tahaei, Mohammad</dc:creator>
 <dc:creator>Jenkins, Adam</dc:creator>
 <dc:creator>Vaniea, Kami</dc:creator>
 <dc:creator>Wolters, Maria</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  The security attitudes and approaches of software developers have a large
impact on the software they produce, yet we know very little about how and when
these views are constructed. This paper investigates the security and privacy
(S&amp;P) perceptions, experiences, and practices of current Computer Science
students at the graduate and undergraduate level using semi-structured
interviews. We find that the attitudes of students already match many of those
that have been observed in professional level developers. Students have a range
of hacker and attack mindsets, lack of experience with security APIs, a mixed
view of who is in charge of S&amp;P in the software life cycle, and a tendency to
trust other peoples' code as a convenient approach to rapidly build software.
We discuss the impact of our results on both curriculum development and support
for professional developers.
</dc:description>
 <dc:date>2021-03-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.09905</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-030-55958-8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.09940</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DomainNet: Homograph Detection for Data Lake Disambiguation</dc:title>
 <dc:creator>Leventidis, Aristotelis</dc:creator>
 <dc:creator>Di Rocco, Laura</dc:creator>
 <dc:creator>Gatterbauer, Wolfgang</dc:creator>
 <dc:creator>Miller, Ren&#xe9;e J.</dc:creator>
 <dc:creator>Riedewald, Mirek</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Modern data lakes are deeply heterogeneous in the vocabulary that is used to
describe data. We study a problem of disambiguation in data lakes: how can we
determine if a data value occurring more than once in the lake has different
meanings and is therefore a homograph? While word and entity disambiguation
have been well studied in computational linguistics, data management and data
science, we show that data lakes provide a new opportunity for disambiguation
of data values since they represent a massive network of interconnected values.
We investigate to what extent this network can be used to disambiguate values.
DomainNet uses network-centrality measures on a bipartite graph whose nodes
represent values and attributes to determine, without supervision, if a value
is a homograph. A thorough experimental evaluation demonstrates that
state-of-the-art techniques in domain discovery cannot be re-purposed to
compete with our method. Specifically, using a domain discovery method to
identify homographs has a precision and a recall of 38% versus 69% with our
method on a synthetic benchmark. By applying a network-centrality measure to
our graph representation, DomainNet achieves a good separation between
homographs and data values with a unique meaning. On a real data lake our
top-200 precision is 89%.
</dc:description>
 <dc:description>Comment: Full version of paper appearing in EDBT 2021</dc:description>
 <dc:date>2021-03-17</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.09940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.09975</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>You Only Group Once: Efficient Point-Cloud Processing with Token
  Representation and Relation Inference Module</dc:title>
 <dc:creator>Xu, Chenfeng</dc:creator>
 <dc:creator>Zhai, Bohan</dc:creator>
 <dc:creator>Wu, Bichen</dc:creator>
 <dc:creator>Li, Tian</dc:creator>
 <dc:creator>Zhan, Wei</dc:creator>
 <dc:creator>Vajda, Peter</dc:creator>
 <dc:creator>Keutzer, Kurt</dc:creator>
 <dc:creator>Tomizuka, Masayoshi</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  3D point-cloud-based perception is a challenging but crucial computer vision
task. A point-cloud consists of a sparse, unstructured, and unordered set of
points. To understand a point-cloud, previous point-based methods, such as
PointNet++, extract visual features through hierarchically aggregation of local
features. However, such methods have several critical limitations: 1) Such
methods require several sampling and grouping operations, which slow down the
inference speed. 2) Such methods spend an equal amount of computation on each
points in a point-cloud, though many of points are redundant. 3) Such methods
aggregate local features together through downsampling, which leads to
information loss and hurts the perception performance. To overcome these
challenges, we propose a novel, simple, and elegant deep learning model called
YOGO (You Only Group Once). Compared with previous methods, YOGO only needs to
sample and group a point-cloud once, so it is very efficient. Instead of
operating on points, YOGO operates on a small number of tokens, each of which
summarizes the point features in a sub-region. This allows us to avoid
computing on the redundant points and thus boosts efficiency.Moreover, YOGO
preserves point-wise features by projecting token features to point features
although the computation is performed on tokens. This avoids information loss
and can improve point-wise perception performance. We conduct thorough
experiments to demonstrate that YOGO achieves at least 3.0x speedup over
point-based baselines while delivering competitive classification and
segmentation performance on the ModelNet, ShapeNetParts and S3DIS datasets.
</dc:description>
 <dc:description>Comment: The code is available at https://github.com/chenfengxu714/YOGO.git</dc:description>
 <dc:date>2021-03-17</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.09975</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10023</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discriminative and Semantic Feature Selection for Place Recognition
  towards Dynamic Environments</dc:title>
 <dc:creator>Tian, Yuxin</dc:creator>
 <dc:creator>MIao, Jinyu</dc:creator>
 <dc:creator>Wu, Xingming</dc:creator>
 <dc:creator>Yue, Haosong</dc:creator>
 <dc:creator>Liu, Zhong</dc:creator>
 <dc:creator>Chen, Weihai</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Features play an important role in various visual tasks, especially in visual
place recognition applied in perceptual changing environments. In this paper,
we address the challenges of place recognition due to dynamics and confusable
patterns by proposing a discriminative and semantic feature selection network,
dubbed as DSFeat. Supervised by both semantic information and attention
mechanism, we can estimate pixel-wise stability of features, indicating the
probability of a static and stable region from which features are extracted,
and then select features that are insensitive to dynamic interference and
distinguishable to be correctly matched. The designed feature selection model
is evaluated in place recognition and SLAM system in several public datasets
with varying appearances and viewpoints. Experimental results conclude that the
effectiveness of the proposed method. It should be noticed that our proposal
can be readily pluggable into any feature-based SLAM system.
</dc:description>
 <dc:description>Comment: The paper is under consideration at Pattern Recognition Letters</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10031</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Vision-Based Cheat Detection in Competitive Gaming</dc:title>
 <dc:creator>Jonnalagadda, Aditya</dc:creator>
 <dc:creator>Frosio, Iuri</dc:creator>
 <dc:creator>Schneider, Seth</dc:creator>
 <dc:creator>McGuire, Morgan</dc:creator>
 <dc:creator>Kim, Joohwan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Game publishers and anti-cheat companies have been unsuccessful in blocking
cheating in online gaming. We propose a novel, vision-based approach that
captures the final state of the frame buffer and detects illicit overlays. To
this aim, we train and evaluate a DNN detector on a new dataset, collected
using two first-person shooter games and three cheating software. We study the
advantages and disadvantages of different DNN architectures operating on a
local or global scale. We use output confidence analysis to avoid unreliable
detections and inform when network retraining is required. In an ablation
study, we show how to use Interval Bound Propagation to build a detector that
is also resistant to potential adversarial attacks and study its interaction
with confidence analysis. Our results show that robust and effective
anti-cheating through machine learning is practically feasible and can be used
to guarantee fair play in online gaming.
</dc:description>
 <dc:description>Comment: 17 pages, 4 figures</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10146</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finite-word-length FPGA implementation of model predictive control for
  ITER resistive wall mode control</dc:title>
 <dc:creator>Gerk&#x161;i&#x10d;, Samo</dc:creator>
 <dc:creator>Pregelj, Bo&#x161;tjan</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>37N35, 49N10, 93B45</dc:subject>
 <dc:description>  In advanced tokamak scenarios, active feedback control of unstable resistive
wall modes (RWM) may be required. A RWM is an instability due to plasma kink at
higher plasma pressure, moderated by the presence of a resistive wall
surrounding the plasma. We address the dominant kink instability associated
with the main nonaxisymmetric (n = 1) RWM, described by the CarMa model. Model
predictive control (MPC) is used, with the aim of enlarging the domain of
attraction of the unstable RWM modes subject to power-supply voltage
constraints. The implementation of MPC is challenging, because the related
quadratic programming (QP) on-line optimization problems must be solved at a
sub-ms sampling rate. Using complexity-reduction pre-processing techniques and
a primal fast gradient method (FGM) QP solver, sufficiently short computation
times for ITER are reachable using a standard personal computer (PC). In this
work we explore even faster finite-word-length (FWL) implementation using
field-programmable gate arrays (FPGA), which would facilitate experimental
testing of such control algorithms on dynamically faster medium-sized tokamaks,
and compare the computational accuracy and time with the PC implementation.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10146</dc:identifier>
 <dc:identifier>Fusion Engineering and Design 169 (2021) 112480</dc:identifier>
 <dc:identifier>doi:10.1016/j.fusengdes.2021.112480</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10198</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phylogenetic typology</dc:title>
 <dc:creator>J&#xe4;ger, Gerhard</dc:creator>
 <dc:creator>Wahle, Johannes</dc:creator>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  In this article we propose a novel method to estimate the frequency
distribution of linguistic variables while controlling for statistical
non-independence due to shared ancestry. Unlike previous approaches, our
technique uses all available data, from language families large and small as
well as from isolates, while controlling for different degrees of relatedness
on a continuous scale estimated from the data. Our approach involves three
steps: First, distributions of phylogenies are inferred from lexical data.
Second, these phylogenies are used as part of a statistical model to
statistically estimate transition rates between parameter states. Finally, the
long-term equilibrium of the resulting Markov process is computed. As a case
study, we investigate a series of potential word-order correlations across the
languages of the world.
</dc:description>
 <dc:description>Comment: 32 pages, 15 figures</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10246</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Bandits for Multi-platform Budget Optimization in Online
  Advertising</dc:title>
 <dc:creator>Avadhanula, Vashist</dc:creator>
 <dc:creator>Colini-Baldeschi, Riccardo</dc:creator>
 <dc:creator>Leonardi, Stefano</dc:creator>
 <dc:creator>Sankararaman, Karthik Abinav</dc:creator>
 <dc:creator>Schrijvers, Okke</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We study the problem of an online advertising system that wants to optimally
spend an advertiser's given budget for a campaign across multiple platforms,
without knowing the value for showing an ad to the users on those platforms. We
model this challenging practical application as a Stochastic Bandits with
Knapsacks problem over $T$ rounds of bidding with the set of arms given by the
set of distinct bidding $m$-tuples, where $m$ is the number of platforms. We
modify the algorithm proposed in Badanidiyuru \emph{et al.,} to extend it to
the case of multiple platforms to obtain an algorithm for both the discrete and
continuous bid-spaces. Namely, for discrete bid spaces we give an algorithm
with regret $O\left(OPT \sqrt {\frac{mn}{B} }+ \sqrt{mn OPT}\right)$, where
$OPT$ is the performance of the optimal algorithm that knows the distributions.
For continuous bid spaces the regret of our algorithm is
$\tilde{O}\left(m^{1/3} \cdot \min\left\{ B^{2/3}, (m T)^{2/3} \right\}
\right)$. When restricted to this special-case, this bound improves over
Sankararaman and Slivkins in the regime $OPT \ll T$, as is the case in the
particular application at hand. Second, we show an $ \Omega\left (\sqrt {m OPT}
\right)$ lower bound for the discrete case and an $\Omega\left( m^{1/3}
B^{2/3}\right)$ lower bound for the continuous setting, almost matching the
upper bounds. Finally, we use a real-world data set from a large internet
online advertising company with multiple ad platforms and show that our
algorithms outperform common benchmarks and satisfy the required properties
warranted in the real-world application.
</dc:description>
 <dc:date>2021-03-16</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10246</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10270</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Requirement Engineering Challenges for AI-intense Systems Development</dc:title>
 <dc:creator>Heyn, Hans-Martin</dc:creator>
 <dc:creator>Knauss, Eric</dc:creator>
 <dc:creator>Muhammad, Amna Pir</dc:creator>
 <dc:creator>Eriksson, Olof</dc:creator>
 <dc:creator>Linder, Jennifer</dc:creator>
 <dc:creator>Subbiah, Padmini</dc:creator>
 <dc:creator>Pradhan, Shameer Kumar</dc:creator>
 <dc:creator>Tungal, Sagar</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Availability of powerful computation and communication technology as well as
advances in artificial intelligence enable a new generation of complex,
AI-intense systems and applications. Such systems and applications promise
exciting improvements on a societal level, yet they also bring with them new
challenges for their development. In this paper we argue that significant
challenges relate to defining and ensuring behaviour and quality attributes of
such systems and applications. We specifically derive four challenge areas from
relevant use cases of complex, AI-intense systems and applications related to
industry, transportation, and home automation: understanding, determining, and
specifying (i) contextual definitions and requirements, (ii) data attributes
and requirements, (iii) performance definition and monitoring, and (iv) the
impact of human factors on system acceptance and success. Solving these
challenges will imply process support that integrates new requirements
engineering methods into development approaches for complex, AI-intense systems
and applications. We present these challenges in detail and propose a research
roadmap.
</dc:description>
 <dc:description>Comment: Contribution to the WAIN'21 1st Workshop on AI Engineering during the
  43rd International Conference on Software Engineering (ICSE21)</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10270</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10347</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shifted Monic Ultraspherical Approximation for solving some of
  Fractional Orders Differential Equations</dc:title>
 <dc:creator>Abdelhakem, M.</dc:creator>
 <dc:creator>R., Doha M.</dc:creator>
 <dc:creator>Saadallah, A. F.</dc:creator>
 <dc:creator>El-Kady, M.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  The purpose of this paper is to show and explain a new formula that indicates
with finality the derivatives of Shifted Monic Ultraspherical polynomials
(SMUPs) of any degree and for any fractional-order using the shifted Monic
Ultraspherical polynomials themselves. We also create a direct method solution
for the linear or nonlinear multi-order fractional differential equations
(FDEs) with constant coefficients involving a spectral Galerkin method. The
spatial approximation with its fractional order derivatives (described in the
Caputo sense) are built using shifted Monic Ultraspherical polynomials.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10347</dc:identifier>
 <dc:identifier>Current Science International, 8(2), 252-259 (2019)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10431</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convexification inversion method for nonlinear SAR imaging with
  experimentally collected data</dc:title>
 <dc:creator>Klibanov, M. V.</dc:creator>
 <dc:creator>Khoa, V. A.</dc:creator>
 <dc:creator>Smirnov, A. V.</dc:creator>
 <dc:creator>Nguyen, L. H.</dc:creator>
 <dc:creator>Bidney, G. W.</dc:creator>
 <dc:creator>Nguyen, L. H.</dc:creator>
 <dc:creator>Sullivan, A. J.</dc:creator>
 <dc:creator>Astratov, V. N.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>78A46, 65L70, 65C20</dc:subject>
 <dc:description>  This paper is concerned with the study of a version of the globally
convergent convexification method with direct application to synthetic aperture
radar (SAR) imaging. Results of numerical testing are presented for
experimentally collected data for a fake landmine. The SAR imaging technique is
a common tool used to create maps of parts of the surface of the Earth or other
planets. Recently, it has been applied in the context of non-invasive
inspections of buildings in military and civilian services. Nowadays, any SAR
imaging software is based on the Born approximation, which is a linearization
of the original wave-like partial differential equation. One of the essential
assumptions this linearization procedure needs is that only those dielectric
constants are imaged whose values are close to the constant background. In this
work, we propose a radically new idea: to work without any linearization while
still using the same data as the conventional SAR imaging technique uses. We
construct a 2D image of the dielectric constant function using a number of 1D
images of this function obtained via solving a 1D coefficient inverse problem
(CIP) for a hyperbolic equation. Different from our previous studies on the
convexification method with concentration on the global convergence of the
gradient projection method, this time we prove the global convergence of the
gradient descent method, which is easier to implement numerically.
</dc:description>
 <dc:description>Comment: 28 pages, 14 figures</dc:description>
 <dc:date>2021-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10432</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MARS: Markov Molecular Sampling for Multi-objective Drug Discovery</dc:title>
 <dc:creator>Xie, Yutong</dc:creator>
 <dc:creator>Shi, Chence</dc:creator>
 <dc:creator>Zhou, Hao</dc:creator>
 <dc:creator>Yang, Yuwei</dc:creator>
 <dc:creator>Zhang, Weinan</dc:creator>
 <dc:creator>Yu, Yong</dc:creator>
 <dc:creator>Li, Lei</dc:creator>
 <dc:subject>Quantitative Biology - Biomolecules</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Searching for novel molecules with desired chemical properties is crucial in
drug discovery. Existing work focuses on developing neural models to generate
either molecular sequences or chemical graphs. However, it remains a big
challenge to find novel and diverse compounds satisfying several properties. In
this paper, we propose MARS, a method for multi-objective drug molecule
discovery. MARS is based on the idea of generating the chemical candidates by
iteratively editing fragments of molecular graphs. To search for high-quality
candidates, it employs Markov chain Monte Carlo sampling (MCMC) on molecules
with an annealing scheme and an adaptive proposal. To further improve sample
efficiency, MARS uses a graph neural network (GNN) to represent and select
candidate edits, where the GNN is trained on-the-fly with samples from MCMC.
Experiments show that MARS achieves state-of-the-art performance in various
multi-objective settings where molecular bio-activity, drug-likeness, and
synthesizability are considered. Remarkably, in the most challenging setting
where all four objectives are simultaneously optimized, our approach
outperforms previous methods significantly in comprehensive evaluations. The
code is available at https://github.com/yutxie/mars.
</dc:description>
 <dc:description>Comment: ICLR 2021</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10432</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10434</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Localization of Cochlear Implant Electrodes from Cone Beam Computed
  Tomography using Particle Belief Propagation</dc:title>
 <dc:creator>Hachmann, Hendrik</dc:creator>
 <dc:creator>Kr&#xfc;ger, Benjamin</dc:creator>
 <dc:creator>Rosenhahn, Bodo</dc:creator>
 <dc:creator>Nogueira, Waldo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>I.4.0</dc:subject>
 <dc:description>  Cochlear implants (CIs) are implantable medical devices that can restore the
hearing sense of people suffering from profound hearing loss. The CI uses a set
of electrode contacts placed inside the cochlea to stimulate the auditory nerve
with current pulses. The exact location of these electrodes may be an important
parameter to improve and predict the performance with these devices. Currently
the methods used in clinics to characterize the geometry of the cochlea as well
as to estimate the electrode positions are manual, error-prone and time
consuming. We propose a Markov random field (MRF) model for CI electrode
localization for cone beam computed tomography (CBCT) data-sets. Intensity and
shape of electrodes are included as prior knowledge as well as distance and
angles between contacts. MRF inference is based on slice sampling particle
belief propagation and guided by several heuristics. A stochastic search finds
the best maximum a posteriori estimation among sampled MRF realizations. We
evaluate our algorithm on synthetic and real CBCT data-sets and compare its
performance with two state of the art algorithms. An increase of localization
precision up to 31.5% (mean), or 48.6% (median) respectively, on real CBCT
data-sets is shown.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10434</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10450</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Please Don't Go -- Increasing Women's Participation in Open Source
  Software</dc:title>
 <dc:creator>Trinkenreich, Bianca</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Women represent less than 24% of the software development industry and suffer
from various types of prejudice and biases. In Open Source Software projects,
despite a variety of efforts to increase diversity and multi-gendered
participation, women are even more underrepresented (less than 10%). My
research focuses on answering the question: How can OSS communities increase
women's participation in OSS projects? I will identify the different OSS career
pathways, and develop a holistic view of women's motivations to join or leave
OSS, along with their definitions of success. Based on this empirical
investigation, I will work together with the Linux Foundation to design
attraction and retention strategies focused on women. Before and after
implementing the strategies, I will conduct empirical studies to evaluate the
state of the practice and understand the implications of the strategies.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:2103.08763</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10450</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10451</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Networks for Semantic Gaze Analysis in XR Settings</dc:title>
 <dc:creator>Stubbemann, Lena</dc:creator>
 <dc:creator>D&#xfc;rrschnabel, Dominik</dc:creator>
 <dc:creator>Refflinghaus, Robert</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>68T45</dc:subject>
 <dc:subject>I.4.8</dc:subject>
 <dc:subject>I.4.9</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:description>  Virtual-reality (VR) and augmented-reality (AR) technology is increasingly
combined with eye-tracking. This combination broadens both fields and opens up
new areas of application, in which visual perception and related cognitive
processes can be studied in interactive but still well controlled settings.
However, performing a semantic gaze analysis of eye-tracking data from
interactive three-dimensional scenes is a resource-intense task, which so far
has been an obstacle to economic use. In this paper we present a novel approach
which minimizes time and information necessary to annotate volumes of interest
(VOIs) by using techniques from object recognition. To do so, we train
convolutional neural networks (CNNs) on synthetic data sets derived from
virtual models using image augmentation techniques. We evaluate our method in
real and virtual environments, showing that the method can compete with
state-of-the-art approaches, while not relying on additional markers or
preexisting databases but instead offering cross-platform use.
</dc:description>
 <dc:description>Comment: 16 pages, 6 figures, 1 table, Accepted to: ETRA2021, ACM Symposium on
  Eye Tracking Research and Applications</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10451</dc:identifier>
 <dc:identifier>doi:10.1145/3448017.3457380</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10452</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extending Sparse Tensor Accelerators to Support Multiple Compression
  Formats</dc:title>
 <dc:creator>Qin, Eric</dc:creator>
 <dc:creator>Jeong, Geonhwa</dc:creator>
 <dc:creator>Won, William</dc:creator>
 <dc:creator>Kao, Sheng-Chun</dc:creator>
 <dc:creator>Kwon, Hyoukjun</dc:creator>
 <dc:creator>Srinivasan, Sudarshan</dc:creator>
 <dc:creator>Das, Dipankar</dc:creator>
 <dc:creator>Moon, Gordon E.</dc:creator>
 <dc:creator>Rajamanickam, Sivasankaran</dc:creator>
 <dc:creator>Krishna, Tushar</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Sparsity, which occurs in both scientific applications and Deep Learning (DL)
models, has been a key target of optimization within recent ASIC accelerators
due to the potential memory and compute savings. These applications use data
stored in a variety of compression formats. We demonstrate that both the
compactness of different compression formats and the compute efficiency of the
algorithms enabled by them vary across tensor dimensions and amount of
sparsity. Since DL and scientific workloads span across all sparsity regions,
there can be numerous format combinations for optimizing memory and compute
efficiency. Unfortunately, many proposed accelerators operate on one or two
fixed format combinations. This work proposes hardware extensions to
accelerators for supporting numerous format combinations seamlessly and
demonstrates ~4X speedup over performing format conversions in software.
</dc:description>
 <dc:description>Comment: Accepted for publication at the 35th IEEE International Parallel &amp;
  Distributed Processing Symposium (IPDPS 2021)</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10452</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10460</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structure Calculation and Reconstruction of Discrete State Dynamics from
  Residual Dipolar Couplings using REDCRAFT</dc:title>
 <dc:creator>Cole, Casey A.</dc:creator>
 <dc:creator>Mukhapadhyay, Rishi</dc:creator>
 <dc:creator>Omar, Hanin</dc:creator>
 <dc:creator>Hennig, Mirko</dc:creator>
 <dc:creator>Valafar, Homayoun</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Residual Dipolar Couplings (RDCs) acquired by Nuclear Magnetic Resonance
(NMR) spectroscopy can be an indispensable source of information in
investigation of molecular structures and dynamics. Here we present a complete
strategy for structure calculation and reconstruction of discrete state
dynamics from RDC data. Our method utilizes the previously presented REDCRAFT
software package and its dynamic-profile analysis to complete the task of
fragmented structure determination and identification of the onset of dynamics
from RDC data. Fragmented structure determination was used to demonstrate
successful structure calculation of static and dynamic domains for several
models of dynamics. We provide a mechanism of producing an ensemble of
conformations for the dynamical regions that describe any observed order tensor
discrepancies between the static and dynamic domains within a protein. In
addition, the presented method is capable of approximating relative occupancy
of each conformational state. The developed methodology has been evaluated on
simulated RDC data with 1Hz of error from an 83 residue {\alpha} protein (PDBID
1A1Z), and a 213 residue {\alpha}/\b{eta} protein DGCR8 (PDBID 2YT4). Using
1A1Z, various models of arc and complex two and three discrete-state dynamics
were simulated. MD simulation was used to generate a 2-state dynamics for
DGCR8. In both instances our method reproduced structure of the protein
including the conformational ensemble to within less than 2{\AA}. Based on our
investigations, arc motions with more than 30{\deg} of rotation are recognized
as internal dynamics and are reconstructed with sufficient accuracy.
Furthermore, states with relative occupancies above 20% are consistently
recognized and reconstructed successfully. Arc motions with magnitude of
15{\deg} or relative occupancy of less than 10% are consistently unrecognizable
as dynamical regions.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10460</dc:identifier>
 <dc:identifier>Was later published in Journal of chemical theory and computation
  12 (4), 1408-1422, 2016/4/12</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10462</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cellcounter: a deep learning framework for high-fidelity spatial
  localization of neurons</dc:title>
 <dc:creator>Batabyal, Tamal</dc:creator>
 <dc:creator>Naik, Aijaz Ahmad</dc:creator>
 <dc:creator>Weller, Daniel</dc:creator>
 <dc:creator>Kapur, Jaideep</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Many neuroscientific applications require robust and accurate localization of
neurons. It is still an unsolved problem because of the enormous variation in
intensity, texture, spatial overlap, morphology and background artifacts. In
addition, curation of a large dataset containing complete manual annotation of
neurons from high-resolution images to train a classifier requires significant
time and effort. We present Cellcounter, a deep learning-based model trained on
images containing incompletely-annotated neurons with highly-varied morphology
and control images containing artifacts and background structures. Leveraging
the striking self-learning ability, Cellcounter gradually labels neurons,
obviating the need for time-intensive complete annotation. Cellcounter shows
its efficacy over the state of the arts in the accurate localization of neurons
while significantly reducing false-positive detection in several protocols.
</dc:description>
 <dc:description>Comment: Submitted to a journal</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10462</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10472</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Kernel Matching for Non-conforming Data: A Case Study of T-cell
  Receptor Datasets</dc:title>
 <dc:creator>Ostmeyer, Jared</dc:creator>
 <dc:creator>Christley, Scott</dc:creator>
 <dc:creator>Cowell, Lindsay</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Most statistical classifiers are designed to find patterns in data where
numbers fit into rows and columns, like in a spreadsheet, but many kinds of
data do not conform to this structure. To uncover patterns in non-conforming
data, we describe an approach for modifying established statistical classifiers
to handle non-conforming data, which we call dynamic kernel matching (DKM). As
examples of non-conforming data, we consider (i) a dataset of T-cell receptor
(TCR) sequences labelled by disease antigen and (ii) a dataset of sequenced TCR
repertoires labelled by patient cytomegalovirus (CMV) serostatus, anticipating
that both datasets contain signatures for diagnosing disease. We successfully
fit statistical classifiers augmented with DKM to both datasets and report the
performance on holdout data using standard metrics and metrics allowing for
indeterminant diagnoses. Finally, we identify the patterns used by our
statistical classifiers to generate predictions and show that these patterns
agree with observations from experimental studies.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10472</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10474</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Model for Query-Document Expansion towards Improving Retrieval
  Relevance</dc:title>
 <dc:creator>Olufade, Onifade</dc:creator>
 <dc:creator>Abiola, Arise</dc:creator>
 <dc:creator>Chisom, Ogboo</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Getting relevant information from search engines has been the heart of
research works in information retrieval. Query expansion is a retrieval
technique that has been studied and proved to yield positive results in
relevance. Users are required to express their queries as a shortlist of words,
sentences, or questions. With this short format, a huge amount of information
is lost in the process of translating the information need from the actual
query size since the user cannot convey all his thoughts in a few words. This
mostly leads to poor query representation which contributes to undesired
retrieval effectiveness. This loss of information has made the study of query
expansion technique a strong area of study. This research work focuses on two
methods of retrieval for both tweet-length queries and sentence-length queries.
Two algorithms have been proposed and the implementation is expected to produce
a better relevance retrieval model than most state-the-art relevance models.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10474</dc:identifier>
 <dc:identifier>In Proceedings of the 6th International Conference on Mobile
  eServices, Ogbomosho, Oyo State, Nigeria. October 28-30, 2015. pp 62-75</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10475</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximum Likelihood Recursive State Estimation using the Expectation
  Maximization Algorithm</dc:title>
 <dc:creator>Ramadan, Mohammad S.</dc:creator>
 <dc:creator>Bitmead, Robert R.</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  A Maximum Likelihood recursive state estimator is derived for non-linear and
non-Gaussian state-space models. The estimator combines a particle filter to
generate the conditional density and the Expectation Maximization algorithm to
compute the maximum likelihood state estimate iteratively. Algorithms for
maximum likelihood state filtering, prediction and smoothing are presented. The
convergence properties of these algorithms, which are inherited from the
Expectation Maximization algorithm, are proven and examined in two examples. It
is shown that, with randomized reinitialization, which is feasible because of
the algorithm simplicity, these methods are able to converge to the Maximum
Likelihood Estimate (MLE) of multimodal, truncated and skewed densities, as
well as those of disjoint support.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures, 5 algorithms</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10475</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10476</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smooth Aggregation for Difficult Stretched Mesh and Coefficient
  Variation Problems</dc:title>
 <dc:creator>Hu, Jonathan J.</dc:creator>
 <dc:creator>Siefert, Chris</dc:creator>
 <dc:creator>Tuminaro, Raymond S.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Four adaptations of the smoothed aggregation algebraic multigrid (SA-AMG)
method are proposed with an eye towards improving the convergence and
robustness of the solver in situations when the discretization matrix contains
many weak connections. These weak connections can cause higher than expected
levels of fill-in within the coarse discretization matrices and can also give
rise to sub-optimal smoothing within the prolongator smoothing phase. These
smoothing drawbacks are due to the relatively small size of some diagonal
entries within the filtered matrix that one obtains after dropping the weak
connections. The new algorithms consider modifications to the Jacobi-like step
that defines the prolongator smoother, modifications to the filtered matrix,
and also direct modifications to the resulting grid transfer operators.
Numerical results are given illustrating the potential benefits of the proposed
adaptations.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10480</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reading Isn't Believing: Adversarial Attacks On Multi-Modal Neurons</dc:title>
 <dc:creator>Noever, David A.</dc:creator>
 <dc:creator>Noever, Samantha E. Miller</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  With Open AI's publishing of their CLIP model (Contrastive Language-Image
Pre-training), multi-modal neural networks now provide accessible models that
combine reading with visual recognition. Their network offers novel ways to
probe its dual abilities to read text while classifying visual objects. This
paper demonstrates several new categories of adversarial attacks, spanning
basic typographical, conceptual, and iconographic inputs generated to fool the
model into making false or absurd classifications. We demonstrate that
contradictory text and image signals can confuse the model into choosing false
(visual) options. Like previous authors, we show by example that the CLIP model
tends to read first, look later, a phenomenon we describe as reading isn't
believing.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10480</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10484</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Concentric Spherical GNN for 3D Representation Learning</dc:title>
 <dc:creator>Fox, James</dc:creator>
 <dc:creator>Zhao, Bo</dc:creator>
 <dc:creator>Rajamanickam, Sivasankaran</dc:creator>
 <dc:creator>Ramprasad, Rampi</dc:creator>
 <dc:creator>Song, Le</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Learning 3D representations that generalize well to arbitrarily oriented
inputs is a challenge of practical importance in applications varying from
computer vision to physics and chemistry. We propose a novel multi-resolution
convolutional architecture for learning over concentric spherical feature maps,
of which the single sphere representation is a special case. Our hierarchical
architecture is based on alternatively learning to incorporate both
intra-sphere and inter-sphere information. We show the applicability of our
method for two different types of 3D inputs, mesh objects, which can be
regularly sampled, and point clouds, which are irregularly distributed. We also
propose an efficient mapping of point clouds to concentric spherical images,
thereby bridging spherical convolutions on grids with general point clouds. We
demonstrate the effectiveness of our approach in improving state-of-the-art
performance on 3D classification tasks with rotated data.
</dc:description>
 <dc:description>Comment: This paper has been submitted for conference review</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10484</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10487</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decompositions and coalescing eigenvalues of symmetric definite pencils
  depending on parameters</dc:title>
 <dc:creator>Dieci, Luca</dc:creator>
 <dc:creator>Papini, Alessandra</dc:creator>
 <dc:creator>Pugliese, Alessandro</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>15A18, 15A23, 65F15, 65F99, 65P30</dc:subject>
 <dc:description>  In this work, we consider symmetric positive definite pencils depending on
two parameters. That is, we are concerned with the generalized eigenvalue
problem $A(x)-\lambda B(x)$, where $A$ and $B$ are symmetric matrix valued
functions in ${\mathbb R}^{n\times n}$, smoothly depending on parameters $x\in
\Omega\subset {\mathbb R}^2$; further, $B$ is also positive definite. In
general, the eigenvalues of this multiparameter problem will not be smooth, the
lack of smoothness resulting from eigenvalues being equal at some parameter
values (conical intersections). We first give general theoretical results on
the smoothness of eigenvalues and eigenvectors for the present generalized
eigenvalue problem, and hence for the corresponding projections, and then
perform a numerical study of the statistical properties of coalescing
eigenvalues for pencils where $A$ and $B$ are either full or banded, for
several bandwidths. Our numerical study will be performed with respect to a
random matrix ensemble which respects the underlying engineering problems
motivating our study.
</dc:description>
 <dc:description>Comment: 34 pages, 4 figures</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10487</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10493</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Synthesis for Data Augmentation in Medical CT using Deep
  Reinforcement Learning</dc:title>
 <dc:creator>Krishna, Arjun</dc:creator>
 <dc:creator>Bartake, Kedar</dc:creator>
 <dc:creator>Niu, Chuang</dc:creator>
 <dc:creator>Wang, Ge</dc:creator>
 <dc:creator>Lai, Youfang</dc:creator>
 <dc:creator>Jia, Xun</dc:creator>
 <dc:creator>Mueller, Klaus</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep learning has shown great promise for CT image reconstruction, in
particular to enable low dose imaging and integrated diagnostics. These merits,
however, stand at great odds with the low availability of diverse image data
which are needed to train these neural networks. We propose to overcome this
bottleneck via a deep reinforcement learning (DRL) approach that is integrated
with a style-transfer (ST) methodology, where the DRL generates the anatomical
shapes and the ST synthesizes the texture detail. We show that our method bears
high promise for generating novel and anatomically accurate high resolution CT
images at large and diverse quantities. Our approach is specifically designed
to work with even small image datasets which is desirable given the often low
amount of image data many researchers have available to them.
</dc:description>
 <dc:description>Comment: Fully3D 2021</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10493</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10496</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Naive Automated Machine Learning -- A Late Baseline for AutoML</dc:title>
 <dc:creator>Mohr, Felix</dc:creator>
 <dc:creator>Wever, Marcel</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Automated Machine Learning (AutoML) is the problem of automatically finding
the pipeline with the best generalization performance on some given dataset.
AutoML has received enormous attention in the last decade and has been
addressed with sophisticated black-box optimization techniques such as Bayesian
Optimization, Grammar-Based Genetic Algorithms, and tree search algorithms. In
contrast to those approaches, we present Naive AutoML, a very simple solution
to AutoML that exploits important meta-knowledge about machine learning
problems and makes simplifying, yet, effective assumptions to quickly come to
high-quality solutions. While Naive AutoML can be considered a baseline for the
highly sophisticated black-box solvers, we empirically show that those solvers
are not able to outperform Naive AutoML; sometimes the contrary is true. On the
other hand, Naive AutoML comes with strong advantages such as interpretability
and flexibility and poses a strong challenge to current tools.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10496</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10510</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hidden Technical Debts for Fair Machine Learning in Financial Services</dc:title>
 <dc:creator>Huang, Chong</dc:creator>
 <dc:creator>Nourian, Arash</dc:creator>
 <dc:creator>Griest, Kevin</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The recent advancements in machine learning (ML) have demonstrated the
potential for providing a powerful solution to build complex prediction systems
in a short time. However, in highly regulated industries, such as the financial
technology (Fintech), people have raised concerns about the risk of ML systems
discriminating against specific protected groups or individuals. To address
these concerns, researchers have introduced various mathematical fairness
metrics and bias mitigation algorithms. This paper discusses hidden technical
debts and challenges of building fair ML systems in a production environment
for Fintech. We explore various stages that require attention for fairness in
the ML system development and deployment life cycle. To identify hidden
technical debts that exist in building fair ML system for Fintech, we focus on
key pipeline stages including data preparation, model development, system
monitoring and integration in production. Our analysis shows that enforcing
fairness for production-ready ML systems in Fintech requires specific
engineering commitments at different stages of ML system life cycle. We also
propose several initial starting points to mitigate these technical debts for
deploying fair ML systems in production.
</dc:description>
 <dc:description>Comment: Presented at NeurIPS 2020 Fair AI in Finance Workshop</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10510</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10511</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EMS and DMS Integration of the Coordinative Real-time Sub-Transmission
  Volt-Var Control Tool under High DER Penetration</dc:title>
 <dc:creator>Nguyen, Quan</dc:creator>
 <dc:creator>Ogle, Jim</dc:creator>
 <dc:creator>Fan, Xiaoyuan</dc:creator>
 <dc:creator>Ke, Xinda</dc:creator>
 <dc:creator>Vallem, Mallikarjuna R.</dc:creator>
 <dc:creator>Samaan, Nader</dc:creator>
 <dc:creator>Lu, Ning</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper proposes an applicable approach to deploy the Coordinative
Real-time Sub-Transmission Volt-Var Control Tool (CReST-VCT), and a holistic
system integration framework considering both the energy management system
(EMS) and distribution system management system (DMS). This provides an
architectural basis and can serve as the implementation guideline of CReST-VCT
and other advanced grid support tools, to co-optimize the operation benefits of
distributed energy resources (DERs) and assets in both transmission and
distribution networks. Potential communication protocols for different physical
domains of a real application is included. Performance and security issues are
also discussed, along with specific considerations for field deployment.
Finally, the paper presents a viable pathway for CReST-VCT and other advanced
grid support tools to be integrated in an open-source standardized-based
platform that supports distribution utilities.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, conference</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10511</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10515</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterizing the Communication Requirements of GNN Accelerators: A
  Model-Based Approach</dc:title>
 <dc:creator>Guirado, Robert</dc:creator>
 <dc:creator>Jain, Akshay</dc:creator>
 <dc:creator>Abadal, Sergi</dc:creator>
 <dc:creator>Alarc&#xf3;n, Eduard</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Relational data present in real world graph representations demands for tools
capable to study it accurately. In this regard Graph Neural Network (GNN) is a
powerful tool, wherein various models for it have also been developed over the
past decade. Recently, there has been a significant push towards creating
accelerators that speed up the inference and training process of GNNs. These
accelerators, however, do not delve into the impact of their dataflows on the
overall data movement and, hence, on the communication requirements. In this
paper, we formulate analytical models that capture the amount of data movement
in the most recent GNN accelerator frameworks. Specifically, the proposed
models capture the dataflows and hardware setup of these accelerator designs
and expose their scalability characteristics for a set of hardware, GNN model
and input graph parameters. Additionally, the proposed approach provides means
for the comparative analysis of the vastly different GNN accelerators.
</dc:description>
 <dc:description>Comment: ISCAS 2021</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10515</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10516</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Multilevel Approach to Stochastic Trace Estimation</dc:title>
 <dc:creator>Hallman, Eric</dc:creator>
 <dc:creator>Troester, Devon</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>68W25, 65C05, 65F60, 65F30</dc:subject>
 <dc:description>  This article presents a randomized matrix-free method for approximating the
trace of $f({\bf A})$, where ${\bf A}$ is a large symmetric matrix and $f$ is a
function analytic in a closed interval containing the eigenvalues of ${\bf A}$.
Our method uses a combination of stochastic trace estimation (i.e.,
Hutchinson's method), Chebyshev approximation, and multilevel Monte Carlo
techniques. We establish general bounds on the approximation error of this
method by extending an existing error bound for Hutchinson's method to
multilevel trace estimators. Numerical experiments are conducted for common
applications such as estimating the log-determinant, nuclear norm, and Estrada
index, and triangle counting in graphs. We find that using multilevel
techniques can substantially reduce the variance of existing single-level
estimators.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10516</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10518</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pretraining the Noisy Channel Model for Task-Oriented Dialogue</dc:title>
 <dc:creator>Liu, Qi</dc:creator>
 <dc:creator>Yu, Lei</dc:creator>
 <dc:creator>Rimell, Laura</dc:creator>
 <dc:creator>Blunsom, Phil</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Direct decoding for task-oriented dialogue is known to suffer from the
explaining-away effect, manifested in models that prefer short and generic
responses. Here we argue for the use of Bayes' theorem to factorize the
dialogue task into two models, the distribution of the context given the
response, and the prior for the response itself. This approach, an
instantiation of the noisy channel model, both mitigates the explaining-away
effect and allows the principled incorporation of large pretrained models for
the response prior. We present extensive experiments showing that a noisy
channel model decodes better responses compared to direct decoding and that a
two stage pretraining strategy, employing both open-domain and task-oriented
dialogue data, improves over randomly initialized models.
</dc:description>
 <dc:description>Comment: Accepted to TACL, pre MIT Press publication version</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10518</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10519</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Auditability, Transparent, and Privacy-Preserving for Supply Chain
  Traceability Based on Blockchain</dc:title>
 <dc:creator>Sezer, Bora Bugra</dc:creator>
 <dc:creator>Topal, Selcuk</dc:creator>
 <dc:creator>Nuriyev, Urfat</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Traceability and auditability are key structures that are vital in supply
chain management and construction. However, trust is the most important aspect
of customers in these systems. Also, we have to rely on third parties to trade
in centralized systems. Although current exist frameworks for these solutions
in the supply chain, these have work poor traceability and lack of real-time
information, and especially lack of privacy-preserving. In this paper, we
propose a privacy-preserving framework for supply chain traceability that using
smart contracts. Development processes, model implementation, and smart
contracts are presented in detail and we show cryptographic techniques in these
technologies to address the aforementioned. Finally, thanks to traceability and
auditability, customers and other parties can view with a single product ID and
also verified with digital signature the claims of the actors in the system.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10519</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10520</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimally Summarizing Data by Small Fact Sets for Concise Answers to
  Voice Queries</dc:title>
 <dc:creator>Trummer, Immanuel</dc:creator>
 <dc:creator>Anderson, Connor</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Our goal is to find combinations of facts that optimally summarize data sets.
We consider this problem in the context of voice query interfaces for simple,
exploratory data analysis. Here, the system answers voice queries with a short
summary of relevant data. Finding optimal voice data summaries is
computationally expensive. Prior work in this domain has exploited sampling and
incremental processing. Instead, we rely on a pre-processing stage generating
summaries of data subsets in a batch operation. This step reduces run time
overheads by orders of magnitude.
  We present multiple algorithms for the pre-processing stage, realizing
different tradeoffs between optimality and data processing overheads. We
analyze our algorithms formally and compare them experimentally with prior
methods for generating voice data summaries. We report on multiple user studies
with a prototype system implementing our approach. Furthermore, we report on
insights gained from a public deployment of our system on the Google Assistant
Platform.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10521</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sensor Placement for Globally Optimal Coverage of 3D-Embedded Surfaces</dc:title>
 <dc:creator>Feng, Si Wei</dc:creator>
 <dc:creator>Gao, Kai</dc:creator>
 <dc:creator>Gong, Jie</dc:creator>
 <dc:creator>Yu, Jingjin</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We carry out a structural and algorithmic study of a mobile sensor coverage
optimization problem targeting 2D surfaces embedded in a 3D workspace. The
investigated settings model multiple important applications including camera
network deployment for surveillance, geological monitoring/survey of 3D
terrains, and UVC-based surface disinfection for the prevention of the spread
of disease agents (e.g., SARS-CoV-2). Under a unified general &quot;sensor coverage&quot;
problem, three concrete formulations are examined, focusing on optimizing
visibility, single-best coverage quality, and cumulative quality, respectively.
After demonstrating the computational intractability of all these formulations,
we describe approximation schemes and mathematical programming models for
near-optimally solving them. The effectiveness of our methods is thoroughly
evaluated under realistic and practical scenarios.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10524</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalizing Object-Centric Task-Axes Controllers using Keypoints</dc:title>
 <dc:creator>Sharma, Mohit</dc:creator>
 <dc:creator>Kroemer, Oliver</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  To perform manipulation tasks in the real world, robots need to operate on
objects with various shapes, sizes and without access to geometric models. It
is often unfeasible to train monolithic neural network policies across such
large variance in object properties. Towards this generalization challenge, we
propose to learn modular task policies which compose object-centric task-axes
controllers. These task-axes controllers are parameterized by properties
associated with underlying objects in the scene. We infer these controller
parameters directly from visual input using multi-view dense correspondence
learning. Our overall approach provides a simple, modular and yet powerful
framework for learning manipulation tasks. We empirically evaluate our approach
on multiple different manipulation tasks and show its ability to generalize to
large variance in object size, shape and geometry.
</dc:description>
 <dc:description>Comment: International Conference on Robotics and Automation (ICRA'21). For
  results see https://sites.google.com/view/robotic-manip-task-axes-ctrlrs</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10524</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10526</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>S3M: Siamese Stack (Trace) Similarity Measure</dc:title>
 <dc:creator>Khvorov, Aleksandr</dc:creator>
 <dc:creator>Vasiliev, Roman</dc:creator>
 <dc:creator>Chernishev, George</dc:creator>
 <dc:creator>Rodrigues, Irving Muller</dc:creator>
 <dc:creator>Koznov, Dmitrij</dc:creator>
 <dc:creator>Povarov, Nikita</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:subject>D.2.7</dc:subject>
 <dc:description>  Automatic crash reporting systems have become a de-facto standard in software
development. These systems monitor target software, and if a crash occurs they
send details to a backend application. Later on, these reports are aggregated
and used in the development process to 1) understand whether it is a new or an
existing issue, 2) assign these bugs to appropriate developers, and 3) gain a
general overview of the application's bug landscape. The efficiency of report
aggregation and subsequent operations heavily depends on the quality of the
report similarity metric. However, a distinctive feature of this kind of report
is that no textual input from the user (i.e., bug description) is available: it
contains only stack trace information.
  In this paper, we present S3M (&quot;extreme&quot;) -- the first approach to computing
stack trace similarity based on deep learning. It is based on a siamese
architecture that uses a biLSTM encoder and a fully-connected classifier to
compute similarity. Our experiments demonstrate the superiority of our approach
over the state-of-the-art on both open-sourced data and a private JetBrains
dataset. Additionally, we review the impact of stack trace trimming on the
quality of the results.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10526</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10529</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>White Paper Machine Learning in Certified Systems</dc:title>
 <dc:creator>Delseny, Herv&#xe9;</dc:creator>
 <dc:creator>Gabreau, Christophe</dc:creator>
 <dc:creator>Gauffriau, Adrien</dc:creator>
 <dc:creator>Beaudouin, Bernard</dc:creator>
 <dc:creator>Ponsolle, Ludovic</dc:creator>
 <dc:creator>Alecu, Lucian</dc:creator>
 <dc:creator>Bonnin, Hugues</dc:creator>
 <dc:creator>Beltran, Brice</dc:creator>
 <dc:creator>Duchel, Didier</dc:creator>
 <dc:creator>Ginestet, Jean-Brice</dc:creator>
 <dc:creator>Hervieu, Alexandre</dc:creator>
 <dc:creator>Martinez, Ghilaine</dc:creator>
 <dc:creator>Pasquet, Sylvain</dc:creator>
 <dc:creator>Delmas, Kevin</dc:creator>
 <dc:creator>Pagetti, Claire</dc:creator>
 <dc:creator>Gabriel, Jean-Marc</dc:creator>
 <dc:creator>Chapdelaine, Camille</dc:creator>
 <dc:creator>Picard, Sylvaine</dc:creator>
 <dc:creator>Damour, Mathieu</dc:creator>
 <dc:creator>Cappi, Cyril</dc:creator>
 <dc:creator>Gard&#xe8;s, Laurent</dc:creator>
 <dc:creator>De Grancey, Florence</dc:creator>
 <dc:creator>Jenn, Eric</dc:creator>
 <dc:creator>Lefevre, Baptiste</dc:creator>
 <dc:creator>Flandin, Gregory</dc:creator>
 <dc:creator>Gerchinovitz, S&#xe9;bastien</dc:creator>
 <dc:creator>Mamalet, Franck</dc:creator>
 <dc:creator>Albore, Alexandre</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>K.7.3</dc:subject>
 <dc:description>  Machine Learning (ML) seems to be one of the most promising solution to
automate partially or completely some of the complex tasks currently realized
by humans, such as driving vehicles, recognizing voice, etc. It is also an
opportunity to implement and embed new capabilities out of the reach of
classical implementation techniques. However, ML techniques introduce new
potential risks. Therefore, they have only been applied in systems where their
benefits are considered worth the increase of risk. In practice, ML techniques
raise multiple challenges that could prevent their use in systems submitted to
certification constraints. But what are the actual challenges? Can they be
overcome by selecting appropriate ML techniques, or by adopting new engineering
or certification practices? These are some of the questions addressed by the ML
Certification 3 Workgroup (WG) set-up by the Institut de Recherche
Technologique Saint Exup\'ery de Toulouse (IRT), as part of the DEEL Project.
</dc:description>
 <dc:description>Comment: 113 pages, White paper</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10529</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10533</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resilient Cooperative Adaptive Cruise Control for Autonomous Vehicles
  Using Machine Learning</dc:title>
 <dc:creator>Boddupalli, Srivalli</dc:creator>
 <dc:creator>Rao, Akash Someshwar</dc:creator>
 <dc:creator>Ray, Sandip</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Cooperative Adaptive Cruise Control (CACC) is a fundamental connected vehicle
application that extends Adaptive Cruise Control by exploiting
vehicle-to-vehicle (V2V) communication. CACC is a crucial ingredient for
numerous autonomous vehicle functionalities including platooning, distributed
route management, etc. Unfortunately, malicious V2V communications can subvert
CACC, leading to string instability and road accidents. In this paper, we
develop a novel resiliency infrastructure, RACCON, for detecting and mitigating
V2V attacks on CACC. RACCON uses machine learning to develop an on-board
prediction model that captures anomalous vehicular responses and performs
mitigation in real time. RACCON-enabled vehicles can exploit the high
efficiency of CACC without compromising safety, even under potentially
adversarial scenarios. We present extensive experimental evaluation to
demonstrate the efficacy of RACCON.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10533</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10546</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovering an Algorithm Actually Learning Restricted Single Occurrence
  Regular Expression with Interleaving</dc:title>
 <dc:creator>Wang, Xiaofan</dc:creator>
 <dc:creator>Zhang, Xiaolan</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  A recent paper proposed an algorithm iSOIRE, which combines single-occurrence
automaton (SOA) and maximum independent set (MIS) to learn a subclass
single-occurrence regular expressions with interleaving (SOIREs) and claims the
learnt expression is SOIRE, which has unrestricted usage for interleaving.
However, in reality, the learnt expression still has many restrictions for
using interleaving, even does for Kleene-star or interation, i.e, the learnt
expression is not an SOIRE, we prove that by examples. In this paper, for the
algorithm iSOIRE, we first give the basic notions, then provide analyses about
incorrectness, finally present the correct result learnt by iSOIRE. Our
theoretical analyses demonstrate that the result derived by iSOIRE belongs to a
subclass of SOIREs.
</dc:description>
 <dc:description>Comment: 6 papges</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10546</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10549</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inductive Inference in Supervised Classification</dc:title>
 <dc:creator>Amiryousefi, Ali</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  Inductive inference in supervised classification context constitutes to
methods and approaches to assign some objects or items into different
predefined classes using a formal rule that is derived from training data and
possibly some additional auxiliary information. The optimality of such an
assignment varies under different conditions due to intrinsic attributes of the
objects being considered for such a task. One of these cases is when all the
objects' features are discrete variables with a priori known categories. As
another example, one can consider a modification of this case with a priori
unknown categories. These two cases are the main focus of this thesis and based
on Bayesian inductive theories, de Finetti type exchangeability is a suitable
assumption that facilitates the derivation of classifiers in the former
scenario. On the contrary, this type of exchangeability is not applicable in
the latter case, instead, it is possible to utilise the partition
exchangeability due to John Kingman. These two types of exchangeabilities are
discussed and furthermore here I investigate inductive supervised classifiers
based on both types of exchangeabilities. I further demonstrate that the
classifiers based on de Finetti type exchangeability can optimally handle test
items independently of each other in the presence of infinite amounts of
training data while on the other hand, classifiers based on partition
exchangeability still continue to benefit from joint labelling of all the test
items. Additionally, it is shown that the inductive learning process for the
simultaneous classifier saturates when the amount of test data tends to
infinity.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10549</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10550</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gender and Racial Fairness in Depression Research using Social Media</dc:title>
 <dc:creator>Aguirre, Carlos</dc:creator>
 <dc:creator>Harrigian, Keith</dc:creator>
 <dc:creator>Dredze, Mark</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Multiple studies have demonstrated that behavior on internet-based social
media platforms can be indicative of an individual's mental health status. The
widespread availability of such data has spurred interest in mental health
research from a computational lens. While previous research has raised concerns
about possible biases in models produced from this data, no study has
quantified how these biases actually manifest themselves with respect to
different demographic groups, such as gender and racial/ethnic groups. Here, we
analyze the fairness of depression classifiers trained on Twitter data with
respect to gender and racial demographic groups. We find that model performance
systematically differs for underrepresented groups and that these discrepancies
cannot be fully explained by trivial data representation issues. Our study
concludes with recommendations on how to avoid these biases in future research.
</dc:description>
 <dc:description>Comment: Accepted to EACL 2021</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10550</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10559</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CDFI: Compression-Driven Network Design for Frame Interpolation</dc:title>
 <dc:creator>Ding, Tianyu</dc:creator>
 <dc:creator>Liang, Luming</dc:creator>
 <dc:creator>Zhu, Zhihui</dc:creator>
 <dc:creator>Zharkov, Ilya</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  DNN-based frame interpolation--that generates the intermediate frames given
two consecutive frames--typically relies on heavy model architectures with a
huge number of features, preventing them from being deployed on systems with
limited resources, e.g., mobile devices. We propose a compression-driven
network design for frame interpolation (CDFI), that leverages model pruning
through sparsity-inducing optimization to significantly reduce the model size
while achieving superior performance. Concretely, we first compress the
recently proposed AdaCoF model and show that a 10X compressed AdaCoF performs
similarly as its original counterpart; then we further improve this compressed
model by introducing a multi-resolution warping module, which boosts visual
consistencies with multi-level details. As a consequence, we achieve a
significant performance gain with only a quarter in size compared with the
original AdaCoF. Moreover, our model performs favorably against other
state-of-the-arts in a broad range of datasets. Finally, the proposed
compression-driven framework is generic and can be easily transferred to other
DNN-based frame interpolation algorithm. Our source code is available at
https://github.com/tding1/CDFI.
</dc:description>
 <dc:description>Comment: To appear in the proceedings of 2021 IEEE/CVF Conference on Computer
  Vision and Pattern Recognition (CVPR)</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10561</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Physics-Inspired Heuristics for Soft MIMO Detection in 5G New Radio and
  Beyond</dc:title>
 <dc:creator>Kim, Minsung</dc:creator>
 <dc:creator>Mandr&#xe0;, Salvatore</dc:creator>
 <dc:creator>Venturelli, Davide</dc:creator>
 <dc:creator>Jamieson, Kyle</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Overcoming the conventional trade-off between throughput and bit error rate
(BER) performance, versus computational complexity is a long-term challenge for
uplink Multiple-Input Multiple-Output (MIMO) detection in base station design
for the cellular 5G New Radio roadmap, as well as in next generation wireless
local area networks. In this work, we present ParaMax, a MIMO detector
architecture that for the first time brings to bear physics-inspired parallel
tempering algorithmic techniques [28, 50, 67] on this class of problems.
ParaMax can achieve near optimal maximum-likelihood (ML) throughput performance
in the Large MIMO regime, Massive MIMO systems where the base station has
additional RF chains, to approach the number of base station antennas, in order
to support even more parallel spatial streams. ParaMax is able to achieve a
near ML-BER performance up to 160x160 and 80x80 Large MIMO for low-order
modulations such as BPSK and QPSK, respectively, only requiring less than tens
of processing elements. With respect to Massive MIMO systems, in 12x24 MIMO
with 16-QAM at SNR 16 dB, ParaMax achieves 330 Mbits/s near-optimal system
throughput with 4--8 processing elements per subcarrier, which is approximately
1.4x throughput than linear detector-based Massive MIMO systems.
</dc:description>
 <dc:description>Comment: ACM MobiCom '21 (https://doi.org/10.1145/3447993.3448619)</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10561</dc:identifier>
 <dc:identifier>doi:10.1145/3447993.3448619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10562</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Grasping with Reachability and Motion Awareness</dc:title>
 <dc:creator>Akinola, Iretiayo</dc:creator>
 <dc:creator>Xu, Jingxi</dc:creator>
 <dc:creator>Song, Shuran</dc:creator>
 <dc:creator>Allen, Peter K.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Grasping in dynamic environments presents a unique set of challenges. A
stable and reachable grasp can become unreachable and unstable as the target
object moves, motion planning needs to be adaptive and in real time, the delay
in computation makes prediction necessary. In this paper, we present a dynamic
grasping framework that is reachability-aware and motion-aware. Specifically,
we model the reachability space of the robot using a signed distance field
which enables us to quickly screen unreachable grasps. Also, we train a neural
network to predict the grasp quality conditioned on the current motion of the
target. Using these as ranking functions, we quickly filter a large grasp
database to a few grasps in real time. In addition, we present a seeding
approach for arm motion generation that utilizes solution from previous time
step. This quickly generates a new arm trajectory that is close to the previous
plan and prevents fluctuation. We implement a recurrent neural network (RNN)
for modelling and predicting the object motion. Our extensive experiments
demonstrate the importance of each of these components and we validate our
pipeline on a real robot.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10562</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10567</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CLTA: Contents and Length-based Temporal Attention for Few-shot Action
  Recognition</dc:title>
 <dc:creator>Bo, Yang</dc:creator>
 <dc:creator>Lu, Yangdi</dc:creator>
 <dc:creator>He, Wenbo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Few-shot action recognition has attracted increasing attention due to the
difficulty in acquiring the properly labelled training samples. Current works
have shown that preserving spatial information and comparing video descriptors
are crucial for few-shot action recognition. However, the importance of
preserving temporal information is not well discussed. In this paper, we
propose a Contents and Length-based Temporal Attention (CLTA) model, which
learns customized temporal attention for the individual video to tackle the
few-shot action recognition problem. CLTA utilizes the Gaussian likelihood
function as the template to generate temporal attention and trains the learning
matrices to study the mean and standard deviation based on both frame contents
and length. We show that even a not fine-tuned backbone with an ordinary
softmax classifier can still achieve similar or better results compared to the
state-of-the-art few-shot action recognition with precisely captured temporal
attention.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10567</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10570</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards an Understanding of Why and How ICT Projects Are Initiated:
  Analysis via Repertory Grid</dc:title>
 <dc:creator>Yi, Htike Htike Wut</dc:creator>
 <dc:creator>MacDonell, Stephen G.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Contemporary business innovation relies increasingly on information and
communications technology (ICT) solutions. As ICT initiatives are generally
implemented via projects the management of ICT projects has come under
increasing scrutiny. ICT projects continue to fail; as a result, while research
in ICT project management has indeed increased, many challenges for research
and practice remain. Many studies have addressed the execution and management
of ICT projects and the many factors that might relate to project outcomes.
Very few, however, have considered ICT project initiation and the crucial
decisions made at that very early, pre-life cycle stage. The primary intent of
this research is therefore to investigate ICT projects with a particular focus
on their initiation. In doing so we wished to understand why ICT projects are
started, and how they are moved from idea or proposal to supported reality. A
combination of semi-structured interviews and the repertory grid data
collection and analysis method was employed to investigate and validate the
motivating factors that influence individual IT Managers' project initiation
decisions and the methods they use to transition from idea to enacted project.
Our results showed that there are indeed multiple underlying reasons for the
decisions made at this early stage and that there are some especially common
decision drivers. Some were expected, in the sense that they mapped to
recommended best practice. For instance, most projects are motivated by a
desire to achieve efficiencies or cost savings, and their potential tends to be
assessed using cost benefit analysis. Other results were more surprising -
competitor pressure was not a common driver for ICT project initiation in our
analysis. Unsurprisingly, formal evaluation methods are more frequently used to
assess project proposals when those projects are larger and higher profile.
(Abridged)
</dc:description>
 <dc:description>Comment: Conference paper, 2 figures, 18 tables</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10570</dc:identifier>
 <dc:identifier>Proceedings of the 2014 International Conference of the
  Association Global Management Studies (ICAGMS2014). Oxford, UK, AGMS, pp.1-18</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10571</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generic Perceptual Loss for Modeling Structured Output Dependencies</dc:title>
 <dc:creator>Liu, Yifan</dc:creator>
 <dc:creator>Chen, Hao</dc:creator>
 <dc:creator>Chen, Yu</dc:creator>
 <dc:creator>Yin, Wei</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The perceptual loss has been widely used as an effective loss term in image
synthesis tasks including image super-resolution, and style transfer. It was
believed that the success lies in the high-level perceptual feature
representations extracted from CNNs pretrained with a large set of images. Here
we reveal that, what matters is the network structure instead of the trained
weights. Without any learning, the structure of a deep network is sufficient to
capture the dependencies between multiple levels of variable statistics using
multiple layers of CNNs. This insight removes the requirements of pre-training
and a particular network structure (commonly, VGG) that are previously assumed
for the perceptual loss, thus enabling a significantly wider range of
applications. To this end, we demonstrate that a randomly-weighted deep CNN can
be used to model the structured dependencies of outputs. On a few dense
per-pixel prediction tasks such as semantic segmentation, depth estimation and
instance segmentation, we show improved results of using the extended
randomized perceptual loss, compared to the baselines using pixel-wise loss
alone. We hope that this simple, extended perceptual loss may serve as a
generic structured-output loss that is applicable to most structured output
learning tasks.
</dc:description>
 <dc:description>Comment: Accepted to Proc. IEEE Conf. Computer Vision and Pattern Recognition
  (CVPR), 2021</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10571</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10572</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum-inspired Multimodal Fusion for Video Sentiment Analysis</dc:title>
 <dc:creator>Li, Qiuchi</dc:creator>
 <dc:creator>Gkoumas, Dimitris</dc:creator>
 <dc:creator>Lioma, Christina</dc:creator>
 <dc:creator>Melucci, Massimo</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  We tackle the crucial challenge of fusing different modalities of features
for multimodal sentiment analysis. Mainly based on neural networks, existing
approaches largely model multimodal interactions in an implicit and
hard-to-understand manner. We address this limitation with inspirations from
quantum theory, which contains principled methods for modeling complicated
interactions and correlations. In our quantum-inspired framework, the word
interaction within a single modality and the interaction across modalities are
formulated with superposition and entanglement respectively at different
stages. The complex-valued neural network implementation of the framework
achieves comparable results to state-of-the-art systems on two benchmarking
video sentiment analysis datasets. In the meantime, we produce the unimodal and
bimodal sentiment directly from the model to interpret the entangled decision.
</dc:description>
 <dc:description>Comment: Post-print accepted by Information Fusion</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10572</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10573</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enabling OpenMP Task Parallelism on Multi-FPGAs</dc:title>
 <dc:creator>Nepomuceno, R.</dc:creator>
 <dc:creator>Sterle, R.</dc:creator>
 <dc:creator>Valarini, G.</dc:creator>
 <dc:creator>Pereira, M.</dc:creator>
 <dc:creator>Yviquel, H.</dc:creator>
 <dc:creator>Araujo, G.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  FPGA-based hardware accelerators have received increasing attention mainly
due to their ability to accelerate deep pipelined applications, thus resulting
in higher computational performance and energy efficiency. Nevertheless, the
amount of resources available on even the most powerful FPGA is still not
enough to speed up very large modern workloads. To achieve that, FPGAs need to
be interconnected in a Multi-FPGA architecture capable of accelerating a single
application. However, programming such architecture is a challenging endeavor
that still requires additional research. This paper extends the OpenMP
task-based computation offloading model to enable a number of FPGAs to work
together as a single Multi-FPGA architecture. Experimental results for a set of
OpenMP stencil applications running on a Multi-FPGA platform consisting of 6
Xilinx VC709 boards interconnected through fiber-optic links have shown close
to linear speedups as the number of FPGAs and IP-cores per FPGA increase.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10573</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10574</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hopper: Multi-hop Transformer for Spatiotemporal Reasoning</dc:title>
 <dc:creator>Zhou, Honglu</dc:creator>
 <dc:creator>Kadav, Asim</dc:creator>
 <dc:creator>Lai, Farley</dc:creator>
 <dc:creator>Niculescu-Mizil, Alexandru</dc:creator>
 <dc:creator>Min, Martin Renqiang</dc:creator>
 <dc:creator>Kapadia, Mubbasir</dc:creator>
 <dc:creator>Graf, Hans Peter</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper considers the problem of spatiotemporal object-centric reasoning
in videos. Central to our approach is the notion of object permanence, i.e.,
the ability to reason about the location of objects as they move through the
video while being occluded, contained or carried by other objects. Existing
deep learning based approaches often suffer from spatiotemporal biases when
applied to video reasoning problems. We propose Hopper, which uses a Multi-hop
Transformer for reasoning object permanence in videos. Given a video and a
localization query, Hopper reasons over image and object tracks to
automatically hop over critical frames in an iterative fashion to predict the
final position of the object of interest. We demonstrate the effectiveness of
using a contrastive loss to reduce spatiotemporal biases. We evaluate over
CATER dataset and find that Hopper achieves 73.2% Top-1 accuracy using just 1
FPS by hopping through just a few critical frames. We also demonstrate Hopper
can perform long-term reasoning by building a CATER-h dataset that requires
multi-step reasoning to localize objects of interest correctly.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10574</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10578</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transfer Learning of Memory Kernels in Coarse-grained Modeling</dc:title>
 <dc:creator>Ma, Zhan</dc:creator>
 <dc:creator>Wang, Shu</dc:creator>
 <dc:creator>Kim, Minhee</dc:creator>
 <dc:creator>Liu, Kaibo</dc:creator>
 <dc:creator>Chen, Chun-Long</dc:creator>
 <dc:creator>Pan, Wenxiao</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  The present work concerns the transferability of coarse-grained (CG) modeling
in reproducing the dynamic properties of the reference atomistic systems across
a range of parameters. In particular, we focus on implicit-solvent CG modeling
of polymer solutions. The CG model is based on the generalized Langevin
equation, where the memory kernel plays the critical role in determining the
dynamics in all time scales. Thus, we propose methods for transfer learning of
memory kernels. The key ingredient of our methods is Gaussian process
regression. By integration with the model order reduction via proper orthogonal
decomposition and the active learning technique, the transfer learning can be
practically efficient and requires minimum training data. Through two example
polymer solution systems, we demonstrate the accuracy and efficiency of the
proposed transfer learning methods in the construction of transferable memory
kernels. The transferability allows for out-of-sample predictions, even in the
extrapolated domain of parameters. Built on the transferable memory kernels,
the CG models can reproduce the dynamic properties of polymers in all time
scales at different thermodynamic conditions (such as temperature and solvent
viscosity) and for different systems with varying concentrations and lengths of
polymers.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10578</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10579</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Experiment Study on Federated LearningTestbed</dc:title>
 <dc:creator>Shen, Cheng</dc:creator>
 <dc:creator>Xue, Wanli</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  While the Internet of Things (IoT) can benefit from machine learning by
outsourcing model training on the cloud, user data exposure to an untrusted
cloud service provider can pose threat to user privacy. Recently, federated
learning is proposed as an approach for privacy-preserving machine learning
(PPML) for the IoT, while its practicability remains unclear. This work
presents the evaluation on the efficiency and privacy performance of a readily
available federated learning framework based on PySyft, a Python library for
distributed deep learning. It is observed that the training speed of the
framework is significantly slower than of the centralized approach due to
communication overhead. Meanwhile, the framework bears some vulnerability to
potential man-in-the-middle attacks at the network level. The report serves as
a starting point for PPML performance analysis and suggests the future
direction for PPML framework development.
</dc:description>
 <dc:description>Comment: Accepted by SMARTCOM2021</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10579</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10582</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Empirical Optimization on Post-Disaster Communication Restoration for
  Social Equality</dc:title>
 <dc:creator>Liu, Jianqing</dc:creator>
 <dc:creator>Dong, Shangjia</dc:creator>
 <dc:creator>Morris, Thomas</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Disasters are constant threats to humankind, and beyond losses in lives, they
cause many implicit yet profound societal issues such as wealth disparity and
digital divide. Among those recovery measures in the aftermath of disasters,
restoring and improving communication services is of vital importance. Although
existing works have proposed many architectural and protocol designs, none of
them have taken human factors and social equality into consideration. Recent
sociological studies have shown that people from marginalized groups (e.g.,
minority, low income, and poor education) are more vulnerable to communication
outages. In this work, we take pioneering efforts in integrating human factors
into an empirical optimization model to determine strategies for post-disaster
communication restoration. We cast the design into a mix-integer non-linear
programming problem, which is proven too complex to be solved. Through a suite
of convex relaxations, we then develop heuristic algorithms to efficiently
solve the transformed optimization problem. Based on a collected dataset, we
further evaluate and demonstrate how our design will prioritize communication
services for vulnerable people and promote social equality compared with an
existing modeling benchmark.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10582</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10583</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Transfer for Multi-Source Domain Adaptation</dc:title>
 <dc:creator>Li, Yunsheng</dc:creator>
 <dc:creator>Yuan, Lu</dc:creator>
 <dc:creator>Chen, Yinpeng</dc:creator>
 <dc:creator>Wang, Pei</dc:creator>
 <dc:creator>Vasconcelos, Nuno</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent works of multi-source domain adaptation focus on learning a
domain-agnostic model, of which the parameters are static. However, such a
static model is difficult to handle conflicts across multiple domains, and
suffers from a performance degradation in both source domains and target
domain. In this paper, we present dynamic transfer to address domain conflicts,
where the model parameters are adapted to samples. The key insight is that
adapting model across domains is achieved via adapting model across samples.
Thus, it breaks down source domain barriers and turns multi-source domains into
a single-source domain. This also simplifies the alignment between source and
target domains, as it only requires the target domain to be aligned with any
part of the union of source domains. Furthermore, we find dynamic transfer can
be simply modeled by aggregating residual matrices and a static convolution
matrix. Experimental results show that, without using domain labels, our
dynamic transfer outperforms the state-of-the-art method by more than 3% on the
large multi-source domain adaptation datasets -- DomainNet. Source code is at
https://github.com/liyunsheng13/DRT.
</dc:description>
 <dc:description>Comment: Accepted by CVPR 2021</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10584</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HW-NAS-Bench:Hardware-Aware Neural Architecture Search Benchmark</dc:title>
 <dc:creator>Li, Chaojian</dc:creator>
 <dc:creator>Yu, Zhongzhi</dc:creator>
 <dc:creator>Fu, Yonggan</dc:creator>
 <dc:creator>Zhang, Yongan</dc:creator>
 <dc:creator>Zhao, Yang</dc:creator>
 <dc:creator>You, Haoran</dc:creator>
 <dc:creator>Yu, Qixuan</dc:creator>
 <dc:creator>Wang, Yue</dc:creator>
 <dc:creator>Lin, Yingyan</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  HardWare-aware Neural Architecture Search (HW-NAS) has recently gained
tremendous attention by automating the design of DNNs deployed in more
resource-constrained daily life devices. Despite its promising performance,
developing optimal HW-NAS solutions can be prohibitively challenging as it
requires cross-disciplinary knowledge in the algorithm, micro-architecture, and
device-specific compilation. First, to determine the hardware-cost to be
incorporated into the NAS process, existing works mostly adopt either
pre-collected hardware-cost look-up tables or device-specific hardware-cost
models. Both of them limit the development of HW-NAS innovations and impose a
barrier-to-entry to non-hardware experts. Second, similar to generic NAS, it
can be notoriously difficult to benchmark HW-NAS algorithms due to their
significant required computational resources and the differences in adopted
search spaces, hyperparameters, and hardware devices. To this end, we develop
HW-NAS-Bench, the first public dataset for HW-NAS research which aims to
democratize HW-NAS research to non-hardware experts and make HW-NAS research
more reproducible and accessible. To design HW-NAS-Bench, we carefully
collected the measured/estimated hardware performance of all the networks in
the search spaces of both NAS-Bench-201 and FBNet, on six hardware devices that
fall into three categories (i.e., commercial edge devices, FPGA, and ASIC).
Furthermore, we provide a comprehensive analysis of the collected measurements
in HW-NAS-Bench to provide insights for HW-NAS research. Finally, we
demonstrate exemplary user cases to (1) show that HW-NAS-Bench allows
non-hardware experts to perform HW-NAS by simply querying it and (2) verify
that dedicated device-specific HW-NAS can indeed lead to optimal accuracy-cost
trade-offs. The codes and all collected data are available at
https://github.com/RICE-EIC/HW-NAS-Bench.
</dc:description>
 <dc:description>Comment: Accepted at ICLR 2021 (Spotlight)</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10584</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10585</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The evolving ecosystem of COVID-19 contact tracing applications</dc:title>
 <dc:creator>Levy, Benjamin</dc:creator>
 <dc:creator>Stewart, Matthew</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Since the outbreak of the novel coronavirus, COVID-19, there has been
increased interest in the use of digital contact tracing as a means of stopping
chains of viral transmission, provoking alarm from privacy advocates.
Concerning the ethics of this technology, recent studies have predominantly
focused on (1) the formation of guidelines for ethical contact tracing, (2) the
analysis of specific implementations, or (3) the review of a select number of
contact tracing applications and their relevant privacy or ethical
implications. In this study, we provide a comprehensive survey of the evolving
ecosystem of COVID-19 tracing applications, examining 152 contact tracing
applications and assessing the extent to which they comply with existing
guidelines for ethical contact tracing. The assessed criteria cover areas
including data collection and storage, transparency and consent, and whether
the implementation is open source. We find that although many apps released
early in the pandemic fell short of best practices, apps released more
recently, following the publication of the Apple/Google exposure notification
protocol, have tended to be more closely aligned with ethical contact tracing
principles. This dataset will be publicly available and may be updated as the
pandemic continues.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10585</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10592</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fusion-FlowNet: Energy-Efficient Optical Flow Estimation using Sensor
  Fusion and Deep Fused Spiking-Analog Network Architectures</dc:title>
 <dc:creator>Lee, Chankyu</dc:creator>
 <dc:creator>Kosta, Adarsh Kumar</dc:creator>
 <dc:creator>Roy, Kaushik</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Standard frame-based cameras that sample light intensity frames are heavily
impacted by motion blur for high-speed motion and fail to perceive scene
accurately when the dynamic range is high. Event-based cameras, on the other
hand, overcome these limitations by asynchronously detecting the variation in
individual pixel intensities. However, event cameras only provide information
about pixels in motion, leading to sparse data. Hence, estimating the overall
dense behavior of pixels is difficult. To address such issues associated with
the sensors, we present Fusion-FlowNet, a sensor fusion framework for
energy-efficient optical flow estimation using both frame- and event-based
sensors, leveraging their complementary characteristics. Our proposed network
architecture is also a fusion of Spiking Neural Networks (SNNs) and Analog
Neural Networks (ANNs) where each network is designed to simultaneously process
asynchronous event streams and regular frame-based images, respectively. Our
network is end-to-end trained using unsupervised learning to avoid expensive
video annotations. The method generalizes well across distinct environments
(rapid motion and challenging lighting conditions) and demonstrates
state-of-the-art optical flow prediction on the Multi-Vehicle Stereo Event
Camera (MVSEC) dataset. Furthermore, our network offers substantial savings in
terms of the number of network parameters and computational energy cost.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10592</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10600</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GCN-ALP: Addressing Matching Collisions in Anchor Link Prediction</dc:title>
 <dc:creator>Gao, Hao</dc:creator>
 <dc:creator>Wang, Yongqing</dc:creator>
 <dc:creator>Lyu, Shanshan</dc:creator>
 <dc:creator>Shen, Huawei</dc:creator>
 <dc:creator>Cheng, Xueqi</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Nowadays online users prefer to join multiple social media for the purpose of
socialized online service. The problem \textit{anchor link prediction} is
formalized to link user data with the common ground on user profile, content
and network structure across social networks. Most of the traditional works
concentrated on learning matching function with explicit or implicit features
on observed user data. However, the low quality of observed user data confuses
the judgment on anchor links, resulting in the matching collision problem in
practice. In this paper, we explore local structure consistency and then
construct a matching graph in order to circumvent matching collisions.
Furthermore, we propose graph convolution networks with mini-batch strategy,
efficiently solving anchor link prediction on matching graph. The experimental
results on three real application scenarios show the great potentials of our
proposed method in both prediction accuracy and efficiency. In addition, the
visualization of learned embeddings provides us a qualitative way to understand
the inference of anchor links on the matching graph.
</dc:description>
 <dc:description>Comment: 8 pages, 5figures, ICKG 2020</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10600</dc:identifier>
 <dc:identifier>doi:10.1109/ICBK50248.2020.00065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10602</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HeterSkinNet: A Heterogeneous Network for Skin Weights Prediction</dc:title>
 <dc:creator>Pan, Xiaoyu</dc:creator>
 <dc:creator>Huang, Jiancong</dc:creator>
 <dc:creator>Mai, Jiaming</dc:creator>
 <dc:creator>Wang, He</dc:creator>
 <dc:creator>Li, Honglin</dc:creator>
 <dc:creator>Su, Tongkui</dc:creator>
 <dc:creator>Wang, Wenjun</dc:creator>
 <dc:creator>Jin, Xiaogang</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Character rigging is universally needed in computer graphics but notoriously
laborious. We present a new method, HeterSkinNet, aiming to fully automate such
processes and significantly boost productivity. Given a character mesh and
skeleton as input, our method builds a heterogeneous graph that treats the mesh
vertices and the skeletal bones as nodes of different types and uses graph
convolutions to learn their relationships. To tackle the graph heterogeneity,
we propose a new graph network convolution operator that transfers information
between heterogeneous nodes. The convolution is based on a new distance
HollowDist that quantifies the relations between mesh vertices and bones. We
show that HeterSkinNet is robust for production characters by providing the
ability to incorporate meshes and skeletons with arbitrary topologies and
morphologies (e.g., out-of-body bones, disconnected mesh components, etc.).
Through exhaustive comparisons, we show that HeterSkinNet outperforms
state-of-the-art methods by large margins in terms of rigging accuracy and
naturalness. HeterSkinNet provides a solution for effective and robust
character rigging.
</dc:description>
 <dc:description>Comment: I3D 2021</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10602</dc:identifier>
 <dc:identifier>doi:10.1145/3451262</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10603</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Noise Modulation: Let Your Model Interpret Itself</dc:title>
 <dc:creator>Li, Haoyang</dc:creator>
 <dc:creator>Wang, Xinggang</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Given the great success of Deep Neural Networks(DNNs) and the black-box
nature of it,the interpretability of these models becomes an important
issue.The majority of previous research works on the post-hoc interpretation of
a trained model.But recently, adversarial training shows that it is possible
for a model to have an interpretable input-gradient through
training.However,adversarial training lacks efficiency for interpretability.To
resolve this problem, we construct an approximation of the adversarial
perturbations and discover a connection between adversarial training and
amplitude modulation. Based on a digital analogy,we propose noise modulation as
an efficient and model-agnostic alternative to train a model that interprets
itself with input-gradients.Experiment results show that noise modulation can
effectively increase the interpretability of input-gradients model-agnosticly.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10603</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10607</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DCF-ASN: Coarse-to-fine Real-time Visual Tracking via Discriminative
  Correlation Filter and Attentional Siamese Network</dc:title>
 <dc:creator>Xue, Xizhe</dc:creator>
 <dc:creator>Li, Ying</dc:creator>
 <dc:creator>Yin, Xiaoyue</dc:creator>
 <dc:creator>Shen, Qiang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Discriminative correlation filters (DCF) and siamese networks have achieved
promising performance on visual tracking tasks thanks to their superior
computational efficiency and reliable similarity metric learning, respectively.
However, how to effectively take advantages of powerful deep networks, while
maintaining the real-time response of DCF, remains a challenging problem.
Embedding the cross-correlation operator as a separate layer into siamese
networks is a popular choice to enhance the tracking accuracy. Being a key
component of such a network, the correlation layer is updated online together
with other parts of the network. Yet, when facing serious disturbance, fused
trackers may still drift away from the target completely due to accumulated
errors. To address these issues, we propose a coarse-to-fine tracking
framework, which roughly infers the target state via an online-updating DCF
module first and subsequently, finely locates the target through an
offline-training asymmetric siamese network (ASN). Benefitting from the
guidance of DCF and the learned channel weights obtained through exploiting the
given ground-truth template, ASN refines feature representation and implements
precise target localization. Systematic experiments on five popular tracking
datasets demonstrate that the proposed DCF-ASN achieves the state-of-the-art
performance while exhibiting good tracking efficiency.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10608</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training image classifiers using Semi-Weak Label Data</dc:title>
 <dc:creator>Zhang, Anxiang</dc:creator>
 <dc:creator>Shah, Ankit</dc:creator>
 <dc:creator>Raj, Bhiksha</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In Multiple Instance learning (MIL), weak labels are provided at the bag
level with only presence/absence information known. However, there is a
considerable gap in performance in comparison to a fully supervised model,
limiting the practical applicability of MIL approaches. Thus, this paper
introduces a novel semi-weak label learning paradigm as a middle ground to
mitigate the problem. We define semi-weak label data as data where we know the
presence or absence of a given class and the exact count of each class as
opposed to knowing the label proportions. We then propose a two-stage framework
to address the problem of learning from semi-weak labels. It leverages the fact
that counting information is non-negative and discrete. Experiments are
conducted on generated samples from CIFAR-10. We compare our model with a
fully-supervised setting baseline, a weakly-supervised setting baseline and
learning from pro-portion (LLP) baseline. Our framework not only outperforms
both baseline models for MIL-based weakly super-vised setting and learning from
proportion setting, but also gives comparable results compared to the fully
supervised model. Further, we conduct thorough ablation studies to analyze
across datasets and variation with batch size, losses architectural changes,
bag size and regularization
</dc:description>
 <dc:description>Comment: First two authors contributed equally</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10608</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10609</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boosting Adversarial Transferability through Enhanced Momentum</dc:title>
 <dc:creator>Wang, Xiaosen</dc:creator>
 <dc:creator>Lin, Jiadong</dc:creator>
 <dc:creator>Hu, Han</dc:creator>
 <dc:creator>Wang, Jingdong</dc:creator>
 <dc:creator>He, Kun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep learning models are known to be vulnerable to adversarial examples
crafted by adding human-imperceptible perturbations on benign images. Many
existing adversarial attack methods have achieved great white-box attack
performance, but exhibit low transferability when attacking other models.
Various momentum iterative gradient-based methods are shown to be effective to
improve the adversarial transferability. In what follows, we propose an
enhanced momentum iterative gradient-based method to further enhance the
adversarial transferability. Specifically, instead of only accumulating the
gradient during the iterative process, we additionally accumulate the average
gradient of the data points sampled in the gradient direction of the previous
iteration so as to stabilize the update direction and escape from poor local
maxima. Extensive experiments on the standard ImageNet dataset demonstrate that
our method could improve the adversarial transferability of momentum-based
methods by a large margin of 11.1% on average. Moreover, by incorporating with
various input transformation methods, the adversarial transferability could be
further improved significantly. We also attack several extra advanced defense
models under the ensemble-model setting, and the enhancements are remarkable
with at least 7.8% on average.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10609</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10611</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge-Guided Object Discovery with Acquired Deep Impressions</dc:title>
 <dc:creator>Yuan, Jinyang</dc:creator>
 <dc:creator>Li, Bin</dc:creator>
 <dc:creator>Xue, Xiangyang</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a framework called Acquired Deep Impressions (ADI) which
continuously learns knowledge of objects as &quot;impressions&quot; for compositional
scene understanding. In this framework, the model first acquires knowledge from
scene images containing a single object in a supervised manner, and then
continues to learn from novel multi-object scene images which may contain
objects that have not been seen before without any further supervision, under
the guidance of the learned knowledge as humans do. By memorizing impressions
of objects into parameters of neural networks and applying the generative
replay strategy, the learned knowledge can be reused to generate images with
pseudo-annotations and in turn assist the learning of novel scenes. The
proposed ADI framework focuses on the acquisition and utilization of knowledge,
and is complementary to existing deep generative models proposed for
compositional scene representation. We adapt a base model to make it fall
within the ADI framework and conduct experiments on two types of datasets.
Empirical results suggest that the proposed framework is able to effectively
utilize the acquired impressions and improve the scene decomposition
performance.
</dc:description>
 <dc:description>Comment: AAAI 2021</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10611</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10615</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Impacts of Sentiments and Tones in Community-Generated Issue
  Discussions</dc:title>
 <dc:creator>Sanei, Arghavan</dc:creator>
 <dc:creator>Cheng, Jinghui</dc:creator>
 <dc:creator>Adams, Bram</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The diverse community members who contribute to the discussions on issue
tracking systems of open-source software projects often exhibit complex
affective states such as sentiments and tones. These affective states can
significantly influence the effectiveness of the issue discussions in
elaborating the initial ideas into actionable tasks that the development teams
need to address. In this paper, we present an extended empirical study to
investigate the impacts of sentiments and tones in community-generated issue
discussions. We created and validated a large dataset of sentiments and tones
in the issues posts and comments created by diverse community members in three
popular open source projects. Our analysis results drew a complex picture of
the relationships between, on the one hand, the sentiments and tones in the
issue discussions, and on the other hand, various discussion and
development-related measures such as the discussion length and the issue
resolution time. We also found that when factors such as the issue poster roles
and the issue types were controlled, sentiments and tones had varied
associations with the measures. Insights gained from these findings can support
open source community members in making and moderating effective issue
discussions and guide the design of tools to better support community
engagement.
</dc:description>
 <dc:description>Comment: 10 pages, 3 figures, CHASE2021</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10615</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10623</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Ontological Analysis of a Proposed Theory for Software Development</dc:title>
 <dc:creator>Kirk, Diana</dc:creator>
 <dc:creator>MacDonell, Stephen G.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  There is growing acknowledgement within the software engineering community
that a theory of software development is needed to integrate the myriad
methodologies that are currently popular, some of which are based on opposing
perspectives. We have been developing such a theory for a number of years. In
this paper, we overview our theory and report on a recent ontological analysis
of the theory constructs. We suggest that, once fully developed, this theory,
or one similar to it, may be applied to support situated software development,
by providing an overarching model within which software initiatives might be
categorised and understood. Such understanding would inevitably lead to greater
predictability with respect to outcomes.
</dc:description>
 <dc:description>Comment: Book Chapter, 8 pages, 1 table. arXiv admin note: substantial text
  overlap with arXiv:2103.03400</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10623</dc:identifier>
 <dc:identifier>Software Technologies. P. Lorenz, J. Cardoso, L.A. Maciaszek and
  M. van Sinderen (eds.), Springer International Publishing(2016), pp.155-171
  [ISBN 978-3-319-30141-9]</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10629</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cascade Weight Shedding in Deep Neural Networks: Benefits and Pitfalls
  for Network Pruning</dc:title>
 <dc:creator>Azarian, Kambiz</dc:creator>
 <dc:creator>Porikli, Fatih</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We report, for the first time, on the cascade weight shedding phenomenon in
deep neural networks where in response to pruning a small percentage of a
network's weights, a large percentage of the remaining is shed over a few
epochs during the ensuing fine-tuning phase. We show that cascade weight
shedding, when present, can significantly improve the performance of an
otherwise sub-optimal scheme such as random pruning. This explains why some
pruning methods may perform well under certain circumstances, but poorly under
others, e.g., ResNet50 vs. MobileNetV3. We provide insight into why the global
magnitude-based pruning, i.e., GMP, despite its simplicity, provides a
competitive performance for a wide range of scenarios. We also demonstrate
cascade weight shedding's potential for improving GMP's accuracy, and reduce
its computational complexity. In doing so, we highlight the importance of
pruning and learning-rate schedules. We shed light on weight and learning-rate
rewinding methods of re-training, showing their possible connections to the
cascade weight shedding and reason for their advantage over fine-tuning. We
also investigate cascade weight shedding's effect on the set of kept weights,
and its implications for semi-structured pruning. Finally, we give directions
for future research.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10629</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10631</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EXSCLAIM! -- An automated pipeline for the construction of labeled
  materials imaging datasets from literature</dc:title>
 <dc:creator>Schwenker, Eric</dc:creator>
 <dc:creator>Jiang, Weixin</dc:creator>
 <dc:creator>Spreadbury, Trevor</dc:creator>
 <dc:creator>Ferrier, Nicola</dc:creator>
 <dc:creator>Cossairt, Oliver</dc:creator>
 <dc:creator>Chan, Maria K. Y.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:description>  Due to recent improvements in image resolution and acquisition speed,
materials microscopy is experiencing an explosion of published imaging data.
The standard publication format, while sufficient for traditional data
ingestion scenarios where a select number of images can be critically examined
and curated manually, is not conducive to large-scale data aggregation or
analysis, hindering data sharing and reuse. Most images in publications are
presented as components of a larger figure with their explicit context buried
in the main body or caption text, so even if aggregated, collections of images
with weak or no digitized contextual labels have limited value. To solve the
problem of curating labeled microscopy data from literature, this work
introduces the EXSCLAIM! Python toolkit for the automatic EXtraction,
Separation, and Caption-based natural Language Annotation of IMages from
scientific literature. We highlight the methodology behind the construction of
EXSCLAIM! and demonstrate its ability to extract and label open-source
scientific images at high volume.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10631</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10635</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PPT-SASMM: Scalable Analytical Shared Memory Model: Predicting the
  Performance of Multicore Caches from a Single-Threaded Execution Trace</dc:title>
 <dc:creator>Barai, Atanu</dc:creator>
 <dc:creator>Chennupati, Gopinath</dc:creator>
 <dc:creator>Santhi, Nandakishore</dc:creator>
 <dc:creator>Badawy, Abdel-Hameed</dc:creator>
 <dc:creator>Arafa, Yehia</dc:creator>
 <dc:creator>Eidenbenz, Stephan</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Performance modeling of parallel applications on multicore processors remains
a challenge in computational co-design due to multicore processors' complex
design. Multicores include complex private and shared memory hierarchies. We
present a Scalable Analytical Shared Memory Model (SASMM). SASMM can predict
the performance of parallel applications running on a multicore. SASMM uses a
probabilistic and computationally-efficient method to predict the reuse
distance profiles of caches in multicores. SASMM relies on a stochastic, static
basic block-level analysis of reuse profiles. The profiles are calculated from
the memory traces of applications that run sequentially rather than using
multi-threaded traces. The experiments show that our model can predict private
L1 cache hit rates with 2.12% and shared L2 cache hit rates with about 1.50%
error rate.
</dc:description>
 <dc:description>Comment: 11 pages, 5 figures. arXiv admin note: text overlap with
  arXiv:1907.12666</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10635</dc:identifier>
 <dc:identifier>doi:10.1145/3422575.3422806</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10643</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CE-FPN: Enhancing Channel Information for Object Detection</dc:title>
 <dc:creator>Luo, Yihao</dc:creator>
 <dc:creator>Cao, Xiang</dc:creator>
 <dc:creator>Zhang, Juntao</dc:creator>
 <dc:creator>Cao, Xiang</dc:creator>
 <dc:creator>Guo, Jingjuan</dc:creator>
 <dc:creator>Shen, Haibo</dc:creator>
 <dc:creator>Wang, Tianjiang</dc:creator>
 <dc:creator>Feng, Qi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Feature pyramid network (FPN) has been an effective framework to extract
multi-scale features in object detection. However, current FPN-based methods
mostly suffer from the intrinsic flaw of channel reduction, which brings about
the loss of semantical information. And the miscellaneous fused feature maps
may cause serious aliasing effects. In this paper, we present a novel channel
enhancement feature pyramid network (CE-FPN) with three simple yet effective
modules to alleviate these problems. Specifically, inspired by sub-pixel
convolution, we propose a sub-pixel skip fusion method to perform both channel
enhancement and upsampling. Instead of the original 1x1 convolution and linear
upsampling, it mitigates the information loss due to channel reduction. Then we
propose a sub-pixel context enhancement module for extracting more feature
representations, which is superior to other context methods due to the
utilization of rich channel information by sub-pixel convolution. Furthermore,
a channel attention guided module is introduced to optimize the final
integrated features on each level, which alleviates the aliasing effect only
with a few computational burdens. Our experiments show that CE-FPN achieves
competitive performance compared to state-of-the-art FPN-based detectors on MS
COCO benchmark.
</dc:description>
 <dc:description>Comment: 9pages</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10643</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10646</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterization of the Gittins index for sequential multistage jobs</dc:title>
 <dc:creator>Aalto, Samuli</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>60K25, 90B22, 90B36, 68M20</dc:subject>
 <dc:subject>D.4.8</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  The optimal scheduling problem in single-server queueing systems is a classic
problem in queueing theory. The Gittins index policy is known to be the optimal
preemptive nonanticipating policy (both for the open version of the problem
with Poisson arrivals and the closed version without arrivals) minimizing the
expected holding costs. While the Gittins index is thoroughly characterized for
ordinary jobs whose state is described by the attained service, it is not at
all the case with jobs that have more complex structure. Recently, a class of
such jobs, the multistage jobs, were introduced, and it was shown that the
computation of Gittins index of a multistage job reduces into separable
computations for the individual stages. The characterization is, however,
indirect in the sense that it relies on the recursion for an auxiliary function
(so called SJP function) and not for the Gittins index itself. In this paper,
we answer the natural question: Is it possible to compute the Gittins index for
a multistage job more directly by recursively combining the Gittins indexes of
its individual stages? According to our results, it seems to be possible, at
least, for sequential multistage jobs that have a fixed (deterministic)
sequence of stages. We prove this for sequential two-stage jobs that have
monotonous hazard rates in both stages, but our numerical experiments give an
indication that the result could possibly be generalized to any sequential
multistage jobs. Our approach, in this paper, is based on the Whittle index
originally developed in the context of restless bandits.
</dc:description>
 <dc:description>Comment: 144 pages, no figures</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10646</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10653</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adoption and Suitability of Software Development Methods and Practices</dc:title>
 <dc:creator>Licorish, Sherlock A.</dc:creator>
 <dc:creator>Holvitie, Johannes</dc:creator>
 <dc:creator>Hyrynsalmi, Sami</dc:creator>
 <dc:creator>Lepp&#xe4;nen, Ville</dc:creator>
 <dc:creator>Sp&#xed;nola, Rodrigo O.</dc:creator>
 <dc:creator>Mendes, Thiago S.</dc:creator>
 <dc:creator>MacDonell, Stephen G.</dc:creator>
 <dc:creator>Buchan, Jim</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In seeking to complement consultants' and tool vendors' reports, there has
been an increasing academic focus on understanding the adoption and use of
software development methods and practices. We surveyed practitioners working
in Brazil, Finland, and New Zealand in a transnational study to contribute to
these efforts. Among our findings we observed that most of the 184
practitioners in our sample focused on a small portfolio of projects that were
of short duration. In addition, Scrum and Kanban were used most; however, some
practitioners also used conventional methods. Coding Standards, Simple Design
and Refactoring were used most by practitioners, and these practices were held
to be largely suitable for project and process management. Our evidence points
to the need to properly understand and support a wide range of software
methods.
</dc:description>
 <dc:description>Comment: Conference Paper, 5 pages, 1 figure, 1 table</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10653</dc:identifier>
 <dc:identifier>Proceedings of the 23rd Asia-Pacific Software Engineering
  Conference (APSEC 2016) (Hamilton, New Zealand, December 6-9, 2016). IEEE
  Press, 369-372</dc:identifier>
 <dc:identifier>doi:10.1109/APSEC.2016.062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10661</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>USTC-NELSLIP System Description for DIHARD-III Challenge</dc:title>
 <dc:creator>Wang, Yuxuan</dc:creator>
 <dc:creator>He, Maokui</dc:creator>
 <dc:creator>Niu, Shutong</dc:creator>
 <dc:creator>Sun, Lei</dc:creator>
 <dc:creator>Gao, Tian</dc:creator>
 <dc:creator>Fang, Xin</dc:creator>
 <dc:creator>Pan, Jia</dc:creator>
 <dc:creator>Du, Jun</dc:creator>
 <dc:creator>Lee, Chin-Hui</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  This system description describes our submission system to the Third DIHARD
Speech Diarization Challenge. Besides the traditional clustering based system,
the innovation of our system lies in the combination of various front-end
techniques to solve the diarization problem, including speech separation and
target-speaker based voice activity detection (TS-VAD), combined with iterative
data purification. We also adopted audio domain classification to design
domain-dependent processing. Finally, we performed post processing to do system
fusion and selection. Our best system achieved DERs of 11.30% in track 1 and
16.78% in track 2 on evaluation set, respectively.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10661</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10663</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>XProtoNet: Diagnosis in Chest Radiography with Global and Local
  Explanations</dc:title>
 <dc:creator>Kim, Eunji</dc:creator>
 <dc:creator>Kim, Siwon</dc:creator>
 <dc:creator>Seo, Minji</dc:creator>
 <dc:creator>Yoon, Sungroh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automated diagnosis using deep neural networks in chest radiography can help
radiologists detect life-threatening diseases. However, existing methods only
provide predictions without accurate explanations, undermining the
trustworthiness of the diagnostic methods. Here, we present XProtoNet, a
globally and locally interpretable diagnosis framework for chest radiography.
XProtoNet learns representative patterns of each disease from X-ray images,
which are prototypes, and makes a diagnosis on a given X-ray image based on the
patterns. It predicts the area where a sign of the disease is likely to appear
and compares the features in the predicted area with the prototypes. It can
provide a global explanation, the prototype, and a local explanation, how the
prototype contributes to the prediction of a single image. Despite the
constraint for interpretability, XProtoNet achieves state-of-the-art
classification performance on the public NIH chest X-ray dataset.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures. Accepted to CVPR2021</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10663</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10668</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>API2Com: On the Improvement of Automatically Generated Code Comments
  Using API Documentations</dc:title>
 <dc:creator>Shahbazi, Ramin</dc:creator>
 <dc:creator>Sharma, Rishab</dc:creator>
 <dc:creator>Fard, Fatemeh H.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Code comments can help in program comprehension and are considered as
important artifacts to help developers in software maintenance. However, the
comments are mostly missing or are outdated, specially in complex software
projects. As a result, several automatic comment generation models are
developed as a solution. The recent models explore the integration of external
knowledge resources such as Unified Modeling Language class diagrams to improve
the generated comments. In this paper, we propose API2Com, a model that
leverages the Application Programming Interface Documentations (API Docs) as a
knowledge resource for comment generation. The API Docs include the description
of the methods in more details and therefore, can provide better context in the
generated comments. The API Docs are used along with the code snippets and
Abstract Syntax Trees in our model. We apply the model on a large Java dataset
of over 130,000 methods and evaluate it using both Transformer and RNN-base
architectures. Interestingly, when API Docs are used, the performance increase
is negligible. We therefore run different experiments to reason about the
results. For methods that only contain one API, adding API Docs improves the
results by 4% BLEU score on average (BLEU score is an automatic evaluation
metric used in machine translation). However, as the number of APIs that are
used in a method increases, the performance of the model in generating comments
decreases due to long documentations used in the input. Our results confirm
that the API Docs can be useful in generating better comments, but, new
techniques are required to identify the most informative ones in a method
rather than using all documentations simultaneously.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10668</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10670</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Image co-segmentation via Deep Metric Learning</dc:title>
 <dc:creator>Li, Zhengwen</dc:creator>
 <dc:creator>Liu, Xiabi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Deep Metric Learning (DML) is helpful in computer vision tasks. In this
paper, we firstly introduce DML into image co-segmentation. We propose a novel
Triplet loss for Image Segmentation, called IS-Triplet loss for short, and
combine it with traditional image segmentation loss. Different from the general
DML task which learns the metric between pictures, we treat each pixel as a
sample, and use their embedded features in high-dimensional space to form
triples, then we tend to force the distance between pixels of different
categories greater than of the same category by optimizing IS-Triplet loss so
that the pixels from different categories are easier to be distinguished in the
high-dimensional feature space. We further present an efficient triple sampling
strategy to make a feasible computation of IS-Triplet loss. Finally, the
IS-Triplet loss is combined with 3 traditional image segmentation losses to
perform image segmentation. We apply the proposed approach to image
co-segmentation and test it on the SBCoseg dataset and the Internet dataset.
The experimental result shows that our approach can effectively improve the
discrimination of pixels' categories in high-dimensional space and thus help
traditional loss achieve better performance of image segmentation with fewer
training epochs.
</dc:description>
 <dc:description>Comment: 11 pages, 5 figures</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10670</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10675</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Locating Faulty Methods with a Mixed RNN and Attention Model</dc:title>
 <dc:creator>Yang, Shouliang</dc:creator>
 <dc:creator>Cao, Junming</dc:creator>
 <dc:creator>Zeng, Hushuang</dc:creator>
 <dc:creator>Shen, Beijun</dc:creator>
 <dc:creator>Zhong, Hao</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  IR-based fault localization approaches achieves promising results when
locating faulty files by comparing a bug report with source code.
Unfortunately, they become less effective to locate faulty methods. We conduct
a preliminary study to explore its challenges, and identify three problems: the
semantic gap problem, the representation sparseness problem, and the single
revision problem. To tackle these problems, we propose MRAM, a mixed RNN and
attention model, which combines bug-fixing features and method structured
features to explore both implicit and explicit relevance between methods and
bug reports for method level fault localization task. The core ideas of our
model are: (1) constructing code revision graphs from code, commits and past
bug reports, which reveal the latent relations among methods to augment short
methods and as well provide all revisions of code and past fixes to train more
accurate models; (2) embedding three method structured features (token
sequences, API invocation sequences, and comments) jointly with RNN and soft
attention to represent source methods and obtain their implicit relevance with
bug reports; and (3) integrating multirevision bug-fixing features, which
provide the explicit relevance between bug reports and methods, to improve the
performance. We have implemented MRAM and conducted a controlled experiment on
five open-source projects. Comparing with stateof-the-art approaches, our MRAM
improves MRR values by 3.8- 5.1% (3.7-5.4%) when the dataset contains (does not
contain) localized bug reports. Our statistics test shows that our improvements
are significant
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10675</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10678</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>6-DOF Feature based LIDAR SLAM using ORB Features from Rasterized Images
  of 3D LIDAR Point Cloud</dc:title>
 <dc:creator>Ali, Waqas</dc:creator>
 <dc:creator>Liu, Peilin</dc:creator>
 <dc:creator>Ying, Rendong</dc:creator>
 <dc:creator>Gong, Zheng</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  An accurate and computationally efficient SLAM algorithm is vital for modern
autonomous vehicles. To make a lightweight the algorithm, most SLAM systems
rely on feature detection from images for vision SLAM or point cloud for
laser-based methods. Feature detection through a 3D point cloud becomes a
computationally challenging task. In this paper, we propose a feature detection
method by projecting a 3D point cloud to form an image and apply the
vision-based feature detection technique. The proposed method gives repeatable
and stable features in a variety of environments. Based on such features, we
build a 6-DOF SLAM system consisting of tracking, mapping, and loop closure
threads. For loop detection, we employ a 2-step approach i.e. nearest
key-frames detection and loop candidate verification by matching features
extracted from rasterized LIDAR images. Furthermore, we utilize a key-frame
structure to achieve a lightweight SLAM system. The proposed system is
evaluated with implementation on the KITTI dataset and the University of
Michigan Ford Campus dataset. Through experimental results, we show that the
algorithm presented in this paper can substantially reduce the computational
cost of feature detection from the point cloud and the whole SLAM system while
giving accurate results.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10682</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Masked Conditional Random Fields for Sequence Labeling</dc:title>
 <dc:creator>Wei, Tianwen</dc:creator>
 <dc:creator>Qi, Jianwei</dc:creator>
 <dc:creator>He, Shenghuan</dc:creator>
 <dc:creator>Sun, Songtao</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Conditional Random Field (CRF) based neural models are among the most
performant methods for solving sequence labeling problems. Despite its great
success, CRF has the shortcoming of occasionally generating illegal sequences
of tags, e.g. sequences containing an &quot;I-&quot; tag immediately after an &quot;O&quot; tag,
which is forbidden by the underlying BIO tagging scheme. In this work, we
propose Masked Conditional Random Field (MCRF), an easy to implement variant of
CRF that impose restrictions on candidate paths during both training and
decoding phases. We show that the proposed method thoroughly resolves this
issue and brings consistent improvement over existing CRF-based models with
near zero additional cost.
</dc:description>
 <dc:description>Comment: accepted by NAACL 2021</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10684</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On a recolouring version of Hadwiger's conjecture</dc:title>
 <dc:creator>Bonamy, Marthe</dc:creator>
 <dc:creator>Heinrich, Marc</dc:creator>
 <dc:creator>Legrand-Duchesne, Cl&#xe9;ment</dc:creator>
 <dc:creator>Narboni, Jonathan</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We prove that for any $\varepsilon&gt;0$, for any large enough $t$, there is a
graph $G$ that admits no $K_t$-minor but admits a
$(\frac32-\varepsilon)t$-colouring that is &quot;frozen&quot; with respect to Kempe
changes, i.e. any two colour classes induce a connected component. This
disproves three conjectures of Las Vergnas and Meyniel from 1981.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10684</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10687</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low differentially uniform permutations from Dobbertin APN function over
  $\mathbb{F}_{2^n}$</dc:title>
 <dc:creator>Wang, Yan-Ping</dc:creator>
 <dc:creator>Zhang, WeiGuo</dc:creator>
 <dc:creator>Zha, Zhengbang</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>12Y05, 11T99</dc:subject>
 <dc:description>  Block ciphers use S-boxes to create confusion in the cryptosystems. Such
S-boxes are functions over $\mathbb{F}_{2^{n}}$. These functions should have
low differential uniformity, high nonlinearity, and high algebraic degree in
order to resist differential attacks, linear attacks, and higher order
differential attacks, respectively. In this paper, we construct new classes of
differentially $4$ and $6$-uniform permutations by modifying the image of the
Dobbertin APN function $x^{d}$ with $d=2^{4k}+2^{3k}+2^{2k}+2^{k}-1$ over a
subfield of $\mathbb{F}_{2^{n}}$. Furthermore, the algebraic degree and the
lower bound of the nonlinearity of the constructed functions are given.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10687</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10692</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Selectively Delaying Instructions to Prevent Microarchitectural Replay
  Attacks</dc:title>
 <dc:creator>Sakalis, Christos</dc:creator>
 <dc:creator>Kaxiras, Stefanos</dc:creator>
 <dc:creator>Sj&#xe4;lander, Magnus</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  MicroScope, and microarchitectural replay attacks in general, take advantage
of the characteristics of speculative execution to trap the execution of the
victim application in an infinite loop, enabling the attacker to amplify a
side-channel attack by executing it indefinitely. Due to the nature of the
replay, it can be used to effectively attack security critical trusted
execution environments (secure enclaves), even under conditions where a
side-channel attack would not be possible. At the same time, unlike speculative
side-channel attacks, MicroScope can be used to amplify the correct path of
execution, rendering many existing speculative side-channel defences
ineffective.
  In this work, we generalize microarchitectural replay attacks beyond
MicroScope and present an efficient defence against them. We make the
observation that such attacks rely on repeated squashes of so-called &quot;replay
handles&quot; and that the instructions causing the side-channel must reside in the
same reorder buffer window as the handles. We propose Delay-on-Squash, a
technique for tracking squashed instructions and preventing them from being
replayed by speculative replay handles. Our evaluation shows that it is
possible to achieve full security against microarchitectural replay attacks
with very modest hardware requirements, while still maintaining 97% of the
insecure baseline performance.
</dc:description>
 <dc:description>Comment: 13 pages, 5 figures</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10692</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10693</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial and Contrastive Variational Autoencoder for Sequential
  Recommendation</dc:title>
 <dc:creator>Xie, Zhe</dc:creator>
 <dc:creator>Liu, Chengxuan</dc:creator>
 <dc:creator>Zhang, Yichi</dc:creator>
 <dc:creator>Lu, Hongtao</dc:creator>
 <dc:creator>Wang, Dong</dc:creator>
 <dc:creator>Ding, Yue</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Sequential recommendation as an emerging topic has attracted increasing
attention due to its important practical significance. Models based on deep
learning and attention mechanism have achieved good performance in sequential
recommendation. Recently, the generative models based on Variational
Autoencoder (VAE) have shown the unique advantage in collaborative filtering.
In particular, the sequential VAE model as a recurrent version of VAE can
effectively capture temporal dependencies among items in user sequence and
perform sequential recommendation. However, VAE-based models suffer from a
common limitation that the representational ability of the obtained approximate
posterior distribution is limited, resulting in lower quality of generated
samples. This is especially true for generating sequences. To solve the above
problem, in this work, we propose a novel method called Adversarial and
Contrastive Variational Autoencoder (ACVAE) for sequential recommendation.
Specifically, we first introduce the adversarial training for sequence
generation under the Adversarial Variational Bayes (AVB) framework, which
enables our model to generate high-quality latent variables. Then, we employ
the contrastive loss. The latent variables will be able to learn more
personalized and salient characteristics by minimizing the contrastive loss.
Besides, when encoding the sequence, we apply a recurrent and convolutional
structure to capture global and local relationships in the sequence. Finally,
we conduct extensive experiments on four real-world datasets. The experimental
results show that our proposed ACVAE model outperforms other state-of-the-art
methods.
</dc:description>
 <dc:description>Comment: 11 pages, WWW 2021</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10693</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10694</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Contextual Reasoning to Provide Human Behavior</dc:title>
 <dc:creator>Jain, Sarika</dc:creator>
 <dc:creator>Patel, Archana</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In recent years, the world has witnessed various primitives pertaining to the
complexity of human behavior. Identifying an event in the presence of
insufficient, incomplete, or tentative premises along with the constraints on
resources such as time, data and memory is a vital aspect of an intelligent
system. Data explosion presents one of the most challenging research issues for
intelligent systems; to optimally represent and store this heterogeneous and
voluminous data semantically to provide human behavior. There is a requirement
of intelligent but personalized human behavior subject to constraints on
resources and priority of the user. Knowledge, when represented in the form of
an ontology, procures an intelligent response to a query posed by users; but it
does not offer content in accordance with the user context. To this aim, we
propose a model to quantify the user context and provide semantic contextual
reasoning. A diagnostic belief algorithm (DBA) is also presented that
identifies a given event and also computes the confidence of the decision as a
function of available resources, premises, exceptions, and desired specificity.
We conduct an empirical study in the domain of day-to-day routine queries and
the experimental results show that the answer to queries and also its
confidence varies with user context.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10694</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10695</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>QROSS: QUBO Relaxation Parameter Optimisation via Learning Solver
  Surrogates</dc:title>
 <dc:creator>Huang, Tian</dc:creator>
 <dc:creator>Goh, Siong Thye</dc:creator>
 <dc:creator>Gopalakrishnan, Sabrish</dc:creator>
 <dc:creator>Luo, Tao</dc:creator>
 <dc:creator>Li, Qianxiao</dc:creator>
 <dc:creator>Lau, Hoong Chuin</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>90C27 (Primary) 81P68, 68T07 (Secondary)</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  An increasingly popular method for solving a constrained combinatorial
optimisation problem is to first convert it into a quadratic unconstrained
binary optimisation (QUBO) problem, and solve it using a standard QUBO solver.
However, this relaxation introduces hyper-parameters that balance the objective
and penalty terms for the constraints, and their chosen values significantly
impact performance. Hence, tuning these parameters is an important problem.
Existing generic hyper-parameter tuning methods require multiple expensive
calls to a QUBO solver, making them impractical for performance critical
applications when repeated solutions of similar combinatorial optimisation
problems are required. In this paper, we propose the QROSS method, in which we
build surrogate models of QUBO solvers via learning from solver data on a
collection of instances of a problem. In this way, we are able capture the
common structure of the instances and their interactions with the solver, and
produce good choices of penalty parameters with fewer number of calls to the
QUBO solver. We take the Traveling Salesman Problem (TSP) as a case study,
where we demonstrate that our method can find better solutions with fewer calls
to QUBO solver compared with conventional hyper-parameter tuning techniques.
Moreover, with simple adaptation methods, QROSS is shown to generalise well to
out-of-distribution datasets and different types of QUBO solvers.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10701</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weakly Complete Semantics Based on Undecidedness Blocking</dc:title>
 <dc:creator>Dondio, Pierpaolo</dc:creator>
 <dc:creator>Longo, Luca</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>68T27 (Primary) 68T30, 68T37 (Secondary)</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  In this paper we introduce a novel family of semantics called weakly complete
semantics. Differently from Dung's complete semantics, weakly complete
semantics employs a mechanism called undecidedness blocking by which the label
undecided of an attacking argument is not always propagated to an otherwise
accepted attacked argument. The new semantics are conflict-free, non-admissible
but employing a weaker notion of admissibility; they allow reinstatement and
they retain the majority of properties of complete semantics. We show how both
weakly complete and Dung's complete semantics can be generated by applying
different undecidedness blocking strategies, making undecidedness blocking a
unifying mechanism underlying argumentation semantics. The semantics are also
an example of ambiguity blocking Dunganian semantics and the first semantics to
tackle the problem of self-defeating attacking arguments. In the last part of
the paper we compare weakly complete semantics with the recent work of Baumann
et al. on weakly admissible semantics. Since the two families of semantics do
not coincide, a principle-based analysis of the two approaches is provided. The
analysis shows how our semantics satisfy a number of principles satisfied by
Dung's complete semantics but not by Baumann et al. semantics, including
directionality, abstention, SCC-decomposability and cardinality of extensions,
making them a more faithful non-admissible version of Dung' semantics.
</dc:description>
 <dc:description>Comment: 48 pages, 9 figures. Preprint</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10701</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10703</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lessons Learned from Educating AI Engineers</dc:title>
 <dc:creator>Heck, Petra</dc:creator>
 <dc:creator>Schouten, Gerard</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Over the past three years we have built a practice-oriented, bachelor level,
educational programme for software engineers to specialize as AI engineers. The
experience with this programme and the practical assignments our students
execute in industry has given us valuable insights on the profession of AI
engineer. In this paper we discuss our programme and the lessons learned for
industry and research.
</dc:description>
 <dc:description>Comment: Acccepted for the 1st International Workshop on AI Engineering
  (WAIN21)</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10705</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuous iterative algorithms for anti-Cheeger cut</dc:title>
 <dc:creator>Shao, Sihong</dc:creator>
 <dc:creator>Yang, Chuan</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>90C27, 05C85, 65K10, 90C26, 90C32</dc:subject>
 <dc:description>  As a judicious correspondence to the classical maxcut, the anti-Cheeger cut
has more balanced structure, but few numerical results on it have been reported
so far. In this paper, we propose a continuous iterative algorithm for the
anti-Cheeger cut problem through fully using an equivalent continuous
formulation. It does not need rounding at all and has advantages that all
subproblems have explicit analytic solutions, the objection function values are
monotonically updated and the iteration points converge to a local optima in
finite steps via an appropriate subgradient selection. It can also be easily
combined with the maxcut iterations for breaking out of local optima and
improving the solution quality thanks to the similarity between the
anti-Cheeger cut problem and the maxcut problem. Numerical experiments on G-set
demonstrate the performance.
</dc:description>
 <dc:description>Comment: 18 pages, 3 figures</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10705</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10725</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Social Are Social Media The Dark Patterns In Facebook's Interface</dc:title>
 <dc:creator>Mildner, Thomas</dc:creator>
 <dc:creator>Savino, Gian-Luca</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Many researchers have been concerned with social media and possible negative
impacts on the well-being of their audience. With the popularity of social
networking sites (SNS) steadily increasing, psychological and social sciences
have shown great interest in their effects and consequences on humans.
Unfortunately, it appears to be difficult to find correlations between SNS and
the results of their works. We, therefore, investigate Facebook using the tools
of HCI to find connections between interface features and the concerns raised
by these domains. With a nod towards Dark Patterns, we use an empirical design
analysis to identify interface interferences that impact users' online privacy.
We further discuss how HCI can help to work towards more ethical user
interfaces in the future.
</dc:description>
 <dc:description>Comment: Position Paper at the Workshop &quot;What Can CHI Do About Dark Patterns?&quot;</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10729</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Connecting Images through Time and Sources: Introducing Low-data,
  Heterogeneous Instance Retrieval</dc:title>
 <dc:creator>Gominski, Dimitri</dc:creator>
 <dc:creator>Gouet-Brunet, Val&#xe9;rie</dc:creator>
 <dc:creator>Chen, Liming</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  With impressive results in applications relying on feature learning, deep
learning has also blurred the line between algorithm and data. Pick a training
dataset, pick a backbone network for feature extraction, and voil\`a ; this
usually works for a variety of use cases. But the underlying hypothesis that
there exists a training dataset matching the use case is not always met.
Moreover, the demand for interconnections regardless of the variations of the
content calls for increasing generalization and robustness in features.
  An interesting application characterized by these problematics is the
connection of historical and cultural databases of images. Through the
seemingly simple task of instance retrieval, we propose to show that it is not
trivial to pick features responding well to a panel of variations and semantic
content. Introducing a new enhanced version of the Alegoria benchmark, we
compare descriptors using the detailed annotations. We further give insights
about the core problems in instance retrieval, testing four state-of-the-art
additional techniques to increase performance.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10729</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10731</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Acoustic word embeddings for zero-resource languages using
  self-supervised contrastive learning and multilingual adaptation</dc:title>
 <dc:creator>Jacobs, Christiaan</dc:creator>
 <dc:creator>Matusevych, Yevgen</dc:creator>
 <dc:creator>Kamper, Herman</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Acoustic word embeddings (AWEs) are fixed-dimensional representations of
variable-length speech segments. For zero-resource languages where labelled
data is not available, one AWE approach is to use unsupervised
autoencoder-based recurrent models. Another recent approach is to use
multilingual transfer: a supervised AWE model is trained on several
well-resourced languages and then applied to an unseen zero-resource language.
We consider how a recent contrastive learning loss can be used in both the
purely unsupervised and multilingual transfer settings. Firstly, we show that
terms from an unsupervised term discovery system can be used for contrastive
self-supervision, resulting in improvements over previous unsupervised
monolingual AWE models. Secondly, we consider how multilingual AWE models can
be adapted to a specific zero-resource language using discovered terms. We find
that self-supervised contrastive adaptation outperforms adapted multilingual
correspondence autoencoder and Siamese AWE models, giving the best overall
results in a word discrimination task on six zero-resource languages.
</dc:description>
 <dc:description>Comment: Accepted to SLT 2021</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10731</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10734</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Congolese Swahili Machine Translation for Humanitarian Response</dc:title>
 <dc:creator>&#xd6;ktem, Alp</dc:creator>
 <dc:creator>DeLuca, Eric</dc:creator>
 <dc:creator>Bashizi, Rodrigue</dc:creator>
 <dc:creator>Paquin, Eric</dc:creator>
 <dc:creator>Tang, Grace</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper we describe our efforts to make a bidirectional Congolese
Swahili (SWC) to French (FRA) neural machine translation system with the
motivation of improving humanitarian translation workflows. For training, we
created a 25,302-sentence general domain parallel corpus and combined it with
publicly available data. Experimenting with low-resource methodologies like
cross-dialect transfer and semi-supervised learning, we recorded improvements
of up to 2.4 and 3.5 BLEU points in the SWC-FRA and FRA-SWC directions,
respectively. We performed human evaluations to assess the usability of our
models in a COVID-domain chatbot that operates in the Democratic Republic of
Congo (DRC). Direct assessment in the SWC-FRA direction demonstrated an average
quality ranking of 6.3 out of 10 with 75% of the target strings conveying the
main message of the source text. For the FRA-SWC direction, our preliminary
tests on post-editing assessment showed its potential usefulness for
machine-assisted translation. We make our models, datasets containing up to 1
million sentences, our development pipeline, and a translator web-app available
for public use.
</dc:description>
 <dc:description>Comment: Accepted to Africa NLP workshop organized within the 16th Conference
  of the European Chapter of the Association for Computational Linguistics
  (EACL2021)</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10734</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10746</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topic Allocation Method on Edge Servers for Latency-sensitive
  Notification Service</dc:title>
 <dc:creator>Tanaka, Tomoya</dc:creator>
 <dc:creator>Kamada, Tomio</dc:creator>
 <dc:creator>Ohta, Chikara</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The importance of real-time notification has been growing for social services
and Intelligent Transporting System (ITS). As an advanced version of Pub/Sub
systems, publish-process-subscribe systems, where published messages are
spooled and processed on edge servers, have been proposed to achieve
data-driven intelligent notifications. In this paper, we present a system that
allows a topic to be managed on multiple edge servers so that messages are
processed near the publishers, even when publishers are spread over a wide
area. Duplicating messages on geographically distributed servers could enable
immediate notification to neighboring subscribers. However, the duplicated
message spool may cause exhaustion of resources. We prepare a formal model of
our publish-process-subscribe system and formulate the topic allocation as an
optimization problem under the resource constraints of edge servers. As the
optimization problem is NP-hard, we propose heuristics leveraging the locality
and the pub/sub relationships observed between clients to use the edge server
resources efficiently. Our performance evaluation shows that our method reduces
the delay to deliver notifications and the effectiveness of the strategy
exploiting the relationships between clients.
</dc:description>
 <dc:description>Comment: 18 pages, 16 figures, 2 tables</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10746</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10750</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Singularly perturbed reaction-diffusion problems as first order systems</dc:title>
 <dc:creator>Franz, Sebastian</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65N12, 65N15, 65N30</dc:subject>
 <dc:description>  We consider a singularly perturbed reaction diffusion problem as a first
order two-by-two system. Using piecewise discontinuous polynomials for the
first component and $H_{div}$-conforming elements for the second component we
provide a convergence analysis on layer adapted meshes and an optimal
convergence order in a balanced norm that is comparable with a balanced
$H^2$-norm for the second order formulation.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10750</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10756</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On-Chain IoT Data Modification in Blockchains</dc:title>
 <dc:creator>Niya, Sina Rafati</dc:creator>
 <dc:creator>Willems, Julius</dc:creator>
 <dc:creator>Stiller, Burkhard</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In recent years, the interest growth in the Blockchains (BC) and
Internet-of-Things (IoT) integration -- termed as BIoT -- for more trust via
decentralization has led to great potentials in various use cases such as
health care, supply chain tracking, and smart cities. A key element of BIoT
ecosystems is the data transactions (TX) that include the data collected by IoT
devices. BIoT applications face many challenges to comply with the European
General Data Protection Regulation (GDPR) i.e., enabling users to hold on to
their rights for deleting or modifying their data stored on publicly accessible
and immutable BCs. In this regard, this paper identifies the requirements of
BCs for being GDPR compliant in BIoT use cases. Accordingly, an on-chain
solution is proposed that allows fine-grained modification (update and erasure)
operations on TXs' data fields within a BC. The proposed solution is based on a
cryptographic primitive called Chameleon Hashing. The novelty of this approach
is manifold. BC users have the authority to update their data, which are
addressed at the TX level with no side-effects on the block or chain. By
performing and storing the data updates, all on-chain, traceability and
verifiability of the BC are preserved. Moreover, the compatibility with TX
aggregation mechanisms that allow the compression of the BC size is maintained.
</dc:description>
 <dc:description>Comment: 10 pages, 3 figures</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10756</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10760</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph Attention Recurrent Neural Networks for Correlated Time Series
  Forecasting -- Full version</dc:title>
 <dc:creator>Cirstea, Razvan-Gabriel</dc:creator>
 <dc:creator>Guo, Chenjuan</dc:creator>
 <dc:creator>Yang, Bin</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We consider a setting where multiple entities inter-act with each other over
time and the time-varying statuses of the entities are represented as multiple
correlated time series. For example, speed sensors are deployed in different
locations in a road network, where the speed of a specific location across time
is captured by the corresponding sensor as a time series, resulting in multiple
speed time series from different locations, which are often correlated. To
enable accurate forecasting on correlated time series, we proposes graph
attention recurrent neural networks.First, we build a graph among different
entities by taking into account spatial proximity and employ a multi-head
attention mechanism to derive adaptive weight matrices for the graph to capture
the correlations among vertices (e.g., speeds at different locations) at
different timestamps. Second, we employ recurrent neural networks to take into
account temporal dependency while taking into account the adaptive weight
matrices learned from the first step to consider the correlations among time
series.Experiments on a large real-world speed time series data set suggest
that the proposed method is effective and outperforms the state-of-the-art in
most settings. This manuscript provides a full version of a workshop paper [1].
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10760</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10764</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DFS: A Diverse Feature Synthesis Model for Generalized Zero-Shot
  Learning</dc:title>
 <dc:creator>Li, Bonan</dc:creator>
 <dc:creator>Nie, Xuecheng</dc:creator>
 <dc:creator>Han, Congying</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Generative based strategy has shown great potential in the Generalized
Zero-Shot Learning task. However, it suffers severe generalization problem due
to lacking of feature diversity for unseen classes to train a good classifier.
In this paper, we propose to enhance the generalizability of GZSL models via
improving feature diversity of unseen classes. For this purpose, we present a
novel Diverse Feature Synthesis (DFS) model. Different from prior works that
solely utilize semantic knowledge in the generation process, DFS leverages
visual knowledge with semantic one in a unified way, thus deriving
class-specific diverse feature samples and leading to robust classifier for
recognizing both seen and unseen classes in the testing phase. To simplify the
learning, DFS represents visual and semantic knowledge in the aligned space,
making it able to produce good feature samples with a low-complexity
implementation. Accordingly, DFS is composed of two consecutive generators: an
aligned feature generator, transferring semantic and visual representations
into aligned features; a synthesized feature generator, producing diverse
feature samples of unseen classes in the aligned space. We conduct
comprehensive experiments to verify the efficacy of DFS. Results demonstrate
its effectiveness to generate diverse features for unseen classes, leading to
superior performance on multiple benchmarks. Code will be released upon
acceptance.
</dc:description>
 <dc:description>Comment: 11 pages,5 figures,conference</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10764</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10773</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>UniMoCo: Unsupervised, Semi-Supervised and Full-Supervised Visual
  Representation Learning</dc:title>
 <dc:creator>Dai, Zhigang</dc:creator>
 <dc:creator>Cai, Bolun</dc:creator>
 <dc:creator>Lin, Yugeng</dc:creator>
 <dc:creator>Chen, Junying</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Momentum Contrast (MoCo) achieves great success for unsupervised visual
representation. However, there are a lot of supervised and semi-supervised
datasets, which are already labeled. To fully utilize the label annotations, we
propose Unified Momentum Contrast (UniMoCo), which extends MoCo to support
arbitrary ratios of labeled data and unlabeled data training. Compared with
MoCo, UniMoCo has two modifications as follows: (1) Different from a single
positive pair in MoCo, we maintain multiple positive pairs on-the-fly by
comparing the query label to a label queue. (2) We propose a Unified
Contrastive(UniCon) loss to support an arbitrary number of positives and
negatives in a unified pair-wise optimization perspective. Our UniCon is more
reasonable and powerful than the supervised contrastive loss in theory and
practice. In our experiments, we pre-train multiple UniMoCo models with
different ratios of ImageNet labels and evaluate the performance on various
downstream tasks. Experiment results show that UniMoCo generalizes well for
unsupervised, semi-supervised and supervised visual representation learning.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10773</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10779</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Page Table Management for Heterogeneous Memory Systems</dc:title>
 <dc:creator>Kumar, Sandeep</dc:creator>
 <dc:creator>Prasad, Aravinda</dc:creator>
 <dc:creator>Sarangi, Smruti R.</dc:creator>
 <dc:creator>Subramoney, Sreenivas</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Modern enterprise servers are increasingly embracing tiered memory systems
with a combination of low latency DRAMs and large capacity but high latency
non-volatile main memories (NVMMs) such as Intel's Optane DC PMM. Prior works
have focused on efficient placement and migration of data on a tiered memory
system, but have not studied the optimal placement of page tables.
  Explicit and efficient placement of page tables is crucial for large memory
footprint applications with high TLB miss rates because they incur dramatically
higher page walk latency when page table pages are placed in NVMM. We show that
(i) page table pages can end up on NVMM even when enough DRAM memory is
available and (ii) page table pages that spill over to NVMM due to DRAM memory
pressure are not migrated back later when memory is available in DRAM.
  We study the performance impact of page table placement in a tiered memory
system and propose an efficient and transparent page table management technique
that (i) applies different placement policies for data and page table pages,
(ii) introduces a differentiating policy for page table pages by placing a
small but critical part of the page table in DRAM, and (iii) dynamically and
judiciously manages the rest of the page table by transparently migrating the
page table pages between DRAM and NVMM. Our implementation on a real system
equipped with Intel's Optane NVMM running Linux reduces the page table walk
cycles by 12% and total cycles by 20% on an average. This improves the runtime
by 20% on an average for a set of synthetic and real-world large memory
footprint applications when compared with various default Linux kernel
techniques.
</dc:description>
 <dc:date>2021-03-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10779</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10787</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LSDAT: Low-Rank and Sparse Decomposition for Decision-based Adversarial
  Attack</dc:title>
 <dc:creator>Esmaeili, Ashkan</dc:creator>
 <dc:creator>Edraki, Marzieh</dc:creator>
 <dc:creator>Rahnavard, Nazanin</dc:creator>
 <dc:creator>Shah, Mubarak</dc:creator>
 <dc:creator>Mian, Ajmal</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose LSDAT, an image-agnostic decision-based black-box attack that
exploits low-rank and sparse decomposition (LSD) to dramatically reduce the
number of queries and achieve superior fooling rates compared to the
state-of-the-art decision-based methods under given imperceptibility
constraints. LSDAT crafts perturbations in the low-dimensional subspace formed
by the sparse component of the input sample and that of an adversarial sample
to obtain query-efficiency. The specific perturbation of interest is obtained
by traversing the path between the input and adversarial sparse components. It
is set forth that the proposed sparse perturbation is the most aligned sparse
perturbation with the shortest path from the input sample to the decision
boundary for some initial adversarial sample (the best sparse approximation of
shortest path, likely to fool the model). Theoretical analyses are provided to
justify the functionality of LSDAT. Unlike other dimensionality reduction based
techniques aimed at improving query efficiency (e.g, ones based on FFT), LSD
works directly in the image pixel domain to guarantee that non-$\ell_2$
constraints, such as sparsity, are satisfied. LSD offers better control over
the number of queries and provides computational efficiency as it performs
sparse decomposition of the input and adversarial images only once to generate
all queries. We demonstrate $\ell_0$, $\ell_2$ and $\ell_\infty$ bounded
attacks with LSDAT to evince its efficiency compared to baseline decision-based
attacks in diverse low-query budget scenarios as outlined in the experiments.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10792</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulation Platform for Autonomous Aerial Manipulation in Dynamic
  Environments</dc:title>
 <dc:creator>Quan, Fengyu</dc:creator>
 <dc:creator>Huang, Huisheng</dc:creator>
 <dc:creator>Zeng, Hongjie</dc:creator>
 <dc:creator>Chen, Haoyao</dc:creator>
 <dc:creator>Liu, Yunhui</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The aerial manipulator (AM) is a systematic operational robotic platform in
high standard on algorithm robustness. Directly deploying the algorithms to the
practical system will take numerous trial and error costs and even cause
destructive results. In this paper, a new modular simulation platform is
designed to evaluate aerial manipulation related algorithms before deploying.
In addition, to realize a fully autonomous aerial grasping, a series of
algorithm modules consisting a complete workflow are designed and integrated in
the simulation platform, including perception, planning and control modules.
This framework empowers the AM to autonomously grasp remote targets without
colliding with surrounding obstacles relying only on on-board sensors.
Benefiting from its modular design, this software architecture can be easily
extended with additional algorithms. Finally, several simulations are performed
to verify the effectiveness of the proposed system.
</dc:description>
 <dc:description>Comment: 7 pages, 9 figures, submitted to IROS 2021</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10798</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Emotion Analysis From Images: Recent Advances and Future
  Directions</dc:title>
 <dc:creator>Zhao, Sicheng</dc:creator>
 <dc:creator>Huang, Quanwei</dc:creator>
 <dc:creator>Tang, Youbao</dc:creator>
 <dc:creator>Yao, Xingxu</dc:creator>
 <dc:creator>Yang, Jufeng</dc:creator>
 <dc:creator>Ding, Guiguang</dc:creator>
 <dc:creator>Schuller, Bj&#xf6;rn W.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Emotions are usually evoked in humans by images. Recently, extensive research
efforts have been dedicated to understanding the emotions of images. In this
chapter, we aim to introduce image emotion analysis (IEA) from a computational
perspective with the focus on summarizing recent advances and suggesting future
directions. We begin with commonly used emotion representation models from
psychology. We then define the key computational problems that the researchers
have been trying to solve and provide supervised frameworks that are generally
used for different IEA tasks. After the introduction of major challenges in
IEA, we present some representative methods on emotion feature extraction,
supervised classifier learning, and domain adaptation. Furthermore, we
introduce available datasets for evaluation and summarize some main results.
Finally, we discuss some open questions and future directions that researchers
can pursue.
</dc:description>
 <dc:description>Comment: Accepted chapter in the book &quot;Human Perception of Visual Information
  Psychological and Computational Perspective&quot;</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10804</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancing Human-in-the-Loop Adaptive Systems through Digital Twins and
  VR Interfaces</dc:title>
 <dc:creator>Yigitbas, Enes</dc:creator>
 <dc:creator>Karakaya, Kadiray</dc:creator>
 <dc:creator>Jovanovikj, Ivan</dc:creator>
 <dc:creator>Engels, Gregor</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Self-adaptation approaches usually rely on closed-loop controllers that avoid
human intervention from adaptation. While such fully automated approaches have
proven successful in many application domains, there are situations where human
involvement in the adaptation process is beneficial or even necessary. For such
&quot;human-in-the-loop&quot; adaptive systems, two major challenges, namely transparency
and controllability, have to be addressed to include the human in the
self-adaptation loop. Transparency means that relevant context information
about the adaptive systems and its context is represented based on a digital
twin enabling the human an immersive and realistic view. Concerning
controllability, the decision-making and adaptation operations should be
managed in a natural and interactive way. As existing human-in-the-loop
adaptation approaches do not fully cover these aspects, we investigate
alternative human-in-the-loop strategies by using a combination of digital
twins and virtual reality (VR) interfaces. Based on the concept of the digital
twin, we represent a self-adaptive system and its respective context in a
virtual environment. With the help of a VR interface, we support an immersive
and realistic human involvement in the self-adaptation loop by mirroring the
physical entities of the real world to the VR interface. For integrating the
human in the decision-making and adaptation process, we have implemented and
analyzed two different human-in-the-loop strategies in VR: a procedural control
where the human can control the decision making-process and adaptations through
VR interactions (human-controlled) and a declarative control where the human
specifies the goal state and the configuration is delegated to an AI planner
(mixed-initiative). We illustrate and evaluate our approach based on an
autonomic robot system that is accessible and controlled through a VR
interface.
</dc:description>
 <dc:description>Comment: Submitted to SEAMS 2021</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10804</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10805</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transferable Model for Shape Optimization subject to Physical
  Constraints</dc:title>
 <dc:creator>Harsch, Lukas</dc:creator>
 <dc:creator>Burgbacher, Johannes</dc:creator>
 <dc:creator>Riedelbauch, Stefan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:description>  The interaction of neural networks with physical equations offers a wide
range of applications. We provide a method which enables a neural network to
transform objects subject to given physical constraints. Therefore an U-Net
architecture is used to learn the underlying physical behaviour of fluid flows.
The network is used to infer the solution of flow simulations, which will be
shown for a wide range of generic channel flow simulations. Physical meaningful
quantities can be computed on the obtained solution, e.g. the total pressure
difference or the forces on the objects. A Spatial Transformer Network with
thin-plate-splines is used for the interaction between the physical constraints
and the geometric representation of the objects. Thus, a transformation from an
initial to a target geometry is performed such that the object is fulfilling
the given constraints. This method is fully differentiable i.e., gradient
informations can be used for the transformation. This can be seen as an inverse
design process. The advantage of this method over many other proposed methods
is, that the physical constraints are based on the inferred flow field
solution. Thus, we have a transferable model which can be applied to varying
problem setups and is not limited to a given set of geometry parameters or
physical quantities.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10805</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10811</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Web API Usage Logging</dc:title>
 <dc:creator>Ko&#xe7;i, Rediana</dc:creator>
 <dc:creator>Franch, Xavier</dc:creator>
 <dc:creator>Jovanovic, Petar</dc:creator>
 <dc:creator>Abell&#xf3;, Alberto</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  A Web API (WAPI) is a type of API whose interaction with its consumers is
done through the Internet. While being accessed through the Internet can be
challenging, mostly when WAPIs evolve, it gives providers the possibility to
monitor their usage, and understand and analyze consumers' behavior. Currently,
WAPI usage is mostly logged for traffic monitoring and troubleshooting. Even
though they contain invaluable information regarding consumers' behavior} they
are not sufficiently used by providers. In this paper, we first consider two
phases of the application development lifecycle, and based on them we
distinguish two different types of usage logs, namely development logs and
production logs. For each of them we show the potential analyses (e.g., WAPI
usability evaluation, consumers' needs identification) that can be performed,
as well as the main impediments, that may be caused by the unsuitable log
format. We then conduct a case study using logs of the same WAPI from different
deployments and different formats, to demonstrate the occurrence of these
impediments and at the same time the importance of a proper log format. Next,
based on the case study results, we present the main quality issues of WAPI log
data and explain their impact on data analyses. For each of them, we give some
practical suggestions on how to deal with them, as well as mitigating their
root cause.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10814</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Skeleton Merger: an Unsupervised Aligned Keypoint Detector</dc:title>
 <dc:creator>Shi, Ruoxi</dc:creator>
 <dc:creator>Xue, Zhengrong</dc:creator>
 <dc:creator>You, Yang</dc:creator>
 <dc:creator>Lu, Cewu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Detecting aligned 3D keypoints is essential under many scenarios such as
object tracking, shape retrieval and robotics. However, it is generally hard to
prepare a high-quality dataset for all types of objects due to the ambiguity of
keypoint itself. Meanwhile, current unsupervised detectors are unable to
generate aligned keypoints with good coverage. In this paper, we propose an
unsupervised aligned keypoint detector, Skeleton Merger, which utilizes
skeletons to reconstruct objects. It is based on an Autoencoder architecture.
The encoder proposes keypoints and predicts activation strengths of edges
between keypoints. The decoder performs uniform sampling on the skeleton and
refines it into small point clouds with pointwise offsets. Then the activation
strengths are applied and the sub-clouds are merged. Composite Chamfer Distance
(CCD) is proposed as a distance between the input point cloud and the
reconstruction composed of sub-clouds masked by activation strengths. We
demonstrate that Skeleton Merger is capable of detecting semantically-rich
salient keypoints with good alignment, and shows comparable performance to
supervised methods on the KeypointNet dataset. It is also shown that the
detector is robust to noise and subsampling. Our code is available at
https://github.com/eliphatfs/SkeletonMerger.
</dc:description>
 <dc:description>Comment: CVPR 2021</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10814</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10820</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-causal regularized least-squares for continuous-time system
  identification with band-limited input excitations</dc:title>
 <dc:creator>Gonz&#xe1;lez, Rodrigo A.</dc:creator>
 <dc:creator>Rojas, Cristian R.</dc:creator>
 <dc:creator>Hjalmarsson, H&#xe5;kan</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  In continuous-time system identification, the intersample behavior of the
input signal is known to play a crucial role in the performance of estimation
methods. One common input behavior assumption is that the spectrum of the input
is band-limited. The sinc interpolation property of these input signals yields
equivalent discrete-time representations that are non-causal. This observation,
often overlooked in the literature, is exploited in this work to study
non-parametric frequency response estimators of linear continuous-time systems.
We study the properties of non-causal least-square estimators for
continuous-time system identification, and propose a kernel-based non-causal
regularized least-squares approach for estimating the band-limited equivalent
impulse response. The proposed methods are tested via extensive numerical
simulations.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10820</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10824</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancing Robustness of On-line Learning Models on Highly Noisy Data</dc:title>
 <dc:creator>Zhao, Zilong</dc:creator>
 <dc:creator>Birke, Robert</dc:creator>
 <dc:creator>Han, Rui</dc:creator>
 <dc:creator>Robu, Bogdan</dc:creator>
 <dc:creator>Bouchenak, Sara</dc:creator>
 <dc:creator>Mokhtar, Sonia Ben</dc:creator>
 <dc:creator>Chen, Lydia Y.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Classification algorithms have been widely adopted to detect anomalies for
various systems, e.g., IoT, cloud and face recognition, under the common
assumption that the data source is clean, i.e., features and labels are
correctly set. However, data collected from the wild can be unreliable due to
careless annotations or malicious data transformation for incorrect anomaly
detection. In this paper, we extend a two-layer on-line data selection
framework: Robust Anomaly Detector (RAD) with a newly designed ensemble
prediction where both layers contribute to the final anomaly detection
decision. To adapt to the on-line nature of anomaly detection, we consider
additional features of conflicting opinions of classifiers, repetitive
cleaning, and oracle knowledge. We on-line learn from incoming data streams and
continuously cleanse the data, so as to adapt to the increasing learning
capacity from the larger accumulated data set. Moreover, we explore the concept
of oracle learning that provides additional information of true labels for
difficult data points. We specifically focus on three use cases, (i) detecting
10 classes of IoT attacks, (ii) predicting 4 classes of task failures of big
data jobs, and (iii) recognising 100 celebrities faces. Our evaluation results
show that RAD can robustly improve the accuracy of anomaly detection, to reach
up to 98.95% for IoT device attacks (i.e., +7%), up to 85.03% for cloud task
failures (i.e., +14%) under 40% label noise, and for its extension, it can
reach up to 77.51% for face recognition (i.e., +39%) under 30% label noise. The
proposed RAD and its extensions are general and can be applied to different
anomaly detection algorithms.
</dc:description>
 <dc:description>Comment: Published in IEEE Transactions on Dependable and Secure Computing.
  arXiv admin note: substantial text overlap with arXiv:1911.04383</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10824</dc:identifier>
 <dc:identifier>doi:10.1109/TDSC.2021.3063947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10825</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational Knowledge Distillation for Disease Classification in Chest
  X-Rays</dc:title>
 <dc:creator>van Sonsbeek, Tom</dc:creator>
 <dc:creator>Zhen, Xiantong</dc:creator>
 <dc:creator>Worring, Marcel</dc:creator>
 <dc:creator>Shao, Ling</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Disease classification relying solely on imaging data attracts great interest
in medical image analysis. Current models could be further improved, however,
by also employing Electronic Health Records (EHRs), which contain rich
information on patients and findings from clinicians. It is challenging to
incorporate this information into disease classification due to the high
reliance on clinician input in EHRs, limiting the possibility for automated
diagnosis. In this paper, we propose \textit{variational knowledge
distillation} (VKD), which is a new probabilistic inference framework for
disease classification based on X-rays that leverages knowledge from EHRs.
Specifically, we introduce a conditional latent variable model, where we infer
the latent representation of the X-ray image with the variational posterior
conditioning on the associated EHR text. By doing so, the model acquires the
ability to extract the visual features relevant to the disease during learning
and can therefore perform more accurate classification for unseen patients at
inference based solely on their X-ray scans. We demonstrate the effectiveness
of our method on three public benchmark datasets with paired X-ray images and
EHRs. The results show that the proposed variational knowledge distillation can
consistently improve the performance of medical image classification and
significantly surpasses current methods.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10825</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10830</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tri-Partitions and Bases of an Ordered Complex</dc:title>
 <dc:creator>Edelsbrunner, Herbert</dc:creator>
 <dc:creator>&#xd6;lsb&#xf6;ck, Katharina</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Generalizing the decomposition of a connected planar graph into a tree and a
dual tree, we prove a combinatorial analog of the classic Helmholz-Hodge
decomposition of a smooth vector field. Specifically, we show that for every
polyhedral complex, $K$, and every dimension, $p$, there is a partition of the
set of $p$-cells into a maximal $p$-tree, a maximal $p$-cotree, and a
collection of $p$-cells whose cardinality is the $p$-th Betti number of $K$.
Given an ordering of the $p$-cells, this tri-partition is unique, and it can be
computed by a matrix reduction algorithm that also constructs canonical bases
of cycle and boundary groups.
</dc:description>
 <dc:description>Comment: 15 pages, 3 figures</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10830</dc:identifier>
 <dc:identifier>Discrete and Computational Geometry (DCG) 64 (2020), 759-775</dc:identifier>
 <dc:identifier>doi:10.1007/s00454-020-00188-x</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10836</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GNNerator: A Hardware/Software Framework for Accelerating Graph Neural
  Networks</dc:title>
 <dc:creator>Stevens, Jacob R.</dc:creator>
 <dc:creator>Das, Dipankar</dc:creator>
 <dc:creator>Avancha, Sasikanth</dc:creator>
 <dc:creator>Kaul, Bharat</dc:creator>
 <dc:creator>Raghunathan, Anand</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Graph Neural Networks (GNNs) use a fully-connected layer to extract features
from the nodes of a graph and aggregate these features using message passing
between nodes, combining two distinct computational patterns: dense, regular
computations and sparse, irregular computations.
  To address this challenge, we propose GNNerator, an accelerator with
heterogeneous compute engines optimized for these two patterns.
  Further, GNNerator implements feature-blocking, a novel GNN dataflow that
beneficially trades off irregular memory accesses during aggregation for
regular memory accesses during feature extraction. We show GNNerator achieves
speedups of 5.7-37x over an NVIDIA RTX 2080-Ti, and 2.3x-3.8x over HyGCN, a
state-of-the-art GNN accelerator.
</dc:description>
 <dc:description>Comment: To appear in Proceedings of the 58th Design Automation Conference
  (DAC '21)</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10836</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10838</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A systematic association of subgraph counts over a network</dc:title>
 <dc:creator>Floros, Dimitris</dc:creator>
 <dc:creator>Pitsianis, Nikos</dc:creator>
 <dc:creator>Sun, Xiaobai</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We associate all small subgraph counting problems with a systematic graph
encoding/representation system which makes a coherent use of graphlet
structures. The system can serve as a unified foundation for studying and
connecting many important graph problems in theory and practice. We describe
topological relations among graphlets (graph elements) in rigorous mathematics
language and from the perspective of graph encoding. We uncover, characterize
and utilize algebraic and numerical relations in graphlet counts/frequencies.
We present a novel algorithm for efficiently counting small subgraphs as a
practical product of our theoretical findings.
</dc:description>
 <dc:description>Comment: 25 pages, 8 figures, 2 tables</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10838</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10842</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prediction of progressive lens performance from neural network
  simulations</dc:title>
 <dc:creator>Leube, Alexander</dc:creator>
 <dc:creator>Lang, Lukas</dc:creator>
 <dc:creator>Kelch, Gerhard</dc:creator>
 <dc:creator>Wahl, Siegfried</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Purpose: The purpose of this study is to present a framework to predict
visual acuity (VA) based on a convolutional neural network (CNN) and to further
to compare PAL designs.
  Method: A simple two hidden layer CNN was trained to classify the gap
orientations of Landolt Cs by combining the feature extraction abilities of a
CNN with psychophysical staircase methods. The simulation was validated
regarding its predictability of clinical VA from induced spherical defocus
(between +/-1.5 D, step size: 0.5 D) from 39 subjectively measured eyes.
Afterwards, a simulation for a presbyopic eye corrected by either a generic
hard or a soft PAL design (addition power: 2.5 D) was performed including lower
and higher order aberrations.
  Result: The validation revealed consistent offset of +0.20 logMAR +/-0.035
logMAR from simulated VA. Bland-Altman analysis from offset-corrected results
showed limits of agreement (+/-1.96 SD) of -0.08 logMAR and +0.07 logMAR, which
is comparable to clinical repeatability of VA assessment. The application of
the simulation for PALs confirmed a bigger far zone for generic hard design but
did not reveal zone width differences for the intermediate or near zone.
Furthermore, a horizontal area of better VA at the mid of the PAL was found,
which confirms the importance for realistic performance simulations using
object-based aberration and physiological performance measures as VA.
  Conclusion: The proposed holistic simulation tool was shown to act as an
accurate model for subjective visual performance. Further, the simulations
application for PALs indicated its potential as an effective method to compare
visual performance of different optical designs. Moreover, the simulation
provides the basis to incorporate neural aspects of visual perception and thus
simulate the VA including neural processing in future.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10844</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From driving automation systems to autonomous vehicles: clarifying the
  terminology</dc:title>
 <dc:creator>Llorca, David Fern&#xe1;ndez</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The terminological landscape is rather cluttered when referring to autonomous
driving or vehicles. A plethora of terms are used interchangeably, leading to
misuse and confusion. With its technological, social and legal progress, it is
increasingly imperative to establish a clear terminology that allows each
concept to be placed in its corresponding place.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10844</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10847</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Better Adaptive Systems by Combining MAPE, Control Theory, and
  Machine Learning</dc:title>
 <dc:creator>Weyns, Danny</dc:creator>
 <dc:creator>Schmerl, Bradley</dc:creator>
 <dc:creator>Kishida, Masako</dc:creator>
 <dc:creator>Leva, Alberto</dc:creator>
 <dc:creator>Litoiu, Marin</dc:creator>
 <dc:creator>Ozay, Necmiye</dc:creator>
 <dc:creator>Paterson, Colin</dc:creator>
 <dc:creator>Tei, Kenji</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Two established approaches to engineer adaptive systems are
architecture-based adaptation that uses a Monitor-Analysis-Planning-Executing
(MAPE) loop that reasons over architectural models (aka Knowledge) to make
adaptation decisions, and control-based adaptation that relies on principles of
control theory (CT) to realize adaptation. Recently, we also observe a rapidly
growing interest in applying machine learning (ML) to support different
adaptation mechanisms. While MAPE and CT have particular characteristics and
strengths to be applied independently, in this paper, we are concerned with the
question of how these approaches are related with one another and whether
combining them and supporting them with ML can produce better adaptive systems.
We motivate the combined use of different adaptation approaches using a
scenario of a cloud-based enterprise system and illustrate the analysis when
combining the different approaches. To conclude, we offer a set of open
questions for further research in this interesting area.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10847</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10851</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>&quot;Do You Know You Are Tracked by Photos That You Didn't Take&quot;:
  Location-Aware Multi-Party Image Privacy Protection</dc:title>
 <dc:creator>Morris, Joshua</dc:creator>
 <dc:creator>Newman, Sara</dc:creator>
 <dc:creator>Palaniappan, Kannappan</dc:creator>
 <dc:creator>Fan, Jianping</dc:creator>
 <dc:creator>Lin, Dan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Most existing image privacy protection works focus mainly on the privacy of
photo owners and their friends, but lack the consideration of other people who
are in the background of the photos and the related location privacy issues. In
fact, when a person is in the background of someone else's photos, he/she may
be unintentionally exposed to the public when the photo owner shares the photo
online. Not only a single visited place could be exposed, attackers may also be
able to piece together a person's travel route from images. In this paper, we
propose a novel image privacy protection system, called LAMP, which aims to
light up the location awareness for people during online image sharing. The
LAMP system is based on a newly designed location-aware multi-party image
access control model. The LAMP system will automatically detect the user's
occurrences on photos regardless the user is the photo owner or not. Once a
user is identified and the location of the photo is deemed sensitive according
to the user's privacy policy, the LAMP system will intelligently replace the
user's face. A prototype of the system was implemented and evaluated to
demonstrate its applicability in the real world.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10851</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10860</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Universal Trading for Order Execution with Oracle Policy Distillation</dc:title>
 <dc:creator>Fang, Yuchen</dc:creator>
 <dc:creator>Ren, Kan</dc:creator>
 <dc:creator>Liu, Weiqing</dc:creator>
 <dc:creator>Zhou, Dong</dc:creator>
 <dc:creator>Zhang, Weinan</dc:creator>
 <dc:creator>Bian, Jiang</dc:creator>
 <dc:creator>Yu, Yong</dc:creator>
 <dc:creator>Liu, Tie-Yan</dc:creator>
 <dc:subject>Quantitative Finance - Trading and Market Microstructure</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  As a fundamental problem in algorithmic trading, order execution aims at
fulfilling a specific trading order, either liquidation or acquirement, for a
given instrument. Towards effective execution strategy, recent years have
witnessed the shift from the analytical view with model-based market
assumptions to model-free perspective, i.e., reinforcement learning, due to its
nature of sequential decision optimization. However, the noisy and yet
imperfect market information that can be leveraged by the policy has made it
quite challenging to build up sample efficient reinforcement learning methods
to achieve effective order execution. In this paper, we propose a novel
universal trading policy optimization framework to bridge the gap between the
noisy yet imperfect market states and the optimal action sequences for order
execution. Particularly, this framework leverages a policy distillation method
that can better guide the learning of the common policy towards practically
optimal execution by an oracle teacher with perfect information to approximate
the optimal trading strategy. The extensive experiments have shown significant
improvements of our method over various strong baselines, with reasonable
trading actions.
</dc:description>
 <dc:description>Comment: Accepted in AAAI 2021, the code and the supplementary materials are
  in https://seqml.github.io/opd/</dc:description>
 <dc:date>2021-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10868</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GLOWin: A Flow-based Invertible Generative Framework for Learning
  Disentangled Feature Representations in Medical Images</dc:title>
 <dc:creator>Sankar, Aadhithya</dc:creator>
 <dc:creator>Keicher, Matthias</dc:creator>
 <dc:creator>Eisawy, Rami</dc:creator>
 <dc:creator>Parida, Abhijeet</dc:creator>
 <dc:creator>Pfister, Franz</dc:creator>
 <dc:creator>Kim, Seong Tae</dc:creator>
 <dc:creator>Navab, Nassir</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Disentangled representations can be useful in many downstream tasks, help to
make deep learning models more interpretable, and allow for control over
features of synthetically generated images that can be useful in training other
models that require a large number of labelled or unlabelled data. Recently,
flow-based generative models have been proposed to generate realistic images by
directly modeling the data distribution with invertible functions. In this
work, we propose a new flow-based generative model framework, named GLOWin,
that is end-to-end invertible and able to learn disentangled representations.
Feature disentanglement is achieved by factorizing the latent space into
components such that each component learns the representation for one
generative factor. Comprehensive experiments have been conducted to evaluate
the proposed method on a public brain tumor MR dataset. Quantitative and
qualitative results suggest that the proposed method is effective in
disentangling the features from complex medical images.
</dc:description>
 <dc:description>Comment: 12 pages, 7 figures</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10868</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10873</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fully Onboard AI-powered Human-Drone Pose Estimation on Ultra-low Power
  Autonomous Flying Nano-UAVs</dc:title>
 <dc:creator>Palossi, Daniele</dc:creator>
 <dc:creator>Zimmerman, Nicky</dc:creator>
 <dc:creator>Burrello, Alessio</dc:creator>
 <dc:creator>Conti, Francesco</dc:creator>
 <dc:creator>M&#xfc;ller, Hanna</dc:creator>
 <dc:creator>Gambardella, Luca Maria</dc:creator>
 <dc:creator>Benini, Luca</dc:creator>
 <dc:creator>Giusti, Alessandro</dc:creator>
 <dc:creator>Guzzi, J&#xe9;r&#xf4;me</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Artificial intelligence-powered pocket-sized air robots have the potential to
revolutionize the Internet-of-Things ecosystem, acting as autonomous,
unobtrusive, and ubiquitous smart sensors. With a few cm$^{2}$ form-factor,
nano-sized unmanned aerial vehicles (UAVs) are the natural befit for indoor
human-drone interaction missions, as the pose estimation task we address in
this work. However, this scenario is challenged by the nano-UAVs' limited
payload and computational power that severely relegates the onboard brain to
the sub-100 mW microcontroller unit-class. Our work stands at the intersection
of the novel parallel ultra-low-power (PULP) architectural paradigm and our
general development methodology for deep neural network (DNN) visual pipelines,
i.e., covering from perception to control. Addressing the DNN model design,
from training and dataset augmentation to 8-bit quantization and deployment, we
demonstrate how a PULP-based processor, aboard a nano-UAV, is sufficient for
the real-time execution (up to 135 frame/s) of our novel DNN, called
PULP-Frontnet. We showcase how, scaling our model's memory and computational
requirement, we can significantly improve the onboard inference (top energy
efficiency of 0.43 mJ/frame) with no compromise in the quality-of-result vs. a
resource-unconstrained baseline (i.e., full-precision DNN). Field experiments
demonstrate a closed-loop top-notch autonomous navigation capability, with a
heavily resource-constrained 27-gram Crazyflie 2.1 nano-quadrotor. Compared
against the control performance achieved using an ideal sensing setup, onboard
relative pose inference yields excellent drone behavior in terms of median
absolute errors, such as positional (onboard: 41 cm, ideal: 26 cm) and angular
(onboard: 3.7$^{\circ}$, ideal: 4.1$^{\circ}$).
</dc:description>
 <dc:description>Comment: 15 pages, 15 figures, 4 tables. This work has been submitted to the
  IEEE for possible publication. Copyright may be transferred without notice,
  after which this version may no longer be accessible</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10873</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10874</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A new method for constructing linear codes with small hulls</dc:title>
 <dc:creator>Qian, Liqin</dc:creator>
 <dc:creator>Cao, Xiwang</dc:creator>
 <dc:creator>Lu, Wei</dc:creator>
 <dc:creator>Sole, Patrick</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The hull of a linear code over finite fields is the intersection of the code
and its dual, which was introduced by Assmus and Key. In this paper, we develop
a method to construct linear codes with trivial hull ( LCD codes) and
one-dimensional hull by employing the positive characteristic analogues of
Gauss sums. These codes are quasi-abelian, and sometimes doubly circulant. Some
sufficient conditions for a linear code to be an LCD code (resp. a linear code
with one-dimensional hull) are presented. It is worth mentioning that we
present a lower bound on the minimum distances of the constructed linear codes.
As an application, using these conditions, we obtain some optimal or almost
optimal LCD codes (resp. linear codes with one-dimensional hull) with respect
to the online Database of Grassl.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10874</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10877</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Supervisory Control of Multi-Agent Discrete-Event Systems with Partial
  Observation</dc:title>
 <dc:creator>Liu, Yingying</dc:creator>
 <dc:creator>Komenda, Jan</dc:creator>
 <dc:creator>Li, Zhiwu</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  In this paper we investigate multi-agent discrete-event systems with partial
observation. The agents can be divided into several groups in each of which the
agents have similar (isomorphic) state transition structures, and thus can be
relabeled into the same template. Based on the template a scalable supervisor
whose state size and computational cost are independent of the number of agents
is designed for the case of partial observation. The scalable supervisor under
partial observation does not need to be recomputed regardless of how many
agents are added to or removed from the system. We generalize our earlier
results to partial observation by proposing sufficient conditions for safety
and maximal permissiveness of the scalable least restrictive supervisor on the
template level. An example is provided to illustrate the proposed scalable
supervisory synthesis.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10877</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10891</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerating SLIDE Deep Learning on Modern CPUs: Vectorization,
  Quantizations, Memory Optimizations, and More</dc:title>
 <dc:creator>Daghaghi, Shabnam</dc:creator>
 <dc:creator>Meisburger, Nicholas</dc:creator>
 <dc:creator>Zhao, Mengnan</dc:creator>
 <dc:creator>Wu, Yong</dc:creator>
 <dc:creator>Gobriel, Sameh</dc:creator>
 <dc:creator>Tai, Charlie</dc:creator>
 <dc:creator>Shrivastava, Anshumali</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Deep learning implementations on CPUs (Central Processing Units) are gaining
more traction. Enhanced AI capabilities on commodity x86 architectures are
commercially appealing due to the reuse of existing hardware and virtualization
ease. A notable work in this direction is the SLIDE system. SLIDE is a C++
implementation of a sparse hash table based back-propagation, which was shown
to be significantly faster than GPUs in training hundreds of million parameter
neural models. In this paper, we argue that SLIDE's current implementation is
sub-optimal and does not exploit several opportunities available in modern
CPUs. In particular, we show how SLIDE's computations allow for a unique
possibility of vectorization via AVX (Advanced Vector Extensions)-512.
Furthermore, we highlight opportunities for different kinds of memory
optimization and quantizations. Combining all of them, we obtain up to 7x
speedup in the computations on the same hardware. Our experiments are focused
on large (hundreds of millions of parameters) recommendation and NLP models.
Our work highlights several novel perspectives and opportunities for
implementing randomized algorithms for deep learning on modern CPUs. We provide
the code and benchmark scripts at https://github.com/RUSH-LAB/SLIDE
</dc:description>
 <dc:date>2021-03-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10891</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10892</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Label Fusion: A 3D End-to-End Hybrid Multi-Atlas Segmentation and
  Deep Learning Pipeline</dc:title>
 <dc:creator>Xie, Long</dc:creator>
 <dc:creator>Wisse, Laura E. M.</dc:creator>
 <dc:creator>Wang, Jiancong</dc:creator>
 <dc:creator>Ravikumar, Sadhana</dc:creator>
 <dc:creator>Glenn, Trevor</dc:creator>
 <dc:creator>Luther, Anica</dc:creator>
 <dc:creator>Lim, Sydney</dc:creator>
 <dc:creator>Wolk, David A.</dc:creator>
 <dc:creator>Yushkevich, Paul A.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Deep learning (DL) is the state-of-the-art methodology in various medical
image segmentation tasks. However, it requires relatively large amounts of
manually labeled training data, which may be infeasible to generate in some
applications. In addition, DL methods have relatively poor generalizability to
out-of-sample data. Multi-atlas segmentation (MAS), on the other hand, has
promising performance using limited amounts of training data and good
generalizability. A hybrid method that integrates the high accuracy of DL and
good generalizability of MAS is highly desired and could play an important role
in segmentation problems where manually labeled data is hard to generate. Most
of the prior work focuses on improving single components of MAS using DL rather
than directly optimizing the final segmentation accuracy via an end-to-end
pipeline. Only one study explored this idea in binary segmentation of 2D
images, but it remains unknown whether it generalizes well to multi-class 3D
segmentation problems. In this study, we propose a 3D end-to-end hybrid
pipeline, named deep label fusion (DLF), that takes advantage of the strengths
of MAS and DL. Experimental results demonstrate that DLF yields significant
improvements over conventional label fusion methods and U-Net, a direct DL
approach, in the context of segmenting medial temporal lobe subregions using 3T
T1-weighted and T2-weighted MRI. Further, when applied to an unseen similar
dataset acquired in 7T, DLF maintains its superior performance, which
demonstrates its good generalizability.
</dc:description>
 <dc:description>Comment: 12 pages paper accepted by the international conference of
  Information Processing in Medical Imaging (IPMI) 2021</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10892</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10893</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An operadic approach to substitution in Lie-Butcher series</dc:title>
 <dc:creator>Rahm, Ludwig</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Rings and Algebras</dc:subject>
 <dc:description>  The paper follows an operadic approach to provide a bialgebraic description
of substitution for Lie-Butcher series. We first show how the well-known
bialgebraic description for substitution in Butcher's $B$-series can be
obtained from the pre-Lie operad. We then apply the same construction to the
post-Lie operad to arrive at a bialgebra $\mathcal{Q}$. By considering a module
over the post-Lie operad, we get a cointeraction between $\mathcal{Q}$ and the
Hopf algebra $\mathcal{H}_N$ that describes composition for Lie-Butcher series.
We use this coaction to describe substitution for Lie-Butcher series.
</dc:description>
 <dc:description>Comment: 24 pages</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10893</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10895</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sewer-ML: A Multi-Label Sewer Defect Classification Dataset and
  Benchmark</dc:title>
 <dc:creator>Haurum, Joakim Bruslund</dc:creator>
 <dc:creator>Moeslund, Thomas B.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Perhaps surprisingly sewerage infrastructure is one of the most costly
infrastructures in modern society. Sewer pipes are manually inspected to
determine whether the pipes are defective. However, this process is limited by
the number of qualified inspectors and the time it takes to inspect a pipe.
Automatization of this process is therefore of high interest. So far, the
success of computer vision approaches for sewer defect classification has been
limited when compared to the success in other fields mainly due to the lack of
public datasets. To this end, in this work we present a large novel and
publicly available multi-label classification dataset for image-based sewer
defect classification called Sewer-ML.
  The Sewer-ML dataset consists of 1.3 million images annotated by professional
sewer inspectors from three different utility companies across nine years.
Together with the dataset, we also present a benchmark algorithm and a novel
metric for assessing performance. The benchmark algorithm is a result of
evaluating 12 state-of-the-art algorithms, six from the sewer defect
classification domain and six from the multi-label classification domain, and
combining the best performing algorithms. The novel metric is a
class-importance weighted F2 score, $\text{F}2_{\text{CIW}}$, reflecting the
economic impact of each class, used together with the normal pipe F1 score,
$\text{F}1_{\text{Normal}}$. The benchmark algorithm achieves an
$\text{F}2_{\text{CIW}}$ score of 55.11% and $\text{F}1_{\text{Normal}}$ score
of 90.94%, leaving ample room for improvement on the Sewer-ML dataset. The
code, models, and dataset are available at the project page
https://vap.aau.dk/sewer-ml/
</dc:description>
 <dc:description>Comment: CVPR 2021. Project webpage: https://vap.aau.dk/sewer-ml/</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10895</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10904</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Frobenius Numbers and Automatic Sequences</dc:title>
 <dc:creator>Shallit, Jeffrey</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Primary 11D07, Secondary 11B85, 11B83</dc:subject>
 <dc:description>  The Frobenius number $g(S)$ of a set $S$ of non-negative integers with $\gcd
1$ is the largest integer not expressible as a linear combination of elements
of $S$. Given a sequence ${\bf s} = (s_i)_{i \geq 0}$, we can define the
associated sequence $G_{\bf s} (i) = g(\{ s_i,s_{i+1},\ldots \})$. In this
paper we compute $G_{\bf s} (i)$ for some classical automatic sequences: the
evil numbers, the odious numbers, and the lower and upper Wythoff sequences. In
contrast with the usual methods, our proofs are based largely on automata
theory and logic.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10904</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10905</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Parameter Discovery and Generative Modeling of Dynamic Systems</dc:title>
 <dc:creator>Barber, Gregory</dc:creator>
 <dc:creator>Haile, Mulugeta A.</dc:creator>
 <dc:creator>Chen, Tzikang</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  Given an unknown dynamic system such as a coupled harmonic oscillator with
$n$ springs and point masses. We are often interested in gaining insights into
its physical parameters, i.e. stiffnesses and masses, by observing trajectories
of motion. How do we achieve this from video frames or time-series data and
without the knowledge of the dynamics model? We present a neural framework for
estimating physical parameters in a manner consistent with the underlying
physics. The neural framework uses a deep latent variable model to disentangle
the system physical parameters from canonical coordinate observations. It then
returns a Hamiltonian parameterization that generalizes well with respect to
the discovered physical parameters. We tested our framework with simple
harmonic oscillators, $n=1$, and noisy observations and show that it discovers
the underlying system parameters and generalizes well with respect to these
discovered parameters. Our model also extrapolates the dynamics of the system
beyond the training interval and outperforms a non-physically constrained
baseline model. Our source code and datasets can be found at this URL:
https://github.com/gbarber94/ConSciNet.
</dc:description>
 <dc:description>Comment: 11 pages, 7 figures</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10905</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10909</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IA Planner: Motion Planning Using Instantaneous Analysis for Autonomous
  Vehicle in the Dense Dynamic Scenarios on Highways</dc:title>
 <dc:creator>Yang, Xiaoyu</dc:creator>
 <dc:creator>Li, Huiyun</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  In dense and dynamic scenarios, planning a safe and comfortable trajectory is
full of challenges when traffic participants are driving at high speed. The
classic graph search and sampling methods first perform path planning and then
configure the corresponding speed, which lacks a strategy to deal with the
high-speed obstacles. Decoupling optimization methods perform motion planning
in the S-L and S-T domains respectively. These methods require a large free
configuration space to plan the lane change trajectory. In dense dynamic
scenes, it is easy to cause the failure of trajectory planning and be cut in by
others, causing slow driving speed and bring safety hazards. We analyze the
collision relationship in the spatio-temporal domain, and propose an
instantaneous analysis model which only analyzes the collision relationship at
the same time. In the model, the collision-free constraints in 3D
spatio-temporal domain is projected to the 2D space domain to remove redundant
constraints and reduce computational complexity. Experimental results show that
our method can plan a safe and comfortable lane-changing trajectory in dense
dynamic scenarios. At the same time, it improves traffic efficiency and
increases ride comfort.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10909</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10911</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis of Deep Learning Workloads on a Composable System</dc:title>
 <dc:creator>Maghraoui, Kauotar El</dc:creator>
 <dc:creator>Herger, Lorraine M.</dc:creator>
 <dc:creator>Choudary, Chekuri</dc:creator>
 <dc:creator>Tran, Kim</dc:creator>
 <dc:creator>Deshane, Todd</dc:creator>
 <dc:creator>Hanson, David</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  A composable infrastructure is defined as resources, such as compute,
storage, accelerators and networking, that are shared in a pool and that can be
grouped in various configurations to meet application requirements. This
freedom to 'mix and match' resources dynamically allows for experimentation
early in the design cycle, prior to the final architectural design or hardware
implementation of a system. This design provides flexibility to serve a variety
of workloads and provides a dynamic co-design platform that allows experiments
and measurements in a controlled manner. For instance, key performance
bottlenecks can be revealed early on in the experimentation phase thus avoiding
costly and time consuming mistakes. Additionally, various system-level
topologies can be evaluated when experimenting with new System on Chip (SoCs)
and new accelerator types. This paper details the design of an enterprise
composable infrastructure that we have implemented and made available to our
partners in the IBM Research AI Hardware Center (AIHC). Our experimental
evaluations on the composable system give insights into how the system works
and evaluates the impact of various resource aggregations and reconfigurations
on representative deep learning benchmarks.
</dc:description>
 <dc:description>Comment: Submitted to IPDPS ScaDL 2021</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10911</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10916</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Drug-Drug Interactions from Heterogeneous Data: An Embedding
  Approach</dc:title>
 <dc:creator>Dhami, Devendra Singh</dc:creator>
 <dc:creator>Yan, Siwen</dc:creator>
 <dc:creator>Kunapuli, Gautam</dc:creator>
 <dc:creator>Page, David</dc:creator>
 <dc:creator>Natarajan, Sriraam</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Predicting and discovering drug-drug interactions (DDIs) using machine
learning has been studied extensively. However, most of the approaches have
focused on text data or textual representation of the drug structures. We
present the first work that uses multiple data sources such as drug structure
images, drug structure string representation and relational representation of
drug relationships as the input. To this effect, we exploit the recent advances
in deep networks to integrate these varied sources of inputs in predicting
DDIs. Our empirical evaluation against several state-of-the-art methods using
standalone different data types for drugs clearly demonstrate the efficacy of
combining heterogeneous data in predicting DDIs.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures, Accepted as a short paper to 'Artificial
  Intelligence in Medicine 2021'</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10916</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10928</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BERTSurv: BERT-Based Survival Models for Predicting Outcomes of Trauma
  Patients</dc:title>
 <dc:creator>Zhao, Yun</dc:creator>
 <dc:creator>Hong, Qinghang</dc:creator>
 <dc:creator>Zhang, Xinlu</dc:creator>
 <dc:creator>Deng, Yu</dc:creator>
 <dc:creator>Wang, Yuqing</dc:creator>
 <dc:creator>Petzold, Linda</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Survival analysis is a technique to predict the times of specific outcomes,
and is widely used in predicting the outcomes for intensive care unit (ICU)
trauma patients. Recently, deep learning models have drawn increasing attention
in healthcare. However, there is a lack of deep learning methods that can model
the relationship between measurements, clinical notes and mortality outcomes.
In this paper we introduce BERTSurv, a deep learning survival framework which
applies Bidirectional Encoder Representations from Transformers (BERT) as a
language representation model on unstructured clinical notes, for mortality
prediction and survival analysis. We also incorporate clinical measurements in
BERTSurv. With binary cross-entropy (BCE) loss, BERTSurv can predict mortality
as a binary outcome (mortality prediction). With partial log-likelihood (PLL)
loss, BERTSurv predicts the probability of mortality as a time-to-event outcome
(survival analysis). We apply BERTSurv on Medical Information Mart for
Intensive Care III (MIMIC III) trauma patient data. For mortality prediction,
BERTSurv obtained an area under the curve of receiver operating characteristic
curve (AUC-ROC) of 0.86, which is an improvement of 3.6% over baseline of
multilayer perceptron (MLP) without notes. For survival analysis, BERTSurv
achieved a concordance index (C-index) of 0.7. In addition, visualizations of
BERT's attention heads help to extract patterns in clinical notes and improve
model interpretability by showing how the model assigns weights to different
inputs.
</dc:description>
 <dc:description>Comment: ICDM 2021</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10930</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prediction of Hydraulic Blockage at Cross Drainage Structures using
  Regression Analysis</dc:title>
 <dc:creator>Iqbal, Umair</dc:creator>
 <dc:creator>Barthelemy, Johan</dc:creator>
 <dc:creator>Perez, Pascal</dc:creator>
 <dc:creator>Li, Wanqing</dc:creator>
 <dc:subject>Physics - Geophysics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Hydraulic blockage of cross-drainage structures such as culverts is
considered one of main contributor in triggering urban flash floods. However,
due to lack of during floods data and highly non-linear nature of debris
interaction, conventional modelling for hydraulic blockage is not possible.
This paper proposes to use machine learning regression analysis for the
prediction of hydraulic blockage. Relevant data has been collected by
performing a scaled in-lab study and replicating different blockage scenarios.
From the regression analysis, Artificial Neural Network (ANN) was reported best
in hydraulic blockage prediction with $R^2$ of 0.89. With deployment of
hydraulic sensors in smart cities, and availability of Big Data, regression
analysis may prove helpful in addressing the blockage detection problem which
is difficult to counter using conventional experimental and hydrological
approaches.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures</dc:description>
 <dc:date>2021-03-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10930</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10942</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of Stability Results for Redundancy Systems</dc:title>
 <dc:creator>Anton, Elene</dc:creator>
 <dc:creator>Ayesta, Urtzi</dc:creator>
 <dc:creator>Jonckheere, Matthieu</dc:creator>
 <dc:creator>Verloop, Ina Maria</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Redundancy mechanisms consist in sending several copies of a same job to a
subset of servers. It constitutes one of the most promising ways to exploit
diversity in multiservers applications. However, its pros and cons are still
not sufficiently understood in the context of realistic models with generic
statistical properties of service-times distributions and correlation
structures of copies. We aim at giving a survey of recent results concerning
the stability-arguably the first benchmark of performance-of systems with
cancel-oncompletion redundancy. We also point out open questions and
conjectures.
</dc:description>
 <dc:date>2021-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10942</dc:identifier>
 <dc:identifier>A.B. Piunovskiy and Y. Zhang (eds.), Modern Trends in Controlled
  Stochastic Processes : Theory and Applications, Volume III, Springer, 2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10952</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymmetry underlies stability in power grids</dc:title>
 <dc:creator>Molnar, Ferenc</dc:creator>
 <dc:creator>Nishikawa, Takashi</dc:creator>
 <dc:creator>Motter, Adilson E.</dc:creator>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Behavioral homogeneity is often critical for the functioning of network
systems of interacting entities. In power grids, whose stable operation
requires generator frequencies to be synchronized--and thus homogeneous--across
the network, previous work suggests that the stability of synchronous states
can be improved by making the generators homogeneous. Here, we show that a
substantial additional improvement is possible by instead making the generators
suitably heterogeneous. We develop a general method for attributing this
counterintuitive effect to converse symmetry breaking, a recently established
phenomenon in which the system must be asymmetric to maintain a stable
symmetric state. These findings constitute the first demonstration of converse
symmetry breaking in real-world systems, and our method promises to enable
identification of this phenomenon in other networks whose functions rely on
behavioral homogeneity.
</dc:description>
 <dc:description>Comment: Includes Supplementary Information</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10952</dc:identifier>
 <dc:identifier>Nature Communications 12, 1457 (2021)</dc:identifier>
 <dc:identifier>doi:10.1038/s41467-021-21290-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10958</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multicriteria asset allocation in practice</dc:title>
 <dc:creator>D&#xe4;chert, Kerstin</dc:creator>
 <dc:creator>Grindel, Ria</dc:creator>
 <dc:creator>Leoff, Elisabeth</dc:creator>
 <dc:creator>Mahnkopp, Jonas</dc:creator>
 <dc:creator>Schirra, Florian</dc:creator>
 <dc:creator>Wenzel, J&#xf6;rg</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Quantitative Finance - Portfolio Management</dc:subject>
 <dc:description>  In this paper we consider the strategic asset allocation of an insurance
company. This task can be seen as a special case of portfolio optimization. In
the 1950s, Markowitz proposed to formulate portfolio optimization as a
bicriteria optimization problem considering risk and return as objectives.
However, recent developments in the field of insurance require four and more
objectives to be considered, among them the so-called solvency ratio that stems
from the Solvency II directive of the European Union issued in 2009. Moreover,
the distance to the current portfolio plays an important role. While literature
on portfolio optimization with three objectives is already scarce, applications
with four and more objectives have not yet been solved so far by
multi-objective approaches based on scalarizations. However, recent algorithmic
improvements in the field of exact multi-objective methods allow the
incorporation of many objectives and the generation of well-spread
representations within few iterations. We describe the implementation of such
an algorithm for a strategic asset allocation with four objective functions and
demonstrate its usefulness for the practitioner. Our approach is in operative
use in a German insurance company. Our partners report a significant
improvement in their decision making process since, due to the proper
integration of the new objectives, the software proposes portfolios of much
better quality than before within short running time.
</dc:description>
 <dc:description>Comment: 24 pages, 4 figures, 5 tables</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10958</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10968</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Multi-View Fusion of Active Stereo Depth Maps for Robotic
  Bin-Picking</dc:title>
 <dc:creator>Yang, Jun</dc:creator>
 <dc:creator>Li, Dong</dc:creator>
 <dc:creator>Waslander, Steven L.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The reliable fusion of depth maps from multiple viewpoints has become an
important problem in many 3D reconstruction pipelines. In this work, we
investigate its impact on robotic bin-picking tasks such as 6D object pose
estimation. The performance of object pose estimation relies heavily on the
quality of depth data. However, due to the prevalence of shiny surfaces and
cluttered scenes, industrial grade depth cameras often fail to sense depth or
generate unreliable measurements from a single viewpoint. To this end, we
propose a novel probabilistic framework for scene reconstruction in robotic
bin-picking. Based on active stereo camera data, we first explicitly estimate
the uncertainty of depth measurements for mitigating the adverse effects of
both noise and outliers. The uncertainty estimates are then incorporated into a
probabilistic model for incrementally updating the scene. To extensively
evaluate the traditional fusion approach alongside our own approach, we will
release a novel representative dataset with multiple views for each bin and
curated parts. Over the entire dataset, we demonstrate that our framework
outperforms a traditional fusion approach by a 12.8% reduction in
reconstruction error, and 6.1% improvement in detection rate. The dataset will
be available at https://www.trailab.utias.utoronto.ca/robi.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10968</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10972</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Task Decomposition with Ordered Memory Policy Network</dc:title>
 <dc:creator>Lu, Yuchen</dc:creator>
 <dc:creator>Shen, Yikang</dc:creator>
 <dc:creator>Zhou, Siyuan</dc:creator>
 <dc:creator>Courville, Aaron</dc:creator>
 <dc:creator>Tenenbaum, Joshua B.</dc:creator>
 <dc:creator>Gan, Chuang</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Many complex real-world tasks are composed of several levels of sub-tasks.
Humans leverage these hierarchical structures to accelerate the learning
process and achieve better generalization. In this work, we study the inductive
bias and propose Ordered Memory Policy Network (OMPN) to discover subtask
hierarchy by learning from demonstration. The discovered subtask hierarchy
could be used to perform task decomposition, recovering the subtask boundaries
in an unstruc-tured demonstration. Experiments on Craft and Dial demonstrate
that our modelcan achieve higher task decomposition performance under both
unsupervised and weakly supervised settings, comparing with strong baselines.
OMPN can also bedirectly applied to partially observable environments and still
achieve higher task decomposition performance. Our visualization further
confirms that the subtask hierarchy can emerge in our model.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10974</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning the solution operator of parametric partial differential
  equations with physics-informed DeepOnets</dc:title>
 <dc:creator>Wang, Sifan</dc:creator>
 <dc:creator>Wang, Hanwen</dc:creator>
 <dc:creator>Perdikaris, Paris</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep operator networks (DeepONets) are receiving increased attention thanks
to their demonstrated capability to approximate nonlinear operators between
infinite-dimensional Banach spaces. However, despite their remarkable early
promise, they typically require large training data-sets consisting of paired
input-output observations which may be expensive to obtain, while their
predictions may not be consistent with the underlying physical principles that
generated the observed data. In this work, we propose a novel model class
coined as physics-informed DeepONets, which introduces an effective
regularization mechanism for biasing the outputs of DeepOnet models towards
ensuring physical consistency. This is accomplished by leveraging automatic
differentiation to impose the underlying physical laws via soft penalty
constraints during model training. We demonstrate that this simple, yet
remarkably effective extension can not only yield a significant improvement in
the predictive accuracy of DeepOnets, but also greatly reduce the need for
large training data-sets. To this end, a remarkable observation is that
physics-informed DeepONets are capable of solving parametric partial
differential equations (PDEs) without any paired input-output observations,
except for a set of given initial or boundary conditions. We illustrate the
effectiveness of the proposed framework through a series of comprehensive
numerical studies across various types of PDEs. Strikingly, a trained physics
informed DeepOnet model can predict the solution of $\mathcal{O}(10^3)$
time-dependent PDEs in a fraction of a second -- up to three orders of
magnitude faster compared a conventional PDE solver. The data and code
accompanying this manuscript are publicly available at
\url{https://github.com/PredictiveIntelligenceLab/Physics-informed-DeepONets}.
</dc:description>
 <dc:description>Comment: 33 pages, 28 figures, 8 tables</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10974</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10975</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerating GMRES with Deep Learning in Real-Time</dc:title>
 <dc:creator>Luna, Kevin</dc:creator>
 <dc:creator>Klymko, Katherine</dc:creator>
 <dc:creator>Blaschke, Johannes P.</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  GMRES is a powerful numerical solver used to find solutions to extremely
large systems of linear equations. These systems of equations appear in many
applications in science and engineering. Here we demonstrate a real-time
machine learning algorithm that can be used to accelerate the time-to-solution
for GMRES. Our framework is novel in that is integrates the deep learning
algorithm in an in situ fashion: the AI-accelerator gradually learns how to
optimizes the time to solution without requiring user input (such as a
pre-trained data set). We describe how our algorithm collects data and
optimizes GMRES. We demonstrate our algorithm by implementing an accelerated
(MLGMRES) solver in Python. We then use MLGMRES to accelerate a solver for the
Poisson equation -- a class of linear problems that appears in may
applications.
  Informed by the properties of formal solutions to the Poisson equation, we
test the performance of different neural networks. Our key takeaway is that
networks which are capable of learning non-local relationships perform well,
without needing to be scaled with the input problem size, making them good
candidates for the extremely large problems encountered in high-performance
computing. For the inputs studied, our method provides a roughly 2$\times$
acceleration.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10975</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10977</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classification of Motor Imagery EEG Signals by Using a Divergence Based
  Convolutional Neural Network</dc:title>
 <dc:creator>Dokur, Zumray</dc:creator>
 <dc:creator>Olmez, Tamer</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Deep neural networks (DNNs) are observed to be successful in pattern
classification. However, high classification performances of DNNs are related
to their large training sets. Unfortunately, in the literature, the datasets
used to classify motor imagery (MI) electroencephalogram (EEG) signals contain
a small number of samples. To achieve high performances with small-sized
datasets, most of the studies have employed a transformation such as common
spatial patterns (CSP) before the classification process. However, CSP is
dependent on subjects and introduces computational load in real-time
applications. It is observed in the literature that the augmentation process is
not applied for increasing the classification performance of EEG signals. In
this study, we have investigated the effect of the augmentation process on the
classification performance of MI EEG signals instead of using a preceding
transformation such as the CSP, and we have demonstrated that by resulting in
high success rates for the classification of MI EEGs, the augmentation process
is able to compete with the CSP. In addition to the augmentation process, we
modified the DNN structure to increase the classification performance, to
decrease the number of nodes in the structure, and to be used with less number
of hyper parameters. A minimum distance network (MDN) following the last layer
of the convolutional neural network (CNN) was used as the classifier instead of
a fully connected neural network (FCNN). By augmenting the EEG dataset and
focusing solely on CNN's training, the training algorithm of the proposed
structure is strengthened without applying any transformation. We tested these
improvements on brain-computer interface (BCI) competitions 2005 and 2008
databases with two and four classes, and the high impact of the augmentation on
the average performances are demonstrated.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10977</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10988</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model-free LQR based PID controller for trajectory tracking of 2-DoF
  helicopter: comparison and experimental results</dc:title>
 <dc:creator>Rouis, Nouha</dc:creator>
 <dc:creator>N'Doye, Ibrahima</dc:creator>
 <dc:creator>Laleg-Kirati, Taous-Meriem</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper studies the performance of a model-free LQR based PID (i-LQR-PID)
controller designed for tracking control problem of a 2-DoF laboratory
helicopter. The control problem addressed in 2-DoF helicopter system aims to
track the desired pitch and yaw axes trajectories despite disturbed operating
conditions. In addition to the unpredictable variations, the 2-DoF helicopter
dynamic is highly nonlinear with having strong cross-couplings in their models
as well as being open loop unstable system. Thus, we propose a model-free LQR
based PID control strategy in order to achieve better trajectory tracking
control objectives. Robustness tests are performed experimentally to show the
effectiveness of the model-free control.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10988</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10990</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Computation Algorithms for Coloring of Uniform Hypergraphs</dc:title>
 <dc:creator>Dorobisz, Andrzej</dc:creator>
 <dc:creator>Kozik, Jakub</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>05C15, 05C65, 68W20, 68Q87</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  We present a progress on local computation algorithms for two coloring of
$k$-uniform hypergraphs. We focus on instances that satisfy strengthened
assumption of Local Lemma of the form $2^{1-\alpha k} (\Delta+1) e &lt; 1$, where
$\Delta$ is the bound on the maximum edge degree of the hypergraph. We discuss
how previous works on the subject can be used to obtain an algorithm that works
in polylogarithmic time per query for $\alpha$ up to about $0.139$. Then, we
present a procedure that, within similar bounds on running time, solves wider
range of instances by allowing $\alpha$ at most about $0.227$.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10990</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.10998</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estrategias para cubrir la demanda insatisfecha en una f\'abrica
  alimenticia</dc:title>
 <dc:creator>Mendoza, Carlos</dc:creator>
 <dc:creator>Guti&#xe9;rrez, Francisco</dc:creator>
 <dc:creator>Leo, Rodrigo</dc:creator>
 <dc:creator>Rebollo, H&#xe9;ctor</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Supply shortage could be a serios problem in production facilities, and an
accurate diagnosis of its cause is crucial for its solution. This work presents
a case study for determining a solution by means of a nonlinear programming
model.
</dc:description>
 <dc:description>Comment: 6 pages, in Spanish, 2 figures</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.10998</dc:identifier>
 <dc:language>es</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11002</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attribution of Gradient Based Adversarial Attacks for Reverse
  Engineering of Deceptions</dc:title>
 <dc:creator>Goebel, Michael</dc:creator>
 <dc:creator>Bunk, Jason</dc:creator>
 <dc:creator>Chattopadhyay, Srinjoy</dc:creator>
 <dc:creator>Nataraj, Lakshmanan</dc:creator>
 <dc:creator>Chandrasekaran, Shivkumar</dc:creator>
 <dc:creator>Manjunath, B. S.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Machine Learning (ML) algorithms are susceptible to adversarial attacks and
deception both during training and deployment. Automatic reverse engineering of
the toolchains behind these adversarial machine learning attacks will aid in
recovering the tools and processes used in these attacks. In this paper, we
present two techniques that support automated identification and attribution of
adversarial ML attack toolchains using Co-occurrence Pixel statistics and
Laplacian Residuals. Our experiments show that the proposed techniques can
identify parameters used to generate adversarial samples. To the best of our
knowledge, this is the first approach to attribute gradient based adversarial
attacks and estimate their parameters. Source code and data is available at:
https://github.com/michael-goebel/ei_red
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11008</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Does Code Structure Affect Comprehension? On Using and Naming
  Intermediate Variables</dc:title>
 <dc:creator>Cates, Roee</dc:creator>
 <dc:creator>Yunik, Nadav</dc:creator>
 <dc:creator>Feitelson, Dror G.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Intermediate variables can be used to break complex expressions into more
manageable smaller expressions, which may be easier to understand. But it is
unclear when and whether this actually helps. We conducted an experiment in
which subjects read 6 mathematical functions and were supposed to give them
meaningful names. 113 subjects participated, of which 58% had 3 or more years
of programming work experience. Each function had 3 versions: using a compound
expression, using intermediate variables with meaningless names, or using
intermediate variables with meaningful names. The results were that in only one
case there was a significant difference between the two extreme versions, in
favor of the one with intermediate variables with meaningful names. This case
was the function that was the hardest to understand to begin with. In two
additional cases using intermediate variables with meaningless names appears to
have caused a slight decrease in understanding. In all other cases the code
structure did not make much of a difference. As it is hard to anticipate what
others will find difficult to understand, the conclusion is that using
intermediate variables is generally desirable. However, this recommendation
hinges on giving them good names.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures, 2 tables. Accepted to the 29th IEEE/ACM
  International Conference on Program Comprehension</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11011</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Let Your Heart Speak in its Mother Tongue: Multilingual Captioning of
  Cardiac Signals</dc:title>
 <dc:creator>Kiyasseh, Dani</dc:creator>
 <dc:creator>Zhu, Tingting</dc:creator>
 <dc:creator>Clifton, David</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Cardiac signals, such as the electrocardiogram, convey a significant amount
of information about the health status of a patient which is typically
summarized by a clinician in the form of a clinical report, a cumbersome
process that is prone to errors. To streamline this routine process, we propose
a deep neural network capable of captioning cardiac signals; it receives a
cardiac signal as input and generates a clinical report as output. We extend
this further to generate multilingual reports. To that end, we create and make
publicly available a multilingual clinical report dataset. In the absence of
sufficient labelled data, deep neural networks can benefit from a warm-start,
or pre-training, procedure in which parameters are first learned in an
arbitrary task. We propose such a task in the form of discriminative
multilingual pre-training where tokens from clinical reports are randomly
replaced with those from other languages and the network is tasked with
predicting the language of all tokens. We show that our method performs on par
with state-of-the-art pre-training methods such as MLM, ELECTRA, and MARGE,
while simultaneously generating diverse and plausible clinical reports. We also
demonstrate that multilingual models can outperform their monolingual
counterparts, informally terming this beneficial phenomenon as the blessing of
multilinguality.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11013</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Exploratory Study of Project Activity Changepoints in Open Source
  Software Evolution</dc:title>
 <dc:creator>Walden, James</dc:creator>
 <dc:creator>Burgin, Noah</dc:creator>
 <dc:creator>Kaur, Kuljit</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  To explore the prevalence of abrupt changes (changepoints) in open source
project activity, we assembled a dataset of 8,919 projects from the World of
Code. Projects were selected based on age, number of commits, and number of
authors. Using the nonparametric PELT algorithm, we identified changepoints in
project activity time series, finding that more than 90% of projects had
between one and six changepoints. Increases and decreases in project activity
occurred with roughly equal frequency. While most changes are relatively small,
on the order of a few authors or few dozen commits per month, there were long
tails of much larger project activity changes. In future work, we plan to focus
on larger changes to search for common open source lifecycle patterns as well
as common responses to external events.
</dc:description>
 <dc:description>Comment: 2 pages + bibliography, 3 figures</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11014</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fight Virus Like a Virus: A New Defense Method Against File-Encrypting
  Ransomware</dc:title>
 <dc:creator>Morris, Joshua</dc:creator>
 <dc:creator>Lin, Dan</dc:creator>
 <dc:creator>Smith, Marcellus</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Nowadays ransomware has become a new profitable form of attack. This type of
malware acts as a form of extortion which encrypts the files in a victim's
computer and forces the victim to pay the ransom to have the data recovered.
Even companies and tech savvy people must use extensive resources to maintain
backups for recovery or else they will lose valuable data, not mentioning
average users. Unfortunately, not any recovery tool can effectively defend
various types of ransomware. To address this challenge, we propose a novel
ransomware defense mechanism that can be easily deployed in modern Windows
system to recover the data and mitigate a ransomware attack. The uniqueness of
our approach is to fight the virus like a virus. We leverage Alternative Data
Streams which are sometimes used by malicious applications, to develop a data
protection method that misleads the ransomware to attack only file 'shells'
instead of the actual file content. We evaluated different file encrypting
ransomware and demonstrate usability, efficiency and effectiveness of our
approach.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11018</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integer and Constraint Programming Revisited for Mutually Orthogonal
  Latin Squares</dc:title>
 <dc:creator>Rubin, Noah</dc:creator>
 <dc:creator>Bright, Curtis</dc:creator>
 <dc:creator>Cheung, Kevin K. H.</dc:creator>
 <dc:creator>Stevens, Brett</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper we provide results on using integer programming (IP) and
constraint programming (CP) to search for sets of mutually orthogonal latin
squares (MOLS). Both programming paradigms have previously successfully been
used to search for MOLS, but solvers for IP and CP solvers have significantly
improved in recent years and data on how modern IP and CP solvers perform on
the MOLS problem is lacking. Using state-of-the-art solvers as black boxes we
were able to quickly find pairs of MOLS (or prove their nonexistence) in all
orders up to ten. Moreover, we improve the effectiveness of the solvers by
formulating an extended symmetry breaking method as well as an improvement to
the straightforward CP encoding. We also analyze the effectiveness of using CP
and IP solvers to search for triples of MOLS, compare our timings to those
which have been previously published, and estimate the running time of using
this approach to resolve the longstanding open problem of determining the
existence of a triple of MOLS of order ten.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11021</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On cumulative residual (past) inaccuracy for truncated random variables</dc:title>
 <dc:creator>Kundu, Chanchal</dc:creator>
 <dc:creator>Di Crescenzo, Antonio</dc:creator>
 <dc:creator>Longobardi, Maria</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>94A17, 62N05, 60E15</dc:subject>
 <dc:description>  To overcome the drawbacks of Shannon's entropy, the concept of cumulative
residual and past entropy has been proposed in the information theoretic
literature. Furthermore, the Shannon entropy has been generalized in a number
of different ways by many researchers. One important extension is Kerridge
inaccuracy measure. In the present communication we study the cumulative
residual and past inaccuracy measures, which are extensions of the
corresponding cumulative entropies. Several properties, including monotonicity
and bounds, are obtained for left, right and doubly truncated random variables.
</dc:description>
 <dc:description>Comment: 19 pages, 3 figures</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11021</dc:identifier>
 <dc:identifier>Metrika, 79 (2016), pp. 335-356</dc:identifier>
 <dc:identifier>doi:10.1007/s00184-015-0557-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11023</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Individually Fair Ranking</dc:title>
 <dc:creator>Bower, Amanda</dc:creator>
 <dc:creator>Eftekhari, Hamid</dc:creator>
 <dc:creator>Yurochkin, Mikhail</dc:creator>
 <dc:creator>Sun, Yuekai</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We develop an algorithm to train individually fair learning-to-rank (LTR)
models. The proposed approach ensures items from minority groups appear
alongside similar items from majority groups. This notion of fair ranking is
based on the definition of individual fairness from supervised learning and is
more nuanced than prior fair LTR approaches that simply ensure the ranking
model provides underrepresented items with a basic level of exposure. The crux
of our method is an optimal transport-based regularizer that enforces
individual fairness and an efficient algorithm for optimizing the regularizer.
We show that our approach leads to certifiably individually fair LTR models and
demonstrate the efficacy of our method on ranking tasks subject to demographic
biases.
</dc:description>
 <dc:description>Comment: ICLR Camera-Ready Version</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11025</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stability and error analysis of a class of high-order IMEX schemes for
  Navier-stokes equations with periodic boundary conditions</dc:title>
 <dc:creator>Huang, Fukeng</dc:creator>
 <dc:creator>Shen, Jie</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65M15, 76D05, 65M70</dc:subject>
 <dc:description>  We construct high-order semi-discrete-in-time and fully discrete (with
Fourier-Galerkin in space) schemes for the incompressible Navier-Stokes
equations with periodic boundary conditions, and carry out corresponding error
analysis. The schemes are of implicit-explicit type based on a scalar auxiliary
variable (SAV) approach. It is shown that numerical solutions of these schemes
are uniformly bounded without any restriction on time step size. These uniform
bounds enable us to carry out a rigorous error analysis for the schemes up to
fifth-order in a unified form, and derive global error estimates in
$l^\infty(0,T;H^1)\cap l^2(0,T;H^2)$ in the two dimensional case as well as
local error estimates in $l^\infty(0,T;H^1)\cap l^2(0,T;H^2)$ in the three
dimensional case. We also present numerical results confirming our theoretical
convergence rates and demonstrating advantages of higher-order schemes for
flows with complex structures in the double shear layer problem.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11027</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relational Operations in FOLE</dc:title>
 <dc:creator>Kent, Robert E.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>H.2.1</dc:subject>
 <dc:description>  This paper discusses relational operations in the first-order logical
environment {FOLE}. Here we demonstrate how FOLE expresses the relational
operations of database theory in a clear and implementable representation. An
analysis of the representation of database tables/relations in FOLE reveals a
principled way to express the relational operations. This representation is
expressed in terms of a distinction between basic components versus composite
relational operations. The 9 basic components fall into three categories:
reflection (2), Booleans or basic operations (3), and adjoint flow (4). Adjoint
flow is given for signatures (2) and for type domains (2), which are then
combined into full adjoint flow. The basic components are used to express
various composite operations, where we illustrate each of these with a
flowchart. Implementation of the composite operations is then expressed in an
input/output table containing four parts: constraint, construction, input, and
output. We explain how limits and colimits are constructed from diagrams of
tables, and then classify composite relational operations into three
categories: limit-like, colimit-like and unorthodox.
</dc:description>
 <dc:description>Comment: 85 pages, 43 figures, 21 tables</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11029</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TextEssence: A Tool for Interactive Analysis of Semantic Shifts Between
  Corpora</dc:title>
 <dc:creator>Newman-Griffis, Denis</dc:creator>
 <dc:creator>Sivaraman, Venkatesh</dc:creator>
 <dc:creator>Perer, Adam</dc:creator>
 <dc:creator>Fosler-Lussier, Eric</dc:creator>
 <dc:creator>Hochheiser, Harry</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Embeddings of words and concepts capture syntactic and semantic regularities
of language; however, they have seen limited use as tools to study
characteristics of different corpora and how they relate to one another. We
introduce TextEssence, an interactive system designed to enable comparative
analysis of corpora using embeddings. TextEssence includes visual,
neighbor-based, and similarity-based modes of embedding analysis in a
lightweight, web-based interface. We further propose a new measure of embedding
confidence based on nearest neighborhood overlap, to assist in identifying
high-quality embeddings for corpus analysis. A case study on COVID-19
scientific literature illustrates the utility of the system. TextEssence is
available from https://github.com/drgriffis/text-essence.
</dc:description>
 <dc:description>Comment: Accepted as a Systems Demonstration at NAACL-HLT 2021. Video
  demonstration at https://youtu.be/1xEEfsMwL0k</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11042</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AI Specialization for Pathways of Economic Diversification</dc:title>
 <dc:creator>Mishra, Saurabh</dc:creator>
 <dc:creator>Koopman, Robert</dc:creator>
 <dc:creator>De-Prato, Giuditta</dc:creator>
 <dc:creator>Rao, Anand</dc:creator>
 <dc:creator>Osorio-Rodarte, Israel</dc:creator>
 <dc:creator>Kim, Julie</dc:creator>
 <dc:creator>Spatafora, Nikola</dc:creator>
 <dc:creator>Strier, Keith</dc:creator>
 <dc:creator>Zaccaria, Andrea</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Economics - General Economics</dc:subject>
 <dc:description>  The growth in AI is rapidly transforming the structure of economic
production. However, very little is known about how within-AI specialization
may relate to broad-based economic diversification. This paper provides a
data-driven framework to integrate the interconnection between AI-based
specialization with goods and services export specialization to help design
future comparative advantage based on the inherent capabilities of nations.
Using detailed data on private investment in AI and export specialization for
more than 80 countries, we propose a systematic framework to help identify the
connection from AI to goods and service sector specialization. The results are
instructive for nations that aim to harness AI specialization to help guide
sources of future competitive advantage. The operational framework could help
inform the public and private sector to uncover connections with nearby areas
of specialization.
</dc:description>
 <dc:description>Comment: 27 pages, 20 figures, 3 tables</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11043</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BEHAVE: Behavior-Aware, Intelligent and Fair Resource Management for
  Heterogeneous Edge-IoT Systems</dc:title>
 <dc:creator>Alqerm, Ismail</dc:creator>
 <dc:creator>Wang, Jianyu</dc:creator>
 <dc:creator>Pan, Jianli</dc:creator>
 <dc:creator>Liu, Yuanni</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Edge computing is an emerging solution to support the future Internet of
Things (IoT) applications that are delay-sensitive, processing-intensive or
that require closer intelligence. Machine intelligence and data-driven
approaches are envisioned to build future Edge-IoT systems that satisfy IoT
devices' demands for edge resources. However, significant challenges and
technical barriers exist which complicate the resource management for such
Edge-IoT systems. IoT devices running various applications can demonstrate a
wide range of behaviors in the devices' resource demand that are extremely
difficult to manage. In addition, the management of multidimensional resources
fairly and efficiently by the edge in such a setting is a challenging task. In
this paper, we develop a novel data-driven resource management framework named
BEHAVE that intelligently and fairly allocates edge resources to heterogeneous
IoT devices with consideration of their behavior of resource demand (BRD).
BEHAVE aims to holistically address the management technical barriers by: 1)
building an efficient scheme for modeling and assessment of the BRD of IoT
devices based on their resource requests and resource usage; 2) expanding a new
Rational, Fair, and Truthful Resource Allocation (RFTA) model that binds the
devices' BRD and resource allocation to achieve fair allocation and encourage
truthfulness in resource demand; and 3) developing an enhanced deep
reinforcement learning (EDRL) scheme to achieve the RFTA goals. The evaluation
results demonstrate BEHAVE's capability to analyze the IoT devices' BRD and
adjust its resource management policy accordingly.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11043</dc:identifier>
 <dc:identifier>IEEE Transactions on Mobile Computing, 2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11046</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Hybrid Error Correction for Time-Sensitive Devices at the
  Edge</dc:title>
 <dc:creator>Yang, Siyi</dc:creator>
 <dc:creator>Hareedy, Ahmed</dc:creator>
 <dc:creator>Calderbank, Robert</dc:creator>
 <dc:creator>Dolecek, Lara</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Computational storage, known as a solution to significantly reduce the
latency by moving data-processing down to the data storage, has received wide
attention because of its potential to accelerate data-driven devices at the
edge. To meet the insatiable appetite for complicated functionalities tailored
for intelligent devices such as autonomous vehicles, properties including
heterogeneity, scalability, and flexibility are becoming increasingly
important. Based on our prior work on hierarchical erasure coding that enables
scalability and flexibility in cloud storage, we develop an efficient decoding
algorithm that corrects a mixture of errors and erasures simultaneously. We
first extract the basic component code, the so-called extended Cauchy (EC)
codes, of the proposed coding solution. We prove that the class of EC codes is
strictly larger than that of relevant codes with known explicit decoding
algorithms. Motivated by this finding, we then develop an efficient decoding
method for the general class of EC codes, based on which we propose the local
and global decoding algorithms for the hierarchical codes. Our proposed hybrid
error correction not only enables the usage of hierarchical codes in
computational storage at the edge, but also applies to any Cauchy-like codes
and allows potentially wider applications of the EC codes.
</dc:description>
 <dc:description>Comment: 29 pages (single column), 0 figures, to be submitted to IEEE
  Transactions on Communications</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11052</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A first step towards automated species recognition from camera trap
  images of mammals using AI in a European temperate forest</dc:title>
 <dc:creator>Choinski, Mateusz</dc:creator>
 <dc:creator>Rogowski, Mateusz</dc:creator>
 <dc:creator>Tynecki, Piotr</dc:creator>
 <dc:creator>Kuijper, Dries P. J.</dc:creator>
 <dc:creator>Churski, Marcin</dc:creator>
 <dc:creator>Bubnicki, Jakub W.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>68T07</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>I.4</dc:subject>
 <dc:description>  Camera traps are used worldwide to monitor wildlife. Despite the increasing
availability of Deep Learning (DL) models, the effective usage of this
technology to support wildlife monitoring is limited. This is mainly due to the
complexity of DL technology and high computing requirements. This paper
presents the implementation of the light-weight and state-of-the-art YOLOv5
architecture for automated labeling of camera trap images of mammals in the
Bialowieza Forest (BF), Poland. The camera trapping data were organized and
harmonized using TRAPPER software, an open source application for managing
large-scale wildlife monitoring projects. The proposed image recognition
pipeline achieved an average accuracy of 85% F1-score in the identification of
the 12 most commonly occurring medium-size and large mammal species in BF using
a limited set of training and testing data (a total 2659 images with animals).
  Based on the preliminary results, we concluded that the YOLOv5 object
detection and classification model is a promising light-weight DL solution
after the adoption of transfer learning technique. It can be efficiently
plugged in via an API into existing web-based camera trapping data processing
platforms such as e.g. TRAPPER system. Since TRAPPER is already used to manage
and classify (manually) camera trapping datasets by many research groups in
Europe, the implementation of AI-based automated species classification may
significantly speed up the data processing workflow and thus better support
data-driven wildlife monitoring and conservation. Moreover, YOLOv5 developers
perform better performance on edge devices which may open a new chapter in
animal population monitoring in real time directly from camera trap devices.
</dc:description>
 <dc:description>Comment: CISIM 2021 conference paper</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11059</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Quantification of Facial Asymmetry using Facial Landmarks</dc:title>
 <dc:creator>Taufique, Abu Md Niamul</dc:creator>
 <dc:creator>Savakis, Andreas</dc:creator>
 <dc:creator>Leckenby, Jonathan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4</dc:subject>
 <dc:subject>I.5</dc:subject>
 <dc:description>  One-sided facial paralysis causes uneven movements of facial muscles on the
sides of the face. Physicians currently assess facial asymmetry in a subjective
manner based on their clinical experience. This paper proposes a novel method
to provide an objective and quantitative asymmetry score for frontal faces. Our
metric has the potential to help physicians for diagnosis as well as monitoring
the rehabilitation of patients with one-sided facial paralysis. A deep learning
based landmark detection technique is used to estimate style invariant facial
landmark points and dense optical flow is used to generate motion maps from a
short sequence of frames. Six face regions are considered corresponding to the
left and right parts of the forehead, eyes, and mouth. Motion is computed and
compared between the left and the right parts of each region of interest to
estimate the symmetry score. For testing, asymmetric sequences are
synthetically generated from a facial expression dataset. A score equation is
developed to quantify symmetry in both symmetric and asymmetric face sequences.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11059</dc:identifier>
 <dc:identifier>2019 IEEE Western New York Image and Signal Processing Workshop
  (WNYISPW)</dc:identifier>
 <dc:identifier>doi:10.1109/WNYIPW.2019.8923078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11061</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visualization of Deep Transfer Learning In SAR Imagery</dc:title>
 <dc:creator>Taufique, Abu Md Niamul</dc:creator>
 <dc:creator>Nagananda, Navya</dc:creator>
 <dc:creator>Savakis, Andreas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4</dc:subject>
 <dc:subject>I.5</dc:subject>
 <dc:description>  Synthetic Aperture Radar (SAR) imagery has diverse applications in land and
marine surveillance. Unlike electro-optical (EO) systems, these systems are not
affected by weather conditions and can be used in the day and night times. With
the growing importance of SAR imagery, it would be desirable if models trained
on widely available EO datasets can also be used for SAR images. In this work,
we consider transfer learning to leverage deep features from a network trained
on an EO ships dataset and generate predictions on SAR imagery. Furthermore, by
exploring the network activations in the form of class-activation maps (CAMs),
we visualize the transfer learning process to SAR imagery and gain insight on
how a deep network interprets a new modality.
</dc:description>
 <dc:description>Comment: 4 pages, 5 figures</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11061</dc:identifier>
 <dc:identifier>IGARSS 2020 - 2020 IEEE International Geoscience and Remote
  Sensing Symposium</dc:identifier>
 <dc:identifier>doi:10.1109/IGARSS39084.2020.9324490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11062</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Unlabeled Data for Entity-Relation Extraction through
  Probabilistic Constraint Satisfaction</dc:title>
 <dc:creator>Ahmed, Kareem</dc:creator>
 <dc:creator>Wang, Eric</dc:creator>
 <dc:creator>Broeck, Guy Van den</dc:creator>
 <dc:creator>Chang, Kai-Wei</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We study the problem of entity-relation extraction in the presence of
symbolic domain knowledge. Such knowledge takes the form of an ontology
defining relations and their permissible arguments. Previous approaches set out
to integrate such knowledge in their learning approaches either through
self-training, or through approximations that lose the precise meaning of the
logical expressions. By contrast, our approach employs semantic loss which
captures the precise meaning of a logical sentence through maintaining a
probability distribution over all possible states, and guiding the model to
solutions which minimize any constraint violations. With a focus on low-data
regimes, we show that semantic loss outperforms the baselines by a wide margin.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11065</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Encrypted Value Iteration and Temporal Difference Learning over Leveled
  Homomorphic Encryption</dc:title>
 <dc:creator>Suh, Jihoon</dc:creator>
 <dc:creator>Tanaka, Takashi</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  We consider an architecture of confidential cloud-based control synthesis
based on Homomorphic Encryption (HE). Our study is motivated by the recent
surge of data-driven control such as deep reinforcement learning, whose heavy
computational requirements often necessitate an outsourcing to the third party
server. To achieve more flexibility than Partially Homomorphic Encryption (PHE)
and less computational overhead than Fully Homomorphic Encryption (FHE), we
consider a Reinforcement Learning (RL) architecture over Leveled Homomorphic
Encryption (LHE). We first show that the impact of the encryption noise under
the Cheon-Kim-Kim-Song (CKKS) encryption scheme on the convergence of the
model-based tabular Value Iteration (VI) can be analytically bounded. We also
consider secure implementations of TD(0), SARSA(0) and Z-learning algorithms
over the CKKS scheme, where we numerically demonstrate that the effects of the
encryption noise on these algorithms are also minimal.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures, American Control Conference</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11067</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Agent Algorithms for Collective Behavior: A structural and
  application-focused atlas</dc:title>
 <dc:creator>Rossi, Federico</dc:creator>
 <dc:creator>Bandyopadhyay, Saptarshi</dc:creator>
 <dc:creator>Wolf, Michael T.</dc:creator>
 <dc:creator>Pavone, Marco</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The goal of this paper is to provide a survey and application-focused atlas
of collective behavior coordination algorithms for multi-agent systems.
  We survey the general family of collective behavior algorithms for
multi-agent systems and classify them according to their underlying
mathematical structure. In doing so, we aim to capture fundamental mathematical
properties of algorithms (e.g., scalability with respect to the number of
agents and bandwidth use) and to show how the same algorithm or family of
algorithms can be used for multiple tasks and applications.
  Collectively, this paper provides an application-focused atlas of algorithms
for collective behavior of multi-agent systems, with three objectives:
  1. to act as a tutorial guide to practitioners in the selection of
coordination algorithms for a given application;
  2. to highlight how mathematically similar algorithms can be used for a
variety of tasks, ranging from low-level control to high-level coordination;
  3. to explore the state-of-the-art in the field of control of multi-agent
systems and identify areas for future research.
</dc:description>
 <dc:description>Comment: Under review for journal publication. Revised and extended version of
  arXiv:1803.05464</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11067</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11073</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>UAV Communications for Sustainable Federated Learning</dc:title>
 <dc:creator>Pham, Quoc-Viet</dc:creator>
 <dc:creator>Zeng, Ming</dc:creator>
 <dc:creator>Ruby, Rukhsana</dc:creator>
 <dc:creator>Huynh-The, Thien</dc:creator>
 <dc:creator>Hwang, Won-Joo</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Federated learning (FL), invented by Google in 2016, has become a hot
research trend. However, enabling FL in wireless networks has to overcome the
limited battery challenge of mobile users. In this regard, we propose to apply
unmanned aerial vehicle (UAV)-empowered wireless power transfer to enable
sustainable FL-based wireless networks. The objective is to maximize the UAV
transmit power efficiency, via a joint optimization of transmission time and
bandwidth allocation, power control, and the UAV placement. Directly solving
the formulated problem is challenging, due to the coupling of variables. Hence,
we leverage the decomposition technique and a successive convex approximation
approach to develop an efficient algorithm, namely UAV for sustainable FL
(UAV-SFL). Finally, simulations illustrate the potential of our proposed
UAV-SFL approach in providing a sustainable solution for FL-based wireless
networks, and in reducing the UAV transmit power by 32.95%, 63.18%, and 78.81%
compared with the benchmarks.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Vehicular Technology correspondence 2021</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11073</dc:identifier>
 <dc:identifier>doi:10.1109/TVT.2021.3065084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11083</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compacting Deep Neural Networks for Internet of Things: Methods and
  Applications</dc:title>
 <dc:creator>Zhang, Ke</dc:creator>
 <dc:creator>Ying, Hanbo</dc:creator>
 <dc:creator>Dai, Hong-Ning</dc:creator>
 <dc:creator>Li, Lin</dc:creator>
 <dc:creator>Peng, Yuangyuang</dc:creator>
 <dc:creator>Guo, Keyi</dc:creator>
 <dc:creator>Yu, Hongfang</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>68T07</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>C.2</dc:subject>
 <dc:description>  Deep Neural Networks (DNNs) have shown great success in completing complex
tasks. However, DNNs inevitably bring high computational cost and storage
consumption due to the complexity of hierarchical structures, thereby hindering
their wide deployment in Internet-of-Things (IoT) devices, which have limited
computational capability and storage capacity. Therefore, it is a necessity to
investigate the technologies to compact DNNs. Despite tremendous advances in
compacting DNNs, few surveys summarize compacting-DNNs technologies, especially
for IoT applications. Hence, this paper presents a comprehensive study on
compacting-DNNs technologies. We categorize compacting-DNNs technologies into
three major types: 1) network model compression, 2) Knowledge Distillation
(KD), 3) modification of network structures. We also elaborate on the diversity
of these approaches and make side-by-side comparisons. Moreover, we discuss the
applications of compacted DNNs in various IoT applications and outline future
directions.
</dc:description>
 <dc:description>Comment: 25 pages, 11 figures</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11083</dc:identifier>
 <dc:identifier>IEEE Internet of Things Journal, 2021</dc:identifier>
 <dc:identifier>doi:10.1109/JIOT.2021.3063497</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11084</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3DMNDT:3D multi-view registration method based on the normal
  distributions transform</dc:title>
 <dc:creator>Zhu, Jihua</dc:creator>
 <dc:creator>Wang, Di</dc:creator>
 <dc:creator>Mu, Jiaxi</dc:creator>
 <dc:creator>Lu, Huimin</dc:creator>
 <dc:creator>Tian, Zhiqiang</dc:creator>
 <dc:creator>Li, Zhongyu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The normal distributions transform (NDT) is an effective paradigm for the
point set registration. This method is originally designed for pair-wise
registration and it will suffer from great challenges when applied to
multi-view registration. Under the NDT framework, this paper proposes a novel
multi-view registration method, named 3D multi-view registration based on the
normal distributions transform (3DMNDT), which integrates the K-means
clustering and Lie algebra solver to achieve multi-view registration. More
specifically, the multi-view registration is cast into the problem of maximum
likelihood estimation. Then, the K-means algorithm is utilized to divide all
data points into different clusters, where a normal distribution is computed to
locally models the probability of measuring a data point in each cluster.
Subsequently, the registration problem is formulated by the NDT-based
likelihood function. To maximize this likelihood function, the Lie algebra
solver is developed to sequentially optimize each rigid transformation. The
proposed method alternately implements data point clustering, NDT computing,
and likelihood maximization until desired registration results are obtained.
Experimental results tested on benchmark data sets illustrate that the proposed
method can achieve state-of-the-art performance for multi-view registration.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11088</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Token-wise Curriculum Learning for Neural Machine Translation</dc:title>
 <dc:creator>Liang, Chen</dc:creator>
 <dc:creator>Jiang, Haoming</dc:creator>
 <dc:creator>Liu, Xiaodong</dc:creator>
 <dc:creator>He, Pengcheng</dc:creator>
 <dc:creator>Chen, Weizhu</dc:creator>
 <dc:creator>Gao, Jianfeng</dc:creator>
 <dc:creator>Zhao, Tuo</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Existing curriculum learning approaches to Neural Machine Translation (NMT)
require sampling sufficient amounts of &quot;easy&quot; samples from training data at the
early training stage. This is not always achievable for low-resource languages
where the amount of training data is limited. To address such limitation, we
propose a novel token-wise curriculum learning approach that creates sufficient
amounts of easy samples. Specifically, the model learns to predict a short
sub-sequence from the beginning part of each target sentence at the early stage
of training, and then the sub-sequence is gradually expanded as the training
progresses. Such a new curriculum design is inspired by the cumulative effect
of translation errors, which makes the latter tokens more difficult to predict
than the beginning ones. Extensive experiments show that our approach can
consistently outperform baselines on 5 language pairs, especially for
low-resource languages. Combining our approach with sentence-level methods
further improves the performance on high-resource languages.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11088</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11089</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dependency Graph-to-String Statistical Machine Translation</dc:title>
 <dc:creator>Li, Liangyou</dc:creator>
 <dc:creator>Way, Andy</dc:creator>
 <dc:creator>Liu, Qun</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We present graph-based translation models which translate source graphs into
target strings. Source graphs are constructed from dependency trees with extra
links so that non-syntactic phrases are connected. Inspired by phrase-based
models, we first introduce a translation model which segments a graph into a
sequence of disjoint subgraphs and generates a translation by combining
subgraph translations left-to-right using beam search. However, similar to
phrase-based models, this model is weak at phrase reordering. Therefore, we
further introduce a model based on a synchronous node replacement grammar which
learns recursive translation rules. We provide two implementations of the model
with different restrictions so that source graphs can be parsed efficiently.
Experiments on Chinese--English and German--English show that our graph-based
models are significantly better than corresponding sequence- and tree-based
baselines.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11089</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11095</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social Link Inference via Multi-View Matching Network from
  Spatio-Temporal Trajectories</dc:title>
 <dc:creator>Zhang, Wei</dc:creator>
 <dc:creator>Lai, Xin</dc:creator>
 <dc:creator>Wang, Jianyong</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In this paper, we investigate the problem of social link inference in a
target Location-aware Social Network (LSN), which aims at predicting the
unobserved links between users within the network. This problem is critical for
downstream applications including network completion and friend recommendation.
In addition to the network structures commonly used in general link prediction,
the studies tailored for social link inference in an LSN leverage user
trajectories from the spatial aspect. However, the temporal factor lying in
user trajectories is largely overlooked by most of the prior studies, limiting
the capabilities of capturing the temporal relevance between users. Moreover,
effective user matching by fusing different views, i.e., social, spatial, and
temporal factors, remains unresolved, which hinders the potential improvement
of link inference. To this end, this paper devises a novel multi-view matching
network (MVMN) by regarding each of the three factors as one view of any target
user pair. MVMN enjoys the flexibility and completeness of modeling each factor
by developing its suitable matching module: 1) location matching module, 2)
time-series matching module, and 3) relation matching module. Each module
learns a view-specific representation for matching, and MVMN fuses them for
final link inference. Extensive experiments on two real-world datasets
demonstrate the superiority of our approach against several competitive
baselines for link prediction and sequence matching, validating the
contribution of its key components.
</dc:description>
 <dc:description>Comment: 12 pages, Published in IEEE TNNLS (Key source code added)</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11095</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11097</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Autocalibration Method for Triaxial Gyroscope without
  External Device</dc:title>
 <dc:creator>Wang, Li</dc:creator>
 <dc:creator>Su, Steven</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Gyroscopes are widely used in various field. The instability of the low-cost
gyroscopes makes them need to be calibrated on every boot. To meet the
requirement of frequency calibration, finding an efficient in-field calibration
method is essential. This paper proposes a fast calibration method that does
not require any external equipment. We use the manual rotation angle as a
calibration reference and linearize the calibration model. On the basis of this
model, a G-optimal experimental design scheme is proposed, which can get enough
calibration information with the least number of experiments. The simulations
indicate that the calibration error is relatively low, and the results are
unbiased. We empirically validate the effectiveness of the proposed method on
two commonly used low-cost gyroscope and achieve real-time calibration on a
low-energy microcontroller. We validate the proposed method by comparing the
above method with the conventional turntable method. The experiment result
shows that the error between these two methods is less than $\pm3 \times
10^{-2}$ and the calibration process takes less than 30 seconds. This method
might have a practical implication for low-cost gyroscope calibration.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11097</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11104</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RLTIR: Activity-based Interactive Person Identification based on
  Reinforcement Learning Tree</dc:title>
 <dc:creator>Li, Qingyang</dc:creator>
 <dc:creator>Yu, Zhiwen</dc:creator>
 <dc:creator>Yao, Lina</dc:creator>
 <dc:creator>Guo, Bin</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Identity recognition plays an important role in ensuring security in our
daily life. Biometric-based (especially activity-based) approaches are favored
due to their fidelity, universality, and resilience. However, most existing
machine learning-based approaches rely on a traditional workflow where models
are usually trained once for all, with limited involvement from end-users in
the process and neglecting the dynamic nature of the learning process. This
makes the models static and can not be updated in time, which usually leads to
high false positive or false negative. Thus, in practice, an expert is desired
to assist with providing high-quality observations and interpretation of model
outputs. It is expedient to combine both advantages of human experts and the
computational capability of computers to create a tight-coupling incremental
learning process for better performance. In this study, we develop RLTIR, an
interactive identity recognition approach based on reinforcement learning, to
adjust the identification model by human guidance. We first build a base
tree-structured identity recognition model. And an expert is introduced in the
model for giving feedback upon model outputs. Then, the model is updated
according to strategies that are automatically learned under a designated
reinforcement learning framework. To the best of our knowledge, it is the very
first attempt to combine human expert knowledge with model learning in the area
of identity recognition. The experimental results show that the reinforced
interactive identity recognition framework outperforms baseline methods with
regard to recognition accuracy and robustness.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11105</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beam-Squint Mitigating for Reconfigurable Intelligent Surface Aided
  Wideband MmWave Communications</dc:title>
 <dc:creator>Chen, Yun</dc:creator>
 <dc:creator>Chen, Da</dc:creator>
 <dc:creator>Jiang, Tao</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we focus our attention on the mitigation of beam squint for
reconfigurable intelligent surface (RIS) aided wideband millimeter wave
(mmWave) communications. Due to the intrinsic passive property, the phase
shifts of all elements in RIS should be the same for all frequencies. However,
in the wideband scenario, beam squint induced distinct path phases require
designing different phase shifts for different frequencies. The above
irreconcilable contradiction will dramatically affect the system performance,
considering the RIS usually consists of enormous elements and the bandwidth of
wideband mmWave communications may be up to several GHz. Therefore, we propose
some novel phase shift design schemes for mitigating the effect of beam squint
for both line-of-sight (LoS) and non-Los (NLoS) scenarios. Specifically, for
the LoS scenario, we firstly derive the optimal phase shift for each frequency
and obtain the common phase shift by maximizing the upper bound of achievable
rate. Then, for the NLoS scenario, a mean channel covariance matrix (MCCM)
based scheme is proposed by fully exploiting the correlations between both the
paths and the subcarriers. Our extensive numerical experiments confirm the
effectiveness of the proposed phase shift design schemes.
</dc:description>
 <dc:description>Comment: 14 pages, 6 figures</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11107</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Subspace Approximation and Subset Selection in Fewer Passes by MCMC
  Sampling</dc:title>
 <dc:creator>Deshpande, Amit</dc:creator>
 <dc:creator>Pratap, Rameshwar</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Spectral Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of subset selection for $\ell_{p}$ subspace
approximation, i.e., given $n$ points in $d$ dimensions, we need to pick a
small, representative subset of the given points such that its span gives
$(1+\epsilon)$ approximation to the best $k$-dimensional subspace that
minimizes the sum of $p$-th powers of distances of all the points to this
subspace. Sampling-based subset selection techniques require adaptive sampling
iterations with multiple passes over the data. Matrix sketching techniques give
a single-pass $(1+\epsilon)$ approximation for $\ell_{p}$ subspace
approximation but require additional passes for subset selection.
  In this work, we propose an MCMC algorithm to reduce the number of passes
required by previous subset selection algorithms based on adaptive sampling.
For $p=2$, our algorithm gives subset selection of nearly optimal size in only
$2$ passes, whereas the number of passes required in previous work depend on
$k$. Our algorithm picks a subset of size $\mathrm{poly}(k/\epsilon)$ that
gives $(1+\epsilon)$ approximation to the optimal subspace. The running time of
the algorithm is $nd + d~\mathrm{poly}(k/\epsilon)$. We extend our results to
the case when outliers are present in the datasets, and suggest a two pass
algorithm for the same. Our ideas also extend to give a reduction in the number
of passes required by adaptive sampling algorithms for $\ell_{p}$ subspace
approximation and subset selection, for $p \geq 2$.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11107</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11110</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Upsampling and Context Convolution for Image Semantic
  Segmentation</dc:title>
 <dc:creator>Sediqi, Khwaja Monib</dc:creator>
 <dc:creator>Lee, Hyo Jong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Semantic segmentation, which refers to pixel-wise classification of an image,
is a fundamental topic in computer vision owing to its growing importance in
robot vision and autonomous driving industries. It provides rich information
about objects in the scene such as object boundary, category, and location.
Recent methods for semantic segmentation often employ an encoder-decoder
structure using deep convolutional neural networks. The encoder part extracts
feature of the image using several filters and pooling operations, whereas the
decoder part gradually recovers the low-resolution feature maps of the encoder
into a full input resolution feature map for pixel-wise prediction. However,
the encoder-decoder variants for semantic segmentation suffer from severe
spatial information loss, caused by pooling operations or convolutions with
stride, and does not consider the context in the scene. In this paper, we
propose a dense upsampling convolution method based on guided filtering to
effectively preserve the spatial information of the image in the network. We
further propose a novel local context convolution method that not only covers
larger-scale objects in the scene but covers them densely for precise object
boundary delineation. Theoretical analyses and experimental results on several
benchmark datasets verify the effectiveness of our method. Qualitatively, our
approach delineates object boundaries at a level of accuracy that is beyond the
current excellent methods. Quantitatively, we report a new record of 82.86% and
81.62% of pixel accuracy on ADE20K and Pascal-Context benchmark datasets,
respectively. In comparison with the state-of-the-art methods, the proposed
method offers promising improvements.
</dc:description>
 <dc:description>Comment: 11 pages, published in sensors journal</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11110</dc:identifier>
 <dc:identifier>Sensors 2021, 21, 2170</dc:identifier>
 <dc:identifier>doi:10.3390/s21062170</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11112</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classifier Crafting: Turn Your ConvNet into a Zero-Shot Learner!</dc:title>
 <dc:creator>Cavazza, Jacopo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In Zero-shot learning (ZSL), we classify unseen categories using textual
descriptions about their expected appearance when observed (class embeddings)
and a disjoint pool of seen classes, for which annotated visual data are
accessible. We tackle ZSL by casting a &quot;vanilla&quot; convolutional neural network
(e.g. AlexNet, ResNet-101, DenseNet-201 or DarkNet-53) into a zero-shot
learner. We do so by crafting the softmax classifier: we freeze its weights
using fixed seen classification rules, either semantic (seen class embeddings)
or visual (seen class prototypes). Then, we learn a data-driven and
ZSL-tailored feature representation on seen classes only to match these fixed
classification rules. Given that the latter seamlessly generalize towards
unseen classes, while requiring not actual unseen data to be computed, we can
perform ZSL inference by augmenting the pool of classification rules at test
time while keeping the very same representation we learnt: nowhere re-training
or fine-tuning on unseen data is performed. The combination of semantic and
visual crafting (by simply averaging softmax scores) improves prior
state-of-the-art methods in benchmark datasets for standard, inductive ZSL.
After rebalancing predictions to better handle the joint inference over seen
and unseen classes, we outperform prior generalized, inductive ZSL methods as
well. Also, we gain interpretability at no additional cost, by using neural
attention methods (e.g., grad-CAM) as they are. Code will be made publicly
available.
</dc:description>
 <dc:description>Comment: 8 pages (excluding references), 9 figures</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11112</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11114</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A novel multimodal fusion network based on a joint coding model for lane
  line segmentation</dc:title>
 <dc:creator>Zou, Zhenhong</dc:creator>
 <dc:creator>Zhang, Xinyu</dc:creator>
 <dc:creator>Liu, Huaping</dc:creator>
 <dc:creator>Li, Zhiwei</dc:creator>
 <dc:creator>Hussain, Amir</dc:creator>
 <dc:creator>Li, Jun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  There has recently been growing interest in utilizing multimodal sensors to
achieve robust lane line segmentation. In this paper, we introduce a novel
multimodal fusion architecture from an information theory perspective, and
demonstrate its practical utility using Light Detection and Ranging (LiDAR)
camera fusion networks. In particular, we develop, for the first time, a
multimodal fusion network as a joint coding model, where each single node,
layer, and pipeline is represented as a channel. The forward propagation is
thus equal to the information transmission in the channels. Then, we can
qualitatively and quantitatively analyze the effect of different fusion
approaches. We argue the optimal fusion architecture is related to the
essential capacity and its allocation based on the source and channel. To test
this multimodal fusion hypothesis, we progressively determine a series of
multimodal models based on the proposed fusion methods and evaluate them on the
KITTI and the A2D2 datasets. Our optimal fusion network achieves 85%+ lane line
accuracy and 98.7%+ overall. The performance gap among the models will inform
continuing future research into development of optimal fusion algorithms for
the deep multimodal learning community.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11118</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Keywords Guided Method Name Generation</dc:title>
 <dc:creator>Ge, Fan</dc:creator>
 <dc:creator>Kuang, Li</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  High quality method names are descriptive and readable, which are helpful for
code development and maintenance. The majority of recent research suggest
method names based on the text summarization approach. They take the token
sequence and abstract syntax tree of the source code as input, and generate
method names through a powerful neural network based model. However, the tokens
composing the method name are closely related to the entity name within its
method implementation. Actually, high proportions of the tokens in method name
can be found in its corresponding method implementation, which makes it
possible for incorporating these common shared token information to improve the
performance of method naming task. Inspired by this key observation, we propose
a two-stage keywords guided method name generation approach to suggest method
names. Specifically, we decompose the method naming task into two subtasks,
including keywords extraction task and method name generation task. For the
keywords extraction task, we apply a graph neural network based model to
extract the keywords from source code. For the method name generation task, we
utilize the extracted keywords to guide the method name generation model. We
apply a dual selective gate in encoder to control the information flow, and a
dual attention mechanism in decoder to combine the semantics of input code
sequence and keywords. Experiment results on an open source dataset demonstrate
that keywords guidance can facilitate method naming task, which enables our
model to outperform the competitive state-of-the-art models by margins of
1.5\%-3.5\% in ROUGE metrics. Especially when programs share one common token
with method names, our approach improves the absolute ROUGE-1 score by 7.8\%.
</dc:description>
 <dc:description>Comment: Research paper accepted at ICPC 2021 (29th IEEE/ACM International
  Conference on Program Comprehension)</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11118</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11119</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Feature Fusion Network for Gaze Tracking in Mobile Tablets</dc:title>
 <dc:creator>Bao, Yiwei</dc:creator>
 <dc:creator>Cheng, Yihua</dc:creator>
 <dc:creator>Liu, Yunfei</dc:creator>
 <dc:creator>Lu, Feng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, many multi-stream gaze estimation methods have been proposed. They
estimate gaze from eye and face appearances and achieve reasonable accuracy.
However, most of the methods simply concatenate the features extracted from eye
and face appearance. The feature fusion process has been ignored. In this
paper, we propose a novel Adaptive Feature Fusion Network (AFF-Net), which
performs gaze tracking task in mobile tablets. We stack two-eye feature maps
and utilize Squeeze-and-Excitation layers to adaptively fuse two-eye features
according to their similarity on appearance. Meanwhile, we also propose
Adaptive Group Normalization to recalibrate eye features with the guidance of
facial feature. Extensive experiments on both GazeCapture and MPIIFaceGaze
datasets demonstrate consistently superior performance of the proposed method.
</dc:description>
 <dc:description>Comment: Accepted at International Conference on Pattern Recognition 2020
  (ICPR)</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11119</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11122</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model-based Learning Network for 3-D Localization in mmWave
  Communications</dc:title>
 <dc:creator>Yang, Jie</dc:creator>
 <dc:creator>Jin, Shi</dc:creator>
 <dc:creator>Wen, Chao-Kai</dc:creator>
 <dc:creator>Guo, Jiajia</dc:creator>
 <dc:creator>Matthaiou, Michail</dc:creator>
 <dc:creator>Gao, Bo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  This study considers the joint location and velocity estimation of UE and
scatterers in a three-dimensional mmWave CRAN architecture. Several existing
works have achieved satisfactory results with neural networks (NNs) for
localization. However, the black box NN localization method has limited
performance and relies on a prohibitive amount of training data. Thus, we
propose a model-based learning network for localization by combining NNs with
geometric models. Specifically, we first develop an unbiased WLS estimator by
utilizing hybrid delay/angular measurements, which determine the location and
velocity of the UE in only one estimator, and can obtain the location and
velocity of scatterers further. The proposed estimator can achieve the CRLB and
outperforms state-of-the-art methods. Second, we establish a NN-assisted
localization method (NN-WLS) by replacing the linear approximations in the
proposed WLS localization model with NNs to learn higher-order error
components, thereby enhancing the performance of the estimator. The solution
possesses the powerful learning ability of the NN and the robustness of the
proposed geometric model. Moreover, the ensemble learning is applied to improve
the localization accuracy further. Comprehensive simulations show that the
proposed NN-WLS is superior to the benchmark methods in terms of localization
accuracy, robustness, and required time resources.
</dc:description>
 <dc:description>Comment: Paper accepted for publication in IEEE Transactions on Wireless
  Communications. arXiv admin note: text overlap with arXiv:1908.04142</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11136</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comprehensive Analysis of Continuously Variable Series Reactor Using G-C
  Framework</dc:title>
 <dc:creator>Hayerikhiyavi, Mohammadali</dc:creator>
 <dc:creator>Dimitrovski, Aleksandar</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Continuously Variable Series Reactor (CVSR) has the ability to regulate the
reactance of an ac circuit using the magnetizing characteristics of its
ferromagnetic core, shared by an ac and a dc winding to control power flow,
damp oscillations and limit fault currents. In order to understand and utilize
a CVSR in the power grid, it is essential to know all of its operational
characteristics. The gyrator-capacitor approach has been applied to model
electromagnetic coupling between the two circuits, controlled ac circuit and
control dc circuit of the device. In this paper, we investigate some of the
CVSR side behavior in terms of the induced voltage across the dc winding, flux
density within the core's branches, and the power exchange between the two
circuits during normal operation and fault conditions.
</dc:description>
 <dc:description>Comment: IEEE PES General Meeting 2021</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11137</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PathEnum: Towards Real-Time Hop-Constrained s-t Path Enumeration</dc:title>
 <dc:creator>Sun, Shixuan</dc:creator>
 <dc:creator>Chen, Yuhang</dc:creator>
 <dc:creator>He, Bingsheng</dc:creator>
 <dc:creator>Hooi, Bryan</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  We study the hop-constrained s-t path enumeration (HcPE) problem, which takes
a graph $G$, two distinct vertices $s,t$ and a hop constraint $k$ as input, and
outputs all paths from $s$ to $t$ whose length is at most $k$. The
state-of-the-art algorithms suffer from severe performance issues caused by the
costly pruning operations during enumeration for the workloads with the large
search space. Consequently, these algorithms hardly meet the real-time
constraints of many online applications. In this paper, we propose PathEnum, an
efficient index-based algorithm towards real-time HcPE. For an input query,
PathEnum first builds a light-weight index aiming to reduce the number of edges
involved in the enumeration, and develops efficient index-based approaches for
enumeration, one based on depth-first search and the other based on joins. We
further develop a query optimizer based on a join-based cost model to optimize
the search order. We conduct experiments with 15 real-world graphs. Our
experiment results show that PathEnum outperforms the state-of-the-art
approaches by orders of magnitude in terms of the query time, throughput and
response time.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11137</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11151</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Interplay of Task Success and Dialogue Quality: An in-depth
  Evaluation in Task-Oriented Visual Dialogues</dc:title>
 <dc:creator>Testoni, Alberto</dc:creator>
 <dc:creator>Bernardi, Raffaella</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  When training a model on referential dialogue guessing games, the best model
is usually chosen based on its task success. We show that in the popular
end-to-end approach, this choice prevents the model from learning to generate
linguistically richer dialogues, since the acquisition of language proficiency
takes longer than learning the guessing task. By comparing models playing
different games (GuessWhat, GuessWhich, and Mutual Friends), we show that this
discrepancy is model- and task-agnostic. We investigate whether and when better
language quality could lead to higher task success. We show that in GuessWhat,
models could increase their accuracy if they learn to ground, encode, and
decode also words that do not occur frequently in the training set.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11155</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recognizing Predictive Substructures with Subgraph Information
  Bottleneck</dc:title>
 <dc:creator>Yu, Junchi</dc:creator>
 <dc:creator>Xu, Tingyang</dc:creator>
 <dc:creator>Rong, Yu</dc:creator>
 <dc:creator>Bian, Yatao</dc:creator>
 <dc:creator>Huang, Junzhou</dc:creator>
 <dc:creator>He, Ran</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The emergence of Graph Convolutional Network (GCN) has greatly boosted the
progress of graph learning. However, two disturbing factors, noise and
redundancy in graph data, and lack of interpretation for prediction results,
impede further development of GCN. One solution is to recognize a predictive
yet compressed subgraph to get rid of the noise and redundancy and obtain the
interpretable part of the graph. This setting of subgraph is similar to the
information bottleneck (IB) principle, which is less studied on
graph-structured data and GCN. Inspired by the IB principle, we propose a novel
subgraph information bottleneck (SIB) framework to recognize such subgraphs,
named IB-subgraph. However, the intractability of mutual information and the
discrete nature of graph data makes the objective of SIB notoriously hard to
optimize. To this end, we introduce a bilevel optimization scheme coupled with
a mutual information estimator for irregular graphs. Moreover, we propose a
continuous relaxation for subgraph selection with a connectivity loss for
stabilization. We further theoretically prove the error bound of our estimation
scheme for mutual information and the noise-invariant nature of IB-subgraph.
Extensive experiments on graph learning and large-scale point cloud tasks
demonstrate the superior property of IB-subgraph.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:2010.05563</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11155</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11165</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RIS Configuration, Beamformer Design, and Power Control in Single-Cell
  and Multi-Cell Wireless Networks</dc:title>
 <dc:creator>Buzzi, Stefano</dc:creator>
 <dc:creator>D'Andrea, Carmen</dc:creator>
 <dc:creator>Zappone, Alessio</dc:creator>
 <dc:creator>Fresia, Maria</dc:creator>
 <dc:creator>Zhang, Yong-Ping</dc:creator>
 <dc:creator>Feng, Shulan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  Reconfigurable Intelligent Surfaces (RISs) are recently attracting a wide
interest due to their capability of tuning wireless propagation environments in
order to increase the system performance of wireless networks. In this paper, a
multiuser wireless network assisted by a RIS is studied and resource allocation
algorithms are presented for several scenarios. First of all, the problem of
channel estimation is considered, and an algorithm that permits separate
estimation of the mobile user-to-RIS and RIS-to-base stations components is
proposed. Then, for the special case of a single-user system, three possible
approaches are shown in order to optimize the Signal-to-Noise Ratio with
respect to the beamformer used at the base station and to the RIS phase shifts.
Next, for a multiuser system with two cells, assuming channel-matched
beamforming, the geometric mean of the downlink Signal-to-Interference plus
Noise Ratios across users is maximized with respect to the base stations
transmit powers and RIS phase shifts configurations. In this scenario, the RIS
is placed at the cell-edge and some users are jointly served by two base
stations to increase the system performance. Numerical results show that the
proposed procedures are effective and that the RIS brings substantial
performance improvements to wireless system.
</dc:description>
 <dc:description>Comment: Accepted for publication on the IEEE Transactions on Cognitive
  Communications and Networking, special issue on &quot;Intelligent Surfaces for
  Smart Wireless Communications&quot;. arXiv admin note: text overlap with
  arXiv:2004.08944</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11165</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11167</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-sequence Spreading Random Access (MSRA) for Compressive
  Sensing-based Grant-free Communication</dc:title>
 <dc:creator>Abebe, Ameha Tsegaye</dc:creator>
 <dc:creator>Kang, Chung G.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The performance of grant-free random access (GF-RA) is limited by the number
of accessible random access resources (RRs) due to the absence of collision
resolution. Compressive sensing (CS)-based RA schemes scale up the RRs at the
expense of increased non-orthogonality among transmitted signals. This paper
presents the design of multi-sequence spreading random access (MSRA) which
employs multiple spreading sequences to spread the different symbols of a user
as opposed to the conventional schemes in which a user employs the same
spreading sequence for each symbol. We show that MSRA provides code diversity,
enabling the multi-user detection (MUD) to be modeled into a well-conditioned
multiple measurement vector (MMV) CS problem. The code diversity is quantified
by the decrease in the average Babel mutual coherence among the spreading
sequences. Moreover, we present a two-stage active user detection (AUD) scheme
for both wideband and narrowband implementation. Our theoretical analysis shows
that with MSRA activity misdetection falls exponentially while the size of
GF-RA frame is increased. Finally, the simulation results show that about 82%
increase in utilization of RRs, i.e., more active users, is supported by MSRA
than the conventional schemes while achieving the RA failure rate lower bound
set by random access collision.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11167</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11168</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Continuous Cost-to-Go Functions for Non-holonomic Systems</dc:title>
 <dc:creator>Huh, Jinwook</dc:creator>
 <dc:creator>Lee, Daniel D.</dc:creator>
 <dc:creator>Isler, Volkan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  This paper presents a supervised learning method to generate continuous
cost-to-go functions of non-holonomic systems directly from the workspace
description. Supervision from informative examples reduces training time and
improves network performance. The manifold representing the optimal
trajectories of a non-holonomic system has high-curvature regions which can not
be efficiently captured with uniform sampling. To address this challenge, we
present an adaptive sampling method which makes use of sampling-based planners
along with local, closed-form solutions to generate training samples. The
cost-to-go function over a specific workspace is represented as a neural
network whose weights are generated by a second, higher order network. The
networks are trained in an end-to-end fashion. In our previous work, this
architecture was shown to successfully learn to generate the cost-to-go
functions of holonomic systems using uniform sampling. In this work, we show
that uniform sampling fails for non-holonomic systems. However, with the
proposed adaptive sampling methodology, our network can generate near-optimal
trajectories for non-holonomic systems while avoiding obstacles. Experiments
show that our method is two orders of magnitude faster compared to traditional
approaches in cluttered environments.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11169</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Your Classifier can Secretly Suffice Multi-Source Domain Adaptation</dc:title>
 <dc:creator>Venkat, Naveen</dc:creator>
 <dc:creator>Kundu, Jogendra Nath</dc:creator>
 <dc:creator>Singh, Durgesh Kumar</dc:creator>
 <dc:creator>Revanur, Ambareesh</dc:creator>
 <dc:creator>Babu, R. Venkatesh</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Multi-Source Domain Adaptation (MSDA) deals with the transfer of task
knowledge from multiple labeled source domains to an unlabeled target domain,
under a domain-shift. Existing methods aim to minimize this domain-shift using
auxiliary distribution alignment objectives. In this work, we present a
different perspective to MSDA wherein deep models are observed to implicitly
align the domains under label supervision. Thus, we aim to utilize implicit
alignment without additional training objectives to perform adaptation. To this
end, we use pseudo-labeled target samples and enforce a classifier agreement on
the pseudo-labels, a process called Self-supervised Implicit Alignment
(SImpAl). We find that SImpAl readily works even under category-shift among the
source domains. Further, we propose classifier agreement as a cue to determine
the training convergence, resulting in a simple training algorithm. We provide
a thorough evaluation of our approach on five benchmarks, along with detailed
insights into each component of our approach.
</dc:description>
 <dc:description>Comment: NeurIPS 2020. Project page: https://sites.google.com/view/simpal</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11174</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonterminal complexity of some families of infinite regular languages</dc:title>
 <dc:creator>Golubenko, Dmitry</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  Nonterminal complexity of a context-free language is the smallest possible
number of nonterminals in its generating grammar. While in general case
nonterminal complexity computation problem is unsolvable, it can be computed
for different families of regular languages. In this paper we study nonterminal
complexity of some families of infinite regular languages.
</dc:description>
 <dc:description>Comment: (to be revisited later)</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11175</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NCoRE: Neural Counterfactual Representation Learning for Combinations of
  Treatments</dc:title>
 <dc:creator>Parbhoo, Sonali</dc:creator>
 <dc:creator>Bauer, Stefan</dc:creator>
 <dc:creator>Schwab, Patrick</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Estimating an individual's potential response to interventions from
observational data is of high practical relevance for many domains, such as
healthcare, public policy or economics. In this setting, it is often the case
that combinations of interventions may be applied simultaneously, for example,
multiple prescriptions in healthcare or different fiscal and monetary measures
in economics. However, existing methods for counterfactual inference are
limited to settings in which actions are not used simultaneously. Here, we
present Neural Counterfactual Relation Estimation (NCoRE), a new method for
learning counterfactual representations in the combination treatment setting
that explicitly models cross-treatment interactions. NCoRE is based on a novel
branched conditional neural representation that includes learnt treatment
interaction modulators to infer the potential causal generative process
underlying the combination of multiple treatments. Our experiments show that
NCoRE significantly outperforms existing state-of-the-art methods for
counterfactual treatment effect estimation that do not account for the effects
of combining multiple treatments across several synthetic, semi-synthetic and
real-world benchmarks.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11175</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11177</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Deep Neural Network Surrogate Modeling Benchmark for Temperature Field
  Prediction of Heat Source Layout</dc:title>
 <dc:creator>Chen, Xianqi</dc:creator>
 <dc:creator>Zhao, Xiaoyu</dc:creator>
 <dc:creator>Gong, Zhiqiang</dc:creator>
 <dc:creator>Zhang, Jun</dc:creator>
 <dc:creator>Zhou, Weien</dc:creator>
 <dc:creator>Chen, Xiaoqian</dc:creator>
 <dc:creator>Yao, Wen</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Thermal issue is of great importance during layout design of heat source
components in systems engineering, especially for high functional-density
products. Thermal analysis generally needs complex simulation, which leads to
an unaffordable computational burden to layout optimization as it iteratively
evaluates different schemes. Surrogate modeling is an effective way to
alleviate computation complexity. However, temperature field prediction (TFP)
with complex heat source layout (HSL) input is an ultra-high dimensional
nonlinear regression problem, which brings great difficulty to traditional
regression models. The Deep neural network (DNN) regression method is a
feasible way for its good approximation performance. However, it faces great
challenges in both data preparation for sample diversity and uniformity in the
layout space with physical constraints, and proper DNN model selection and
training for good generality, which necessitates efforts of both layout
designer and DNN experts. To advance this cross-domain research, this paper
proposes a DNN based HSL-TFP surrogate modeling task benchmark. With
consideration for engineering applicability, sample generation, dataset
evaluation, DNN model, and surrogate performance metrics, are thoroughly
studied. Experiments are conducted with ten representative state-of-the-art DNN
models. Detailed discussion on baseline results is provided and future
prospects are analyzed for DNN based HSL-TFP tasks.
</dc:description>
 <dc:description>Comment: 31 pages, 25 figures</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11177</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11182</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Performance Bounds for Randomized Sensor Selection in
  Kalman Filtering</dc:title>
 <dc:creator>Calle, Christopher I.</dc:creator>
 <dc:creator>Bopardikar, Shaunak D.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We consider the problem of randomly choosing the sensors of a linear
time-invariant dynamical system subject to process and measurement noise. We
sample the sensors independently and from the same distribution. We measure the
performance of a Kalman filter by its estimation error covariance. Using tools
from random matrix theory, we derive probabilistic bounds on the estimation
error covariance in the semi-definite sense. We indirectly improve the
performance of our Kalman filter for the maximum eigenvalue metric and show
that under certain conditions the optimal sampling distribution that minimizes
the maximum eigenvalue of the upper bound is the solution to an appropriately
defined convex optimization problem. Our numerical results show the efficacy of
the optimal sampling scheme in improving Kalman filter performance relative to
the trivial uniform sampling distribution and a greedy sampling $\textit{with
replacement}$ algorithm.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11182</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11186</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3M: Multi-style image caption generation using Multi-modality features
  under Multi-UPDOWN model</dc:title>
 <dc:creator>Li, Chengxi</dc:creator>
 <dc:creator>Harrison, Brent</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we build a multi-style generative model for stylish image
captioning which uses multi-modality image features, ResNeXt features and text
features generated by DenseCap. We propose the 3M model, a Multi-UPDOWN caption
model that encodes multi-modality features and decode them to captions. We
demonstrate the effectiveness of our model on generating human-like captions by
examining its performance on two datasets, the PERSONALITY-CAPTIONS dataset and
the FlickrStyle10K dataset. We compare against a variety of state-of-the-art
baselines on various automatic NLP metrics such as BLEU, ROUGE-L, CIDEr, SPICE,
etc. A qualitative study has also been done to verify our 3M model can be used
for generating different stylized captions.
</dc:description>
 <dc:description>Comment: To be published at FLAIRS-34</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11187</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tubu-io Decentralized Application Development &amp; Test Workbench</dc:title>
 <dc:creator>I&#x15f;&#x131;k, Ercan</dc:creator>
 <dc:creator>Birim, Melih</dc:creator>
 <dc:creator>Karaarslan, Enis</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Decentralized services are increasingly being developed and their proper
usage in different areas is being experimented with. Autonomous codes, which
are also called smart contracts, can be developed with Integrated Development
Environments (IDE). However, these tools lack live environment tests. The
underlying blockchain technologies are also evolving and it is not easy to
catch all the developments. There is a need for an easy-to-use interface by
which the developers can see the results of their codes. Tubu-io decentralized
application development workbench is developed to serve as an efficient way for
the programmers to deploy smart contracts on the blockchain networks and
interact with them easily. It can also be used for teaching decentralized
application programming for junior blockchain developers on blockchain
testbeds. Finally, it will have an effect in decreasing the development time
and the costs of developing decentralized application projects.
</dc:description>
 <dc:description>Comment: 3 pages, 4 figures</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11187</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11188</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attaining Sudan's decoding radius with no genus penalty for algebraic
  geometry codes</dc:title>
 <dc:creator>Panaccione, Isabella</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:description>  In this paper we present a decoding algorithm for algebraic geometry codes
with error-correcting capacity beyond half the designed distance of the code.
This algorithm comes as a fusion of the Power Error Locating Pairs algorithm
for algebraic geometry codes and the technique used by Ehrhard in order to
correct these codes up to half the designed distance. The decoding radius of
this algorithm reaches that of Sudan algorithm, without any penalty given by
the genus of the curve.
</dc:description>
 <dc:description>Comment: Typo in the title corrected</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11189</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Effectiveness of Morphology-aware Segmentation in Low-Resource
  Neural Machine Translation</dc:title>
 <dc:creator>S&#xe4;lev&#xe4;, Jonne</dc:creator>
 <dc:creator>Lignos, Constantine</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper evaluates the performance of several modern subword segmentation
methods in a low-resource neural machine translation setting. We compare
segmentations produced by applying BPE at the token or sentence level with
morphologically-based segmentations from LMVR and MORSEL. We evaluate
translation tasks between English and each of Nepali, Sinhala, and Kazakh, and
predict that using morphologically-based segmentation methods would lead to
better performance in this setting. However, comparing to BPE, we find that no
consistent and reliable differences emerge between the segmentation methods.
While morphologically-based methods outperform BPE in a few cases, what
performs best tends to vary across tasks, and the performance of segmentation
methods is often statistically indistinguishable.
</dc:description>
 <dc:description>Comment: EACL 2021 Student Research Workshop</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11191</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FEniCS-preCICE: Coupling FEniCS to other Simulation Software</dc:title>
 <dc:creator>Rodenberg, Benjamin</dc:creator>
 <dc:creator>Desai, Ishaan</dc:creator>
 <dc:creator>Hertrich, Richard</dc:creator>
 <dc:creator>Jaust, Alexander</dc:creator>
 <dc:creator>Uekermann, Benjamin</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  The new software FEniCS-preCICE is a middle software layer, sitting in
between the existing finite-element library FEniCS and the coupling library
preCICE. The middle layer simplifies coupling (existing) FEniCS application
codes to other simulation software via preCICE. To this end, FEniCS-preCICE
converts between FEniCS and preCICE mesh and data structures, provides
easy-to-use coupling conditions, and manages data checkpointing for implicit
coupling. The new software is a library itself and follows a FEniCS-native
style. Only a few lines of additional code are necessary to prepare a FEniCS
application code for coupling. We illustrate the functionality of
FEniCS-preCICE by two examples: a FEniCS heat conduction code coupled to
OpenFOAM and a FEniCS linear elasticity code coupled to SU2. The results of
both scenarios are compared with other simulation software showing good
agreement.
</dc:description>
 <dc:description>Comment: submitted to SoftwareX, fixed layout of Fig. 3 &amp; 4, updated reference
  to code examples to https://github.com/precice/tutorials/tree/a166efa</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11192</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Software Engineering for IoT-Driven Data Analytics Applications</dc:title>
 <dc:creator>Ahmad, Aakash</dc:creator>
 <dc:creator>Fahmideh, Mahdi</dc:creator>
 <dc:creator>Altamimi, Ahmed B.</dc:creator>
 <dc:creator>Katib, Iyad</dc:creator>
 <dc:creator>Albeshri, Aiiad</dc:creator>
 <dc:creator>Alreshidi, Abdulrahman</dc:creator>
 <dc:creator>Alanazi, Adwan</dc:creator>
 <dc:creator>Mehmood, Rashid</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Internet of Things Driven Data Analytics (IoT-DA) has the potential to excel
data-driven operationalisation of smart environments. However, limited research
exists on how IoT-DA applications are designed, implemented, operationalised,
and evolved in the context of software and system engineering life-cycle. This
article empirically derives a framework that could be used to systematically
investigate the role of software engineering (SE) processes and their
underlying practices to engineer IoT-DA applications. First, using existing
frameworks and taxonomies, we develop an evaluation framework to evaluate
software processes, methods, and other artefacts of SE for IoT-DA. Secondly, we
perform a systematic mapping study to qualitatively select 16 processes (from
academic research and industrial solutions) of SE for IoT-DA. Thirdly, we apply
our developed evaluation framework based on 17 distinct criterion (a.k.a.
process activities) for fine-grained investigation of each of the 16 SE
processes. Fourthly, we apply our proposed framework on a case study to
demonstrate development of an IoT-DA healthcare application. Finally, we
highlight key challenges, recommended practices, and the lessons learnt based
on framework's support for process-centric software engineering of IoT-DA. The
results of this research can facilitate researchers and practitioners to
engineer emerging and next-generation of IoT-DA software applications.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11192</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11204</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Supervised Steering Angle Prediction for Vehicle Control Using
  Visual Odometry</dc:title>
 <dc:creator>Khan, Qadeer</dc:creator>
 <dc:creator>Wenzel, Patrick</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Vision-based learning methods for self-driving cars have primarily used
supervised approaches that require a large number of labels for training.
However, those labels are usually difficult and expensive to obtain. In this
paper, we demonstrate how a model can be trained to control a vehicle's
trajectory using camera poses estimated through visual odometry methods in an
entirely self-supervised fashion. We propose a scalable framework that
leverages trajectory information from several different runs using a camera
setup placed at the front of a car. Experimental results on the CARLA simulator
demonstrate that our proposed approach performs at par with the model trained
with supervision.
</dc:description>
 <dc:description>Comment: Accepted at International Conference on Artificial Intelligence and
  Statistics (AISTATS), 2021</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11206</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Simulation of Quantum Secret Sharing</dc:title>
 <dc:creator>Sutradhar, Kartick</dc:creator>
 <dc:creator>Om, Hari</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  In quantum cryptography, quantum secret sharing $(QSS)$ is a fundamental
primitive. $QSS$ can be used to create complex and secure multiparty quantum
protocols. Existing $QSS$ protocols are either at the $(n, n)$ threshold $2$
level or at the $(t, n)$ threshold $d$ level with a trusted player, where $n$
denotes the number of players and $t$ denotes the threshold number of players.
Here, we propose a secure $d$-level $QSS$ protocol for sharing a secret with
efficient simulation. This protocol is more secure, flexible, and practical as
compared to the existing $QSS$ protocols: $(n, n)$ threshold $2$-level and
$(t,n)$ threshold $d$-level with a trusted player. Further, it does not
disclose any information about the secret to players. Its security analysis
shows that the intercept-resend, intercept, entangle-measure, forgery,
collision and collusion attacks are not possible in this protocol.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11210</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Global Optimization of Non-differentiable, Symmetric
  Objectives for Multi Camera Placement</dc:title>
 <dc:creator>H&#xe4;nel, Maria L.</dc:creator>
 <dc:creator>Sch&#xf6;nlieb, Carola-B.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>90-05, 90C26, 90C30, 90C56, 90C59</dc:subject>
 <dc:subject>I.4.8</dc:subject>
 <dc:subject>I.6</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>G.1.1</dc:subject>
 <dc:description>  We propose a novel iterative method for optimally placing and orienting
multiple cameras in a 3D scene. Sample applications include improving the
accuracy of 3D reconstruction, maximizing the covered area for surveillance, or
improving the coverage in multi-viewpoint pedestrian tracking. Our algorithm is
based on a block-coordinate ascent combined with a surrogate function and an
exclusion area technique. This allows to flexibly handle difficult objective
functions that are often expensive and quantized or non-differentiable. The
solver is globally convergent and easily parallelizable. We show how to
accelerate the optimization by exploiting special properties of the objective
function, such as symmetry. Additionally, we discuss the trade-off between
non-optimal stationary points and the cost reduction when optimizing the
viewpoints consecutively.
</dc:description>
 <dc:description>Comment: Submitted to be reviewed, 10 pages, 6 figures, 2 tables, 3 algorithms</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11210</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11211</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi Camera Placement via Z-buffer Rendering for the Optimization of
  the Coverage and the Visual Hull</dc:title>
 <dc:creator>H&#xe4;nel, Maria L.</dc:creator>
 <dc:creator>V&#xf6;lkel, Johannes</dc:creator>
 <dc:creator>Henrich, Dominik</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>65D19, 65D18, 68T45, 68T42, 90-05, 90C26, 90C30, 90C56</dc:subject>
 <dc:subject>I.4.8</dc:subject>
 <dc:subject>I.6.4</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>B.8.2</dc:subject>
 <dc:subject>J.7</dc:subject>
 <dc:description>  We can only allow human-robot-cooperation in a common work cell if the human
integrity is guaranteed. A surveillance system with multiple cameras can detect
collisions without contact to the human collaborator. A failure safe system
needs to optimally cover the important areas of the robot work cell with safety
overlap. We propose an efficient algorithm for optimally placing and orienting
the cameras in a 3D CAD model of the work cell. In order to evaluate the
quality of the camera constellation in each step, our method simulates the
vision system using a z-buffer rendering technique for image acquisition, a
voxel space for the overlap and a refined visual hull method for a conservative
human reconstruction. The simulation allows to evaluate the quality with
respect to the distortion of images and advanced image analysis in the presence
of static and dynamic visual obstacles such as tables, racks, walls, robots and
people. Our method is ideally suited for maximizing the coverage of multiple
cameras or minimizing an error made by the visual hull and can be extended to
probabilistic space carving.
</dc:description>
 <dc:description>Comment: 8 pages, 9 figures, not reviewed yet</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11214</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uncertainty Estimation in SARS-CoV-2 B-cell Epitope Prediction for
  Vaccine Development</dc:title>
 <dc:creator>Ghoshal, Bhargab</dc:creator>
 <dc:creator>Ghoshal, Biraja</dc:creator>
 <dc:creator>Swift, Stephen</dc:creator>
 <dc:creator>Tucker, Allan</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  B-cell epitopes play a key role in stimulating B-cells, triggering the
primary immune response which results in antibody production as well as the
establishment of long-term immunity in the form of memory cells. Consequently,
being able to accurately predict appropriate linear B-cell epitope regions
would pave the way for the development of new protein-based vaccines. Knowing
how much confidence there is in a prediction is also essential for gaining
clinicians' trust in the technology. In this article, we propose a calibrated
uncertainty estimation in deep learning to approximate variational Bayesian
inference using MC-DropWeights to predict epitope regions using the data from
the immune epitope database. Having applied this onto SARS-CoV-2, it can more
reliably predict B-cell epitopes than standard methods. This will be able to
identify safe and effective vaccine candidates against Covid-19.
</dc:description>
 <dc:description>Comment: Paper accepted for the 19th International Conference on Artificial
  Intelligence in Medicine</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11214</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11225</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Network Limits of Infectious Disease Control via Occupation-Based
  Targeting</dc:title>
 <dc:creator>Avraam, Demetris</dc:creator>
 <dc:creator>Obradovich, Nick</dc:creator>
 <dc:creator>Pescetelli, Niccol&#xf3;</dc:creator>
 <dc:creator>Cebrian, Manuel</dc:creator>
 <dc:creator>Rutherford, Alex</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Policymakers commonly employ non-pharmaceutical interventions to manage the
scale and severity of pandemics. Of non-pharmaceutical interventions, social
distancing policies -- designed to reduce person-to-person pathogenic spread --
have risen to recent prominence. In particular, stay-at-home policies of the
sort widely implemented around the globe in response to the COVID-19 pandemic
have proven to be markedly effective at slowing pandemic growth. However, such
blunt policy instruments, while effective, produce numerous unintended
consequences, including potentially dramatic reductions in economic
productivity. Here we develop methods to investigate the potential to
simultaneously contain pandemic spread while also minimizing economic
disruptions. We do so by incorporating both occupational and network
information contained within an urban environment, information that is commonly
excluded from typical pandemic control policy design. The results of our method
suggest that large gains in both economic productivity and pandemic control
might be had by the incorporation and consideration of simple-to-measure
characteristics of the occupational contact network. However we find evidence
that more sophisticated, and more privacy invasive, measures of this network do
not drastically increase performance.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11226</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Demystifying the Effects of Non-Independence in Federated Learning</dc:title>
 <dc:creator>Arnold, Stefan</dc:creator>
 <dc:creator>Yesilbas, Dilara</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Federated Learning (FL) enables statistical models to be built on
user-generated data without compromising data security and user privacy. For
this reason, FL is well suited for on-device learning from mobile devices where
data is abundant and highly privatized. Constrained by the temporal
availability of mobile devices, only a subset of devices is accessible to
participate in the iterative protocol consisting of training and aggregation.
In this study, we take a step toward better understanding the effect of
non-independent data distributions arising from block-cyclic sampling. By
conducting extensive experiments on visual classification, we measure the
effects of block-cyclic sampling (both standalone and in combination with
non-balanced block distributions). Specifically, we measure the alterations
induced by block-cyclic sampling from the perspective of accuracy, fairness,
and convergence rate. Experimental results indicate robustness to cycling over
a two-block structure, e.g., due to time zones. In contrast, drawing data
samples dependently from a multi-block structure significantly degrades the
performance and rate of convergence by up to 26%. Moreover, we find that this
performance degeneration is further aggravated by unbalanced block
distributions to a point that can no longer be adequately compensated by higher
communication and more frequent synchronization.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11238</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Markov Modeling of Time-Series Data using Symbolic Analysis</dc:title>
 <dc:creator>Jha, Devesh K.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Markov models are often used to capture the temporal patterns of sequential
data for statistical learning applications. While the Hidden Markov
modeling-based learning mechanisms are well studied in literature, we analyze a
symbolic-dynamics inspired approach. Under this umbrella, Markov modeling of
time-series data consists of two major steps -- discretization of continuous
attributes followed by estimating the size of temporal memory of the
discretized sequence. These two steps are critical for the accurate and concise
representation of time-series data in the discrete space. Discretization
governs the information content of the resultant discretized sequence. On the
other hand, memory estimation of the symbolic sequence helps to extract the
predictive patterns in the discretized data. Clearly, the effectiveness of
signal representation as a discrete Markov process depends on both these steps.
In this paper, we will review the different techniques for discretization and
memory estimation for discrete stochastic processes. In particular, we will
focus on the individual problems of discretization and order estimation for
discrete stochastic process. We will present some results from literature on
partitioning from dynamical systems theory and order estimation using concepts
of information theory and statistical learning. The paper also presents some
related problem formulations which will be useful for machine learning and
statistical learning application using the symbolic framework of data analysis.
We present some results of statistical analysis of a complex thermoacoustic
instability phenomenon during lean-premixed combustion in jet-turbine engines
using the proposed Markov modeling method.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11238</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11239</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Control and Simulation of a Grid-Forming Inverter for Hybrid PV-Battery
  Plants in Power System Black Start</dc:title>
 <dc:creator>Nguyen, Quan</dc:creator>
 <dc:creator>Vallem, Mallikarjuna R.</dc:creator>
 <dc:creator>Vyakaranam, Bharat</dc:creator>
 <dc:creator>Tbaileh, Ahmad</dc:creator>
 <dc:creator>Ke, Xinda</dc:creator>
 <dc:creator>Samaan, Nader</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Power system restoration is an important part of system planning. Power
utilities are required to maintain black start capable generators that can
energize the transmission system and provide cranking power to non-blackstart
capable generators. Traditionally, hydro and diesel units are used as black
start capable generators. With the increased penetration of bulk size solar
farms, inverter based generation can play an important role in faster and
parallel black start thus ensuring system can be brought back into service
without the conventional delays that can be expected with limited black start
generators. Inverter-based photovoltaic (PV) power plants have advantages that
are suitable for black start. This paper proposes the modeling, control, and
simulation of a grid-forming inverter-based PV-battery power plant that can be
used as a black start unit. The inverter control includes both primary and
secondary control loops to imitate the control of a conventional synchronous
machine. The proposed approach is verified using a test system modified from
the IEEE 9-bus system in the time-domain electromagnetic transient simulation
tool PSCAD. The simulation results shows voltage and frequency stability during
a multi-step black-start and network energization process.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11239</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11249</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SELM: Software Engineering of Machine Learning Models</dc:title>
 <dc:creator>Jafari, Nafiseh</dc:creator>
 <dc:creator>Besharati, Mohammad Reza</dc:creator>
 <dc:creator>Izadi, Mohammad</dc:creator>
 <dc:creator>Hourali, Maryam</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  One of the pillars of any machine learning model is its concepts. Using
software engineering, we can engineer these concepts and then develop and
expand them. In this article, we present a SELM framework for Software
Engineering of machine Learning Models. We then evaluate this framework through
a case study. Using the SELM framework, we can improve a machine learning
process efficiency and provide more accuracy in learning with less processing
hardware resources and a smaller training dataset. This issue highlights the
importance of an interdisciplinary approach to machine learning. Therefore, in
this article, we have provided interdisciplinary teams' proposals for machine
learning.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11254</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Heart-Failure Patients EHR Clinical Features via SHAP
  Interpretation of Tree-Based Machine Learning Model Predictions</dc:title>
 <dc:creator>Lu, Shuyu</dc:creator>
 <dc:creator>Chen, Ruoyu</dc:creator>
 <dc:creator>Wei, Wei</dc:creator>
 <dc:creator>Lu, Xinghua</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Heart failure (HF) is a major cause of mortality. Accurately monitoring HF
progress and adjust therapies are critical for improving patient outcomes. An
experienced cardiologist can make accurate HF stage diagnoses based on
combination of symptoms, signs, and lab results from the electronic health
records (EHR) of a patient, without directly measuring heart function. We
examined whether machine learning models, more specifically the XGBoost model,
can accurately predict patient stage based on EHR, and we further applied the
SHapley Additive exPlanations (SHAP) framework to identify informative features
and their interpretations. Our results indicate that based on structured data
from EHR, our models could predict patients' ejection fraction (EF) scores with
moderate accuracy. SHAP analyses identified informative features and revealed
potential clinical subtypes of HF. Our findings provide insights on how to
design computing systems to accurately monitor disease progression of HF
patients through continuously mining patients' EHR data.
</dc:description>
 <dc:description>Comment: Submitted to AMIA 2021 Annual Symposium</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11254</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11263</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Supervised Test-Time Learning for Reading Comprehension</dc:title>
 <dc:creator>Banerjee, Pratyay</dc:creator>
 <dc:creator>Gokhale, Tejas</dc:creator>
 <dc:creator>Baral, Chitta</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Recent work on unsupervised question answering has shown that models can be
trained with procedurally generated question-answer pairs and can achieve
performance competitive with supervised methods. In this work, we consider the
task of unsupervised reading comprehension and present a method that performs
&quot;test-time learning&quot; (TTL) on a given context (text passage), without requiring
training on large-scale human-authored datasets containing
\textit{context-question-answer} triplets. This method operates directly on a
single test context, uses self-supervision to train models on synthetically
generated question-answer pairs, and then infers answers to unseen
human-authored questions for this context. Our method achieves accuracies
competitive with fully supervised methods and significantly outperforms current
unsupervised methods. TTL methods with a smaller model are also competitive
with the current state-of-the-art in unsupervised reading comprehension.
</dc:description>
 <dc:description>Comment: Accepted to NAACL 2021</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11263</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11264</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporally-Weighted Hierarchical Clustering for Unsupervised Action
  Segmentation</dc:title>
 <dc:creator>Sarfraz, M. Saquib</dc:creator>
 <dc:creator>Murray, Naila</dc:creator>
 <dc:creator>Sharma, Vivek</dc:creator>
 <dc:creator>Diba, Ali</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:creator>Stiefelhagen, Rainer</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Action segmentation refers to inferring boundaries of semantically consistent
visual concepts in videos and is an important requirement for many video
understanding tasks. For this and other video understanding tasks, supervised
approaches have achieved encouraging performance but require a high volume of
detailed frame-level annotations. We present a fully automatic and unsupervised
approach for segmenting actions in a video that does not require any training.
Our proposal is an effective temporally-weighted hierarchical clustering
algorithm that can group semantically consistent frames of the video. Our main
finding is that representing a video with a 1-nearest neighbor graph by taking
into account the time progression is sufficient to form semantically and
temporally consistent clusters of frames where each cluster may represent some
action in the video. Additionally, we establish strong unsupervised baselines
for action segmentation and show significant performance improvements over
published unsupervised methods on five challenging action segmentation
datasets. Our code is available at
https://github.com/ssarfraz/FINCH-Clustering/tree/master/TW-FINCH
</dc:description>
 <dc:description>Comment: CVPR 2021</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11264</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11265</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Distributional Policy Gradients</dc:title>
 <dc:creator>Li, Luchen</dc:creator>
 <dc:creator>Faisal, A. Aldo</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Distributional Reinforcement Learning (RL) maintains the entire probability
distribution of the reward-to-go, i.e. the return, providing more learning
signals that account for the uncertainty associated with policy performance,
which may be beneficial for trading off exploration and exploitation and policy
learning in general. Previous works in distributional RL focused mainly on
computing the state-action-return distributions, here we model the state-return
distributions. This enables us to translate successful conventional RL
algorithms that are based on state values into distributional RL. We formulate
the distributional Bellman operation as an inference-based auto-encoding
process that minimises Wasserstein metrics between target/model return
distributions. The proposed algorithm, BDPG (Bayesian Distributional Policy
Gradients), uses adversarial training in joint-contrastive learning to estimate
a variational posterior from the returns. Moreover, we can now interpret the
return prediction uncertainty as an information gain, which allows to obtain a
new curiosity measure that helps BDPG steer exploration actively and
efficiently. We demonstrate in a suite of Atari 2600 games and MuJoCo tasks,
including well known hard-exploration challenges, how BDPG learns generally
faster and with higher asymptotic performance than reference distributional RL
algorithms.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11265</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11269</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Development and Validation of a Deep Learning Model for Prediction of
  Severe Outcomes in Suspected COVID-19 Infection</dc:title>
 <dc:creator>Buch, Varun</dc:creator>
 <dc:creator>Zhong, Aoxiao</dc:creator>
 <dc:creator>Li, Xiang</dc:creator>
 <dc:creator>Rockenbach, Marcio Aloisio Bezerra Cavalcanti</dc:creator>
 <dc:creator>Wu, Dufan</dc:creator>
 <dc:creator>Ren, Hui</dc:creator>
 <dc:creator>Guan, Jiahui</dc:creator>
 <dc:creator>Liteplo, Andrew</dc:creator>
 <dc:creator>Dutta, Sayon</dc:creator>
 <dc:creator>Dayan, Ittai</dc:creator>
 <dc:creator>Li, Quanzheng</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  COVID-19 patient triaging with predictive outcome of the patients upon first
present to emergency department (ED) is crucial for improving patient
prognosis, as well as better hospital resources management and cross-infection
control. We trained a deep feature fusion model to predict patient outcomes,
where the model inputs were EHR data including demographic information,
co-morbidities, vital signs and laboratory measurements, plus patient's CXR
images. The model output was patient outcomes defined as the most insensitive
oxygen therapy required. For patients without CXR images, we employed Random
Forest method for the prediction. Predictive risk scores for COVID-19 severe
outcomes (&quot;CO-RISK&quot; score) were derived from model output and evaluated on the
testing dataset, as well as compared to human performance. The study's dataset
(the &quot;MGB COVID Cohort&quot;) was constructed from all patients presenting to the
Mass General Brigham (MGB) healthcare system from March 1st to June 1st, 2020.
ED visits with incomplete or erroneous data were excluded. Patients with no
test order for COVID or confirmed negative test results were excluded. Patients
under the age of 15 were also excluded. Finally, electronic health record (EHR)
data from a total of 11060 COVID-19 confirmed or suspected patients were used
in this study. Chest X-ray (CXR) images were also collected from each patient
if available. Results show that CO-RISK score achieved area under the Curve
(AUC) of predicting MV/death (i.e. severe outcomes) in 24 hours of 0.95, and
0.92 in 72 hours on the testing dataset. The model shows superior performance
to the commonly used risk scores in ED (CURB-65 and MEWS). Comparing with
physician's decisions, CO-RISK score has demonstrated superior performance to
human in making ICU/floor decisions.
</dc:description>
 <dc:description>Comment: Varun Buch, Aoxiao Zhong and Xiang Li contribute equally to this work</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11269</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11271</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structural Textile Pattern Recognition and Processing Based on
  Hypergraphs</dc:title>
 <dc:creator>Ngo, Vuong M.</dc:creator>
 <dc:creator>Helmer, Sven</dc:creator>
 <dc:creator>Le-Khac, Nhien-An</dc:creator>
 <dc:creator>Kechadi, M-Tahar</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The humanities, like many other areas of society, are currently undergoing
major changes in the wake of digital transformation. However, in order to make
collection of digitised material in this area easily accessible, we often still
lack adequate search functionality. For instance, digital archives for textiles
offer keyword search, which is fairly well understood, and arrange their
content following a certain taxonomy, but search functionality at the level of
thread structure is still missing. To facilitate the clustering and search, we
introduce an approach for recognising similar weaving patterns based on their
structures for textile archives. We first represent textile structures using
hypergraphs and extract multisets of k-neighbourhoods describing weaving
patterns from these graphs. Then, the resulting multisets are clustered using
various distance measures and various clustering algorithms (K-Means for
simplicity and hierarchical agglomerative algorithms for precision). We
evaluate the different variants of our approach experimentally, showing that
this can be implemented efficiently (meaning it has linear complexity), and
demonstrate its quality to query and cluster datasets containing large textile
samples. As, to the est of our knowledge, this is the first practical approach
for explicitly modelling complex and irregular weaving patterns usable for
retrieval, we aim at establishing a solid baseline.
</dc:description>
 <dc:description>Comment: 38 pages, 23 figures</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11271</dc:identifier>
 <dc:identifier>Information Retrieval Journal, Springer, 2021</dc:identifier>
 <dc:identifier>doi:10.1007/s10791-020-09384-y</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11273</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Networked Supervisor Synthesis Against Lossy Channels with Bounded
  Network Delays as Non-Networked Synthesis</dc:title>
 <dc:creator>Lin, Liyong</dc:creator>
 <dc:creator>Zhu, Yuting</dc:creator>
 <dc:creator>Tai, Ruochen</dc:creator>
 <dc:creator>Ware, Simon</dc:creator>
 <dc:creator>Su, Rong</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  In this work, we study the problem of supervisory control of networked
discrete event systems. We consider lossy communication channels with bounded
network delays, for both the control channel and the observation channel. By a
model transformation, we transform the networked supervisor synthesis problem
into the classical (non-networked) supervisor synthesis problem (for
non-deterministic plants), such that the existing supervisor synthesis tools
can be used for synthesizing networked supervisors. In particular, we can use
the (state-based) normality property for the synthesis of the supremal
networked supervisors, whose existence is guaranteed by construction due to our
consideration of command non-deterministic supervisors. The effectiveness of
our approach is illustrated on a mini-guideway example that is adapted from the
literature, for which the supremal networked supervisor has been synthesized in
the synthesis tools SuSyNA and TCT.
</dc:description>
 <dc:description>Comment: This paper is under review for Automatica</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11274</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sliding Mode Learning Control of Uncertain Nonlinear Systems with
  Lyapunov Stability Analysis</dc:title>
 <dc:creator>Kayacan, Erkan</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  This paper addresses to Sliding Mode Learning Control (SMLC) of uncertain
nonlinear systems with Lyapunov stability analysis. In the control scheme, a
conventional control term is used to provide the system stability in compact
space while a Type-2 Neuro-Fuzzy Controller (T2NFC) learns system behavior so
that the T2NFC takes the overall control of the system completely in a very
short time period. The stability of the sliding mode learning algorithm was
proven in literature; however, it is so restrictive for systems without the
overall system stability. To address this shortcoming, a novel control
structure with a novel sliding surface is proposed in this paper and the
stability of the overall system is proven for nth-order uncertain nonlinear
systems. To investigate the capability and effectiveness of the proposed
learning and control algorithms, the simulation studies have been achieved
under noisy conditions. The simulation results confirm that the developed SMLC
algorithm can learn the system behavior in the absence of any mathematical
model knowledge and exhibit robust control performance against external
disturbances.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11274</dc:identifier>
 <dc:identifier>Transactions of the Institute of Measurement and Control, vol.
  41(6), pp. 1750-1760, 2019</dc:identifier>
 <dc:identifier>doi:10.1177/0142331218788125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11276</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High precision control and deep learning-based corn stand counting
  algorithms for agricultural robot</dc:title>
 <dc:creator>Zhang, Zhongzhong</dc:creator>
 <dc:creator>Kayacan, Erkan</dc:creator>
 <dc:creator>Thompson, Benjamin</dc:creator>
 <dc:creator>Chowdhary, Girish</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents high precision control and deep learning-based corn stand
counting algorithms for a low-cost, ultra-compact 3D printed and autonomous
field robot for agricultural operations. Currently, plant traits, such as
emergence rate, biomass, vigor, and stand counting, are measured manually. This
is highly labor-intensive and prone to errors. The robot, termed TerraSentia,
is designed to automate the measurement of plant traits for efficient
phenotyping as an alternative to manual measurements. In this paper, we
formulate a Nonlinear Moving Horizon Estimator (NMHE) that identifies key
terrain parameters using onboard robot sensors and a learning-based Nonlinear
Model Predictive Control (NMPC) that ensures high precision path tracking in
the presence of unknown wheel-terrain interaction. Moreover, we develop a
machine vision algorithm designed to enable an ultra-compact ground robot to
count corn stands by driving through the fields autonomously. The algorithm
leverages a deep network to detect corn plants in images, and a visual tracking
model to re-identify detected objects at different time steps. We collected
data from 53 corn plots in various fields for corn plants around 14 days after
emergence (stage V3 - V4). The robot predictions have agreed well with the
ground truth with $C_{robot}=1.02 \times C_{human}-0.86$ and a correlation
coefficient $R=0.96$. The mean relative error given by the algorithm is
$-3.78\%$, and the standard deviation is $6.76\%$. These results indicate a
first and significant step towards autonomous robot-based real-time phenotyping
using low-cost, ultra-compact ground robots for corn and potentially other
crops.
</dc:description>
 <dc:description>Comment: 14 pages, 9 figures</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11276</dc:identifier>
 <dc:identifier>Autonomous Robots, volume 44, pages 1289-1302, 2020</dc:identifier>
 <dc:identifier>doi:10.1007/s10514-020-09915-y</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11277</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sliding Mode Control for Systems with Mismatched Time-Varying
  Uncertainties via a Self-Learning Disturbance Observer</dc:title>
 <dc:creator>Kayacan, Erkan</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents a novel Sliding Mode Control (SMC) algorithm to handle
mismatched uncertainties in systems via a novel Self-Learning Disturbance
Observer (SLDO). A computationally efficient SLDO is developed within a
framework of feedback-error learning scheme in which a conventional estimation
law and a Neuro-Fuzzy Structure (NFS) work in parallel. In this framework, the
NFS estimates the mismatched disturbances and becomes the leading disturbance
estimator while the former feeds the learning error to the NFS to learn system
behavior. The simulation results demonstrate that the proposed SMC based on
SLDO (SMC-SLDO) ensures the robust control performance in the presence of
mismatched time-varying uncertainties when compared to SMC, integral SMC (ISMC)
and SMC based on a Basic Nonlinear Disturbance Observer (SMC-BNDO), and also
remains the nominal control performance in the absence of mismatched
uncertainties. Additionally, the SMC-SLDO not only counteracts mismatched
time-varying uncertainties but also improve the transient response performance
in the presence of mismatched time-invariant uncertainties. Moreover, the
controller gain of the SMC-SLDO is required to be selected larger than the
upper bound of the disturbance estimation error rather than the upper bound of
the actual disturbance to guarantee the system stability which results in
eliminating the chattering effects on the control signal.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11277</dc:identifier>
 <dc:identifier>Transactions of the Institute of Measurement and Control, vol.
  41(7), pp. 2039-2052, 2019</dc:identifier>
 <dc:identifier>doi:10.1177/0142331218794266</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11278</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Study of Design of Rate-Compatible Polar Codes Based on Non-Uniform
  Channel Polarization</dc:title>
 <dc:creator>Oliveira, R. M.</dc:creator>
 <dc:creator>de Lamare, R. C.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We propose a novel scheme for rate-compatible arbitrary-length polar code
construction for the additive white Gaussian noise (AWGN) channel. The proposed
scheme is based on the concept of non-uniform channel polarization. The
original polar codes can only be designed with code lengths that are powers of
two. Puncturing, shortening and extension are three strategies to obtain
arbitrary code lengths and code rates for polar codes. There are other ways to
design codes with arbitrary length but which have encoding and decoding with
higher complexity such as multi-kernel, concatenated codes and specific
constructions for Belief propagation (BP) or Successive Cancellation (SC)
decoding. In general, the quality of the projected bit channels by these
arbitrary-length techniques differs from that of the original bit channels,
which can greatly affect the performance of the constructed polar codes. The
proposed Non-Uniform Polarization based on Gaussian Approximation (NUPGA) is an
efficient construction technique for rate-compatible arbitrary-length polar
codes, which chooses the best channels (i.e., selects the positions of the
information bits) by re-polarization of the codeword with desired length. A
generalization of the Gaussian Approximation is devised for both polarization
and re-polarization processes. We also present shortening and extension
techniques for design polar codes. Simulations verify the effectiveness of the
proposed NUPGA designs against existing rate-compatible techniques.
</dc:description>
 <dc:description>Comment: 11 figures, 11 pages. arXiv admin note: text overlap with
  arXiv:1911.07137</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11278</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11282</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracking error learning control for precise mobile robot path tracking
  in outdoor environment</dc:title>
 <dc:creator>Kayacan, Erkan</dc:creator>
 <dc:creator>Chowdhary, Girish</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents a Tracking-Error Learning Control (TELC) algorithm for
precise mobile robot path tracking in off-road terrain. In traditional tracking
error-based control approaches, feedback and feedforward controllers are
designed based on the nominal model which cannot capture the uncertainties,
disturbances and changing working conditions so that they cannot ensure precise
path tracking performance in the outdoor environment. In TELC algorithm, the
feedforward control actions are updated by using the tracking error dynamics
and the plant-model mismatch problem is thus discarded. Therefore, the
feedforward controller gradually eliminates the feedback controller from the
control of the system once the mobile robot has been on-track. In addition to
the proof of the stability, it is proven that the cost functions do not have
local minima so that the coefficients in TELC algorithm guarantee that the
global minimum is reached. The experimental results show that the TELC
algorithm results in better path tracking performance than the traditional
tracking error-based control method. The mobile robot controlled by TELC
algorithm can track a target path precisely with less than $10$ cm error in
off-road terrain.
</dc:description>
 <dc:description>Comment: 12 pages, 13 figures</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11282</dc:identifier>
 <dc:identifier>Journal of Intelligent and Robotic Systems, vol. 95, pp. 975-986,
  2019</dc:identifier>
 <dc:identifier>doi:10.1007/s10846-018-0916-3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11284</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Optimal Fronthauling and Decentralized Edge Computation in Fog
  Radio Access Networks</dc:title>
 <dc:creator>Lee, Hoon</dc:creator>
 <dc:creator>Kim, Junbeom</dc:creator>
 <dc:creator>Park, Seok-Hwan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Fog radio access networks (F-RANs), which consist of a cloud and multiple
edge nodes (ENs) connected via fronthaul links, have been regarded as promising
network architectures. The F-RAN entails a joint optimization of cloud and edge
computing as well as fronthaul interactions, which is challenging for
traditional optimization techniques. This paper proposes a Cloud-Enabled
Cooperation-Inspired Learning (CECIL) framework, a structural deep learning
mechanism for handling a generic F-RAN optimization problem. The proposed
solution mimics cloud-aided cooperative optimization policies by including
centralized computing at the cloud, distributed decision at the ENs, and their
uplink-downlink fronthaul interactions. A group of deep neural networks (DNNs)
are employed for characterizing computations of the cloud and ENs. The
forwardpass of the DNNs is carefully designed such that the impacts of the
practical fronthaul links, such as channel noise and signling overheads, can be
included in a training step. As a result, operations of the cloud and ENs can
be jointly trained in an end-to-end manner, whereas their real-time inferences
are carried out in a decentralized manner by means of the fronthaul
coordination. To facilitate fronthaul cooperation among multiple ENs, the
optimal fronthaul multiple access schemes are designed. Training algorithms
robust to practical fronthaul impairments are also presented. Numerical results
validate the effectiveness of the proposed approaches.
</dc:description>
 <dc:description>Comment: to appear in IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11284</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11285</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geo-Spatiotemporal Features and Shape-Based Prior Knowledge for
  Fine-grained Imbalanced Data Classification</dc:title>
 <dc:creator>Kantor, Charles A.</dc:creator>
 <dc:creator>Skreta, Marta</dc:creator>
 <dc:creator>Rauby, Brice</dc:creator>
 <dc:creator>Boussioux, L&#xe9;onard</dc:creator>
 <dc:creator>Jehanno, Emmanuel</dc:creator>
 <dc:creator>Luccioni, Alexandra</dc:creator>
 <dc:creator>Rolnick, David</dc:creator>
 <dc:creator>Talbot, Hugues</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Fine-grained classification aims at distinguishing between items with similar
global perception and patterns, but that differ by minute details. Our primary
challenges come from both small inter-class variations and large intra-class
variations. In this article, we propose to combine several innovations to
improve fine-grained classification within the use-case of wildlife, which is
of practical interest for experts. We utilize geo-spatiotemporal data to enrich
the picture information and further improve the performance. We also
investigate state-of-the-art methods for handling the imbalanced data issue.
</dc:description>
 <dc:description>Comment: Copyright by the authors. All rights reserved to authors only.
  Correspondence to: ckantor (at) stanford [dot] edu</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11285</dc:identifier>
 <dc:identifier>Proc. IJCAI 2021, Workshop on AI for Social Good, Harvard
  University (2021)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11286</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Systematical Study on Application Performance Management Libraries for
  Apps</dc:title>
 <dc:creator>Tang, Yutian</dc:creator>
 <dc:creator>Wang, Haoyu</dc:creator>
 <dc:creator>Zhan, Xian</dc:creator>
 <dc:creator>Luo, Xiapu</dc:creator>
 <dc:creator>Zhou, Yajin</dc:creator>
 <dc:creator>Zhou, Hao</dc:creator>
 <dc:creator>Yan, Qiben</dc:creator>
 <dc:creator>Sui, Yulei</dc:creator>
 <dc:creator>Keung, Jacky</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Being able to automatically detect the performance issues in apps can
significantly improve apps' quality as well as having a positive influence on
user satisfaction. Application Performance Management (APM) libraries are used
to locate the apps' performance bottleneck, monitor their behaviors at runtime,
and identify potential security risks. Although app developers have been
exploiting application performance management (APM) tools to capture these
potential performance issues, most of them do not fully understand the
internals of these APM tools and the effect on their apps. To fill this gap, in
this paper, we conduct the first systematic study on APMs for apps by
scrutinizing 25 widely-used APMs for Android apps and develop a framework named
APMHunter for exploring the usage of APMs in Android apps. Using APMHunter, we
conduct a large-scale empirical study on 500,000 Android apps to explore the
usage patterns of APMs and discover the potential misuses of APMs. We obtain
two major findings: 1) some APMs still employ deprecated permissions and
approaches, which makes APMs fail to perform as expected; 2) inappropriate use
of APMs can cause privacy leaks. Thus, our study suggests that both APM vendors
and developers should design and use APMs scrupulously.
</dc:description>
 <dc:description>Comment: Journal extension of ASE'19 &quot;Demystifying Application Performance
  Management Libraries for Android&quot;</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11286</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11288</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ActivationNet: Representation learning to predict contact quality of
  interacting 3-D surfaces in engineering designs</dc:title>
 <dc:creator>Ranade, Rishikesh</dc:creator>
 <dc:creator>Pathak, Jay</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Engineering simulations for analysis of structural and fluid systems require
information of contacts between various 3-D surfaces of the geometry to
accurately model the physics between them. In machine learning applications,
3-D surfaces are most suitably represented with point clouds or meshes and
learning representations of interacting geometries form point-based
representations is challenging. The objective of this work is to introduce a
machine learning algorithm, ActivationNet, that can learn from point clouds or
meshes of interacting 3-D surfaces and predict the quality of contact between
these surfaces. The ActivationNet generates activation states from point-based
representation of surfaces using a multi-dimensional binning approach. The
activation states are further used to contact quality between surfaces using
deep neural networks. The performance of our model is demonstrated using
several experiments, including tests on interacting surfaces extracted from
engineering geometries. In all the experiments presented in this paper, the
contact quality predictions of ActivationNet agree well with the expectations.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11288</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11292</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feedback Linearization Control for Systems with Mismatched Uncertainties
  via Disturbance Observers</dc:title>
 <dc:creator>Kayacan, Erkan</dc:creator>
 <dc:creator>Fossen, Thor I.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper focuses on a novel feedback linearization control (FLC) law based
on a self-learning disturbance observer (SLDO) to counteract mismatched
uncertainties. The FLC based on BNDO (FLC-BNDO) demonstrates robust control
performance only against mismatched time-invariant uncertainties while the FLC
based on SLDO (FLC-SLDO) demonstrates robust control performance against
mismatched time-invariant and -varying uncertainties, and both of them maintain
the nominal control performance in the absence of mismatched uncertainties. In
the estimation scheme for the SLDO, the BNDO is used to provide a conventional
estimation law, which is used as being the learning error for the type-2
neuro-fuzzy system (T2NFS), and T2NFS learns mismatched uncertainties. Thus,
the T2NFS takes the overall control of the estimation signal entirely in a very
short time and gives unbiased estimation results for the disturbance. A novel
learning algorithm established on sliding mode control theory is derived for an
interval type-2 fuzzy logic system. The stability of the overall system is
proven for a second-order nonlinear system with mismatched uncertainties. The
simulation results show that the FLC-SLDO demonstrates better control
performance than the traditional FLC, FLC with an integral action (FLC-I) and
FLC-BNDO.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11292</dc:identifier>
 <dc:identifier>Asian Journal of Control, vol. 21, pp. 1064-1076, 2019</dc:identifier>
 <dc:identifier>doi:10.1002/asjc.1802</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11294</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High Precision Control of Tracked Field Robots in the Presence of
  Unknown Traction Coefficients</dc:title>
 <dc:creator>Kayacan, Erkan</dc:creator>
 <dc:creator>Young, Sierra N.</dc:creator>
 <dc:creator>Peschel, Joshua M.</dc:creator>
 <dc:creator>Chowdhary, Girish</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Accurate steering through crop rows that avoids crop damage is one of the
most important tasks for agricultural robots utilized in various field
operations, such as monitoring, mechanical weeding, or spraying. In practice,
varying soil conditions can result in off-track navigation due to unknown
traction coefficients so that it can cause crop damage. To address this
problem, this paper presents the development, application, and experimental
results of a real-time receding horizon estimation and control (RHEC) framework
applied to a fully autonomous mobile robotic platform to increase its steering
accuracy. Recent advances in cheap and fast microprocessors, as well as
advances in solution methods for nonlinear optimization problems, have made
nonlinear receding horizon control (RHC) and receding horizon estimation (RHE)
methods suitable for field robots that require high frequency (milliseconds)
updates. A real-time RHEC framework is developed and applied to a fully
autonomous mobile robotic platform designed by the authors for in-field
phenotyping applications in Sorghum fields. Nonlinear RHE is used to estimate
constrained states and parameters, and nonlinear RHC is designed based on an
adaptive system model which contains time-varying parameters. The capabilities
of the real-time RHEC framework are verified experimentally, and the results
show an accurate tracking performance on a bumpy and wet soil field. The mean
values of the Euclidean error and required computation time of the RHEC
framework are respectively equal to $0.0423$ m and $0.88$ milliseconds.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11294</dc:identifier>
 <dc:identifier>Journal of Field Robotics, vol. 35, pp. 1050-1062, 2018</dc:identifier>
 <dc:identifier>doi:10.1002/rob.21794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11297</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Insight-centric Visualization Recommendation</dc:title>
 <dc:creator>Harris, Camille</dc:creator>
 <dc:creator>Rossi, Ryan A.</dc:creator>
 <dc:creator>Malik, Sana</dc:creator>
 <dc:creator>Hoffswell, Jane</dc:creator>
 <dc:creator>Du, Fan</dc:creator>
 <dc:creator>Lee, Tak Yeon</dc:creator>
 <dc:creator>Koh, Eunyee</dc:creator>
 <dc:creator>Zhao, Handong</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Visualization recommendation systems simplify exploratory data analysis (EDA)
and make understanding data more accessible to users of all skill levels by
automatically generating visualizations for users to explore. However, most
existing visualization recommendation systems focus on ranking all
visualizations into a single list or set of groups based on particular
attributes or encodings. This global ranking makes it difficult and
time-consuming for users to find the most interesting or relevant insights. To
address these limitations, we introduce a novel class of visualization
recommendation systems that automatically rank and recommend both groups of
related insights as well as the most important insights within each group. Our
proposed approach combines results from many different learning-based methods
to discover insights automatically. A key advantage is that this approach
generalizes to a wide variety of attribute types such as categorical,
numerical, and temporal, as well as complex non-trivial combinations of these
different attribute types. To evaluate the effectiveness of our approach, we
implemented a new insight-centric visualization recommendation system,
SpotLight, which generates and ranks annotated visualizations to explain each
insight. We conducted a user study with 12 participants and two datasets which
showed that users are able to quickly understand and find relevant insights in
unfamiliar data.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11297</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11299</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Modular and Unified Framework for Detecting and Localizing Video
  Anomalies</dc:title>
 <dc:creator>Doshi, Keval</dc:creator>
 <dc:creator>Yilmaz, Yasin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Anomaly detection in videos has been attracting an increasing amount of
attention. Despite the competitive performance of recent methods on benchmark
datasets, they typically lack desirable features such as modularity,
cross-domain adaptivity, interpretability, and real-time anomalous event
detection. Furthermore, current state-of-the-art approaches are evaluated using
the standard instance-based detection metric by considering video frames as
independent instances, which is not ideal for video anomaly detection.
Motivated by these research gaps, we propose a modular and unified approach to
the online video anomaly detection and localization problem, called MOVAD,
which consists of a novel transfer learning based plug-and-play architecture, a
sequential anomaly detector, a mathematical framework for selecting the
detection threshold, and a suitable performance metric for real-time anomalous
event detection in videos. Extensive performance evaluations on benchmark
datasets show that the proposed framework significantly outperforms the current
state-of-the-art approaches.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11299</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11302</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Common Sense Knowledge, Ontology and Text Mining for Implicit
  Requirements</dc:title>
 <dc:creator>Emebo, Onyeka</dc:creator>
 <dc:creator>Varde, Aparna S.</dc:creator>
 <dc:creator>Daramola, Olawande</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>D.2.1</dc:subject>
 <dc:subject>I.2.1</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  The ability of a system to meet its requirements is a strong determinant of
success. Thus effective requirements specification is crucial. Explicit
Requirements are well-defined needs for a system to execute. IMplicit
Requirements (IMRs) are assumed needs that a system is expected to fulfill
though not elicited during requirements gathering. Studies have shown that a
major factor in the failure of software systems is the presence of unhandled
IMRs. Since relevance of IMRs is important for efficient system functionality,
there are methods developed to aid the identification and management of IMRs.
In this paper, we emphasize that Common Sense Knowledge, in the field of
Knowledge Representation in AI, would be useful to automatically identify and
manage IMRs. This paper is aimed at identifying the sources of IMRs and also
proposing an automated support tool for managing IMRs within an organizational
context. Since this is found to be a present gap in practice, our work makes a
contribution here. We propose a novel approach for identifying and managing
IMRs based on combining three core technologies: common sense knowledge, text
mining and ontology. We claim that discovery and handling of unknown and
non-elicited requirements would reduce risks and costs in software development.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures, 2 tables, conference: DMIN 2016 conference by
  CSREA</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11311</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic 3D Map Change Detection and Update based on Smartphone Visual
  Positioning System</dc:title>
 <dc:creator>Lee, Max Jwo Lem</dc:creator>
 <dc:creator>Hsu, Li-Ta</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Accurate localization and 3D maps are increasingly needed for various
artificial intelligence based IoT applications such as augmented reality,
intelligent transportation, crowd monitoring, robotics, etc. This article
proposes a novel semantic 3D map change detection and update based on a
smartphone visual positioning system (VPS) for the outdoor and indoor
environments. The proposed method presents an alternate solution to SLAM for
map update in terms of efficiency, cost, availability, and map reuse. Building
on existing 3D maps of recent years, a system is designed to use artificial
intelligence to identify high-level semantics in images for positioning and map
change detection. Then, a virtual LIDAR that estimates the depth of objects in
the 3D map is used to generate a compact point cloud to update changes in the
scene. We present an excellent performance of localization with respect to
other state-of-the-art smartphone positioning solutions to accurately update
semantic 3D maps. It is shown that the proposed solution can position users
within 1.9m, and update objects with an average error of 2.1m.
</dc:description>
 <dc:description>Comment: 12 pages, 4 figures. arXiv admin note: text overlap with
  arXiv:2011.10743</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11311</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11312</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward Consistent Drift-free Visual Inertial Localization on Keyframe
  Based Map</dc:title>
 <dc:creator>Zhang, Zhuqing</dc:creator>
 <dc:creator>Jiao, Yanmei</dc:creator>
 <dc:creator>Huang, Shoudong</dc:creator>
 <dc:creator>Wang, Yue</dc:creator>
 <dc:creator>Xiong, Rong</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Global localization is essential for robots to perform further tasks like
navigation. In this paper, we propose a new framework to perform global
localization based on a filter-based visual-inertial odometry framework MSCKF.
To reduce the computation and memory consumption, we only maintain the keyframe
poses of the map and employ Schmidt-EKF to update the state. This global
localization framework is shown to be able to maintain the consistency of the
state estimator. Furthermore, we introduce a re-linearization mechanism during
the updating phase. This mechanism could ease the linearization error of
observation function to make the state estimation more precise. The experiments
show that this mechanism is crucial for large and challenging scenes.
Simulations and experiments demonstrate the effectiveness and consistency of
our global localization framework.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11312</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11313</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PGT: A Progressive Method for Training Models on Long Videos</dc:title>
 <dc:creator>Pang, Bo</dc:creator>
 <dc:creator>Peng, Gao</dc:creator>
 <dc:creator>Li, Yizhuo</dc:creator>
 <dc:creator>Lu, Cewu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional video models have an order of magnitude larger computational
complexity than their counterpart image-level models. Constrained by
computational resources, there is no model or training method that can train
long video sequences end-to-end. Currently, the main-stream method is to split
a raw video into clips, leading to incomplete fragmentary temporal information
flow. Inspired by natural language processing techniques dealing with long
sentences, we propose to treat videos as serial fragments satisfying Markov
property, and train it as a whole by progressively propagating information
through the temporal dimension in multiple steps. This progressive training
(PGT) method is able to train long videos end-to-end with limited resources and
ensures the effective transmission of information. As a general and robust
training method, we empirically demonstrate that it yields significant
performance improvements on different models and datasets. As an illustrative
example, the proposed method improves SlowOnly network by 3.7 mAP on Charades
and 1.9 top-1 accuracy on Kinetics with negligible parameter and computation
overhead. Code is available at https://github.com/BoPang1996/PGT.
</dc:description>
 <dc:description>Comment: CVPR21, Oral</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11313</dc:identifier>
 <dc:identifier>CVPR2021 oral</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11314</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Learned Compact and Editable Light Field Representation</dc:title>
 <dc:creator>Xia, Menghan</dc:creator>
 <dc:creator>Echevarria, Jose</dc:creator>
 <dc:creator>Xie, Minshan</dc:creator>
 <dc:creator>Wong, Tien-Tsin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Light fields are 4D scene representation typically structured as arrays of
views, or several directional samples per pixel in a single view. This highly
correlated structure is not very efficient to transmit and manipulate
(especially for editing), though. To tackle these problems, we present a novel
compact and editable light field representation, consisting of a set of visual
channels (i.e. the central RGB view) and a complementary meta channel that
encodes the residual geometric and appearance information. The visual channels
in this representation can be edited using existing 2D image editing tools,
before accurately reconstructing the whole edited light field back. We propose
to learn this representation via an autoencoder framework, consisting of an
encoder for learning the representation, and a decoder for reconstructing the
light field. To handle the challenging occlusions and propagation of edits, we
specifically designed an editing-aware decoding network and its associated
training strategy, so that the edits to the visual channels can be consistently
propagated to the whole light field upon reconstruction.Experimental results
show that our proposed method outperforms related existing methods in
reconstruction accuracy, and achieves visually pleasant performance in editing
propagation.
</dc:description>
 <dc:description>Comment: submitted to TIP since 2020.08.03</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11314</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11316</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Software Vulnerability Assessment with Concept Drift</dc:title>
 <dc:creator>Le, Triet H. M.</dc:creator>
 <dc:creator>Sabir, Bushra</dc:creator>
 <dc:creator>Babar, M. Ali</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Software Engineering researchers are increasingly using Natural Language
Processing (NLP) techniques to automate Software Vulnerabilities (SVs)
assessment using the descriptions in public repositories. However, the existing
NLP-based approaches suffer from concept drift. This problem is caused by a
lack of proper treatment of new (out-of-vocabulary) terms for the evaluation of
unseen SVs over time. To perform automated SVs assessment with concept drift
using SVs' descriptions, we propose a systematic approach that combines both
character and word features. The proposed approach is used to predict seven
Vulnerability Characteristics (VCs). The optimal model of each VC is selected
using our customized time-based cross-validation method from a list of eight
NLP representations and six well-known Machine Learning models. We have used
the proposed approach to conduct large-scale experiments on more than 100,000
SVs in the National Vulnerability Database (NVD). The results show that our
approach can effectively tackle the concept drift issue of the SVs'
descriptions reported from 2000 to 2018 in NVD even without retraining the
model. In addition, our approach performs competitively compared to the
existing word-only method. We also investigate how to build compact
concept-drift-aware models with much fewer features and give some
recommendations on the choice of classifiers and NLP representations for SVs
assessment.
</dc:description>
 <dc:description>Comment: Published as a full paper at the 16th International Conference on
  Mining Software Repositories 2019</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11316</dc:identifier>
 <dc:identifier>Proceedings of the 16th International Conference on Mining
  Software Repositories, 2019, pp. 371-382</dc:identifier>
 <dc:identifier>doi:10.1109/MSR.2019.00063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11318</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Language-Agnostic Representation Learning of Source Code from Structure
  and Context</dc:title>
 <dc:creator>Z&#xfc;gner, Daniel</dc:creator>
 <dc:creator>Kirschstein, Tobias</dc:creator>
 <dc:creator>Catasta, Michele</dc:creator>
 <dc:creator>Leskovec, Jure</dc:creator>
 <dc:creator>G&#xfc;nnemann, Stephan</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Source code (Context) and its parsed abstract syntax tree (AST; Structure)
are two complementary representations of the same computer program.
Traditionally, designers of machine learning models have relied predominantly
either on Structure or Context. We propose a new model, which jointly learns on
Context and Structure of source code. In contrast to previous approaches, our
model uses only language-agnostic features, i.e., source code and features that
can be computed directly from the AST. Besides obtaining state-of-the-art on
monolingual code summarization on all five programming languages considered in
this work, we propose the first multilingual code summarization model. We show
that jointly training on non-parallel data from multiple programming languages
improves results on all individual languages, where the strongest gains are on
low-resource languages. Remarkably, multilingual training only from Context
does not lead to the same improvements, highlighting the benefits of combining
Structure and Context for representation learning on code.
</dc:description>
 <dc:description>Comment: ICLR 2021</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11318</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11319</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reference-Aided Part-Aligned Feature Disentangling for Video Person
  Re-Identification</dc:title>
 <dc:creator>Zhang, Guoqing</dc:creator>
 <dc:creator>Chen, Yuhao</dc:creator>
 <dc:creator>Dai, Yang</dc:creator>
 <dc:creator>Zheng, Yuhui</dc:creator>
 <dc:creator>Wu, Yi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, video-based person re-identification (re-ID) has drawn increasing
attention in compute vision community because of its practical application
prospects. Due to the inaccurate person detections and pose changes, pedestrian
misalignment significantly increases the difficulty of feature extraction and
matching. To address this problem, in this paper, we propose a
\textbf{R}eference-\textbf{A}ided \textbf{P}art-\textbf{A}ligned
(\textbf{RAPA}) framework to disentangle robust features of different parts.
Firstly, in order to obtain better references between different videos, a
pose-based reference feature learning module is introduced. Secondly, an
effective relation-based part feature disentangling module is explored to align
frames within each video. By means of using both modules, the informative parts
of pedestrian in videos are well aligned and more discriminative feature
representation is generated. Comprehensive experiments on three widely-used
benchmarks, i.e. iLIDS-VID, PRID-2011 and MARS datasets verify the
effectiveness of the proposed framework. Our code will be made publicly
available.
</dc:description>
 <dc:description>Comment: 6 pages, accepted by ICME 2021</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11321</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fault Prediction based on Software Metrics and SonarQube Rules. Machine
  or Deep Learning?</dc:title>
 <dc:creator>Lomio, Francesco</dc:creator>
 <dc:creator>Moreschini, Sergio</dc:creator>
 <dc:creator>Lenarduzzi, Valentina</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Background. Developers spend more time fixing bugs and refactoring the code
to increase the maintainability than developing new features. Researchers
investigated the code quality impact on fault-proneness focusing on code smells
and code metrics. Objective. We aim at advancing fault-inducing commit
prediction based on SonarQube considering the contribution provided by each
rule and metric. Method. We designed and conducted a case study among 33 Java
projects analyzed with SonarQube and SZZ to identify fault-inducing and
fault-fixing commits. Moreover, we investigated fault-proneness of each
SonarQube rule and metric using Machine and Deep Learning models. Results. We
analyzed 77,932 commits that contain 40,890 faults and infected by more than
174 SonarQube rules violated 1,9M times, on which there was calculated 24
software metrics available by the tool. Compared to machine learning models,
deep learning provide a more accurate fault detection accuracy and allowed us
to accurately identify the fault-prediction power of each SonarQube rule. As a
result, fourteen of the 174 violated rules has an importance higher than 1\%
and account for 30\% of the total fault-proneness importance, while the fault
proneness of the remaining 165 rules is negligible. Conclusion. Future works
might consider the adoption of timeseries analysis and anomaly detection
techniques to better and more accurately detect the rules that impact
fault-proneness.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11322</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Learning of Depth Estimation and Visual Odometry for Sparse
  Light Field Cameras</dc:title>
 <dc:creator>Digumarti, S. Tejaswi</dc:creator>
 <dc:creator>Daniel, Joseph</dc:creator>
 <dc:creator>Ravendran, Ahalya</dc:creator>
 <dc:creator>Dansereau, Donald G.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4.8</dc:subject>
 <dc:subject>I.4.10</dc:subject>
 <dc:description>  While an exciting diversity of new imaging devices is emerging that could
dramatically improve robotic perception, the challenges of calibrating and
interpreting these cameras have limited their uptake in the robotics community.
In this work we generalise techniques from unsupervised learning to allow a
robot to autonomously interpret new kinds of cameras. We consider emerging
sparse light field (LF) cameras, which capture a subset of the 4D LF function
describing the set of light rays passing through a plane. We introduce a
generalised encoding of sparse LFs that allows unsupervised learning of
odometry and depth. We demonstrate the proposed approach outperforming
monocular and conventional techniques for dealing with 4D imagery, yielding
more accurate odometry and depth maps and delivering these with metric scale.
We anticipate our technique to generalise to a broad class of LF and sparse LF
cameras, and to enable unsupervised recalibration for coping with shifts in
camera behaviour over the lifetime of a robot. This work represents a first
step toward streamlining the integration of new kinds of imaging devices in
robotics applications.
</dc:description>
 <dc:description>Comment: Submitted to IROS 2021, 8 pages, 6 figures, 2 tables, for associated
  project page, see https://roboticimaging.org/Projects/LearnLFOdo/</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11322</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11338</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mining GIS Data to Predict Urban Sprawl</dc:title>
 <dc:creator>Pampoore-Thampi, Anita</dc:creator>
 <dc:creator>Varde, Aparna S.</dc:creator>
 <dc:creator>Yu, Danlin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>I.2.1</dc:subject>
 <dc:description>  This paper addresses the interesting problem of processing and analyzing data
in geographic information systems (GIS) to achieve a clear perspective on urban
sprawl. The term urban sprawl refers to overgrowth and expansion of low-density
areas with issues such as car dependency and segregation between residential
versus commercial use. Sprawl has impacts on the environment and public health.
In our work, spatiotemporal features related to real GIS data on urban sprawl
such as population growth and demographics are mined to discover knowledge for
decision support. We adapt data mining algorithms, Apriori for association rule
mining and J4.8 for decision tree classification to geospatial analysis,
deploying the ArcGIS tool for mapping. Knowledge discovered by mining this
spatiotemporal data is used to implement a prototype spatial decision support
system (SDSS). This SDSS predicts whether urban sprawl is likely to occur.
Further, it estimates the values of pertinent variables to understand how the
variables impact each other. The SDSS can help decision-makers identify
problems and create solutions for avoiding future sprawl occurrence and
conducting urban planning where sprawl already occurs, thus aiding sustainable
development. This work falls in the broad realm of geospatial intelligence and
sets the stage for designing a large scale SDSS to process big data in complex
environments, which constitutes part of our future work.
</dc:description>
 <dc:description>Comment: 8 Pages, 13 figures, KDD 2014 conference Bloomberg track</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11339</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Escaping the Time Pit: Pitfalls and Guidelines for Using Time-Based Git
  Data</dc:title>
 <dc:creator>Flint, Samuel W.</dc:creator>
 <dc:creator>Chauhan, Jigyasa</dc:creator>
 <dc:creator>Dyer, Robert</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Many software engineering research papers rely on time-based data (e.g.,
commit timestamps, issue report creation/update/close dates, release dates).
Like most real-world data however, time-based data is often dirty. To date,
there are no studies that quantify how frequently such data is used by the
software engineering research community, or investigate sources of and quantify
how often such data is dirty. Depending on the research task and method used,
including such dirty data could affect the research results. This paper
presents the first survey of papers that utilize time-based data, published in
the Mining Software Repositories (MSR) conference series. Out of the 690
technical track and data papers published in MSR 2004--2020, we saw at least
35% of papers utilized time-based data. We then used the Boa and Software
Heritage infrastructures to help identify and quantify several sources of dirty
commit timestamp data. Finally we provide guidelines/best practices for
researchers utilizing time-based data from Git repositories.
</dc:description>
 <dc:description>Comment: Accepted to the 18th International Conference on Mining Software
  Repositories (MSR 2021)</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11342</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BigCarl: Mining frequent subnets from a single large Petri net</dc:title>
 <dc:creator>Lu, Ruqian</dc:creator>
 <dc:creator>Zhang, Shuhan</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  While there have been lots of work studying frequent subgraph mining, very
rare publications have discussed frequent subnet mining from more complicated
data structures such as Petri nets. This paper studies frequent subnets mining
from a single large Petri net. We follow the idea of transforming a Petri net
in net graph form and to mine frequent sub-net graphs to avoid high complexity.
Technically, we take a minimal traversal approach to produce a canonical label
of the big net graph. We adapted the maximal independent embedding set approach
to the net graph representation and proposed an incremental pattern growth
(independent embedding set reduction) way for discovering frequent sub-net
graphs from the single large net graph, which are finally transformed back to
frequent subnets. Extensive performance studies made on a single large Petri
net, which contains 10K events, 40K conditions and 30 K arcs, showed that our
approach is correct and the complexity is reasonable.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11342</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11345</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monte Carlo Information-Oriented Planning</dc:title>
 <dc:creator>Thomas, Vincent</dc:creator>
 <dc:creator>Hutin, G&#xe9;r&#xe9;my</dc:creator>
 <dc:creator>Buffet, Olivier</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this article, we discuss how to solve information-gathering problems
expressed as rho-POMDPs, an extension of Partially Observable Markov Decision
Processes (POMDPs) whose reward rho depends on the belief state. Point-based
approaches used for solving POMDPs have been extended to solving rho-POMDPs as
belief MDPs when its reward rho is convex in B or when it is
Lipschitz-continuous. In the present paper, we build on the POMCP algorithm to
propose a Monte Carlo Tree Search for rho-POMDPs, aiming for an efficient
on-line planner which can be used for any rho function. Adaptations are
required due to the belief-dependent rewards to (i) propagate more than one
state at a time, and (ii) prevent biases in value estimates. An asymptotic
convergence proof to epsilon-optimal values is given when rho is continuous.
Experiments are conducted to analyze the algorithms at hand and show that they
outperform myopic approaches.
</dc:description>
 <dc:description>Comment: 9 pages, revised version of ECAI 2020 paper</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11349</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neighbor Embedding Variational Autoencoder</dc:title>
 <dc:creator>Tu, Renfei</dc:creator>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:creator>Xue, Yongzeng</dc:creator>
 <dc:creator>Wang, Cheng</dc:creator>
 <dc:creator>Guo, Maozu</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Being one of the most popular generative framework, variational
autoencoders(VAE) are known to suffer from a phenomenon termed posterior
collapse, i.e. the latent variational distributions collapse to the prior,
especially when a strong decoder network is used. In this work, we analyze the
latent representation of collapsed VAEs, and proposed a novel model, neighbor
embedding VAE(NE-VAE), which explicitly constraints the encoder to encode
inputs close in the input space to be close in the latent space. We observed
that for VAE variants that report similar ELBO, KL divergence or even mutual
information scores may still behave quite differently in the latent
organization. In our experiments, NE-VAE can produce qualitatively different
latent representations with majority of the latent dimensions remained active,
which may benefit downstream latent space optimization tasks. NE-VAE can
prevent posterior collapse to a much greater extent than it's predecessors, and
can be easily plugged into any autoencoder framework, without introducing
addition model components and complex training routines.
</dc:description>
 <dc:description>Comment: Paper under review for ICML2021</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11352</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Label Noise via Leave-One-Out Cross-Validation</dc:title>
 <dc:creator>Tang, Yu-Hang</dc:creator>
 <dc:creator>Zhu, Yuanran</dc:creator>
 <dc:creator>de Jong, Wibe A.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present a simple algorithm for identifying and correcting real-valued
noisy labels from a mixture of clean and corrupted sample points using Gaussian
process regression. A heteroscedastic noise model is employed, in which
additive Gaussian noise terms with independent variances are associated with
each and all of the observed labels. Optimizing the noise model using maximum
likelihood estimation leads to the containment of the GPR model's predictive
error by the posterior standard deviation in leave-one-out cross-validation. A
multiplicative update scheme is proposed for solving the maximum likelihood
estimation problem under non-negative constraints. While we provide proof of
convergence for certain special cases, the multiplicative scheme has
empirically demonstrated monotonic convergence behavior in virtually all our
numerical experiments. We show that the presented method can pinpoint corrupted
sample points and lead to better regression models when trained on synthetic
and real-world scientific data sets.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11352</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11354</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Strongly Convex Optimization with Unknown Delays</dc:title>
 <dc:creator>Wan, Yuanyu</dc:creator>
 <dc:creator>Tu, Wei-Wei</dc:creator>
 <dc:creator>Zhang, Lijun</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We investigate the problem of online convex optimization with unknown delays,
in which the feedback of a decision arrives with an arbitrary delay. Previous
studies have presented a delayed variant of online gradient descent (OGD), and
achieved the regret bound of $O(\sqrt{T+D})$ by only utilizing the convexity
condition, where $D$ is the sum of delays over $T$ rounds. In this paper, we
further exploit the strong convexity to improve the regret bound. Specifically,
we first extend the delayed variant of OGD for strongly convex functions, and
establish a better regret bound of $O(d\log T)$, where $d$ is the maximum
delay. The essential idea is to let the learning rate decay with the total
number of received feedback linearly. Furthermore, we consider the more
challenging bandit setting, and obtain similar theoretical guarantees by
incorporating the classical multi-point gradient estimator into our extended
method. To the best of our knowledge, this is the first work that solves online
strongly convex optimization under the general delayed setting.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11356</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structural block driven - enhanced convolutional neural representation
  for relation extraction</dc:title>
 <dc:creator>Wang, Dongsheng</dc:creator>
 <dc:creator>Tiwari, Prayag</dc:creator>
 <dc:creator>Garg, Sahil</dc:creator>
 <dc:creator>Zhu, Hongyin</dc:creator>
 <dc:creator>Bruza, Peter</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper, we propose a novel lightweight relation extraction approach of
structural block driven - convolutional neural learning. Specifically, we
detect the essential sequential tokens associated with entities through
dependency analysis, named as a structural block, and only encode the block on
a block-wise and an inter-block-wise representation, utilizing multi-scale
CNNs. This is to 1) eliminate the noisy from irrelevant part of a sentence;
meanwhile 2) enhance the relevant block representation with both block-wise and
inter-block-wise semantically enriched representation. Our method has the
advantage of being independent of long sentence context since we only encode
the sequential tokens within a block boundary. Experiments on two datasets
i.e., SemEval2010 and KBP37, demonstrate the significant advantages of our
method. In particular, we achieve the new state-of-the-art performance on the
KBP37 dataset; and comparable performance with the state-of-the-art on the
SemEval2010 dataset.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11356</dc:identifier>
 <dc:identifier>doi:10.1016/j.asoc.2019.105913</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11360</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NameRec*: Highly Accurate and Fine-grained Person Name Recognition</dc:title>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:creator>Dai, Yimeng</dc:creator>
 <dc:creator>Liu, Shijie</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we introduce the NameRec* task, which aims to do highly
accurate and fine-grained person name recognition. Traditional Named Entity
Recognition models have good performance in recognising well-formed person
names from text with consistent and complete syntax, such as news articles.
However, there are rapidly growing scenarios where sentences are of incomplete
syntax and names are in various forms such as user-generated contents and
academic homepages. To address person name recognition in this context, we
propose a fine-grained annotation scheme based on anthroponymy. To take full
advantage of the fine-grained annotations, we propose a Co-guided Neural
Network (CogNN) for person name recognition. CogNN fully explores the
intra-sentence context and rich training signals of name forms. To better
utilize the inter-sentence context and implicit relations, which are extremely
essential for recognizing person names in long documents, we further propose an
Inter-sentence BERT Model (IsBERT). IsBERT has an overlapped input processor,
and an inter-sentence encoder with bidirectional overlapped contextual
embedding learning and multi-hop inference mechanisms. To derive benefit from
different documents with a diverse abundance of context, we propose an advanced
Adaptive Inter-sentence BERT Model (Ada-IsBERT) to dynamically adjust the
inter-sentence overlapping ratio to different documents. We conduct extensive
experiments to demonstrate the superiority of the proposed methods on both
academic homepages and news articles.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11360</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11362</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self adversarial attack as an augmentation method for
  immunohistochemical stainings</dc:title>
 <dc:creator>Vasiljevi&#x107;, Jelica</dc:creator>
 <dc:creator>Feuerhake, Friedrich</dc:creator>
 <dc:creator>Wemmert, C&#xe9;dric</dc:creator>
 <dc:creator>Lampert, Thomas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  It has been shown that unpaired image-to-image translation methods
constrained by cycle-consistency hide the information necessary for accurate
input reconstruction as imperceptible noise. We demonstrate that, when applied
to histopathology data, this hidden noise appears to be related to stain
specific features and show that this is the case with two immunohistochemical
stainings during translation to Periodic acid- Schiff (PAS), a histochemical
staining method commonly applied in renal pathology. Moreover, by perturbing
this hidden information, the translation models produce different, plausible
outputs. We demonstrate that this property can be used as an augmentation
method which, in a case of supervised glomeruli segmentation, leads to improved
performance.
</dc:description>
 <dc:description>Comment: Accepted to ISBI 2021</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11362</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11367</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ROSITA: Refined BERT cOmpreSsion with InTegrAted techniques</dc:title>
 <dc:creator>Liu, Yuanxin</dc:creator>
 <dc:creator>Lin, Zheng</dc:creator>
 <dc:creator>Yuan, Fengcheng</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Pre-trained language models of the BERT family have defined the
state-of-the-arts in a wide range of NLP tasks. However, the performance of
BERT-based models is mainly driven by the enormous amount of parameters, which
hinders their application to resource-limited scenarios. Faced with this
problem, recent studies have been attempting to compress BERT into a
small-scale model. However, most previous work primarily focuses on a single
kind of compression technique, and few attention has been paid to the
combination of different methods. When BERT is compressed with integrated
techniques, a critical question is how to design the entire compression
framework to obtain the optimal performance. In response to this question, we
integrate three kinds of compression methods (weight pruning, low-rank
factorization and knowledge distillation (KD)) and explore a range of designs
concerning model architecture, KD strategy, pruning frequency and learning rate
schedule. We find that a careful choice of the designs is crucial to the
performance of the compressed model. Based on the empirical findings, our best
compressed model, dubbed Refined BERT cOmpreSsion with InTegrAted techniques
(ROSITA), is $7.5 \times$ smaller than BERT while maintains $98.5\%$ of the
performance on five tasks of the GLUE benchmark, outperforming the previous
BERT compression methods with similar parameter budget. The code is available
at https://github.com/llyx97/Rosita.
</dc:description>
 <dc:description>Comment: Published as a conference paper at AAAI 2021</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11370</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Convex Optimization with Continuous Switching Constraint</dc:title>
 <dc:creator>Wang, Guanghui</dc:creator>
 <dc:creator>Wan, Yuanyu</dc:creator>
 <dc:creator>Yang, Tianbao</dc:creator>
 <dc:creator>Zhang, Lijun</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In many sequential decision making applications, the change of decision would
bring an additional cost, such as the wear-and-tear cost associated with
changing server status. To control the switching cost, we introduce the problem
of online convex optimization with continuous switching constraint, where the
goal is to achieve a small regret given a budget on the \emph{overall}
switching cost. We first investigate the hardness of the problem, and provide a
lower bound of order $\Omega(\sqrt{T})$ when the switching cost budget
$S=\Omega(\sqrt{T})$, and $\Omega(\min\{\frac{T}{S},T\})$ when $S=O(\sqrt{T})$,
where $T$ is the time horizon. The essential idea is to carefully design an
adaptive adversary, who can adjust the loss function according to the
cumulative switching cost of the player incurred so far based on the orthogonal
technique. We then develop a simple gradient-based algorithm which enjoys the
minimax optimal regret bound. Finally, we show that, for strongly convex
functions, the regret bound can be improved to $O(\log T)$ for $S=\Omega(\log
T)$, and $O(\min\{T/\exp(S)+S,T\})$ for $S=O(\log T)$.
</dc:description>
 <dc:description>Comment: 18 pages, 2 figures</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11370</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11372</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Natural Perturbed Training for General Robustness of Neural Network
  Classifiers</dc:title>
 <dc:creator>Gulshad, Sadaf</dc:creator>
 <dc:creator>Smeulders, Arnold</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We focus on the robustness of neural networks for classification. To permit a
fair comparison between methods to achieve robustness, we first introduce a
standard based on the mensuration of a classifier's degradation. Then, we
propose natural perturbed training to robustify the network. Natural
perturbations will be encountered in practice: the difference of two images of
the same object may be approximated by an elastic deformation (when they have
slightly different viewing angles), by occlusions (when they hide differently
behind objects), or by saturation, Gaussian noise etc. Training some fraction
of the epochs on random versions of such variations will help the classifier to
learn better. We conduct extensive experiments on six datasets of varying sizes
and granularity. Natural perturbed learning show better and much faster
performance than adversarial training on clean, adversarial as well as natural
perturbed images. It even improves general robustness on perturbations not seen
during the training. For Cifar-10 and STL-10 natural perturbed training even
improves the accuracy for clean data and reaches the state of the art
performance. Ablation studies verify the effectiveness of natural perturbed
training.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11372</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11373</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ProgressiveSpinalNet architecture for FC layers</dc:title>
 <dc:creator>Chopra, Praveen</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In deeplearning models the FC (fully connected) layer has biggest important
role for classification of the input based on the learned features from
previous layers. The FC layers has highest numbers of parameters and
fine-tuning these large numbers of parameters, consumes most of the
computational resources, so in this paper it is aimed to reduce these large
numbers of parameters significantly with improved performance. The motivation
is inspired from SpinalNet and other biological architecture. The proposed
architecture has a gradient highway between input to output layers and this
solves the problem of diminishing gradient in deep networks. In this all the
layers receives the input from previous layers as well as the CNN layer output
and this way all layers contribute in decision making with last layer. This
approach has improved classification performance over the SpinalNet
architecture and has SOTA performance on many datasets such as Caltech101,
KMNIST, QMNIST and EMNIST. The source code is available at
https://github.com/praveenchopra/ProgressiveSpinalNet.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11373</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11374</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MaAST: Map Attention with Semantic Transformersfor Efficient Visual
  Navigation</dc:title>
 <dc:creator>Seymour, Zachary</dc:creator>
 <dc:creator>Thopalli, Kowshik</dc:creator>
 <dc:creator>Mithun, Niluthpol</dc:creator>
 <dc:creator>Chiu, Han-Pang</dc:creator>
 <dc:creator>Samarasekera, Supun</dc:creator>
 <dc:creator>Kumar, Rakesh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Visual navigation for autonomous agents is a core task in the fields of
computer vision and robotics. Learning-based methods, such as deep
reinforcement learning, have the potential to outperform the classical
solutions developed for this task; however, they come at a significantly
increased computational load. Through this work, we design a novel approach
that focuses on performing better or comparable to the existing learning-based
solutions but under a clear time/computational budget. To this end, we propose
a method to encode vital scene semantics such as traversable paths, unexplored
areas, and observed scene objects -- alongside raw visual streams such as RGB,
depth, and semantic segmentation masks -- into a semantically informed,
top-down egocentric map representation. Further, to enable the effective use of
this information, we introduce a novel 2-D map attention mechanism, based on
the successful multi-layer Transformer networks. We conduct experiments on 3-D
reconstructed indoor PointGoal visual navigation and demonstrate the
effectiveness of our approach. We show that by using our novel attention schema
and auxiliary rewards to better utilize scene semantics, we outperform multiple
baselines trained with only raw inputs or implicit semantic information while
operating with an 80% decrease in the agent's experience.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures, accepted at ICRA 2021</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11374</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11377</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mining API Interactions to Analyze Software Revisions for the Evolution
  of Energy Consumption</dc:title>
 <dc:creator>Schuler, Andreas</dc:creator>
 <dc:creator>Kotsis, Gabriele</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  With the widespread use and adoption of mobile platforms like Android a new
software quality concern has emerged -- energy consumption. However, developing
energy-efficient software and applications requires knowledge and likewise
proper tooling to support mobile developers. To this aim, we present an
approach to examine the energy evolution of software revisions based on their
API interactions. The approach stems from the assumption that the utilization
of an API has direct implications on the energy being consumed during runtime.
Based on an empirical evaluation, we show initial results that API interactions
serve as a flexible, lightweight, and effective way to compare software
revisions regarding their energy evolution. Given our initial results we
envision that in future using our approach mobile developers will be able to
gain insights on the energy implications of changes in source code in the
course of the software development life-cycle.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11381</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Machine Learning with HQC Architectures using non-Classically
  Simulable Feature Maps</dc:title>
 <dc:creator>Ahmad, Syed Farhan</dc:creator>
 <dc:creator>Rawat, Raghav</dc:creator>
 <dc:creator>Moharir, Minal</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Hybrid Quantum-Classical (HQC) Architectures are used in near-term NISQ
Quantum Computers for solving Quantum Machine Learning problems. The quantum
advantage comes into picture due to the exponential speedup offered over
classical computing. One of the major challenges in implementing such
algorithms is the choice of quantum embeddings and the use of a functionally
correct quantum variational circuit. In this paper, we present an application
of QSVM (Quantum Support Vector Machines) to predict if a person will require
mental health treatment in the tech world in the future using the dataset from
OSMI Mental Health Tech Surveys. We achieve this with non-classically simulable
feature maps and prove that NISQ HQC Architectures for Quantum Machine Learning
can be used alternatively to create good performance models in near-term
real-world applications.
</dc:description>
 <dc:description>Comment: 5 pages, 8 figures</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11384</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Representation based Query-Specific Prototypical Network
  for Few-Shot Image Classification</dc:title>
 <dc:creator>Li, Yaohui</dc:creator>
 <dc:creator>Li, Huaxiong</dc:creator>
 <dc:creator>Chen, Haoxing</dc:creator>
 <dc:creator>Chen, Chunlin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Few-shot image classification aims at recognizing unseen categories with a
small number of labeled training data. Recent metric-based frameworks tend to
represent a support class by a fixed prototype (e.g., the mean of the support
category) and make classification according to the similarities between query
instances and support prototypes. However, discriminative dominant regions may
locate uncertain areas of images and have various scales, which leads to the
misaligned metric. Besides, a fixed prototype for one support category cannot
fit for all query instances to accurately reflect their distances with this
category, which lowers the efficiency of metric. Therefore, query-specific
dominant regions in support samples should be extracted for a high-quality
metric. To address these problems, we propose a Hierarchical Representation
based Query-Specific Prototypical Network (QPN) to tackle the limitations by
generating a region-level prototype for each query sample, which achieves both
positional and dimensional semantic alignment simultaneously. Extensive
experiments conducted on five benchmark datasets (including three fine-grained
datasets) show that our proposed method outperforms the current
state-of-the-art methods.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11384</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11385</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterising Communities of Twitter Users Who Posted Vaccines Related
  Tweets by Information Sources</dc:title>
 <dc:creator>Biswas, Md. Rafiul</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  Objective: We formed community structure based on web page credibility and we
measured the types of information for characterizing communities of tweeter
users who posted about tweets related to vaccine. Methods: We performed the
experiment on only Twitter data (tweets) regarding vaccine. The duration of
data collection was between 17 January 2017 and 14 March 2018. We formulated
cluster based on the information on its contents and sources it resides (i.e.,
website domains). We only focused the topics which were related to vaccine. To
detect the structure and network of community, we applied Louvain community
algorithm along with Random walks called Info map method over vaccines related
tweeter user. We defined the communities based on various measures derived from
the information shared by Twitter users. Representations and visualizations of
the communities based on these derived measures help the public health
organization to make understand the possible cause of the rejecting the safety
and efficacy of vaccines. Results: To analyse people perception over social
media, we downloaded 6,591,566 tweets. We distinguished 1,860,662 users who
were posting related to vaccine. We applied Louvain community detection
algorithm along with DMM values and we found 192 communities. It also produced
higher alignment values as long as the number of topics were low. With the
increase of topics number, the alignment becomes lower. The total tweets were
divided into two parts based on their characterizes. The first category
contained 163,148 (57.16%) tweets which were based as evidence and advocacy and
the second category contained 6244 (2.19%) tweets which were based on the
experiences and opinion. We observed 4548 users were posting about experiential
tweets about vaccine and of them 3449 users (75.84%) were posted evidence and
advocacy related.
</dc:description>
 <dc:description>Comment: 16 pages, 8 figures, 1 table</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11386</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterization and Prediction of Questions without Accepted Answers on
  Stack Overflow</dc:title>
 <dc:creator>Yazdaninia, Mohamad</dc:creator>
 <dc:creator>Lo, David</dc:creator>
 <dc:creator>Sami, Ashkan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  A fast and effective approach to obtain information regarding software
development problems is to search them to find similar solved problems or post
questions on community question answering (CQA) websites. Solving coding
problems in a short time is important, so these CQAs have a considerable impact
on the software development process. However, if developers do not get their
expected answers, the websites will not be useful, and software development
time will increase. Stack Overflow is the most popular CQA concerning
programming problems. According to its rules, the only sign that shows a
question poser has achieved the desired answer is the user's acceptance. In
this paper, we investigate unresolved questions, without accepted answers, on
Stack Overflow. The number of unresolved questions is increasing. As of August
2019, 47% of Stack Overflow questions were unresolved. In this study, we
analyze the effectiveness of various features, including some novel features,
to resolve a question. We do not use the features that contain information not
present at the time of asking a question, such as answers. To evaluate our
features, we deploy several predictive models trained on the features of 18
million questions to predict whether a question will get an accepted answer or
not. The results of this study show a significant relationship between our
proposed features and getting accepted answers. Finally, we introduce an online
tool that predicts whether a question will get an accepted answer or not.
Currently, Stack Overflow's users do not receive any feedback on their
questions before asking them, so they could carelessly ask unclear, unreadable,
or inappropriately tagged questions. By using this tool, they can modify their
questions and tags to check the different results of the tool and deliberately
improve their questions to get accepted answers.
</dc:description>
 <dc:description>Comment: Accepted in the 29th IEEE/ACM International Conference on Program
  Comprehension (ICPC 2021)</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11388</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collaborative Agent Gameplay in the Pandemic Board Game</dc:title>
 <dc:creator>Sfikas, Konstantinos</dc:creator>
 <dc:creator>Liapis, Antonios</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>I.2.1</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  While artificial intelligence has been applied to control players' decisions
in board games for over half a century, little attention is given to games with
no player competition. Pandemic is an exemplar collaborative board game where
all players coordinate to overcome challenges posed by events occurring during
the game's progression. This paper proposes an artificial agent which controls
all players' actions and balances chances of winning versus risk of losing in
this highly stochastic environment. The agent applies a Rolling Horizon
Evolutionary Algorithm on an abstraction of the game-state that lowers the
branching factor and simulates the game's stochasticity. Results show that the
proposed algorithm can find winning strategies more consistently in different
games of varying difficulty. The impact of a number of state evaluation metrics
is explored, balancing between optimistic strategies that favor winning and
pessimistic strategies that guard against losing.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11388</dc:identifier>
 <dc:identifier>Proceedings of the Foundations of Digital Games Conference, 2020</dc:identifier>
 <dc:identifier>doi:10.1145/3402942.3402943</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11392</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Architecture Erosion: The Practitioners' Perceptive</dc:title>
 <dc:creator>Li, Ruiyin</dc:creator>
 <dc:creator>Liang, Peng</dc:creator>
 <dc:creator>Soliman, Mohamed</dc:creator>
 <dc:creator>Avgeriou, Paris</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  As software systems evolve, their architecture is meant to adapt accordingly
by following the changes in requirements, the environment, and the
implementation. However, in practice, the evolving system often deviates from
the architecture, causing severe consequences to system maintenance and
evolution. This phenomenon of architecture erosion has been studied extensively
in research, but not yet been examined from the point of view of developers. In
this exploratory study, we look into how developers perceive the notion of
architecture erosion, its causes and consequences, as well as tools and
practices to identify and control architecture erosion. To this end, we
searched through several popular online developer communities for collecting
data of discussions related to architecture erosion. Besides, we identified
developers involved in these discussions and conducted a survey with 10
participants and held interviews with 4 participants. Our findings show that:
(1) developers either focus on the structural manifestation of architecture
erosion or on its effect on run-time qualities, maintenance and evolution; (2)
alongside technical factors, architecture erosion is caused to a large extent
by non-technical factors; (3) despite the lack of dedicated tools for detecting
architecture erosion, developers usually identify erosion through a number of
symptoms; and (4) there are effective measures that can help to alleviate the
impact of architecture erosion.
</dc:description>
 <dc:description>Comment: The 29th IEEE/ACM International Conference on Program Comprehension
  (ICPC)</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11392</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11393</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating Lower Body Kinematics using a Lie Group Constrained Extended
  Kalman Filter and Reduced IMU Count</dc:title>
 <dc:creator>Sy, Luke Wicent</dc:creator>
 <dc:creator>Lovell, Nigel H.</dc:creator>
 <dc:creator>Redmond, Stephen J.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Goal: This paper presents an algorithm for estimating pelvis, thigh, shank,
and foot kinematics during walking using only two or three wearable inertial
sensors. Methods: The algorithm makes novel use of a Lie-group-based extended
Kalman filter. The algorithm iterates through the prediction (kinematic
equation), measurement (pelvis position pseudo-measurements, zero-velocity
update, and flat-floor assumption), and constraint update (hinged knee and
ankle joints, constant leg lengths). Results: The inertial motion capture
algorithm was extensively evaluated on two datasets showing its performance
against two standard benchmark approaches in optical motion capture (i.e.,
plug-in gait (commonly used in gait analysis) and a kinematic fit (commonly
used in animation, robotics, and musculoskeleton simulation)), giving insight
into the similarity and differences between the said approaches used in
different application areas. The overall mean body segment position (relative
to mid-pelvis origin) and orientation error magnitude of our algorithm ($n=14$
participants) for free walking was $5.93 \pm 1.33$ cm and $13.43 \pm
1.89^\circ$ when using three IMUs placed on the feet and pelvis, and $6.35 \pm
1.20$ cm and $12.71 \pm 1.60^\circ$ when using only two IMUs placed on the
feet. Conclusion: The algorithm was able to track the joint angles in the
sagittal plane for straight walking well, but requires improvement for
unscripted movements (e.g., turning around, side steps), especially for dynamic
movements or when considering clinical applications. Significance: This work
has brought us closer to comprehensive remote gait monitoring using IMUs on the
shoes. The low computational cost also suggests that it can be used in
real-time with gait assistive devices.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11393</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11397</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuous API Evolution in Heterogenous Enterprise Software Systems</dc:title>
 <dc:creator>Knoche, Holger</dc:creator>
 <dc:creator>Hasselbring, Wilhelm</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.2</dc:subject>
 <dc:subject>D.2.7</dc:subject>
 <dc:subject>D.2.11</dc:subject>
 <dc:subject>D.2.12</dc:subject>
 <dc:description>  The ability to independently deploy parts of a software system is one of the
cornerstones of modern software development, and allows for these parts to
evolve independently and at different speeds.
  A major challenge of such independent deployment, however, is to ensure that
despite their individual evolution, the interfaces between interacting parts
remain compatible. This is especially important for enterprise software
systems, which are often highly integrated and based on heterogenous IT
infrastructures.
  Although several approaches for interface evolution have been proposed, many
of these rely on the developer to adhere to certain rules, but provide little
guidance for doing so. In this paper, we present an approach for interface
evolution that is easy to use for developers, and also addresses typical
challenges of heterogenous enterprise software, especially legacy system
integration.
</dc:description>
 <dc:description>Comment: Preprint of a paper to be published at the 18th IEEE International
  Conference on Software Architecture (ICSA 2021)</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11397</dc:identifier>
 <dc:identifier>doi:10.1109/ICSA51549.2021.00014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11401</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SwissDial: Parallel Multidialectal Corpus of Spoken Swiss German</dc:title>
 <dc:creator>Dogan-Sch&#xf6;nberger, Pelin</dc:creator>
 <dc:creator>M&#xe4;der, Julian</dc:creator>
 <dc:creator>Hofmann, Thomas</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Swiss German is a dialect continuum whose natively acquired dialects
significantly differ from the formal variety of the language. These dialects
are mostly used for verbal communication and do not have standard orthography.
This has led to a lack of annotated datasets, rendering the use of many NLP
methods infeasible. In this paper, we introduce the first annotated parallel
corpus of spoken Swiss German across 8 major dialects, plus a Standard German
reference. Our goal has been to create and to make available a basic dataset
for employing data-driven NLP applications in Swiss German. We present our data
collection procedure in detail and validate the quality of our corpus by
conducting experiments with the recent neural models for speech synthesis.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11401</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11402</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Instant-Teaching: An End-to-End Semi-Supervised Object Detection
  Framework</dc:title>
 <dc:creator>Zhou, Qiang</dc:creator>
 <dc:creator>Yu, Chaohui</dc:creator>
 <dc:creator>Wang, Zhibin</dc:creator>
 <dc:creator>Qian, Qi</dc:creator>
 <dc:creator>Li, Hao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Supervised learning based object detection frameworks demand plenty of
laborious manual annotations, which may not be practical in real applications.
Semi-supervised object detection (SSOD) can effectively leverage unlabeled data
to improve the model performance, which is of great significance for the
application of object detection models. In this paper, we revisit SSOD and
propose Instant-Teaching, a completely end-to-end and effective SSOD framework,
which uses instant pseudo labeling with extended weak-strong data augmentations
for teaching during each training iteration. To alleviate the confirmation bias
problem and improve the quality of pseudo annotations, we further propose a
co-rectify scheme based on Instant-Teaching, denoted as Instant-Teaching$^*$.
Extensive experiments on both MS-COCO and PASCAL VOC datasets substantiate the
superiority of our framework. Specifically, our method surpasses
state-of-the-art methods by 4.2 mAP on MS-COCO when using $2\%$ labeled data.
Even with full supervised information of MS-COCO, the proposed method still
outperforms state-of-the-art methods by about 1.0 mAP. On PASCAL VOC, we can
achieve more than 5 mAP improvement by applying VOC07 as labeled data and VOC12
as unlabeled data.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11402</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11405</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Autoregressive Translation by Learning Target Categorical Codes</dc:title>
 <dc:creator>Bao, Yu</dc:creator>
 <dc:creator>Huang, Shujian</dc:creator>
 <dc:creator>Xiao, Tong</dc:creator>
 <dc:creator>Wang, Dongqi</dc:creator>
 <dc:creator>Dai, Xinyu</dc:creator>
 <dc:creator>Chen, Jiajun</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Non-autoregressive Transformer is a promising text generation model. However,
current non-autoregressive models still fall behind their autoregressive
counterparts in translation quality. We attribute this accuracy gap to the lack
of dependency modeling among decoder inputs. In this paper, we propose CNAT,
which learns implicitly categorical codes as latent variables into the
non-autoregressive decoding. The interaction among these categorical codes
remedies the missing dependencies and improves the model capacity. Experiment
results show that our model achieves comparable or better performance in
machine translation tasks, compared with several strong baselines.
</dc:description>
 <dc:description>Comment: 11 pages, 3 figures, 7 tables. Accepted by NAACL-2021</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11405</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11411</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Role of Asymptomatic Carriers in Epidemic Spread Processes</dc:title>
 <dc:creator>Bi, Xiaoqi</dc:creator>
 <dc:creator>Beck, Carolyn L.</dc:creator>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  We present an epidemiological compartment model, SAIR(S), that explicitly
captures the dynamics of asymptomatic infected individuals in an epidemic
spread process. We first present a group model and then discuss networked
versions. We provide an investigation of equilibria and stability properties
for these models, and present simulation results illustrating the effects of
asymptomatic-infected individuals on the spread of the disease. We also discuss
local isolation effects on the epidemic dynamics in terms of the networked
models. Finally, we provide initial parameter estimation results based on
simple least-squares approaches and local test-site data.\par Keywords:
Epidemic dynamics, networks, data-informed modeling, stability analysis,
parameter estimation
</dc:description>
 <dc:description>Comment: 19 Pages</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11411</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11415</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximation, regularization and smoothing of trigonometric splines</dc:title>
 <dc:creator>Denysiuk, V.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  The methods of approximation, regularization and smoothing of trigonometric
interpolation splines are considered in the paper. It is shown that
trigonometric splines can be considered from two points of view - as a
trigonometric Fourier series and as discrete trigonometric Fourier series
according to certain systems of functions that are smoothness carriers. It is
argued that with approximation and smoothing of trigonometric splines it is
expedient to consider as discrete rows, since their differential properties are
stored.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11415</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11424</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Distribution-preserving Incomplete Clustering with Optimal
  Transport</dc:title>
 <dc:creator>Luo, Mingjie</dc:creator>
 <dc:creator>Wang, Siwei</dc:creator>
 <dc:creator>Liu, Xinwang</dc:creator>
 <dc:creator>Tu, Wenxuan</dc:creator>
 <dc:creator>Zhang, Yi</dc:creator>
 <dc:creator>Guo, Xifeng</dc:creator>
 <dc:creator>Zhou, Sihang</dc:creator>
 <dc:creator>Zhu, En</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Clustering is a fundamental task in the computer vision and machine learning
community. Although various methods have been proposed, the performance of
existing approaches drops dramatically when handling incomplete
high-dimensional data (which is common in real world applications). To solve
the problem, we propose a novel deep incomplete clustering method, named Deep
Distribution-preserving Incomplete Clustering with Optimal Transport (DDIC-OT).
To avoid insufficient sample utilization in existing methods limited by few
fully-observed samples, we propose to measure distribution distance with the
optimal transport for reconstruction evaluation instead of traditional
pixel-wise loss function. Moreover, the clustering loss of the latent feature
is introduced to regularize the embedding with more discrimination capability.
As a consequence, the network becomes more robust against missing features and
the unified framework which combines clustering and sample imputation enables
the two procedures to negotiate to better serve for each other. Extensive
experiments demonstrate that the proposed network achieves superior and stable
clustering performance improvement against existing state-of-the-art incomplete
clustering methods over different missing ratios.
</dc:description>
 <dc:description>Comment: Data are provided at
  https://github.com/wangsiwei2010/Single-view-incomplete-datasets-for-deep-clustering</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11424</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11430</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge Discovery in Surveys using Machine Learning: A Case Study of
  Women in Entrepreneurship in UAE</dc:title>
 <dc:creator>Ahmad, Syed Farhan</dc:creator>
 <dc:creator>Hermayen, Amrah</dc:creator>
 <dc:creator>Bhavani, Ganga</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Knowledge Discovery plays a very important role in analyzing data and getting
insights from them to drive better business decisions. Entrepreneurship in a
Knowledge based economy contributes greatly to the development of a country's
economy. In this paper, we analyze surveys that were conducted on women in
entrepreneurship in UAE. Relevant insights are extracted from the data that can
help us to better understand the current landscape of women in entrepreneurship
and predict the future as well. The features are analyzed using machine
learning to drive better business decisions in the future.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11430</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11431</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SEMIE: SEMantically Infused Embeddings with Enhanced Interpretability
  for Domain-specific Small Corpus</dc:title>
 <dc:creator>Gupta, Rishabh</dc:creator>
 <dc:creator>Rao, Rajesh N</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Word embeddings are a basic building block of modern NLP pipelines. Efforts
have been made to learn rich, efficient, and interpretable embeddings for large
generic datasets available in the public domain. However, these embeddings have
limited applicability for small corpora from specific domains such as
automotive, manufacturing, maintenance and support, etc. In this work, we
present a comprehensive notion of interpretability for word embeddings and
propose a novel method to generate highly interpretable and efficient
embeddings for a domain-specific small corpus. We report the evaluation results
of our resulting word embeddings and demonstrate their novel features for
enhanced interpretability.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11436</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Responsible AI: Gender bias assessment in emotion recognition</dc:title>
 <dc:creator>Domnich, Artem</dc:creator>
 <dc:creator>Anbarjafari, Gholamreza</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Rapid development of artificial intelligence (AI) systems amplify many
concerns in society. These AI algorithms inherit different biases from humans
due to mysterious operational flow and because of that it is becoming adverse
in usage. As a result, researchers have started to address the issue by
investigating deeper in the direction towards Responsible and Explainable AI.
Among variety of applications of AI, facial expression recognition might not be
the most important one, yet is considered as a valuable part of human-AI
interaction. Evolution of facial expression recognition from the feature based
methods to deep learning drastically improve quality of such algorithms. This
research work aims to study a gender bias in deep learning methods for facial
expression recognition by investigating six distinct neural networks, training
them, and further analysed on the presence of bias, according to the three
definition of fairness. The main outcomes show which models are gender biased,
which are not and how gender of subject affects its emotion recognition. More
biased neural networks show bigger accuracy gap in emotion recognition between
male and female test sets. Furthermore, this trend keeps for true positive and
false positive rates. In addition, due to the nature of the research, we can
observe which types of emotions are better classified for men and which for
women. Since the topic of biases in facial expression recognition is not well
studied, a spectrum of continuation of this research is truly extensive, and
may comprise detail analysis of state-of-the-art methods, as well as targeting
other biases.
</dc:description>
 <dc:description>Comment: 19 pages, 31 figures</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11437</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Betweenness Centrality Analysis of 30 European Cities</dc:title>
 <dc:creator>Yamaoka, Kaoru</dc:creator>
 <dc:creator>Kumakoshi, Yusuke</dc:creator>
 <dc:creator>Yoshimura, Yuji</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Urban morphology and socioeconomic aspects of cities have been explored by
analysing urban street network. To analyse the network, several variations of
the centrality indices are often used. However, its nature has not yet been
widely studied, thus leading to an absence of robust visualisation method of
urban road network characteristics. To fill this gap, we propose to use a set
of local betweenness centrality and a new simple and robust visualisation
method. By analysing 30 European cities, we found that our method illustrates
common structures of the cities: road segments important for long-distance
transportations are concentrated along larger streets while those for short
range transportations form clusters around CBD, historical, or residential
districts. Quantitative analysis has corroborated these findings. Our findings
are useful for urban planners and decision-makers to understand the current
situation of the city and make informed decisions.
</dc:description>
 <dc:description>Comment: 26 pages, 13 figures. To be appear in CUPUM 2021</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11437</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11439</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Checkpointing and Migration of IoT Edge Functions</dc:title>
 <dc:creator>Karhula, Pekka</dc:creator>
 <dc:creator>Janak, Jan</dc:creator>
 <dc:creator>Schulzrinne, Henning</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The serverless and functions as a service (FaaS) paradigms are currently
trending among cloud providers and are now increasingly being applied to the
network edge, and to the Internet of Things (IoT) devices. The benefits include
reduced latency for communication, less network traffic and increased privacy
for data processing. However, there are challenges as IoT devices have limited
resources for running multiple simultaneous containerized functions, and also
FaaS does not typically support long-running functions. Our implementation
utilizes Docker and CRIU for checkpointing and suspending long-running blocking
functions. The results show that checkpointing is slightly slower than regular
Docker pause, but it saves memory and allows for more long-running functions to
be run on an IoT device. Furthermore, the resulting checkpoint files are small,
hence they are suitable for live migration and backing up stateful functions,
therefore improving availability and reliability of the system.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11439</dc:identifier>
 <dc:identifier>EdgeSys '19: Proceedings of the 2nd International Workshop on Edge
  Systems, Analytics and Networking, March 2019</dc:identifier>
 <dc:identifier>doi:10.1145/3301418.3313947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11445</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph Transformation and Specialized Code Generation For Sparse
  Triangular Solve (SpTRSV)</dc:title>
 <dc:creator>Yilmaz, Buse</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Sparse Triangular Solve (SpTRSV) is an important computational kernel used in
the solution of sparse linear algebra systems in many scientific and
engineering applications. It is diffcult to parallelize SpTRSV in today's
architectures. The limited parallelism due to the dependencies between
calculations and the irregular nature of the computations require an effective
load balancing and synchronization mechanism approach. In this work, we present
a novel graph transformation method where the equation representing a row is
rewritten to break the dependencies. Using this approach, we propose a
dependency graph transformation and code generation framework that increases
the parallelism of the parts of a sparse matrix where it is scarce, reducing
the need for synchronization points. In addition, the proposed framework
generates specialized code for the transformed dependency graph on CPUs using
domain-specific optimizations.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11445</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11446</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Code Smell Detection via Code Review: A Study of the
  OpenStack Community</dc:title>
 <dc:creator>Han, Xiaofeng</dc:creator>
 <dc:creator>Tahir, Amjed</dc:creator>
 <dc:creator>Liang, Peng</dc:creator>
 <dc:creator>Counsell, Steve</dc:creator>
 <dc:creator>Luo, Yajing</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Code review plays an important role in software quality control. A typical
review process would involve a careful check of a piece of code in an attempt
to find defects and other quality issues/violations. One type of issues that
may impact the quality of the software is code smells - i.e., bad programming
practices that may lead to defects or maintenance issues. Yet, little is known
about the extent to which code smells are identified during code reviews. To
investigate the concept behind code smells identified in code reviews and what
actions reviewers suggest and developers take in response to the identified
smells, we conducted an empirical study of code smells in code reviews using
the two most active OpenStack projects (Nova and Neutron). We manually checked
19,146 review comments obtained by keywords search and random selection, and
got 1,190 smell-related reviews to study the causes of code smells and actions
taken against the identified smells. Our analysis found that 1) code smells
were not commonly identified in code reviews, 2) smells were usually caused by
violation of coding conventions, 3) reviewers usually provided constructive
feedback, including fixing (refactoring) recommendations to help developers
remove smells, and 4) developers generally followed those recommendations and
actioned the changes. Our results suggest that 1) developers should closely
follow coding conventions in their projects to avoid introducing code smells,
and 2) review-based detection of code smells is perceived to be a trustworthy
approach by developers, mainly because reviews are context-sensitive (as
reviewers are more aware of the context of the code given that they are part of
the project's development team).
</dc:description>
 <dc:description>Comment: The 29th IEEE/ACM International Conference on Program Comprehension
  (ICPC)</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11446</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11453</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RAID: Tool Support for Refactoring-Aware Code Reviews</dc:title>
 <dc:creator>Brito, Rodrigo</dc:creator>
 <dc:creator>Valente, Marco Tulio</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Code review is a key development practice that contributes to improve
software quality and to foster knowledge sharing among developers. However,
code review usually takes time and demands detailed and time-consuming analysis
of textual diffs. Particularly, detecting refactorings during code reviews is
not a trivial task, since they are not explicitly represented in diffs. For
example, a Move Function refactoring is represented by deleted (-) and added
lines (+) of code which can be located in different and distant source code
files. To tackle this problem, we introduce RAID, a refactoring-aware and
intelligent diff tool. Besides proposing an architecture for RAID, we
implemented a Chrome browser plug-in that supports our solution. Then, we
conducted a field experiment with eight professional developers who used RAID
for three months. We concluded that RAID can reduce the cognitive effort
required for detecting and reviewing refactorings in textual diff. Besides
documenting refactorings in diffs, RAID reduces the number of lines required
for reviewing such operations. For example, the median number of lines to be
reviewed decreases from 14.5 to 2 lines in the case of move refactorings and
from 113 to 55 lines in the case of extractions.
</dc:description>
 <dc:description>Comment: Accepted at 29th IEEE/ACM International Conference on Program
  Comprehension (ICPC), 11 pages, 2021</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11453</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11456</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Set-Theoretic Learning for Detection in Cell-Less C-RAN Systems</dc:title>
 <dc:creator>Awan, Daniyal Amir</dc:creator>
 <dc:creator>Cavalcante, Renato L. G.</dc:creator>
 <dc:creator>Utkovski, Zoran</dc:creator>
 <dc:creator>Stanczak, Slawomir</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Cloud-radio access network (C-RAN) can enable cell-less operation by
connecting distributed remote radio heads (RRHs) via fronthaul links to a
powerful central unit. In conventional C-RAN, baseband signals are forwarded
after quantization/ compression to the central unit for centralized processing
to keep the complexity of the RRHs low. However, the limited capacity of the
fronthaul is thought to be a significant bottleneck in the ability of C-RAN to
support large systems (e.g. massive machine-type communications (mMTC)).
Therefore, in contrast to the conventional C-RAN, we propose a learning-based
system in which the detection is performed locally at each RRH and only the
likelihood information is conveyed to the CU. To this end, we develop a general
set-theoretic learningmethod to estimate likelihood functions. The method can
be used to extend existing detection methods to the C-RAN setting.
</dc:description>
 <dc:description>Comment: Published in 2018 IEEE Global Conference on Signal and Information
  Processing (GlobalSIP)</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11456</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11459</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Support Vector Regression Parameters Optimization using Golden Sine
  Algorithm and its application in stock market</dc:title>
 <dc:creator>Ghanbari, Mohammadreza</dc:creator>
 <dc:creator>Goldani, Mahdi</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Quantitative Finance - Computational Finance</dc:subject>
 <dc:description>  Support vector machine modeling is a new approach in machine learning for
classification showing good performance on forecasting problems of small
samples and high dimensions. Later, it promoted to Support Vector Regression
(SVR) for regression problems. A big challenge for achieving reliable is the
choice of appropriate parameters. Here, a novel Golden sine algorithm (GSA)
based SVR is proposed for proper selection of the parameters. For comparison,
the performance of the proposed algorithm is compared with eleven other
meta-heuristic algorithms on some historical stock prices of technological
companies from Yahoo Finance website based on Mean Squared Error and Mean
Absolute Percent Error. The results demonstrate that the given algorithm is
efficient for tuning the parameters and is indeed competitive in terms of
accuracy and computing time.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11460</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>UAV Images Dataset for Moving Object Detection from Moving Cameras</dc:title>
 <dc:creator>Delibasoglu, Ibrahim</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  This paper presents a new high resolution aerial images dataset in which
moving objects are labelled manually. It aims to contribute to the evaluation
of the moving object detection methods for moving cameras. The problem of
recognizing moving objects from aerial images is one of the important issues in
computer vision. The biggest problem in the images taken by UAV is that the
background is constantly variable due to camera movement. There are various
datasets in the literature in which proposed methods for motion detection are
evaluated. Prepared dataset consists of challenging images containing small
targets compared to other datasets. Two methods in the literature have been
tested for the prepared dataset. In addition, a simpler method compared to
these methods has been proposed for moving object object in this paper.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11460</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11467</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Cell-Load Learning with a Small Sample Set</dc:title>
 <dc:creator>Awan, Daniyal Amir</dc:creator>
 <dc:creator>Cavalcante, Renato L. G.</dc:creator>
 <dc:creator>Stanczak, Slawomir</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Learning of the cell-load in radio access networks (RANs) has to be performed
within a short time period. Therefore, we propose a learning framework that is
robust against uncertainties resulting from the need for learning based on a
relatively small training sample set. To this end, we incorporate prior
knowledge about the cell-load in the learning framework. For example, an
inherent property of the cell-load is that it is monotonic in downlink (data)
rates. To obtain additional prior knowledge we first study the feasible rate
region, i.e., the set of all vectors of user rates that can be supported by the
network. We prove that the feasible rate region is compact. Moreover, we show
the existence of a Lipschitz function that maps feasible rate vectors to
cell-load vectors. With these results in hand, we present a learning technique
that guarantees a minimum approximation error in the worst-case scenario by
using prior knowledge and a small training sample set. Simulations in the
network simulator NS3 demonstrate that the proposed method exhibits better
robustness and accuracy than standard multivariate learning techniques,
especially for small training sample sets.
</dc:description>
 <dc:description>Comment: Published in IEEE Transactions on Signal Processing ( Volume: 68)</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11467</dc:identifier>
 <dc:identifier>IEEE Transactions on Signal Processing, Volume 68, 2020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11471</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conditional Generative Adversarial Networks for Speed Control in
  Trajectory Simulation</dc:title>
 <dc:creator>Julka, Sahib</dc:creator>
 <dc:creator>Sowrirajan, Vishal</dc:creator>
 <dc:creator>Schloetterer, Joerg</dc:creator>
 <dc:creator>Granitzer, Michael</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Motion behaviour is driven by several factors -- goals, presence and actions
of neighbouring agents, social relations, physical and social norms, the
environment with its variable characteristics, and further. Most factors are
not directly observable and must be modelled from context. Trajectory
prediction, is thus a hard problem, and has seen increasing attention from
researchers in the recent years. Prediction of motion, in application, must be
realistic, diverse and controllable. In spite of increasing focus on multimodal
trajectory generation, most methods still lack means for explicitly controlling
different modes of the data generation. Further, most endeavours invest heavily
in designing special mechanisms to learn the interactions in latent space. We
present Conditional Speed GAN (CSG), that allows controlled generation of
diverse and socially acceptable trajectories, based on user controlled speed.
During prediction, CSG forecasts future speed from latent space and conditions
its generation based on it. CSG is comparable to state-of-the-art GAN methods
in terms of the benchmark distance metrics, while being simple and useful for
simulation and data augmentation for different contexts such as fast or slow
paced environments. Additionally, we compare the effect of different
aggregation mechanisms and show that a naive approach of concatenation works
comparable to its attention and pooling alternatives.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11471</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11481</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How do we Evaluate Self-adaptive Software Systems?</dc:title>
 <dc:creator>Gerostathopoulos, Ilias</dc:creator>
 <dc:creator>Vogel, Thomas</dc:creator>
 <dc:creator>Weyns, Danny</dc:creator>
 <dc:creator>Lago, Patricia</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  With the increase of research in self-adaptive systems, there is a need to
better understand the way research contributions are evaluated. Such insights
will support researchers to better compare new findings when developing new
knowledge for the community. However, so far there is no clear overview of how
evaluations are performed in self-adaptive systems. To address this gap, we
conduct a mapping study. The study focuses on experimental evaluations
published in the last decade at the prime venue of research in software
engineering for self-adaptive systems -- the International Symposium on
Software Engineering for Adaptive and Self-Managing Systems (SEAMS). Results
point out that specifics of self-adaptive systems require special attention in
the experimental process, including the distinction of the managing system
(i.e., the target of evaluation) and the managed system, the presence of
uncertainties that affect the system behavior and hence need to be taken into
account in data analysis, and the potential of managed systems to be reused
across experiments, beyond replications. To conclude, we offer a set of
suggestions derived from our study that can be used as input to enhance future
experiments in self-adaptive systems.
</dc:description>
 <dc:description>Comment: Accepted at the 16th International Symposium on Software Engineering
  for Adaptive and Self-Managing Systems (SEAMS 2021)</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11485</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Occupancy-Driven Stochastic Decision Framework for Ranking Commercial
  Building Loads</dc:title>
 <dc:creator>Jain, Milan</dc:creator>
 <dc:creator>Kundu, Soumya</dc:creator>
 <dc:creator>Bhattacharya, Arnab</dc:creator>
 <dc:creator>Huang, Sen</dc:creator>
 <dc:creator>Chandan, Vikas</dc:creator>
 <dc:creator>Radhakrishnan, Nikitha</dc:creator>
 <dc:creator>Adetola, Veronica</dc:creator>
 <dc:creator>Vrabie, Draguna</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  For effective integration of building operations into the evolving demand
response programs of the power grid, real-time decisions concerning the use of
building appliances for grid services must excel on multiple criteria, ranging
from the added value to occupants' comfort to the quality of the grid services.
In this paper, we present a data-driven decision-support framework to
dynamically rank load control alternatives in a commercial building, addressing
the needs of multiple decision criteria (e.g. occupant comfort, grid service
quality) under uncertainties in occupancy patterns. We adopt a stochastic
multi-criteria decision algorithm recently applied to prioritize residential
on/off loads, and extend it to i) complex load control decisions (e.g. dimming
of lights, changing zone temperature set-points) in a commercial building; and
ii) systematic integration of zonal occupancy patterns to accurately identify
short-term grid service opportunities. We evaluate the performance of the
framework for curtailment of air-conditioning, lighting, and plug-loads in a
multi-zone office building for a range of design choices. With the help of a
prototype system that integrates an interactive \textit{Data Analytics and
Visualization} frontend, we demonstrate a way for the building operators to
monitor the flexibility in energy consumption and to develop trust in the
decision recommendations by interpreting the rationale behind the ranking.
</dc:description>
 <dc:description>Comment: accepted in the 2021 American Control Conference</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11485</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11486</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Experiences on Managing Technical Debt with Code Smells and AntiPatterns</dc:title>
 <dc:creator>Lahti, Jacinto Ramirez</dc:creator>
 <dc:creator>Tuovinen, Antti-Pekka</dc:creator>
 <dc:creator>Mikkonen, Tommi</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Technical debt has become a common metaphor for the accumulation of software
design and implementation choices that seek fast initial gains but that are
under par and counterproductive in the long run. However, as a metaphor,
technical debt does not offer actionable advice on how to get rid of it. To get
to a practical level in solving problems, more focused mechanisms are needed.
Commonly used approaches for this include identifying code smells as quick
indications of possible problems in the codebase and detecting the presence of
AntiPatterns that refer to overt, recurring problems in design. There are known
remedies for both code smells and AntiPatterns. In paper, our goal is to show
how to effectively use common tools and the existing body of knowledge on code
smells and AntiPatterns to detect technical debt and pay it back. We present
two main results: (i) How a combination of static code analysis and manual
inspection was used to detect code smells in a codebase leading to the
discovery of AntiPatterns; and (ii) How AntiPatterns were used to identify,
characterize, and fix problems in the software. The experiences stem from a
private company and its long-lasting software product development effort.
</dc:description>
 <dc:description>Comment: Accepted at the 4th International Conference on Technical Debt
  (TechDebt 2021)</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11486</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11489</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>UCB-based Algorithms for Multinomial Logistic Regression Bandits</dc:title>
 <dc:creator>Amani, Sanae</dc:creator>
 <dc:creator>Thrampoulidis, Christos</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Out of the rich family of generalized linear bandits, perhaps the most well
studied ones are logisitc bandits that are used in problems with binary
rewards: for instance, when the learner/agent tries to maximize the profit over
a user that can select one of two possible outcomes (e.g., `click' vs
`no-click'). Despite remarkable recent progress and improved algorithms for
logistic bandits, existing works do not address practical situations where the
number of outcomes that can be selected by the user is larger than two (e.g.,
`click', `show me later', `never show again', `no click'). In this paper, we
study such an extension. We use multinomial logit (MNL) to model the
probability of each one of $K+1\geq 2$ possible outcomes (+1 stands for the
`not click' outcome): we assume that for a learner's action $\mathbf{x}_t$, the
user selects one of $K+1\geq 2$ outcomes, say outcome $i$, with a multinomial
logit (MNL) probabilistic model with corresponding unknown parameter
$\bar{\boldsymbol\theta}_{\ast i}$. Each outcome $i$ is also associated with a
revenue parameter $\rho_i$ and the goal is to maximize the expected revenue.
For this problem, we present MNL-UCB, an upper confidence bound (UCB)-based
algorithm, that achieves regret $\tilde{\mathcal{O}}(dK\sqrt{T})$ with small
dependency on problem-dependent constants that can otherwise be arbitrarily
large and lead to loose regret bounds. We present numerical simulations that
corroborate our theoretical results.
</dc:description>
 <dc:description>Comment: 27 pages, 5 figures</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11489</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11491</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Potential Gap: Using Reactive Policies to Guarantee Safe Navigation</dc:title>
 <dc:creator>Xu, Ruoyang</dc:creator>
 <dc:creator>Feng, Shiyu</dc:creator>
 <dc:creator>Vela, Patricio A.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper considers the integration of gap-based local navigation methods
with artificial potential field (APF) methods to derive a local planning module
for hierarchical navigation systems that has provable collision-free
properties. Given that APF theory applies to idealized robot models, the
provable properties are lost when applied to more realistic models. We describe
a set of algorithm modifications that correct for these errors and enhance
robustness to non-ideal models. Central to the construction of the local
planner is the use of sensory-derived local free-space models that detect gaps
and use them for the synthesis of the APF. Modifications are given for a
nonholonomic robot model. Integration of the local planner, called potential
gap, into a hierarchical navigation system provides the local goals and
trajectories needed for collision-free navigation through unknown environments.
Monte Carlo experiments in benchmark worlds confirm the asserted safety and
robustness properties by testing under various robot models.
</dc:description>
 <dc:description>Comment: Submitted to RA-L with IROS 2021 option</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11491</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11505</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Policy-Guided Heuristic Search with Guarantees</dc:title>
 <dc:creator>Orseau, Laurent</dc:creator>
 <dc:creator>Lelis, Levi H. S.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The use of a policy and a heuristic function for guiding search can be quite
effective in adversarial problems, as demonstrated by AlphaGo and its
successors, which are based on the PUCT search algorithm. While PUCT can also
be used to solve single-agent deterministic problems, it lacks guarantees on
its search effort and it can be computationally inefficient in practice.
Combining the A* algorithm with a learned heuristic function tends to work
better in these domains, but A* and its variants do not use a policy. Moreover,
the purpose of using A* is to find solutions of minimum cost, while we seek
instead to minimize the search loss (e.g., the number of search steps). LevinTS
is guided by a policy and provides guarantees on the number of search steps
that relate to the quality of the policy, but it does not make use of a
heuristic function. In this work we introduce Policy-guided Heuristic Search
(PHS), a novel search algorithm that uses both a heuristic function and a
policy and has theoretical guarantees on the search loss that relates to both
the quality of the heuristic and of the policy. We show empirically on the
sliding-tile puzzle, Sokoban, and a puzzle from the commercial game `The
Witness' that PHS enables the rapid learning of both a policy and a heuristic
function and compares favorably with A*, Weighted A*, Greedy Best-First Search,
LevinTS, and PUCT in terms of number of problems solved and search time in all
three domains tested.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11505</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11516</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Homophily Outlier Detection in Non-IID Categorical Data</dc:title>
 <dc:creator>Pang, Guansong</dc:creator>
 <dc:creator>Cao, Longbing</dc:creator>
 <dc:creator>Chen, Ling</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Most of existing outlier detection methods assume that the outlier factors
(i.e., outlierness scoring measures) of data entities (e.g., feature values and
data objects) are Independent and Identically Distributed (IID). This
assumption does not hold in real-world applications where the outlierness of
different entities is dependent on each other and/or taken from different
probability distributions (non-IID). This may lead to the failure of detecting
important outliers that are too subtle to be identified without considering the
non-IID nature. The issue is even intensified in more challenging contexts,
e.g., high-dimensional data with many noisy features. This work introduces a
novel outlier detection framework and its two instances to identify outliers in
categorical data by capturing non-IID outlier factors. Our approach first
defines and incorporates distribution-sensitive outlier factors and their
interdependence into a value-value graph-based representation. It then models
an outlierness propagation process in the value graph to learn the outlierness
of feature values. The learned value outlierness allows for either direct
outlier detection or outlying feature selection. The graph representation and
mining approach is employed here to well capture the rich non-IID
characteristics. Our empirical results on 15 real-world data sets with
different levels of data complexities show that (i) the proposed outlier
detection methods significantly outperform five state-of-the-art methods at the
95%/99% confidence level, achieving 10%-28% AUC improvement on the 10 most
complex data sets; and (ii) the proposed feature selection methods
significantly outperform three competing methods in enabling subsequent outlier
detection of two different existing detectors.
</dc:description>
 <dc:description>Comment: To appear in Data Ming and Knowledge Discovery Journal</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11516</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11518</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Empirical Study of OSS-Fuzz Bugs</dc:title>
 <dc:creator>Ding, Zhen Yu</dc:creator>
 <dc:creator>Goues, Claire Le</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Continuous fuzzing is an increasingly popular technique for automated quality
and security assurance. Google maintains OSS-Fuzz: a continuous fuzzing service
for open source software. We conduct the first empirical study of OSS-Fuzz,
analyzing 23,907 bugs found in 316 projects. We examine the characteristics of
fuzzer-found faults, the lifecycles of such faults, and the evolution of
fuzzing campaigns over time. We find that OSS-Fuzz is often effective at
quickly finding bugs, and developers are often quick to patch them. However,
flaky bugs, timeouts, and out of memory errors are problematic, people rarely
file CVEs for security vulnerabilities, and fuzzing campaigns often exhibit
punctuated equilibria, where developers might be surprised by large spikes in
bugs found. Our findings have implications on future fuzzing research and
practice.
</dc:description>
 <dc:description>Comment: 12 pages; accepted at the 2021 IEEE/ACM 18th International Conference
  on Mining Software Repositories (MSR)</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11518</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11519</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Improving the Trustworthiness of Hardware based Malware Detector
  using Online Uncertainty Estimation</dc:title>
 <dc:creator>Kumar, Harshit</dc:creator>
 <dc:creator>Chawla, Nikhil</dc:creator>
 <dc:creator>Mukhopadhyay, Saibal</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Hardware-based Malware Detectors (HMDs) using Machine Learning (ML) models
have shown promise in detecting malicious workloads. However, the conventional
black-box based machine learning (ML) approach used in these HMDs fail to
address the uncertain predictions, including those made on zero-day malware.
The ML models used in HMDs are agnostic to the uncertainty that determines
whether the model &quot;knows what it knows,&quot; severely undermining its
trustworthiness. We propose an ensemble-based approach that quantifies
uncertainty in predictions made by ML models of an HMD, when it encounters an
unknown workload than the ones it was trained on. We test our approach on two
different HMDs that have been proposed in the literature. We show that the
proposed uncertainty estimator can detect &gt;90% of unknown workloads for the
Power-management based HMD, and conclude that the overlapping benign and
malware classes undermine the trustworthiness of the Performance Counter-based
HMD.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11519</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11522</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-directional Bicycle Robot for Steel Structure Inspection</dc:title>
 <dc:creator>Nguyen, Son Thanh</dc:creator>
 <dc:creator>Nguyen, Hai</dc:creator>
 <dc:creator>Bui, Son Tien</dc:creator>
 <dc:creator>Ho, Van Anh</dc:creator>
 <dc:creator>La, Hung Manh</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents a novel design of a multi-directional bicycle robot,
which targets inspecting general ferromagnetic structures including
complex-shaped structures. The locomotion concept is based on arranging two
magnetic wheels in a bicycle-like configuration with two independent steering
actuators. This configuration allows the robot to possess multi-directional
mobility. An additional free joint helps the robot naturally adapt to non-flat
and complex surfaces of steel structures. The robot has the biggest advantage
to be mechanically simple with high mobility. Besides, the robot is equipped
with sensing tools for structure health monitoring. We demonstrate the
deployment of our robot to perform steel rust detection on steel bridges. The
final inspection results are visualized as 3D models of the bridges together
with marked locations of detected rusty areas.
</dc:description>
 <dc:description>Comment: Under review at IROS 2021</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11522</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11526</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ExAD: An Ensemble Approach for Explanation-based Adversarial Detection</dc:title>
 <dc:creator>Vardhan, Raj</dc:creator>
 <dc:creator>Liu, Ninghao</dc:creator>
 <dc:creator>Chinprutthiwong, Phakpoom</dc:creator>
 <dc:creator>Fu, Weijie</dc:creator>
 <dc:creator>Hu, Zhenyu</dc:creator>
 <dc:creator>Hu, Xia Ben</dc:creator>
 <dc:creator>Gu, Guofei</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Recent research has shown Deep Neural Networks (DNNs) to be vulnerable to
adversarial examples that induce desired misclassifications in the models. Such
risks impede the application of machine learning in security-sensitive domains.
Several defense methods have been proposed against adversarial attacks to
detect adversarial examples at test time or to make machine learning models
more robust. However, while existing methods are quite effective under blackbox
threat model, where the attacker is not aware of the defense, they are
relatively ineffective under whitebox threat model, where the attacker has full
knowledge of the defense.
  In this paper, we propose ExAD, a framework to detect adversarial examples
using an ensemble of explanation techniques. Each explanation technique in ExAD
produces an explanation map identifying the relevance of input variables for
the model's classification. For every class in a dataset, the system includes a
detector network, corresponding to each explanation technique, which is trained
to distinguish between normal and abnormal explanation maps. At test time, if
the explanation map of an input is detected as abnormal by any detector model
of the classified class, then we consider the input to be an adversarial
example. We evaluate our approach using six state-of-the-art adversarial
attacks on three image datasets. Our extensive evaluation shows that our
mechanism can effectively detect these attacks under blackbox threat model with
limited false-positives. Furthermore, we find that our approach achieves
promising results in limiting the success rate of whitebox attacks.
</dc:description>
 <dc:description>Comment: 15 pages, 10 figures</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11526</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11534</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Models to Reduce Test Cases in Software Repositories</dc:title>
 <dc:creator>Gharachorlu, Golnaz</dc:creator>
 <dc:creator>Sumner, Nick</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Given a failing test case, test case reduction yields a smaller test case
that reproduces the failure. This process can be time consuming due to repeated
trial and error with smaller test cases. Current techniques speed up reduction
by only exploring syntactically valid candidates, but they still spend
significant effort on semantically invalid candidates. In this paper, we
propose a model-guided approach to speed up test case reduction. The approach
trains a model of semantic properties driven by syntactic test case properties.
By using this model, we can skip testing even syntactically valid test case
candidates that are unlikely to succeed. We evaluate this model-guided
reduction on a suite of 14 large fuzzer-generated C test cases from the bug
repositories of two well-known C compilers, GCC and Clang. Our results show
that with an average precision of 77%, we can decrease the number of removal
trials by 14% to 61%. We observe a 30% geomean improvement in reduction time
over the state of the art technique while preserving similar reduction power.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11534</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11537</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to Design Sample and Computationally Efficient VQA Models</dc:title>
 <dc:creator>Samel, Karan</dc:creator>
 <dc:creator>Zhao, Zelin</dc:creator>
 <dc:creator>Chen, Binghong</dc:creator>
 <dc:creator>Wang, Kuan</dc:creator>
 <dc:creator>Luo, Robin</dc:creator>
 <dc:creator>Song, Le</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In multi-modal reasoning tasks, such as visual question answering (VQA),
there have been many modeling and training paradigms tested. Previous models
propose different methods for the vision and language tasks, but which ones
perform the best while being sample and computationally efficient? Based on our
experiments, we find that representing the text as probabilistic programs and
images as object-level scene graphs best satisfy these desiderata. We extend
existing models to leverage these soft programs and scene graphs to train on
question answer pairs in an end-to-end manner. Empirical results demonstrate
that this differentiable end-to-end program executor is able to maintain
state-of-the-art accuracy while being sample and computationally efficient.
</dc:description>
 <dc:description>Comment: 20 pages, 5 figures</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11537</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11542</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smart Scheduling based on Deep Reinforcement Learning for Cellular
  Networks</dc:title>
 <dc:creator>Wang, Jian</dc:creator>
 <dc:creator>Xu, Chen</dc:creator>
 <dc:creator>Li, Rong</dc:creator>
 <dc:creator>Ge, Yiqun</dc:creator>
 <dc:creator>Wang, Jun</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  To improve the system performance towards the Shannon limit, advanced radio
resource management mechanisms play a fundamental role. In particular,
scheduling should receive much attention, because it allocates radio resources
among different users in terms of their channel conditions and QoS
requirements. The difficulties of scheduling algorithms are the tradeoffs need
to be made among multiple objectives, such as throughput, fairness and packet
drop rate. We propose a smart scheduling scheme based on deep reinforcement
learning (DRL). We not only verify the performance gain achieved, but also
provide implementation-friend designs, i.e., a scalable neural network design
for the agent and a virtual environment training framework. With the scalable
neural network design, the DRL agent can easily handle the cases when the
number of active users is time-varying without the need to redesign and retrain
the DRL agent. Training the DRL agent in a virtual environment offline first
and using it as the initial version in the practical usage helps to prevent the
system from suffering from performance and robustness degradation due to the
time-consuming training. Through both simulations and field tests, we show that
the DRL-based smart scheduling outperforms the conventional scheduling method
and can be adopted in practical systems.
</dc:description>
 <dc:description>Comment: 14 figures, submitted to a journal for possible publication</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11542</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11544</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal convergence rate of modified Milstein scheme for SDEs with rough
  fractional diffusions</dc:title>
 <dc:creator>Huang, Chuying</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We combine the rough path theory and stochastic backward error analysis to
develop a new framework for error analysis on numerical schemes. Based on our
approach, we prove that the almost sure convergence rate of the modified
Milstein scheme for stochastic differential equations driven by multiplicative
multidimensional fractional Brownian motion with Hurst parameter
$H\in(\frac14,\frac12)$ is $(2H-\frac12)^-$ for sufficiently smooth
coefficients, which is optimal in the sense that it is consistent with the
result of the corresponding implementable approximation of the L\'evy area of
fractional Brownian motion. Our result gives a positive answer to the
conjecture proposed in [11] for the case $H\in(\frac13,\frac12)$, and reveals
for the first time that numerical schemes constructed by a second-order Taylor
expansion do converge for the case $H\in(\frac14,\frac13]$.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11544</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11551</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>QoS-Constrained Federated Learning Empowered by Intelligent Reflecting
  Surface</dc:title>
 <dc:creator>Zheng, Jingheng</dc:creator>
 <dc:creator>Ni, Wanli</dc:creator>
 <dc:creator>Tian, Hui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper investigates the model aggregation process in an over-the-air
federated learning (AirFL) system, where an intelligent reflecting surface
(IRS) is deployed to assist the transmission from users to the base station
(BS). With the purpose of overcoming the absence of the security examination
against malicious individuals, successive interference cancellation (SIC) is
adopted as a basis to support analyzing statistic characteristics of model
parameters from devices. The objective of this paper is to minimize the
mean-square-error by jointly optimizing the receive beamforming vector at the
BS, transmit power allocation at users, and phase shift matrix of the IRS,
subject to the transmit power constraint for devices, unit-modulus constraint
for reflecting elements, SIC decoding order constraint and quality-of-service
constraint. To address this complicated problem, alternating optimization is
employed to decompose it into three subproblems, where the optimal receive
beamforming vector is obtained by solving the first subproblem with the
Lagrange dual method. Then, the convex relaxation method is applied to the
transmit power allocation subproblem to find a suboptimal solution. Eventually,
the phase shift matrix subproblem is addressed by invoking the semidefinite
relaxation. Simulation results validate the availability of IRS and the
effectiveness of the proposed scheme in improving federated learning
performance.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11551</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11554</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ISTA-Net++: Flexible Deep Unfolding Network for Compressive Sensing</dc:title>
 <dc:creator>You, Di</dc:creator>
 <dc:creator>Xie, Jingfen</dc:creator>
 <dc:creator>Zhang, Jian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  While deep neural networks have achieved impressive success in image
compressive sensing (CS), most of them lack flexibility when dealing with
multi-ratio tasks and multi-scene images in practical applications. To tackle
these challenges, we propose a novel end-to-end flexible ISTA-unfolding deep
network, dubbed ISTA-Net++, with superior performance and strong flexibility.
Specifically, by developing a dynamic unfolding strategy, our model enjoys the
adaptability of handling CS problems with different ratios, i.e., multi-ratio
tasks, through a single model. A cross-block strategy is further utilized to
reduce blocking artifacts and enhance the CS recovery quality. Furthermore, we
adopt a balanced dataset for training, which brings more robustness when
reconstructing images of multiple scenes. Extensive experiments on four
datasets show that ISTA-Net++ achieves state-of-the-art results in terms of
both quantitative metrics and visual quality. Considering its flexibility,
effectiveness and practicability, our model is expected to serve as a suitable
baseline in future CS research. The source code is available on
https://github.com/jianzhangcs/ISTA-Netpp.
</dc:description>
 <dc:description>Comment: ICME 2021 ORAL accepted</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11554</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11555</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Context-aware Biaffine Localizing Network for Temporal Sentence
  Grounding</dc:title>
 <dc:creator>Liu, Daizong</dc:creator>
 <dc:creator>Qu, Xiaoye</dc:creator>
 <dc:creator>Dong, Jianfeng</dc:creator>
 <dc:creator>Zhou, Pan</dc:creator>
 <dc:creator>Cheng, Yu</dc:creator>
 <dc:creator>Wei, Wei</dc:creator>
 <dc:creator>Xu, Zichuan</dc:creator>
 <dc:creator>Xie, Yulai</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper addresses the problem of temporal sentence grounding (TSG), which
aims to identify the temporal boundary of a specific segment from an untrimmed
video by a sentence query. Previous works either compare pre-defined candidate
segments with the query and select the best one by ranking, or directly regress
the boundary timestamps of the target segment. In this paper, we propose a
novel localization framework that scores all pairs of start and end indices
within the video simultaneously with a biaffine mechanism. In particular, we
present a Context-aware Biaffine Localizing Network (CBLN) which incorporates
both local and global contexts into features of each start/end position for
biaffine-based localization. The local contexts from the adjacent frames help
distinguish the visually similar appearance, and the global contexts from the
entire video contribute to reasoning the temporal relation. Besides, we also
develop a multi-modal self-attention module to provide fine-grained
query-guided video representation for this biaffine strategy. Extensive
experiments show that our CBLN significantly outperforms state-of-the-arts on
three public datasets (ActivityNet Captions, TACoS, and Charades-STA),
demonstrating the effectiveness of the proposed localization framework.
</dc:description>
 <dc:description>Comment: Accepted by CVPR 2021</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11555</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11558</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weighted Neural Tangent Kernel: A Generalized and Improved
  Network-Induced Kernel</dc:title>
 <dc:creator>Tan, Lei</dc:creator>
 <dc:creator>Wu, Shutong</dc:creator>
 <dc:creator>Huang, Xiaolin</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The Neural Tangent Kernel (NTK) has recently attracted intense study, as it
describes the evolution of an over-parameterized Neural Network (NN) trained by
gradient descent. However, it is now well-known that gradient descent is not
always a good optimizer for NNs, which can partially explain the unsatisfactory
practical performance of the NTK regression estimator. In this paper, we
introduce the Weighted Neural Tangent Kernel (WNTK), a generalized and improved
tool, which can capture an over-parameterized NN's training dynamics under
different optimizers. Theoretically, in the infinite-width limit, we prove: i)
the stability of the WNTK at initialization and during training, and ii) the
equivalence between the WNTK regression estimator and the corresponding NN
estimator with different learning rates on different parameters. With the
proposed weight update algorithm, both empirical and analytical WNTKs
outperform the corresponding NTKs in numerical experiments.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11559</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Provably Correct Optimization and Exploration with Non-linear Policies</dc:title>
 <dc:creator>Feng, Fei</dc:creator>
 <dc:creator>Yin, Wotao</dc:creator>
 <dc:creator>Agarwal, Alekh</dc:creator>
 <dc:creator>Yang, Lin F.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Policy optimization methods remain a powerful workhorse in empirical
Reinforcement Learning (RL), with a focus on neural policies that can easily
reason over complex and continuous state and/or action spaces. Theoretical
understanding of strategic exploration in policy-based methods with non-linear
function approximation, however, is largely missing. In this paper, we address
this question by designing ENIAC, an actor-critic method that allows non-linear
function approximation in the critic. We show that under certain assumptions,
e.g., a bounded eluder dimension $d$ for the critic class, the learner finds a
near-optimal policy in $O(\poly(d))$ exploration rounds. The method is robust
to model misspecification and strictly extends existing works on linear
function approximation. We also develop some computational optimizations of our
approach with slightly worse statistical guarantees and an empirical adaptation
building on existing deep RL tools. We empirically evaluate this adaptation and
show that it outperforms prior heuristics inspired by linear methods,
establishing the value via correctly reasoning about the agent's uncertainty
under non-linear function approximation.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11561</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ConfInLog: Leveraging Software Logs to Infer Configuration Constraints</dc:title>
 <dc:creator>Zhou, Shulin</dc:creator>
 <dc:creator>Liu, Xiaodong</dc:creator>
 <dc:creator>Li, Shanshan</dc:creator>
 <dc:creator>Jia, Zhouyang</dc:creator>
 <dc:creator>Zhang, Yuanliang</dc:creator>
 <dc:creator>Wang, Teng</dc:creator>
 <dc:creator>Li, Wang</dc:creator>
 <dc:creator>Liao, Xiangke</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Misconfigurations have become the dominant causes of software failures in
recent years, drawing tremendous attention for their increasing prevalence and
severity. Configuration constraints can preemptively avoid misconfiguration by
defining the conditions that configuration options should satisfy.
Documentation is the main source of configuration constraints, but it might be
incomplete or inconsistent with the source code. In this regard, prior
researches have focused on obtaining configuration constraints from software
source code through static analysis. However, the difficulty in pointer
analysis and context comprehension prevents them from collecting accurate and
comprehensive constraints. In this paper, we observed that software logs often
contain configuration constraints. We conducted an empirical study and
summarized patterns of configuration-related log messages. Guided by the study,
we designed and implemented ConfInLog, a static tool to infer configuration
constraints from log messages. ConfInLog first selects configuration-related
log messages from source code by using the summarized patterns, then infers
constraints from log messages based on the summarized natural language
patterns. To evaluate the effectiveness of ConfInLog, we applied our tool on
seven popular open-source software systems. ConfInLog successfully inferred 22
to 163 constraints, in which 59.5% to 61.6% could not be inferred by the
state-of-the-art work. Finally, we submitted 67 documentation patches regarding
the constraints inferred by ConfInLog. The constraints in 29 patches have been
confirmed by the developers, among which 10 patches have been accepted.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11561</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11562</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RadarLoc: Learning to Relocalize in FMCW Radar</dc:title>
 <dc:creator>Wang, Wei</dc:creator>
 <dc:creator>de Gusmo, Pedro P. B.</dc:creator>
 <dc:creator>Yang, Bo</dc:creator>
 <dc:creator>Markham, Andrew</dc:creator>
 <dc:creator>Trigoni, Niki</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Relocalization is a fundamental task in the field of robotics and computer
vision. There is considerable work in the field of deep camera relocalization,
which directly estimates poses from raw images. However, learning-based methods
have not yet been applied to the radar sensory data. In this work, we
investigate how to exploit deep learning to predict global poses from Emerging
Frequency-Modulated Continuous Wave (FMCW) radar scans. Specifically, we
propose a novel end-to-end neural network with self-attention, termed RadarLoc,
which is able to estimate 6-DoF global poses directly. We also propose to
improve the localization performance by utilizing geometric constraints between
radar scans. We validate our approach on the recently released challenging
outdoor dataset Oxford Radar RobotCar. Comprehensive experiments demonstrate
that the proposed method outperforms radar-based localization and deep camera
relocalization methods by a significant margin.
</dc:description>
 <dc:description>Comment: To appear in ICRA 2021</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11562</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11565</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Switching Controller Synthesis for Delay Hybrid Systems under
  Perturbations</dc:title>
 <dc:creator>Bai, Yunjun</dc:creator>
 <dc:creator>Gan, Ting</dc:creator>
 <dc:creator>Jiao, Li</dc:creator>
 <dc:creator>Xia, Bican</dc:creator>
 <dc:creator>Xue, Bai</dc:creator>
 <dc:creator>Zhan, Naijun</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Delays are ubiquitous in modern hybrid systems, which exhibit both continuous
and discrete dynamical behaviors. Induced by signal transmission, conversion,
the nature of plants, and so on, delays may appear either in the continuous
evolution of a hybrid system such that the evolution depends not only on the
present state but also on its execution history, or in the discrete switching
between its different control modes. In this paper we come up with a new model
of hybrid systems, called \emph{delay hybrid automata}, to capture the dynamics
of systems with the aforementioned two kinds of delays. Furthermore, based upon
this model we study the robust switching controller synthesis problem such that
the controlled delay system is able to satisfy the specified safety properties
regardless of perturbations. To the end, a novel method is proposed to
synthesize switching controllers based on the computation of differential
invariants for continuous evolution and backward reachable sets of discrete
jumps with delays. Finally, we implement a prototypical tool of our approach
and demonstrate it on some case studies.
</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11565</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11571</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Lumigraph Rendering</dc:title>
 <dc:creator>Kellnhofer, Petr</dc:creator>
 <dc:creator>Jebe, Lars</dc:creator>
 <dc:creator>Jones, Andrew</dc:creator>
 <dc:creator>Spicer, Ryan</dc:creator>
 <dc:creator>Pulli, Kari</dc:creator>
 <dc:creator>Wetzstein, Gordon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Novel view synthesis is a challenging and ill-posed inverse rendering
problem. Neural rendering techniques have recently achieved photorealistic
image quality for this task. State-of-the-art (SOTA) neural volume rendering
approaches, however, are slow to train and require minutes of inference (i.e.,
rendering) time for high image resolutions. We adopt high-capacity neural scene
representations with periodic activations for jointly optimizing an implicit
surface and a radiance field of a scene supervised exclusively with posed 2D
images. Our neural rendering pipeline accelerates SOTA neural volume rendering
by about two orders of magnitude and our implicit surface representation is
unique in allowing us to export a mesh with view-dependent texture information.
Thus, like other implicit surface representations, ours is compatible with
traditional graphics pipelines, enabling real-time rendering rates, while
achieving unprecedented image quality compared to other surface methods. We
assess the quality of our approach using existing datasets as well as
high-quality 3D face data captured with a custom multi-camera rig.
</dc:description>
 <dc:description>Comment: Project website:
  http://www.computationalimaging.org/publications/nlr/</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11571</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11574</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-agent Aerial Monitoring of Moving Convoys using Elliptical Orbits</dc:title>
 <dc:creator>Borkar, Aseem Vivek</dc:creator>
 <dc:creator>Chowdhary, Girish</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  We propose a novel scheme for surveillance of a dynamic ground convoy moving
along a non-linear trajectory, by aerial agents that maintain a uniformly
spaced formation on a time-varying elliptical orbit encompassing the convoy.
Elliptical orbits are used as they are more economical than circular orbits for
circumnavigating the group of targets in the moving convoy. The proposed scheme
includes an algorithm for computing feasible elliptical orbits, a vector
guidance law for agent motion along the desired orbit, and a cooperative
strategy to control the speeds of the aerial agents in order to quickly achieve
and maintain the desired formation. It achieves mission objectives while
accounting for linear and angular speed constraints on the aerial agents. The
scheme is validated through simulations and actual experiments with a convoy of
ground robots and a team of quadrotors as the aerial agents, in a motion
capture environment.
</dc:description>
 <dc:description>Comment: This is the extended version of the paper with same title published
  in International Conference on Robotics and Automation (ICRA) 2021</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11574</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11576</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grey-box Adversarial Attack And Defence For Sentiment Classification</dc:title>
 <dc:creator>Xu, Ying</dc:creator>
 <dc:creator>Zhong, Xu</dc:creator>
 <dc:creator>Yepes, Antonio Jimeno</dc:creator>
 <dc:creator>Lau, Jey Han</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We introduce a grey-box adversarial attack and defence framework for
sentiment classification. We address the issues of differentiability, label
preservation and input reconstruction for adversarial attack and defence in one
unified framework. Our results show that once trained, the attacking model is
capable of generating high-quality adversarial examples substantially faster
(one order of magnitude less in time) than state-of-the-art attacking methods.
These examples also preserve the original sentiment according to human
evaluation. Additionally, our framework produces an improved classifier that is
robust in defending against multiple adversarial attacking methods. Code is
available at: https://github.com/ibm-aur-nlp/adv-def-text-dist.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11576</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11586</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Thomson's Multitaper Method Revisited</dc:title>
 <dc:creator>Karnik, Santhosh</dc:creator>
 <dc:creator>Romberg, Justin</dc:creator>
 <dc:creator>Davenport, Mark A.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>62-08, 62G05</dc:subject>
 <dc:description>  Thomson's multitaper method estimates the power spectrum of a signal from $N$
equally spaced samples by averaging $K$ tapered periodograms. Discrete prolate
spheroidal sequences (DPSS) are used as tapers since they provide excellent
protection against spectral leakage. Thomson's multitaper method is widely used
in applications, but most of the existing theory is qualitative or asymptotic.
Furthermore, many practitioners use a DPSS bandwidth $W$ and number of tapers
that are smaller than what the theory suggests is optimal because the
computational requirements increase with the number of tapers. We revisit
Thomson's multitaper method from a linear algebra perspective involving
subspace projections. This provides additional insight and helps us establish
nonasymptotic bounds on some statistical properties of the multitaper spectral
estimate, which are similar to existing asymptotic results. We show using
$K=2NW-O(\log(NW))$ tapers instead of the traditional $2NW-O(1)$ tapers better
protects against spectral leakage, especially when the power spectrum has a
high dynamic range. Our perspective also allows us to derive an
$\epsilon$-approximation to the multitaper spectral estimate which can be
evaluated on a grid of frequencies using $O(\log(NW)\log\tfrac{1}{\epsilon})$
FFTs instead of $K=O(NW)$ FFTs. This is useful in problems where many samples
are taken, and thus, using many tapers is desirable.
</dc:description>
 <dc:description>Comment: 39 pages, 7 figures</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11586</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11587</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Brain Image Synthesis with Unsupervised Multivariate Canonical
  CSC$\ell_4$Net</dc:title>
 <dc:creator>Huang, Yawen</dc:creator>
 <dc:creator>Zheng, Feng</dc:creator>
 <dc:creator>Wang, Danyang</dc:creator>
 <dc:creator>Huang, Weilin</dc:creator>
 <dc:creator>Scott, Matthew R.</dc:creator>
 <dc:creator>Shao, Ling</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Recent advances in neuroscience have highlighted the effectiveness of
multi-modal medical data for investigating certain pathologies and
understanding human cognition. However, obtaining full sets of different
modalities is limited by various factors, such as long acquisition times, high
examination costs and artifact suppression. In addition, the complexity, high
dimensionality and heterogeneity of neuroimaging data remains another key
challenge in leveraging existing randomized scans effectively, as data of the
same modality is often measured differently by different machines. There is a
clear need to go beyond the traditional imaging-dependent process and
synthesize anatomically specific target-modality data from a source input. In
this paper, we propose to learn dedicated features that cross both intre- and
intra-modal variations using a novel CSC$\ell_4$Net. Through an initial
unification of intra-modal data in the feature maps and multivariate canonical
adaptation, CSC$\ell_4$Net facilitates feature-level mutual transformation. The
positive definite Riemannian manifold-penalized data fidelity term further
enables CSC$\ell_4$Net to reconstruct missing measurements according to
transformed features. Finally, the maximization $\ell_4$-norm boils down to a
computationally efficient optimization problem. Extensive experiments validate
the ability and robustness of our CSC$\ell_4$Net compared to the
state-of-the-art methods on multiple datasets.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures CVPR2021 oral</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11587</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11588</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comprehensive process-molten pool relations modeling using CNN for
  wire-feed laser additive manufacturing</dc:title>
 <dc:creator>Jamnikar, Noopur</dc:creator>
 <dc:creator>Liu, Sen</dc:creator>
 <dc:creator>Brice, Craig</dc:creator>
 <dc:creator>Zhang, Xiaoli</dc:creator>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Wire-feed laser additive manufacturing (WLAM) is gaining wide interest due to
its high level of automation, high deposition rates, and good quality of
printed parts. In-process monitoring and feedback controls that would reduce
the uncertainty in the quality of the material are in the early stages of
development. Machine learning promises the ability to accelerate the adoption
of new processes and property design in additive manufacturing by making
process-structure-property connections between process setting inputs and
material quality outcomes. The molten pool dimensional information and
temperature are the indicators for achieving the high quality of the build,
which can be directly controlled by processing parameters. For the purpose of
in situ quality control, the process parameters should be controlled in
real-time based on sensed information from the process, in particular the
molten pool. Thus, the molten pool-process relations are of preliminary
importance. This paper analyzes experimentally collected in situ sensing data
from the molten pool under a set of controlled process parameters in a WLAM
system. The variations in the steady-state and transient state of the molten
pool are presented with respect to the change of independent process
parameters. A multi-modality convolutional neural network (CNN) architecture is
proposed for predicting the control parameter directly from the measurable
molten pool sensor data for achieving desired geometric and microstructural
properties. Dropout and regularization are applied to the CNN architecture to
avoid the problem of overfitting. The results highlighted that the multi-modal
CNN, which receives temperature profile as an external feature to the features
extracted from the image data, has improved prediction performance compared to
the image-based uni-modality CNN approach.
</dc:description>
 <dc:description>Comment: 23 pages</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11588</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11589</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarially Optimized Mixup for Robust Classification</dc:title>
 <dc:creator>Bunk, Jason</dc:creator>
 <dc:creator>Chattopadhyay, Srinjoy</dc:creator>
 <dc:creator>Manjunath, B. S.</dc:creator>
 <dc:creator>Chandrasekaran, Shivkumar</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Mixup is a procedure for data augmentation that trains networks to make
smoothly interpolated predictions between datapoints. Adversarial training is a
strong form of data augmentation that optimizes for worst-case predictions in a
compact space around each data-point, resulting in neural networks that make
much more robust predictions. In this paper, we bring these ideas together by
adversarially probing the space between datapoints, using projected gradient
descent (PGD). The fundamental approach in this work is to leverage
backpropagation through the mixup interpolation during training to optimize for
places where the network makes unsmooth and incongruous predictions.
Additionally, we also explore several modifications and nuances, like
optimization of the mixup ratio and geometrical label assignment, and discuss
their impact on enhancing network robustness. Through these ideas, we have been
able to train networks that robustly generalize better; experiments on CIFAR-10
and CIFAR-100 demonstrate consistent improvements in accuracy against strong
adversaries, including the recent strong ensemble attack AutoAttack. Our source
code would be released for reproducibility.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11589</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11590</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Delving into Variance Transmission and Normalization: Shift of Average
  Gradient Makes the Network Collapse</dc:title>
 <dc:creator>Liu, Yuxiang</dc:creator>
 <dc:creator>Ge, Jidong</dc:creator>
 <dc:creator>Li, Chuanyi</dc:creator>
 <dc:creator>Gui, Jie</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Normalization operations are essential for state-of-the-art neural networks
and enable us to train a network from scratch with a large learning rate (LR).
We attempt to explain the real effect of Batch Normalization (BN) from the
perspective of variance transmission by investigating the relationship between
BN and Weights Normalization (WN). In this work, we demonstrate that the
problem of the shift of the average gradient will amplify the variance of every
convolutional (conv) layer. We propose Parametric Weights Standardization
(PWS), a fast and robust to mini-batch size module used for conv filters, to
solve the shift of the average gradient. PWS can provide the speed-up of BN.
Besides, it has less computation and does not change the output of a conv
layer. PWS enables the network to converge fast without normalizing the
outputs. This result enhances the persuasiveness of the shift of the average
gradient and explains why BN works from the perspective of variance
transmission. The code and appendix will be made available on
https://github.com/lyxzzz/PWSConv.
</dc:description>
 <dc:description>Comment: This paper has been accepted by AAAI21</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11590</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11596</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monolingual and Parallel Corpora for Kangri Low Resource Language</dc:title>
 <dc:creator>Chauhan, Shweta</dc:creator>
 <dc:creator>Saxena, Shefali</dc:creator>
 <dc:creator>Daniel, Philemon</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper we present the dataset of Himachali low resource endangered
language, Kangri (ISO 639-3xnr) listed in the United Nations Educational,
Scientific and Cultural Organization (UNESCO). The compilation of kangri corpus
has been a challenging task due to the non-availability of the digitalized
resources. The corpus contains 1,81,552 Monolingual and 27,362 Hindi-Kangri
Parallel corpora. We shared pre-trained kangri word embeddings. We also
reported the Bilingual Evaluation Understudy (BLEU) score and Metric for
Evaluation of Translation with Explicit ORdering (METEOR) score of Statistical
Machine Translation (SMT) and Neural Machine Translation (NMT) results for the
corpus. The corpus is freely available for non-commercial usages and research.
To the best of our knowledge, this is the first Himachali low resource
endangered language corpus. The resources are available at
(https://github.com/chauhanshweta/Kangri_corpus)
</dc:description>
 <dc:description>Comment: 7 pages, 6 Tables, 1 Figure</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11597</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human De-occlusion: Invisible Perception and Recovery for Humans</dc:title>
 <dc:creator>Zhou, Qiang</dc:creator>
 <dc:creator>Wang, Shiyin</dc:creator>
 <dc:creator>Wang, Yitong</dc:creator>
 <dc:creator>Huang, Zilong</dc:creator>
 <dc:creator>Wang, Xinggang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we tackle the problem of human de-occlusion which reasons
about occluded segmentation masks and invisible appearance content of humans.
In particular, a two-stage framework is proposed to estimate the invisible
portions and recover the content inside. For the stage of mask completion, a
stacked network structure is devised to refine inaccurate masks from a general
instance segmentation model and predict integrated masks simultaneously.
Additionally, the guidance from human parsing and typical pose masks are
leveraged to bring prior information. For the stage of content recovery, a
novel parsing guided attention module is applied to isolate body parts and
capture context information across multiple scales. Besides, an Amodal Human
Perception dataset (AHP) is collected to settle the task of human de-occlusion.
AHP has advantages of providing annotations from real-world scenes and the
number of humans is comparatively larger than other amodal perception datasets.
Based on this dataset, experiments demonstrate that our method performs over
the state-of-the-art techniques in both tasks of mask completion and content
recovery. Our AHP dataset is available at
\url{https://sydney0zq.github.io/ahp/}.
</dc:description>
 <dc:description>Comment: 11 pages, 6 figures, conference</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11597</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11598</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Degradation Process with Deep Learning-Driven Trajectory</dc:title>
 <dc:creator>Yang, Li</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Remaining useful life (RUL) estimation is a crucial component in the
implementation of intelligent predictive maintenance and health management.
Deep neural network (DNN) approaches have been proven effective in RUL
estimation due to their capacity in handling high-dimensional non-linear
degradation features. However, the applications of DNN in practice face two
challenges: (a) online update of lifetime information is often unavailable, and
(b) uncertainties in predicted values may not be analytically quantified. This
paper addresses these issues by developing a hybrid DNN-based prognostic
approach, where a Wiener-based-degradation model is enhanced with adaptive
drift to characterize the system degradation. An LSTM-CNN encoder-decoder is
developed to predict future degradation trajectories by jointly learning noise
coefficients as well as drift coefficients, and adaptive drift is updated via
Bayesian inference. A computationally efficient algorithm is proposed for the
calculation of RUL distributions. Numerical experiments are presented using
turbofan engines degradation data to demonstrate the superior accuracy of RUL
prediction of our proposed approach.
</dc:description>
 <dc:description>Comment: This work will be submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11598</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11599</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Project-Level Encoding for Neural Source Code Summarization of
  Subroutines</dc:title>
 <dc:creator>Bansal, Aakash</dc:creator>
 <dc:creator>Haque, Sakib</dc:creator>
 <dc:creator>McMillan, Collin</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Source code summarization of a subroutine is the task of writing a short,
natural language description of that subroutine. The description usually serves
in documentation aimed at programmers, where even brief phrase (e.g.
&quot;compresses data to a zip file&quot;) can help readers rapidly comprehend what a
subroutine does without resorting to reading the code itself. Techniques based
on neural networks (and encoder-decoder model designs in particular) have
established themselves as the state-of-the-art. Yet a problem widely recognized
with these models is that they assume the information needed to create a
summary is present within the code being summarized itself - an assumption
which is at odds with program comprehension literature. Thus a current research
frontier lies in the question of encoding source code context into neural
models of summarization. In this paper, we present a project-level encoder to
improve models of code summarization. By project-level, we mean that we create
a vectorized representation of selected code files in a software project, and
use that representation to augment the encoder of state-of-the-art neural code
summarization techniques. We demonstrate how our encoder improves several
existing models, and provide guidelines for maximizing improvement while
controlling time and resource costs in model size.
</dc:description>
 <dc:description>Comment: 10 pages + 2 for references. Accepted at ICPC 2021</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11599</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11600</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PriorityCut: Occlusion-guided Regularization for Warp-based Image
  Animation</dc:title>
 <dc:creator>Cheung, Wai Ting</dc:creator>
 <dc:creator>Chae, Gyeongsu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Image animation generates a video of a source image following the motion of a
driving video. State-of-the-art self-supervised image animation approaches warp
the source image according to the motion of the driving video and recover the
warping artifacts by inpainting. These approaches mostly use vanilla
convolution for inpainting, and vanilla convolution does not distinguish
between valid and invalid pixels. As a result, visual artifacts are still
noticeable after inpainting. CutMix is a state-of-the-art regularization
strategy that cuts and mixes patches of images and is widely studied in
different computer vision tasks. Among the remaining computer vision tasks,
warp-based image animation is one of the fields that the effects of CutMix have
yet to be studied. This paper first presents a preliminary study on the effects
of CutMix on warp-based image animation. We observed in our study that CutMix
helps improve only pixel values, but disturbs the spatial relationships between
pixels. Based on such observation, we propose PriorityCut, a novel augmentation
approach that uses the top-k percent occluded pixels of the foreground to
regularize warp-based image animation. By leveraging the domain knowledge in
warp-based image animation, PriorityCut significantly reduces the warping
artifacts in state-of-the-art warp-based image animation models on diverse
datasets.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11600</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11603</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Alleviate Exposure Bias in Sequence Prediction \\ with Recurrent Neural
  Networks</dc:title>
 <dc:creator>Yuan, Liping</dc:creator>
 <dc:creator>Feng, Jiangtao</dc:creator>
 <dc:creator>Zheng, Xiaoqing</dc:creator>
 <dc:creator>Huang, Xuanjing</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  A popular strategy to train recurrent neural networks (RNNs), known as
``teacher forcing'' takes the ground truth as input at each time step and makes
the later predictions partly conditioned on those inputs. Such training
strategy impairs their ability to learn rich distributions over entire
sequences because the chosen inputs hinders the gradients back-propagating to
all previous states in an end-to-end manner. We propose a fully differentiable
training algorithm for RNNs to better capture long-term dependencies by
recovering the probability of the whole sequence. The key idea is that at each
time step, the network takes as input a ``bundle'' of similar words predicted
at the previous step instead of a single ground truth. The representations of
these similar words forms a convex hull, which can be taken as a kind of
regularization to the input. Smoothing the inputs by this way makes the whole
process trainable and differentiable. This design makes it possible for the
model to explore more feasible combinations (possibly unseen sequences), and
can be interpreted as a computationally efficient approximation to the beam
search. Experiments on multiple sequence generation tasks yield performance
improvements, especially in sequence-level metrics, such as BLUE or ROUGE-2.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11603</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11610</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>psc2code: Denoising Code Extraction from Programming Screencasts</dc:title>
 <dc:creator>Bao, Lingfeng</dc:creator>
 <dc:creator>Xing, Zhenchang</dc:creator>
 <dc:creator>Xia, Xin</dc:creator>
 <dc:creator>Lo, David</dc:creator>
 <dc:creator>Wu, Minghui</dc:creator>
 <dc:creator>Yang, Xiaohu</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In this paper, we propose an approach named psc2code to denoise the process
of extracting source code from programming screencasts. First, psc2code
leverages the Convolutional Neural Network based image classification to remove
non-code and noisy-code frames. Then, psc2code performs edge detection and
clustering-based image segmentation to detect sub-windows in a code frame, and
based on the detected sub-windows, it identifies and crops the screen region
that is most likely to be a code editor. Finally, psc2code calls the API of a
professional OCR tool to extract source code from the cropped code regions and
leverages the OCRed cross-frame information in the programming screencast and
the statistical language model of a large corpus of source code to correct
errors in the OCRed source code.
  We conduct an experiment on 1,142 programming screencasts from YouTube. We
find that our CNN-based image classification technique can effectively remove
the non-code and noisy-code frames, which achieves an F1-score of 0.95 on the
valid code frames. Based on the source code denoised by psc2code, we implement
two applications: 1) a programming screencast search engine; 2) an
interaction-enhanced programming screencast watching tool. Based on the source
code extracted from the 1,142 collected programming screencasts, our
experiments show that our programming screencast search engine achieves the
precision@5, 10, and 20 of 0.93, 0.81, and 0.63, respectively.
</dc:description>
 <dc:description>Comment: pre-print TOSEM paper for ICSE 2021</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11610</dc:identifier>
 <dc:identifier>ACM Trans. Softw. Eng. Methodol. 29, 3, Article 21 (July 2020), 38
  pages</dc:identifier>
 <dc:identifier>doi:10.1145/3392093</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11611</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational quantum compiling with double Q-learning</dc:title>
 <dc:creator>He, Zhimin</dc:creator>
 <dc:creator>Li, Lvzhou</dc:creator>
 <dc:creator>Zheng, Shenggen</dc:creator>
 <dc:creator>Li, Yongyao</dc:creator>
 <dc:creator>Situ, Haozhen</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Quantum compiling aims to construct a quantum circuit V by quantum gates
drawn from a native gate alphabet, which is functionally equivalent to the
target unitary U. It is a crucial stage for the running of quantum algorithms
on noisy intermediate-scale quantum (NISQ) devices. However, the space for
structure exploration of quantum circuit is enormous, resulting in the
requirement of human expertise, hundreds of experimentations or modifications
from existing quantum circuits. In this paper, we propose a variational quantum
compiling (VQC) algorithm based on reinforcement learning (RL), in order to
automatically design the structure of quantum circuit for VQC with no human
intervention. An agent is trained to sequentially select quantum gates from the
native gate alphabet and the qubits they act on by double Q-learning with
\epsilon-greedy exploration strategy and experience replay. At first, the agent
randomly explores a number of quantum circuits with different structures, and
then iteratively discovers structures with higher performance on the learning
task. Simulation results show that the proposed method can make exact
compilations with less quantum gates compared to previous VQC algorithms. It
can reduce the errors of quantum algorithms due to decoherence process and gate
noise in NISQ devices, and enable quantum algorithms especially for complex
algorithms to be executed within coherence time.
</dc:description>
 <dc:description>Comment: 21 pages, 10 figures</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11611</dc:identifier>
 <dc:identifier>New J. Phys. 23 (2021) 033002</dc:identifier>
 <dc:identifier>doi:10.1088/1367-2630/abe0ae</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11619</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Server Averaging for Federated Learning</dc:title>
 <dc:creator>Pu, George</dc:creator>
 <dc:creator>Zhou, Yanlin</dc:creator>
 <dc:creator>Wu, Dapeng</dc:creator>
 <dc:creator>Li, Xiaolin</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Federated learning allows distributed devices to collectively train a model
without sharing or disclosing the local dataset with a central server. The
global model is optimized by training and averaging the model parameters of all
local participants. However, the improved privacy of federated learning also
introduces challenges including higher computation and communication costs. In
particular, federated learning converges slower than centralized training. We
propose the server averaging algorithm to accelerate convergence. Sever
averaging constructs the shared global model by periodically averaging a set of
previous global models. Our experiments indicate that server averaging not only
converges faster, to a target accuracy, than federated averaging (FedAvg), but
also reduces the computation costs on the client-level through epoch decay.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11622</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Progressive and Aligned Pose Attention Transfer for Person Image
  Generation</dc:title>
 <dc:creator>Zhu, Zhen</dc:creator>
 <dc:creator>Huang, Tengteng</dc:creator>
 <dc:creator>Xu, Mengde</dc:creator>
 <dc:creator>Shi, Baoguang</dc:creator>
 <dc:creator>Cheng, Wenqing</dc:creator>
 <dc:creator>Bai, Xiang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a new generative adversarial network for pose transfer,
i.e., transferring the pose of a given person to a target pose. We design a
progressive generator which comprises a sequence of transfer blocks. Each block
performs an intermediate transfer step by modeling the relationship between the
condition and the target poses with attention mechanism. Two types of blocks
are introduced, namely Pose-Attentional Transfer Block (PATB) and Aligned
Pose-Attentional Transfer Bloc ~(APATB). Compared with previous works, our
model generates more photorealistic person images that retain better appearance
consistency and shape consistency compared with input images. We verify the
efficacy of the model on the Market-1501 and DeepFashion datasets, using
quantitative and qualitative measures. Furthermore, we show that our method can
be used for data augmentation for the person re-identification task,
alleviating the issue of data insufficiency. Code and pretrained models are
available at https://github.com/tengteng95/Pose-Transfer.git.
</dc:description>
 <dc:description>Comment: Accepted by TPAMI. An extension of the conference version. Conference
  version at arXiv:1904.03349</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11622</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11623</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Transmitter Coded Caching Networks with Transmitter-side Knowledge
  of File Popularity</dc:title>
 <dc:creator>Lampiris, Eleftherios</dc:creator>
 <dc:creator>Serbetci, Berksan</dc:creator>
 <dc:creator>Spyropoulos, Thrasyvoulos</dc:creator>
 <dc:creator>Caire, Giuseppe</dc:creator>
 <dc:creator>Elia, Petros</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This work presents a new way of exploiting non-uniform file popularity in
coded caching networks. Focusing on a fully-connected fully-interfering
wireless setting with multiple cache-enabled transmitters and receivers, we
show how non-uniform file popularity can be used very efficiently to accelerate
the impact of transmitter-side data redundancy on receiver-side coded caching.
This approach is motivated by the recent discovery that, under any realistic
file-size constraint, having content appear in multiple transmitters can in
fact dramatically boost the speed-up factor attributed to coded caching.
  We formulate an optimization problem that exploits file popularity to
optimize the placement of files at the transmitters. We then provide a proof
that reduces significantly the variable search space, and propose a new search
algorithm that solves the problem at hand. We also prove an analytical
performance upper bound, which is in fact met by our algorithm in the regime of
many receivers. Our work reflects the benefits of allocating higher cache
redundancy to more popular files, but also reflects a law of diminishing
returns where for example very popular files may in fact benefit from minimum
redundancy. In the end, this work reveals that in the context of coded caching,
employing multiple transmitters can be a catalyst in fully exploiting file
popularity, as it avoids various asymmetry complications that appear when file
popularity is used to alter the receiver-side cache placement.
</dc:description>
 <dc:description>Comment: 14 pages, submitted to Transactions on Networking</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11623</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11624</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multimodal Motion Prediction with Stacked Transformers</dc:title>
 <dc:creator>Liu, Yicheng</dc:creator>
 <dc:creator>Zhang, Jinghuai</dc:creator>
 <dc:creator>Fang, Liangji</dc:creator>
 <dc:creator>Jiang, Qinhong</dc:creator>
 <dc:creator>Zhou, Bolei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Predicting multiple plausible future trajectories of the nearby vehicles is
crucial for the safety of autonomous driving. Recent motion prediction
approaches attempt to achieve such multimodal motion prediction by implicitly
regularizing the feature or explicitly generating multiple candidate proposals.
However, it remains challenging since the latent features may concentrate on
the most frequent mode of the data while the proposal-based methods depend
largely on the prior knowledge to generate and select the proposals. In this
work, we propose a novel transformer framework for multimodal motion
prediction, termed as mmTransformer. A novel network architecture based on
stacked transformers is designed to model the multimodality at feature level
with a set of fixed independent proposals. A region-based training strategy is
then developed to induce the multimodality of the generated proposals.
Experiments on Argoverse dataset show that the proposed model achieves the
state-of-the-art performance on motion prediction, substantially improving the
diversity and the accuracy of the predicted trajectories. Demo video and code
are available at https://decisionforce.github.io/mmTransformer.
</dc:description>
 <dc:description>Comment: CVPR2021</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11625</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Volumetric Objectives for Multi-Robot Exploration of Three-Dimensional
  Environments</dc:title>
 <dc:creator>Corah, Micah</dc:creator>
 <dc:creator>Michael, Nathan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Volumetric objectives for exploration and perception tasks seek to capture a
sense of value (or reward) for hypothetical observations at one or more camera
views for robots operating in unknown environments. For example, a volumetric
objective may reward robots proportionally to the expected volume of unknown
space to be observed. We identify connections between existing
information-theoretic and coverage objectives in terms of expected coverage,
particularly that mutual information without noise is a special case of
expected coverage. Likewise, we provide the first comparison, of which we are
aware, between information-based approximations and coverage objectives for
exploration, and we find, perhaps surprisingly, that coverage objectives can
significantly outperform information-based objectives in practice.
Additionally, the analysis for information and coverage objectives demonstrates
that Randomized Sequential Partitions -- a method for efficient distributed
sensor planning -- applies for both classes of objectives, and we provide
simulation results in a variety of environments for as many as 32 robots.
</dc:description>
 <dc:description>Comment: 8 pages, accepted to ICRA'21</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11625</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11630</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Processing of k-regret Minimization Queries with Theoretical
  Guarantees</dc:title>
 <dc:creator>Zheng, Jiping</dc:creator>
 <dc:creator>Dong, Qi</dc:creator>
 <dc:creator>Wang, Xiaoyang</dc:creator>
 <dc:creator>Zhang, Ying</dc:creator>
 <dc:creator>Ma, Wei</dc:creator>
 <dc:creator>Ma, Yuan</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Assisting end users to identify desired results from a large dataset is an
important problem for multi-criteria decision making. To address this problem,
top-k and skyline queries have been widely adopted, but they both have inherent
drawbacks, i.e., the user either has to provide a specific utility function or
faces many results. The k-regret minimization query is proposed, which
integrates the merits of top-k and skyline queries. Due to the NP-hardness of
the problem, the k-regret minimization query is time consuming and the greedy
framework is widely adopted. However, formal theoretical analysis of the greedy
approaches for the quality of the returned results is still lacking. In this
paper, we first fill this gap by conducting a nontrivial theoretical analysis
of the approximation ratio of the returned results. To speed up query
processing, a sampling-based method, StocPreGreed,, is developed to reduce the
evaluation cost. In addition, a theoretical analysis of the required sample
size is conducted to bound the quality of the returned results. Finally,
comprehensive experiments are conducted on both real and synthetic datasets to
demonstrate the efficiency and effectiveness of the proposed methods.
</dc:description>
 <dc:description>Comment: 14 pages, 7 figures, 6 tables</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11630</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11642</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Batch Normalization Classifier for Domain Adaptation</dc:title>
 <dc:creator>Behrend, Matthew R.</dc:creator>
 <dc:creator>Robinson, Sean M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Adapting a model to perform well on unforeseen data outside its training set
is a common problem that continues to motivate new approaches. We demonstrate
that application of batch normalization in the output layer, prior to softmax
activation, results in improved generalization across visual data domains in a
refined ResNet model. The approach adds negligible computational complexity yet
outperforms many domain adaptation methods that explicitly learn to align data
domains. We benchmark this technique on the Office-Home dataset and show that
batch normalization is competitive with other leading methods. We show that
this method is not sensitive to presence of source data during adaptation and
further present the impact on trained tensor distributions tends toward
sparsity. Code is available at https://github.com/matthewbehrend/BNC
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11642</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11645</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AET-EFN: A Versatile Design for Static and Dynamic Event-Based Vision</dc:title>
 <dc:creator>Liu, Chang</dc:creator>
 <dc:creator>Qi, Xiaojuan</dc:creator>
 <dc:creator>Lam, Edmund</dc:creator>
 <dc:creator>Wong, Ngai</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:description>  The neuromorphic event cameras, which capture the optical changes of a scene,
have drawn increasing attention due to their high speed and low power
consumption. However, the event data are noisy, sparse, and nonuniform in the
spatial-temporal domain with an extremely high temporal resolution, making it
challenging to design backend algorithms for event-based vision. Existing
methods encode events into point-cloud-based or voxel-based representations,
but suffer from noise and/or information loss. Additionally, there is little
research that systematically studies how to handle static and dynamic scenes
with one universal design for event-based vision. This work proposes the
Aligned Event Tensor (AET) as a novel event data representation, and a neat
framework called Event Frame Net (EFN), which enables our model for event-based
vision under static and dynamic scenes. The proposed AET and EFN are evaluated
on various datasets, and proved to surpass existing state-of-the-art methods by
large margins. Our method is also efficient and achieves the fastest inference
speed among others.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11645</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11647</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prototypical Representation Learning for Relation Extraction</dc:title>
 <dc:creator>Ding, Ning</dc:creator>
 <dc:creator>Wang, Xiaobin</dc:creator>
 <dc:creator>Fu, Yao</dc:creator>
 <dc:creator>Xu, Guangwei</dc:creator>
 <dc:creator>Wang, Rui</dc:creator>
 <dc:creator>Xie, Pengjun</dc:creator>
 <dc:creator>Shen, Ying</dc:creator>
 <dc:creator>Huang, Fei</dc:creator>
 <dc:creator>Zheng, Hai-Tao</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Recognizing relations between entities is a pivotal task of relational
learning. Learning relation representations from distantly-labeled datasets is
difficult because of the abundant label noise and complicated expressions in
human language. This paper aims to learn predictive, interpretable, and robust
relation representations from distantly-labeled data that are effective in
different settings, including supervised, distantly supervised, and few-shot
learning. Instead of solely relying on the supervision from noisy labels, we
propose to learn prototypes for each relation from contextual information to
best explore the intrinsic semantics of relations. Prototypes are
representations in the feature space abstracting the essential semantics of
relations between entities in sentences. We learn prototypes based on
objectives with clear geometric interpretation, where the prototypes are unit
vectors uniformly dispersed in a unit ball, and statement embeddings are
centered at the end of their corresponding prototype vectors on the surface of
the ball. This approach allows us to learn meaningful, interpretable prototypes
for the final classification. Results on several relation learning tasks show
that our model significantly outperforms the previous state-of-the-art models.
We further demonstrate the robustness of the encoder and the interpretability
of prototypes with extensive experiments.
</dc:description>
 <dc:description>Comment: Accepted by ICLR 2021</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11647</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11651</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating glioma growth predictions as a forward ranking problem</dc:title>
 <dc:creator>van Garderen, Karin A.</dc:creator>
 <dc:creator>van der Voort, Sebastian R.</dc:creator>
 <dc:creator>Wijnenga, Maarten M. J.</dc:creator>
 <dc:creator>Incekara, Fatih</dc:creator>
 <dc:creator>Kapsas, Georgios</dc:creator>
 <dc:creator>Gahrmann, Renske</dc:creator>
 <dc:creator>Alafandi, Ahmad</dc:creator>
 <dc:creator>Smits, Marion</dc:creator>
 <dc:creator>Klein, Stefan</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The problem of tumor growth prediction is challenging, but promising results
have been achieved with both model-driven and statistical methods. In this
work, we present a framework for the evaluation of growth predictions that
focuses on the spatial infiltration patterns, and specifically evaluating a
prediction of future growth. We propose to frame the problem as a ranking
problem rather than a segmentation problem. Using the average precision as a
metric, we can evaluate the results with segmentations while using the full
spatiotemporal prediction. Furthermore, by separating the model goodness-of-fit
from future predictive performance, we show that in some cases, a better fit of
model parameters does not guarantee a better the predictive power.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11651</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11658</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intra-Inter Camera Similarity for Unsupervised Person Re-Identification</dc:title>
 <dc:creator>Xuan, Shiyu</dc:creator>
 <dc:creator>Zhang, Shiliang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Most of unsupervised person Re-Identification (Re-ID) works produce
pseudo-labels by measuring the feature similarity without considering the
distribution discrepancy among cameras, leading to degraded accuracy in label
computation across cameras. This paper targets to address this challenge by
studying a novel intra-inter camera similarity for pseudo-label generation. We
decompose the sample similarity computation into two stage, i.e., the
intra-camera and inter-camera computations, respectively. The intra-camera
computation directly leverages the CNN features for similarity computation
within each camera. Pseudo-labels generated on different cameras train the
re-id model in a multi-branch network. The second stage considers the
classification scores of each sample on different cameras as a new feature
vector. This new feature effectively alleviates the distribution discrepancy
among cameras and generates more reliable pseudo-labels. We hence train our
re-id model in two stages with intra-camera and inter-camera pseudo-labels,
respectively. This simple intra-inter camera similarity produces surprisingly
good performance on multiple datasets, e.g., achieves rank-1 accuracy of 89.5%
on the Market1501 dataset, outperforming the recent unsupervised works by 9+%,
and is comparable with the latest transfer learning works that leverage extra
annotations.
</dc:description>
 <dc:description>Comment: CVPR2021</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11658</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11668</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Checking App Behavior Against App Descriptions: What If There are No App
  Descriptions?</dc:title>
 <dc:creator>Shamsujjoha, Md.</dc:creator>
 <dc:creator>Grundy, John</dc:creator>
 <dc:creator>Li, Li</dc:creator>
 <dc:creator>Khalajzadeh, Hourieh</dc:creator>
 <dc:creator>Lu, Qinghua</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Classifying mobile apps based on their description is beneficial for several
purposes. However, many app descriptions do not reflect app functionalities,
whether accidentally or on purpose. Most importantly, these app classification
methods do not work if the app description is unavailable. This paper
investigates a Reverse Engineering-based Approach to Classify mobile apps using
The data that exists in the app, called REACT. To validate the proposed REACT
method, we use a large set of Android apps (24,652 apps in total). We also show
REACTs' extendibility for malware/anomaly detection and prove its reliability
and scalability. However, our analysis shows some limitations in REACT
procedure and implementation, especially for similar feature based app
grouping. We discuss the root cause of these failures, our key lessons learned,
and some future enhancement ideas. We also share our REACT tools and reproduced
datasets for the app market analyst, mobile app developers and software
engineering research communities for further research purposes.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11668</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11669</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Space Lower Bounds for Approximating Maximum Matching in the Edge
  Arrival Model</dc:title>
 <dc:creator>Kapralov, Michael</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The bipartite matching problem in the online and streaming settings has
received a lot of attention recently. The classical vertex arrival setting, for
which the celebrated Karp, Vazirani and Vazirani (KVV) algorithm achieves a
$1-1/e$ approximation, is rather well understood: the $1-1/e$ approximation is
optimal in both the online and semi-streaming setting, where the algorithm is
constrained to use $n\cdot \log^{O(1)} n$ space. The more challenging the edge
arrival model has seen significant progress recently in the online algorithms
literature. For the strictly online model (no preemption) approximations better
than trivial factor $1/2$ have been ruled out [Gamlath et al'FOCS'19]. For the
less restrictive online preemptive model a better than $\frac1{1+\ln
2}$-approximation [Epstein et al'STACS'12] and even a better than
$(2-\sqrt{2})$-approximation[Huang et al'SODA'19] have been ruled out.
  The recent hardness results for online preemptive matching in the edge
arrival model are based on the idea of stringing together multiple copies of a
KVV hard instance using edge arrivals. In this paper, we show how to implement
such constructions using ideas developed in the literature on Ruzsa-Szemer\'edi
graphs. As a result, we show that any single pass streaming algorithm that
approximates the maximum matching in a bipartite graph with $n$ vertices to a
factor better than $\frac1{1+\ln 2}\approx 0.59$ requires
$n^{1+\Omega(1/\log\log n)}\gg n \log^{O(1)} n$ space. This gives the first
separation between the classical one sided vertex arrival setting and the edge
arrival setting in the semi-streaming model.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11669</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11671</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Two-Stage Anomaly Detection</dc:title>
 <dc:creator>Liu, Yunfei</dc:creator>
 <dc:creator>Zhuang, Chaoqun</dc:creator>
 <dc:creator>Lu, Feng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Anomaly detection from a single image is challenging since anomaly data is
always rare and can be with highly unpredictable types. With only anomaly-free
data available, most existing methods train an AutoEncoder to reconstruct the
input image and find the difference between the input and output to identify
the anomalous region. However, such methods face a potential problem - a coarse
reconstruction generates extra image differences while a high-fidelity one may
draw in the anomaly. In this paper, we solve this contradiction by proposing a
two-stage approach, which generates high-fidelity yet anomaly-free
reconstructions. Our Unsupervised Two-stage Anomaly Detection (UTAD) relies on
two technical components, namely the Impression Extractor (IE-Net) and the
Expert-Net. The IE-Net and Expert-Net accomplish the two-stage anomaly-free
image reconstruction task while they also generate intuitive intermediate
results, making the whole UTAD interpretable. Extensive experiments show that
our method outperforms state-of-the-arts on four anomaly detection datasets
with different types of real-world objects and textures.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11671</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11674</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Geometry Modeling and Analysis for THz-mmWave Hybrid IoT
  Networks</dc:title>
 <dc:creator>Wang, Chao</dc:creator>
 <dc:creator>Chun, Young Jin</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Terahertz (THz) band contains abundant spectrum resources that can offer
ultra-high data rates. However, due to the THz band's inherent characteristics,
i.e., low penetrability, high path loss, and non-negligible molecular
absorption effect, THz communication can only provide limited coverage. To
overcome these fundamental obstacles and fully utilize the THz band, we
consider a hybrid Internet-of-Things (IoT) network consisting of THz and
millimeter wave (mmWave) cells. A hybrid IoT network can dynamically switch
between mmWave and THz links to ensure reliable and ultra-fast data connection.
We use a stochastic geometric framework to evaluate the proposed hybrid IoT
network's coverage probability and spectral efficiency and validate the
analysis through numerical simulation. In this paper, we derive a closed-form
expression of the Laplace transform of the interference while considering an
accurate multi-level Flat-top (MLFT) antenna pattern. We observed that a large
antenna array with a strong bias to the THz base station (TBS) improves the
end-to-end network performance through numerical results. Furthermore, we
recognized a fundamental trade-off relation between the TBS's node density and
the bias to mmWave/THz; e.g., high TBS density with a strong bias to the TBS
may degrade the network performance.
</dc:description>
 <dc:description>Comment: Submitted to IEEE IoT Journal</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11678</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature Selection for Imbalanced Data with Deep Sparse Autoencoders
  Ensemble</dc:title>
 <dc:creator>Massi, Michela C.</dc:creator>
 <dc:creator>Ieva, Francesca</dc:creator>
 <dc:creator>Gasperoni, Francesca</dc:creator>
 <dc:creator>Paganoni, Anna Maria</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Class imbalance is a common issue in many domain applications of learning
algorithms. Oftentimes, in the same domains it is much more relevant to
correctly classify and profile minority class observations. This need can be
addressed by Feature Selection (FS), that offers several further advantages,
s.a. decreasing computational costs, aiding inference and interpretability.
However, traditional FS techniques may become sub-optimal in the presence of
strongly imbalanced data. To achieve FS advantages in this setting, we propose
a filtering FS algorithm ranking feature importance on the basis of the
Reconstruction Error of a Deep Sparse AutoEncoders Ensemble (DSAEE). We use
each DSAE trained only on majority class to reconstruct both classes. From the
analysis of the aggregated Reconstruction Error, we determine the features
where the minority class presents a different distribution of values w.r.t. the
overrepresented one, thus identifying the most relevant features to
discriminate between the two. We empirically demonstrate the efficacy of our
algorithm in several experiments on high-dimensional datasets of varying sample
size, showcasing its capability to select relevant and generalizable features
to profile and classify minority class, outperforming other benchmark FS
methods. We also briefly present a real application in radiogenomics, where the
methodology was applied successfully.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11681</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual
  Tracking</dc:title>
 <dc:creator>Wang, Ning</dc:creator>
 <dc:creator>Zhou, Wengang</dc:creator>
 <dc:creator>Wang, Jie</dc:creator>
 <dc:creator>Li, Houqaing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In video object tracking, there exist rich temporal contexts among successive
frames, which have been largely overlooked in existing trackers. In this work,
we bridge the individual video frames and explore the temporal contexts across
them via a transformer architecture for robust object tracking. Different from
classic usage of the transformer in natural language processing tasks, we
separate its encoder and decoder into two parallel branches and carefully
design them within the Siamese-like tracking pipelines. The transformer encoder
promotes the target templates via attention-based feature reinforcement, which
benefits the high-quality tracking model generation. The transformer decoder
propagates the tracking cues from previous templates to the current frame,
which facilitates the object searching process. Our transformer-assisted
tracking framework is neat and trained in an end-to-end manner. With the
proposed transformer, a simple Siamese matching approach is able to outperform
the current top-performing trackers. By combining our transformer with the
recent discriminative tracking pipeline, our method sets several new
state-of-the-art records on prevalent tracking benchmarks.
</dc:description>
 <dc:description>Comment: To appear in CVPR 2021 (Oral)</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11683</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comprehensive Integration of API Usage Patterns</dc:title>
 <dc:creator>Shen, Qi</dc:creator>
 <dc:creator>Wu, Shijun</dc:creator>
 <dc:creator>Zou, Yanzhen</dc:creator>
 <dc:creator>Xie, Bing</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Nowadays, developers often reuse existing APIs to implement their programming
tasks. A lot of API usage patterns are mined to help developers learn API usage
rules. However, there are still many missing variables to be synthesized when
developers integrate the patterns into their programming context. To deal with
this issue, we propose a comprehensive approach to integrate API usage patterns
in this paper. We first perform an empirical study by analyzing how API usage
patterns are integrated in real-world projects. We find the expressions for
variable synthesis is often non-trivial and can be divided into 5 syntax types.
Based on the observation, we promote an approach to help developers
interactively complete API usage patterns. Compared to the existing code
completion techniques, our approach can recommend infrequent expressions
accompanied with their real-world usage examples according to the user intent.
The evaluation shows that our approach could assist users to integrate APIs
more efficiently and complete the programming tasks faster than existing works.
</dc:description>
 <dc:description>Comment: 11 pages, Accepted to the 29th IEEE/ACM International Conference on
  Program Comprehension</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11683</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11688</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Space Mapping of Spline Spaces over Hierarchical T-meshes</dc:title>
 <dc:creator>Liu, Jingjing</dc:creator>
 <dc:creator>Deng, Fang</dc:creator>
 <dc:creator>Deng, Jiansong</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>65D07</dc:subject>
 <dc:subject>G.1.1</dc:subject>
 <dc:description>  In this paper, we construct a bijective mapping between a biquadratic spline
space over the hierarchical T-mesh and the piecewise constant space over the
corresponding crossing-vertex-relationship graph (CVR graph). We propose a
novel structure, by which we offer an effective and easy operative method for
constructing the basis functions of the biquadratic spline space. The mapping
we construct is an isomorphism. The basis functions of the biquadratic spline
space hold the properties such as linearly independent, completeness and the
property of partition of unity, which are the same with the properties for the
basis functions of piecewise constant space over the CVR graph. To demonstrate
that the new basis functions are efficient, we apply the basis functions to fit
some open surfaces.
</dc:description>
 <dc:description>Comment: 31 pages,20 figures</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11688</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11691</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Programming-Language Commits in OSS: An Empirical Study on Apache
  Projects</dc:title>
 <dc:creator>Li, Zengyang</dc:creator>
 <dc:creator>Qi, Xiaoxiao</dc:creator>
 <dc:creator>Yu, Qinyi</dc:creator>
 <dc:creator>Liang, Peng</dc:creator>
 <dc:creator>Mo, Ran</dc:creator>
 <dc:creator>Yang, Chen</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Modern software systems, such as Spark, are usually written in multiple
programming languages (PLs). Besides benefiting from code reuse, such systems
can also take advantages of specific PLs to implement certain features, to meet
various quality needs, and to improve development efficiency. In this context,
a change to such systems may need to modify source files written in different
PLs. We define a multi-programming-language commit (MPLC) in a version control
system (e.g., Git) as a commit that involves modified source files written in
two or more PLs. To our knowledge, the phenomenon of MPLCs in software
development has not been explored yet. In light of the potential impact of
MPLCs on development difficulty and software quality, we performed an empirical
study to understand the state of MPLCs, their change complexity, as well as
their impact on open time of issues and bug proneness of source files in
real-life software projects. By exploring the MPLCs in 20 non-trivial Apache
projects with 205,994 commits, we obtained the following findings: (1) 9% of
the commits from all the projects are MPLCs, and the proportion of MPLCs in 80%
of the projects goes to a relatively stable level; (2) more than 90% of the
MPLCs from all the projects involve source files written in two PLs; (3) the
change complexity of MPLCs is significantly higher than that of non-MPLCs in
all projects; (4) issues fixed in MPLCs take significantly longer to be
resolved than issues fixed in non-MPLCs in 80% of the projects; and (5) source
files that have been modified in MPLCs tend to be more bug-prone than source
files that have never been modified in MPLCs. These findings provide
practitioners with useful insights on the architecture design and quality
management of software systems written in multiple PLs.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11691</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11692</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recognizing LTLf/PLTLf Goals in Fully Observable Non-Deterministic
  Domain Models</dc:title>
 <dc:creator>Pereira, Ramon Fraga</dc:creator>
 <dc:creator>Fuggitti, Francesco</dc:creator>
 <dc:creator>De Giacomo, Giuseppe</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Goal Recognition is the task of discerning the correct intended goal that an
agent aims to achieve, given a set of possible goals, a domain model, and a
sequence of observations as a sample of the plan being executed in the
environment. Existing approaches assume that the possible goals are formalized
as a conjunction in deterministic settings. In this paper, we develop a novel
approach that is capable of recognizing temporally extended goals in Fully
Observable Non-Deterministic (FOND) planning domain models, focusing on goals
on finite traces expressed in Linear Temporal Logic (LTLf) and (Pure) Past
Linear Temporal Logic (PLTLf). We empirically evaluate our goal recognition
approach using different LTLf and PLTLf goals over six common FOND planning
domain models, and show that our approach is accurate to recognize temporally
extended goals at several levels of observability.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11692</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11695</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting brain-age from raw T 1 -weighted Magnetic Resonance Imaging
  data using 3D Convolutional Neural Networks</dc:title>
 <dc:creator>Fisch, Lukas</dc:creator>
 <dc:creator>Ernsting, Jan</dc:creator>
 <dc:creator>Winter, Nils R.</dc:creator>
 <dc:creator>Holstein, Vincent</dc:creator>
 <dc:creator>Leenings, Ramona</dc:creator>
 <dc:creator>Beisemann, Marie</dc:creator>
 <dc:creator>Sarink, Kelvin</dc:creator>
 <dc:creator>Emden, Daniel</dc:creator>
 <dc:creator>Opel, Nils</dc:creator>
 <dc:creator>Redlich, Ronny</dc:creator>
 <dc:creator>Repple, Jonathan</dc:creator>
 <dc:creator>Grotegerd, Dominik</dc:creator>
 <dc:creator>Meinert, Susanne</dc:creator>
 <dc:creator>Wulms, Niklas</dc:creator>
 <dc:creator>Minnerup, Heike</dc:creator>
 <dc:creator>Hirsch, Jochen G.</dc:creator>
 <dc:creator>Niendorf, Thoralf</dc:creator>
 <dc:creator>Endemann, Beate</dc:creator>
 <dc:creator>Bamberg, Fabian</dc:creator>
 <dc:creator>Kr&#xf6;ncke, Thomas</dc:creator>
 <dc:creator>Peters, Annette</dc:creator>
 <dc:creator>B&#xfc;low, Robin</dc:creator>
 <dc:creator>V&#xf6;lzke, Henry</dc:creator>
 <dc:creator>von Stackelberg, Oyunbileg</dc:creator>
 <dc:creator>Sowade, Ramona Felizitas</dc:creator>
 <dc:creator>Umutlu, Lale</dc:creator>
 <dc:creator>Schmidt, B&#xf6;rge</dc:creator>
 <dc:creator>Caspers, Svenja</dc:creator>
 <dc:creator>Consortium, German National Cohort Study Center</dc:creator>
 <dc:creator>Kugel, Harald</dc:creator>
 <dc:creator>Baune, Bernhard T.</dc:creator>
 <dc:creator>Kircher, Tilo</dc:creator>
 <dc:creator>Risse, Benjamin</dc:creator>
 <dc:creator>Dannlowski, Udo</dc:creator>
 <dc:creator>Berger, Klaus</dc:creator>
 <dc:creator>Hahn, Tim</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Age prediction based on Magnetic Resonance Imaging (MRI) data of the brain is
a biomarker to quantify the progress of brain diseases and aging. Current
approaches rely on preparing the data with multiple preprocessing steps, such
as registering voxels to a standardized brain atlas, which yields a significant
computational overhead, hampers widespread usage and results in the predicted
brain-age to be sensitive to preprocessing parameters. Here we describe a 3D
Convolutional Neural Network (CNN) based on the ResNet architecture being
trained on raw, non-registered T$_ 1$-weighted MRI data of N=10,691 samples
from the German National Cohort and additionally applied and validated in
N=2,173 samples from three independent studies using transfer learning. For
comparison, state-of-the-art models using preprocessed neuroimaging data are
trained and validated on the same samples. The 3D CNN using raw neuroimaging
data predicts age with a mean average deviation of 2.84 years, outperforming
the state-of-the-art brain-age models using preprocessed data. Since our
approach is invariant to preprocessing software and parameter choices, it
enables faster, more robust and more accurate brain-age modeling.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11696</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Control Distance IoU and Control Distance IoU Loss Function for Better
  Bounding Box Regression</dc:title>
 <dc:creator>Chen, Dong</dc:creator>
 <dc:creator>Miao, Duoqian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Numerous improvements for feedback mechanisms have contributed to the great
progress in object detection. In this paper, we first present an
evaluation-feedback module, which is proposed to consist of evaluation system
and feedback mechanism. Then we analyze and summarize the disadvantages and
improvements of traditional evaluation-feedback module. Finally, we focus on
both the evaluation system and the feedback mechanism, and propose Control
Distance IoU and Control Distance IoU loss function (or CDIoU and CDIoU loss
for short) without increasing parameters or FLOPs in models, which show
different significant enhancements on several classical and emerging models.
Some experiments and comparative tests show that coordinated
evaluation-feedback module can effectively improve model performance. CDIoU and
CDIoU loss have different excellent performances in several models such as
Faster R-CNN, YOLOv4, RetinaNet and ATSS. There is a maximum AP improvement of
1.9% and an average AP of 0.8% improvement on MS COCO dataset, compared to
traditional evaluation-feedback modules.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11703</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model-based 3D Hand Reconstruction via Self-Supervised Learning</dc:title>
 <dc:creator>Chen, Yujin</dc:creator>
 <dc:creator>Tu, Zhigang</dc:creator>
 <dc:creator>Kang, Di</dc:creator>
 <dc:creator>Bao, Linchao</dc:creator>
 <dc:creator>Zhang, Ying</dc:creator>
 <dc:creator>Zhe, Xuefei</dc:creator>
 <dc:creator>Chen, Ruizhi</dc:creator>
 <dc:creator>Yuan, Junsong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Reconstructing a 3D hand from a single-view RGB image is challenging due to
various hand configurations and depth ambiguity. To reliably reconstruct a 3D
hand from a monocular image, most state-of-the-art methods heavily rely on 3D
annotations at the training stage, but obtaining 3D annotations is expensive.
To alleviate reliance on labeled training data, we propose S2HAND, a
self-supervised 3D hand reconstruction network that can jointly estimate pose,
shape, texture, and the camera viewpoint. Specifically, we obtain geometric
cues from the input image through easily accessible 2D detected keypoints. To
learn an accurate hand reconstruction model from these noisy geometric cues, we
utilize the consistency between 2D and 3D representations and propose a set of
novel losses to rationalize outputs of the neural network. For the first time,
we demonstrate the feasibility of training an accurate 3D hand reconstruction
network without relying on manual annotations. Our experiments show that the
proposed method achieves comparable performance with recent fully-supervised
methods while using fewer supervision data.
</dc:description>
 <dc:description>Comment: Accepted by CVPR21</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11704</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>n-hot: Efficient bit-level sparsity for powers-of-two neural network
  quantization</dc:title>
 <dc:creator>Sakuma, Yuiko</dc:creator>
 <dc:creator>Sumihiro, Hiroshi</dc:creator>
 <dc:creator>Nishikawa, Jun</dc:creator>
 <dc:creator>Nakamura, Toshiki</dc:creator>
 <dc:creator>Ikegaya, Ryoji</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Powers-of-two (PoT) quantization reduces the number of bit operations of deep
neural networks on resource-constrained hardware. However, PoT quantization
triggers a severe accuracy drop because of its limited representation ability.
Since DNN models have been applied for relatively complex tasks (e.g.,
classification for large datasets and object detection), improvement in
accuracy for the PoT quantization method is required. Although some previous
works attempt to improve the accuracy of PoT quantization, there is no work
that balances accuracy and computation costs in a memory-efficient way. To
address this problem, we propose an efficient PoT quantization scheme.
Bit-level sparsity is introduced; weights (or activations) are rounded to
values that can be calculated by n shift operations in multiplication. We also
allow not only addition but also subtraction as each operation. Moreover, we
use a two-stage fine-tuning algorithm to recover the accuracy drop that is
triggered by introducing the bit-level sparsity. The experimental results on an
object detection model (CenterNet, MobileNet-v2 backbone) on the COCO dataset
show that our proposed method suppresses the accuracy drop by 0.3% at most
while reducing the number of operations by about 75% and model size by 11.5%
compared to the uniform method.
</dc:description>
 <dc:description>Comment: 10 pages, 3 figures</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11704</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11705</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring Web Search Engines to Find Architectural Knowledge</dc:title>
 <dc:creator>Soliman, Mohamed</dc:creator>
 <dc:creator>Wiese, Marion</dc:creator>
 <dc:creator>Li, Yikun</dc:creator>
 <dc:creator>Riebisch, Matthias</dc:creator>
 <dc:creator>Avgeriou, Paris</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Software engineers need relevant and up-to-date architectural knowledge (AK),
in order to make well-founded design decisions. However, finding such AK is
quite challenging. One pragmatic approach is to search for AK on the web using
traditional search engines (e.g. Google); this is common practice among
software engineers. Still, we know very little about what AK is retrieved, from
where, and how useful it is. In this paper, we conduct an empirical study with
53 software engineers, who used Google to make design decisions using the
Attribute-Driven-Design method. Based on how the subjects assessed the nature
and relevance of the retrieved results, we determined how effective web search
engines are to find relevant architectural information. Moreover, we identified
the different sources of AK on the web and their associated AK concepts.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11705</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11706</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpreting Deep Learning Models with Marginal Attribution by
  Conditioning on Quantiles</dc:title>
 <dc:creator>Merz, M.</dc:creator>
 <dc:creator>Richman, R.</dc:creator>
 <dc:creator>Tsanakas, T.</dc:creator>
 <dc:creator>W&#xfc;thrich, M. V.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Quantitative Finance - Statistical Finance</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>68T07</dc:subject>
 <dc:description>  A vastly growing literature on explaining deep learning models has emerged.
This paper contributes to that literature by introducing a global
gradient-based model-agnostic method, which we call Marginal Attribution by
Conditioning on Quantiles (MACQ). Our approach is based on analyzing the
marginal attribution of predictions (outputs) to individual features (inputs).
Specificalllly, we consider variable importance by mixing (global) output
levels and, thus, explain how features marginally contribute across different
regions of the prediction space. Hence, MACQ can be seen as a marginal
attribution counterpart to approaches such as accumulated local effects (ALE),
which study the sensitivities of outputs by perturbing inputs. Furthermore,
MACQ allows us to separate marginal attribution of individual features from
interaction effect, and visually illustrate the 3-way relationship between
marginal attribution, output level, and feature value.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11706</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11709</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Superposition-Based Calculus for Quantum Diagrammatic Reasoning and
  Beyond</dc:title>
 <dc:creator>Echahed, Rachid</dc:creator>
 <dc:creator>Echenim, Mnacho</dc:creator>
 <dc:creator>Mhalla, Mehdi</dc:creator>
 <dc:creator>Peltier, Nicolas</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We introduce a class of rooted graphs which allows one to encode various
kinds of classical or quantum circuits. We then follow a set-theoretic approach
to define rewrite systems over the considered graphs and propose a new complete
Superposition callculus which handles sets of formulas consisting of equations
or disequations over these graphs.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11713</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatially Dependent U-Nets: Highly Accurate Architectures for Medical
  Imaging Segmentation</dc:title>
 <dc:creator>Carvalho, Jo&#xe3;o B. S.</dc:creator>
 <dc:creator>Santinha, Jo&#xe3;o A.</dc:creator>
 <dc:creator>Miladinovi&#x107;, &#x110;or&#x111;e</dc:creator>
 <dc:creator>Buhmann, Joachim M.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In clinical practice, regions of interest in medical imaging often need to be
identified through a process of precise image segmentation. The quality of this
image segmentation step critically affects the subsequent clinical assessment
of the patient status. To enable high accuracy, automatic image segmentation,
we introduce a novel deep neural network architecture that exploits the
inherent spatial coherence of anatomical structures and is well equipped to
capture long-range spatial dependencies in the segmented pixel/voxel space. In
contrast to the state-of-the-art solutions based on convolutional layers, our
approach leverages on recently introduced spatial dependency layers that have
an unbounded receptive field and explicitly model the inductive bias of spatial
coherence. Our method performs favourably to commonly used U-Net and U-Net++
architectures as demonstrated by improved Dice and Jaccardscore in three
different medical segmentation tasks: nuclei segmentation in microscopy images,
polyp segmentation in colonoscopy videos, and liver segmentation in abdominal
CT scans.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11713</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11715</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transforming Exploratory Creativity with DeLeNoX</dc:title>
 <dc:creator>Liapis, Antonios</dc:creator>
 <dc:creator>Martinez, Hector P.</dc:creator>
 <dc:creator>Togelius, Julian</dc:creator>
 <dc:creator>Yannakakis, Georgios N.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We introduce DeLeNoX (Deep Learning Novelty Explorer), a system that
autonomously creates artifacts in constrained spaces according to its own
evolving interestingness criterion. DeLeNoX proceeds in alternating phases of
exploration and transformation. In the exploration phases, a version of novelty
search augmented with constraint handling searches for maximally diverse
artifacts using a given distance function. In the transformation phases, a deep
learning autoencoder learns to compress the variation between the found
artifacts into a lower-dimensional space. The newly trained encoder is then
used as the basis for a new distance function, transforming the criteria for
the next exploration phase. In the current paper, we apply DeLeNoX to the
creation of spaceships suitable for use in two-dimensional arcade-style
computer games, a representative problem in procedural content generation in
games. We also situate DeLeNoX in relation to the distinction between
exploratory and transformational creativity, and in relation to Schmidhuber's
theory of creativity through the drive for compression progress.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11715</dc:identifier>
 <dc:identifier>Proceedings of the Fourth International Conference on
  Computational Creativity, 2013, pages 56-63</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11716</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Retinal-inspired Filtering for Dynamic Image Coding</dc:title>
 <dc:creator>Doutsi, Effrosyni</dc:creator>
 <dc:creator>Fillatre, Lionel</dc:creator>
 <dc:creator>Antonini, Marc</dc:creator>
 <dc:creator>Gaulmin, Julien</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  This paper introduces a novel non-Separable sPAtioteMporal filter (non-SPAM)
which enables the spatiotemporal decomposition of a still-image. The
construction of this filter is inspired by the model of the retina which is
able to selectively transmit information to the brain. The non-SPAM filter
mimics the retinal-way to extract necessary information for a dynamic
encoding/decoding system. We applied the non-SPAM filter on a still image which
is flashed for a long time. We prove that the non-SPAM filter decomposes the
still image over a set of time-varying difference of Gaussians, which form a
frame. We simulate the analysis and synthesis system based on this frame. This
system results in a progressive reconstruction of the input image. Both the
theoretical and numerical results show that the quality of the reconstruction
improves while the time increases.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11716</dc:identifier>
 <dc:identifier>doi:10.1109/ICIP.2015.7351456</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11719</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TICaM: A Time-of-flight In-car Cabin Monitoring Dataset</dc:title>
 <dc:creator>Katrolia, Jigyasa Singh</dc:creator>
 <dc:creator>Mirbach, Bruno</dc:creator>
 <dc:creator>El-Sherif, Ahmed</dc:creator>
 <dc:creator>Feld, Hartmut</dc:creator>
 <dc:creator>Rambach, Jason</dc:creator>
 <dc:creator>Stricker, Didier</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present TICaM, a Time-of-flight In-car Cabin Monitoring dataset for
vehicle interior monitoring using a single wide-angle depth camera. Our dataset
addresses the deficiencies of currently available in-car cabin datasets in
terms of the ambit of labeled classes, recorded scenarios and provided
annotations; all at the same time. We record an exhaustive list of actions
performed while driving and provide for them multi-modal labeled images (depth,
RGB and IR), with complete annotations for 2D and 3D object detection, instance
and semantic segmentation as well as activity annotations for RGB frames.
Additional to real recordings, we provide a synthetic dataset of in-car cabin
images with same multi-modality of images and annotations, providing a unique
and extremely beneficial combination of synthetic and real data for effectively
training cabin monitoring systems and evaluating domain adaptation approaches.
The dataset is available at https://vizta-tof.kl.dfki.de/.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11719</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11726</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SuSketch: Surrogate Models of Gameplay as a Design Assistant</dc:title>
 <dc:creator>Migkotzidis, Panagiotis</dc:creator>
 <dc:creator>Liapis, Antonios</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  This paper introduces SuSketch, a design tool for first person shooter
levels. SuSketch provides the designer with gameplay predictions for two
competing players of specific character classes. The interface allows the
designer to work side-by-side with an artificially intelligent creator and to
receive varied types of feedback such as path information, predicted balance
between players in a complete playthrough, or a predicted heatmap of the
locations of player deaths. The system also proactively designs alternatives to
the level and class pairing, and presents them to the designer as suggestions
that improve the predicted balance of the game. SuSketch offers a new way of
integrating machine learning into mixed-initiative co-creation tools, as a
surrogate of human play trained on a large corpus of artificial playtraces. A
user study with 16 game developers indicated that the tool was easy to use, but
also highlighted a need to make SuSketch more accessible and more explainable.
</dc:description>
 <dc:description>Comment: To be published in IEEE Transactions on Games, 11 pages</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11726</dc:identifier>
 <dc:identifier>doi:10.1109/TG.2021.3068360</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11740</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy-aware Process Performance Indicators: Framework and Release
  Mechanisms</dc:title>
 <dc:creator>Kabierski, Martin</dc:creator>
 <dc:creator>Fahrenkrog-Petersen, Stephan</dc:creator>
 <dc:creator>Weidlich, Matthias</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Process performance indicators (PPIs) are metrics to quantify the degree with
which organizational goals defined based on business processes are fulfilled.
They exploit the event logs recorded by information systems during the
execution of business processes, thereby providing a basis for process
monitoring and subsequent optimization. However, PPIs are often evaluated on
processes that involve individuals, which implies an inevitable risk of privacy
intrusion. In this paper, we address the demand for privacy protection in the
computation of PPIs. We first present a framework that enforces control over
the data exploited for process monitoring. We then show how PPIs defined based
on the established PPINOT meta-model are instantiated in this framework through
a set of data release mechanisms. These mechanisms are designed to provide
provable guarantees in terms of differential privacy. We evaluate our framework
and the release mechanisms in a series of controlled experiments. We further
use a public event log to compare our framework with approaches based on
privatization of event logs. The results demonstrate feasibility and shed light
on the trade-offs between data utility and privacy guarantees in the
computation of PPIs.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11744</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large Motion Video Super-Resolution with Dual Subnet and Multi-Stage
  Communicated Upsampling</dc:title>
 <dc:creator>Liu, Hongying</dc:creator>
 <dc:creator>Zhao, Peng</dc:creator>
 <dc:creator>Ruan, Zhubo</dc:creator>
 <dc:creator>Shang, Fanhua</dc:creator>
 <dc:creator>Liu, Yuanyuan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Video super-resolution (VSR) aims at restoring a video in low-resolution (LR)
and improving it to higher-resolution (HR). Due to the characteristics of video
tasks, it is very important that motion information among frames should be well
concerned, summarized and utilized for guidance in a VSR algorithm. Especially,
when a video contains large motion, conventional methods easily bring
incoherent results or artifacts. In this paper, we propose a novel deep neural
network with Dual Subnet and Multi-stage Communicated Upsampling (DSMC) for
super-resolution of videos with large motion. We design a new module named
U-shaped residual dense network with 3D convolution (U3D-RDN) for fine implicit
motion estimation and motion compensation (MEMC) as well as coarse spatial
feature extraction. And we present a new Multi-Stage Communicated Upsampling
(MSCU) module to make full use of the intermediate results of upsampling for
guiding the VSR. Moreover, a novel dual subnet is devised to aid the training
of our DSMC, whose dual loss helps to reduce the solution space as well as
enhance the generalization ability. Our experimental results confirm that our
method achieves superior performance on videos with large motion compared to
state-of-the-art methods.
</dc:description>
 <dc:description>Comment: Accepted by AAAI 2021</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11744</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11750</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Catastrophic Forgetting in Deep Graph Networks: an Introductory
  Benchmark for Graph Classification</dc:title>
 <dc:creator>Carta, Antonio</dc:creator>
 <dc:creator>Cossu, Andrea</dc:creator>
 <dc:creator>Errica, Federico</dc:creator>
 <dc:creator>Bacciu, Davide</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  In this work, we study the phenomenon of catastrophic forgetting in the graph
representation learning scenario. The primary objective of the analysis is to
understand whether classical continual learning techniques for flat and
sequential data have a tangible impact on performances when applied to graph
data. To do so, we experiment with a structure-agnostic model and a deep graph
network in a robust and controlled environment on three different datasets. The
benchmark is complemented by an investigation on the effect of
structure-preserving regularization techniques on catastrophic forgetting. We
find that replay is the most effective strategy in so far, which also benefits
the most from the use of regularization. Our findings suggest interesting
future research at the intersection of the continual and graph representation
learning fields. Finally, we provide researchers with a flexible software
framework to reproduce our results and carry out further experiments.
</dc:description>
 <dc:description>Comment: Accepted at the 2021 Web Conference Workshop on Graph Learning
  Benchmarks (GLB 2021). Code available at
  https://github.com/diningphil/continual_learning_for_graphs</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11750</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11751</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Functional Pearl: Witness Me -- Constructive Arguments Must Be Guided
  with Concrete Witness</dc:title>
 <dc:creator>Ishii, Hiromi</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Beloved Curry--Howard correspondence tells that types are intuitionistic
propositions, and in constructive math, a proof of proposition can be seen as
some kind of a construction, or witness, conveying the information of the
proposition. We demonstrate how useful this point of view is as the guiding
principle for developing dependently-typed programs.
</dc:description>
 <dc:description>Comment: Submitted to Haskell'21</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11751</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11759</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On how generalised entropies without parameters impact information
  optimisation processes</dc:title>
 <dc:creator>Fuentes, Jes&#xfa;s</dc:creator>
 <dc:creator>Obreg&#xf3;n, Octavio</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:description>  As an application of generalised statistical mechanics, it is studied a
possible route toward a consistent generalised information theory in terms of a
family of non-extensive, non-parametric entropies $H^\pm_D(P)$. Unlike other
proposals based on non-extensive entropies with a parameter dependence, our
scheme is asymptotically equivalent to the one formulated by Shannon, while it
differs in regions where the density of states is reasonably small, which leads
to information distributions constrained to their background. Two basic
concepts are discussed to this aim. First, we prove two effective coding
theorems for the entropies $H^\pm_D(P)$. Then we calculate the channel capacity
of a binary symmetric channel (BSC) and a binary erasure channel (BEC) in terms
of these entropies. We found that processes such as data compression and
channel capacity maximisation can be improved in regions where there is a low
density of states, whereas for high densities our results coincide with
Shannon's formulation.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures</dc:description>
 <dc:date>2021-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11759</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11760</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-end Precoding Validation over a Live GEO Satellite Forward Link</dc:title>
 <dc:creator>Krivochiza, Jevgenij</dc:creator>
 <dc:creator>Duncan, Juan Carlos Merlano</dc:creator>
 <dc:creator>Querol, Jorge</dc:creator>
 <dc:creator>Maturo, Nicola</dc:creator>
 <dc:creator>Marrero, Liz Martinez</dc:creator>
 <dc:creator>Andrenacci, Stefano</dc:creator>
 <dc:creator>Krause, Jens</dc:creator>
 <dc:creator>Chatzinotas, Symeon</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  In this paper we demonstrate end-to-end precoded multi-user multiple-input
single-output (MU-MISO) communications over a live GEO satellite link. Precoded
communications enable full frequency reuse (FFR) schemes in satellite
communications (SATCOM) to achieve broader service availability and higher
spectrum efficiency than with the conventional four-color (4CR) and two-color
(2CR) reuse approaches. In this scope, we develop an over-the-air test-bed for
end-to-end precoding validations. We use an actual multi-beam satellite to
transmit and receive precoded signals using the DVB-S2X standard based gateway
and user terminals. The developed system is capable of end-to-end real-time
communications over the satellite link including channel measurements and
precompensation. It is shown, that by successfully canceling inter-user
interference in the actual satellite FFR link precoding brings gains in terms
of enhanced SINR and increased system goodput.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Access Journal</dc:description>
 <dc:date>2021-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11760</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11761</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extracting Semantic Process Information from the Natural Language in
  Event Logs</dc:title>
 <dc:creator>Rebmann, Adrian</dc:creator>
 <dc:creator>van der Aa, Han</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Process mining focuses on the analysis of recorded event data in order to
gain insights about the true execution of business processes. While
foundational process mining techniques treat such data as sequences of abstract
events, more advanced techniques depend on the availability of specific kinds
of information, such as resources in organizational mining and business objects
in artifact-centric analysis. However, this information is generally not
readily available, but rather associated with events in an ad hoc manner, often
even as part of unstructured textual attributes. Given the size and complexity
of event logs, this calls for automated support to extract such process
information and, thereby, enable advanced process mining techniques. In this
paper, we present an approach that achieves this through so-called semantic
role labeling of event data. We combine the analysis of textual attribute
values, based on a state-of-the-art language model, with a novel attribute
classification technique. In this manner, our approach extracts information
about up to eight semantic roles per event. We demonstrate the approach's
efficacy through a quantitative evaluation using a broad range of event logs
and demonstrate the usefulness of the extracted information in a case study.
</dc:description>
 <dc:date>2021-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11761</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11763</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design and Performance Analysis of a Chaotic Pseudo Orthogonal Carriers
  Multi-Access Communication System</dc:title>
 <dc:creator>Bai, Chao</dc:creator>
 <dc:creator>Yao, Jun-Liang</dc:creator>
 <dc:creator>Sun, Yu-Zhe</dc:creator>
 <dc:creator>Ren, Hai-Peng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A Chaotic Pseudo Orthogonal Carriers Multi-Access (CPOCMA) communication
based on Chaotic Pseudo Orthogonal Shape-forming Filter (CPOSF) bank, Chaotic
Pseudo Orthogonal Matched Filter (CPOMF) bank and Chaotic Pseudo Orthogonal
Correlation Filter (CPOCF) bank is proposed in this work. At the transmitter,
the multiple CPOSFs are used to generate pseudo orthogonal signals. It provides
a good trade-off between spectrum efficiency and high bit transmission rate. At
the receiver, the CPOMF bank and CPOCF bank are used to maximize the
Signal-to-Noise Ratio (SNR) and extract the received information from each
sub-channel, respectively. The received signal is demodulated by averaging the
sampled sequence from the matched filter bank output and sorting the sampling
sequence from the CPOCF bank output to recover the transmitted information
bits. The proposed CPOCMA communication system not only offers multiuser access
with high reliability and high data transmission rate, but also achieves higher
spectrum efficiency. Analytical Bit Error Rate (BER) expression is derived. The
proposed communication system performance has been evaluated in Additive White
Gaussian Noise (AWGN) channel and wireless channel by both numerical
simulations and experiments based on a Wireless open-Access Research Platform
(WARP), the results show the effectiveness and the superiority of the proposed
method.
</dc:description>
 <dc:date>2021-03-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11763</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11764</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transfer learning from High-Resource to Low-Resource Language Improves
  Speech Affect Recognition Classification Accuracy</dc:title>
 <dc:creator>Durrani, Sara</dc:creator>
 <dc:creator>Arshad, Umair</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Speech Affect Recognition is a problem of extracting emotional affects from
audio data. Low resource languages corpora are rear and affect recognition is a
difficult task in cross-corpus settings. We present an approach in which the
model is trained on high resource language and fine-tune to recognize affects
in low resource language. We train the model in same corpus setting on SAVEE,
EMOVO, Urdu, and IEMOCAP by achieving baseline accuracy of 60.45, 68.05, 80.34,
and 56.58 percent respectively. For capturing the diversity of affects in
languages cross-corpus evaluations are discussed in detail. We find that
accuracy improves by adding the domain target data into the training data.
Finally, we show that performance is improved for low resource language speech
affect recognition by achieving the UAR OF 69.32 and 68.2 for Urdu and Italian
speech affects.
</dc:description>
 <dc:date>2021-03-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11764</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11765</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A General and Configurable Framework for Blockchain-based Marketplaces</dc:title>
 <dc:creator>Merlina, Andrea</dc:creator>
 <dc:creator>Vitenberg, Roman</dc:creator>
 <dc:creator>Setty, Vinay</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The first generation of blockchain focused on digital currencies and secure
storage, management and transfer of tokenized values. Thereafter, the focus has
been shifting from currencies to a broader application space. In this paper, we
systematically explore marketplace types and properties, and consider the
mechanisms required to support those properties through blockchain. We propose
a generic and configurable framework for blockchain-based marketplaces, and
describe how popular marketplace types, price discovery policies, and other
configuration parameters are implemented within the framework by presenting
concrete event-based algorithms. Finally, we consider three use cases with
widely diverging properties and show how the proposed framework supports them.
</dc:description>
 <dc:description>Comment: 27 pages, 2 figures, 7 algorithms</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11765</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11770</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AdaSGN: Adapting Joint Number and Model Size for Efficient
  Skeleton-Based Action Recognition</dc:title>
 <dc:creator>Shi, Lei</dc:creator>
 <dc:creator>Zhang, Yifan</dc:creator>
 <dc:creator>Cheng, Jian</dc:creator>
 <dc:creator>Lu, Hanqing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Existing methods for skeleton-based action recognition mainly focus on
improving the recognition accuracy, whereas the efficiency of the model is
rarely considered. Recently, there are some works trying to speed up the
skeleton modeling by designing light-weight modules. However, in addition to
the model size, the amount of the data involved in the calculation is also an
important factor for the running speed, especially for the skeleton data where
most of the joints are redundant or non-informative to identify a specific
skeleton. Besides, previous works usually employ one fix-sized model for all
the samples regardless of the difficulty of recognition, which wastes
computations for easy samples. To address these limitations, a novel approach,
called AdaSGN, is proposed in this paper, which can reduce the computational
cost of the inference process by adaptively controlling the input number of the
joints of the skeleton on-the-fly. Moreover, it can also adaptively select the
optimal model size for each sample to achieve a better trade-off between
accuracy and efficiency. We conduct extensive experiments on three challenging
datasets, namely, NTU-60, NTU-120 and SHREC, to verify the superiority of the
proposed approach, where AdaSGN achieves comparable or even higher performance
with much lower GFLOPs compared with the baseline method.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11770</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11777</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Issue Assignment: Results and Insights from an Industrial Case</dc:title>
 <dc:creator>Aktas, Ethem Utku</dc:creator>
 <dc:creator>Yilmaz, Cemal</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Softtech, being a subsidiary of the largest private bank in Turkey, called
IsBank, receives an average of 350 issue reports from the field every day.
Manually assigning the reported issues to the software development teams is
costly and cumbersome. We automate the issue assignments using data mining
approaches and share our experience gained by deploying the resulting system at
Softtech/IsBank. Automated issue assignment has been studied in the literature.
However, most of these works report the results obtained on open source
projects and the remaining few, although they use commercial, closed source
projects, carry out the assignments in a retrospective manner. We, on the other
hand, deploy the proposed approach, which has been making all the assignments
since Jan 12, 2018. This presents us with an unprecedented opportunity to
observe the practical effects of automated issue assignment in the field and to
carry out user studies, which have not been done before in this context. We
observe that it is not just about deploying a system for automated issue
assignment, but also about designing/changing the assignment process around the
system; the accuracy of the assignments does not have to be higher than that of
manual assignments in order for the system to be useful; deploying such a
system requires the development of additional functionalities, such as
detecting deteriorations in assignment accuracies in an online manner and
creating human-readable explanations for the assignments; stakeholders do not
necessarily resist change; and gradual transition can help stakeholders build
confidence.
</dc:description>
 <dc:description>Comment: Preprint for EMSE journal</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11777</dc:identifier>
 <dc:identifier>Empirical Software Engineering v25 (2020) 3544-3589</dc:identifier>
 <dc:identifier>doi:10.1007/s10664-020-09846-3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11778</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Total-Variation Sparseness-Promoting Method for the Synthesis of
  Contiguously Clustered Linear Arrays</dc:title>
 <dc:creator>Anselmi, N.</dc:creator>
 <dc:creator>Gottardi, G.</dc:creator>
 <dc:creator>Oliveri, G.</dc:creator>
 <dc:creator>Massa, A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  By exploiting an innovative total-variation compressive sensing (TV-CS)
formulation, a new method for the synthesis of physically contiguous clustered
linear arrays is presented. The computation of the feed network excitations is
recast as the maximization of the gradient sparsity of the excitation vector
subject to matching a user-defined pattern. The arising TV-CS functional is
then optimized by means of a deterministic alternating direction algorithm. A
selected set of representative numerical results, drawn from a wide validation,
is reported to illustrate the potentialities and the limitations of the
proposed approach when clustering arrays of both ideal and realistic antenna
elements. Comparisons with some competitive state-of-the-art subarraying
techniques are performed as well.
</dc:description>
 <dc:date>2021-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11778</dc:identifier>
 <dc:identifier>IEEE Transactions on Antennas and Propagation, vol. 67, no. 7,
  July 2019</dc:identifier>
 <dc:identifier>doi:10.1109/TAP.2019.2911375</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11779</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating a bot detection model on git commit messages</dc:title>
 <dc:creator>Golzadeh, Mehdi</dc:creator>
 <dc:creator>Decan, Alexandre</dc:creator>
 <dc:creator>Mens, Tom</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Detecting the presence of bots in distributed software development activity
is very important in order to prevent bias in large-scale socio-technical
empirical analyses. In previous work, we proposed a classification model to
detect bots in GitHub repositories based on the pull request and issue comments
of GitHub accounts. The current study generalises the approach to git
contributors based on their commit messages. We train and evaluate the
classification model on a large dataset of 6,922 git contributors. The original
model based on pull request and issue comments obtained a precision of 0.77 on
this dataset. Retraining the classification model on git commit messages
increased the precision to 0.80. As a proof-of-concept, we implemented this
model in BoDeGiC, an open source command-line tool to detect bots in git
repositories.
</dc:description>
 <dc:description>Comment: 4 pages, 1 pages of references</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11779</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11780</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Autoregressive Belief Propagation for Decoding Block Codes</dc:title>
 <dc:creator>Nachmani, Eliya</dc:creator>
 <dc:creator>Wolf, Lior</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We revisit recent methods that employ graph neural networks for decoding
error correcting codes and employ messages that are computed in an
autoregressive manner. The outgoing messages of the variable nodes are
conditioned not only on the incoming messages, but also on an estimation of the
SNR and on the inferred codeword and on two downstream computations: (i) an
extended vector of parity check outcomes, (ii) the mismatch between the
inferred codeword and the re-encoding of the information bits of this codeword.
Unlike most learned methods in the field, our method violates the symmetry
conditions that enable the other methods to train exclusively with the
zero-word. Despite not having the luxury of training on a single word, and the
inability to train on more than a small fraction of the relevant sample space,
we demonstrate effective training. The new method obtains a bit error rate that
outperforms the latest methods by a sizable margin.
</dc:description>
 <dc:date>2021-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11780</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11781</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Metric Learning: Towards a Scalable Metric Space to Accommodate
  Multiple Semantic Scales</dc:title>
 <dc:creator>Sun, Yifan</dc:creator>
 <dc:creator>Zhu, Yuke</dc:creator>
 <dc:creator>Zhang, Yuhan</dc:creator>
 <dc:creator>Zheng, Pengkun</dc:creator>
 <dc:creator>Qiu, Xi</dc:creator>
 <dc:creator>Zhang, Chi</dc:creator>
 <dc:creator>Wei, Yichen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper introduces a new fundamental characteristic, \ie, the dynamic
range, from real-world metric tools to deep visual recognition. In metrology,
the dynamic range is a basic quality of a metric tool, indicating its
flexibility to accommodate various scales. Larger dynamic range offers higher
flexibility. In visual recognition, the multiple scale problem also exist.
Different visual concepts may have different semantic scales. For example,
``Animal'' and ``Plants'' have a large semantic scale while ``Elk'' has a much
smaller one. Under a small semantic scale, two different elks may look quite
\emph{different} to each other . However, under a large semantic scale (\eg,
animals and plants), these two elks should be measured as being \emph{similar}.
%We argue that such flexibility is also important for deep metric learning,
because different visual concepts indeed correspond to different semantic
scales.
  Introducing the dynamic range to deep metric learning, we get a novel
computer vision task, \ie, the Dynamic Metric Learning. It aims to learn a
scalable metric space to accommodate visual concepts across multiple semantic
scales. Based on three types of images, \emph{i.e.}, vehicle, animal and online
products, we construct three datasets for Dynamic Metric Learning. We benchmark
these datasets with popular deep metric learning methods and find Dynamic
Metric Learning to be very challenging. The major difficulty lies in a conflict
between different scales: the discriminative ability under a small scale
usually compromises the discriminative ability under a large one, and vice
versa. As a minor contribution, we propose Cross-Scale Learning (CSL) to
alleviate such conflict. We show that CSL consistently improves the baseline on
all the three datasets. The datasets and the code will be publicly available at
https://github.com/SupetZYK/DynamicMetricLearning.
</dc:description>
 <dc:description>Comment: 8pages, accepted by CVPR 2021</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11781</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11785</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entangled q-Convolutional Neural Nets</dc:title>
 <dc:creator>Anagiannis, Vassilis</dc:creator>
 <dc:creator>Cheng, Miranda C. N.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We introduce a machine learning model, the q-CNN model, sharing key features
with convolutional neural networks and admitting a tensor network description.
As examples, we apply q-CNN to the MNIST and Fashion MNIST classification
tasks. We explain how the network associates a quantum state to each
classification label, and study the entanglement structure of these network
states. In both our experiments on the MNIST and Fashion-MNIST datasets, we
observe a distinct increase in both the left/right as well as the up/down
bipartition entanglement entropy during training as the network learns the fine
features of the data. More generally, we observe a universal negative
correlation between the value of the entanglement entropy and the value of the
cost function, suggesting that the network needs to learn the entanglement
structure in order the perform the task accurately. This supports the
possibility of exploiting the entanglement structure as a guide to design the
machine learning algorithm suitable for given tasks.
</dc:description>
 <dc:date>2021-03-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11785</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11786</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>JPS-daprinfo: A Dataset for Japanese Dialog Act Analysis and
  People-related Information Detection</dc:title>
 <dc:creator>Fu, Changzeng</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We conducted a labeling work on a spoken Japanese dataset (I-JAS) for the
text classification, which contains 50 interview dialogues of two-way Japanese
conversation that discuss the participants' past present and future. Each
dialogue is 30 minutes long. From this dataset, we selected the interview
dialogues of native Japanese speakers as the samples. Given the dataset, we
annotated sentences with 13 labels. The labeling work was conducted by native
Japanese speakers who have experiences with data annotation. The total amount
of the annotated samples is 20130.
</dc:description>
 <dc:date>2021-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11786</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11787</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Competitive Perimeter Defense on a Line</dc:title>
 <dc:creator>Bajaj, Shivam</dc:creator>
 <dc:creator>Torng, Eric</dc:creator>
 <dc:creator>Bopardikar, Shaunak D.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  We consider a perimeter defense problem in which a single vehicle seeks to
defend a compact region from intruders in a one-dimensional environment
parameterized by the perimeter size and the intruder-to-vehicle speed ratio.
The intruders move inward with fixed speed and direction to reach the
perimeter. We provide both positive and negative worst-case performance results
over the parameter space using competitive analysis. We first establish
fundamental limits by identifying the most difficult parameter combinations
that admit no $c$-competitive algorithms for any constant $c\geq 1$ and
slightly easier parameter combinations in which every algorithm is at best
$2$-competitive. We then design three classes of algorithms and prove they are
$1$, $2$, and $4$-competitive, respectively, for increasingly difficult
parameter combinations. Finally, we present numerical studies that provide
insights into the performance of these algorithms against stochastically
generated intruders.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11789</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time-Domain Hybrid PAM for Data-Rate and Distance Adaptive UWOC System</dc:title>
 <dc:creator>Kodama, T.</dc:creator>
 <dc:creator>Aizat, M.</dc:creator>
 <dc:creator>Kobori, F.</dc:creator>
 <dc:creator>Kimura, T.</dc:creator>
 <dc:creator>Inoue, Y.</dc:creator>
 <dc:creator>Jinno, M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  The challenge for next-generation underwater optical wireless communication
systems is to develop optical transceivers that can operate with low power
consumption by maximizing the transmission capacity according to the
transmission distance between transmitters and receivers. This study proposes
an underwater wireless optical communication (UWOC) system using an optical
transceiver with an optimum transmission rate for the deep sea with near-pure
water properties. As a method for actualizing an optical transceiver with an
optimum transmission rate in a UWOC system, time-domain hybrid pulse amplitude
modulation (PAM) (TDHP) using a transmission rate and distance-adaptive
intensity modulation/direct detection optical transceiver is considered. In the
TDHP method, variable transmission capacity is actualized while changing the
generation ratio of two intensity-modulated signals with different noise
immunities in the time domain. Three different color laser diodes (LDs), red,
blue, and green are used in an underwater channel transmission transceiver that
comprises the LD and a photodiode. The maximum transmission distance while
changing the incidence of PAM 2 and PAM 4 signals that calibrate the TDHP in a
pure transmission line and how the maximum transmission distance changes when
the optical transmitter/receiver spatial optical system is altered from the
optimum conditions are clarified based on numerical calculation and simulation.
To the best knowledge of the authors, there is no other research on data-rate
and distance adaptive UWOC system that applies the TDHP signal with power
optimization between two modulation formats.
</dc:description>
 <dc:date>2021-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11789</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11792</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparing the Performance of NLP Toolkits and Evaluation measures in
  Legal Tech</dc:title>
 <dc:creator>Khan, Muhammad Zohaib</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Recent developments in Natural Language Processing have led to the
introduction of state-of-the-art Neural Language Models, enabled with
unsupervised transferable learning, using different pretraining objectives.
While these models achieve excellent results on the downstream NLP tasks,
various domain adaptation techniques can improve their performance on
domain-specific tasks. We compare and analyze the pretrained Neural Language
Models, XLNet (autoregressive), and BERT (autoencoder) on the Legal Tasks.
Results show that XLNet Model performs better on our Sequence Classification
task of Legal Opinions Classification, whereas BERT produces better results on
the NER task. We use domain-specific pretraining and additional legal
vocabulary to adapt BERT Model further to the Legal Domain. We prepared
multiple variants of the BERT Model, using both methods and their combination.
Comparing our variants of the BERT Model, specializing in the Legal Domain, we
conclude that both additional pretraining and vocabulary techniques enhance the
BERT model's performance on the Legal Opinions Classification task. Additional
legal vocabulary improves BERT's performance on the NER task. Combining the
pretraining and vocabulary techniques further improves the final results. Our
Legal-Vocab-BERT Model gives the best results on the Legal Opinions Task,
outperforming the larger pretrained general Language Models, i.e., BERT-Base
and XLNet-Base.
</dc:description>
 <dc:date>2021-03-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11794</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph Ensemble Learning over Multiple Dependency Trees for Aspect-level
  Sentiment Classification</dc:title>
 <dc:creator>Hou, Xiaochen</dc:creator>
 <dc:creator>Qi, Peng</dc:creator>
 <dc:creator>Wang, Guangtao</dc:creator>
 <dc:creator>Ying, Rex</dc:creator>
 <dc:creator>Huang, Jing</dc:creator>
 <dc:creator>He, Xiaodong</dc:creator>
 <dc:creator>Zhou, Bowen</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Recent work on aspect-level sentiment classification has demonstrated the
efficacy of incorporating syntactic structures such as dependency trees with
graph neural networks(GNN), but these approaches are usually vulnerable to
parsing errors. To better leverage syntactic information in the face of
unavoidable errors, we propose a simple yet effective graph ensemble technique,
GraphMerge, to make use of the predictions from differ-ent parsers. Instead of
assigning one set of model parameters to each dependency tree, we first combine
the dependency relations from different parses before applying GNNs over the
resulting graph. This allows GNN mod-els to be robust to parse errors at no
additional computational cost, and helps avoid overparameterization and
overfitting from GNN layer stacking by introducing more connectivity into the
ensemble graph. Our experiments on the SemEval 2014 Task 4 and ACL 14 Twitter
datasets show that our GraphMerge model not only outperforms models with single
dependency tree, but also beats other ensemble mod-els without adding model
parameters.
</dc:description>
 <dc:description>Comment: Accepted by NAACL 2021</dc:description>
 <dc:date>2021-03-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11795</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simpson's Bias in NLP Training</dc:title>
 <dc:creator>Yuan, Fei</dc:creator>
 <dc:creator>Zhang, Longtu</dc:creator>
 <dc:creator>Bojun, Huang</dc:creator>
 <dc:creator>Liang, Yaobo</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In most machine learning tasks, we evaluate a model $M$ on a given data
population $S$ by measuring a population-level metric $F(S;M)$. Examples of
such evaluation metric $F$ include precision/recall for (binary) recognition,
the F1 score for multi-class classification, and the BLEU metric for language
generation. On the other hand, the model $M$ is trained by optimizing a
sample-level loss $G(S_t;M)$ at each learning step $t$, where $S_t$ is a subset
of $S$ (a.k.a. the mini-batch). Popular choices of $G$ include cross-entropy
loss, the Dice loss, and sentence-level BLEU scores. A fundamental assumption
behind this paradigm is that the mean value of the sample-level loss $G$, if
averaged over all possible samples, should effectively represent the
population-level metric $F$ of the task, such as, that $\mathbb{E}[ G(S_t;M) ]
\approx F(S;M)$.
  In this paper, we systematically investigate the above assumption in several
NLP tasks. We show, both theoretically and experimentally, that some popular
designs of the sample-level loss $G$ may be inconsistent with the true
population-level metric $F$ of the task, so that models trained to optimize the
former can be substantially sub-optimal to the latter, a phenomenon we call it,
Simpson's bias, due to its deep connections with the classic paradox known as
Simpson's reversal paradox in statistics and social sciences.
</dc:description>
 <dc:description>Comment: AAAI 2021</dc:description>
 <dc:date>2021-03-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11795</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11798</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepStyle: User Style Embedding for Authorship Attribution of Short
  Texts</dc:title>
 <dc:creator>Hu, Zhiqiang</dc:creator>
 <dc:creator>Lee, Roy Ka-Wei</dc:creator>
 <dc:creator>Wang, Lei</dc:creator>
 <dc:creator>Lim, Ee-Peng</dc:creator>
 <dc:creator>Dai, Bo</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Authorship attribution (AA), which is the task of finding the owner of a
given text, is an important and widely studied research topic with many
applications. Recent works have shown that deep learning methods could achieve
significant accuracy improvement for the AA task. Nevertheless, most of these
proposed methods represent user posts using a single type of feature (e.g.,
word bi-grams) and adopt a text classification approach to address the task.
Furthermore, these methods offer very limited explainability of the AA results.
In this paper, we address these limitations by proposing DeepStyle, a novel
embedding-based framework that learns the representations of users' salient
writing styles. We conduct extensive experiments on two real-world datasets
from Twitter and Weibo. Our experiment results show that DeepStyle outperforms
the state-of-the-art baselines on the AA task.
</dc:description>
 <dc:description>Comment: Paper accepted for 4th APWeb-WAIM Joint Conference on Web and Big
  Data</dc:description>
 <dc:date>2021-03-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11799</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepHate: Hate Speech Detection via Multi-Faceted Text Representations</dc:title>
 <dc:creator>Cao, Rui</dc:creator>
 <dc:creator>Lee, Roy Ka-Wei</dc:creator>
 <dc:creator>Hoang, Tuan-Anh</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Online hate speech is an important issue that breaks the cohesiveness of
online social communities and even raises public safety concerns in our
societies. Motivated by this rising issue, researchers have developed many
traditional machine learning and deep learning methods to detect hate speech in
online social platforms automatically. However, most of these methods have only
considered single type textual feature, e.g., term frequency, or using word
embeddings. Such approaches neglect the other rich textual information that
could be utilized to improve hate speech detection. In this paper, we propose
DeepHate, a novel deep learning model that combines multi-faceted text
representations such as word embeddings, sentiments, and topical information,
to detect hate speech in online social platforms. We conduct extensive
experiments and evaluate DeepHate on three large publicly available real-world
datasets. Our experiment results show that DeepHate outperforms the
state-of-the-art baselines on the hate speech detection task. We also perform
case studies to provide insights into the salient features that best aid in
detecting hate speech in online social platforms.
</dc:description>
 <dc:description>Comment: Paper Accepted for 12th International ACM Conference on Web Science</dc:description>
 <dc:date>2021-03-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11799</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11800</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AngryBERT: Joint Learning Target and Emotion for Hate Speech Detection</dc:title>
 <dc:creator>Awal, Md Rabiul</dc:creator>
 <dc:creator>Cao, Rui</dc:creator>
 <dc:creator>Lee, Roy Ka-Wei</dc:creator>
 <dc:creator>Mitrovic, Sandra</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Automated hate speech detection in social media is a challenging task that
has recently gained significant traction in the data mining and Natural
Language Processing community. However, most of the existing methods adopt a
supervised approach that depended heavily on the annotated hate speech
datasets, which are imbalanced and often lack training samples for hateful
content. This paper addresses the research gaps by proposing a novel multitask
learning-based model, AngryBERT, which jointly learns hate speech detection
with sentiment classification and target identification as secondary relevant
tasks. We conduct extensive experiments to augment three commonly-used hate
speech detection datasets. Our experiment results show that AngryBERT
outperforms state-of-the-art single-task-learning and multitask learning
baselines. We conduct ablation studies and case studies to empirically examine
the strengths and characteristics of our AngryBERT model and show that the
secondary tasks are able to improve hate speech detection.
</dc:description>
 <dc:description>Comment: Paper Accepted for 25th Pacific-Asia Conference on Knowledge
  Discovery and Data Mining</dc:description>
 <dc:date>2021-03-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11806</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tackling Racial Bias in Automated Online Hate Detection: Towards Fair
  and Accurate Classification of Hateful Online Users Using Geometric Deep
  Learning</dc:title>
 <dc:creator>Ahmed, Zo</dc:creator>
 <dc:creator>Vidgen, Bertie</dc:creator>
 <dc:creator>Hale, Scott A.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Online hate is a growing concern on many social media platforms and other
sites. To combat it, technology companies are increasingly identifying and
sanctioning `hateful users' rather than simply moderating hateful content. Yet,
most research in online hate detection to date has focused on hateful content.
This paper examines how fairer and more accurate hateful user detection systems
can be developed by incorporating social network information through geometric
deep learning. Geometric deep learning dynamically learns information-rich
network representations and can generalise to unseen nodes. This is essential
for moving beyond manually engineered network features, which lack scalability
and produce information-sparse network representations. This paper compares the
accuracy of geometric deep learning with other techniques which either exclude
network information or incorporate it through manual feature engineering (e.g.,
node2vec). It also evaluates the fairness of these techniques using the
`predictive equality' criteria, comparing the false positive rates on a subset
of 136 African-American users with 4836 other users. Geometric deep learning
produces the most accurate and fairest classifier, with an AUC score of 90.8\%
on the entire dataset and a false positive rate of zero among the
African-American subset for the best performing model. This highlights the
benefits of more effectively incorporating social network features in automated
hateful user detection. Such an approach is also easily operationalized for
real-world content moderation as it has an efficient and scalable design.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11806</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11821</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regenerativity of Viterbi process for pairwise Markov models</dc:title>
 <dc:creator>Lember, J&#xfc;ri</dc:creator>
 <dc:creator>Sova, Joonas</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  For hidden Markov models one of the most popular estimates of the hidden
chain is the Viterbi path -- the path maximising the posterior probability. We
consider a more general setting, called the pairwise Markov model (PMM), where
the joint process consisting of finite-state hidden process and observation
process is assumed to be a Markov chain. It has been recently proven that under
some conditions the Viterbi path of the PMM can almost surely be extended to
infinity, thereby defining the infinite Viterbi decoding of the observation
sequence, called the Viterbi process. This was done by constructing a block of
observations, called a barrier, which ensures that the Viterbi path goes trough
a given state whenever this block occurs in the observation sequence. In this
paper we prove that the joint process consisting of Viterbi process and PMM is
regenerative. The proof involves a delicate construction of regeneration times
which coincide with the occurrences of barriers. As one possible application of
our theory, some results on the asymptotics of the Viterbi training algorithm
are derived.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1708.03799</dc:description>
 <dc:date>2021-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11821</dc:identifier>
 <dc:identifier>Journal of Theoretical Probability volume 34 (2021)</dc:identifier>
 <dc:identifier>doi:10.1007/s10959-020-01022-z</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11823</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Organizing mmWave MIMO Cell-Free Networks With Hybrid Beamforming:
  A Hierarchical DRL-Based Design</dc:title>
 <dc:creator>Al-Eryani, Yasser</dc:creator>
 <dc:creator>Hossain, Ekram</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In a cell-free wireless network, distributed access points (APs) jointly
serve all user equipments (UEs) within the their coverage area by using the
same time/frequency resources. In this paper, we develop a novel downlink
cell-free multiple-input multiple-output (MIMO) millimeter wave (mmWave)
network architecture that enables all APs and UEs to dynamically self-partition
into a set of independent cell-free subnetworks in a time-slot basis. For this,
we propose several network partitioning algorithms based on deep reinforcement
learning (DRL). Furthermore, to mitigate interference between different
cell-free subnetworks, we develop a novel hybrid analog beamsteering-digital
beamforming model that zero-forces interference among cell-free subnetworks and
at the same time maximizes the instantaneous sum-rate of all UEs within each
subnetwork. Specifically, the hybrid beamforming model is implemented by using
a novel mixed DRL-convex optimization method in which analog beamsteering
between APs and UEs is conducted based on DRL while digital beamforming is
modeled and solved as a convex optimization problem. The DRL models for network
clustering and hybrid beamsteering are combined into a single hierarchical DRL
design that enables exchange of DRL agents' experiences during both network
training and operation. We also benchmark the performance of DRL models for
clustering and beamsteering in terms of network performance, convergence rate,
and computational complexity.
</dc:description>
 <dc:date>2021-03-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11823</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11825</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Digital Humanities to Quantum Humanities: Potentials and
  Applications</dc:title>
 <dc:creator>Barzen, Johanna</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  Quantum computers are becoming real. Therefore, it is promising to use their
potentials in different applications areas, which includes research in the
humanities. Due to an increasing amount of data that needs to be processed in
the digital humanities the use of quantum computers can contribute to this
research area. To give an impression on how beneficial such involvement of
quantum computers can be when analyzing data from the humanities, a use case
from the media science is presented. Therefore, both the theoretical basis and
the tooling support for analyzing the data from our digital humanities project
MUSE is described. This includes a data analysis pipeline, containing e.g.
various approaches for data preparation, feature engineering, clustering, and
classification where several steps can be realized classically, but also
supported by quantum computers.
</dc:description>
 <dc:description>Comment: To appear in the book Quantum Computing in the Arts and Humanities:
  An Introduction to Core Concepts, Theory and Applications. E. R. Miranda
  (Ed.). Cham: Springer Nature, 202x</dc:description>
 <dc:date>2021-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11825</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11832</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep RGB-D Saliency Detection with Depth-Sensitive Attention and
  Automatic Multi-Modal Fusion</dc:title>
 <dc:creator>Sun, Peng</dc:creator>
 <dc:creator>Zhang, Wenhu</dc:creator>
 <dc:creator>Wang, Huanyu</dc:creator>
 <dc:creator>Li, Songyuan</dc:creator>
 <dc:creator>Li, Xi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  RGB-D salient object detection (SOD) is usually formulated as a problem of
classification or regression over two modalities, i.e., RGB and depth. Hence,
effective RGBD feature modeling and multi-modal feature fusion both play a
vital role in RGB-D SOD. In this paper, we propose a depth-sensitive RGB
feature modeling scheme using the depth-wise geometric prior of salient
objects. In principle, the feature modeling scheme is carried out in a
depth-sensitive attention module, which leads to the RGB feature enhancement as
well as the background distraction reduction by capturing the depth geometry
prior. Moreover, to perform effective multi-modal feature fusion, we further
present an automatic architecture search approach for RGB-D SOD, which does
well in finding out a feasible architecture from our specially designed
multi-modal multi-scale search space. Extensive experiments on seven standard
benchmarks demonstrate the effectiveness of the proposed approach against the
state-of-the-art.
</dc:description>
 <dc:description>Comment: Accepted by CVPR2021, Oral</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11832</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11833</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AutoSpace: Neural Architecture Search with Less Human Interference</dc:title>
 <dc:creator>Zhou, Daquan</dc:creator>
 <dc:creator>Jin, Xiaojie</dc:creator>
 <dc:creator>Lian, Xiaochen</dc:creator>
 <dc:creator>Yang, Linjie</dc:creator>
 <dc:creator>Xue, Yujing</dc:creator>
 <dc:creator>Hou, Qibin</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Current neural architecture search (NAS) algorithms still require expert
knowledge and effort to design a search space for network construction. In this
paper, we consider automating the search space design to minimize human
interference, which however faces two challenges: the explosive complexity of
the exploration space and the expensive computation cost to evaluate the
quality of different search spaces. To solve them, we propose a novel
differentiable evolutionary framework named AutoSpace, which evolves the search
space to an optimal one with following novel techniques: a differentiable
fitness scoring function to efficiently evaluate the performance of cells and a
reference architecture to speedup the evolution procedure and avoid falling
into sub-optimal solutions. The framework is generic and compatible with
additional computational constraints, making it feasible to learn specialized
search spaces that fit different computational budgets. With the learned search
space, the performance of recent NAS algorithms can be improved significantly
compared with using previously manually designed spaces. Remarkably, the models
generated from the new search space achieve 77.8% top-1 accuracy on ImageNet
under the mobile setting (MAdds &lt; 500M), out-performing previous SOTA
EfficientNet-B0 by 0.7%. All codes will be made public.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11833</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11835</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bridging the gap between supervised classification and unsupervised
  topic modelling for social-media assisted crisis management</dc:title>
 <dc:creator>Brunila, Mikael</dc:creator>
 <dc:creator>Zhao, Rosie</dc:creator>
 <dc:creator>Mircea, Andrei</dc:creator>
 <dc:creator>Lumley, Sam</dc:creator>
 <dc:creator>Sieber, Renee</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Social media such as Twitter provide valuable information to crisis managers
and affected people during natural disasters. Machine learning can help
structure and extract information from the large volume of messages shared
during a crisis; however, the constantly evolving nature of crises makes
effective domain adaptation essential. Supervised classification is limited by
unchangeable class labels that may not be relevant to new events, and
unsupervised topic modelling by insufficient prior knowledge. In this paper, we
bridge the gap between the two and show that BERT embeddings finetuned on
crisis-related tweet classification can effectively be used to adapt to a new
crisis, discovering novel topics while preserving relevant classes from
supervised training, and leveraging bidirectional self-attention to extract
topic keywords. We create a dataset of tweets from a snowstorm to evaluate our
method's transferability to new crises, and find that it outperforms
traditional topic models in both automatic, and human evaluations grounded in
the needs of crisis managers. More broadly, our method can be used for textual
domain adaptation where the latent classes are unknown but overlap with known
classes from other domains.
</dc:description>
 <dc:description>Comment: Adapt-NLP @EACL2021; first three authors contributed equally; code
  available at https://github.com/smacawi/bert-topics/</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11845</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Simulate on Sparse Trajectory Data</dc:title>
 <dc:creator>Wei, Hua</dc:creator>
 <dc:creator>Chen, Chacha</dc:creator>
 <dc:creator>Liu, Chang</dc:creator>
 <dc:creator>Zheng, Guanjie</dc:creator>
 <dc:creator>Li, Zhenhui</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Simulation of the real-world traffic can be used to help validate the
transportation policies. A good simulator means the simulated traffic is
similar to real-world traffic, which often requires dense traffic trajectories
(i.e., with a high sampling rate) to cover dynamic situations in the real
world. However, in most cases, the real-world trajectories are sparse, which
makes simulation challenging. In this paper, we present a novel framework
ImInGAIL to address the problem of learning to simulate the driving behavior
from sparse real-world data. The proposed architecture incorporates data
interpolation with the behavior learning process of imitation learning. To the
best of our knowledge, we are the first to tackle the data sparsity issue for
behavior learning problems. We investigate our framework on both synthetic and
real-world trajectory datasets of driving vehicles, showing that our method
outperforms various baselines and state-of-the-art methods.
</dc:description>
 <dc:description>Comment: Accepted by ECML-PKDD 2020, Best Applied Data Science Paper. 16
  pages, 6 figures</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11845</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11847</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discrete cosine transform LSQR and GMRES methods for multidimensional
  ill-posed problems</dc:title>
 <dc:creator>Guide, M. El</dc:creator>
 <dc:creator>Ichi, A. El</dc:creator>
 <dc:creator>Jbilou, K.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65F10, 65F22</dc:subject>
 <dc:description>  In the present work, we propose new tensor Krylov subspace method for ill
posed linear tensor problems such as in color or video image restoration. Those
methods are based on the tensor-tensor discrete cosine transform that gives
fast tensor-tensor product computations. In particular, we will focus on the
tensor discrete cosine versions of GMRES, Golub-Kahan bidiagonalisation and
LSQR methods. The presented numerical tests show that the methods are very fast
and give good accuracies when solving some linear tensor ill-posed problems.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:2006.07133</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11847</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11852</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Racial Bias in Jury Selection</dc:title>
 <dc:creator>Dunn, Jack</dc:creator>
 <dc:creator>Zhuo, Ying Daisy</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  To support the 2019 U.S. Supreme Court case &quot;Flowers v. Mississippi&quot;, APM
Reports collated historical court records to assess whether the State exhibited
a racial bias in striking potential jurors. This analysis used backward
stepwise logistic regression to conclude that race was a significant factor,
however this method for selecting relevant features is only a heuristic, and
additionally cannot consider interactions between features. We apply Optimal
Feature Selection to identify the globally-optimal subset of features and
affirm that there is significant evidence of racial bias in the strike
decisions. We also use Optimal Classification Trees to segment the juror
population subgroups with similar characteristics and probability of being
struck, and find that three of these subgroups exhibit significant racial
disparity in strike rate, pinpointing specific areas of bias in the dataset.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11852</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11859</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Part of speech and gramset tagging algorithms for unknown words based on
  morphological dictionaries of the Veps and Karelian languages</dc:title>
 <dc:creator>Krizhanovsky, Andrew</dc:creator>
 <dc:creator>Krizhanovsky, Natalia</dc:creator>
 <dc:creator>Novak, Irina</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>68T50</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:subject>H.3.6</dc:subject>
 <dc:description>  This research devoted to the low-resource Veps and Karelian languages.
Algorithms for assigning part of speech tags to words and grammatical
properties to words are presented in the article. These algorithms use our
morphological dictionaries, where the lemma, part of speech and a set of
grammatical features (gramset) are known for each word form. The algorithms are
based on the analogy hypothesis that words with the same suffixes are likely to
have the same inflectional models, the same part of speech and gramset. The
accuracy of these algorithms were evaluated and compared. 313 thousand Vepsian
and 66 thousand Karelian words were used to verify the accuracy of these
algorithms. The special functions were designed to assess the quality of
results of the developed algorithms. 92.4% of Vepsian words and 86.8% of
Karelian words were assigned a correct part of speech by the developed
algorithm. 95.3% of Vepsian words and 90.7% of Karelian words were assigned a
correct gramset by our algorithm. Morphological and semantic tagging of texts,
which are closely related and inseparable in our corpus processes, are
described in the paper.
</dc:description>
 <dc:description>Comment: 17 pages, 4 tables, 7 figures, published in the conference proceeding</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11859</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11860</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatio-Temporal Neural Network for Fitting and Forecasting COVID-19</dc:title>
 <dc:creator>Niu, Yi-Shuai</dc:creator>
 <dc:creator>Ding, Wentao</dc:creator>
 <dc:creator>Hu, Junpeng</dc:creator>
 <dc:creator>Xu, Wenxu</dc:creator>
 <dc:creator>Canu, Stephane</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We established a Spatio-Temporal Neural Network, namely STNN, to forecast the
spread of the coronavirus COVID-19 outbreak worldwide in 2020. The basic
structure of STNN is similar to the Recurrent Neural Network (RNN)
incorporating with not only temporal data but also spatial features. Two
improved STNN architectures, namely the STNN with Augmented Spatial States
(STNN-A) and the STNN with Input Gate (STNN-I), are proposed, which ensure more
predictability and flexibility. STNN and its variants can be trained using
Stochastic Gradient Descent (SGD) algorithm and its improved variants (e.g.,
Adam, AdaGrad and RMSProp). Our STNN models are compared with several classical
epidemic prediction models, including the fully-connected neural network
(BPNN), and the recurrent neural network (RNN), the classical curve fitting
models, as well as the SEIR dynamical system model. Numerical simulations
demonstrate that STNN models outperform many others by providing more accurate
fitting and prediction, and by handling both spatial and temporal data.
</dc:description>
 <dc:description>Comment: 20 pages, 8 figures</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11864</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recovery of Joint Probability Distribution from one-way marginals: Low
  rank Tensors and Random Projections</dc:title>
 <dc:creator>Vora, Jian</dc:creator>
 <dc:creator>Gurumoorthy, Karthik S.</dc:creator>
 <dc:creator>Rajwade, Ajit</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Joint probability mass function (PMF) estimation is a fundamental machine
learning problem. The number of free parameters scales exponentially with
respect to the number of random variables. Hence, most work on nonparametric
PMF estimation is based on some structural assumptions such as clique
factorization adopted by probabilistic graphical models, imposition of low rank
on the joint probability tensor and reconstruction from 3-way or 2-way
marginals, etc. In the present work, we link random projections of data to the
problem of PMF estimation using ideas from tomography. We integrate this idea
with the idea of low-rank tensor decomposition to show that we can estimate the
joint density from just one-way marginals in a transformed space. We provide a
novel algorithm for recovering factors of the tensor from one-way marginals,
test it across a variety of synthetic and real-world datasets, and also perform
MAP inference on the estimated model for classification.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11864</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11865</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>#LaCulturaNonsiFerma: Report on Use and Diffusion of #Hashtags from the
  Italian Cultural Institutions during the COVID-19 outbreak</dc:title>
 <dc:creator>Carlino, Carola</dc:creator>
 <dc:creator>Nolano, Gennaro</dc:creator>
 <dc:creator>di Buono, Maria Pia</dc:creator>
 <dc:creator>Monti, Johanna</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  This report presents an analysis of #hashtags used by Italian Cultural
Heritage institutions to promote and communicate cultural content during the
COVID-19 lock-down period in Italy. Several activities to support and engage
users' have been proposed using social media. Most of these activities present
one or more #hashtags which help to aggregate content and create a community on
specific topics. Results show that on one side Italian institutions have been
very proactive in adapting to the pandemic scenario and on the other side
users' reacted very positively increasing their participation in the proposed
activities.
</dc:description>
 <dc:description>Comment: 17 pages, 14 figures, 5 tables</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11865</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11871</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement Learning based on MPC/MHE for Unmodeled and Partially
  Observable Dynamics</dc:title>
 <dc:creator>Esfahani, Hossein Nejatbakhsh</dc:creator>
 <dc:creator>Kordabad, Arash Bahari</dc:creator>
 <dc:creator>Gros, Sebastien</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper proposes an observer-based framework for solving Partially
Observable Markov Decision Processes (POMDPs) when an accurate model is not
available. We first propose to use a Moving Horizon Estimation-Model Predictive
Control (MHE-MPC) scheme in order to provide a policy for the POMDP problem,
where the full state of the real process is not measured and necessarily known.
We propose to parameterize both MPC and MHE formulations, where certain
adjustable parameters are regarded for tuning the policy. In this paper, for
the sake of tackling the unmodeled and partially observable dynamics, we
leverage the Reinforcement Learning (RL) to tune the parameters of MPC and MHE
schemes jointly, with the closed-loop performance of the policy as a goal
rather than model fitting or the MHE performance. Illustrations show that the
proposed approach can effectively increase the performance of close-loop
control of systems formulated as POMDPs.
</dc:description>
 <dc:description>Comment: This paper has been accepted to 2021 American Control Conference
  (ACC) to be held in New Orleans, USA</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11871</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11873</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rate-Diverse Gaussian Multiple Access: Efficient Encoder and Decoder
  Designs</dc:title>
 <dc:creator>Chen, Pingping</dc:creator>
 <dc:creator>Shi, Long</dc:creator>
 <dc:creator>Fang, Yi</dc:creator>
 <dc:creator>Lau, Francis C. M.</dc:creator>
 <dc:creator>Cheng, Jun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  In this work, we develop a pair of rate-diverse encoder and decoder for a
two-user Gaussian multiple access channel (GMAC). The proposed scheme enables
the users to transmit with the same codeword length but different coding rates
under diverse user channel conditions. First, we propose the row-combining (RC)
method and row-extending (RE) method to design practical low-density
parity-check (LDPC) channel codes for rate-diverse GMAC. Second, we develop an
iterative rate-diverse joint user messages decoding (RDJD) algorithm for GMAC,
where all user messages are decoded with a single parity-check matrix. In
contrast to the conventional network-coded multiple access (NCMA) and
compute-forward multiple access (CFMA) schemes that first recover a linear
combination of the transmitted codewords and then decode both user messages,
this work can decode both the user messages simultaneously. Extrinsic
information transfer (EXIT) chart analysis and simulation results indicate that
RDJD can achieve gains up to 1.0 dB over NCMA and CFMA in the two-user GMAC. In
particular, we show that there exists an optimal rate allocation for the two
users to achieve the best decoding performance given the channel conditions and
sum rate.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11873</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11881</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Introspective Visuomotor Control: Exploiting Uncertainty in Deep
  Visuomotor Control for Failure Recovery</dc:title>
 <dc:creator>Hung, Chia-Man</dc:creator>
 <dc:creator>Sun, Li</dc:creator>
 <dc:creator>Wu, Yizhe</dc:creator>
 <dc:creator>Havoutis, Ioannis</dc:creator>
 <dc:creator>Posner, Ingmar</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:description>  End-to-end visuomotor control is emerging as a compelling solution for robot
manipulation tasks. However, imitation learning-based visuomotor control
approaches tend to suffer from a common limitation, lacking the ability to
recover from an out-of-distribution state caused by compounding errors. In this
paper, instead of using tactile feedback or explicitly detecting the failure
through vision, we investigate using the uncertainty of a policy neural
network. We propose a novel uncertainty-based approach to detect and recover
from failure cases. Our hypothesis is that policy uncertainties can implicitly
indicate the potential failures in the visuomotor control task and that robot
states with minimum uncertainty are more likely to lead to task success. To
recover from high uncertainty cases, the robot monitors its uncertainty along a
trajectory and explores possible actions in the state-action space to bring
itself to a more certain state. Our experiments verify this hypothesis and show
a significant improvement on task success rate: 12% in pushing, 15% in
pick-and-reach and 22% in pick-and-place.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures, 1 table</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11881</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11882</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generating Adversarial Computer Programs using Optimized Obfuscations</dc:title>
 <dc:creator>Srikant, Shashank</dc:creator>
 <dc:creator>Liu, Sijia</dc:creator>
 <dc:creator>Mitrovska, Tamara</dc:creator>
 <dc:creator>Chang, Shiyu</dc:creator>
 <dc:creator>Fan, Quanfu</dc:creator>
 <dc:creator>Zhang, Gaoyuan</dc:creator>
 <dc:creator>O'Reilly, Una-May</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Machine learning (ML) models that learn and predict properties of computer
programs are increasingly being adopted and deployed. These models have
demonstrated success in applications such as auto-completing code, summarizing
large programs, and detecting bugs and malware in programs. In this work, we
investigate principled ways to adversarially perturb a computer program to fool
such learned models, and thus determine their adversarial robustness. We use
program obfuscations, which have conventionally been used to avoid attempts at
reverse engineering programs, as adversarial perturbations. These perturbations
modify programs in ways that do not alter their functionality but can be
crafted to deceive an ML model when making a decision. We provide a general
formulation for an adversarial program that allows applying multiple
obfuscation transformations to a program in any language. We develop
first-order optimization algorithms to efficiently determine two key aspects --
which parts of the program to transform, and what transformations to use. We
show that it is important to optimize both these aspects to generate the best
adversarially perturbed program. Due to the discrete nature of this problem, we
also propose using randomized smoothing to improve the attack loss landscape to
ease optimization. We evaluate our work on Python and Java programs on the
problem of program summarization. We show that our best attack proposal
achieves a $52\%$ improvement over a state-of-the-art attack generation
approach for programs trained on a seq2seq model. We further show that our
formulation is better at training models that are robust to adversarial
attacks.
</dc:description>
 <dc:description>Comment: This work will be published at ICLR 2021</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11882</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11887</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deconvolution-and-convolution Networks</dc:title>
 <dc:creator>Yang, Yimin</dc:creator>
 <dc:creator>Zhang, Wandong</dc:creator>
 <dc:creator>Wu, Jonathan</dc:creator>
 <dc:creator>Zhao, Will</dc:creator>
 <dc:creator>Chen, Ao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  2D Convolutional neural network (CNN) has arguably become the de facto
standard for computer vision tasks. Recent findings, however, suggest that CNN
may not be the best option for 1D pattern recognition, especially for datasets
with over 1 M training samples, e.g., existing CNN-based methods for 1D signals
are highly reliant on human pre-processing. Common practices include utilizing
discrete Fourier transform (DFT) to reconstruct 1D signal into 2D array. To add
to extant knowledge, in this paper, a novel 1D data processing algorithm is
proposed for 1D big data analysis through learning a deep
deconvolutional-convolutional network. Rather than resorting to human-based
techniques, we employed deconvolution layers to convert 1 D signals into 2D
data. On top of the deconvolution model, the data was identified by a 2D CNN.
Compared with the existing 1D signal processing algorithms, DCNet boasts the
advantages of less human-made inference and higher generalization performance.
Our experimental results from a varying number of training patterns (50 K to 11
M) from classification and regression demonstrate the desirability of our new
approach.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11890</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coexistence of Communications and Cognitive MIMO Radar: Waveform Design
  and Prototype</dc:title>
 <dc:creator>Alaee-Kerahroodi, Mohammad</dc:creator>
 <dc:creator>Raei, Ehsan</dc:creator>
 <dc:creator>Kumar, Sumit</dc:creator>
 <dc:creator>Rao, Bhavani Shankar Mysore Rama</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  New generation of radar systems will need to coexist with other radio
frequency (RF) systems, anticipating their behavior and reacting appropriately
to avoid interference. In light of this requirement, this paper designs,
implements, and evaluates the performance of phase-only sequences (with
constant power) for intelligent spectrum utilization using the custom built
cognitive Multiple Input Multiple Output (MIMO) radar prototype. The proposed
transmit waveforms avoid the frequency bands occupied by narrowband interferers
or communication links, while simultaneously have a small cross-correlation
among each other to enable their separability at the MIMO radar receiver. The
performance of the optimized set of sequences obtained through solving a
non-convex bi-objective optimization problem, is compared with the
state-of-the-art counterparts, and its applicability is illustrated by the
developed prototype. A realistic Long Term Evolution (LTE) downlink is used for
the communications, and the real-time system implementation is validated and
evaluated through the throughput calculations for communications and the
detection performance measurement for the radar system.
</dc:description>
 <dc:description>Comment: 13 pages, 17 figures,</dc:description>
 <dc:date>2021-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11890</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11891</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Increasing Energy Efficiency of Massive-MIMO Network via Base Stations
  Switching using Reinforcement Learning and Radio Environment Maps</dc:title>
 <dc:creator>Hoffmann, Marcin</dc:creator>
 <dc:creator>Kryszkiewicz, Pawel</dc:creator>
 <dc:creator>Kliks, Adrian</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Energy Efficiency (EE) is of high importance while considering Massive
Multiple-Input Multiple-Output (M-MIMO) networks where base stations (BSs) are
equipped with an antenna array composed of up to hundreds of elements. M-MIMO
transmission, although highly spectrally efficient, results in high energy
consumption growing with the number of antennas. This paper investigates EE
improvement through switching on/off underutilized BSs. It is proposed to use
the location-aware approach, where data about an optimal active BSs set is
stored in a Radio Environment Map (REM). For efficient acquisition, processing
and utilization of the REM data, reinforcement learning (RL) algorithms are
used. State-of-the-art exploration/exploitation methods including e-greedy,
Upper Confidence Bound (UCB), and Gradient Bandit are evaluated. Then
analytical action filtering, and an REM-based Exploration Algorithm (REM-EA)
are proposed to improve the RL convergence time. Algorithms are evaluated using
an advanced, system-level simulator of an M-MIMO Heterogeneous Network (HetNet)
utilizing an accurate 3D-ray-tracing radio channel model. The proposed RL-based
BSs switching algorithm is proven to provide 70% gains in EE over a
state-of-the-art algorithm using an analytical heuristic. Moreover, the
proposed action filtering and REM-EA can reduce RL convergence time in relation
to the best-performing state-of-the-art exploration method by 60% and 83%,
respectively.
</dc:description>
 <dc:date>2021-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11891</dc:identifier>
 <dc:identifier>Computer Communications, Volume 169, 2021, Pages 232-242, ISSN
  0140-3664</dc:identifier>
 <dc:identifier>doi:10.1016/j.comcom.2021.01.012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11893</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Thresholding Greedy Pursuit for Sparse Recovery Problems</dc:title>
 <dc:creator>Le, Hai</dc:creator>
 <dc:creator>Novikov, Alexei</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We study here sparse recovery problems in the presence of additive noise. We
analyze a thresholding version of the CoSaMP algorithm, named Thresholding
Greedy Pursuit (TGP). We demonstrate that an appropriate choice of thresholding
parameter, even without the knowledge of sparsity level of the signal and
strength of the noise, can result in exact recovery with no false discoveries
as the dimension of the data increases to infinity.
</dc:description>
 <dc:description>Comment: First version</dc:description>
 <dc:date>2021-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11893</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11894</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mea culpa: How developers fix their own simple bugs differently from
  other developers</dc:title>
 <dc:creator>Zhu, Wenhan</dc:creator>
 <dc:creator>Godfrey, Michael W.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In this work, we study how the authorship of code affects bug-fixing commits
using the SStuBs dataset, a collection of single-statement bug fix changes in
popular Java Maven projects. More specifically, we study the differences in
characteristics between simple bug fixes by the original author -- that is, the
developer who submitted the bug-inducing commit -- and by different developers
(i.e., non-authors). Our study shows that nearly half (i.e., 44.3%) of simple
bugs are fixed by a different developer. We found that bug fixes by the
original author and by different developers differed qualitatively and
quantitatively. We observed that bug-fixing time by authors is much shorter
than that of other developers. We also found that bug-fixing commits by authors
tended to be larger in size and scope, and address multiple issues, whereas
bug-fixing commits by other developers tended to be smaller and more focused on
the bug itself. Future research can further study the different patterns in
bug-fixing and create more tailored tools based on the developer's needs.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures, accepted as MSR challenge 2021</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11894</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11897</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Context-Aware Layout to Image Generation with Enhanced Object Appearance</dc:title>
 <dc:creator>He, Sen</dc:creator>
 <dc:creator>Liao, Wentong</dc:creator>
 <dc:creator>Yang, Michael Ying</dc:creator>
 <dc:creator>Yang, Yongxin</dc:creator>
 <dc:creator>Song, Yi-Zhe</dc:creator>
 <dc:creator>Rosenhahn, Bodo</dc:creator>
 <dc:creator>Xiang, Tao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A layout to image (L2I) generation model aims to generate a complicated image
containing multiple objects (things) against natural background (stuff),
conditioned on a given layout. Built upon the recent advances in generative
adversarial networks (GANs), existing L2I models have made great progress.
However, a close inspection of their generated images reveals two major
limitations: (1) the object-to-object as well as object-to-stuff relations are
often broken and (2) each object's appearance is typically distorted lacking
the key defining characteristics associated with the object class. We argue
that these are caused by the lack of context-aware object and stuff feature
encoding in their generators, and location-sensitive appearance representation
in their discriminators. To address these limitations, two new modules are
proposed in this work. First, a context-aware feature transformation module is
introduced in the generator to ensure that the generated feature encoding of
either object or stuff is aware of other co-existing objects/stuff in the
scene. Second, instead of feeding location-insensitive image features to the
discriminator, we use the Gram matrix computed from the feature maps of the
generated object images to preserve location-sensitive information, resulting
in much enhanced object appearance. Extensive experiments show that the
proposed method achieves state-of-the-art performance on the COCO-Thing-Stuff
and Visual Genome benchmarks.
</dc:description>
 <dc:description>Comment: CVPR 2021</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11897</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11902</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Autocorrelation-Driven Synthesis of Antenna Arrays -- The Case of
  DS-Based Planar Isophoric Thinned Arrays</dc:title>
 <dc:creator>Oliveri, G.</dc:creator>
 <dc:creator>Gottardi, G.</dc:creator>
 <dc:creator>Hannan, M. A.</dc:creator>
 <dc:creator>Anselmi, N.</dc:creator>
 <dc:creator>Poli, L.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  A new methodology for the design of isophoric thinned arrays with a priori
controlled pattern features is introduced. A fully analytical and general
(i.e., valid for any lattice and set of weights) relationship between the
autocorrelation of the array excitations and the power pattern samples is first
derived. Binary 2-D sequences with known autocorrelation properties, namely the
difference sets (DSs), are then chosen as a representative benchmark to prove
that it is possible to deduce closed-form synthesis formulas that a priori
guarantee to fit requirements on the sidelobe level (SLL), the directivity, the
half-power beamwidth, and the power pattern in user-defined directions. The
selected results from a wide numerical assessment, which also includes
full-wave simulations with realistic radiators, are illustrated to validate the
reliability and the accuracy of the proposed design equations and the
associated performance bounds.
</dc:description>
 <dc:date>2021-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11902</dc:identifier>
 <dc:identifier>IEEE Transactions on Antennas and Propagation, vol. 68, no. 4, pp.
  2895-2910, April 2020</dc:identifier>
 <dc:identifier>doi:10.1109/TAP.2019.2947180</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11903</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracking Performance of Incremental LMS Algorithm over Adaptive
  Distributed Sensor Networks</dc:title>
 <dc:creator>Mostafapour, Ehsan</dc:creator>
 <dc:creator>Ghobadi, C.</dc:creator>
 <dc:creator>Nourinia, Javad</dc:creator>
 <dc:creator>Amirani, M. Chehel</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we focus on the tracking performance of incremental adaptive
LMS algorithm in an adaptive network. For this reason we consider the unknown
weight vector to be a time varying sequence. First we analyze the performance
of network in tracking a time varying weight vector and then we explain the
estimation of Rayleigh fading channel through a random walk model. Closed-form
relations are derived for mean square error (MSE), mean square deviation (MSD)
and excess mean square error (EMSE)of analyzed network in tracking Rayleigh
fading channel and random walk model. Comparison between theoretical and
simulation results shows a perfect match and verifies performed calculations.
</dc:description>
 <dc:date>2021-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11903</dc:identifier>
 <dc:identifier>doi:10.22070/JCE.2016.325</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11904</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Capacity Upper Bounds For Binary Deletion Channel</dc:title>
 <dc:creator>Tavakoli, Hassan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers a binary channel with deletions. We derive two close
form upper bound on the capacity of binary deletion channel. The first upper
bound is based on computing the capacity of an auxiliary channel and we show
how the capacity of auxiliary channel is the upper bound of the binary deletion
channel. Our main idea for the second bound is based on computing the mutual
information between the sent bits and the received bits in binary deletion
channel. We approximate the exact mutual information and we give a close form
expression. All bounds utilize first-order Markov process for the channel
input. The second proposed upper bound improves the best upper bound [6,11] up
to 0.1.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2021-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11904</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11912</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating Post-Training Compression in GANs using Locality-Sensitive
  Hashing</dc:title>
 <dc:creator>Mordido, Gon&#xe7;alo</dc:creator>
 <dc:creator>Yang, Haojin</dc:creator>
 <dc:creator>Meinel, Christoph</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The analysis of the compression effects in generative adversarial networks
(GANs) after training, i.e. without any fine-tuning, remains an unstudied,
albeit important, topic with the increasing trend of their computation and
memory requirements. While existing works discuss the difficulty of compressing
GANs during training, requiring novel methods designed with the instability of
GANs training in mind, we show that existing compression methods (namely
clipping and quantization) may be directly applied to compress GANs
post-training, without any additional changes. High compression levels may
distort the generated set, likely leading to an increase of outliers that may
negatively affect the overall assessment of existing k-nearest neighbor (KNN)
based metrics. We propose two new precision and recall metrics based on
locality-sensitive hashing (LSH), which, on top of increasing the outlier
robustness, decrease the complexity of assessing an evaluation sample against
$n$ reference samples from $O(n)$ to $O(\log(n))$, if using LSH and KNN, and to
$O(1)$, if only applying LSH. We show that low-bit compression of several
pre-trained GANs on multiple datasets induces a trade-off between precision and
recall, retaining sample quality while sacrificing sample diversity.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11912</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11916</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stable Haptic Teleoperation of UAVs via Small $L_2$ Gain and Control
  Barrier Functions</dc:title>
 <dc:creator>Zhang, Dawei</dc:creator>
 <dc:creator>Tron, Roberto</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present a novel haptic teleoperation approach that considers not only the
safety but also the stability of a teleoperation system. Specifically, we build
upon previous work on haptic shared control, which uses control barrier
functions (CBFs) to generate a reference haptic feedback that informs the human
operator on the internal state of the system, helping them to safely navigate
the robot without taking away their control authority. Crucially, in this
approach the force rendered to the user is not directly reflected in the motion
of the robot (which is still directly controlled by the user); however,
previous work in the area neglected to consider the feedback loop through the
user, possibly resulting in unstable closed trajectories. In this paper we
introduce a differential constraint on the rendered force that makes the system
finite-gain $L_2$ stable; the constraint results in a Quadratically Constrained
Quadratic Program (QCQP), for which we provide a closed-form solution. Our
constraint is related to but less restrictive than the typical passivity
constraint used in previous literature. We conducted an experimental simulation
in which a human operator flies a UAV near an obstacle to evaluate the proposed
method.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11916</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11921</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nutri-bullets: Summarizing Health Studies by Composing Segments</dc:title>
 <dc:creator>Shah, Darsh J</dc:creator>
 <dc:creator>Yu, Lili</dc:creator>
 <dc:creator>Lei, Tao</dc:creator>
 <dc:creator>Barzilay, Regina</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We introduce \emph{Nutri-bullets}, a multi-document summarization task for
health and nutrition. First, we present two datasets of food and health
summaries from multiple scientific studies. Furthermore, we propose a novel
\emph{extract-compose} model to solve the problem in the regime of limited
parallel data. We explicitly select key spans from several abstracts using a
policy network, followed by composing the selected spans to present a summary
via a task specific language model. Compared to state-of-the-art methods, our
approach leads to more faithful, relevant and diverse summarization --
properties imperative to this application. For instance, on the BreastCancer
dataset our approach gets a more than 50\% improvement on relevance and
faithfulness.\footnote{Our code and data is available at
\url{https://github.com/darsh10/Nutribullets.}}
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11921</dc:identifier>
 <dc:identifier>AAAI 2021 Camera Ready</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11922</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prioritized Architecture Sampling with Monto-Carlo Tree Search</dc:title>
 <dc:creator>Su, Xiu</dc:creator>
 <dc:creator>Huang, Tao</dc:creator>
 <dc:creator>Li, Yanxi</dc:creator>
 <dc:creator>You, Shan</dc:creator>
 <dc:creator>Wang, Fei</dc:creator>
 <dc:creator>Qian, Chen</dc:creator>
 <dc:creator>Zhang, Changshui</dc:creator>
 <dc:creator>Xu, Chang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  One-shot neural architecture search (NAS) methods significantly reduce the
search cost by considering the whole search space as one network, which only
needs to be trained once. However, current methods select each operation
independently without considering previous layers. Besides, the historical
information obtained with huge computation cost is usually used only once and
then discarded. In this paper, we introduce a sampling strategy based on Monte
Carlo tree search (MCTS) with the search space modeled as a Monte Carlo tree
(MCT), which captures the dependency among layers. Furthermore, intermediate
results are stored in the MCT for the future decision and a better
exploration-exploitation balance. Concretely, MCT is updated using the training
loss as a reward to the architecture performance; for accurately evaluating the
numerous nodes, we propose node communication and hierarchical node selection
methods in the training and search stages, respectively, which make better uses
of the operation rewards and hierarchical information. Moreover, for a fair
comparison of different NAS methods, we construct an open-source NAS benchmark
of a macro search space evaluated on CIFAR-10, namely NAS-Bench-Macro.
Extensive experiments on NAS-Bench-Macro and ImageNet demonstrate that our
method significantly improves search efficiency and performance. For example,
by only searching $20$ architectures, our obtained architecture achieves
$78.0\%$ top-1 accuracy with 442M FLOPs on ImageNet. Code (Benchmark) is
available at: \url{https://github.com/xiusu/NAS-Bench-Macro}.
</dc:description>
 <dc:description>Comment: Accepted by CVPR2021. We also release a NAS benchmark on the one-shot
  MobileNetV2 search space</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11922</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11926</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differentiated nonblocking: a new progress condition and a matching
  queue algorithm</dc:title>
 <dc:creator>Chan, David Y. C.</dc:creator>
 <dc:creator>Chi, Shucheng</dc:creator>
 <dc:creator>Hadzilacos, Vassos</dc:creator>
 <dc:creator>Toueg, Sam</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this paper, we first propose a new liveness requirement for shared objects
and data structures, we then give a shared queue algorithm that satisfies this
requirement and we prove its correctness. We also implement this algorithm and
compare it to a well-known shared queue algorithm that is used in practice. In
addition to having a stronger worst-case progress guarantee, our experimental
results suggest that, at the cost of a marginal decrease in throughput, our
algorithm is significantly fairer, by a natural definition of fairness that we
introduce here.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11926</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11927</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hardware Acceleration of Explainable Machine Learning using Tensor
  Processing Units</dc:title>
 <dc:creator>Pan, Zhixin</dc:creator>
 <dc:creator>Mishra, Prabhat</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Machine learning (ML) is successful in achieving human-level performance in
various fields. However, it lacks the ability to explain an outcome due to its
black-box nature. While existing explainable ML is promising, almost all of
these methods focus on formatting interpretability as an optimization problem.
Such a mapping leads to numerous iterations of time-consuming complex
computations, which limits their applicability in real-time applications. In
this paper, we propose a novel framework for accelerating explainable ML using
Tensor Processing Units (TPUs). The proposed framework exploits the synergy
between matrix convolution and Fourier transform, and takes full advantage of
TPU's natural ability in accelerating matrix computations. Specifically, this
paper makes three important contributions. (1) To the best of our knowledge,
our proposed work is the first attempt in enabling hardware acceleration of
explainable ML using TPUs. (2) Our proposed approach is applicable across a
wide variety of ML algorithms, and effective utilization of TPU-based
acceleration can lead to real-time outcome interpretation. (3) Extensive
experimental results demonstrate that our proposed approach can provide an
order-of-magnitude speedup in both classification time (25x on average) and
interpretation time (13x on average) compared to state-of-the-art techniques.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11927</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11930</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Volumetric Procedural Models for Shape Representation</dc:title>
 <dc:creator>Willis, Andrew</dc:creator>
 <dc:creator>Ganesh, Prashant</dc:creator>
 <dc:creator>Volle, Kyle</dc:creator>
 <dc:creator>Zhang, Jincheng</dc:creator>
 <dc:creator>Brink, Kevin</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  This article describes a volumetric approach for procedural shape modeling
and a new Procedural Shape Modeling Language (PSML) that facilitates the
specification of these models. PSML provides programmers the ability to
describe shapes in terms of their 3D elements where each element may be a
semantic group of 3D objects, e.g., a brick wall, or an indivisible object,
e.g., an individual brick. Modeling shapes in this manner facilitates the
creation of models that more closely approximate the organization and structure
of their real-world counterparts. As such, users may query these models for
volumetric information such as the number, position, orientation and volume of
3D elements which cannot be provided using surface based model-building
techniques. PSML also provides a number of new language-specific capabilities
that allow for a rich variety of context-sensitive behaviors and
post-processing functions. These capabilities include an object-oriented
approach for model design, methods for querying the model for component-based
information and the ability to access model elements and components to perform
Boolean operations on the model parts. PSML is open-source and includes freely
available tutorial videos, demonstration code and an integrated development
environment to support writing PSML programs.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11930</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11931</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhanced Principal Component Analysis under A Collaborative-Robust
  Framework</dc:title>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:creator>Zhang, Hongyuan</dc:creator>
 <dc:creator>Li, Xuelong</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Principal component analysis (PCA) frequently suffers from the disturbance of
outliers and thus a spectrum of robust extensions and variations of PCA have
been developed. However, existing extensions of PCA treat all samples equally
even those with large noise. In this paper, we first introduce a general
collaborative-robust weight learning framework that combines weight learning
and robust loss in a non-trivial way. More significantly, under the proposed
framework, only a part of well-fitting samples are activated which indicates
more importance during training, and others, whose errors are large, will not
be ignored. In particular, the negative effects of inactivated samples are
alleviated by the robust loss function. Then we furthermore develop an enhanced
PCA which adopts a point-wise sigma-loss function that interpolates between
L_2,1-norm and squared Frobenius-norm and meanwhile retains the rotational
invariance property. Extensive experiments are conducted on occluded datasets
from two aspects including reconstructed errors and clustering accuracy. The
experimental results prove the superiority and effectiveness of our model.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11931</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11937</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regularized Optimal Transport for Dynamic Semi-supervised Learning</dc:title>
 <dc:creator>Hamri, Mourad El</dc:creator>
 <dc:creator>Bennani, Youn&#xe8;s</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Semi-supervised learning provides an effective paradigm for leveraging
unlabeled data to improve a model's performance. Among the many strategies
proposed, graph-based methods have shown excellent properties, in particular
since they allow to solve directly the transductive tasks according to Vapnik's
principle and they can be extended efficiently for inductive tasks. In this
paper, we propose a novel approach for the transductive semi-supervised
learning, using a complete bipartite edge-weighted graph. The proposed approach
uses the regularized optimal transport between empirical measures defined on
labelled and unlabelled data points in order to obtain an affinity matrix from
the optimal transport plan. This matrix is further used to propagate labels
through the vertices of the graph in an incremental process ensuring the
certainty of the predictions by incorporating a certainty score based on
Shannon's entropy. We also analyze the convergence of our approach and we
derive an efficient way to extend it for out-of-sample data. Experimental
analysis was used to compare the proposed approach with other label propagation
algorithms on 12 benchmark datasets, for which we surpass state-of-the-art
results. We release our code.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11937</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11940</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shallow or Deep? An Empirical Study on Detecting Vulnerabilities using
  Deep Learning</dc:title>
 <dc:creator>Mazuera-Rozo, Alejandro</dc:creator>
 <dc:creator>Mojica-Hanke, Anamaria</dc:creator>
 <dc:creator>Linares-V&#xe1;squez, Mario</dc:creator>
 <dc:creator>Bavota, Gabriele</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Deep learning (DL) techniques are on the rise in the software engineering
research community. More and more approaches have been developed on top of DL
models, also due to the unprecedented amount of software-related data that can
be used to train these models. One of the recent applications of DL in the
software engineering domain concerns the automatic detection of software
vulnerabilities. While several DL models have been developed to approach this
problem, there is still limited empirical evidence concerning their actual
effectiveness especially when compared with shallow machine learning
techniques. In this paper, we partially fill this gap by presenting a
large-scale empirical study using three vulnerability datasets and five
different source code representations (i.e., the format in which the code is
provided to the classifiers to assess whether it is vulnerable or not) to
compare the effectiveness of two widely used DL-based models and of one shallow
machine learning model in (i) classifying code functions as vulnerable or
non-vulnerable (i.e., binary classification), and (ii) classifying code
functions based on the specific type of vulnerability they contain (or &quot;clean&quot;,
if no vulnerability is there). As a baseline we include in our study the AutoML
utility provided by the Google Cloud Platform. Our results show that the
experimented models are still far from ensuring reliable vulnerability
detection, and that a shallow learning classifier represents a competitive
baseline for the newest DL-based models.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11941</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Adaptive Manufacturing with Digital Twins</dc:title>
 <dc:creator>Bolender, Tim</dc:creator>
 <dc:creator>B&#xfc;rvenich, Gereon</dc:creator>
 <dc:creator>Dalibor, Manuela</dc:creator>
 <dc:creator>Rumpe, Bernhard</dc:creator>
 <dc:creator>Wortmann, Andreas</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Digital Twins are part of the vision of Industry 4.0 to represent, control,
predict, and optimize the behavior of Cyber-Physical Production Systems
(CPPSs). These CPPSs are long-living complex systems deployed to and configured
for diverse environments. Due to specific deployment, configuration, wear and
tear, or other environmental effects, their behavior might diverge from the
intended behavior over time. Properly adapting the configuration of CPPSs then
relies on the expertise of human operators. Digital Twins (DTs) that reify this
expertise and learn from it to address unforeseen challenges can significantly
facilitate self-adaptive manufacturing where experience is very specific and,
hence, insufficient to employ deep learning techniques. We leverage the
explicit modeling of domain expertise through case-based reasoning to improve
the capabilities of Digital Twins for adapting to such situations. To this
effect, we present a modeling framework for self-adaptive manufacturing that
supports modeling domain-specific cases, describing rules for case similarity
and case-based reasoning within a modular Digital Twin. Automatically
configuring Digital Twins based on explicitly modeled domain expertise can
improve manufacturing times, reduce wastage, and, ultimately, contribute to
better sustainable manufacturing.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11941</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11943</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BERT: A Review of Applications in Natural Language Processing and
  Understanding</dc:title>
 <dc:creator>Koroteev, M. V.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In this review, we describe the application of one of the most popular deep
learning-based language models - BERT. The paper describes the mechanism of
operation of this model, the main areas of its application to the tasks of text
analytics, comparisons with similar models in each task, as well as a
description of some proprietary models. In preparing this review, the data of
several dozen original scientific articles published over the past few years,
which attracted the most attention in the scientific community, were
systematized. This survey will be useful to all students and researchers who
want to get acquainted with the latest advances in the field of natural
language text analysis.
</dc:description>
 <dc:description>Comment: 18 pages, 7 figures</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11943</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11958</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preliminary Analysis of Potential Harms in the Luca Tracing System</dc:title>
 <dc:creator>Stadler, Theresa</dc:creator>
 <dc:creator>Lueks, Wouter</dc:creator>
 <dc:creator>Kohls, Katharina</dc:creator>
 <dc:creator>Troncoso, Carmela</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  In this document, we analyse the potential harms a large-scale deployment of
the Luca system might cause to individuals, venues, and communities. The Luca
system is a digital presence tracing system designed to provide health
departments with the contact information necessary to alert individuals who
have visited a location at the same time as a SARS-CoV-2-positive person.
Multiple regional health departments in Germany have announced their plans to
deploy the Luca system for the purpose of presence tracing. The system's
developers suggest its use across various types of venues: from bars and
restaurants to public and private events, such religious or political
gatherings, weddings, and birthday parties. Recently, an extension to include
schools and other educational facilities was discussed in public. Our analysis
of the potential harms of the system is based on the publicly available Luca
Security Concept which describes the system's security architecture and its
planned protection mechanisms. The Security Concept furthermore provides a set
of claims about the system's security and privacy properties. Besides an
analysis of harms, our analysis includes a validation of these claims.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11958</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11961</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Artificial Intelligence Narratives: An Objective Perspective on Current
  Developments</dc:title>
 <dc:creator>Klarmann, Noah</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This work provides a starting point for researchers interested in gaining a
deeper understanding of the big picture of artificial intelligence (AI). To
this end, a narrative is conveyed that allows the reader to develop an
objective view on current developments that is free from false promises that
dominate public communication. An essential takeaway for the reader is that AI
must be understood as an umbrella term encompassing a plethora of different
methods, schools of thought, and their respective historical movements.
Consequently, a bottom-up strategy is pursued in which the field of AI is
introduced by presenting various aspects that are characteristic of the
subject. This paper is structured in three parts: (i) Discussion of current
trends revealing false public narratives, (ii) an introduction to the history
of AI focusing on recurring patterns and main characteristics, and (iii) a
critical discussion on the limitations of current methods in the context of the
potential emergence of a strong(er) AI. It should be noted that this work does
not cover any of these aspects holistically; rather, the content addressed is a
selection made by the author and subject to a didactic strategy.
</dc:description>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11961</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11982</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wireless Network Coding with Intelligent Reflecting Surfaces</dc:title>
 <dc:creator>Kafizov, Amanat</dc:creator>
 <dc:creator>Elzanaty, Ahmed</dc:creator>
 <dc:creator>Varshney, Lav R.</dc:creator>
 <dc:creator>Alouini, Mohamed-Slim</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  Conventional wireless techniques are becoming inadequate for beyond
fifth-generation (5G) networks due to latency and bandwidth considerations. To
improve the error performance and throughput of wireless communication systems,
we propose physical layer network coding (PNC) in an intelligent reflecting
surface (IRS)-assisted environment. We consider an IRS-aided butterfly network,
where we propose an algorithm for obtaining the optimal IRS phases. Also,
analytic expressions for the bit error rate (BER) are derived. The numerical
results demonstrate that the proposed scheme significantly improves the BER
performance. For instance, the BER at the relay in the presence of a 32-element
IRS is three orders of magnitudes less than that without an IRS.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11982</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11987</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The footprint of a metrics-based research evaluation system on Spanish
  philosophical scholarship: an analysis of researchers perceptions</dc:title>
 <dc:creator>Feenstra, Ramon A.</dc:creator>
 <dc:creator>Lopez-Cozar, Emilio Delgado</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  The use of bibliometric indicators in research evaluation has a series of
complex impacts on academic inquiry. These systems have gradually spread into a
wide range of locations and disciplines, including the humanities. The aim of
the present study is to examine their effects as perceived by philosophy
researchers in Spain, a country where bibliometric indicators have long been
used to evaluate research. The study combines data from a self-administered
questionnaire completed by 201 researchers and from 14 in-depth interviews with
researchers selected according to their affiliation, professional category,
gender and area of knowledge. Results show that the evaluation system is widely
perceived to affect research behaviour in significant ways, particularly
related to publication practices (document type and publication language), the
transformation of research agendas and the neglect of teaching work, as well as
increasing research misconduct and negatively affecting mental health. Although
to a lesser extent, other consequences included increased research productivity
and enhanced transparency and impartiality in academic selection processes.
</dc:description>
 <dc:description>Comment: 28 pages, 4 figures, 6 tables</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11987</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.11991</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kokkos Kernels: Performance Portable Sparse/Dense Linear Algebra and
  Graph Kernels</dc:title>
 <dc:creator>Rajamanickam, Sivasankaran</dc:creator>
 <dc:creator>Acer, Seher</dc:creator>
 <dc:creator>Berger-Vergiat, Luc</dc:creator>
 <dc:creator>Dang, Vinh</dc:creator>
 <dc:creator>Ellingwood, Nathan</dc:creator>
 <dc:creator>Harvey, Evan</dc:creator>
 <dc:creator>Kelley, Brian</dc:creator>
 <dc:creator>Trott, Christian R.</dc:creator>
 <dc:creator>Wilke, Jeremiah</dc:creator>
 <dc:creator>Yamazaki, Ichitaro</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  As hardware architectures are evolving in the push towards exascale,
developing Computational Science and Engineering (CSE) applications depend on
performance portable approaches for sustainable software development. This
paper describes one aspect of performance portability with respect to
developing a portable library of kernels that serve the needs of several CSE
applications and software frameworks. We describe Kokkos Kernels, a library of
kernels for sparse linear algebra, dense linear algebra and graph kernels. We
describe the design principles of such a library and demonstrate portable
performance of the library using some selected kernels. Specifically, we
demonstrate the performance of four sparse kernels, three dense batched
kernels, two graph kernels and one team level algorithm.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.11991</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12002</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Robustness of Monte Carlo Dropout Trained with Noisy Labels</dc:title>
 <dc:creator>Goel, Purvi</dc:creator>
 <dc:creator>Chen, Li</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The memorization effect of deep learning hinders its performance to
effectively generalize on test set when learning with noisy labels. Prior study
has discovered that epistemic uncertainty techniques are robust when trained
with noisy labels compared with neural networks without uncertainty estimation.
They obtain prolonged memorization effect and better generalization performance
under the adversarial setting of noisy labels. Due to its superior performance
amongst other selected epistemic uncertainty methods under noisy labels, we
focus on Monte Carlo Dropout (MCDropout) and investigate why it is robust when
trained with noisy labels. Through empirical studies on datasets MNIST,
CIFAR-10, Animal-10n, we deep dive into three aspects of MCDropout under noisy
label setting: 1. efficacy: understanding the learning behavior and test
accuracy of MCDropout when training set contains artificially generated or
naturally embedded label noise; 2. representation volatility: studying the
responsiveness of neurons by examining the mean and standard deviation on each
neuron's activation; 3. network sparsity: investigating the network support of
MCDropout in comparison with deterministic neural networks. Our findings
suggest that MCDropout further sparsifies and regularizes the deterministic
neural networks and thus provides higher robustness against noisy labels.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12010</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Federated Quantum Machine Learning</dc:title>
 <dc:creator>Chen, Samuel Yen-Chi</dc:creator>
 <dc:creator>Yoo, Shinjae</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Distributed training across several quantum computers could significantly
improve the training time and if we could share the learned model, not the
data, it could potentially improve the data privacy as the training would
happen where the data is located. However, to the best of our knowledge, no
work has been done in quantum machine learning (QML) in federation setting yet.
In this work, we present the federated training on hybrid quantum-classical
machine learning models although our framework could be generalized to pure
quantum machine learning model. Specifically, we consider the quantum neural
network (QNN) coupled with classical pre-trained convolutional model. Our
distributed federated learning scheme demonstrated almost the same level of
trained model accuracies and yet significantly faster distributed training. It
demonstrates a promising future research direction for scaling and privacy
aspects.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12012</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SP Async:Single Source Shortest Path in Asynchronous Mode on MPI</dc:title>
 <dc:creator>Yadav, Sangeeta</dc:creator>
 <dc:creator>Khan, Asif</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Finding single source shortest path is a very ubiquitous problem. But with
the increasing size of large datasets in important application like social
network data-mining, network topology determination-efficient parallelization
of these techniques is needed to match the need of really large graphs. We
present a new Inter node-bellman cum Intra node Dijkstra technique implemented
in MPI to solve SSSP problem. We have used a triangle based edge pruning for
idle processes, and two different techniques for termination detection. Within
each node the algorithm works as Dijkstra and for outer communication it
behaves as inter node bellman ford. First termination detection technique is
based on the token ring and counter. Second is a heuristic based technique, in
which the timeout is calculated from the number of inter-edges and number of
partitions. In this project asynchronous mode of message passing is used.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12016</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fairness Perceptions of Algorithmic Decision-Making: A Systematic Review
  of the Empirical Literature</dc:title>
 <dc:creator>Starke, Christopher</dc:creator>
 <dc:creator>Baleis, Janine</dc:creator>
 <dc:creator>Keller, Birte</dc:creator>
 <dc:creator>Marcinkowski, Frank</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Algorithmic decision-making (ADM) increasingly shapes people's daily lives.
Given that such autonomous systems can cause severe harm to individuals and
social groups, fairness concerns have arisen. A human-centric approach demanded
by scholars and policymakers requires taking people's fairness perceptions into
account when designing and implementing ADM. We provide a comprehensive,
systematic literature review synthesizing the existing empirical insights on
perceptions of algorithmic fairness from 39 empirical studies spanning multiple
domains and scientific disciplines. Through thorough coding, we systemize the
current empirical literature along four dimensions: (a) algorithmic predictors,
(b) human predictors, (c) comparative effects (human decision-making vs.
algorithmic decision-making), and (d) consequences of ADM. While we identify
much heterogeneity around the theoretical concepts and empirical measurements
of algorithmic fairness, the insights come almost exclusively from
Western-democratic contexts. By advocating for more interdisciplinary research
adopting a society-in-the-loop framework, we hope our work will contribute to
fairer and more responsible ADM.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12031</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Groovy Parallel Patterns: A Process oriented Parallelization Library</dc:title>
 <dc:creator>Kerridge, Jon</dc:creator>
 <dc:creator>Urquhart, Neil</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:description>  A novel parallel patterns library, Groovy Parallel Patterns, is presented
which, from the outset, has been designed to exploit more general process
parallelism than the usual data and task parallel architectures. The library
executes on a standard Java Virtual Machine. The library provides a collection
of processes that can be plugged together to form a variety of parallel
architectures and is intrinsically its own DSL. A network of processes is
guaranteed to be deadlock and livelock free and terminate correctly and this is
proved by the use of formal methods. Error capture and a basic logging
mechanism have been incorporated. The library enables effective refinement of
solutions between process networks which can be checked also using formal
methods. A library user is only required to create the required methods as
pieces of sequential code, typically taken from extant sequential solutions,
which can then be invoked by the processes as required. The utility of the
library is demonstrated by several examples including; Monte Carlo Methods,
Concordance, Jacobi solutions, N-body problems and Mandelbrot, which is
implemented on both a multicore processor and a workstation cluster. The
examples are analysed for speedup and efficiency, which show good and
consistent performance improvement up to the number of available processor
cores and workstations.
</dc:description>
 <dc:description>Comment: 34 pages, 14 Figures, 10 Tables, 21 Code Listings, 52 References</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12032</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tangent Space Backpropagation for 3D Transformation Groups</dc:title>
 <dc:creator>Teed, Zachary</dc:creator>
 <dc:creator>Deng, Jia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We address the problem of performing backpropagation for computation graphs
involving 3D transformation groups SO(3), SE(3), and Sim(3). 3D transformation
groups are widely used in 3D vision and robotics, but they do not form vector
spaces and instead lie on smooth manifolds. The standard backpropagation
approach, which embeds 3D transformations in Euclidean spaces, suffers from
numerical difficulties. We introduce a new library, which exploits the group
structure of 3D transformations and performs backpropagation in the tangent
spaces of manifolds. We show that our approach is numerically more stable,
easier to implement, and beneficial to a diverse set of tasks. Our
plug-and-play PyTorch library is available at
https://github.com/princeton-vl/lietorch.
</dc:description>
 <dc:description>Comment: fixed typos</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12051</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SSD: A Unified Framework for Self-Supervised Outlier Detection</dc:title>
 <dc:creator>Sehwag, Vikash</dc:creator>
 <dc:creator>Chiang, Mung</dc:creator>
 <dc:creator>Mittal, Prateek</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We ask the following question: what training information is required to
design an effective outlier/out-of-distribution (OOD) detector, i.e., detecting
samples that lie far away from the training distribution? Since unlabeled data
is easily accessible for many applications, the most compelling approach is to
develop detectors based on only unlabeled in-distribution data. However, we
observe that most existing detectors based on unlabeled data perform poorly,
often equivalent to a random prediction. In contrast, existing state-of-the-art
OOD detectors achieve impressive performance but require access to fine-grained
data labels for supervised training. We propose SSD, an outlier detector based
on only unlabeled in-distribution data. We use self-supervised representation
learning followed by a Mahalanobis distance based detection in the feature
space. We demonstrate that SSD outperforms most existing detectors based on
unlabeled data by a large margin. Additionally, SSD even achieves performance
on par, and sometimes even better, with supervised training based detectors.
Finally, we expand our detection framework with two key extensions. First, we
formulate few-shot OOD detection, in which the detector has access to only one
to five samples from each class of the targeted OOD dataset. Second, we extend
our framework to incorporate training data labels, if available. We find that
our novel detection framework based on SSD displays enhanced performance with
these extensions, and achieves state-of-the-art performance. Our code is
publicly available at https://github.com/inspire-group/SSD.
</dc:description>
 <dc:description>Comment: ICLR 2021</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12065</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Concept of an Autonomic Avionics Platform and the Resulting Software
  Engineering Challenges</dc:title>
 <dc:creator>Annighoefer, Bjoern</dc:creator>
 <dc:creator>Reinhart, Johannes</dc:creator>
 <dc:creator>Brunner, Matthias</dc:creator>
 <dc:creator>Schulz, Bernd</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>68N30</dc:subject>
 <dc:subject>D.2.11</dc:subject>
 <dc:subject>D.2.9</dc:subject>
 <dc:description>  The self-* properties commonly associated with the concept of autonomic
computing are capabilities desirable for avionics software platforms. They
decrease the configuration effort and inherently provide new fault tolerance
and resource savings possibilities. The rigid certification process and the
requirements for a static and predetermined system behavior are, however, in
contradiction with the adaptive and flexible nature of autonomic computing
systems. We propose a partition-based architecture providing autonomic features
for avionics software platforms while being compliant to regulations and
accepted technologies, such as ARINC 653. The core is a platform consciousness
based on a domain-specific model and a novel MAP-QE-K cycle. Moreover, we
suggest a planning intelligence, a virtual qualification authority, and a
minimized execution unit. For each component we define the required design
assurance level and possible realization techniques. We discuss the overall
feasibility and point out central challenges in the fields of runtime
verification and models at runtime. These challenges need to be solved up to
the realization of autonomic avionics, e.g. a virtual security assessment and a
qualifiable domain-specific model database.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12066</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine learning based in situ quality estimation by molten pool
  condition-quality relations modeling using experimental data</dc:title>
 <dc:creator>Jamnikar, Noopur</dc:creator>
 <dc:creator>Liu, Sen</dc:creator>
 <dc:creator>Brice, Craig</dc:creator>
 <dc:creator>Zhang, Xiaoli</dc:creator>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The advancement of machine learning promises the ability to accelerate the
adoption of new processes and property designs for metal additive
manufacturing. The molten pool geometry and molten pool temperature are the
significant indicators for the final part's geometric shape and microstructural
properties for the Wire-feed laser direct energy deposition process. Thus, the
molten pool condition-property relations are of preliminary importance for in
situ quality assurance. To enable in situ quality monitoring of bead geometry
and characterization properties, we need to continuously monitor the sensor's
data for molten pool dimensions and temperature for the Wire-feed laser
additive manufacturing (WLAM) system. We first develop a machine learning
convolutional neural network (CNN) model for establishing the correlations from
the measurable molten pool image and temperature data directly to the geometric
shape and microstructural properties. The multi-modality network receives both
the camera image and temperature measurement as inputs, yielding the
corresponding characterization properties of the final build part (e.g., fusion
zone depth, alpha lath thickness). The performance of the CNN model is compared
with the regression model as a baseline. The developed models enable molten
pool condition-quality relations mapping for building quantitative and
collaborative in situ quality estimation and assurance framework.
</dc:description>
 <dc:description>Comment: 23 pages. arXiv admin note: substantial text overlap with
  arXiv:2103.11588</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12067</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding performance variability in standard and pipelined parallel
  Krylov solvers</dc:title>
 <dc:creator>Morgan, Hannah</dc:creator>
 <dc:creator>Sanan, Patrick</dc:creator>
 <dc:creator>Knepley, Matthew G.</dc:creator>
 <dc:creator>Mills, Richard Tran</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  In this work, we collect data from runs of Krylov subspace methods and
pipelined Krylov algorithms in an effort to understand and model the impact of
machine noise and other sources of variability on performance. We find large
variability of Krylov iterations between compute nodes for standard methods
that is reduced in pipelined algorithms, directly supporting conjecture, as
well as large variation between statistical distributions of runtimes across
iterations. Based on these results, we improve upon a previously introduced
nondeterministic performance model by allowing iterations to fluctuate over
time. We present our data from runs of various Krylov algorithms across
multiple platforms as well as our updated non-stationary model that provides
good agreement with observations. We also suggest how it can be used as a
predictive tool.
</dc:description>
 <dc:description>Comment: 18 pages, 12 figures</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12067</dc:identifier>
 <dc:identifier>IJHPCA, 35(1), 2020</dc:identifier>
 <dc:identifier>doi:10.1177/1094342020966835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12071</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Selective information exchange in collaborative clustering using
  regularized Optimal Transport</dc:title>
 <dc:creator>Bouazza, Fatima Ezzahraa Ben</dc:creator>
 <dc:creator>Bennani, Youn&#xe8;s</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Collaborative learning has recently achieved very significant results. It
still suffers, however, from several issues, including the type of information
that needs to be exchanged, the criteria for stopping and how to choose the
right collaborators. We aim in this paper to improve the quality of the
collaboration and to resolve these issues via a novel approach inspired by
Optimal Transport theory. More specifically, the objective function for the
exchange of information is based on the Wasserstein distance, with a
bidirectional transport of information between collaborators. This formulation
allows to learns a stopping criterion and provide a criterion to choose the
best collaborators. Extensive experiments are conducted on multiple data-sets
to evaluate the proposed approach.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12071</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12106</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Spatial and Photometric Context for Calibrated Non-Lambertian
  Photometric Stereo</dc:title>
 <dc:creator>Honz&#xe1;tko, David</dc:creator>
 <dc:creator>T&#xfc;retken, Engin</dc:creator>
 <dc:creator>Fua, Pascal</dc:creator>
 <dc:creator>Dunbar, L. Andrea</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The problem of estimating a surface shape from its observed reflectance
properties still remains a challenging task in computer vision. The presence of
global illumination effects such as inter-reflections or cast shadows makes the
task particularly difficult for non-convex real-world surfaces.
State-of-the-art methods for calibrated photometric stereo address these issues
using convolutional neural networks (CNNs) that primarily aim to capture either
the spatial context among adjacent pixels or the photometric one formed by
illuminating a sample from adjacent directions.
  In this paper, we bridge these two objectives and introduce an efficient
fully-convolutional architecture that can leverage both spatial and photometric
context simultaneously. In contrast to existing approaches that rely on
standard 2D CNNs and regress directly to surface normals, we argue that using
separable 4D convolutions and regressing to 2D Gaussian heat-maps severely
reduces the size of the network and makes inference more efficient. Our
experimental results on a real-world photometric stereo benchmark show that the
proposed approach outperforms the existing methods both in efficiency and
accuracy.
</dc:description>
 <dc:description>Comment: Submitted to ICCV 2021</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12112</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The quest for scaling BFT Consensus through Tree-Based Vote Aggregation</dc:title>
 <dc:creator>Neiheiser, Ray</dc:creator>
 <dc:creator>Matos, Miguel</dc:creator>
 <dc:creator>Rodrigues, Lu&#xed;s</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  With the growing commercial interest in blockchain, permissioned
implementations have received increasing attention. Unfortunately, existing BFT
consensus protocols that are the backbone of permissioned blockchains, either
scale poorly or offer limited throughput. Most of these algorithms require at
least one process to receive and validate the votes from all other processes
and then broadcast the result, which is inherently non-scalable. Some
algorithms avoid this bottleneck by using aggregation trees to collect and
validate votes. However, to the best of our knowledge, such algorithms offer
limited throughput and degrade quickly in the presence of faults. In this paper
we propose \thesystem, the first BFT communication abstraction that organizes
participants in a tree to perform scalable vote aggregation and that, in faulty
runs, is able to terminate the protocol within an optimal number of
reconfigurations ($f+1$). We define precisely which aggregation trees allow for
optimal reconfiguration and show that, unlike previous protocols, when using
these configurations, \thesystem scales to large number of processes and
outperforms HotStuff's throughput by up to 38x.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12112</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12125</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anomaly Detection Algorithms for Location Security in 5G Scenarios</dc:title>
 <dc:creator>Bartoletti, Stefania</dc:creator>
 <dc:creator>Palam&#xe0;, Ivan</dc:creator>
 <dc:creator>Orlando, Danilo</dc:creator>
 <dc:creator>Bianchi, Giuseppe</dc:creator>
 <dc:creator>Melazzi, Nicola Blefari</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Location based services are expected to play a major role in future
generation cellular networks, starting from the incoming 5G systems. At the
same time, localization technologies may be severely affected by attackers
capable to deploy low cost fake base stations and use them to alter
localization signals. In this paper, we concretely focus on two classes of
threats: noise-like jammers, whose objective is to reduce the signal-to-noise
ratio, and spoofing/meaconing attacks, whose objective is to inject false or
erroneous information into the receiver. Then, we formulate the detection
problems as binary hypothesis tests and solve them resorting to the generalized
likelihood ratio test design procedure as well as the Latent Variable Models,
which involves the expectation-maximization algorithm to estimate the unknown
data distribution parameters. The proposed techniques can be applied to a large
class of location data regardless the subsumed network architecture. The
performance analysis is conducted over simulated data generated by using
measurement models from the literature and highlights the effectiveness of the
proposed approaches in detecting the aforementioned classes of attacks.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12131</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The IoT Exchange</dc:title>
 <dc:creator>Berzin, Oleg</dc:creator>
 <dc:creator>Ansay, Rafael</dc:creator>
 <dc:creator>Kempf, James</dc:creator>
 <dc:creator>Sheikh, Imam</dc:creator>
 <dc:creator>Hendel, Doron</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The IoT ecosystem suffers from a variety of problems around security,
identity, access control, data flow and data storage that introduce friction
into interactions between various parties. In many respects, the situation is
similar to the early days of the Internet, where, prior to the establishment of
Internet Exchanges, routing between different BGP autonomous systems was often
point to point. We propose a similar solution, the IoT Exchange, where IoT
device owners can register their devices and offer data for sale or can upload
data into the IoT services of any of the big hyperscale cloud platforms for
further processing. The goal of the IoT Exchange is to break down the silos
within which device wireless connectivity types and cloud provider IoT systems
constrain users to operate. In addition, if the device owner needs to maintain
the data close to the edge to reduce access latency, the MillenniumDB service
running in an edge data center with minimal latency to the edge device,
provides a database with a variety of schema engines (SQL, noSQL, etc). The IoT
exchange uses decentralized identifiers for identity management and verifiable
credentials for authorizing software updates and to control access to the
devices, to avoid dependence on certificate authorities and other centralized
identity and authorization management systems. In addition, verifiable
credentials provide a way whereby privacy preserving processing can be applied
to traffic between a device and an end data or control customer, if some risk
of privacy compromise exists.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12131</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12134</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Joint Reinforcement-Learning Enabled Caching and Cross-Layer Network
  Code for Sum-Rate Maximization in F-RAN with D2D Communications</dc:title>
 <dc:creator>Al-Abiad, Mohammed S.</dc:creator>
 <dc:creator>Hassan, Md. Zoheb</dc:creator>
 <dc:creator>Hossain, Md. Jahangir</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we leverage reinforcement learning (RL) and cross-layer
network coding (CLNC) for efficiently pre-fetching users' contents to the local
caches and delivering these contents to users in a downlink fog-radio access
network (F-RAN) with device-to-device (D2D) communications. In the considered
system, fog access points (F-APs) and cache-enabled D2D (CE-D2D) users are
equipped with local caches for alleviating traffic burden at the fronthaul,
while users' contents can be easily and quickly accommodated. In CLNC, the
coding decisions take users' contents, their rates, and power levels of F-APs
and CE-D2D users into account, and RL optimizes caching strategy. Towards this
goal, a joint content placement and delivery problem is formulated as an
optimization problem with a goal to maximize system sum-rate. For this NP-hard
problem, we first develop an innovative decentralized CLNC coalition formation
(CLNC-CF) algorithm to obtain a stable solution for the content delivery
problem, where F-APs and CE-D2D users utilize CLNC resource allocation. By
taking the behavior of F-APs and CE-D2D users into account, we then develop a
multi-agent RL (MARL) algorithm for optimizing the content placements at both
F-APs and CE-D2D users. Simulation results show that the proposed joint CLNC-CF
and RL framework can effectively improve the sum-rate by up to 30\%, 60\%, and
150\%, respectively, compared to: 1) an optimal uncoded algorithm, 2) a
standard rate-aware-NC algorithm, and 3) a benchmark classical NC with
network-layer optimization.
</dc:description>
 <dc:description>Comment: 15 pages, 9 figures, journal</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12134</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12141</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Bounds for Neural Network Estimators: Applications in Fault
  Detection</dc:title>
 <dc:creator>Hashemi, Navid</dc:creator>
 <dc:creator>Fazlyab, Mahyar</dc:creator>
 <dc:creator>Ruths, Justin</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  We exploit recent results in quantifying the robustness of neural networks to
input variations to construct and tune a model-based anomaly detector, where
the data-driven estimator model is provided by an autoregressive neural
network. In tuning, we specifically provide upper bounds on the rate of false
alarms expected under normal operation. To accomplish this, we provide a theory
extension to allow for the propagation of multiple confidence ellipsoids
through a neural network. The ellipsoid that bounds the output of the neural
network under the input variation informs the sensitivity - and thus the
threshold tuning - of the detector. We demonstrate this approach on a linear
and nonlinear dynamical system.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12141</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12142</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Reward Information from Multiple Sources</dc:title>
 <dc:creator>Krasheninnikov, Dmitrii</dc:creator>
 <dc:creator>Shah, Rohin</dc:creator>
 <dc:creator>van Hoof, Herke</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Given two sources of evidence about a latent variable, one can combine the
information from both by multiplying the likelihoods of each piece of evidence.
However, when one or both of the observation models are misspecified, the
distributions will conflict. We study this problem in the setting with two
conflicting reward functions learned from different sources. In such a setting,
we would like to retreat to a broader distribution over reward functions, in
order to mitigate the effects of misspecification. We assume that an agent will
maximize expected reward given this distribution over reward functions, and
identify four desiderata for this setting. We propose a novel algorithm,
Multitask Inverse Reward Design (MIRD), and compare it to a range of simple
baselines. While all methods must trade off between conservatism and
informativeness, through a combination of theory and empirical results on a toy
environment, we find that MIRD and its variant MIRD-IF strike a good balance
between the two.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12142</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12144</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Edge Intelligence for Empowering IoT-based Healthcare Systems</dc:title>
 <dc:creator>Hayyolalam, Vahideh</dc:creator>
 <dc:creator>Aloqaily, Moayad</dc:creator>
 <dc:creator>Ozkasap, Oznur</dc:creator>
 <dc:creator>Guizani, Mohsen</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The demand for real-time, affordable, and efficient smart healthcare services
is increasing exponentially due to the technological revolution and burst of
population. To meet the increasing demands on this critical infrastructure,
there is a need for intelligent methods to cope with the existing obstacles in
this area. In this regard, edge computing technology can reduce latency and
energy consumption by moving processes closer to the data sources in comparison
to the traditional centralized cloud and IoT-based healthcare systems. In
addition, by bringing automated insights into the smart healthcare systems,
artificial intelligence (AI) provides the possibility of detecting and
predicting high-risk diseases in advance, decreasing medical costs for
patients, and offering efficient treatments. The objective of this article is
to highlight the benefits of the adoption of edge intelligent technology, along
with AI in smart healthcare systems. Moreover, a novel smart healthcare model
is proposed to boost the utilization of AI and edge technology in smart
healthcare systems. Additionally, the paper discusses issues and research
directions arising when integrating these different technologies together.
</dc:description>
 <dc:description>Comment: This paper has been accepted in IEEE Wireless Communication Magazine</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12144</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12149</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Directed, Bi-Populated Preferential Attachment Model with Applications
  to Analyzing the Glass Ceiling Effect</dc:title>
 <dc:creator>Nettasinghe, Buddhika</dc:creator>
 <dc:creator>Alipourfard, Nazanin</dc:creator>
 <dc:creator>Krishnamurthy, Vikram</dc:creator>
 <dc:creator>Lerman, Kristina</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Preferential attachment, homophily and, their consequences such as the glass
ceiling effect have been well-studied in the context of undirected networks.
However, the lack of an intuitive, theoretically tractable model of a directed,
bi-populated~(i.e.,~containing two groups) network with variable levels of
preferential attachment, homophily and growth dynamics~(e.g.,~the rate at which
new nodes join, whether the new nodes mostly follow existing nodes or the
existing nodes follow them, etc.) has largely prevented such consequences from
being explored in the context of directed networks, where they more naturally
occur due to the asymmetry of links. To this end, we present a rigorous
theoretical analysis of the \emph{Directed Mixed Preferential Attachment} model
and, use it to analyze the glass ceiling effect in directed networks. More
specifically, we derive the closed-form expressions for the power-law exponents
of the in- and out- degree distributions of each group~(minority and majority)
and, compare them with each other to obtain insights. In particular, our
results yield answers to questions such as: \emph{when does the minority group
have a heavier out-degree (or in-degree) distribution compared to the majority
group? what effect does frequent addition of edges between existing nodes have
on the in- and out- degree distributions of the majority and minority groups?}.
Such insights shed light on the interplay between the structure~(i.e., the in-
and out- degree distributions of the two groups) and dynamics~(characterized
collectively by the homophily, preferential attachment, group sizes and growth
dynamics) of various real-world networks. Finally, we utilize the obtained
analytical results to characterize the conditions under which the glass ceiling
effect emerge in a directed network. Our analytical results are supported by
detailed numerical results.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12151</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Interference-Aware Constrained Massive MIMO Beamforming for
  mm-Wave JSDM</dc:title>
 <dc:creator>Bayraktar, Murat</dc:creator>
 <dc:creator>Guvensen, Gokhan Muzaffer</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  Low-complexity beamformer design with practical constraints is an attractive
research area for hybrid analog/digital systems in mm-wave massive
multiple-input multiple-output (MIMO). This paper investigates
interference-aware pre-beamformer (analog beamformer) design for joint spatial
division and multiplexing (JSDM) which is a user-grouping based two-stage
beamforming method. Single-carrier frequency domain equalization (SC-FDE) is
employed in uplink frequency-selective channels. First, unconstrained slowly
changing statistical analog beamformer of each group, namely, generalized
eigenbeamformer (GEB) which has strong interference suppression capability is
designed where the mutual information in reduced dimension is maximized. Then,
constant-modulus constrained approximations of unconstrained beamformer are
obtained by utilizing alternating minimization algorithms for fully connected
arrays and fixed subarrays. In addition, a dynamic subarray algorithm is
proposed where the connections between radio frequency (RF) chains and antennas
are changed with changing channel statistics. Convergence of the proposed
alternating minimization-based algorithms are provided along with their
complexity analysis. It is observed that additional complexity of proposed
algorithms is insignificant for the overall system design. Although most of the
interference is suppressed with the help of proposed constrained beamformers,
there may be some residual interference after the analog beamforming stage.
Therefore, linear minimum mean square error (LMMSE) type digital beamformers,
which take the residual interference in reduced dimension into account, are
proposed instead of zero-forcing (ZF) type. Simulation results verify the
superiority of the proposed interference-aware constrained design over existing
approaches in terms of beampattern, spectral efficiency, outage capacity and
channel estimation accuracy.
</dc:description>
 <dc:description>Comment: 16 pages, 9 figures. This work has been submitted to IEEE Access for
  possible publication. Copyright may be transferred without notice, after
  which this version may no longer be accessible</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12155</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prediction of lung and colon cancer through analysis of
  histopathological images by utilizing Pre-trained CNN models with
  visualization of class activation and saliency maps</dc:title>
 <dc:creator>Garg, Satvik</dc:creator>
 <dc:creator>Garg, Somya</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:subject>I.5.2</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:description>  Colon and Lung cancer is one of the most perilous and dangerous ailments that
individuals are enduring worldwide and has become a general medical problem. To
lessen the risk of death, a legitimate and early finding is particularly
required. In any case, it is a truly troublesome task that depends on the
experience of histopathologists. If a histologist is under-prepared it may even
hazard the life of a patient. As of late, deep learning has picked up energy,
and it is being valued in the analysis of Medical Imaging. This paper intends
to utilize and alter the current pre-trained CNN-based model to identify lung
and colon cancer utilizing histopathological images with better augmentation
techniques. In this paper, eight distinctive Pre-trained CNN models, VGG16,
NASNetMobile, InceptionV3, InceptionResNetV2, ResNet50, Xception, MobileNet,
and DenseNet169 are trained on LC25000 dataset. The model performances are
assessed on precision, recall, f1score, accuracy, and auroc score. The results
exhibit that all eight models accomplished noteworthy results ranging from 96%
to 100% accuracy. Subsequently, GradCAM and SmoothGrad are also used to picture
the attention images of Pre-trained CNN models classifying malignant and benign
images.
</dc:description>
 <dc:description>Comment: This Paper has been accepted and presented in 2nd Asia Pacific
  Digital Image Processing (ADIP) Workshop of 3rd Artificial Intelligence and
  Cloud Computing Conference (AICCC 2020), ACM, Japan. 2020 December 3-5. The
  publication can be accessed from the proceedings of the AICCC 2020
  conference. (https://dl.acm.org/doi/10.1145/3442536.3442543)</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12155</dc:identifier>
 <dc:identifier>doi:10.1145/3442536.3442543</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12156</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Autonomous Flight through Cluttered Outdoor Environments Using a
  Memoryless Planner</dc:title>
 <dc:creator>Lee, Junseok</dc:creator>
 <dc:creator>Wu, Xiangyu</dc:creator>
 <dc:creator>Lee, Seung Jae</dc:creator>
 <dc:creator>Mueller, Mark W.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper introduces a collision avoidance system for navigating a
multicopter in cluttered outdoor environments based on the recent memory-less
motion planner, rectangular pyramid partitioning using integrated depth sensors
(RAPPIDS). The RAPPIDS motion planner generates collision-free flight
trajectories at high speed with low computational cost using only the latest
depth image. In this work we extend it to improve the performance of the
planner by taking the following issues into account. (a) Changes in the dynamic
characteristics of the multicopter that occur during flight, such as changes in
motor input/output characteristics due to battery voltage drop. (b) The noise
of the flight sensor, which can cause unwanted control input components. (c)
Planner utility function which may not be suitable for the cluttered
environment. Therefore, in this paper we introduce solutions to each of the
above problems and propose a system for the successful operation of the RAPPIDS
planner in an outdoor cluttered flight environment. At the end of the paper, we
validate the proposed method's effectiveness by presenting the flight
experiment results in a forest environment. A video can be found at
www.youtube.com/channel/UCK-gErmvZlBODN5gQpNcpsg
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12156</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12157</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tiny Transformers for Environmental Sound Classification at the Edge</dc:title>
 <dc:creator>Elliott, David</dc:creator>
 <dc:creator>Otero, Carlos E.</dc:creator>
 <dc:creator>Wyatt, Steven</dc:creator>
 <dc:creator>Martino, Evan</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  With the growth of the Internet of Things and the rise of Big Data, data
processing and machine learning applications are being moved to cheap and low
size, weight, and power (SWaP) devices at the edge, often in the form of mobile
phones, embedded systems, or microcontrollers. The field of Cyber-Physical
Measurements and Signature Intelligence (MASINT) makes use of these devices to
analyze and exploit data in ways not otherwise possible, which results in
increased data quality, increased security, and decreased bandwidth. However,
methods to train and deploy models at the edge are limited, and models with
sufficient accuracy are often too large for the edge device. Therefore, there
is a clear need for techniques to create efficient AI/ML at the edge. This work
presents training techniques for audio models in the field of environmental
sound classification at the edge. Specifically, we design and train
Transformers to classify office sounds in audio clips. Results show that a
BERT-based Transformer, trained on Mel spectrograms, can outperform a CNN using
99.85% fewer parameters. To achieve this result, we first tested several audio
feature extraction techniques designed for Transformers, using ESC-50 for
evaluation, along with various augmentations. Our final model outperforms the
state-of-the-art MFCC-based CNN on the office sounds dataset, using just over
6,000 parameters -- small enough to run on a microcontroller.
</dc:description>
 <dc:description>Comment: 12 pages, submitted to IEEE Journal of Internet of Things</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12157</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12161</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scale-free Distributed Cooperative Voltage Control of Inverter-based
  Microgrids with General Time-varying Communication Graphs</dc:title>
 <dc:creator>Nojavanzadeh, Donya</dc:creator>
 <dc:creator>Lotfifard, Saeed</dc:creator>
 <dc:creator>Liu, Zhenwei</dc:creator>
 <dc:creator>Saberi, Ali</dc:creator>
 <dc:creator>Stoorvogel, Anton A.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents a method for controlling the voltage of inverter-based
Microgrids by proposing a new scale-free distributed cooperative controller.
The communication network is modeled by a general time-varying graph which
enhances the resilience of the proposed protocol against communication link
failure, data packet loss, and fast plug and play operation in the presence of
arbitrarily communication delays. The proposed scale-free distributed
cooperative controller is independent of any information about the
communication system and the size of the network (i.e., the number of
distributed generators). The stability analysis of the proposed protocol is
provided. The proposed method is simulated on the CIGRE medium voltage
Microgrid test system. The simulation results demonstrate the feasibility of
the proposed scale-free distributed nonlinear protocol for regulating the
voltage of Microgrids in presence of communication failures, data packet loss,
noise, and degradation.
</dc:description>
 <dc:description>Comment: A version of this paper is submitted to IEEE Transactions on Power
  Systems Journal</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12162</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D Reconstruction and Alignment by Consumer RGB-D Sensors and Fiducial
  Planar Markers for Patient Positioning in Radiation Therapy</dc:title>
 <dc:creator>Sarmadi, Hamid</dc:creator>
 <dc:creator>Mu&#xf1;oz-Salinas, Rafael</dc:creator>
 <dc:creator>Berb&#xed;s, M. &#xc1;lvaro</dc:creator>
 <dc:creator>Luna, Antonio</dc:creator>
 <dc:creator>Medina-Carnicer, Rafael</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  BACKGROUND AND OBJECTIVE: Patient positioning is a crucial step in radiation
therapy, for which non-invasive methods have been developed based on surface
reconstruction using optical 3D imaging. However, most solutions need expensive
specialized hardware and a careful calibration procedure that must be repeated
over time.This paper proposes a fast and cheap patient positioning method based
on inexpensive consumer level RGB-D sensors.
  METHODS: The proposed method relies on a 3D reconstruction approach that
fuses, in real-time, artificial and natural visual landmarks recorded from a
hand-held RGB-D sensor. The video sequence is transformed into a set of
keyframes with known poses, that are later refined to obtain a realistic 3D
reconstruction of the patient. The use of artificial landmarks allows our
method to automatically align the reconstruction to a reference one, without
the need of calibrating the system with respect to the linear accelerator
coordinate system.
  RESULTS:The experiments conducted show that our method obtains a median of 1
cm in translational error, and 1 degree of rotational error with respect to
reference pose. Additionally, the proposed method shows as visual output
overlayed poses (from the reference and the current scene) and an error map
that can be used to correct the patient's current pose to match the reference
pose.
  CONCLUSIONS: A novel approach to obtain 3D body reconstructions for patient
positioning without requiring expensive hardware or dedicated graphic cards is
proposed. The method can be used to align in real time the patient's current
pose to a preview pose, which is a relevant step in radiation therapy.
</dc:description>
 <dc:description>Comment: 11 pages, 5 figures</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12162</dc:identifier>
 <dc:identifier>doi:10.1016/j.cmpb.2019.105004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12163</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The numerical solutions of linear semi-discrete evolution problems on
  the half-line using the Unified Transform Method</dc:title>
 <dc:creator>Cisneros, Jorge</dc:creator>
 <dc:creator>Deconinck, Bernard</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We discuss a semi-discrete analogue of the Unified Transform Method,
introduced by A. S. Fokas, to solve initial-boundary-value problems for linear
evolution partial differential equations of constant coefficients. The
semi-discrete method is applied to various spacial discretizations of several
first and second-order linear equations on the half-line $x \geq 0$, producing
the exact solution for the semi-discrete problem, given appropriate initial and
boundary data. We additionally show how the Unified Transform Method treats
derivative boundary conditions and ghost points introduced by the choice of
discretization stencil. We consider the continuum limit of the semi-discrete
solutions and provide several numerical examples.
</dc:description>
 <dc:description>Comment: 31 pages, 16 figures, submitted to journal</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12163</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12165</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated and Autonomous Experiment in Electron and Scanning Probe
  Microscopy</dc:title>
 <dc:creator>Kalinin, Sergei V.</dc:creator>
 <dc:creator>Ziatdinov, Maxim A.</dc:creator>
 <dc:creator>Hinkle, Jacob</dc:creator>
 <dc:creator>Jesse, Stephen</dc:creator>
 <dc:creator>Ghosh, Ayana</dc:creator>
 <dc:creator>Kelley, Kyle P.</dc:creator>
 <dc:creator>Lupini, Andrew R.</dc:creator>
 <dc:creator>Sumpter, Bobby G.</dc:creator>
 <dc:creator>Vasudevan, Rama K.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:description>  Machine learning and artificial intelligence (ML/AI) are rapidly becoming an
indispensable part of physics research, with domain applications ranging from
theory and materials prediction to high-throughput data analysis. In parallel,
the recent successes in applying ML/AI methods for autonomous systems from
robotics through self-driving cars to organic and inorganic synthesis are
generating enthusiasm for the potential of these techniques to enable automated
and autonomous experiment (AE) in imaging. Here, we aim to analyze the major
pathways towards AE in imaging methods with sequential image formation
mechanisms, focusing on scanning probe microscopy (SPM) and (scanning)
transmission electron microscopy ((S)TEM). We argue that automated experiments
should necessarily be discussed in a broader context of the general domain
knowledge that both informs the experiment and is increased as the result of
the experiment. As such, this analysis should explore the human and ML/AI roles
prior to and during the experiment, and consider the latencies, biases, and
knowledge priors of the decision-making process. Similarly, such discussion
should include the limitations of the existing imaging systems, including
intrinsic latencies, non-idealities and drifts comprising both correctable and
stochastic components. We further pose that the role of the AE in microscopy is
not the exclusion of human operators (as is the case for autonomous driving),
but rather automation of routine operations such as microscope tuning, etc.,
prior to the experiment, and conversion of low latency decision making
processes on the time scale spanning from image acquisition to human-level
high-order experiment planning.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12165</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12171</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Feature Augmentation and Normalization for Visual
  Recognition</dc:title>
 <dc:creator>Chen, Tianlong</dc:creator>
 <dc:creator>Cheng, Yu</dc:creator>
 <dc:creator>Gan, Zhe</dc:creator>
 <dc:creator>Wang, Jianfeng</dc:creator>
 <dc:creator>Wang, Lijuan</dc:creator>
 <dc:creator>Wang, Zhangyang</dc:creator>
 <dc:creator>Liu, Jingjing</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent advances in computer vision take advantage of adversarial data
augmentation to ameliorate the generalization ability of classification models.
Here, we present an effective and efficient alternative that advocates
adversarial augmentation on intermediate feature embeddings, instead of relying
on computationally-expensive pixel-level perturbations. We propose Adversarial
Feature Augmentation and Normalization (A-FAN), which (i) first augments visual
recognition models with adversarial features that integrate flexible scales of
perturbation strengths, (ii) then extracts adversarial feature statistics from
batch normalization, and re-injects them into clean features through feature
normalization. We validate the proposed approach across diverse visual
recognition tasks with representative backbone networks, including ResNets and
EfficientNets for classification, Faster-RCNN for detection, and Deeplab V3+
for segmentation. Extensive experiments show that A-FAN yields consistent
generalization improvement over strong baselines across various datasets for
classification, detection and segmentation tasks, such as CIFAR-10, CIFAR-100,
ImageNet, Pascal VOC2007, Pascal VOC2012, COCO2017, and Cityspaces.
Comprehensive ablation studies and detailed analyses also demonstrate that
adding perturbations to specific modules and layers of
classification/detection/segmentation backbones yields optimal performance.
Codes and pre-trained models will be made available at:
https://github.com/VITA-Group/CV_A-FAN.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12171</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12172</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-iterative domain decomposition for the Helmholtz equation using the
  method of difference potentials</dc:title>
 <dc:creator>North, Evan</dc:creator>
 <dc:creator>Tsynkov, Semyon</dc:creator>
 <dc:creator>Turkel, Eli</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We use the Method of Difference Potentials (MDP) to solve a non-overlapping
domain decomposition formulation of the Helmholtz equation. The MDP reduces the
Helmholtz equation on each subdomain to a Calderon's boundary equation with
projection on its boundary. The unknowns for the Calderon's equation are the
Dirichlet and Neumann data. Coupling between neighboring subdomains is rendered
by applying their respective Calderon's equations to the same data at the
common interface. Solutions on individual subdomains are computed concurrently
using a straightforward direct solver. We provide numerical examples
demonstrating that our method is insensitive to interior cross-points and mixed
boundary conditions, as well as large jumps in the wavenumber for transmission
problems, which are known to be problematic for many other Domain Decomposition
Methods.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12172</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12181</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of backward Euler primal DPG methods</dc:title>
 <dc:creator>F&#xfc;hrer, Thomas</dc:creator>
 <dc:creator>Heuer, Norbert</dc:creator>
 <dc:creator>Karkulik, Michael</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65N30, 65N12</dc:subject>
 <dc:description>  We analyse backward Euler time stepping schemes for the primal DPG
formulation of a class of parabolic problems. Optimal error estimates are shown
in the natural norm and in the $L^2$ norm of the field variable. For the heat
equation the solution of our primal DPG formulation equals the solution of a
standard Galerkin scheme and, thus, optimal error bounds are found in the
literature. In the presence of advection and reaction terms, however, the
latter identity is not valid anymore and the analysis of optimal error bounds
requires to resort to elliptic projection operators. It is essential that these
operators be projections with respect to the spatial part of the PDE, as in
standard Galerkin schemes, and not with respect to the full PDE at a time step,
as done previously.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12181</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12188</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Partitioned hybrid learning of Bayesian network structures</dc:title>
 <dc:creator>Huang, Jireh</dc:creator>
 <dc:creator>Zhou, Qing</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We develop a novel hybrid method for Bayesian network structure learning
called partitioned hybrid greedy search (pHGS), composed of three distinct yet
compatible new algorithms: Partitioned PC (pPC) accelerates skeleton learning
via a divide-and-conquer strategy, $p$-value adjacency thresholding (PATH)
effectively accomplishes parameter tuning with a single execution, and hybrid
greedy initialization (HGI) maximally utilizes constraint-based information to
obtain a high-scoring and well-performing initial graph for greedy search. We
establish structure learning consistency of our algorithms in the large-sample
limit, and empirically validate our methods individually and collectively
through extensive numerical comparisons. The combined merits of pPC and PATH
achieve significant computational reductions compared to the PC algorithm
without sacrificing the accuracy of estimated structures, and our generally
applicable HGI strategy reliably improves the estimation structural accuracy of
popular hybrid algorithms with negligible additional computational expense. Our
empirical results demonstrate the superior empirical performance of pHGS
against many state-of-the-art structure learning algorithms.
</dc:description>
 <dc:description>Comment: 44 pages</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12189</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Integration of Battery Electric Buses into Urban Bus Networks</dc:title>
 <dc:creator>Dirks, Nicolas</dc:creator>
 <dc:creator>Schiffer, Maximilian</dc:creator>
 <dc:creator>Walther, Grit</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Cities all around the world struggle with urban air quality due to
transportation related emissions. In public transport networks, replacing
internal combustion engine buses by electric buses provides an opportunity to
improve air quality. Hence, many bus network operators currently ask for an
optimal transformation plan to integrate battery electric buses into their
fleet. Ideally, this plan also considers the installation of necessary charging
infrastructure to ensure a fleet's operational feasibility. Against this
background, we introduce an integrated modeling approach to determine a
cost-optimal, long-term, multi-period transformation plan for integrating
battery electric buses into urban bus networks. Our model connects central
strategic and operational decisions. We minimize total cost of ownership and
analyze potential reductions of nitrogen oxide emissions. Our results base on a
case study of a real-world bus network and show that a comprehensive
integration of battery electric buses is feasible and economically beneficial.
By analyzing the impact of battery capacities and charging power on the optimal
fleet transformation, we show that medium-power charging facilities combined
with medium-capacity batteries are superior to networks with low-power or
high-power charging facilities.
</dc:description>
 <dc:description>Comment: 25 pages, 13 figures</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12191</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using an Epidemiological Model to Study the Spread of Misinformation
  during the Black Lives Matter Movement</dc:title>
 <dc:creator>Maleki, Maryam</dc:creator>
 <dc:creator>Mead, Esther</dc:creator>
 <dc:creator>Arani, Mohammad</dc:creator>
 <dc:creator>Agarwal, Nitin</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The proliferation of social media platforms like Twitter has heightened the
consequences of the spread of misinformation. To understand and model the
spread of misinformation, in this paper, we leveraged the SEIZ (Susceptible,
Exposed, Infected, Skeptics) epidemiological model to describe the underlying
process that delineates the spread of misinformation on Twitter. Compared to
the other epidemiological models, this model produces broader results because
it includes the additional Skeptics (Z) compartment, wherein a user may be
exposed to an item of misinformation but not engage in any reaction to it, and
the additional Exposed (E) compartment, wherein the user may need some time
before deciding to spread a misinformation item. We analyzed misinformation
regarding the unrest in Washington, D.C. in the month of March 2020 which was
propagated by the use of the #DCblackout hashtag by different users across the
U.S. on Twitter. Our analysis shows that misinformation can be modeled using
the concept of epidemiology. To the best of our knowledge, this research is the
first to attempt to apply the SEIZ epidemiological model to the spread of a
specific item of misinformation, which is a category distinct from that of
rumor, and a hoax on online social media platforms. Applying a mathematical
model can help to understand the trends and dynamics of the spread of
misinformation on Twitter and ultimately help to develop techniques to quickly
identify and control it.
</dc:description>
 <dc:description>Comment: This paper is accepted on the International Conference on Fake News,
  Social Media Manipulation and Misinformation 2021 (ICFNSMMM 2021)</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12195</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Max-Min Fair Energy-Efficient Beamforming Design for Intelligent
  Reflecting Surface-Aided SWIPT Systems with Non-linear Energy Harvesting
  Model</dc:title>
 <dc:creator>Zargari, Shayan</dc:creator>
 <dc:creator>Khalili, Ata</dc:creator>
 <dc:creator>Wu, Qingqing</dc:creator>
 <dc:creator>Mili, Mohammad Robat</dc:creator>
 <dc:creator>Ng, Derrick Wing Kwan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  This paper considers an intelligent reflecting sur-face (IRS)-aided
simultaneous wireless information and power transfer (SWIPT) network, where
multiple users decode data and harvest energy from the transmitted signal of a
transmit-ter. The proposed design framework exploits the cost-effective IRS to
establish favorable communication environment to improve the fair energy
efficient. In particular, we study the max-min energy efficiency (EE) of the
system by jointly designing the transmit information and energy beamforming at
the base station (BS), phase shifts at the IRS, as well as the power splitting
(PS) ratio at all users subject to the minimum rate, minimum harvested energy,
and transmit power constraints. The formulated problem is non-convex and thus
challenging to be solved. We propose two algorithms namely penalty-based and
inner approximation (IA)-based to handle the non-convexity of the optimization
problem. As such, we divide the original problem into two sub-problems and
apply the alternating optimization (AO) algorithm for both proposed algorithms
to handle it iteratively. In particular, in the penalty-based algorithm for the
first sub-problem, the semi-definite relaxation (SDR) technique, difference of
convex functions (DC) programming, majorization-minimization (MM) approach, and
fractional programming theory are exploited to transform the non-convex
optimization problem into a convex form that can be addressed efficiently. For
the second sub-problem, a penalty-based approach is proposed to handle the
optimization on the phase shifts introduced by the IRS with the proposed
algorithms. For the IA-based method, we optimize jointly beamforming vectors
and phase shifts while the PS ratio is solved optimally in the first
sub-problem...
</dc:description>
 <dc:description>Comment: Minor Revision by IEEE TVT</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12195</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12198</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Challenges in Statistical Analysis of Data Collected by a Bandit
  Algorithm: An Empirical Exploration in Applications to Adaptively Randomized
  Experiments</dc:title>
 <dc:creator>Williams, Joseph Jay</dc:creator>
 <dc:creator>Nogas, Jacob</dc:creator>
 <dc:creator>Deliu, Nina</dc:creator>
 <dc:creator>Shaikh, Hammad</dc:creator>
 <dc:creator>Villar, Sofia S.</dc:creator>
 <dc:creator>Durand, Audrey</dc:creator>
 <dc:creator>Rafferty, Anna</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Multi-armed bandit algorithms have been argued for decades as useful for
adaptively randomized experiments. In such experiments, an algorithm varies
which arms (e.g. alternative interventions to help students learn) are assigned
to participants, with the goal of assigning higher-reward arms to as many
participants as possible. We applied the bandit algorithm Thompson Sampling
(TS) to run adaptive experiments in three university classes. Instructors saw
great value in trying to rapidly use data to give their students in the
experiments better arms (e.g. better explanations of a concept). Our
deployment, however, illustrated a major barrier for scientists and
practitioners to use such adaptive experiments: a lack of quantifiable insight
into how much statistical analysis of specific real-world experiments is
impacted (Pallmann et al, 2018; FDA, 2019), compared to traditional uniform
random assignment. We therefore use our case study of the ubiquitous two-arm
binary reward setting to empirically investigate the impact of using Thompson
Sampling instead of uniform random assignment. In this setting, using common
statistical hypothesis tests, we show that collecting data with TS can as much
as double the False Positive Rate (FPR; incorrectly reporting differences when
none exist) and the False Negative Rate (FNR; failing to report differences
when they exist)...
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12204</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human-like Controllable Image Captioning with Verb-specific Semantic
  Roles</dc:title>
 <dc:creator>Chen, Long</dc:creator>
 <dc:creator>Jiang, Zhihong</dc:creator>
 <dc:creator>Xiao, Jun</dc:creator>
 <dc:creator>Liu, Wei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Controllable Image Captioning (CIC) -- generating image descriptions
following designated control signals -- has received unprecedented attention
over the last few years. To emulate the human ability in controlling caption
generation, current CIC studies focus exclusively on control signals concerning
objective properties, such as contents of interest or descriptive patterns.
However, we argue that almost all existing objective control signals have
overlooked two indispensable characteristics of an ideal control signal: 1)
Event-compatible: all visual contents referred to in a single sentence should
be compatible with the described activity. 2) Sample-suitable: the control
signals should be suitable for a specific image sample. To this end, we propose
a new control signal for CIC: Verb-specific Semantic Roles (VSR). VSR consists
of a verb and some semantic roles, which represents a targeted activity and the
roles of entities involved in this activity. Given a designated VSR, we first
train a grounded semantic role labeling (GSRL) model to identify and ground all
entities for each role. Then, we propose a semantic structure planner (SSP) to
learn human-like descriptive semantic structures. Lastly, we use a role-shift
captioning model to generate the captions. Extensive experiments and ablations
demonstrate that our framework can achieve better controllability than several
strong baselines on two challenging CIC benchmarks. Besides, we can generate
multi-level diverse captions easily. The code is available at:
https://github.com/mad-red/VSR-guided-CIC.
</dc:description>
 <dc:description>Comment: Accepted by CVPR 2021. The code is available at:
  https://github.com/mad-red/VSR-guided-CIC</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12205</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two-Dimensional Cruise Control of Autonomous Vehicles on Lane-Free Roads</dc:title>
 <dc:creator>Karafyllis, Iasson</dc:creator>
 <dc:creator>Theodosis, Dionysis</dc:creator>
 <dc:creator>Papageorgiou, Markos</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we design decentralized control strategies for the
two-dimensional movement of autonomous vehicles on lane-free roads. The bicycle
kinematic model is used to model the dynamics of the vehicles, and each vehicle
determines its control input based only on its own speed and on the distance
from other (adjacent) vehicles and the boundary of the road. Potential
functions and Barbalat's lemma are employed to prove the following properties,
which are ensured by the proposed controller: (i) the vehicles do not collide
with each other or with the boundary of the road; (ii) the speeds of all
vehicles are always positive, i.e., no vehicle moves backwards at any time;
(iii) the speed of all vehicles remain below a given speed limit; (iv) all
vehicle speeds converge to a given longitudinal speed set-point; and (v) the
accelerations, lateral speeds, and orientations of all vehicles tend to zero.
The efficiency of the proposed 2-D cruise controllers is illustrated by means
of numerical examples.
</dc:description>
 <dc:description>Comment: 29 pages, 8 figures</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12213</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal Feature Networks for CNN based Object Detection</dc:title>
 <dc:creator>Weber, Michael</dc:creator>
 <dc:creator>Wald, Tassilo</dc:creator>
 <dc:creator>Z&#xf6;llner, J. Marius</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  For reliable environment perception, the use of temporal information is
essential in some situations. Especially for object detection, sometimes a
situation can only be understood in the right perspective through temporal
information. Since image-based object detectors are currently based almost
exclusively on CNN architectures, an extension of their feature extraction with
temporal features seems promising.
  Within this work we investigate different architectural components for a
CNN-based temporal information extraction. We present a Temporal Feature
Network which is based on the insights gained from our architectural
investigations. This network is trained from scratch without any ImageNet
information based pre-training as these images are not available with temporal
information. The object detector based on this network is evaluated against the
non-temporal counterpart as baseline and achieves competitive results in an
evaluation on the KITTI object detection dataset.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12213</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12218</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bug or not bug? That is the question</dc:title>
 <dc:creator>Perez, Quentin</dc:creator>
 <dc:creator>Jean, Pierre-Antoine</dc:creator>
 <dc:creator>Urtado, Christelle</dc:creator>
 <dc:creator>Vauttier, Sylvain</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Nowadays, development teams often rely on tools such as Jira or Bugzilla to
manage backlogs of issues to be solved to develop or maintain software.
Although they relate to many different concerns (e.g., bug fixing, new feature
development, architecture refactoring), few means are proposed to identify and
classify these different kinds of issues, except for non mandatory labels that
can be manually associated to them. This may lead to a lack of issue
classification or to issue misclassification that may impact automatic issue
management (planning, assignment) or issue-derived metrics. Automatic issue
classification thus is a relevant topic for assisting backlog management. This
paper proposes a binary classification solution for discriminating bug from non
bug issues. This solution combines natural language processing (TF-IDF) and
classification (multi-layer perceptron) techniques, selected after comparing
commonly used solutions to classify issues. Moreover, hyper-parameters of the
neural network are optimized using a genetic algorithm. The obtained results,
as compared to existing works on a commonly used benchmark, show significant
improvements on the F1 measure for all datasets.
</dc:description>
 <dc:description>Comment: Accepted as Research track at ICPC 2021</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12221</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mining Scientific Workflows for Anomalous Data Transfers</dc:title>
 <dc:creator>Tu, Huy</dc:creator>
 <dc:creator>Papadimitriou, George</dc:creator>
 <dc:creator>Kiran, Mariam</dc:creator>
 <dc:creator>Wang, Cong</dc:creator>
 <dc:creator>Mandal, Anirban</dc:creator>
 <dc:creator>Deelman, Ewa</dc:creator>
 <dc:creator>Menzies, Tim</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Modern scientific workflows are data-driven and are often executed on
distributed, heterogeneous, high-performance computing infrastructures.
Anomalies and failures in the workflow execution cause loss of scientific
productivity and inefficient use of the infrastructure. Hence, detecting,
diagnosing, and mitigating these anomalies are immensely important for reliable
and performant scientific workflows. Since these workflows rely heavily on
high-performance network transfers that require strict QoS constraints,
accurately detecting anomalous network performance is crucial to ensure
reliable and efficient workflow execution. To address this challenge, we have
developed X-FLASH, a network anomaly detection tool for faulty TCP workflow
transfers. X-FLASH incorporates novel hyperparameter tuning and data mining
approaches for improving the performance of the machine learning algorithms to
accurately classify the anomalous TCP packets. X-FLASH leverages XGBoost as an
ensemble model and couples XGBoost with a sequential optimizer, FLASH, borrowed
from search-based Software Engineering to learn the optimal model parameters.
X-FLASH found configurations that outperformed the existing approach up to
28\%, 29\%, and 40\% relatively for F-measure, G-score, and recall in less than
30 evaluations. From (1) large improvement and (2) simple tuning, we recommend
future research to have additional tuning study as a new standard, at least in
the area of scientific workflow anomaly detection.
</dc:description>
 <dc:description>Comment: Accepted for MSR 2021: Working Conference on Mining Software
  Repositories
  (https://2021.msrconf.org/details/msr-2021-technical-papers/1/Mining-Workflows-for-Anomalous-Data-Transfers)</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12221</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12227</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Challenges in systematic reviews and meta-analyses of mediation analyses</dc:title>
 <dc:creator>Vo, Tat-Thang</dc:creator>
 <dc:creator>Vansteelandt, Stijn</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Systematic reviews and meta-analyses of mediation studies are increasingly
being implemented in practice. Nonetheless, the methodology for conducting such
review and analysis is still in a development phase, with much room for
improvement. In this paper, we highlight and discuss challenges that
investigators face in mediation systematic reviews and meta-analyses, then
propose ways of accommodating these in practice.
</dc:description>
 <dc:description>Comment: Currently under peer-review at the American Journal of Epidemiology</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12227</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12228</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Channel Scaling: A Scale-and-Select Approach for Transfer Learning</dc:title>
 <dc:creator>Wong, Ken C. L.</dc:creator>
 <dc:creator>Kashyap, Satyananda</dc:creator>
 <dc:creator>Moradi, Mehdi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Transfer learning with pre-trained neural networks is a common strategy for
training classifiers in medical image analysis. Without proper channel
selections, this often results in unnecessarily large models that hinder
deployment and explainability. In this paper, we propose a novel approach to
efficiently build small and well performing networks by introducing the
channel-scaling layers. A channel-scaling layer is attached to each frozen
convolutional layer, with the trainable scaling weights inferring the
importance of the corresponding feature channels. Unlike the fine-tuning
approaches, we maintain the weights of the original channels and large datasets
are not required. By imposing L1 regularization and thresholding on the scaling
weights, this framework iteratively removes unnecessary feature channels from a
pre-trained model. Using an ImageNet pre-trained VGG16 model, we demonstrate
the capabilities of the proposed framework on classifying opacity from chest
X-ray images. The results show that we can reduce the number of parameters by
95% while delivering a superior performance.
</dc:description>
 <dc:description>Comment: This paper was accepted by the IEEE International Symposium on
  Biomedical Imaging (ISBI) 2021</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12228</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12229</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HaPPY-Mine: Designing a Mining Reward Function</dc:title>
 <dc:creator>Kiffer, Lucianna</dc:creator>
 <dc:creator>Rajaraman, Rajmohan</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In cryptocurrencies, the block reward is meant to serve as the incentive
mechanism for miners to commit resources to create blocks and in effect secure
the system. Existing systems primarily divide the reward in proportion to
expended resources and follow one of two static models for total block reward:
(i) a fixed reward for each block (e.g., Ethereum), or (ii) one where the block
reward halves every set number of blocks (e.g., the Bitcoin model of halving
roughly every 4 years) but otherwise remains fixed between halvings. In recent
work, a game-theoretic analysis of the static model under asymmetric miner
costs showed that an equilibrium always exists and is unique. Their analysis
also reveals how asymmetric costs can lead to large-scale centralization in
blockchain mining, a phenomenon that has been observed in Bitcoin and Ethereum
and highlighted by other studies. In this work we introduce a novel family of
mining reward functions, HaPPY-Mine (HAsh-Pegged Proportional Yield), which peg
the value of the reward to the hashrate of the system, decreasing the reward as
the hashrate increases. HaPPY-Mine distributes rewards in proportion to
expended hashrate and inherits the safety properties of the generalized
proportional reward function. We study HaPPY-Mine under a heterogeneous miner
cost model and show that an equilibrium always exists with a unique set of
miner participants and a unique total hashrate. Significantly, we prove that a
HaPPY-Mine equilibrium is more decentralized than the static model equilibrium
under a set of metrics including number of mining participants and hashrate
distribution. Finally, we show that any HaPPY-Mine equilibrium is also safe
against collusion and sybil attacks, and explore how the market value of the
currency affects the equilibrium.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12229</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12231</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Role of System Software in Energy Management of Neuromorphic
  Computing</dc:title>
 <dc:creator>Titirsha, Twisha</dc:creator>
 <dc:creator>Song, Shihao</dc:creator>
 <dc:creator>Balaji, Adarsha</dc:creator>
 <dc:creator>Das, Anup</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Neuromorphic computing systems such as DYNAPs and Loihi have recently been
introduced to the computing community to improve performance and energy
efficiency of machine learning programs, especially those that are implemented
using Spiking Neural Network (SNN). The role of a system software for
neuromorphic systems is to cluster a large machine learning model (e.g., with
many neurons and synapses) and map these clusters to the computing resources of
the hardware. In this work, we formulate the energy consumption of a
neuromorphic hardware, considering the power consumed by neurons and synapses,
and the energy consumed in communicating spikes on the interconnect. Based on
such formulation, we first evaluate the role of a system software in managing
the energy consumption of neuromorphic systems. Next, we formulate a simple
heuristic-based mapping approach to place the neurons and synapses onto the
computing resources to reduce energy consumption. We evaluate our approach with
10 machine learning applications and demonstrate that the proposed mapping
approach leads to a significant reduction of energy consumption of neuromorphic
computing systems.
</dc:description>
 <dc:description>Comment: To appear in 18th Computer Frontiers 2021</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12239</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Biologically Inspired Collision Avoidance Without Distance Information</dc:title>
 <dc:creator>Marinho, Thiago</dc:creator>
 <dc:creator>Amrouche, Massi</dc:creator>
 <dc:creator>Stipanovic, Dusan</dc:creator>
 <dc:creator>Cichella, Venanzio</dc:creator>
 <dc:creator>Hovakimyan, Naira</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Biological evidence shows that animals are capable of evading eminent
collision without using depth information, relying solely on looming stimuli.
In robotics, collision avoidance among uncooperative vehicles requires
measurement of relative distance to the obstacle. Small, low-cost mobile robots
and UAVs might be unable to carry distance measuring sensors, like LIDARS and
depth cameras. We propose a control framework suitable for a unicycle-like
vehicle moving in a 2D plane that achieves collision avoidance. The control
strategy is inspired by the reaction of invertebrates to approaching obstacles,
relying exclusively on line-of-sight (LOS) angle, LOS angle rate, and
time-to-collision as feedback. Those quantities can readily be estimated from a
monocular camera vision system onboard a mobile robot. The proposed avoidance
law commands the heading angle to circumvent a moving obstacle with unknown
position, while the velocity controller is left as a degree of freedom to
accomplish other mission objectives. Theoretical guarantees are provided to
show that minimum separation between the vehicle and the obstacle is attained
regardless of the exogenous tracking controller.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12239</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12243</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Importance Sampling for Finite-Sum Optimization and Sampling
  with Decreasing Step-Sizes</dc:title>
 <dc:creator>Hanchi, Ayoub El</dc:creator>
 <dc:creator>Stephens, David A.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Reducing the variance of the gradient estimator is known to improve the
convergence rate of stochastic gradient-based optimization and sampling
algorithms. One way of achieving variance reduction is to design importance
sampling strategies. Recently, the problem of designing such schemes was
formulated as an online learning problem with bandit feedback, and algorithms
with sub-linear static regret were designed. In this work, we build on this
framework and propose Avare, a simple and efficient algorithm for adaptive
importance sampling for finite-sum optimization and sampling with decreasing
step-sizes. Under standard technical conditions, we show that Avare achieves
$\mathcal{O}(T^{2/3})$ and $\mathcal{O}(T^{5/6})$ dynamic regret for SGD and
SGLD respectively when run with $\mathcal{O}(1/t)$ step sizes. We achieve this
dynamic regret bound by leveraging our knowledge of the dynamics defined by the
algorithm, and combining ideas from online learning and variance-reduced
stochastic optimization. We validate empirically the performance of our
algorithm and identify settings in which it leads to significant improvements.
</dc:description>
 <dc:description>Comment: Advances in Neural Information Processing Systems, Dec 2020,
  Vancouver, Canada</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12243</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12245</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiview and Multiclass Image Segmentation using Deep Learning in Fetal
  Echocardiography</dc:title>
 <dc:creator>Wong, Ken C. L.</dc:creator>
 <dc:creator>Sinkovskaya, Elena S.</dc:creator>
 <dc:creator>Abuhamad, Alfred Z.</dc:creator>
 <dc:creator>Syeda-Mahmood, Tanveer</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Congenital heart disease (CHD) is the most common congenital abnormality
associated with birth defects in the United States. Despite training efforts
and substantial advancement in ultrasound technology over the past years, CHD
remains an abnormality that is frequently missed during prenatal
ultrasonography. Therefore, computer-aided detection of CHD can play a critical
role in prenatal care by improving screening and diagnosis. Since many CHDs
involve structural abnormalities, automatic segmentation of anatomical
structures is an important step in the analysis of fetal echocardiograms. While
existing methods mainly focus on the four-chamber view with a small number of
structures, here we present a more comprehensive deep learning segmentation
framework covering 14 anatomical structures in both three-vessel trachea and
four-chamber views. Specifically, our framework enhances the V-Net with spatial
dropout, group normalization, and deep supervision to train a segmentation
model that can be applied on both views regardless of abnormalities. By
identifying the pitfall of using the Dice loss when some labels are unavailable
in some images, this framework integrates information from multiple views and
is robust to missing structures due to anatomical anomalies, achieving an
average Dice score of 79%.
</dc:description>
 <dc:description>Comment: This paper was accepted by SPIE Medical Imaging 2021</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12245</dc:identifier>
 <dc:identifier>doi:10.1117/12.2582191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12246</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Hybrid Approximation for Uncertainty Management in
  Gas-Electric Systems</dc:title>
 <dc:creator>Malley, Conor O'</dc:creator>
 <dc:creator>Hug, Gabriela</dc:creator>
 <dc:creator>Roald, Line</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Gas-fired generators, with their ability to quickly ramp up and down their
electricity production, play an important role in managing renewable energy
variability. However, these changes in electricity production translate into
variability in the consumption of natural gas, and propagate uncertainty from
the electric grid to the natural gas system. To ensure that both systems are
operating safely, there is an increasing need for coordination and uncertainty
management among the electricity and gas networks. A challenging aspect of this
coordination is the consideration of natural gas dynamics, which play an
important role at the time scale of interest, but give rise to a set of
non-linear and non-convex equations that are hard to optimize over even in the
deterministic case. Many conventional methods for stochastic optimization
cannot be used because they either incorporate a large number of scenarios
directly or require the underlying problem to be convex. To address these
challenges, we propose using a Stochastic Hybrid Approximation algorithm to
more efficiently solve these problems and investigate several different
variants of this algorithm. In a case study, we demonstrate that the proposed
technique is able to quickly obtain high quality solutions and outperforms
existing benchmarks such as Generalized Benders Decomposition. We demonstrate
that coordinated uncertainty management that accounts for the gas system can
significantly reduce both electric and gas system load shed in stressed
conditions.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12246</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12247</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gradient-enhanced multifidelity neural networks for high-dimensional
  function approximation</dc:title>
 <dc:creator>Nagawkar, Jethro</dc:creator>
 <dc:creator>Leifsson, Leifur</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In this work, a novel multifidelity machine learning (ML) model, the
gradient-enhanced multifidelity neural networks (GEMFNNs), is proposed. This
model is a multifidelity version of gradient-enhanced neural networks (GENNs)
as it uses both function and gradient information available at multiple levels
of fidelity to make function approximations. Its construction is similar to
multifidelity neural networks (MFNNs). This model is tested on three analytical
function, a one, two, and a 20 variable function. It is also compared to neural
networks (NNs), GENNs, and MFNNs, and the number of samples required to reach a
global accuracy of 0.99 coefficient of determination (R^2) is measured. GEMFNNs
required 18, 120, and 600 high-fidelity samples for the one, two, and 20
dimensional cases, respectively, to meet the target accuracy. NNs performed
best on the one variable case, requiring only ten samples, while GENNs worked
best on the two variable case, requiring 120 samples. GEMFNNs worked best for
the 20 variable case, while requiring nearly eight times fewer samples than its
nearest competitor, GENNs. For this case, NNs and MFNNs did not reach the
target global accuracy even after using 10,000 high-fidelity samples. This work
demonstrates the benefits of using gradient as well as multifidelity
information in NNs for high-dimensional problems.
</dc:description>
 <dc:description>Comment: Submitted to AMSE 2021 IDETC/CIE conference. 10 pages, 5 figures</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12247</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12256</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatio-Temporal Sparsification for General Robust Graph Convolution
  Networks</dc:title>
 <dc:creator>Lu, Mingming</dc:creator>
 <dc:creator>Zhang, Ya</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Graph Neural Networks (GNNs) have attracted increasing attention due to its
successful applications on various graph-structure data. However, recent
studies have shown that adversarial attacks are threatening the functionality
of GNNs. Although numerous works have been proposed to defend adversarial
attacks from various perspectives, most of them can be robust against the
attacks only on specific scenarios. To address this shortage of robust
generalization, we propose to defend the adversarial attacks on GNN through
applying the Spatio-Temporal sparsification (called ST-Sparse) on the GNN
hidden node representation. ST-Sparse is similar to the Dropout regularization
in spirit. Through intensive experiment evaluation with GCN as the target GNN
model, we identify the benefits of ST-Sparse as follows: (1) ST-Sparse shows
the defense performance improvement in most cases, as it can effectively
increase the robust accuracy by up to 6\% improvement; (2) ST-Sparse
illustrates its robust generalization capability by integrating with the
existing defense methods, similar to the integration of Dropout into various
deep learning models as a standard regularization technique; (3) ST-Sparse also
shows its ordinary generalization capability on clean datasets, in that
ST-SparseGCN (the integration of ST-Sparse and the original GCN) even
outperform the original GCN, while the other three representative defense
methods are inferior to the original GCN.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12256</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12259</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A stabilized computational nonlocal poromechanics model for dynamic
  analysis of saturated porous media</dc:title>
 <dc:creator>Menon, Shashank</dc:creator>
 <dc:creator>Song, Xiaoyu</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  In this article we formulate a stable computational nonlocal poromechanics
model for dynamic analysis of saturated porous media. As a novelty, the
stabilization formulation eliminates zero-energy modes associated with the
original multiphase correspondence constitutive models in the coupled nonlocal
poromechanics model. The two-phase stabilization scheme is formulated based on
an energy method that incorporates inhomogeneous solid deformation and fluid
flow. In this method, the nonlocal formulations of skeleton strain energy and
fluid flow dissipation energy equate to their local formulations. The stable
coupled nonlocal poromechanics model is solved for dynamic analysis by an
implicit time integration scheme. As a new contribution, we validate the
coupled stabilization formulation by comparing numerical results with
analytical and finite element solutions for one-dimensional and two-dimensional
dynamic problems in saturated porous media. Numerical examples of dynamic
strain localization in saturated porous media are presented to demonstrate the
efficacy of the stable coupled poromechanics framework for localized failure
under dynamic loads.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12269</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GelSlim3.0: High-Resolution Measurement of Shape, Force and Slip in a
  Compact Tactile-Sensing Finger</dc:title>
 <dc:creator>Taylor, Ian</dc:creator>
 <dc:creator>Dong, Siyuan</dc:creator>
 <dc:creator>Rodriguez, Alberto</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This work presents a new version of the tactile-sensing finger GelSlim 3.0,
which integrates the ability to sense high-resolution shape, force, and slip in
a compact form factor for use with small parallel jaw grippers in cluttered
bin-picking scenarios. The novel design incorporates the capability to use
real-time analytic methods to measure shape, estimate the contact 3D force
distribution, and detect incipient slip. To achieve a compact integration, we
optimize the optical path from illumination source to camera and other
geometric variables in a optical simulation environment. In particular, we
optimize the illumination sources and a light shaping lens around the
constraints imposed by the photometric stereo algorithm used for depth
reconstruction. The optimized optical configuration is integrated into a finger
design composed of robust and easily replaceable snap-to-fit fingetip module
that allow for ease of manufacture, assembly, use, and repair. To stimulate
future research in tactile-sensing and provide the robotics community access to
reliable and easily-reproducible tactile finger with a diversity of sensing
modalities, we open-source the design and software at
https://github.com/mcubelab/gelslim.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12269</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12270</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dilated SpineNet for Semantic Segmentation</dc:title>
 <dc:creator>Rashwan, Abdullah</dc:creator>
 <dc:creator>Du, Xianzhi</dc:creator>
 <dc:creator>Yin, Xiaoqi</dc:creator>
 <dc:creator>Li, Jing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Scale-permuted networks have shown promising results on object bounding box
detection and instance segmentation. Scale permutation and cross-scale fusion
of features enable the network to capture multi-scale semantics while
preserving spatial resolution. In this work, we evaluate this meta-architecture
design on semantic segmentation - another vision task that benefits from high
spatial resolution and multi-scale feature fusion at different network stages.
By further leveraging dilated convolution operations, we propose SpineNet-Seg,
a network discovered by NAS that is searched from the DeepLabv3 system.
SpineNet-Seg is designed with a better scale-permuted network topology with
customized dilation ratios per block on a semantic segmentation task.
SpineNet-Seg models outperform the DeepLabv3/v3+ baselines at all model scales
on multiple popular benchmarks in speed and accuracy. In particular, our
SpineNet-S143+ model achieves the new state-of-the-art on the popular
Cityscapes benchmark at 83.04% mIoU and attained strong performance on the
PASCAL VOC2012 benchmark at 85.56% mIoU. SpineNet-Seg models also show
promising results on a challenging Street View segmentation dataset. Code and
checkpoints will be open-sourced.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12270</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12273</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An alternative reconstruction for WENO schemes with adaptive order</dc:title>
 <dc:creator>Shen, Hua</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  We propose an alternative reconstruction for weighted essentially
non-oscillatory schemes with adaptive order (WENO-AO) for solving hyperbolic
conservation laws. The alternative reconstruction has a more concise form than
the original WENO-AO reconstruction. Moreover, it is a strictly convex
combination of polynomials with unequal degrees. Numerical examples show that
the alternative reconstruction maintains the accuracy and robustness of the
WENO-AO schemes.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12277</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conditional Training with Bounding Map for Universal Lesion Detection</dc:title>
 <dc:creator>Li, Han</dc:creator>
 <dc:creator>Chen, Long</dc:creator>
 <dc:creator>Han, Hu</dc:creator>
 <dc:creator>Zhou, S. Kevin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Universal Lesion Detection (ULD) in computed tomography plays an essential
role in computer-aided diagnosis. Promising ULD results have been reported by
coarse-to-fine two-stage detection approaches, but such two-stage ULD methods
still suffer from issues like imbalance of positive v.s. negative anchors
during object proposal and insufficient supervision problem during localization
regression and classification of the region of interest (RoI) proposals. While
leveraging pseudo segmentation masks such as bounding map (BM) can reduce the
above issues to some degree, it is still an open problem to effectively handle
the diverse lesion shapes and sizes in ULD. In this paper, we propose a
BM-based conditional training for two-stage ULD, which can (i) reduce positive
vs. negative anchor imbalance via BM-based conditioning (BMC) mechanism for
anchor sampling instead of traditional IoU-based rule; and (ii) adaptively
compute size-adaptive BM (ABM) from lesion bounding box, which is used for
improving lesion localization accuracy via ABMsupervised segmentation.
Experiments with four state-of-the-art methods show that the proposed approach
can bring an almost free detection accuracy improvement without requiring
expensive lesion mask annotations.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12277</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12278</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Comprehensive Motion Representation for Action Recognition</dc:title>
 <dc:creator>Wu, Mingyu</dc:creator>
 <dc:creator>Jiang, Boyuan</dc:creator>
 <dc:creator>Luo, Donghao</dc:creator>
 <dc:creator>Yan, Junchi</dc:creator>
 <dc:creator>Wang, Yabiao</dc:creator>
 <dc:creator>Tai, Ying</dc:creator>
 <dc:creator>Wang, Chengjie</dc:creator>
 <dc:creator>Li, Jilin</dc:creator>
 <dc:creator>Huang, Feiyue</dc:creator>
 <dc:creator>Yang, Xiaokang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  For action recognition learning, 2D CNN-based methods are efficient but may
yield redundant features due to applying the same 2D convolution kernel to each
frame. Recent efforts attempt to capture motion information by establishing
inter-frame connections while still suffering the limited temporal receptive
field or high latency. Moreover, the feature enhancement is often only
performed by channel or space dimension in action recognition. To address these
issues, we first devise a Channel-wise Motion Enhancement (CME) module to
adaptively emphasize the channels related to dynamic information with a
channel-wise gate vector. The channel gates generated by CME incorporate the
information from all the other frames in the video. We further propose a
Spatial-wise Motion Enhancement (SME) module to focus on the regions with the
critical target in motion, according to the point-to-point similarity between
adjacent feature maps. The intuition is that the change of background is
typically slower than the motion area. Both CME and SME have clear physical
meaning in capturing action clues. By integrating the two modules into the
off-the-shelf 2D network, we finally obtain a Comprehensive Motion
Representation (CMR) learning method for action recognition, which achieves
competitive performance on Something-Something V1 &amp; V2 and Kinetics-400. On the
temporal reasoning datasets Something-Something V1 and V2, our method
outperforms the current state-of-the-art by 2.3% and 1.9% when using 16 frames
as input, respectively.
</dc:description>
 <dc:description>Comment: Accepted by AAAI21</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12278</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12286</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Discovery of Real-Time Network Camera Data From Heterogeneous
  Web Pages</dc:title>
 <dc:creator>Dailey, Ryan</dc:creator>
 <dc:creator>Chawla, Aniesh</dc:creator>
 <dc:creator>Liu, Andrew</dc:creator>
 <dc:creator>Mishra, Sripath</dc:creator>
 <dc:creator>Zhang, Ling</dc:creator>
 <dc:creator>Majors, Josh</dc:creator>
 <dc:creator>Lu, Yung-Hsiang</dc:creator>
 <dc:creator>Thiruvathukal, George K.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Reduction in the cost of Network Cameras along with a rise in connectivity
enables entities all around the world to deploy vast arrays of camera networks.
Network cameras offer real-time visual data that can be used for studying
traffic patterns, emergency response, security, and other applications.
Although many sources of Network Camera data are available, collecting the data
remains difficult due to variations in programming interface and website
structures. Previous solutions rely on manually parsing the target website,
taking many hours to complete. We create a general and automated solution for
aggregating Network Camera data spread across thousands of uniquely structured
web pages. We analyze heterogeneous web page structures and identify common
characteristics among 73 sample Network Camera websites (each website has
multiple web pages). These characteristics are then used to build an automated
camera discovery module that crawls and aggregates Network Camera data. Our
system successfully extracts 57,364 Network Cameras from 237,257 unique web
pages.
</dc:description>
 <dc:description>Comment: This paper has been accepted by ACM Transactions on Internet
  Technology</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12286</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12292</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NDT-Transformer: Large-Scale 3D Point Cloud Localisation using the
  Normal Distribution Transform Representation</dc:title>
 <dc:creator>Zhou, Zhicheng</dc:creator>
 <dc:creator>Zhao, Cheng</dc:creator>
 <dc:creator>Adolfsson, Daniel</dc:creator>
 <dc:creator>Su, Songzhi</dc:creator>
 <dc:creator>Gao, Yang</dc:creator>
 <dc:creator>Duckett, Tom</dc:creator>
 <dc:creator>Sun, Li</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  3D point cloud-based place recognition is highly demanded by autonomous
driving in GPS-challenged environments and serves as an essential component
(i.e. loop-closure detection) in lidar-based SLAM systems. This paper proposes
a novel approach, named NDT-Transformer, for realtime and large-scale place
recognition using 3D point clouds. Specifically, a 3D Normal Distribution
Transform (NDT) representation is employed to condense the raw, dense 3D point
cloud as probabilistic distributions (NDT cells) to provide the geometrical
shape description. Then a novel NDT-Transformer network learns a global
descriptor from a set of 3D NDT cell representations. Benefiting from the NDT
representation and NDT-Transformer network, the learned global descriptors are
enriched with both geometrical and contextual information. Finally, descriptor
retrieval is achieved using a query-database for place recognition. Compared to
the state-of-the-art methods, the proposed approach achieves an improvement of
7.52% on average top 1 recall and 2.73% on average top 1% recall on the Oxford
Robotcar benchmark.
</dc:description>
 <dc:description>Comment: To be appear in ICRA2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12292</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12293</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Reweighted Gradient Descent</dc:title>
 <dc:creator>Hanchi, Ayoub El</dc:creator>
 <dc:creator>Stephens, David A.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Despite the strong theoretical guarantees that variance-reduced finite-sum
optimization algorithms enjoy, their applicability remains limited to cases
where the memory overhead they introduce (SAG/SAGA), or the periodic full
gradient computation they require (SVRG/SARAH) are manageable. A promising
approach to achieving variance reduction while avoiding these drawbacks is the
use of importance sampling instead of control variates. While many such methods
have been proposed in the literature, directly proving that they improve the
convergence of the resulting optimization algorithm has remained elusive. In
this work, we propose an importance-sampling-based algorithm we call SRG
(stochastic reweighted gradient). We analyze the convergence of SRG in the
strongly-convex case and show that, while it does not recover the linear rate
of control variates methods, it provably outperforms SGD. We pay particular
attention to the time and memory overhead of our proposed method, and design a
specialized red-black tree allowing its efficient implementation. Finally, we
present empirical results to support our findings.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12293</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12294</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gradient Regularized Contrastive Learning for Continual Domain
  Adaptation</dc:title>
 <dc:creator>Tang, Shixiang</dc:creator>
 <dc:creator>Su, Peng</dc:creator>
 <dc:creator>Chen, Dapeng</dc:creator>
 <dc:creator>Ouyang, Wanli</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Human beings can quickly adapt to environmental changes by leveraging
learning experience. However, adapting deep neural networks to dynamic
environments by machine learning algorithms remains a challenge. To better
understand this issue, we study the problem of continual domain adaptation,
where the model is presented with a labelled source domain and a sequence of
unlabelled target domains. The obstacles in this problem are both domain shift
and catastrophic forgetting. We propose Gradient Regularized Contrastive
Learning (GRCL) to solve the obstacles. At the core of our method, gradient
regularization plays two key roles: (1) enforcing the gradient not to harm the
discriminative ability of source features which can, in turn, benefit the
adaptation ability of the model to target domains; (2) constraining the
gradient not to increase the classification loss on old target domains, which
enables the model to preserve the performance on old target domains when
adapting to an in-coming target domain. Experiments on Digits, DomainNet and
Office-Caltech benchmarks demonstrate the strong performance of our approach
when compared to the other state-of-the-art methods.
</dc:description>
 <dc:description>Comment: Accepted by AAAI2021 (poster). arXiv admin note: text overlap with
  arXiv:2007.12942</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12296</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reconfigurable Intelligent Surface-Assisted MAC for Wireless Networks:
  Protocol Design, Analysis, and Optimization</dc:title>
 <dc:creator>Cao, Xuelin</dc:creator>
 <dc:creator>Yang, Bo</dc:creator>
 <dc:creator>Zhang, Hongliang</dc:creator>
 <dc:creator>Huang, Chongwen</dc:creator>
 <dc:creator>Yuen, Chau</dc:creator>
 <dc:creator>Han, Zhu</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  Reconfigurable intelligent surface (RIS) is a promising reflective radio
technology for improving the coverage and rate of future wireless systems by
reconfiguring the wireless propagation environment. The current work mainly
focuses on the physical layer design of RIS. However, enabling multiple devices
to communicate with the assistance of RIS is a crucial challenging problem.
Motivated by this, we explore RIS-assisted communications at the medium access
control (MAC) layer and propose an RIS-assisted MAC framework. In particular,
RISassisted transmissions are implemented by pre-negotiation and a
multi-dimension reservation (MDR) scheme. Based on this, we investigate
RIS-assisted single-channel multi-user (SCMU) communications. Wherein the RIS
regarded as a whole unity can be reserved by one user to support the multiple
data transmissions, thus achieving high efficient RIS-assisted connections at
the user. Moreover, under frequency-selective channels, implementing the MDR
scheme on the RIS group division, RISassisted multi-channel multi-user (MCMU)
communications are further explored to improve the service efficiency of the
RIS and decrease the computation complexity. Besides, a Markov chain is built
based on the proposed RIS-assisted MAC framework to analyze the system
performance of SCMU/MCMU. Then the optimization problem is formulated to
maximize the overall system capacity of SCMU/MCMU with energy-efficient
constraint. The performance evaluations demonstrate the feasibility and
effectiveness of each
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12296</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12298</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting Dockerfiles in Open Source Software Over Time</dc:title>
 <dc:creator>Eng, Kalvin</dc:creator>
 <dc:creator>Hindle, Abram</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Docker is becoming ubiquitous with containerization for developing and
deploying applications. Previous studies have analyzed Dockerfiles that are
used to create container images in order to better understand how to improve
Docker tooling. These studies obtain Dockerfiles using either Docker Hub or
Github. In this paper, we revisit the findings of previous studies using the
largest set of Dockerfiles known to date with over 9.4 million unique
Dockerfiles found in the World of Code infrastructure spanning from 2013-2020.
We contribute a historical view of the Dockerfile format by analyzing the
Docker engine changelogs and use the history to enhance our analysis of
Dockerfiles. We also reconfirm previous findings of a downward trend in using
OS images and an upward trend of using language images. As well, we reconfirm
that Dockerfile smell counts are slightly decreasing meaning that Dockerfile
authors are likely getting better at following best practices. Based on these
findings, it indicates that previous analyses from prior works have been
correct in many of their findings and their suggestions to build better tools
for Docker image creation are further substantiated.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12298</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12300</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Drop-Bottleneck: Learning Discrete Compressed Representation for
  Noise-Robust Exploration</dc:title>
 <dc:creator>Kim, Jaekyeom</dc:creator>
 <dc:creator>Kim, Minjung</dc:creator>
 <dc:creator>Woo, Dongyeon</dc:creator>
 <dc:creator>Kim, Gunhee</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We propose a novel information bottleneck (IB) method named Drop-Bottleneck,
which discretely drops features that are irrelevant to the target variable.
Drop-Bottleneck not only enjoys a simple and tractable compression objective
but also additionally provides a deterministic compressed representation of the
input variable, which is useful for inference tasks that require consistent
representation. Moreover, it can jointly learn a feature extractor and select
features considering each feature dimension's relevance to the target task,
which is unattainable by most neural network-based IB methods. We propose an
exploration method based on Drop-Bottleneck for reinforcement learning tasks.
In a multitude of noisy and reward sparse maze navigation tasks in VizDoom
(Kempka et al., 2016) and DMLab (Beattie et al., 2016), our exploration method
achieves state-of-the-art performance. As a new IB framework, we demonstrate
that Drop-Bottleneck outperforms Variational Information Bottleneck (VIB)
(Alemi et al., 2017) in multiple aspects including adversarial robustness and
dimensionality reduction.
</dc:description>
 <dc:description>Comment: Accepted to ICLR 2021. Code at http://vision.snu.ac.kr/projects/db</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12300</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12304</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracing Vulnerable Code Lineage</dc:title>
 <dc:creator>Reid, David</dc:creator>
 <dc:creator>Eng, Kalvin</dc:creator>
 <dc:creator>Bogart, Chris</dc:creator>
 <dc:creator>Tutko, Adam</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This paper presents results from the MSR 2021 Hackathon. Our team
investigates files/projects that contain known security vulnerabilities and how
widespread they are throughout repositories in open source software. These
security vulnerabilities can potentially be propagated through code reuse even
when the vulnerability is fixed in different versions of the code. We utilize
the World of Code infrastructure to discover file-level duplication of code
from a nearly complete collection of open source software. This paper describes
a method and set of tools to find all open source projects that use known
vulnerable files and any previous revisions of those files.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12304</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12308</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IAIA-BL: A Case-based Interpretable Deep Learning Model for
  Classification of Mass Lesions in Digital Mammography</dc:title>
 <dc:creator>Barnett, Alina Jade</dc:creator>
 <dc:creator>Schwartz, Fides Regina</dc:creator>
 <dc:creator>Tao, Chaofan</dc:creator>
 <dc:creator>Chen, Chaofan</dc:creator>
 <dc:creator>Ren, Yinhao</dc:creator>
 <dc:creator>Lo, Joseph Y.</dc:creator>
 <dc:creator>Rudin, Cynthia</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.4.9</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:description>  Interpretability in machine learning models is important in high-stakes
decisions, such as whether to order a biopsy based on a mammographic exam.
Mammography poses important challenges that are not present in other computer
vision tasks: datasets are small, confounding information is present, and it
can be difficult even for a radiologist to decide between watchful waiting and
biopsy based on a mammogram alone. In this work, we present a framework for
interpretable machine learning-based mammography. In addition to predicting
whether a lesion is malignant or benign, our work aims to follow the reasoning
processes of radiologists in detecting clinically relevant semantic features of
each image, such as the characteristics of the mass margins. The framework
includes a novel interpretable neural network algorithm that uses case-based
reasoning for mammography. Our algorithm can incorporate a combination of data
with whole image labelling and data with pixel-wise annotations, leading to
better accuracy and interpretability even with a small number of images. Our
interpretable models are able to highlight the classification-relevant parts of
the image, whereas other methods highlight healthy tissue and confounding
information. Our models are decision aids, rather than decision makers, aimed
at better overall human-machine collaboration. We do not observe a loss in mass
margin classification accuracy over a black box neural network trained on the
same data.
</dc:description>
 <dc:description>Comment: 24 pages, 5 figures, 2 tables</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12312</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TMR: Evaluating NER Recall on Tough Mentions</dc:title>
 <dc:creator>Tu, Jingxuan</dc:creator>
 <dc:creator>Lignos, Constantine</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We propose the Tough Mentions Recall (TMR) metrics to supplement traditional
named entity recognition (NER) evaluation by examining recall on specific
subsets of &quot;tough&quot; mentions: unseen mentions, those whose tokens or token/type
combination were not observed in training, and type-confusable mentions, token
sequences with multiple entity types in the test data. We demonstrate the
usefulness of these metrics by evaluating corpora of English, Spanish, and
Dutch using five recent neural architectures. We identify subtle differences
between the performance of BERT and Flair on two English NER corpora and
identify a weak spot in the performance of current models in Spanish. We
conclude that the TMR metrics enable differentiation between otherwise
similar-scoring systems and identification of patterns in performance that
would go unnoticed from overall precision, recall, and F1.
</dc:description>
 <dc:description>Comment: To appear in the 2021 EACL Student Research Workshop (SRW)</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12312</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12317</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HADAD: A Lightweight Approach for Optimizing Hybrid Complex Analytics
  Queries (Extended Version)</dc:title>
 <dc:creator>Alotaibi, Rana</dc:creator>
 <dc:creator>Cautis, Bogdan</dc:creator>
 <dc:creator>Deutsch, Alin</dc:creator>
 <dc:creator>Manolescu, Ioana</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Hybrid complex analytics workloads typically include (i) data management
tasks (joins, selections, etc. ), easily expressed using relational algebra
(RA)-based languages, and (ii) complex analytics tasks (regressions, matrix
decompositions, etc.), mostly expressed in linear algebra (LA) expressions.
Such workloads are common in many application areas, including scientific
computing, web analytics, and business recommendation. Existing solutions for
evaluating hybrid analytical tasks - ranging from LA-oriented systems, to
relational systems (extended to handle LA operations), to hybrid systems -
either optimize data management and complex tasks separately, exploit RA
properties only while leaving LA-specific optimization opportunities
unexploited, or focus heavily on physical optimization, leaving semantic query
optimization opportunities unexplored. Additionally, they are not able to
exploit precomputed (materialized) results to avoid recomputing (part of) a
given mixed (RA and/or LA) computation. In this paper, we take a major step
towards filling this gap by proposing HADAD, an extensible lightweight approach
for optimizing hybrid complex analytics queries, based on a common abstraction
that facilitates unified reasoning: a relational model endowed with integrity
constraints. Our solution can be naturally and portably applied on top of pure
LA and hybrid RA-LA platforms without modifying their internals. An extensive
empirical evaluation shows that HADAD yields significant performance gains on
diverse workloads, ranging from LA-centered to hybrid.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12321</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning 6DoF Grasping Using Reward-Consistent Demonstration</dc:title>
 <dc:creator>Kawakami, Daichi</dc:creator>
 <dc:creator>Ishikawa, Ryoichi</dc:creator>
 <dc:creator>Roxas, Menandro</dc:creator>
 <dc:creator>Sato, Yoshihiro</dc:creator>
 <dc:creator>Oishi, Takeshi</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  As the number of the robot's degrees of freedom increases, the implementation
of robot motion becomes more complex and difficult. In this study, we focus on
learning 6DOF-grasping motion and consider dividing the grasping motion into
multiple tasks. We propose to combine imitation and reinforcement learning in
order to facilitate a more efficient learning of the desired motion. In order
to collect demonstration data as teacher data for the imitation learning, we
created a virtual reality (VR) interface that allows humans to operate the
robot intuitively. Moreover, by dividing the motion into simpler tasks, we
simplify the design of reward functions for reinforcement learning and show in
our experiments a reduction in the steps required to learn the grasping motion.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12322</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extracting Causal Visual Features for Limited label Classification</dc:title>
 <dc:creator>Prabhushankar, Mohit</dc:creator>
 <dc:creator>AlRegib, Ghassan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Neural networks trained to classify images do so by identifying features that
allow them to distinguish between classes. These sets of features are either
causal or context dependent. Grad-CAM is a popular method of visualizing both
sets of features. In this paper, we formalize this feature divide and provide a
methodology to extract causal features from Grad-CAM. We do so by defining
context features as those features that allow contrast between predicted class
and any contrast class. We then apply a set theoretic approach to separate
causal from contrast features for COVID-19 CT scans. We show that on average,
the image regions with the proposed causal features require 15% less bits when
encoded using Huffman encoding, compared to Grad-CAM, for an average increase
of 3% classification accuracy, over Grad-CAM. Moreover, we validate the
transfer-ability of causal features between networks and comment on the
non-human interpretable causal nature of current networks.
</dc:description>
 <dc:description>Comment: Submitted to IEEE International Conference on Image Processing (ICIP)</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12322</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12324</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A machine-learning approach to synthesize virtual sensors for
  parameter-varying systems</dc:title>
 <dc:creator>Masti, Daniele</dc:creator>
 <dc:creator>Bernardini, Daniele</dc:creator>
 <dc:creator>Bemporad, Alberto</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper introduces a novel model-free approach to synthesize virtual
sensors for the estimation of dynamical quantities that are unmeasurable at
runtime but are available for design purposes on test benches. After collecting
a dataset of measurements of such quantities, together with other variables
that are also available during on-line operations, the virtual sensor is
obtained using machine learning techniques by training a predictor whose inputs
are the measured variables and the features extracted by a bank of linear
observers fed with the same measures. The approach is applicable to infer the
value of quantities such as physical states and other time-varying parameters
that affect the dynamics of the system. The proposed virtual sensor
architecture - whose structure can be related to the Multiple Model Adaptive
Estimation framework - is conceived to keep computational and memory
requirements as low as possible, so that it can be efficiently implemented in
embedded hardware platforms.
  The effectiveness of the approach is shown in different numerical examples,
involving the estimation of the scheduling parameter of a nonlinear
parameter-varying system, the reconstruction of the mode of a switching linear
system, and the estimation of the state of charge (SoC) of a lithium-ion
battery.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12324</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12326</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Security of Healthcare Data Using Blockchains: A Survey</dc:title>
 <dc:creator>Pandey, Mayank</dc:creator>
 <dc:creator>Agarwal, Rachit</dc:creator>
 <dc:creator>Shukla, Sandeep K.</dc:creator>
 <dc:creator>Verma, Nishchal K.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The advancement in the healthcare sector is entering into a new era in the
form of Health 4.0. The integration of innovative technologies like
Cyber-Physical Systems (CPS), Big Data, Cloud Computing, Machine Learning, and
Blockchain with Healthcare services has led to improved performance and
efficiency through data-based learning and interconnection of systems. On the
other hand, it has also increased complexities and has brought its own share of
vulnerabilities due to the heavy influx, sharing, and storage of healthcare
data. The protection of the same from cyber-attacks along with privacy
preservation through authenticated access is one of the significant challenges
for the healthcare sector. For this purpose, the use of blockchain-based
networks can lead to a considerable reduction in the vulnerabilities of the
healthcare systems and secure their data. This chapter explores blockchain's
role in strengthening healthcare data security by answering the questions
related to what data use, when we need, why we need, who needs, and how
state-of-the-art techniques use blockchains to secure healthcare data. As a
case study, we also explore and analyze the state-of-the-art implementations
for blockchain in healthcare data security for the COVID-19 pandemic. In order
to provide a path to future research directions, we identify and discuss the
technical limitations and regulatory challenges associated with
blockchain-based healthcare data security implementation.
</dc:description>
 <dc:description>Comment: Submitted as a book chapter</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12326</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12327</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Fractional-Order Sliding Mode Controller with Neural Network
  Compensator for an Ultrasonic Motor</dc:title>
 <dc:creator>Chen, Xiaolong</dc:creator>
 <dc:creator>Liang, Wenyu</dc:creator>
 <dc:creator>Zhao, Han</dc:creator>
 <dc:creator>Mamun, Abdullah Al</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Ultrasonic motors (USMs) are commonly used in aerospace, robotics, and
medical devices, where fast and precise motion is needed. Remarkably, sliding
mode controller (SMC) is an effective controller to achieve precision motion
control of the USMs. To improve the tracking accuracy and lower the chattering
in the SMC, the fractional-order calculus is introduced in the design of an
adaptive SMC in this paper, namely, adaptive fractional-order SMC (AFOSMC), in
which the bound of the uncertainty existing in the USMs is estimated by a
designed adaptive law. Additionally, a short memory principle is employed to
overcome the difficulty of implementing the fractional-order calculus on a
practical system in real-time. Here, the short memory principle may increase
the tracking errors because some information is lost during its operation.
Thus, a compensator according to the framework of Bellman's optimal control
theory is proposed so that the residual errors caused by the short memory
principle can be attenuated. Lastly, experiments on a USM are conducted, which
comparative results verify the performance of the designed controller.
</dc:description>
 <dc:description>Comment: 9 pages, 9 figures</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12327</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12328</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decomposing Normal and Abnormal Features of Medical Images into Discrete
  Latent Codes for Content-Based Image Retrieval</dc:title>
 <dc:creator>Kobayashi, Kazuma</dc:creator>
 <dc:creator>Hataya, Ryuichiro</dc:creator>
 <dc:creator>Kurose, Yusuke</dc:creator>
 <dc:creator>Miyake, Mototaka</dc:creator>
 <dc:creator>Takahashi, Masamichi</dc:creator>
 <dc:creator>Nakagawa, Akiko</dc:creator>
 <dc:creator>Harada, Tatsuya</dc:creator>
 <dc:creator>Hamamoto, Ryuji</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In medical imaging, the characteristics purely derived from a disease should
reflect the extent to which abnormal findings deviate from the normal features.
Indeed, physicians often need corresponding images without abnormal findings of
interest or, conversely, images that contain similar abnormal findings
regardless of normal anatomical context. This is called comparative diagnostic
reading of medical images, which is essential for a correct diagnosis. To
support comparative diagnostic reading, content-based image retrieval (CBIR),
which can selectively utilize normal and abnormal features in medical images as
two separable semantic components, will be useful. Therefore, we propose a
neural network architecture to decompose the semantic components of medical
images into two latent codes: normal anatomy code and abnormal anatomy code.
The normal anatomy code represents normal anatomies that should have existed if
the sample is healthy, whereas the abnormal anatomy code attributes to abnormal
changes that reflect deviation from the normal baseline. These latent codes are
discretized through vector quantization to enable binary hashing, which can
reduce the computational burden at the time of similarity search. By
calculating the similarity based on either normal or abnormal anatomy codes or
the combination of the two codes, our algorithm can retrieve images according
to the selected semantic component from a dataset consisting of brain magnetic
resonance images of gliomas. Our CBIR system qualitatively and quantitatively
achieves remarkable results.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12328</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12329</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contrastive Reasoning in Neural Networks</dc:title>
 <dc:creator>Prabhushankar, Mohit</dc:creator>
 <dc:creator>AlRegib, Ghassan</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Neural networks represent data as projections on trained weights in a high
dimensional manifold. The trained weights act as a knowledge base consisting of
causal class dependencies. Inference built on features that identify these
dependencies is termed as feed-forward inference. Such inference mechanisms are
justified based on classical cause-to-effect inductive reasoning models.
Inductive reasoning based feed-forward inference is widely used due to its
mathematical simplicity and operational ease. Nevertheless, feed-forward models
do not generalize well to untrained situations. To alleviate this
generalization challenge, we propose using an effect-to-cause inference model
that reasons abductively. Here, the features represent the change from existing
weight dependencies given a certain effect. We term this change as contrast and
the ensuing reasoning mechanism as contrastive reasoning. In this paper, we
formalize the structure of contrastive reasoning and propose a methodology to
extract a neural network's notion of contrast. We demonstrate the value of
contrastive reasoning in two stages of a neural network's reasoning pipeline :
in inferring and visually explaining decisions for the application of object
recognition. We illustrate the value of contrastively recognizing images under
distortions by reporting an improvement of 3.47%, 2.56%, and 5.48% in average
accuracy under the proposed contrastive framework on CIFAR-10C, noisy STL-10,
and VisDA datasets respectively.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Pattern Analysis and Machine
  Intelligence</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12334</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Taming Time-Varying Information Asymmetry in Fresh Status Acquisition</dc:title>
 <dc:creator>Wang, Zhiyuan</dc:creator>
 <dc:creator>Gao, Lin</dc:creator>
 <dc:creator>Huang, Jianwei</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Many online platforms are providing valuable real-time contents (e.g.,
traffic) by continuously acquiring the status of different Points of Interest
(PoIs). In status acquisition, it is challenging to determine how frequently a
PoI should upload its status to a platform, since they are self-interested with
private and possibly time-varying preferences. This paper considers a general
multi-period status acquisition system, aiming to maximize the aggregate social
welfare and ensure the platform freshness. The freshness is measured by a
metric termed age of information. For this goal, we devise a long-term
decomposition (LtD) mechanism to resolve the time-varying information
asymmetry. The key idea is to construct a virtual social welfare that only
depends on the current private information, and then decompose the per-period
operation into multiple distributed bidding problems for the PoIs and
platforms. The LtD mechanism enables the platforms to achieve a tunable
trade-off between payoff maximization and freshness conditions. Moreover, the
LtD mechanism retains the same social performance compared to the benchmark
with symmetric information and asymptotically ensures the platform freshness
conditions. Numerical results based on real-world data show that when the
platforms pay more attention to payoff maximization, each PoI still obtains a
non-negative payoff in the long-term.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12334</dc:identifier>
 <dc:identifier>IEEE INFOCOM 2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12335</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model Based Control of Commercial-Off-TheShelf (COTS) Unmanned
  Rotorcraft for BrickWall Construction</dc:title>
 <dc:creator>Sridhar, Nithya</dc:creator>
 <dc:creator>N, Sai Abhinay.</dc:creator>
 <dc:creator>B, Chaithanya Krishna.</dc:creator>
 <dc:creator>Shobhit, Shubhankar</dc:creator>
 <dc:creator>Das, Kaushik</dc:creator>
 <dc:creator>Ghose, Debasish</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This work proposes a systematic framework for modelling and controller design
of a Commercial-Off-The Shelf (COTS) unmanned rotorcraft using control theory
and principles, for brick wall construction. With point to point navigation as
the primary application, command velocities in the three axes of the Unmanned
Aerial Vehicle (UAV) are considered as inputs of the system while its actual
velocities are system outputs. Using the sine and step response data acquired
from a Hardware-in-Loop (HiL) test simulator, the considered system was
modelled in individual axes with the help of the proposed framework. This model
was employed for controller design where a sliding mode controller was chosen
to satisfy certain requirements of the application like robustness, flexibility
and accuracy. The model was validated using step response data and produced a
deviation of only 9%. Finally, the controller results from field test showed
fine control up to 8 cms accuracy. Sliding Mode Control (SMC) was also compared
with a linear controller derived from iterative experimentations and seen to
perform better than the latter in terms of accuracy, and robustness to
parametric variations and wind disturbances.
</dc:description>
 <dc:description>Comment: MBZIRC Symposium 2020</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12335</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12337</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Salient Image Matting</dc:title>
 <dc:creator>Deora, Rahul</dc:creator>
 <dc:creator>Sharma, Rishab</dc:creator>
 <dc:creator>Raj, Dinesh Samuel Sathia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose an image matting framework called Salient Image
Matting to estimate the per-pixel opacity value of the most salient foreground
in an image. To deal with a large amount of semantic diversity in images, a
trimap is conventionally required as it provides important guidance about
object semantics to the matting process. However, creating a good trimap is
often expensive and timeconsuming. The SIM framework simultaneously deals with
the challenge of learning a wide range of semantics and salient object types in
a fully automatic and an end to end manner. Specifically, our framework is able
to produce accurate alpha mattes for a wide range of foreground objects and
cases where the foreground class, such as human, appears in a very different
context than the train data directly from an RGB input. This is done by
employing a salient object detection model to produce a trimap of the most
salient object in the image in order to guide the matting model about
higher-level object semantics. Our framework leverages large amounts of coarse
annotations coupled with a heuristic trimap generation scheme to train the
trimap prediction network so it can produce trimaps for arbitrary foregrounds.
Moreover, we introduce a multi-scale fusion architecture for the task of
matting to better capture finer, low-level opacity semantics. With high-level
guidance provided by the trimap network, our framework requires only a fraction
of expensive matting data as compared to other automatic methods while being
able to produce alpha mattes for a diverse range of inputs. We demonstrate our
framework on a range of diverse images and experimental results show our
framework compares favourably against state of art matting methods without the
need for a trimap
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12337</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12338</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consistency Analysis of the Closed-loop SRIVC Estimator</dc:title>
 <dc:creator>Pan, Siqi</dc:creator>
 <dc:creator>Welsh, James S.</dc:creator>
 <dc:creator>Gonzalez, Rodrigo A.</dc:creator>
 <dc:creator>Rojas, Cristian R.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  The Consistency of the Closed-Loop Simplified Refined Instrumental Variable
method for Continuous-time system (CLSRIVC) is analysed based on sampled data.
It is proven that the CLSRIVC estimator is not consistent when a
continuous-time controller is used in the closed-loop.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12339</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Domain Conditioned Adaptation Network</dc:title>
 <dc:creator>Li, Shuang</dc:creator>
 <dc:creator>Xie, Binhui</dc:creator>
 <dc:creator>Lin, Qiuxia</dc:creator>
 <dc:creator>Liu, Chi Harold</dc:creator>
 <dc:creator>Huang, Gao</dc:creator>
 <dc:creator>Wang, Guoren</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Domain Adaptation (DA) attempts to transfer knowledge learned in the labeled
source domain to the unlabeled but related target domain without requiring
large amounts of target supervision. Recent advances in DA mainly proceed by
aligning the source and target distributions. Despite the significant success,
the adaptation performance still degrades accordingly when the source and
target domains encounter a large distribution discrepancy. We consider this
limitation may attribute to the insufficient exploration of domain-specialized
features because most studies merely concentrate on domain-general feature
learning in task-specific layers and integrate totally-shared convolutional
networks (convnets) to generate common features for both domains. In this
paper, we relax the completely-shared convnets assumption adopted by previous
DA methods and propose Domain Conditioned Adaptation Network (DCAN), which
introduces domain conditioned channel attention module with a multi-path
structure to separately excite channel activation for each domain. Such a
partially-shared convnets module allows domain-specialized features in
low-level to be explored appropriately. Further, given the knowledge
transferability varying along with convolutional layers, we develop Generalized
Domain Conditioned Adaptation Network (GDCAN) to automatically determine
whether domain channel activations should be separately modeled in each
attention module. Afterward, the critical domain-specialized knowledge could be
adaptively extracted according to the domain statistic gaps. As far as we know,
this is the first work to explore the domain-wise convolutional channel
activations separately for deep DA networks. Additionally, to effectively match
high-level feature distributions across domains, we consider deploying feature
adaptation blocks after task-specific layers, which can explicitly mitigate the
domain discrepancy.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Transactions on Pattern Analysis and Machine
  Intelligence (T-PAMI). Journal version of arXiv:2005.06717 (AAAI 2020). Code
  is available at https://github.com/BIT-DA/GDCAN</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12339</dc:identifier>
 <dc:identifier>doi:10.1109/TPAMI.2021.3062644</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12340</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Occlusion-Aware Instance Segmentation with Overlapping BiLayers</dc:title>
 <dc:creator>Ke, Lei</dc:creator>
 <dc:creator>Tai, Yu-Wing</dc:creator>
 <dc:creator>Tang, Chi-Keung</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Segmenting highly-overlapping objects is challenging, because typically no
distinction is made between real object contours and occlusion boundaries.
Unlike previous two-stage instance segmentation methods, we model image
formation as composition of two overlapping layers, and propose Bilayer
Convolutional Network (BCNet), where the top GCN layer detects the occluding
objects (occluder) and the bottom GCN layer infers partially occluded instance
(occludee). The explicit modeling of occlusion relationship with bilayer
structure naturally decouples the boundaries of both the occluding and occluded
instances, and considers the interaction between them during mask regression.
We validate the efficacy of bilayer decoupling on both one-stage and two-stage
object detectors with different backbones and network layer choices. Despite
its simplicity, extensive experiments on COCO and KINS show that our
occlusion-aware BCNet achieves large and consistent performance gain especially
for heavy occlusion cases. Code is available at https://github.com/lkeab/BCNet.
</dc:description>
 <dc:description>Comment: Accepted by CVPR2021. BCNet Code: https://github.com/lkeab/BCNet</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12345</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Success of AdaBoost and Its Application in Portfolio Management</dc:title>
 <dc:creator>Chuan, Yijian</dc:creator>
 <dc:creator>Zhao, Chaoyi</dc:creator>
 <dc:creator>He, Zhenrui</dc:creator>
 <dc:creator>Wu, Lan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Quantitative Finance - Portfolio Management</dc:subject>
 <dc:description>  We develop a novel approach to explain why AdaBoost is a successful
classifier. By introducing a measure of the influence of the noise points (ION)
in the training data for the binary classification problem, we prove that there
is a strong connection between the ION and the test error. We further identify
that the ION of AdaBoost decreases as the iteration number or the complexity of
the base learners increases. We confirm that it is impossible to obtain a
consistent classifier without deep trees as the base learners of AdaBoost in
some complicated situations. We apply AdaBoost in portfolio management via
empirical studies in the Chinese market, which corroborates our theoretical
propositions.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12346</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Co-Grounding Networks with Semantic Attention for Referring Expression
  Comprehension in Videos</dc:title>
 <dc:creator>Song, Sijie</dc:creator>
 <dc:creator>Lin, Xudong</dc:creator>
 <dc:creator>Liu, Jiaying</dc:creator>
 <dc:creator>Guo, Zongming</dc:creator>
 <dc:creator>Chang, Shih-Fu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we address the problem of referring expression comprehension
in videos, which is challenging due to complex expression and scene dynamics.
Unlike previous methods which solve the problem in multiple stages (i.e.,
tracking, proposal-based matching), we tackle the problem from a novel
perspective, \textbf{co-grounding}, with an elegant one-stage framework. We
enhance the single-frame grounding accuracy by semantic attention learning and
improve the cross-frame grounding consistency with co-grounding feature
learning. Semantic attention learning explicitly parses referring cues in
different attributes to reduce the ambiguity in the complex expression.
Co-grounding feature learning boosts visual feature representations by
integrating temporal correlation to reduce the ambiguity caused by scene
dynamics. Experiment results demonstrate the superiority of our framework on
the video grounding datasets VID and LiOTB in generating accurate and stable
results across frames. Our model is also applicable to referring expression
comprehension in images, illustrated by the improved performance on the RefCOCO
dataset. Our project is available at https://sijiesong.github.io/co-grounding.
</dc:description>
 <dc:description>Comment: Accepted to CVPR2021. The project page is at
  https://sijiesong.github.io/co-grounding</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12346</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12350</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Roughness Index and Roughness Distance for Benchmarking Medical
  Segmentation</dc:title>
 <dc:creator>Rathour, Vidhiwar Singh</dc:creator>
 <dc:creator>Yamakazi, Kashu</dc:creator>
 <dc:creator>Le, T. Hoang Ngan</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Medical image segmentation is one of the most challenging tasks in medical
image analysis and has been widely developed for many clinical applications.
Most of the existing metrics have been first designed for natural images and
then extended to medical images. While object surface plays an important role
in medical segmentation and quantitative analysis i.e. analyze brain tumor
surface, measure gray matter volume, most of the existing metrics are limited
when it comes to analyzing the object surface, especially to tell about surface
smoothness or roughness of a given volumetric object or to analyze the
topological errors. In this paper, we first analysis both pros and cons of all
existing medical image segmentation metrics, specially on volumetric data. We
then propose an appropriate roughness index and roughness distance for medical
image segmentation analysis and evaluation. Our proposed method addresses two
kinds of segmentation errors, i.e. (i)topological errors on boundary/surface
and (ii)irregularities on the boundary/surface. The contribution of this work
is four-fold: (i) detect irregular spikes/holes on a surface, (ii) propose
roughness index to measure surface roughness of a given object, (iii) propose a
roughness distance to measure the distance of two boundaries/surfaces by
utilizing the proposed roughness index and (iv) suggest an algorithm which
helps to remove the irregular spikes/holes to smooth the surface. Our proposed
roughness index and roughness distance are built upon the solid surface
roughness parameter which has been successfully developed in the civil
engineering.
</dc:description>
 <dc:description>Comment: Paper has been accepted at BIOIMAGING2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12351</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple Robust MPC for Linear Systems with Parametric and Additive
  Uncertainty</dc:title>
 <dc:creator>Bujarbaruah, Monimoy</dc:creator>
 <dc:creator>Rosolia, Ugo</dc:creator>
 <dc:creator>St&#xfc;rz, Yvonne R.</dc:creator>
 <dc:creator>Borrelli, Francesco</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  We propose a simple and computationally efficient approach for designing a
robust Model Predictive Controller (MPC) for constrained uncertain linear
systems. The uncertainty is modeled as an additive disturbance and an additive
error on the system dynamics matrices. Set based bounds for each component of
the model uncertainty are assumed to be known. We separate the constraint
tightening strategy into two parts, depending on the length of the MPC horizon.
For a horizon length of one, the robust MPC problem is solved exactly, whereas
for other horizon lengths, the model uncertainty is over-approximated with a
net-additive component. The resulting MPC controller guarantees robust
satisfaction of state and input constraints in closed-loop with the uncertain
system. With appropriately designed terminal components and an adaptive horizon
strategy, we prove the controller's recursive feasibility and stability of the
origin. With numerical simulations, we demonstrate that our proposed approach
gains up to 15x online computation speedup over a tube MPC strategy, while
stabilizing about 98$\%$ of the latter's region of attraction.
</dc:description>
 <dc:description>Comment: Final version for IEEE American Control Conference (ACC), May 2021.
  arXiv admin note: text overlap with arXiv:2007.00930</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12351</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12357</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unleashing the Hidden Power of Compiler Optimization on Binary Code
  Difference: An Empirical Study</dc:title>
 <dc:creator>Ren, Xiaolei</dc:creator>
 <dc:creator>Ho, Michael</dc:creator>
 <dc:creator>Ming, Jiang</dc:creator>
 <dc:creator>Lei, Yu</dc:creator>
 <dc:creator>Li, Li</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Since compiler optimization is the most common source contributing to binary
code differences in syntax, testing the resilience against the changes caused
by different compiler optimization settings has become a standard evaluation
step for most binary diffing approaches. For example, 47 top-venue papers in
the last 12 years compared different program versions compiled by default
optimization levels (e.g., -Ox in GCC and LLVM). Although many of them claim
they are immune to compiler transformations, it is yet unclear about their
resistance to non-default optimization settings. Especially, we have observed
that adversaries explored non-default compiler settings to amplify malware
differences.
  This paper takes the first step to systematically studying the effectiveness
of compiler optimization on binary code differences. We tailor search-based
iterative compilation for the auto-tuning of binary code differences. We
develop BinTuner to search near-optimal optimization sequences that can
maximize the amount of binary code differences. We run BinTuner with GCC 10.2
and LLVM 11.0 on SPEC benchmarks (CPU2006 &amp; CPU2017), Coreutils, and OpenSSL.
Our experiments show that at the cost of 279 to 1,881 compilation iterations,
BinTuner can find custom optimization sequences that are substantially better
than the general -Ox settings. BinTuner's outputs seriously undermine prominent
binary diffing tools' comparisons. In addition, the detection rate of the IoT
malware variants tuned by BinTuner falls by more than 50%. Our findings paint a
cautionary tale for security analysts that attackers have a new way to mutate
malware code cost-effectively, and the research community needs to step back to
reassess optimization-resistance evaluations.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12362</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Sub-Layered Hierarchical Pyramidal Neural Architecture for Facial
  Expression Recognition</dc:title>
 <dc:creator>Siqueira, Henrique</dc:creator>
 <dc:creator>Barros, Pablo</dc:creator>
 <dc:creator>Magg, Sven</dc:creator>
 <dc:creator>Weber, Cornelius</dc:creator>
 <dc:creator>Wermter, Stefan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In domains where computational resources and labeled data are limited, such
as in robotics, deep networks with millions of weights might not be the optimal
solution. In this paper, we introduce a connectivity scheme for pyramidal
architectures to increase their capacity for learning features. Experiments on
facial expression recognition of unseen people demonstrate that our approach is
a potential candidate for applications with restricted resources, due to good
generalization performance and low computational cost. We show that our
approach generalizes as well as convolutional architectures in this task but
uses fewer trainable parameters and is more robust for low-resolution faces.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12362</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12365</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Risk Analysis and Policy Enforcement of Function Interactions in Robot
  Apps</dc:title>
 <dc:creator>Xu, Yuan</dc:creator>
 <dc:creator>Zhang, Tianwei</dc:creator>
 <dc:creator>Bao, Yungang</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Robot apps are becoming more automated, complex and diverse. An app usually
consists of many functions, interacting with each other and the environment.
This allows robots to conduct various tasks. However, it also opens a new door
for cyber attacks: adversaries can leverage these interactions to threaten the
safety of robot operations. Unfortunately, this issue is rarely explored in
past works.
  We present the first systematic investigation about the function interactions
in common robot apps. First, we disclose the potential risks and damages caused
by malicious interactions. We introduce a comprehensive graph to model the
function interactions in robot apps by analyzing 3,100 packages from the Robot
Operating System (ROS) platform. From this graph, we identify and categorize
three types of interaction risks. Second, we propose RTron, a novel system to
detect and mitigate these risks and protect the operations of robot apps. We
introduce security policies for each type of risks, and design coordination
nodes to enforce the policies and regulate the interactions. We conduct
extensive experiments on 110 robot apps from the ROS platform and two complex
apps (Baidu Apollo and Autoware) widely adopted in industry. Evaluation results
indicated RTron can correctly identify and mitigate all potential risks with
negligible performance cost. To validate the practicality of the risks and
solutions, we implement and evaluate RTron on a physical UGV (Turtlebot) with
real-word apps and environments.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12365</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12366</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Group-aware Label Transfer for Domain Adaptive Person Re-identification</dc:title>
 <dc:creator>Zheng, Kecheng</dc:creator>
 <dc:creator>Liu, Wu</dc:creator>
 <dc:creator>He, Lingxiao</dc:creator>
 <dc:creator>Mei, Tao</dc:creator>
 <dc:creator>Luo, Jiebo</dc:creator>
 <dc:creator>Zha, Zheng-Jun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Unsupervised Domain Adaptive (UDA) person re-identification (ReID) aims at
adapting the model trained on a labeled source-domain dataset to a
target-domain dataset without any further annotations. Most successful UDA-ReID
approaches combine clustering-based pseudo-label prediction with representation
learning and perform the two steps in an alternating fashion. However, offline
interaction between these two steps may allow noisy pseudo labels to
substantially hinder the capability of the model. In this paper, we propose a
Group-aware Label Transfer (GLT) algorithm, which enables the online
interaction and mutual promotion of pseudo-label prediction and representation
learning. Specifically, a label transfer algorithm simultaneously uses pseudo
labels to train the data while refining the pseudo labels as an online
clustering algorithm. It treats the online label refinery problem as an optimal
transport problem, which explores the minimum cost for assigning M samples to N
pseudo labels. More importantly, we introduce a group-aware strategy to assign
implicit attribute group IDs to samples. The combination of the online label
refining algorithm and the group-aware strategy can better correct the noisy
pseudo label in an online fashion and narrow down the search space of the
target identity. The effectiveness of the proposed GLT is demonstrated by the
experimental results (Rank-1 accuracy) for Market1501$\to$DukeMTMC (82.0\%) and
DukeMTMC$\to$Market1501 (92.2\%), remarkably closing the gap between
unsupervised and supervised performance on person re-identification.
</dc:description>
 <dc:description>Comment: Accepted by CVPR 2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12370</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Robot Task Allocation -- Complexity and Approximation</dc:title>
 <dc:creator>Aziz, Haris</dc:creator>
 <dc:creator>Chan, Hau</dc:creator>
 <dc:creator>Cseh, &#xc1;gnes</dc:creator>
 <dc:creator>Li, Bo</dc:creator>
 <dc:creator>Ramezani, Fahimeh</dc:creator>
 <dc:creator>Wang, Chenhao</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Multi-robot task allocation is one of the most fundamental classes of
problems in robotics and is crucial for various real-world robotic applications
such as search, rescue and area exploration. We consider the Single-Task robots
and Multi-Robot tasks Instantaneous Assignment (ST-MR-IA) setting where each
task requires at least a certain number of robots and each robot can work on at
most one task and incurs an operational cost for each task. Our aim is to
consider a natural computational problem of allocating robots to complete the
maximum number of tasks subject to budget constraints. We consider budget
constraints of three different kinds: (1) total budget, (2) task budget, and
(3) robot budget. We provide a detailed complexity analysis including results
on approximations as well as polynomial-time algorithms for the general setting
and important restricted settings.
</dc:description>
 <dc:description>Comment: AAMAS 2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12370</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12371</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised domain adaptation via coarse-to-fine feature alignment
  method using contrastive learning</dc:title>
 <dc:creator>Tang, Shiyu</dc:creator>
 <dc:creator>Tang, Peijun</dc:creator>
 <dc:creator>Gong, Yanxiang</dc:creator>
 <dc:creator>Ma, Zheng</dc:creator>
 <dc:creator>Xie, Mei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Previous feature alignment methods in Unsupervised domain adaptation(UDA)
mostly only align global features without considering the mismatch between
class-wise features. In this work, we propose a new coarse-to-fine feature
alignment method using contrastive learning called CFContra. It draws
class-wise features closer than coarse feature alignment or class-wise feature
alignment only, therefore improves the model's performance to a great extent.
We build it upon one of the most effective methods of UDA called entropy
minimization to further improve performance. In particular, to prevent
excessive memory occupation when applying contrastive loss in semantic
segmentation, we devise a new way to build and update the memory bank. In this
way, we make the algorithm more efficient and viable with limited memory.
Extensive experiments show the effectiveness of our method and model trained on
the GTA5 to Cityscapes dataset has boost mIOU by 3.5 compared to the MinEnt
algorithm. Our code will be publicly available.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12371</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12376</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalizing Face Forgery Detection with High-frequency Features</dc:title>
 <dc:creator>Luo, Yuchen</dc:creator>
 <dc:creator>Zhang, Yong</dc:creator>
 <dc:creator>Yan, Junchi</dc:creator>
 <dc:creator>Liu, Wei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Current face forgery detection methods achieve high accuracy under the
within-database scenario where training and testing forgeries are synthesized
by the same algorithm. However, few of them gain satisfying performance under
the cross-database scenario where training and testing forgeries are
synthesized by different algorithms. In this paper, we find that current
CNN-based detectors tend to overfit to method-specific color textures and thus
fail to generalize. Observing that image noises remove color textures and
expose discrepancies between authentic and tampered regions, we propose to
utilize the high-frequency noises for face forgery detection. We carefully
devise three functional modules to take full advantage of the high-frequency
features. The first is the multi-scale high-frequency feature extraction module
that extracts high-frequency noises at multiple scales and composes a novel
modality. The second is the residual-guided spatial attention module that
guides the low-level RGB feature extractor to concentrate more on forgery
traces from a new perspective. The last is the cross-modality attention module
that leverages the correlation between the two complementary modalities to
promote feature learning for each other. Comprehensive evaluations on several
benchmark databases corroborate the superior generalization performance of our
proposed method.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12376</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12377</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exercise? I thought you said 'Extra Fries': Leveraging Sentence
  Demarcations and Multi-hop Attention for Meme Affect Analysis</dc:title>
 <dc:creator>Pramanick, Shraman</dc:creator>
 <dc:creator>Akhtar, Md Shad</dc:creator>
 <dc:creator>Chakraborty, Tanmoy</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Today's Internet is awash in memes as they are humorous, satirical, or ironic
which make people laugh. According to a survey, 33% of social media users in
age bracket [13-35] send memes every day, whereas more than 50% send every
week. Some of these memes spread rapidly within a very short time-frame, and
their virality depends on the novelty of their (textual and visual) content. A
few of them convey positive messages, such as funny or motivational quotes;
while others are meant to mock/hurt someone's feelings through sarcastic or
offensive messages. Despite the appealing nature of memes and their rapid
emergence on social media, effective analysis of memes has not been adequately
attempted to the extent it deserves.
  In this paper, we attempt to solve the same set of tasks suggested in the
SemEval'20-Memotion Analysis competition. We propose a multi-hop
attention-based deep neural network framework, called MHA-MEME, whose prime
objective is to leverage the spatial-domain correspondence between the visual
modality (an image) and various textual segments to extract fine-grained
feature representations for classification. We evaluate MHA-MEME on the
'Memotion Analysis' dataset for all three sub-tasks - sentiment classification,
affect classification, and affect class quantification. Our comparative study
shows sota performances of MHA-MEME for all three tasks compared to the top
systems that participated in the competition. Unlike all the baselines which
perform inconsistently across all three tasks, MHA-MEME outperforms baselines
in all the tasks on average. Moreover, we validate the generalization of
MHA-MEME on another set of manually annotated test samples and observe it to be
consistent. Finally, we establish the interpretability of MHA-MEME.
</dc:description>
 <dc:description>Comment: Accepted for publication in ICWSM-2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12379</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Network Controller for Autonomous Pile Loading Revised</dc:title>
 <dc:creator>Yang, Wenyan</dc:creator>
 <dc:creator>Strokina, Nataliya</dc:creator>
 <dc:creator>Serbenyuk, Nikolay</dc:creator>
 <dc:creator>Pajarinen, Joni</dc:creator>
 <dc:creator>Ghabcheloo, Reza</dc:creator>
 <dc:creator>Vihonen, Juho</dc:creator>
 <dc:creator>Aref, Mohammad M.</dc:creator>
 <dc:creator>K&#xe4;m&#xe4;r&#xe4;inen, Joni-Kristian</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  We have recently proposed two pile loading controllers that learn from human
demonstrations: a neural network (NNet) [1] and a random forest (RF) controller
[2]. In the field experiments the RF controller obtained clearly better success
rates. In this work, the previous findings are drastically revised by
experimenting summer time trained controllers in winter conditions. The winter
experiments revealed a need for additional sensors, more training data, and a
controller that can take advantage of these. Therefore, we propose a revised
neural controller (NNetV2) which has a more expressive structure and uses a
neural attention mechanism to focus on important parts of the sensor and
control signals. Using the same data and sensors to train and test the three
controllers, NNetV2 achieves better robustness against drastically changing
conditions and superior success rate. To the best of our knowledge, this is the
first work testing a learning-based controller for a heavy-duty machine in
drastically varying outdoor conditions and delivering high success rate in
winter, being trained in summer.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12382</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rule-Based Safety-Critical Control Design using Control Barrier
  Functions with Application to Autonomous Lane Change</dc:title>
 <dc:creator>He, Suiyi</dc:creator>
 <dc:creator>Zeng, Jun</dc:creator>
 <dc:creator>Zhang, Bike</dc:creator>
 <dc:creator>Sreenath, Koushil</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper develops a new control design for guaranteeing a vehicle's safety
during lane change maneuvers in a complex traffic environment. The proposed
method uses a finite state machine (FSM), where a quadratic program based
optimization problem using control Lyapunov functions and control barrier
functions (CLF-CBF-QP) is used to calculate the system's optimal inputs via
rule-based control strategies. The FSM can make switches between different
states automatically according to the command of driver and traffic
environment, which makes the ego vehicle find a safe opportunity to do a
collision-free lane change maneuver. By using a convex quadratic program, the
controller can guarantee the system's safety at a high update frequency. A set
of pre-designed typical lane change scenarios as well as randomly generated
driving scenarios are simulated to show the performance of our controller.
</dc:description>
 <dc:description>Comment: Accepted to ACC 2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12382</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12386</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One- and multi-dimensional CWENOZ reconstructions for implementing
  boundary conditions without ghost cells</dc:title>
 <dc:creator>Semplice, M.</dc:creator>
 <dc:creator>Travaglia, E.</dc:creator>
 <dc:creator>Puppo, G.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65M08 76M12</dc:subject>
 <dc:description>  We address the issue of point value reconstructions from cell averages in the
context of third order finite volume schemes, focusing in particular on the
cells close to the boundaries of the domain. In fact, most techniques known in
the literature rely on the creation of ghost cells outside the boundary and on
some form of extrapolation from the inside that, taking into account the
boundary conditions, fills the ghost cells with appropriate values, so that a
standard reconstruction can be applied also in boundary cells. In (Naumann,
Kolb, Semplice, 2018), motivated by the difficulty of choosing appropriate
boundary conditions at the internal nodes of a network, a different technique
was explored that avoids the use of ghost cells, but instead employs for the
boundary cells a different stencil, biased towards the interior of the domain.
  In this paper, extending that approach, which does not make use of ghost
cells, we propose a more accurate reconstruction for the one-dimensional case
and a two-dimensional one for Cartesian grids. In several numerical tests we
compare the novel reconstruction with the standard approach using ghost cells.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12393</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RISC-NN: Use RISC, NOT CISC as Neural Network Hardware Infrastructure</dc:title>
 <dc:creator>Xiang, Taoran</dc:creator>
 <dc:creator>Zhang, Lunkai</dc:creator>
 <dc:creator>An, Shuqian</dc:creator>
 <dc:creator>Ye, Xiaochun</dc:creator>
 <dc:creator>Zhang, Mingzhe</dc:creator>
 <dc:creator>Liu, Yanhuan</dc:creator>
 <dc:creator>Yan, Mingyu</dc:creator>
 <dc:creator>Wang, Da</dc:creator>
 <dc:creator>Zhang, Hao</dc:creator>
 <dc:creator>Li, Wenming</dc:creator>
 <dc:creator>Sun, Ninghui</dc:creator>
 <dc:creator>Fan, Dongrui</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Neural Networks (NN) have been proven to be powerful tools to analyze Big
Data. However, traditional CPUs cannot achieve the desired performance and/or
energy efficiency for NN applications. Therefore, numerous NN accelerators have
been used or designed to meet these goals. These accelerators all fall into
three categories: GPGPUs, ASIC NN Accelerators and CISC NN Accelerators. Though
CISC NN Accelerators can achieve considerable smaller memory footprint than
GPGPU thus improve energy efficiency; they still fail to provide same level of
data reuse optimization achieved by ASIC NN Accelerators because of the
inherited poor pragrammability of their CISC architecture. We argue that, for
NN Accelerators, RISC is a better design choice than CISC, as is the case with
general purpose processors. We propose RISC-NN, a novel many-core RISC-based NN
accelerator that achieves high expressiveness and high parallelism and features
strong programmability and low control-hardware costs. We show that, RISC-NN
can implement all the necessary instructions of state-of-the-art CISC NN
Accelerators; in the meantime, RISC-NN manages to achieve advanced optimization
such as multiple-level data reuse and support for Sparse NN applications which
previously only existed in ASIC NN Accelerators. Experiment results show that,
RISC-NN achieves on average 11.88X performance efficiency compared with
state-of-the-art Nvidia TITAN Xp GPGPU for various NN applications. RISC-NN
also achieves on average 1.29X, 8.37X and 21.71X performance efficiency over
CISC-based TPU in CNN, MLP and LSTM applications, respectively. Finally,
RISC-NN can achieve additional 26.05% performance improvement and 33.13% energy
reduction after applying pruning for Sparse NN applications.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12393</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12399</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Hammer and the Nut: Is Bilevel Optimization Really Needed to Poison
  Linear Classifiers?</dc:title>
 <dc:creator>Cin&#xe0;, Antonio Emanuele</dc:creator>
 <dc:creator>Vascon, Sebastiano</dc:creator>
 <dc:creator>Demontis, Ambra</dc:creator>
 <dc:creator>Biggio, Battista</dc:creator>
 <dc:creator>Roli, Fabio</dc:creator>
 <dc:creator>Pelillo, Marcello</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  One of the most concerning threats for modern AI systems is data poisoning,
where the attacker injects maliciously crafted training data to corrupt the
system's behavior at test time. Availability poisoning is a particularly
worrisome subset of poisoning attacks where the attacker aims to cause a
Denial-of-Service (DoS) attack. However, the state-of-the-art algorithms are
computationally expensive because they try to solve a complex bi-level
optimization problem (the &quot;hammer&quot;). We observed that in particular conditions,
namely, where the target model is linear (the &quot;nut&quot;), the usage of
computationally costly procedures can be avoided. We propose a
counter-intuitive but efficient heuristic that allows contaminating the
training set such that the target system's performance is highly compromised.
We further suggest a re-parameterization trick to decrease the number of
variables to be optimized. Finally, we demonstrate that, under the considered
settings, our framework achieves comparable, or even better, performances in
terms of the attacker's objective while being significantly more
computationally efficient.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures, Submitted to IJCNN 2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12399</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12404</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diversity Regularized Interests Modeling for Recommender Systems</dc:title>
 <dc:creator>Hao, Junmei</dc:creator>
 <dc:creator>Shi, Jingcheng</dc:creator>
 <dc:creator>Da, Qing</dc:creator>
 <dc:creator>Zeng, Anxiang</dc:creator>
 <dc:creator>Dun, Yujie</dc:creator>
 <dc:creator>Qian, Xueming</dc:creator>
 <dc:creator>Lin, Qianying</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  With the rapid development of E-commerce and the increase in the quantity of
items, users are presented with more items hence their interests broaden. It is
increasingly difficult to model user intentions with traditional methods, which
model the user's preference for an item by combining a single user vector and
an item vector. Recently, some methods are proposed to generate multiple user
interest vectors and achieve better performance compared to traditional
methods. However, empirical studies demonstrate that vectors generated from
these multi-interests methods are sometimes homogeneous, which may lead to
sub-optimal performance. In this paper, we propose a novel method of Diversity
Regularized Interests Modeling (DRIM) for Recommender Systems. We apply a
capsule network in a multi-interest extractor to generate multiple user
interest vectors. Each interest of the user should have a certain degree of
distinction, thus we introduce three strategies as the diversity regularized
separator to separate multiple user interest vectors. Experimental results on
public and industrial data sets demonstrate the ability of the model to capture
different interests of a user and the superior performance of the proposed
approach.
</dc:description>
 <dc:description>Comment: 7pages,4figures</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12409</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binary disease prediction using tail quantiles of the distribution of
  continuous biomarkers</dc:title>
 <dc:creator>Paus, Michiel H. J.</dc:creator>
 <dc:creator>Heuvel, Edwin R. van den</dc:creator>
 <dc:creator>Meddens, Marc J. M.</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  In the analysis of binary disease classification, single biomarkers might not
have significant discriminating power and multiple biomarkers from a large set
of biomarkers should be selected. Numerous approaches exist, but they merely
work well for mean differences in biomarkers between cases and controls.
Biological processes are however much more heterogeneous, and differences could
also occur in other distributional characteristics (e.g. variances, skewness).
Many machine learning techniques are better capable of utilizing these higher
order distributional differences, sometimes at cost of explainability.
  In this study we propose quantile based prediction (QBP), a binary
classification method that is based on the selection of multiple continuous
biomarkers. QBP generates a single score using the tails of the biomarker
distributions for cases and controls. This single score can then be evaluated
by ROC analysis to investigate its predictive power.
  The performance of QBP is compared to supervised learning methods using
extensive simulation studies, and two case studies: major depression disorder
and trisomy. Simultaneously, the classification performance of the existing
techniques in relation to each other is assessed. The key strengths of QBP are
the opportunity to select relevant biomarkers and the outstanding
classification performance in the case biomarkers predominantly show variance
differences between cases and controls. When only shifts in means were present
in the biomarkers, QBP obtained an inferior performance. Lastly, QBP proved to
be unbiased in case of absence of disease relevant biomarkers and outperformed
the other methods on the MDD case study.
  More research is needed to further optimize QBP, since it has several
opportunities to improve its performance. Here we wanted to introduce the
principle of QBP and show its potential.
</dc:description>
 <dc:description>Comment: 26 pages, 5 figures</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12409</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12411</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CubeFlow: Money Laundering Detection with Coupled Tensors</dc:title>
 <dc:creator>Sun, Xiaobing</dc:creator>
 <dc:creator>Zhang, Jiabao</dc:creator>
 <dc:creator>Zhao, Qiming</dc:creator>
 <dc:creator>Liu, Shenghua</dc:creator>
 <dc:creator>Chen, Jinglei</dc:creator>
 <dc:creator>Zhuang, Ruoyu</dc:creator>
 <dc:creator>Shen, Huawei</dc:creator>
 <dc:creator>Cheng, Xueqi</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Money laundering (ML) is the behavior to conceal the source of money achieved
by illegitimate activities, and always be a fast process involving frequent and
chained transactions. How can we detect ML and fraudulent activity in large
scale attributed transaction data (i.e.~tensors)? Most existing methods detect
dense blocks in a graph or a tensor, which do not consider the fact that money
are frequently transferred through middle accounts. CubeFlow proposed in this
paper is a scalable, flow-based approach to spot fraud from a mass of
transactions by modeling them as two coupled tensors and applying a novel
multi-attribute metric which can reveal the transfer chains accurately.
Extensive experiments show CubeFlow outperforms state-of-the-art baselines in
ML behavior detection in both synthetic and real data.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12411</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12412</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Multi-domain, Heterogeneous Data using Deep Multitask
  Learning for Hate Speech Detection</dc:title>
 <dc:creator>Kapil, Prashant</dc:creator>
 <dc:creator>Ekbal, Asif</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  With the exponential rise in user-generated web content on social media, the
proliferation of abusive languages towards an individual or a group across the
different sections of the internet is also rapidly increasing. It is very
challenging for human moderators to identify the offensive contents and filter
those out. Deep neural networks have shown promise with reasonable accuracy for
hate speech detection and allied applications. However, the classifiers are
heavily dependent on the size and quality of the training data. Such a
high-quality large data set is not easy to obtain. Moreover, the existing data
sets that have emerged in recent times are not created following the same
annotation guidelines and are often concerned with different types and
sub-types related to hate. To solve this data sparsity problem, and to obtain
more global representative features, we propose a Convolution Neural Network
(CNN) based multi-task learning models (MTLs)\footnote{code is available at
https://github.com/imprasshant/STL-MTL} to leverage information from multiple
sources. Empirical analysis performed on three benchmark datasets shows the
efficacy of the proposed approach with the significant improvement in accuracy
and F-score to obtain state-of-the-art performance with respect to the existing
systems.
</dc:description>
 <dc:description>Comment: 10 pages, 2 figures, 13 tables. Accepted at THE SEVENTEENTH
  INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING (ICON) 2020</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12412</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12417</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OFFSEG: A Semantic Segmentation Framework For Off-Road Driving</dc:title>
 <dc:creator>Viswanath, Kasi</dc:creator>
 <dc:creator>Singh, Kartikeya</dc:creator>
 <dc:creator>Jiang, Peng</dc:creator>
 <dc:creator>B., Sujit P.</dc:creator>
 <dc:creator>Saripalli, Srikanth</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Off-road image semantic segmentation is challenging due to the presence of
uneven terrains, unstructured class boundaries, irregular features and strong
textures. These aspects affect the perception of the vehicle from which the
information is used for path planning. Current off-road datasets exhibit
difficulties like class imbalance and understanding of varying environmental
topography. To overcome these issues we propose a framework for off-road
semantic segmentation called as OFFSEG that involves (i) a pooled class
semantic segmentation with four classes (sky, traversable region,
non-traversable region and obstacle) using state-of-the-art deep learning
architectures (ii) a colour segmentation methodology to segment out specific
sub-classes (grass, puddle, dirt, gravel, etc.) from the traversable region for
better scene understanding. The evaluation of the framework is carried out on
two off-road driving datasets, namely, RELLIS-3D and RUGD. We have also tested
proposed framework in IISERB campus frames. The results show that OFFSEG
achieves good performance and also provides detailed information on the
traversable region.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12417</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12420</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HSEarch: semantic search system for workplace accident reports</dc:title>
 <dc:creator>Inan, Emrah</dc:creator>
 <dc:creator>Thompson, Paul</dc:creator>
 <dc:creator>Yates, Tim</dc:creator>
 <dc:creator>Ananiadou, Sophia</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Semantic search engines, which integrate the output of text mining (TM)
methods, can significantly increase the ease and efficiency of finding relevant
documents and locating important information within them. We present a novel
search engine for the construction industry, HSEarch
(http://www.nactem.ac.uk/hse/), which uses TM methods to provide
semantically-enhanced, faceted search over a repository of workplace accident
reports. Compared to previous TM-driven search engines for the construction
industry, HSEarch provides a more interactive means for users to explore the
contents of the repository, to review documents more systematically and to
locate relevant knowledge within them.
</dc:description>
 <dc:description>Comment: Accepted to appear in ECIR 2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12428</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling the Severity of Complaints in Social Media</dc:title>
 <dc:creator>Jin, Mali</dc:creator>
 <dc:creator>Aletras, Nikolaos</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The speech act of complaining is used by humans to communicate a negative
mismatch between reality and expectations as a reaction to an unfavorable
situation. Linguistic theory of pragmatics categorizes complaints into various
severity levels based on the face-threat that the complainer is willing to
undertake. This is particularly useful for understanding the intent of
complainers and how humans develop suitable apology strategies. In this paper,
we study the severity level of complaints for the first time in computational
linguistics. To facilitate this, we enrich a publicly available data set of
complaints with four severity categories and train different transformer-based
networks combined with linguistic information achieving 55.7 macro F1. We also
jointly model binary complaint classification and complaint severity in a
multi-task setting achieving new state-of-the-art results on binary complaint
detection reaching up to 88.2 macro F1. Finally, we present a qualitative
analysis of the behavior of our models in predicting complaint severity levels.
</dc:description>
 <dc:description>Comment: Accepted at NAACL 2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12428</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12432</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strong Detectability and Observers for Linear Time Varying Systems</dc:title>
 <dc:creator>Tranninger, Markus</dc:creator>
 <dc:creator>Seeber, Richard</dc:creator>
 <dc:creator>Rueda-Escobedo, Juan G.</dc:creator>
 <dc:creator>Horn, Martin</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This work presents a notion of strong detectability for linear time varying
systems affected by unknown inputs. It is shown that this notion is equivalent
to detectability of an auxiliary system without unknown inputs. This allows a
straightforward observer design for dependable state estimation in the presence
of unknown inputs. The design reduces to a deterministic Kalman filter design
problem, where the observer gains can be obtained from the solution of a
differential Riccati equation. The efficacy of the proposed approach is
demonstrated by means of a numerical example.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12432</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12441</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Partial Matching in the Space of Varifolds</dc:title>
 <dc:creator>Antonsanti, Pierre-Louis</dc:creator>
 <dc:creator>Glaun&#xe8;s, Joan</dc:creator>
 <dc:creator>Benseghir, Thomas</dc:creator>
 <dc:creator>Jugnon, Vincent</dc:creator>
 <dc:creator>Kaltenmark, Ir&#xe8;ne</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Differential Geometry</dc:subject>
 <dc:subject>58Axx</dc:subject>
 <dc:description>  In computer vision and medical imaging, the problem of matching structures
finds numerous applications from automatic annotation to data reconstruction.
The data however, while corresponding to the same anatomy, are often very
different in topology or shape and might only partially match each other. We
introduce a new asymmetric data dissimilarity term for various geometric shapes
like sets of curves or surfaces. This term is based on the Varifold shape
representation and assesses the embedding of a shape into another one without
relying on correspondences between points. It is designed as data attachment
for the Large Deformation Diffeomorphic Metric Mapping (LDDMM) framework,
allowing to compute meaningful deformation of one shape onto a subset of the
other. Registrations are illustrated on sets of synthetic 3D curves, real
vascular trees and livers' surfaces from two different modalities: Computed
Tomography (CT) and Cone Beam Computed Tomography (CBCT). All experiments show
that this data dissimilarity term leads to coherent partial matching despite
the topological differences.
</dc:description>
 <dc:description>Comment: 12 pages, 3 figures, The 27th international conference on Information
  Processing in Medical Imaging (June, 2021)</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12441</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12447</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What we can learn from how programmers debug their code</dc:title>
 <dc:creator>Hirsch, Thomas</dc:creator>
 <dc:creator>Hofer, Birgit</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Researchers have developed numerous debugging approaches to help programmers
in the debugging process, but these approaches are rarely used in practice. In
this paper, we investigate how programmers debug their code and what
researchers should consider when developing debugging approaches. We conducted
an online questionnaire where 102 programmers provided information about
recently fixed bugs. We found that the majority of bugs (69.6 %) are semantic
bugs. Memory and concurrency bugs do not occur as frequently (6.9 % and 8.8 %),
but they consume more debugging time. Locating a bug is more difficult than
reproducing and fixing it. Programmers often use only IDE build-in tools for
debugging. Furthermore, programmers frequently use a
replication-observation-deduction pattern when debugging. These results suggest
that debugging support is particularly valuable for memory and concurrency
bugs. Furthermore, researchers should focus on the fault localization phase and
integrate their tools into commonly used IDEs.
</dc:description>
 <dc:description>Comment: 4 pages, accepted and to be published in Proceedings of SER&amp;IP 2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12447</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12456</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Health Status Prediction with Local-Global Heterogeneous Behavior Graph</dc:title>
 <dc:creator>Ma, Xuan</dc:creator>
 <dc:creator>Yang, Xiaoshan</dc:creator>
 <dc:creator>Gao, Junyu</dc:creator>
 <dc:creator>Xu, Changsheng</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Health management is getting increasing attention all over the world.
However, existing health management mainly relies on hospital examination and
treatment, which are complicated and untimely. The emerging of mobile devices
provides the possibility to manage people's health status in a convenient and
instant way. Estimation of health status can be achieved with various kinds of
data streams continuously collected from wearable sensors. However, these data
streams are multi-source and heterogeneous, containing complex temporal
structures with local contextual and global temporal aspects, which makes the
feature learning and data joint utilization challenging. We propose to model
the behavior-related multi-source data streams with a local-global graph, which
contains multiple local context sub-graphs to learn short term local context
information with heterogeneous graph neural networks and a global temporal
sub-graph to learn long term dependency with self-attention networks. Then
health status is predicted based on the structure-aware representation learned
from the local-global behavior graph. We take experiments on StudentLife
dataset, and extensive results demonstrate the effectiveness of our proposed
model.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12456</dc:identifier>
 <dc:identifier>doi:10.1145/3457893</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12462</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lifelong Person Re-Identification via Adaptive Knowledge Accumulation</dc:title>
 <dc:creator>Pu, Nan</dc:creator>
 <dc:creator>Chen, Wei</dc:creator>
 <dc:creator>Liu, Yu</dc:creator>
 <dc:creator>Bakker, Erwin M.</dc:creator>
 <dc:creator>Lew, Michael S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Person ReID methods always learn through a stationary domain that is fixed by
the choice of a given dataset. In many contexts (e.g., lifelong learning),
those methods are ineffective because the domain is continually changing in
which case incremental learning over multiple domains is required potentially.
In this work we explore a new and challenging ReID task, namely lifelong person
re-identification (LReID), which enables to learn continuously across multiple
domains and even generalise on new and unseen domains. Following the cognitive
processes in the human brain, we design an Adaptive Knowledge Accumulation
(AKA) framework that is endowed with two crucial abilities: knowledge
representation and knowledge operation. Our method alleviates catastrophic
forgetting on seen domains and demonstrates the ability to generalize to unseen
domains. Correspondingly, we also provide a new and large-scale benchmark for
LReID. Extensive experiments demonstrate our method outperforms other
competitors by a margin of 5.8% mAP in generalising evaluation.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures, Accepted by CVPR2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12462</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12465</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Deep Learning Pipelines for Accurate Cost Estimations Over
  Large Scale Query Workload</dc:title>
 <dc:creator>Kang, Johan Kok Zhi</dc:creator>
 <dc:creator>Gaurav</dc:creator>
 <dc:creator>Tan, Sien Yi</dc:creator>
 <dc:creator>Cheng, Feng</dc:creator>
 <dc:creator>Sun, Shixuan</dc:creator>
 <dc:creator>He, Bingsheng</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The use of deep learning models for forecasting the resource consumption
patterns of SQL queries have recently been a popular area of study. With many
companies using cloud platforms to power their data lakes for large scale
analytic demands, these models form a critical part of the pipeline in managing
cloud resource provisioning. While these models have demonstrated promising
accuracy, training them over large scale industry workloads are expensive.
Space inefficiencies of encoding techniques over large numbers of queries and
excessive padding used to enforce shape consistency across diverse query plans
implies 1) longer model training time and 2) the need for expensive, scaled up
infrastructure to support batched training. In turn, we developed Prestroid, a
tree convolution based data science pipeline that accurately predicts resource
consumption patterns of query traces, but at a much lower cost.
  We evaluated our pipeline over 19K Presto OLAP queries from Grab, on a data
lake of more than 20PB of data. Experimental results imply that our pipeline
outperforms benchmarks on predictive accuracy, contributing to more precise
resource prediction for large-scale workloads, yet also reduces per-batch
memory footprint by 13.5x and per-epoch training time by 3.45x. We demonstrate
direct cost savings of up to 13.2x for large batched model training over
Microsoft Azure VMs.
</dc:description>
 <dc:description>Comment: Technical report, 11 pages</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12465</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12466</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applying graph matching techniques to enhance reuse of plant design
  information</dc:title>
 <dc:creator>Rantala, Miia</dc:creator>
 <dc:creator>Niemist&#xf6;, Hannu</dc:creator>
 <dc:creator>Karhela, Tommi</dc:creator>
 <dc:creator>Sierla, Seppo</dc:creator>
 <dc:creator>Vyatkin, Valeriy</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  This article investigates how graph matching can be applied to process plant
design data in order to support the reuse of previous designs. A literature
review of existing graph matching algorithms is performed, and a group of
algorithms is chosen for further testing. A use case from early phase plant
design is presented. A methodology for addressing the use case is proposed,
including graph simplification algorithms and node similarity measures, so that
existing graph matching algorithms can be applied in the process plant domain.
The proposed methodology is evaluated empirically on an industrial case
consisting of design data from several pulp and paper plants.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12466</dc:identifier>
 <dc:identifier>Computers in Industry, 2019, 107: 81-98</dc:identifier>
 <dc:identifier>doi:10.1016/j.compind.2019.01.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12469</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RPATTACK: Refined Patch Attack on General Object Detectors</dc:title>
 <dc:creator>Huang, Hao</dc:creator>
 <dc:creator>Wang, Yongtao</dc:creator>
 <dc:creator>Chen, Zhaoyu</dc:creator>
 <dc:creator>Tang, Zhi</dc:creator>
 <dc:creator>Zhang, Wenqiang</dc:creator>
 <dc:creator>Ma, Kai-Kuang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Nowadays, general object detectors like YOLO and Faster R-CNN as well as
their variants are widely exploited in many applications. Many works have
revealed that these detectors are extremely vulnerable to adversarial patch
attacks. The perturbed regions generated by previous patch-based attack works
on object detectors are very large which are not necessary for attacking and
perceptible for human eyes. To generate much less but more efficient
perturbation, we propose a novel patch-based method for attacking general
object detectors. Firstly, we propose a patch selection and refining scheme to
find the pixels which have the greatest importance for attack and remove the
inconsequential perturbations gradually. Then, for a stable ensemble attack, we
balance the gradients of detectors to avoid over-optimizing one of them during
the training phase. Our RPAttack can achieve an amazing missed detection rate
of 100% for both Yolo v4 and Faster R-CNN while only modifies 0.32% pixels on
VOC 2007 test set. Our code is available at
https://github.com/VDIGPKU/RPAttack.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, IEEE International Conference on Multimedia and
  Expo (ICME) 2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12469</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12472</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-intrusive reduced order modeling of parametric electromagnetic
  scattering problems through Gaussian process regression</dc:title>
 <dc:creator>Zhao, Ying</dc:creator>
 <dc:creator>Li, Liang</dc:creator>
 <dc:creator>Li, Kun</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65M25</dc:subject>
 <dc:description>  This paper is concerned with the design of a non-intrusive model order
reduction (MOR) for the system of parametric time-domain Maxwell equations. A
time- and parameter-independent reduced basis (RB) is constructed by using a
two-step proper orthogonal decomposition (POD) technique from a collection of
full-order electromagnetic field solutions, which are generated via a
discontinuous Galerkin time-domain (DGTD) solver. The mapping between the
time/parameter values and the projection coefficients onto the RB space is
approximated by a Gaussian process regression (GPR). Based on the data
characteristics of electromagnetic field solutions, the singular value
decomposition (SVD) is applied to extract the principal components of the
training data of each projection coefficient, and the GPR models are trained
for time- and parameter-modes respectively, by which the final global
regression function can be represented as a linear combination of these time-
and parameter-Gaussian processes. The extraction of the RB and the training of
GPR surrogate models are both completed in the offline stage. Then the field
solution at any new input time/parameter point can be directly recovered in the
online stage as a linear combination of the RB with the regression outputs as
the coefficients. In virtue of its non-intrusive nature, the proposed POD-GPR
framework, which is equation-free, decouples the offline and online stages
completely, and hence can predict the electromagnetic solution fields at unseen
parameter locations quickly and effectively. The performance of our method is
illustrated by a scattering problem of a multi-layer dielectric cylinder.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12472</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12475</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attention-based neural re-ranking approach for next city in trip
  recommendations</dc:title>
 <dc:creator>Petrov, Aleksandr</dc:creator>
 <dc:creator>Makarov, Yuriy</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  This paper describes an approach to solving the next destination city
recommendation problem for a travel reservation system. We propose a two stages
approach: a heuristic approach for candidates selection and an attention neural
network model for candidates re-ranking. Our method was inspired by listwise
learning-to-rank methods and recent developments in natural language processing
and the transformer architecture in particular. We used this approach to solve
the Booking.com recommendations challenge Our team achieved 5th place on the
challenge using this method, with 0.555 accuracy@4 value on the closed part of
the dataset.
</dc:description>
 <dc:description>Comment: The paper was accepted on ACM WSDM WebTour 2021 Workshop on Web
  Tourism, https://web.ec.tuwien.ac.at/webtour21/?page_id=27</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12475</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12476</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differentiable Agent-Based Simulation for Gradient-Guided
  Simulation-Based Optimization</dc:title>
 <dc:creator>Andelfinger, Philipp</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Simulation-based optimization using agent-based models is typically carried
out under the assumption that the gradient describing the sensitivity of the
simulation output to the input cannot be evaluated directly. To still apply
gradient-based optimization methods, which efficiently steer the optimization
towards a local optimum, gradient estimation methods can be employed. However,
many simulation runs are needed to obtain accurate estimates if the input
dimension is large. Automatic differentiation (AD) is a family of techniques to
compute gradients of general programs directly. Here, we explore the use of AD
in the context of time-driven agent-based simulations. By substituting common
discrete model elements such as conditional branching with smooth
approximations, we obtain gradient information across discontinuities in the
model logic. On the example of microscopic traffic models and an epidemics
model, we study the fidelity and overhead of the differentiable models, as well
as the convergence speed and solution quality achieved by gradient-based
optimization compared to gradient-free methods. In traffic signal timing
optimization problems with high input dimension, the gradient-based methods
exhibit substantially superior performance. Finally, we demonstrate that the
approach enables gradient-based training of neural network-controlled
simulation entities embedded in the model logic.
</dc:description>
 <dc:description>Comment: Accepted at the 2021 ACM SIGSIM Conference Conference on Principles
  of Advanced Discrete Simulation (PADS'21)</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12483</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Convolutional Precoding in PAC Codes</dc:title>
 <dc:creator>Rowshan, Mohammad</dc:creator>
 <dc:creator>Viterbo, Emanuele</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Polarization-adjusted convolutional (PAC) codes are special concatenated
codes in which we employ a one-to-one convolutional transform as a precoding
step before the polar transform. In this scheme, the polar transform (as a
mapper) and the successive cancellation process (as a demapper) present a
synthetic vector channel to the convolutional transformation. The numerical
results in the literature show that this concatenation improves the weight
distribution of polar codes which justifies the superior error correction
performance of PAC codes relative to polar codes. In this work, we explicitly
show why the convolutional precoding reduces the number of minimumweight
codewords. Further analysis exhibits where the precoding stage is not
effective. Then, we recognize weaknesses of the convolutional precoding which
are unequal error protection (UEP) of the information bits due to rate
profiling and lack of cross-segmental convolution. Finally, we assess the
possibility of improving the precoding stage by proposing some irregular
convolutional precodings.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12491</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Expanding Semantic Knowledge for Zero-shot Graph Embedding</dc:title>
 <dc:creator>Wang, Zheng</dc:creator>
 <dc:creator>Shao, Ruihang</dc:creator>
 <dc:creator>Wang, Changping</dc:creator>
 <dc:creator>Hu, Changjun</dc:creator>
 <dc:creator>Wang, Chaokun</dc:creator>
 <dc:creator>Gong, Zhiguo</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Zero-shot graph embedding is a major challenge for supervised graph learning.
Although a recent method RECT has shown promising performance, its working
mechanisms are not clear and still needs lots of training data. In this paper,
we give deep insights into RECT, and address its fundamental limits. We show
that its core part is a GNN prototypical model in which a class prototype is
described by its mean feature vector. As such, RECT maps nodes from the
raw-input feature space into an intermediate-level semantic space that connects
the raw-input features to both seen and unseen classes. This mechanism makes
RECT work well on both seen and unseen classes, which however also reduces the
discrimination. To realize its full potentials, we propose two label expansion
strategies. Specifically, besides expanding the labeled node set of seen
classes, we can also expand that of unseen classes. Experiments on real-world
datasets validate the superiority of our methods.
</dc:description>
 <dc:description>Comment: Accepted by DASFAA2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12491</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12496</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting Self-Supervised Monocular Depth Estimation</dc:title>
 <dc:creator>Kim, Ue-Hwan</dc:creator>
 <dc:creator>Kim, Jong-Hwan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Self-supervised learning of depth map prediction and motion estimation from
monocular video sequences is of vital importance -- since it realizes a broad
range of tasks in robotics and autonomous vehicles. A large number of research
efforts have enhanced the performance by tackling illumination variation,
occlusions, and dynamic objects, to name a few. However, each of those efforts
targets individual goals and endures as separate works. Moreover, most of
previous works have adopted the same CNN architecture, not reaping
architectural benefits. Therefore, the need to investigate the inter-dependency
of the previous methods and the effect of architectural factors remains. To
achieve these objectives, we revisit numerous previously proposed
self-supervised methods for joint learning of depth and motion, perform a
comprehensive empirical study, and unveil multiple crucial insights.
Furthermore, we remarkably enhance the performance as a result of our study --
outperforming previous state-of-the-art performance.
</dc:description>
 <dc:description>Comment: 14 pages, 3 figures, 4 tables</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12496</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12498</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stereo Object Matching Network</dc:title>
 <dc:creator>Choe, Jaesung</dc:creator>
 <dc:creator>Joo, Kyungdon</dc:creator>
 <dc:creator>Rameau, Francois</dc:creator>
 <dc:creator>Kweon, In So</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a stereo object matching method that exploits both 2D
contextual information from images as well as 3D object-level information.
Unlike existing stereo matching methods that exclusively focus on the
pixel-level correspondence between stereo images within a volumetric space
(i.e., cost volume), we exploit this volumetric structure in a different
manner. The cost volume explicitly encompasses 3D information along its
disparity axis, therefore it is a privileged structure that can encapsulate the
3D contextual information from objects. However, it is not straightforward
since the disparity values map the 3D metric space in a non-linear fashion.
Thus, we present two novel strategies to handle 3D objectness in the cost
volume space: selective sampling (RoISelect) and 2D-3D fusion
(fusion-by-occupancy), which allow us to seamlessly incorporate 3D object-level
information and achieve accurate depth performance near the object boundary
regions. Our depth estimation achieves competitive performance in the KITTI
dataset and the Virtual-KITTI 2.0 dataset.
</dc:description>
 <dc:description>Comment: Accepted at ICRA 2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12498</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12506</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Predicting the Factuality and the Bias of News Media</dc:title>
 <dc:creator>Nakov, Preslav</dc:creator>
 <dc:creator>Sencar, Husrev Taha</dc:creator>
 <dc:creator>An, Jisun</dc:creator>
 <dc:creator>Kwak, Haewoon</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>68T50</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  The present level of proliferation of fake, biased, and propagandistic
content online has made it impossible to fact-check every single suspicious
claim or article, either manually or automatically. Thus, many researchers are
shifting their attention to higher granularity, aiming to profile entire news
outlets, which makes it possible to detect likely &quot;fake news&quot; the moment it is
published, by simply checking the reliability of its source. Source factuality
is also an important element of systems for automatic fact-checking and &quot;fake
news&quot; detection, as they need to assess the reliability of the evidence they
retrieve online. Political bias detection, which in the Western political
landscape is about predicting left-center-right bias, is an equally important
topic, which has experienced a similar shift towards profiling entire news
outlets. Moreover, there is a clear connection between the two, as highly
biased media are less likely to be factual; yet, the two problems have been
addressed separately. In this survey, we review the state of the art on media
profiling for factuality and bias, arguing for the need to model them jointly.
We further discuss interesting recent advances in using different information
sources and modalities, which go beyond the text of the articles the target
news outlet has published. Finally, we discuss current challenges and outline
future research directions.
</dc:description>
 <dc:description>Comment: factuality of reporting, fact-checking, political ideology, media
  bias, disinformation, propaganda, social media, news media</dc:description>
 <dc:date>2021-03-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12506</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12510</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Newton Product of Polynomial Projectors. Part 2 : approximation
  properties</dc:title>
 <dc:creator>Bertrand, Fran&#xe7;ois</dc:creator>
 <dc:creator>Calvi, Jean-Paul</dc:creator>
 <dc:subject>Mathematics - Complex Variables</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>41A05, 41A63, 32A05, 32A15</dc:subject>
 <dc:description>  We prove that the Newton product of efficient polynomial projectors is still
efficient. Various polynomial approximation theorems are established involving
Newton product projectors on spaces of holomorphic functions on a neighborhood
of a regular compact set, on spaces of entire functions of given growth and on
spaces of differentiable functions. Efficient explicit new projectors are
presented.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12510</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12512</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Remote Sensing to Control Respiratory Viral Diseases Outbreaks using
  Internet of Vehicles</dc:title>
 <dc:creator>Sahraoui, Yesin</dc:creator>
 <dc:creator>Korichi, Ahmed</dc:creator>
 <dc:creator>Kerrache, Chaker Abdelaziz</dc:creator>
 <dc:creator>Bilal, Muhammad</dc:creator>
 <dc:creator>Amadeo, Marica</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>68W15, 68M10, 68M11, 68M12, 68M14, 68M18</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:subject>C.2.6</dc:subject>
 <dc:subject>C.2.2</dc:subject>
 <dc:subject>K.4.0</dc:subject>
 <dc:description>  The respiratory viral diseases, such as those caused by the family of
coronaviruses, can be extremely contagious and spread through saliva droplets
generated by coughing, sneezing, or breathing. In humans, the most common
symptoms of the infection include fever and difficulty in breathing. In order
to reduce the diffusion of the current &quot;Coronavirus disease 2019 (COVID-19)&quot;
pandemic, the Internet of Things (IoT) technologies can play an important role;
for instance, they can be effectively used for implementing a real-time patient
tracking and warning system at a city scale. Crucial places to install the
tracking IoT devices are the public/private vehicles that, augmented with
multiple connectivity solutions, can implement the Internet of Vehicles (IoV)
paradigm. In such a ubiquitous network environment, vehicles are equipped with
a variety of sensors, including regular cameras that can be replaced with
thermal cameras. Therefore, this paper proposes a new design for widely
detecting respiratory viral diseases that leverages IoV to collect real-time
body temperature and breathing rate measurements of pedestrians. This
information can be used to recognize geographic areas affected by possible
COVID-19 cases and to implement proactive preventive strategies that would
further limit the spread of the disease.
</dc:description>
 <dc:description>Comment: 12 pages, 11 figures, Accepted for publication in Transactions on
  Emerging Telecommunications Technologies (ETT)</dc:description>
 <dc:date>2020-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12516</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Edge-Cloud Collaboration Enabled Video Service Enhancement: A Hybrid
  Human-Artificial Intelligence Scheme</dc:title>
 <dc:creator>Wu, Dapeng</dc:creator>
 <dc:creator>Bao, Ruili</dc:creator>
 <dc:creator>Li, Zhidu</dc:creator>
 <dc:creator>Wang, Honggang</dc:creator>
 <dc:creator>Wang, Ruyan</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  In this paper, a video service enhancement strategy is investigated under an
edge-cloud collaboration framework, where video caching and delivery decisions
are made in the cloud and edge respectively. We aim to guarantee the user
fairness in terms of video coding rate under statistical delay constraint and
edge caching capacity constraint. A hybrid human-artificial intelligence
approach is developed to improve the user hit rate for video caching.
Specifically, individual user interest is first characterized by merging
factorization machine (FM) model and multi-layer perceptron (MLP) model, where
both low-order and high-order features can be well learned simultaneously.
Thereafter, a social aware similarity model is constructed to transferred
individual user interest to group interest, based on which, videos can be
selected to cache. Furthermore, a double bisection exploration scheme is
proposed to optimize wireless resource allocation and video coding rate. The
effectiveness of the proposed video caching scheme and video delivery scheme is
finally validated by extensive experiments with a real-world data set.
</dc:description>
 <dc:description>Comment: This paper has been submitted to IEEE Transactions on Multimedia for
  review</dc:description>
 <dc:date>2021-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12516</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12517</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scenario-Based Trajectory Optimization in Uncertain Dynamic Environments</dc:title>
 <dc:creator>de Groot, O.</dc:creator>
 <dc:creator>Brito, B.</dc:creator>
 <dc:creator>Ferranti, L.</dc:creator>
 <dc:creator>Gavrila, D.</dc:creator>
 <dc:creator>Alonso-Mora, J.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present an optimization-based method to plan the motion of an autonomous
robot under the uncertainties associated with dynamic obstacles, such as
humans. Our method bounds the marginal risk of collisions at each point in time
by incorporating chance constraints into the planning problem. This problem is
not suitable for online optimization outright for arbitrary probability
distributions. Hence, we sample from these chance constraints using an
uncertainty model, to generate &quot;scenarios&quot;, which translate the probabilistic
constraints into deterministic ones. In practice, each scenario represents the
collision constraint for a dynamic obstacle at the location of the sample. The
number of theoretically required scenarios can be very large. Nevertheless, by
exploiting the geometry of the workspace, we show how to prune most scenarios
before optimization and we demonstrate how the reduced scenarios can still
provide probabilistic guarantees on the safety of the motion plan. Since our
approach is scenario based, we are able to handle arbitrary uncertainty
distributions. We apply our method in a Model Predictive Contouring Control
framework and demonstrate its benefits in simulations and experiments with a
moving robot platform navigating among pedestrians, running in real-time.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures. To be published in IEEE Robotics and Automation
  Letters</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12517</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12519</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A multi-layer network model to assess school opening policies during the
  COVID-19 vaccination campaign</dc:title>
 <dc:creator>Bongiorno, Christian</dc:creator>
 <dc:creator>Zino, Lorenzo</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  We propose a multi-layer network model for the spread of COVID-19 that
accounts for interactions within the family, between schoolmates, and casual
contacts in the population. We utilize the proposed model-calibrated on
epidemiological and demographic data-to investigate current questions
concerning the implementation of non-pharmaceutical interventions (NPIs) during
the vaccination campaign. Specifically, we consider scenarios in which the most
fragile population has already received the vaccine, and we focus our analysis
on the role of schools as drivers of the contagions and on the implementation
of targeted intervention policies oriented to children and their families. We
perform our analysis by means of a campaign of Monte Carlo simulations. Our
findings suggest that, in a phase with NPIs enacted but in-person education,
children play a key role in the spreading of COVID-19. Interestingly, we show
that children's testing might be an important tool to flatten the epidemic
curve, in particular when combined with enacting temporary online education for
classes in which infected students are detected. Finally, we test a vaccination
strategy that prioritizes the members of large families and we demonstrate its
good performance. We believe that our modeling framework and our findings could
be of help for public health authorities for planning their current and future
interventions, as well as to increase preparedness for future epidemic
outbreaks.
</dc:description>
 <dc:date>2021-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12519</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12520</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Security Games: A Survey</dc:title>
 <dc:creator>Galinkin, Erick</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We introduce some preliminaries about game theory and information security.
Then surveying a subset of the literature, we identify opportunities for future
research.
</dc:description>
 <dc:description>Comment: Drexel University PhD Candidacy Document</dc:description>
 <dc:date>2021-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12521</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Ensemble Learning</dc:title>
 <dc:creator>Stamp, Mark</dc:creator>
 <dc:creator>Chandak, Aniket</dc:creator>
 <dc:creator>Wong, Gavin</dc:creator>
 <dc:creator>Ye, Allen</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In this paper, we consider ensemble classifiers, that is, machine learning
based classifiers that utilize a combination of scoring functions. We provide a
framework for categorizing such classifiers, and we outline several ensemble
techniques, discussing how each fits into our framework. From this general
introduction, we then pivot to the topic of ensemble learning within the
context of malware analysis. We present a brief survey of some of the ensemble
techniques that have been used in malware (and related) research. We conclude
with an extensive set of experiments, where we apply ensemble techniques to a
large and challenging malware dataset. While many of these ensemble techniques
have appeared in the malware literature, previously there has been no way to
directly compare results such as these, as different datasets and different
measures of success are typically used. Our common framework and empirical
results are an effort to bring some sense of order to the chaos that is evident
in the evolving field of ensemble learning -- both within the narrow confines
of the malware analysis problem, and in the larger realm of machine learning in
general.
</dc:description>
 <dc:date>2021-03-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12523</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Region extraction based approach for cigarette usage classification
  using deep learning</dc:title>
 <dc:creator>Pundhir, Anshul</dc:creator>
 <dc:creator>Verma, Deepak</dc:creator>
 <dc:creator>Kumar, Puneet</dc:creator>
 <dc:creator>Raman, Balasubramanian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper has proposed a novel approach to classify the subjects' smoking
behavior by extracting relevant regions from a given image using deep learning.
After the classification, we have proposed a conditional detection module based
on Yolo-v3, which improves model's performance and reduces its complexity. As
per the best of our knowledge, we are the first to work on this dataset. This
dataset contains a total of 2,400 images that include smokers and non-smokers
equally in various environmental settings. We have evaluated the proposed
approach's performance using quantitative and qualitative measures, which
confirms its effectiveness in challenging situations. The proposed approach has
achieved a classification accuracy of 96.74% on this dataset.
</dc:description>
 <dc:description>Comment: 5 pages, 16 figures. To appear in the proceedings of the 28th IEEE
  International Conference on Image Processing (IEEE - ICIP), September 19-22,
  2021, Anchorage, Alaska, USA</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12523</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12528</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multilingual Autoregressive Entity Linking</dc:title>
 <dc:creator>De Cao, Nicola</dc:creator>
 <dc:creator>Wu, Ledell</dc:creator>
 <dc:creator>Popat, Kashyap</dc:creator>
 <dc:creator>Artetxe, Mikel</dc:creator>
 <dc:creator>Goyal, Naman</dc:creator>
 <dc:creator>Plekhanov, Mikhail</dc:creator>
 <dc:creator>Zettlemoyer, Luke</dc:creator>
 <dc:creator>Cancedda, Nicola</dc:creator>
 <dc:creator>Riedel, Sebastian</dc:creator>
 <dc:creator>Petroni, Fabio</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present mGENRE, a sequence-to-sequence system for the Multilingual Entity
Linking (MEL) problem -- the task of resolving language-specific mentions to a
multilingual Knowledge Base (KB). For a mention in a given language, mGENRE
predicts the name of the target entity left-to-right, token-by-token in an
autoregressive fashion. The autoregressive formulation allows us to effectively
cross-encode mention string and entity names to capture more interactions than
the standard dot product between mention and entity vectors. It also enables
fast search within a large KB even for mentions that do not appear in mention
tables and with no need for large-scale vector indices. While prior MEL works
use a single representation for each entity, we match against entity names of
as many languages as possible, which allows exploiting language connections
between source input and target name. Moreover, in a zero-shot setting on
languages with no training data at all, mGENRE treats the target language as a
latent variable that is marginalized at prediction time. This leads to over 50%
improvements in average accuracy. We show the efficacy of our approach through
extensive evaluation including experiments on three popular MEL benchmarks
where mGENRE establishes new state-of-the-art results. Code and pre-trained
models at https://github.com/facebookresearch/GENRE.
</dc:description>
 <dc:description>Comment: 20 pages, 8 figures, and 11 tables</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12528</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12529</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhanced Gradient for Differentiable Architecture Search</dc:title>
 <dc:creator>Zhang, Haichao</dc:creator>
 <dc:creator>Hao, Kuangrong</dc:creator>
 <dc:creator>Gao, Lei</dc:creator>
 <dc:creator>Tang, Xuesong</dc:creator>
 <dc:creator>Wei, Bing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In recent years, neural architecture search (NAS) methods have been proposed
for the automatic generation of task-oriented network architecture in image
classification. However, the architectures obtained by existing NAS approaches
are optimized only for classification performance and do not adapt to devices
with limited computational resources. To address this challenge, we propose a
neural network architecture search algorithm aiming to simultaneously improve
network performance (e.g., classification accuracy) and reduce network
complexity. The proposed framework automatically builds the network
architecture at two stages: block-level search and network-level search. At the
stage of block-level search, a relaxation method based on the gradient is
proposed, using an enhanced gradient to design high-performance and
low-complexity blocks. At the stage of network-level search, we apply an
evolutionary multi-objective algorithm to complete the automatic design from
blocks to the target network. The experiment results demonstrate that our
method outperforms all evaluated hand-crafted networks in image classification,
with an error rate of on CIFAR10 and an error rate of on CIFAR100, both at
network parameter size less than one megabit. Moreover, compared with other
neural architecture search methods, our method offers a tremendous reduction in
designed network architecture parameters.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12529</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12534</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uncovering Dominant Features in Short-term Power Load Forecasting Based
  on Multi-source Feature</dc:title>
 <dc:creator>Zeng, Pan</dc:creator>
 <dc:creator>Elahe, Md Fazla</dc:creator>
 <dc:creator>Xu, Junlin</dc:creator>
 <dc:creator>Jin, Min</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Due to the limitation of data availability, traditional power load
forecasting methods focus more on studying the load variation pattern and the
influence of only a few factors such as temperature and holidays, which fail to
reveal the inner mechanism of load variation. This paper breaks the limitation
and collects 80 potential features from astronomy, geography, and society to
study the complex nexus between power load variation and influence factors,
based on which a short-term power load forecasting method is proposed. Case
studies show that, compared with the state-of-the-art methods, the proposed
method improves the forecasting accuracy by 33.0% to 34.7%. The forecasting
result reveals that geographical features have the most significant impact on
improving the load forecasting accuracy, in which temperature is the dominant
feature. Astronomical features have more significant influence than social
features and features related to the sun play an important role, which are
obviously ignored in previous research. Saturday and Monday are the most
important social features. Temperature, solar zenith angle, civil twilight
duration, and lagged clear sky global horizontal irradiance have a V-shape
relationship with power load, indicating that there exist balance points for
them. Global horizontal irradiance is negatively related to power load.
</dc:description>
 <dc:description>Comment: 8 pages, 10 figures</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12534</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12537</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A News Recommender System Considering Temporal Dynamics and Diversity</dc:title>
 <dc:creator>Raza, Shaina</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In a news recommender system, a reader's preferences change over time. Some
preferences drift quite abruptly (short-term preferences), while others change
over a longer period of time (long-term preferences). Although the existing
news recommender systems consider the reader's full history, they often ignore
the dynamics in the reader's behavior. Thus, they cannot meet the demand of the
news readers for their time-varying preferences. In addition, the
state-of-the-art news recommendation models are often focused on providing
accurate predictions, which can work well in traditional recommendation
scenarios. However, in a news recommender system, diversity is essential, not
only to keep news readers engaged, but also to play a key role in a democratic
society. In this PhD dissertation, our goal is to build a news recommender
system to address these two challenges. Our system should be able to: (i)
accommodate the dynamics in reader behavior; and (ii) consider both accuracy
and diversity in the design of the recommendation model. Our news recommender
system can also work for unprofiled, anonymous and short-term readers, by
leveraging the rich side information of the news items and by including the
implicit feedback in our model. We evaluate our model with multiple evaluation
measures (both accuracy and diversity-oriented metrics) to demonstrate the
effectiveness of our methods.
</dc:description>
 <dc:description>Comment: A doctoral symposium</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12537</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12542</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EmgAuth: Unlocking Smartphones with EMG Signals</dc:title>
 <dc:creator>Fan, Boyu</dc:creator>
 <dc:creator>Su, Xiang</dc:creator>
 <dc:creator>Niu, Jianwei</dc:creator>
 <dc:creator>Hui, Pan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Screen lock is a critical security feature for smartphones to prevent
unauthorized access. Although various screen unlocking technologies, including
fingerprint and facial recognition, have been widely adopted, they still have
some limitations. For example, fingerprints can be stolen by special material
stickers and facial recognition systems can be cheated by 3D-printed head
models. In this paper, we propose EmgAuth, a novel electromyography(EMG)-based
smartphone unlocking system based on the Siamese network. EmgAuth enables users
to unlock their smartphones by leveraging the EMG data of the smartphone users
collected from Myo armbands. When training the Siamese network, we design a
special data augmentation technique to make the system resilient to the
rotation of the armband, which makes EmgAuth free of calibration. We conduct
extensive experiments including 53 participants and the evaluation results
verify that EmgAuth can effectively authenticate users with an average true
acceptance rate of 91.81% while keeping the average false acceptance rate of
7.43%. In addition, we also demonstrate that EmgAuth can work well for
smartphones with different screen sizes and for different scenarios when users
are placing smartphones at different locations and with different orientations.
EmgAuth shows great promise to serve as a good supplement for existing screen
unlocking systems to improve the safety of smartphones.
</dc:description>
 <dc:description>Comment: 13 pages, 16 figures</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12542</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12545</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MetaHDR: Model-Agnostic Meta-Learning for HDR Image Reconstruction</dc:title>
 <dc:creator>Pan, Edwin</dc:creator>
 <dc:creator>Vento, Anthony</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Capturing scenes with a high dynamic range is crucial to reproducing images
that appear similar to those seen by the human visual system. Despite progress
in developing data-driven deep learning approaches for converting low dynamic
range images to high dynamic range images, existing approaches are limited by
the assumption that all conversions are governed by the same nonlinear mapping.
To address this problem, we propose &quot;Model-Agnostic Meta-Learning for HDR Image
Reconstruction&quot; (MetaHDR), which applies meta-learning to the LDR-to-HDR
conversion problem using existing HDR datasets. Our key novelty is the
reinterpretation of LDR-to-HDR conversion scenes as independently sampled tasks
from a common LDR-to-HDR conversion task distribution. Naturally, we use a
meta-learning framework that learns a set of meta-parameters which capture the
common structure consistent across all LDR-to-HDR conversion tasks. Finally, we
perform experimentation with MetaHDR to demonstrate its capacity to tackle
challenging LDR-to-HDR image conversions. Code and pretrained models are
available at https://github.com/edwin-pan/MetaHDR.
</dc:description>
 <dc:description>Comment: 7 pages, 6 figures, 2 tables</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12545</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12547</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A new public Alsat-2B dataset for single-image super-resolution</dc:title>
 <dc:creator>Djerida, Achraf</dc:creator>
 <dc:creator>Djerriri, Khelifa</dc:creator>
 <dc:creator>Karoui, Moussa Sofiane</dc:creator>
 <dc:creator>larabi, Mohammed El Amin</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Currently, when reliable training datasets are available, deep learning
methods dominate the proposed solutions for image super-resolution. However,
for remote sensing benchmarks, it is very expensive to obtain high spatial
resolution images. Most of the super-resolution methods use down-sampling
techniques to simulate low and high spatial resolution pairs and construct the
training samples. To solve this issue, the paper introduces a novel public
remote sensing dataset (Alsat2B) of low and high spatial resolution images (10m
and 2.5m respectively) for the single-image super-resolution task. The
high-resolution images are obtained through pan-sharpening. Besides, the
performance of some super-resolution methods on the dataset is assessed based
on common criteria. The obtained results reveal that the proposed scheme is
promising and highlight the challenges in the dataset which shows the need for
advanced methods to grasp the relationship between the low and high-resolution
patches.
</dc:description>
 <dc:description>Comment: This paper has been Accepted for publication in the International
  Geoscience and Remote Sensing Symposium (IGARSS 2021)</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12553</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Safe Multi-Agent Reinforcement Learning through Decentralized Multiple
  Control Barrier Functions</dc:title>
 <dc:creator>Cai, Zhiyuan</dc:creator>
 <dc:creator>Cao, Huanhui</dc:creator>
 <dc:creator>Lu, Wenjie</dc:creator>
 <dc:creator>Zhang, Lin</dc:creator>
 <dc:creator>Xiong, Hao</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Multi-Agent Reinforcement Learning (MARL) algorithms show amazing performance
in simulation in recent years, but placing MARL in real-world applications may
suffer safety problems. MARL with centralized shields was proposed and verified
in safety games recently. However, centralized shielding approaches can be
infeasible in several real-world multi-agent applications that involve
non-cooperative agents or communication delay. Thus, we propose to combine MARL
with decentralized Control Barrier Function (CBF) shields based on available
local information. We establish a safe MARL framework with decentralized
multiple CBFs and develop Multi-Agent Deep Deterministic Policy Gradient
(MADDPG) to Multi-Agent Deep Deterministic Policy Gradient with decentralized
multiple Control Barrier Functions (MADDPG-CBF). Based on a collision-avoidance
problem that includes not only cooperative agents but obstacles, we demonstrate
the construction of multiple CBFs with safety guarantees in theory. Experiments
are conducted and experiment results verify that the proposed safe MARL
framework can guarantee the safety of agents included in MARL.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12553</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12562</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transferable Semantic Augmentation for Domain Adaptation</dc:title>
 <dc:creator>Li, Shuang</dc:creator>
 <dc:creator>Xie, Mixue</dc:creator>
 <dc:creator>Gong, Kaixiong</dc:creator>
 <dc:creator>Liu, Chi Harold</dc:creator>
 <dc:creator>Wang, Yulin</dc:creator>
 <dc:creator>Li, Wei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Domain adaptation has been widely explored by transferring the knowledge from
a label-rich source domain to a related but unlabeled target domain. Most
existing domain adaptation algorithms attend to adapting feature
representations across two domains with the guidance of a shared
source-supervised classifier. However, such classifier limits the
generalization ability towards unlabeled target recognition. To remedy this, we
propose a Transferable Semantic Augmentation (TSA) approach to enhance the
classifier adaptation ability through implicitly generating source features
towards target semantics. Specifically, TSA is inspired by the fact that deep
feature transformation towards a certain direction can be represented as
meaningful semantic altering in the original input space. Thus, source features
can be augmented to effectively equip with target semantics to train a more
transferable classifier. To achieve this, for each class, we first use the
inter-domain feature mean difference and target intra-class feature covariance
to construct a multivariate normal distribution. Then we augment source
features with random directions sampled from the distribution class-wisely.
Interestingly, such source augmentation is implicitly implemented through an
expected transferable cross-entropy loss over the augmented source
distribution, where an upper bound of the expected loss is derived and
minimized, introducing negligible computational overhead. As a light-weight and
general technique, TSA can be easily plugged into various domain adaptation
methods, bringing remarkable improvements. Comprehensive experiments on
cross-domain benchmarks validate the efficacy of TSA.
</dc:description>
 <dc:description>Comment: Accepted as CVPR 2021. The code is publicly available at
  https://github.com/BIT-DA/TSA</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12562</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12567</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Iterative Super-Twisting Sliding Mode Control: A Case Study
  on Flexure-Joint Dual-Drive H-Gantry Stage</dc:title>
 <dc:creator>Wang, Wenxin</dc:creator>
 <dc:creator>Ma, Jun</dc:creator>
 <dc:creator>Cheng, Zilong</dc:creator>
 <dc:creator>Li, Xiaocong</dc:creator>
 <dc:creator>Mamun, Abdullah Al</dc:creator>
 <dc:creator>Lee, Tong Heng</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Mechatronic systems are commonly used in the industry, where fast and
accurate motion performance is always required to guarantee manufacturing
precision and efficiency. Nevertheless, the system model and parameters are
difficult to be obtained accurately. Moreover, the high-order modes, strong
coupling in the multi-axis systems, or unmodeled frictions will bring uncertain
dynamics to the system. To overcome the above-mentioned issues and enhance the
motion performance, this paper introduces a novel intelligent and totally
model-free control method for mechatronic systems with unknown dynamics. In
detail, a 2-degree-of-freedom (DOF) architecture is designed, which organically
merges a generalized super-twisting algorithm with a unique iterative learning
law. The controller solely utilizes the input-output data collected in
iterations such that it works without any knowledge of the system parameters.
The rigorous proof of convergence ability is given and a case study on
flexture-joint dual-drive H-gantry stage is shown to validate the effectiveness
of the proposed method.
</dc:description>
 <dc:description>Comment: 7 pages, 8 figures</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12567</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12575</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multimodal Personal Ear Authentication Using Smartphones</dc:title>
 <dc:creator>Itani, S.</dc:creator>
 <dc:creator>Kita, S.</dc:creator>
 <dc:creator>Kajikawa, Y.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  In recent years, biometric authentication technology for smartphones has
become widespread, with the mainstream methods being fingerprint authentication
and face recognition. However, fingerprint authentication cannot be used when
hands are wet, and face recognition cannot be used when a person is wearing a
mask. Therefore, we examine a personal authentication system using the pinna as
a new approach for biometric authentication on smartphones. Authentication
systems based on the acoustic transfer function of the pinna (PRTF: Pinna
Related Transfer Function) have been investigated. However, the authentication
accuracy decreases due to the positional fluctuation across each measurement.
In this paper, we propose multimodal personal authentication on smartphones
using PRTF. The pinna image and positional sensor information are used with the
PRTF, and the effectiveness of the authentication method is examined. We
demonstrate that the proposed authentication system can compensate for the
positional changes in each measurement and improve robustness.
</dc:description>
 <dc:description>Comment: 9 pages, 23 figures</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12575</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12576</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards interpretability of Mixtures of Hidden Markov Models</dc:title>
 <dc:creator>Safinianaini, Negar</dc:creator>
 <dc:creator>Bostr&#xf6;m, Henrik</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Mixtures of Hidden Markov Models (MHMMs) are frequently used for clustering
of sequential data. An important aspect of MHMMs, as of any clustering
approach, is that they can be interpretable, allowing for novel insights to be
gained from the data. However, without a proper way of measuring
interpretability, the evaluation of novel contributions is difficult and it
becomes practically impossible to devise techniques that directly optimize this
property. In this work, an information-theoretic measure (entropy) is proposed
for interpretability of MHMMs, and based on that, a novel approach to improve
model interpretability is proposed, i.e., an entropy-regularized Expectation
Maximization (EM) algorithm. The new approach aims for reducing the entropy of
the Markov chains (involving state transition matrices) within an MHMM, i.e.,
assigning higher weights to common state transitions during clustering. It is
argued that this entropy reduction, in general, leads to improved
interpretability since the most influential and important state transitions of
the clusters can be more easily identified. An empirical investigation shows
that it is possible to improve the interpretability of MHMMs, as measured by
entropy, without sacrificing (but rather improving) clustering performance and
computational costs, as measured by the v-measure and number of EM iterations,
respectively.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12576</dc:identifier>
 <dc:identifier>AAAI Workshop XAI (2021) 4-10</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12585</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pursuing robust decisions in uncertain traffic equilibrium problems</dc:title>
 <dc:creator>Fabiani, Filippo</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We evaluate the robustness of agents' traffic equilibria in randomized
routing games characterized by an uncertain network demand with a possibly
unknown probability distribution. Specifically, we extend the so-called hose
model by considering a traffic equilibrium model where the uncertain network
demand configuration belongs to a polyhedral set, whose shape is itself
a-priori unknown. By exploiting available data, we apply the scenario approach
theory to establish distribution-free feasibility guarantees for agents'
traffic equilibria of the uncertain routing game without the need to know an
explicit characterization of such set. A numerical example on a traffic network
testbed corroborates the proposed theoretical results.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12585</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12593</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accurate and efficient time-domain classification with adaptive spiking
  recurrent neural networks</dc:title>
 <dc:creator>Yin, Bojian</dc:creator>
 <dc:creator>Corradi, Federico</dc:creator>
 <dc:creator>Bohte, Sander M.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Inspired by more detailed modeling of biological neurons, Spiking neural
networks (SNNs) have been investigated both as more biologically plausible and
potentially more powerful models of neural computation, and also with the aim
of extracting biological neurons' energy efficiency; the performance of such
networks however has remained lacking compared to classical artificial neural
networks (ANNs). Here, we demonstrate how a novel surrogate gradient combined
with recurrent networks of tunable and adaptive spiking neurons yields
state-of-the-art for SNNs on challenging benchmarks in the time-domain, like
speech and gesture recognition. This also exceeds the performance of standard
classical recurrent neural networks (RNNs) and approaches that of the best
modern ANNs. As these SNNs exhibit sparse spiking, we show that they
theoretically are one to three orders of magnitude more computationally
efficient compared to RNNs with comparable performance. Together, this
positions SNNs as an attractive solution for AI hardware implementations.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2021-03-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12593</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12594</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid Edge Partitioner: Partitioning Large Power-Law Graphs under
  Memory Constraints</dc:title>
 <dc:creator>Mayer, Ruben</dc:creator>
 <dc:creator>Jacobsen, Hans-Arno</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Distributed systems that manage and process graph-structured data internally
solve a graph partitioning problem to minimize their communication overhead and
query run-time. Besides computational complexity -- optimal graph partitioning
is NP-hard -- another important consideration is the memory overhead.
Real-world graphs often have an immense size, such that loading the complete
graph into memory for partitioning is not economical or feasible. Currently,
the common approach to reduce memory overhead is to rely on streaming
partitioning algorithms. While the latest streaming algorithms lead to
reasonable partitioning quality on some graphs, they are still not completely
competitive to in-memory partitioners. In this paper, we propose a new system,
Hybrid Edge Partitioner (HEP), that can partition graphs that fit partly into
memory while yielding a high partitioning quality. HEP can flexibly adapt its
memory overhead by separating the edge set of the graph into two sub-sets. One
sub-set is partitioned by NE++, a novel, efficient in-memory algorithm, while
the other sub-set is partitioned by a streaming approach. Our evaluations on
large real-world graphs show that in many cases, HEP outperforms both in-memory
partitioning and streaming partitioning at the same time. Hence, HEP is an
attractive alternative to existing solutions that cannot fine-tune their memory
overheads. Finally, we show that using HEP, we achieve a significant speedup of
distributed graph processing jobs on Spark/GraphX compared to state-of-the-art
partitioning algorithms.
</dc:description>
 <dc:description>Comment: SIGMOD 2021, 14 pages</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12594</dc:identifier>
 <dc:identifier>doi:10.1145/3448016.3457300</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12595</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An augmentation strategy to mimic multi-scanner variability in MRI</dc:title>
 <dc:creator>Meyer, Maria Ines</dc:creator>
 <dc:creator>de la Rosa, Ezequiel</dc:creator>
 <dc:creator>Barros, Nuno</dc:creator>
 <dc:creator>Paolella, Roberto</dc:creator>
 <dc:creator>Van Leemput, Koen</dc:creator>
 <dc:creator>Sima, Diana M.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Most publicly available brain MRI datasets are very homogeneous in terms of
scanner and protocols, and it is difficult for models that learn from such data
to generalize to multi-center and multi-scanner data. We propose a novel data
augmentation approach with the aim of approximating the variability in terms of
intensities and contrasts present in real world clinical data. We use a
Gaussian Mixture Model based approach to change tissue intensities
individually, producing new contrasts while preserving anatomical information.
We train a deep learning model on a single scanner dataset and evaluate it on a
multi-center and multi-scanner dataset. The proposed approach improves the
generalization capability of the model to other scanners not present in the
training data.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures. accepted for presentation at the International
  Symposium on Biomedical Imaging (ISBI) 2021. Code available at
  https://github.com/icometrix/gmm-augmentation</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12595</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12605</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MonoRUn: Monocular 3D Object Detection by Reconstruction and Uncertainty
  Propagation</dc:title>
 <dc:creator>Chen, Hansheng</dc:creator>
 <dc:creator>Huang, Yuyao</dc:creator>
 <dc:creator>Tian, Wei</dc:creator>
 <dc:creator>Gao, Zhong</dc:creator>
 <dc:creator>Xiong, Lu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Object localization in 3D space is a challenging aspect in monocular 3D
object detection. Recent advances in 6DoF pose estimation have shown that
predicting dense 2D-3D correspondence maps between image and object 3D model
and then estimating object pose via Perspective-n-Point (PnP) algorithm can
achieve remarkable localization accuracy. Yet these methods rely on training
with ground truth of object geometry, which is difficult to acquire in real
outdoor scenes. To address this issue, we propose MonoRUn, a novel detection
framework that learns dense correspondences and geometry in a self-supervised
manner, with simple 3D bounding box annotations. To regress the pixel-related
3D object coordinates, we employ a regional reconstruction network with
uncertainty awareness. For self-supervised training, the predicted 3D
coordinates are projected back to the image plane. A Robust KL loss is proposed
to minimize the uncertainty-weighted reprojection error. During testing phase,
we exploit the network uncertainty by propagating it through all downstream
modules. More specifically, the uncertainty-driven PnP algorithm is leveraged
to estimate object pose and its covariance. Extensive experiments demonstrate
that our proposed approach outperforms current state-of-the-art methods on
KITTI benchmark.
</dc:description>
 <dc:description>Comment: CVPR 2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12605</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12607</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ESCORT: Ethereum Smart COntRacTs Vulnerability Detection using Deep
  Neural Network and Transfer Learning</dc:title>
 <dc:creator>Lutz, Oliver</dc:creator>
 <dc:creator>Chen, Huili</dc:creator>
 <dc:creator>Fereidooni, Hossein</dc:creator>
 <dc:creator>Sendner, Christoph</dc:creator>
 <dc:creator>Dmitrienko, Alexandra</dc:creator>
 <dc:creator>Sadeghi, Ahmad Reza</dc:creator>
 <dc:creator>Koushanfar, Farinaz</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Ethereum smart contracts are automated decentralized applications on the
blockchain that describe the terms of the agreement between buyers and sellers,
reducing the need for trusted intermediaries and arbitration. However, the
deployment of smart contracts introduces new attack vectors into the
cryptocurrency systems. In particular, programming flaws in smart contracts can
be and have already been exploited to gain enormous financial profits. It is
thus an emerging yet crucial issue to detect vulnerabilities of different
classes in contracts in an efficient manner. Existing machine learning-based
vulnerability detection methods are limited and only inspect whether the smart
contract is vulnerable, or train individual classifiers for each specific
vulnerability, or demonstrate multi-class vulnerability detection without
extensibility consideration. To overcome the scalability and generalization
limitations of existing works, we propose ESCORT, the first Deep Neural Network
(DNN)-based vulnerability detection framework for Ethereum smart contracts that
support lightweight transfer learning on unseen security vulnerabilities, thus
is extensible and generalizable. ESCORT leverages a multi-output NN
architecture that consists of two parts: (i) A common feature extractor that
learns the semantics of the input contract; (ii) Multiple branch structures
where each branch learns a specific vulnerability type based on features
obtained from the feature extractor. Experimental results show that ESCORT
achieves an average F1-score of 95% on six vulnerability types and the
detection time is 0.02 seconds per contract. When extended to new vulnerability
types, ESCORT yields an average F1-score of 93%. To the best of our knowledge,
ESCORT is the first framework that enables transfer learning on new
vulnerability types with minimal modification of the DNN model architecture and
re-training overhead.
</dc:description>
 <dc:description>Comment: 17 pages, 10 figures, 5 tables, 5 equations, 2 listings</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12609</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incrementally Zero-Shot Detection by an Extreme Value Analyzer</dc:title>
 <dc:creator>Zheng, Sixiao</dc:creator>
 <dc:creator>Fu, Yanwei</dc:creator>
 <dc:creator>Hou, Yanxi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Human beings not only have the ability to recognize novel unseen classes, but
also can incrementally incorporate the new classes to existing knowledge
preserved. However, zero-shot learning models assume that all seen classes
should be known beforehand, while incremental learning models cannot recognize
unseen classes. This paper introduces a novel and challenging task of
Incrementally Zero-Shot Detection (IZSD), a practical strategy for both
zero-shot learning and class-incremental learning in real-world object
detection. An innovative end-to-end model -- IZSD-EVer was proposed to tackle
this task that requires incrementally detecting new classes and detecting the
classes that have never been seen. Specifically, we propose a novel extreme
value analyzer to detect objects from old seen, new seen, and unseen classes,
simultaneously. Additionally and technically, we propose two innovative losses,
i.e., background-foreground mean squared error loss alleviating the extreme
imbalance of the background and foreground of images, and projection distance
loss aligning the visual space and semantic spaces of old seen classes.
Experiments demonstrate the efficacy of our model in detecting objects from
both the seen and unseen classes, outperforming the alternative models on
Pascal VOC and MSCOCO datasets.
</dc:description>
 <dc:description>Comment: International Conference on Pattern Recognition (ICPR)</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12609</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12614</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decentralized Connectivity Maintenance with Time Delays using Control
  Barrier Functions</dc:title>
 <dc:creator>Capelli, Beatrice</dc:creator>
 <dc:creator>Fouad, Hassan</dc:creator>
 <dc:creator>Beltrame, Giovanni</dc:creator>
 <dc:creator>Sabattini, Lorenzo</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Connectivity maintenance is crucial for the real world deployment of
multi-robot systems, as it ultimately allows the robots to communicate,
coordinate and perform tasks in a collaborative way. A connectivity maintenance
controller must keep the multi-robot system connected independently from the
system's mission and in the presence of undesired real world effects such as
communication delays, model errors, and computational time delays, among
others. In this paper we present the implementation, on a real robotic setup,
of a connectivity maintenance control strategy based on Control Barrier
Functions. During experimentation, we found that the presence of communication
delays has a significant impact on the performance of the controlled system,
with respect to the ideal case. We propose a heuristic to counteract the
effects of communication delays, and we verify its efficacy both in simulation
and with physical robot experiments.
</dc:description>
 <dc:description>Comment: Proceedings of International Conference on Robotics and Automation
  (ICRA) 2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12614</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12615</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A General Framework for Learning Prosodic-Enhanced Representation of Rap
  Lyrics</dc:title>
 <dc:creator>Liang, Hongru</dc:creator>
 <dc:creator>Wang, Haozheng</dc:creator>
 <dc:creator>Li, Qian</dc:creator>
 <dc:creator>Wang, Jun</dc:creator>
 <dc:creator>Xu, Guandong</dc:creator>
 <dc:creator>Chen, Jiawei</dc:creator>
 <dc:creator>Wei, Jin-Mao</dc:creator>
 <dc:creator>Yang, Zhenglu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Learning and analyzing rap lyrics is a significant basis for many web
applications, such as music recommendation, automatic music categorization, and
music information retrieval, due to the abundant source of digital music in the
World Wide Web. Although numerous studies have explored the topic, knowledge in
this field is far from satisfactory, because critical issues, such as prosodic
information and its effective representation, as well as appropriate
integration of various features, are usually ignored. In this paper, we propose
a hierarchical attention variational autoencoder framework (HAVAE), which
simultaneously consider semantic and prosodic features for rap lyrics
representation learning. Specifically, the representation of the prosodic
features is encoded by phonetic transcriptions with a novel and effective
strategy~(i.e., rhyme2vec). Moreover, a feature aggregation strategy is
proposed to appropriately integrate various features and generate
prosodic-enhanced representation. A comprehensive empirical evaluation
demonstrates that the proposed framework outperforms the state-of-the-art
approaches under various metrics in different rap lyrics learning tasks.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12615</dc:identifier>
 <dc:identifier>doi:10.1007/s11280-019-00672-2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12616</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Multilinear Map from Graded Encoding Scheme</dc:title>
 <dc:creator>Salimi, Majid</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Though the multilinear maps have many cryptographic applications, secure and
efficient construction of such maps is an open problem. Many multilinear maps
like GGH, GGH15, CLT, and CLT15 have been and are being proposed, while none of
them is both secure and efficient. The construction of some multilinear maps is
based on the Graded Encoding Scheme (GES), where, the necessity of announcing
zero-testing parameter and encoding of zero has destroyed the security of the
multilinear map.
  Attempt is made to propose a new GES, where, instead of encoding an element,
the users can obtain the encoding of an associated but unknown random element.
In this new setting, there is no need to publish the encodings of zero and one.
This new GES provides the actual functionality of the usual GES and can be
applied in constructing a secure and efficient multilinear map and a
multi-party non-interactive key exchange (MP-NIKE) scheme. We also improve the
MP-NIKE scheme of \cite{Access20} and turn it into an ID-based MP-NIKE scheme.
</dc:description>
 <dc:description>Comment: 15 pagess</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12616</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12623</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evolving Learning Rate Optimizers for Deep Neural Networks</dc:title>
 <dc:creator>Carvalho, Pedro</dc:creator>
 <dc:creator>Louren&#xe7;o, Nuno</dc:creator>
 <dc:creator>Machado, Penousal</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>68W50 (Primary), 68T05 (Secondary)</dc:subject>
 <dc:description>  Artificial Neural Networks (ANNs) became popular due to their successful
application difficult problems such image and speech recognition. However, when
practitioners want to design an ANN they need to undergo laborious process of
selecting a set of parameters and topology. Currently, there are several
state-of-the art methods that allow for the automatic selection of some of
these aspects. Learning Rate optimizers are a set of such techniques that
search for good values of learning rates. Whilst these techniques are effective
and have yielded good results over the years, they are general solution i.e.
they do not consider the characteristics of a specific network.
  We propose a framework called AutoLR to automatically design Learning Rate
Optimizers. Two versions of the system are detailed. The first one, Dynamic
AutoLR, evolves static and dynamic learning rate optimizers based on the
current epoch and the previous learning rate. The second version, Adaptive
AutoLR, evolves adaptive optimizers that can fine tune the learning rate for
each network eeight which makes them generally more effective. The results are
competitive with the best state of the art methods, even outperforming them in
some scenarios. Furthermore, the system evolved a classifier, ADES, that
appears to be novel and innovative since, to the best of our knowledge, it has
a structure that differs from state of the art methods.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12623</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12624</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Genetic column generation: Fast computation of high-dimensional
  multi-marginal optimal transport problems</dc:title>
 <dc:creator>Friesecke, Gero</dc:creator>
 <dc:creator>Schulz, Andreas S.</dc:creator>
 <dc:creator>V&#xf6;gler, Daniela</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We introduce a simple, accurate, and extremely efficient method for
numerically solving the multi-marginal optimal transport (MMOT) problems
arising in density functional theory. The method relies on (i) the sparsity of
optimal plans [for $N$ marginals discretized by $\ell$ gridpoints each, general
Kantorovich plans require $\ell^N$ gridpoints but the support of optimizers is
of size $O(\ell\cdot N)$ [FV18]], (ii) the method of column generation (CG)
from discrete optimization which to our knowledge has not hitherto been used in
MMOT, and (iii) ideas from machine learning. The well-known bottleneck in CG
consists in generating new candidate columns efficiently; we prove that in our
context, finding the best new column is an NP-complete problem. To overcome
this bottleneck we use a genetic learning method tailormade for MMOT in which
the dual state within CG plays the role of an &quot;adversary&quot;, in loose similarity
to Wasserstein GANs. On a sequence of benchmark problems with up to 120
gridpoints and up to 30 marginals, our method always found the exact
optimizers. Moreover, empirically the number of computational steps needed to
find them appears to scale only polynomially when both $N$ and $\ell$ are
simultaneously increased (while keeping their ratio fixed to mimic a
thermodynamic limit of the particle system).
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12628</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Are all outliers alike? On Understanding the Diversity of Outliers for
  Detecting OODs</dc:title>
 <dc:creator>Kaur, Ramneet</dc:creator>
 <dc:creator>Jha, Susmit</dc:creator>
 <dc:creator>Roy, Anirban</dc:creator>
 <dc:creator>Sokolsky, Oleg</dc:creator>
 <dc:creator>Lee, Insup</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Deep neural networks (DNNs) are known to produce incorrect predictions with
very high confidence on out-of-distribution (OOD) inputs. This limitation is
one of the key challenges in the adoption of deep learning models in
high-assurance systems such as autonomous driving, air traffic management, and
medical diagnosis. This challenge has received significant attention recently,
and several techniques have been developed to detect inputs where the model's
prediction cannot be trusted. These techniques use different statistical,
geometric, or topological signatures. This paper presents a taxonomy of OOD
outlier inputs based on their source and nature of uncertainty. We demonstrate
how different existing detection approaches fail to detect certain types of
outliers. We utilize these insights to develop a novel integrated detection
approach that uses multiple attributes corresponding to different types of
outliers. Our results include experiments on CIFAR10, SVHN and MNIST as
in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for
SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such
as ResNet34, WideResNet, DenseNet, and LeNet5.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12628</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12633</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GA-SVM for Evaluating Heroin Consumption Risk</dc:title>
 <dc:creator>Palicki, Sean-Kelly</dc:creator>
 <dc:creator>Azad, R. Muhammad Atif</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  There were over 70,000 drug overdose deaths in the USA in 2017. Almost half
of those involved the use of Opioids such as Heroin. This research supports
efforts to combat the Opioid Epidemic by further understanding factors that
lead to Heroin consumption. Previous research has debated the cause of Heroin
addiction, with some explaining the phenomenon as a transition from
prescription Opioids, and others pointing to various psycho-social factors.
This research used self-reported information about personality, demographics
and drug consumption behavior to predict Heroin consumption. By applying a
Support Vector Machine algorithm optimized with a Genetic Algorithm (GA-SVM
Hybrid) to simultaneously identify predictive features and model parameters,
this research produced several models that were more accurate in predicting
Heroin use than those produced in previous studies. Although all factors had
predictive power, these results showed that consumption of other drugs (both
prescription and illicit) were stronger predictors of Heroin use than
psycho-social factors. The use of prescription drugs as a strong predictor of
Heroin use is an important though disturbing discovery but that can help combat
Heroin use.
</dc:description>
 <dc:description>Comment: Genetic Algorithm, Feature Selection, Applied Computing, Psychology</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12633</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12641</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pairwise Adjusted Mutual Information</dc:title>
 <dc:creator>Lazarenko, Denys</dc:creator>
 <dc:creator>Bonald, Thomas</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  A well-known metric for quantifying the similarity between two clusterings is
the adjusted mutual information. Compared to mutual information, a corrective
term based on random permutations of the labels is introduced, preventing two
clusterings being similar by chance. Unfortunately, this adjustment makes the
metric computationally expensive. In this paper, we propose a novel adjustment
based on {pairwise} label permutations instead of full label permutations.
Specifically, we consider permutations where only two samples, selected
uniformly at random, exchange their labels. We show that the corresponding
adjusted metric, which can be expressed explicitly, behaves similarly to the
standard adjusted mutual information for assessing the quality of a clustering,
while having a much lower time complexity. Both metrics are compared in terms
of quality and performance on experiments based on synthetic and real data.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12645</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FoamFactor: Hydrogel-Foam Composite with Tunable Stiffness and
  Compressibility</dc:title>
 <dc:creator>Yang, Humphrey</dc:creator>
 <dc:creator>Yan, Zeyu</dc:creator>
 <dc:creator>Luo, Danli</dc:creator>
 <dc:creator>Yao, Lining</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.m</dc:subject>
 <dc:description>  This paper presents FoamFactor, a novel material with tunable stiffness and
compressibility between hydration states, and a tailored pipeline to design and
fabricate artifacts consisting of it. This technique compounds hydrogel with
open-cell foams via additive manufacturing to produce a water-responsive
composite material. Enabled by the large volumetric changes of hydrogel
dispersions, the material is soft and compressible when dehydrated and becomes
stiffer and rather incompressible when hydrated. Leveraging this material
property transition, we explore its design space in various aspects pertaining
to the transition of hydration states, including multi-functional shoes,
amphibious cars, mechanical transmission systems, and self-deploying robotic
grippers.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12645</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12670</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What is the Vocabulary of Flaky Tests? An Extended Replication</dc:title>
 <dc:creator>Camara, B. H. P.</dc:creator>
 <dc:creator>Silva, M. A. G.</dc:creator>
 <dc:creator>Endo, A. T.</dc:creator>
 <dc:creator>Vergilio, S. R.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Software systems have been continuously evolved and delivered with high
quality due to the widespread adoption of automated tests. A recurring issue
hurting this scenario is the presence of flaky tests, a test case that may pass
or fail non-deterministically. A promising, but yet lacking more empirical
evidence, approach is to collect static data of automated tests and use them to
predict their flakiness. In this paper, we conducted an empirical study to
assess the use of code identifiers to predict test flakiness. To do so, we
first replicate most parts of the previous study of Pinto~et~al.~(MSR~2020).
This replication was extended by using a different ML Python platform
(Scikit-learn) and adding different learning algorithms in the analyses. Then,
we validated the performance of trained models using datasets with other flaky
tests and from different projects. We successfully replicated the results of
Pinto~et~al.~(2020), with minor differences using Scikit-learn; different
algorithms had performance similar to the ones used previously. Concerning the
validation, we noticed that the recall of the trained models was smaller, and
classifiers presented a varying range of decreases. This was observed in both
intra-project and inter-projects test flakiness prediction.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12670</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12672</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Out-of-Distribution Detection of Melanoma using Normalizing Flows</dc:title>
 <dc:creator>Valiuddin, M. M. A.</dc:creator>
 <dc:creator>Viviers, C. G. A.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Generative modelling has been a topic at the forefront of machine learning
research for a substantial amount of time. With the recent success in the field
of machine learning, especially in deep learning, there has been an increased
interest in explainable and interpretable machine learning. The ability to
model distributions and provide insight in the density estimation and exact
data likelihood is an example of such a feature. Normalizing Flows (NFs), a
relatively new research field of generative modelling, has received substantial
attention since it is able to do exactly this at a relatively low cost whilst
enabling competitive generative results. While the generative abilities of NFs
are typically explored, we focus on exploring the data distribution modelling
for Out-of-Distribution (OOD) detection. Using one of the state-of-the-art NF
models, GLOW, we attempt to detect OOD examples in the ISIC dataset. We notice
that this model under performs in conform related research. To improve the OOD
detection, we explore the masking methods to inhibit co-adaptation of the
coupling layers however find no substantial improvement. Furthermore, we
utilize Wavelet Flow which uses wavelets that can filter particular frequency
components, thus simplifying the modeling process to data-driven conditional
wavelet coefficients instead of complete images. This enables us to efficiently
model larger resolution images in the hopes that it would capture more relevant
features for OOD. The paper that introduced Wavelet Flow mainly focuses on its
ability of sampling high resolution images and did not treat OOD detection. We
present the results and propose several ideas for improvement such as
controlling frequency components, using different wavelets and using other
state-of-the-art NF architectures.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12672</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12681</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Distributed Active Set Method for Model Predictive Control</dc:title>
 <dc:creator>Stomberg, G&#xf6;sta</dc:creator>
 <dc:creator>Engelmann, Alexander</dc:creator>
 <dc:creator>Faulwasser, Timm</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents a novel distributed active set method for model
predictive control of linear systems. The method combines a primal active set
strategy with a decentralized conjugate gradient method to solve convex
quadratic programs. An advantage of the proposed method compared to existing
distributed model predictive algorithms is the primal feasibility of the
iterates. Numerical results show that the proposed method can compete with the
alternating direction method of multipliers in terms of communication
requirements for a chain of masses example.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12682</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to decay your learning rate</dc:title>
 <dc:creator>Lewkowycz, Aitor</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Complex learning rate schedules have become an integral part of deep
learning. We find empirically that common fine-tuned schedules decay the
learning rate after the weight norm bounces. This leads to the proposal of
ABEL: an automatic scheduler which decays the learning rate by keeping track of
the weight norm. ABEL's performance matches that of tuned schedules and is more
robust with respect to its parameters. Through extensive experiments in vision,
NLP, and RL, we show that if the weight norm does not bounce, we can simplify
schedules even further with no loss in performance. In such cases, a complex
schedule has similar performance to a constant learning rate with a decay at
the end of training.
</dc:description>
 <dc:description>Comment: 9 + 14 pages, 5 + 11 figures</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12685</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative Minimization Networks: Training GANs Without Competition</dc:title>
 <dc:creator>Grnarova, Paulina</dc:creator>
 <dc:creator>Kilcher, Yannic</dc:creator>
 <dc:creator>Levy, Kfir Y.</dc:creator>
 <dc:creator>Lucchi, Aurelien</dc:creator>
 <dc:creator>Hofmann, Thomas</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Many applications in machine learning can be framed as minimization problems
and solved efficiently using gradient-based techniques. However, recent
applications of generative models, particularly GANs, have triggered interest
in solving min-max games for which standard optimization techniques are often
not suitable. Among known problems experienced by practitioners is the lack of
convergence guarantees or convergence to a non-optimum cycle. At the heart of
these problems is the min-max structure of the GAN objective which creates
non-trivial dependencies between the players. We propose to address this
problem by optimizing a different objective that circumvents the min-max
structure using the notion of duality gap from game theory. We provide novel
convergence guarantees on this objective and demonstrate why the obtained limit
point solves the problem better than known techniques.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12685</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12687</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating Dissemination and Implementation Strategies to Develop
  Clinical Software</dc:title>
 <dc:creator>M&#xe1;rquez, Gast&#xf3;n</dc:creator>
 <dc:creator>Taramasco, Carla</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Clinical software has become a significant contribution to support clinical
management and intra-hospital processes. In this regard, the success or failure
of clinical software is mostly yielded on a suitable requirements elicitation
process. Although several techniques and approaches address this process, the
complexity of clinical services and the variety of clinicians involved in those
services make it challenging to elicit requirements. To address this concern,
in our previous work, we have proposed the D&amp;I Framework. This collaborative
technique translates clinical priorities into guidelines for eliciting software
requirements in the healthcare context using implementation and dissemination
strategies. This article evaluates the functionalities and tasks implemented in
a clinical bed management system whose requirements were elicited using the D&amp;I
Framework. We focused on evaluating clinicians' usability expectation levels
using a specific questionnaire executed in 2018 and 2020. The results show
that, in comparison with the first release (2018) and the last one (2020),
clinicians perceive an improvement in the functionalities and tasks implemented
in the system. This study introduces the effects of implementation and
dissemination strategies to elicit pragmatic clinical requirements.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12687</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12694</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Meta-Adversarial Inverse Reinforcement Learning for Decision-making
  Tasks</dc:title>
 <dc:creator>Wang, Pin</dc:creator>
 <dc:creator>Li, Hanhan</dc:creator>
 <dc:creator>Chan, Ching-Yao</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Learning from demonstrations has made great progress over the past few years.
However, it is generally data hungry and task specific. In other words, it
requires a large amount of data to train a decent model on a particular task,
and the model often fails to generalize to new tasks that have a different
distribution. In practice, demonstrations from new tasks will be continuously
observed and the data might be unlabeled or only partially labeled. Therefore,
it is desirable for the trained model to adapt to new tasks that have limited
data samples available. In this work, we build an adaptable imitation learning
model based on the integration of Meta-learning and Adversarial Inverse
Reinforcement Learning (Meta-AIRL). We exploit the adversarial learning and
inverse reinforcement learning mechanisms to learn policies and reward
functions simultaneously from available training tasks and then adapt them to
new tasks with the meta-learning framework. Simulation results show that the
adapted policy trained with Meta-AIRL can effectively learn from limited number
of demonstrations, and quickly reach the performance comparable to that of the
experts on unseen tasks.
</dc:description>
 <dc:description>Comment: 2021 International Conference on Robotics and Automation (ICRA 2021)</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12694</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12702</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Considerations and Challenges of Measuring Operator Performance in
  Telepresence and Teleoperation Entailing Mixed Reality Technologies</dc:title>
 <dc:creator>Triantafyllidis, Eleftherios</dc:creator>
 <dc:creator>Li, Zhibin</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Assessing human performance in robotic scenarios such as those seen in
telepresence and teleoperation has always been a challenging task. With the
recent spike in mixed reality technologies and the subsequent focus by
researchers, new pathways have opened in elucidating human perception and
maximising overall immersion. Yet with the multitude of different assessment
methods in evaluating operator performance in virtual environments within the
field of HCI and HRI, inter-study comparability and transferability are
limited. In this short paper, we present a brief overview of existing methods
in assessing operator performance including subjective and objective approaches
while also attempting to capture future technical challenges and frontiers. The
ultimate goal is to assist and pinpoint readers towards potentially important
directions with the future hope of providing a unified immersion framework for
teleoperation and telepresence by standardizing a set of guidelines and
evaluation methods.
</dc:description>
 <dc:description>Comment: Accepted at ACM CHI 2021 Conference on Human Factors in Computing
  Systems Workshop CHI' 21 (Evaluating User Experiences in Mixed Reality)</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12702</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12703</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PanGEA: The Panoramic Graph Environment Annotation Toolkit</dc:title>
 <dc:creator>Ku, Alexander</dc:creator>
 <dc:creator>Anderson, Peter</dc:creator>
 <dc:creator>Pont-Tuset, Jordi</dc:creator>
 <dc:creator>Baldridge, Jason</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  PanGEA, the Panoramic Graph Environment Annotation toolkit, is a lightweight
toolkit for collecting speech and text annotations in photo-realistic 3D
environments. PanGEA immerses annotators in a web-based simulation and allows
them to move around easily as they speak and/or listen. It includes database
and cloud storage integration, plus utilities for automatically aligning
recorded speech with manual transcriptions and the virtual pose of the
annotators. Out of the box, PanGEA supports two tasks -- collecting navigation
instructions and navigation instruction following -- and it could be easily
adapted for annotating walking tours, finding and labeling landmarks or
objects, and similar tasks. We share best practices learned from using PanGEA
in a 20,000 hour annotation effort to collect the Room-Across-Room dataset. We
hope that our open-source annotation toolkit and insights will both expedite
future data collection efforts and spur innovation on the kinds of grounded
language tasks such environments can support.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12718</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Supervised Pretraining Improves Self-Supervised Pretraining</dc:title>
 <dc:creator>Reed, Colorado J.</dc:creator>
 <dc:creator>Yue, Xiangyu</dc:creator>
 <dc:creator>Nrusimha, Ani</dc:creator>
 <dc:creator>Ebrahimi, Sayna</dc:creator>
 <dc:creator>Vijaykumar, Vivek</dc:creator>
 <dc:creator>Mao, Richard</dc:creator>
 <dc:creator>Li, Bo</dc:creator>
 <dc:creator>Zhang, Shanghang</dc:creator>
 <dc:creator>Guillory, Devin</dc:creator>
 <dc:creator>Metzger, Sean</dc:creator>
 <dc:creator>Keutzer, Kurt</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While self-supervised pretraining has proven beneficial for many computer
vision tasks, it requires expensive and lengthy computation, large amounts of
data, and is sensitive to data augmentation. Prior work demonstrates that
models pretrained on datasets dissimilar to their target data, such as chest
X-ray models trained on ImageNet, underperform models trained from scratch.
Users that lack the resources to pretrain must use existing models with lower
performance. This paper explores Hierarchical PreTraining (HPT), which
decreases convergence time and improves accuracy by initializing the
pretraining process with an existing pretrained model. Through experimentation
on 16 diverse vision datasets, we show HPT converges up to 80x faster, improves
accuracy across tasks, and improves the robustness of the self-supervised
pretraining process to changes in the image augmentation policy or amount of
pretraining data. Taken together, HPT provides a simple framework for obtaining
better pretrained representations with less computational resources.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12720</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Energy Efficiency: Power Allocation and Outage Analysis for
  SWIPT-in-DAS based IoT</dc:title>
 <dc:creator>Bulla, Aaqib</dc:creator>
 <dc:creator>Shah, Shahid M</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  In this paper we study secure energy efficiency (SEE) for simultaneous
wireless information and power transfer (SWIPT) in a distributed antenna system
(DAS) based IoT network. We consider a system in which both legitimate users
(Bobs) and eavesdroppers (Eves) have power splitting (PS) receivers to
simultaneously decode information and harvest energy from the received signal.
When the channel state information (CSI) is known at the transmitter, we
analyze the effect of an energy harvesting eavesdropper (EHE) over the
maximization of SEE of the system. Next, considering the fact that perfect CSI
is hard to achieve in practice, we characterize the system performance in terms
of the outage probability of SEE. For the given SWIPT-in-DAS setup, we derive
the closed form expression for the outage probability of SEE and with the help
of numerical results, we study the effect of transmit power levels, number of
distributed antenna (DA) ports and the PS ratio of devices. To the best of our
knowledge, this is the first attempt to define the outage probability of SEE
for SWIPT-in-DAS.
</dc:description>
 <dc:description>Comment: Submitted to a journal for possible publication</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12720</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12721</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strictly Decentralized Adaptive Estimation of External Fields using
  Reproducing Kernels</dc:title>
 <dc:creator>Guo, Jia</dc:creator>
 <dc:creator>Kepler, Michael E.</dc:creator>
 <dc:creator>Paruchuri, Sai Tej</dc:creator>
 <dc:creator>Wang, Haoran</dc:creator>
 <dc:creator>Kurdila, Andrew J.</dc:creator>
 <dc:creator>Stilwell, Daniel J.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper describes an adaptive method in continuous time for the estimation
of external fields by a team of $N$ agents. The agents $i$ each explore
subdomains $\Omega^i$ of a bounded subset of interest $\Omega\subset X :=
\mathbb{R}^d$. Ideal adaptive estimates $\hat{g}^i_t$ are derived for each
agent from a distributed parameter system (DPS) that takes values in the
scalar-valued reproducing kernel Hilbert space $H_X$ of functions over $X$.
Approximations of the evolution of the ideal local estimate $\hat{g}^i_t$ of
agent $i$ is constructed solely using observations made by agent $i$ on a fine
time scale. Since the local estimates on the fine time scale are constructed
independently for each agent, we say that the method is strictly decentralized.
On a coarse time scale, the individual local estimates $\hat{g}^i_t$ are fused
via the expression $\hat{g}_t:=\sum_{i=1}^N\Psi^i \hat{g}^i_t$ that uses a
partition of unity $\{\Psi^i\}_{1\leq i\leq N}$ subordinate to the cover
$\{\Omega^i\}_{i=1,\ldots,N}$ of $\Omega$. Realizable algorithms are obtained
by constructing finite dimensional approximations of the DPS in terms of
scattered bases defined by each agent from samples along their trajectories.
Rates of convergence of the error in the finite dimensional approximations are
derived in terms of the fill distance of the samples that define the scattered
centers in each subdomain. The qualitative performance of the convergence rates
for the decentralized estimation method is illustrated via numerical
simulations.
</dc:description>
 <dc:description>Comment: 10 pages, 3 figures</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12721</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12723</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeFLOCNet: Deep Image Editing via Flexible Low-level Controls</dc:title>
 <dc:creator>Liu, Hongyu</dc:creator>
 <dc:creator>Wan, Ziyu</dc:creator>
 <dc:creator>Huang, Wei</dc:creator>
 <dc:creator>Song, Yibing</dc:creator>
 <dc:creator>Han, Xintong</dc:creator>
 <dc:creator>Liao, Jing</dc:creator>
 <dc:creator>Jiang, Bing</dc:creator>
 <dc:creator>Liu, Wei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  User-intended visual content fills the hole regions of an input image in the
image editing scenario. The coarse low-level inputs, which typically consist of
sparse sketch lines and color dots, convey user intentions for content creation
(\ie, free-form editing). While existing methods combine an input image and
these low-level controls for CNN inputs, the corresponding feature
representations are not sufficient to convey user intentions, leading to
unfaithfully generated content. In this paper, we propose DeFLOCNet which
relies on a deep encoder-decoder CNN to retain the guidance of these controls
in the deep feature representations. In each skip-connection layer, we design a
structure generation block. Instead of attaching low-level controls to an input
image, we inject these controls directly into each structure generation block
for sketch line refinement and color propagation in the CNN feature space. We
then concatenate the modulated features with the original decoder features for
structure generation. Meanwhile, DeFLOCNet involves another decoder branch for
texture generation and detail enhancement. Both structures and textures are
rendered in the decoder, leading to user-intended editing results. Experiments
on benchmarks demonstrate that DeFLOCNet effectively transforms different user
intentions to create visually pleasing content.
</dc:description>
 <dc:description>Comment: Accepted by CVPR2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12723</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12759</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Optimal Control via Hilbert Space Embeddings of Distributions</dc:title>
 <dc:creator>Thorpe, Adam J.</dc:creator>
 <dc:creator>Oishi, Meeko M. K.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Kernel embeddings of distributions have recently gained significant attention
in the machine learning community as a data-driven technique for representing
probability distributions. Broadly, these techniques enable efficient
computation of expectations by representing integral operators as elements in a
reproducing kernel Hilbert space. We apply these techniques to the area of
stochastic optimal control theory and present a method to compute approximately
optimal policies for stochastic systems with arbitrary disturbances. Our
approach reduces the optimization problem to a linear program, which can easily
be solved via the Lagrangian dual, without resorting to gradient-based
optimization algorithms. We focus on discrete-time dynamic programming, and
demonstrate our proposed approach on a linear regulation problem, and on a
nonlinear target tracking problem. This approach is broadly applicable to a
wide variety of optimal control problems, and provides a means of working with
stochastic systems in a data-driven setting.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12759</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12777</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Contextual Paraphrase Generation using Lexical Control and
  Reinforcement Learning</dc:title>
 <dc:creator>Garg, Sonal</dc:creator>
 <dc:creator>Prabhu, Sumanth</dc:creator>
 <dc:creator>Misra, Hemant</dc:creator>
 <dc:creator>Srinivasaraghavan, G.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Customer support via chat requires agents to resolve customer queries with
minimum wait time and maximum customer satisfaction. Given that the agents as
well as the customers can have varying levels of literacy, the overall quality
of responses provided by the agents tend to be poor if they are not predefined.
But using only static responses can lead to customer detraction as the
customers tend to feel that they are no longer interacting with a human. Hence,
it is vital to have variations of the static responses to reduce monotonicity
of the responses. However, maintaining a list of such variations can be
expensive. Given the conversation context and the agent response, we propose an
unsupervised frame-work to generate contextual paraphrases using autoregressive
models. We also propose an automated metric based on Semantic Similarity,
Textual Entailment, Expression Diversity and Fluency to evaluate the quality of
contextual paraphrases and demonstrate performance improvement with
Reinforcement Learning (RL) fine-tuning using the automated metric as the
reward function.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12777</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12778</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PSIMiner: A Tool for Mining Rich Abstract Syntax Trees from Code</dc:title>
 <dc:creator>Spirin, Egor</dc:creator>
 <dc:creator>Bogomolov, Egor</dc:creator>
 <dc:creator>Kovalenko, Vladimir</dc:creator>
 <dc:creator>Bryksin, Timofey</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The application of machine learning algorithms to source code has grown in
the past years. Since these algorithms are quite sensitive to input data, it is
not surprising that researchers experiment with input representations.
Nowadays, a popular starting point to represent code is abstract syntax trees
(ASTs). Abstract syntax trees have been used for a long time in various
software engineering domains, and in particular in IDEs. The API of modern IDEs
allows to manipulate and traverse ASTs, resolve references between code
elements, etc. Such algorithms can enrich ASTs with new data and therefore may
be useful in ML-based code analysis. In this work, we present PSIMiner - a tool
for processing PSI trees from the IntelliJ Platform. PSI trees contain code
syntax trees as well as functions to work with them, and therefore can be used
to enrich code representation using static analysis algorithms of modern IDEs.
To showcase this idea, we use our tool to infer types of identifiers in Java
ASTs and extend the code2seq model for the method name prediction problem.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12778</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12793</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A large-scale study on research code quality and execution</dc:title>
 <dc:creator>Trisovic, Ana</dc:creator>
 <dc:creator>Lau, Matthew K.</dc:creator>
 <dc:creator>Pasquier, Thomas</dc:creator>
 <dc:creator>Crosas, Merc&#xe8;</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  This article presents a study on the quality and execution of research code
from publicly-available replication datasets at the Harvard Dataverse
repository. Research code is typically created by a group of scientists and
published together with academic papers to facilitate research transparency and
reproducibility. For this study, we define ten questions to address aspects
impacting research reproducibility and reuse. First, we retrieve and analyze
more than 2000 replication datasets with over 9000 unique R files published
from 2010 to 2020. Second, we execute the code in a clean runtime environment
to assess its ease of reuse. Common coding errors were identified, and some of
them were solved with automatic code cleaning to aid code execution. We find
that 74\% of R files crashed in the initial execution, while 56\% crashed when
code cleaning was applied, showing that many errors can be prevented with good
coding practices. We also analyze the replication datasets from journals'
collections and discuss the impact of the journal policy strictness on the code
re-execution rate. Finally, based on our results, we propose a set of
recommendations for code dissemination aimed at researchers, journals, and
repositories.
</dc:description>
 <dc:description>Comment: 30 pages</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12797</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RPT: Effective and Efficient Retrieval of Program Translations from Big
  Code</dc:title>
 <dc:creator>Chen, Binger</dc:creator>
 <dc:creator>Abedjan, Ziawasch</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Program translation is a growing demand in software engineering. Manual
program translation requires programming expertise in source and target
language. One way to automate this process is to make use of the big data of
programs, i.e., Big Code. In particular, one can search for program
translations in Big Code. However, existing code retrieval techniques are not
designed for cross-language code retrieval. Other data-driven approaches
require human efforts in constructing cross-language parallel datasets to train
translation models. In this paper, we present RPT, a novel code translation
retrieval system. We propose a lightweight but informative program
representation, which can be generalized to all imperative PLs. Furthermore, we
present our index structure and hierarchical filtering mechanism for efficient
code retrieval from a Big Code database.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12797</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12801</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variable Name Recovery in Decompiled Binary Code using Constrained
  Masked Language Modeling</dc:title>
 <dc:creator>Banerjee, Pratyay</dc:creator>
 <dc:creator>Pal, Kuntal Kumar</dc:creator>
 <dc:creator>Wang, Fish</dc:creator>
 <dc:creator>Baral, Chitta</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Decompilation is the procedure of transforming binary programs into a
high-level representation, such as source code, for human analysts to examine.
While modern decompilers can reconstruct and recover much information that is
discarded during compilation, inferring variable names is still extremely
difficult. Inspired by recent advances in natural language processing, we
propose a novel solution to infer variable names in decompiled code based on
Masked Language Modeling, Byte-Pair Encoding, and neural architectures such as
Transformers and BERT. Our solution takes \textit{raw} decompiler output, the
less semantically meaningful code, as input, and enriches it using our proposed
\textit{finetuning} technique, Constrained Masked Language Modeling. Using
Constrained Masked Language Modeling introduces the challenge of predicting the
number of masked tokens for the original variable name. We address this
\textit{count of token prediction} challenge with our post-processing
algorithm. Compared to the state-of-the-art approaches, our trained VarBERT
model is simpler and of much better performance. We evaluated our model on an
existing large-scale data set with 164,632 binaries and showed that it can
predict variable names identical to the ones present in the original source
code up to 84.15\% of the time.
</dc:description>
 <dc:description>Comment: Work In Progress</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12801</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12809</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multipath-based SLAM using Belief Propagation with Interacting Multiple
  Dynamic Models</dc:title>
 <dc:creator>Leitinger, Erik</dc:creator>
 <dc:creator>Grebien, Stefan</dc:creator>
 <dc:creator>Witrisal, Klaus</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we present a Bayesian multipath-based simultaneous
localization and mapping (SLAM) algorithm that continuously adapts interacting
multiple models (IMM) parameters to describe the mobile agent state dynamics.
The time-evolution of the IMM parameters is described by a Markov chain and the
parameters are incorporated into the factor graph structure that represents the
statistical structure of the SLAM problem. The proposed belief propagation
(BP)-based algorithm adapts, in an online manner, to time-varying system models
by jointly inferring the model parameters along with the agent and map feature
states. The performance of the proposed algorithm is finally evaluating with a
simulated scenario. Our numerical simulation results show that the proposed
multipath-based SLAM algorithm is able to cope with strongly changing agent
state dynamics.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures. To be published in Proc. EuCAP-21</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12809</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12810</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robot Learning of 6 DoF Grasping using Model-based Adaptive Primitives</dc:title>
 <dc:creator>Berscheid, Lars</dc:creator>
 <dc:creator>Friedrich, Christian</dc:creator>
 <dc:creator>Kr&#xf6;ger, Torsten</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Robot learning is often simplified to planar manipulation due to its data
consumption. Then, a common approach is to use a fully-convolutional neural
network to estimate the reward of grasp primitives. In this work, we extend
this approach by parametrizing the two remaining, lateral Degrees of Freedom
(DoFs) of the primitives. We apply this principle to the task of 6 DoF bin
picking: We introduce a model-based controller to calculate angles that avoid
collisions, maximize the grasp quality while keeping the uncertainty small. As
the controller is integrated into the training, our hybrid approach is able to
learn about and exploit the model-based controller. After real-world training
of 27000 grasp attempts, the robot is able to grasp known objects with a
success rate of over 92% in dense clutter. Grasp inference takes less than
50ms. In further real-world experiments, we evaluate grasp rates in a range of
scenarios including its ability to generalize to unknown objects. We show that
the system is able to avoid collisions, enabling grasps that would not be
possible without primitive adaption.
</dc:description>
 <dc:description>Comment: 2021 IEEE International Conference on Robotics and Automation (ICRA)</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12811</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combinators: A Centennial View</dc:title>
 <dc:creator>Wolfram, Stephen</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We give a modern computational introduction to the S,K combinators invented
by Moses Sch\&quot;onfinkel in 1920, and present a variety of new results and ideas
about combinators. We explore the spectrum of behavior obtained with small
combinator expressions, showing a variety of approaches to analysis and
visualization. We discuss the implications of evaluation strategies, and of
multiway systems representing all possible strategies. We show how causal
graphs introduced in recent models of fundamental physics can be applied to
combinators, as well as describing how combinators introduce a new form of
treelike separation. We give a variety of new results on minimal combinator
expressions, as well as showing how empirical computation theory and
computational complexity theory can be done with combinators. We also suggest
that when viewed in terms of ongoing computation, the S combinator alone may be
capable of universal computation.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12814</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Co-matching: Combating Noisy Labels by Augmentation Anchoring</dc:title>
 <dc:creator>Lu, Yangdi</dc:creator>
 <dc:creator>Bo, Yang</dc:creator>
 <dc:creator>He, Wenbo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Deep learning with noisy labels is challenging as deep neural networks have
the high capacity to memorize the noisy labels. In this paper, we propose a
learning algorithm called Co-matching, which balances the consistency and
divergence between two networks by augmentation anchoring. Specifically, we
have one network generate anchoring label from its prediction on a
weakly-augmented image. Meanwhile, we force its peer network, taking the
strongly-augmented version of the same image as input, to generate prediction
close to the anchoring label. We then update two networks simultaneously by
selecting small-loss instances to minimize both unsupervised matching loss
(i.e., measure the consistency of the two networks) and supervised
classification loss (i.e. measure the classification performance). Besides, the
unsupervised matching loss makes our method not heavily rely on noisy labels,
which prevents memorization of noisy labels. Experiments on three benchmark
datasets demonstrate that Co-matching achieves results comparable to the
state-of-the-art methods.
</dc:description>
 <dc:description>Comment: 13 pages, 10 figures. arXiv admin note: text overlap with
  arXiv:2003.02752 by other authors</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12814</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12819</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Massively Parallel Time-Domain Coupled Electrodynamics-Micromagnetics
  Solver</dc:title>
 <dc:creator>Yao, Zhi</dc:creator>
 <dc:creator>Jambunathan, Revathi</dc:creator>
 <dc:creator>Zeng, Yadong</dc:creator>
 <dc:creator>Nonaka, Andrew</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Physics - Applied Physics</dc:subject>
 <dc:subject>35-04, 35Q60, 35Q61, 78-04, 78-10, 78M20, 78A50</dc:subject>
 <dc:description>  We present a new, high-performance coupled electrodynamics-micromagnetics
solver for full physical modeling of signals in microelectronic circuitry. The
overall strategy couples a finite-difference time-domain (FDTD) approach for
Maxwell's equations to a magnetization model described by the
Landau-Lifshitz-Gilbert (LLG) equation. The algorithm is implemented in the
Exascale Computing Project software framework, AMReX, which provides effective
scalability on manycore and GPU-based supercomputing architectures.
Furthermore, the code leverages ongoing developments of the Exascale
Application Code, WarpX, primarily developed for plasma wakefield accelerator
modeling. Our novel temporal coupling scheme provides second-order accuracy in
space and time by combining the integration steps for the magnetic field and
magnetization into an iterative sub-step that includes a trapezoidal
discretization for the magnetization. The performance of the algorithm is
demonstrated by the excellent scaling results on NERSC multicore and GPU
systems, with a significant (59x) speedup on the GPU using a node-by-node
comparison. We demonstrate the utility of our code by performing simulations of
an electromagnetic waveguide and a magnetically tunable filter.
</dc:description>
 <dc:description>Comment: 13 pages, 7 figures, two of the figures have sub-panels</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12820</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Review &amp; Framework for Modeling Complex Engineered System Development
  Processes</dc:title>
 <dc:creator>Meluso, John</dc:creator>
 <dc:creator>Austin-Breneman, Jesse</dc:creator>
 <dc:creator>Bagrow, James P.</dc:creator>
 <dc:creator>H&#xe9;bert-Dufresne, Laurent</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:description>  Developing complex engineered systems (CES) poses significant challenges for
engineers, managers, designers, and businesspeople alike due to the inherent
complexity of the systems and contexts involved. Furthermore, experts have
expressed great interest in filling the gap in theory about how CES develop.
This article begins to address that gap in two ways. First, it reviews the
numerous definitions of CES along with existing theory and methods on CES
development processes. Then, it proposes the ComplEx System Integrated
Utilities Model (CESIUM), a novel framework for exploring how numerous system
and development process characteristics may affect the performance of CES.
CESIUM creates simulated representations of a system architecture, the
corresponding engineering organization, and the new product development process
through which the organization designs the system. It does so by representing
the system as a network of interdependent artifacts designed by agents. Agents
iteratively design their artifacts through optimization and share information
with other agents, thereby advancing the CES toward a solution. This paper
describes the model, conducts a sensitivity analysis, provides validation, and
suggests directions for future study.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12820</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12835</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spoken Digit Classification by In-Materio Reservoir Computing with
  Neuromorphic Atomic Switch Networks</dc:title>
 <dc:creator>Lilak, Sam</dc:creator>
 <dc:creator>Woods, Walt</dc:creator>
 <dc:creator>Scharnhorst, Kelsey</dc:creator>
 <dc:creator>Dunham, Christopher</dc:creator>
 <dc:creator>Teuscher, Christof</dc:creator>
 <dc:creator>Stieg, Adam Z.</dc:creator>
 <dc:creator>Gimzewski, James K.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Mesoscale and Nanoscale Physics</dc:subject>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:description>  Atomic Switch Networks (ASN) comprising silver iodide (AgI) junctions, a
material previously unexplored as functional memristive elements within
highly-interconnected nanowire networks, were employed as a neuromorphic
substrate for physical Reservoir Computing (RC). This new class of ASN-based
devices has been physically characterized and utilized to classify spoken digit
audio data, demonstrating the utility of substrate-based device architectures
where intrinsic material properties can be exploited to perform computation
in-materio. This work demonstrates high accuracy in the classification of
temporally analyzed Free-Spoken Digit Data (FSDD). These results expand upon
the class of viable memristive materials available for the production of
functional nanowire networks and bolster the utility of ASN-based devices as
unique hardware platforms for neuromorphic computing applications involving
memory, adaptation and learning.
</dc:description>
 <dc:description>Comment: 11 pages, 7 figures</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12837</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Approach for the Automation of IaaS Cloud Upgrade</dc:title>
 <dc:creator>Nabi, Mina</dc:creator>
 <dc:creator>Khendek, Ferhat</dc:creator>
 <dc:creator>Toeroe, Maria</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>90B25</dc:subject>
 <dc:subject>D.2.9</dc:subject>
 <dc:subject>D.4.5</dc:subject>
 <dc:description>  An Infrastructure as a Service (IaaS) cloud provider is committed to each
tenant by a service level agreement (SLA) which indicates the terms of
commitment, e.g. the level of availability of the IaaS cloud service.The
different resources providing this IaaS cloud service may need to be upgraded
several times throughout their life-cycle; and these upgrades may affect the
service delivered by the IaaS layer. This may violate the SLAs towards the
tenants and result in penalty as they impact the tenant services relying on the
IaaS.Therefore, it is important to handle upgrades properly with respect to the
SLAs.The upgrade of IaaS cloud systems inherits all the challenges of clustered
systems and faces other, cloud specific challenges, such as size and dynamicity
due to elasticity.In this paper, we propose a novel approach to automatically
upgrade an IaaS cloud system under SLA constraints such as availability and
elasticity.In this approach, the upgrade methods and actions appropriate for
each upgrade request are identified, scheduled, and applied automatically in an
iterative manner based on the vendors descriptions of the infrastructure
components, the tenant SLAs, and the status of the system. The proposed
approach allows new upgrade requests during ongoing upgrades, which makes it
suitable for continuous delivery.In addition, it also handles failures of
upgrade actions through localized retry and undo operations automatically.
</dc:description>
 <dc:description>Comment: 20 pages, 11 figures</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12837</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12840</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of Distributed Optimization Methods for Multi-Robot Systems</dc:title>
 <dc:creator>Halsted, Trevor</dc:creator>
 <dc:creator>Shorinwa, Ola</dc:creator>
 <dc:creator>Yu, Javier</dc:creator>
 <dc:creator>Schwager, Mac</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Distributed optimization consists of multiple computation nodes working
together to minimize a common objective function through local computation
iterations and network-constrained communication steps. In the context of
robotics, distributed optimization algorithms can enable multi-robot systems to
accomplish tasks in the absence of centralized coordination. We present a
general framework for applying distributed optimization as a module in a
robotics pipeline. We survey several classes of distributed optimization
algorithms and assess their practical suitability for multi-robot applications.
We further compare the performance of different classes of algorithms in
simulations for three prototypical multi-robot problem scenarios. The Consensus
Alternating Direction Method of Multipliers (C-ADMM) emerges as a particularly
attractive and versatile distributed optimization method for multi-robot
systems.
</dc:description>
 <dc:description>Comment: submitted to IEEE T-RO</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12840</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12841</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ground Truths for the Humanities</dc:title>
 <dc:creator>Oortwijn, Yvette</dc:creator>
 <dc:creator>Berg, Hein van den</dc:creator>
 <dc:creator>Betti, Arianna</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Ensuring a faithful interaction with data and its representation for
humanities can and should depend on expert-constructed ground truths.
</dc:description>
 <dc:description>Comment: Provocation paper presented at the 5th Workshop on Visualization for
  the Digital Humanities (VIS4DH), part of the 31st IEEE Visualization
  Conference, IEEE VIS 2020, Virtual Event, Salt Lake City, USA, October 25-30,
  2020. 1 page + 1 page of references</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12841</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12842</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Is radicalization reinforced by social media censorship?</dc:title>
 <dc:creator>Lane, Justin E.</dc:creator>
 <dc:creator>McCaffree, Kevin</dc:creator>
 <dc:creator>Shults, F. LeRon</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Radicalized beliefs, such as those tied to QAnon, Russiagate, and other
political conspiracy theories, can lead some individuals and groups to engage
in violent behavior, as evidenced in recent months. Understanding the
mechanisms by which such beliefs are accepted, spread, and intensified is
critical for any attempt to mitigate radicalization and avoid increased
political polarization. This article presents and agent-based model of a social
media network that enables investigation of the effects of censorship on the
amount of dissenting information to which agents become exposed and the
certainty of their radicalized views. The model explores two forms of
censorship: 1) decentralized censorship-in which individuals can choose to
break an online social network tie (unfriend or unfollow) with another
individual who transmits conflicting beliefs and 2) centralized censorship-in
which a single authority can ban an individual from the social media network
for spreading a certain type of belief. This model suggests that both forms of
censorship increase certainty in radicalized views by decreasing the amount of
dissent to which an agent is exposed, but centralized &quot;banning&quot; of individuals
has the strongest effect on radicalization.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12843</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scam Pandemic: How Attackers Exploit Public Fear through Phishing</dc:title>
 <dc:creator>Bitaab, Marzieh</dc:creator>
 <dc:creator>Cho, Haehyun</dc:creator>
 <dc:creator>Oest, Adam</dc:creator>
 <dc:creator>Zhang, Penghui</dc:creator>
 <dc:creator>Sun, Zhibo</dc:creator>
 <dc:creator>Pourmohamad, Rana</dc:creator>
 <dc:creator>Kim, Doowon</dc:creator>
 <dc:creator>Bao, Tiffany</dc:creator>
 <dc:creator>Wang, Ruoyu</dc:creator>
 <dc:creator>Shoshitaishvili, Yan</dc:creator>
 <dc:creator>Doup&#xe9;, Adam</dc:creator>
 <dc:creator>Ahn, Gail-Joon</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  As the COVID-19 pandemic started triggering widespread lockdowns across the
globe, cybercriminals did not hesitate to take advantage of users' increased
usage of the Internet and their reliance on it. In this paper, we carry out a
comprehensive measurement study of online social engineering attacks in the
early months of the pandemic. By collecting, synthesizing, and analyzing DNS
records, TLS certificates, phishing URLs, phishing website source code,
phishing emails, web traffic to phishing websites, news articles, and
government announcements, we track trends of phishing activity between January
and May 2020 and seek to understand the key implications of the underlying
trends.
  We find that phishing attack traffic in March and April 2020 skyrocketed up
to 220\% of its pre-COVID-19 rate, far exceeding typical seasonal spikes.
Attackers exploited victims' uncertainty and fear related to the pandemic
through a variety of highly targeted scams, including emerging scam types
against which current defenses are not sufficient as well as traditional
phishing which outpaced the ecosystem's collective response.
</dc:description>
 <dc:description>Comment: 10 pages, Accepted to eCrime 2020</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12843</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12854</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Actionable Cognitive Twins for Decision Making in Manufacturing</dc:title>
 <dc:creator>Ro&#x17e;anec, Jo&#x17e;e M.</dc:creator>
 <dc:creator>Lu, Jinzhi</dc:creator>
 <dc:creator>Rupnik, Jan</dc:creator>
 <dc:creator>&#x160;krjanc, Maja</dc:creator>
 <dc:creator>Mladeni&#x107;, Dunja</dc:creator>
 <dc:creator>Fortuna, Bla&#x17e;</dc:creator>
 <dc:creator>Zheng, Xiaochen</dc:creator>
 <dc:creator>Kiritsis, Dimitris</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Actionable Cognitive Twins are the next generation Digital Twins enhanced
with cognitive capabilities through a knowledge graph and artificial
intelligence models that provide insights and decision-making options to the
users. The knowledge graph describes the domain-specific knowledge regarding
entities and interrelationships related to a manufacturing setting. It also
contains information on possible decision-making options that can assist
decision-makers, such as planners or logisticians. In this paper, we propose a
knowledge graph modeling approach to construct actionable cognitive twins for
capturing specific knowledge related to demand forecasting and production
planning in a manufacturing plant. The knowledge graph provides semantic
descriptions and contextualization of the production lines and processes,
including data identification and simulation or artificial intelligence
algorithms and forecasts used to support them. Such semantics provide ground
for inferencing, relating different knowledge types: creative, deductive,
definitional, and inductive. To develop the knowledge graph models for
describing the use case completely, systems thinking approach is proposed to
design and verify the ontology, develop a knowledge graph and build an
actionable cognitive twin. Finally, we evaluate our approach in two use cases
developed for a European original equipment manufacturer related to the
automotive industry as part of the European Horizon 2020 project FACTLOG.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12854</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12863</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Plenum-Based Calibration Device for Tactile Sensor Arrays</dc:title>
 <dc:creator>Kangro, Joan</dc:creator>
 <dc:creator>Sureshbabu, Anand Vazhapilli</dc:creator>
 <dc:creator>Traversaro, Silvio</dc:creator>
 <dc:creator>Pucci, Daniele</dc:creator>
 <dc:creator>Nori, Francesco</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In modern robotic applications, tactile sensor arrays (i.e., artificial
skins) are an emergent solution to determine the locations of contacts between
a robot and an external agent. Localizing the point of contact is useful but
determining the force applied on the skin provides many additional
possibilities. This additional feature usually requires time-consuming
calibration procedures to relate the sensor readings to the applied forces.
This letter presents a novel device that enables the calibration of tactile
sensor arrays in a fast and simple way. The key idea is to design a plenum
chamber where the skin is inserted, and then the calibration of the tactile
sensors is achieved by relating the air pressure and the sensor readings. This
general concept is tested experimentally to calibrate the skin of the iCub
robot. The validation of the calibration device is achieved by placing the
masses of known weight on the artificial skin and comparing the applied force
against the one estimated by the sensors.
</dc:description>
 <dc:description>Comment: 8 pages, 18 figures</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12863</dc:identifier>
 <dc:identifier>IEEE Robotics and Automation Letters ( Volume: 3, Issue: 4, Oct.
  2018)</dc:identifier>
 <dc:identifier>doi:10.1109/LRA.2018.2857858</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12864</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learned complex masks for multi-instrument source separation</dc:title>
 <dc:creator>Jansson, Andreas</dc:creator>
 <dc:creator>Bittner, Rachel M.</dc:creator>
 <dc:creator>Montecchio, Nicola</dc:creator>
 <dc:creator>Weyde, Tillman</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Music source separation in the time-frequency domain is commonly achieved by
applying a soft or binary mask to the magnitude component of (complex)
spectrograms. The phase component is usually not estimated, but instead copied
from the mixture and applied to the magnitudes of the estimated isolated
sources. While this method has several practical advantages, it imposes an
upper bound on the performance of the system, where the estimated isolated
sources inherently exhibit audible &quot;phase artifacts&quot;. In this paper we address
these shortcomings by directly estimating masks in the complex domain,
extending recent work from the speech enhancement literature. The method is
particularly well suited for multi-instrument musical source separation since
residual phase artifacts are more pronounced for spectrally overlapping
instrument sources, a common scenario in music. We show that complex masks
result in better separation than masks that operate solely on the magnitude
component.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12864</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12866</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PAC-Bayesian theory for stochastic LTI systems</dc:title>
 <dc:creator>Eringis, Deividas</dc:creator>
 <dc:creator>Leth, John</dc:creator>
 <dc:creator>Tan, Zheng-Hua</dc:creator>
 <dc:creator>Wisniewski, Rafal</dc:creator>
 <dc:creator>Esfahani, Alireza Fakhrizadeh</dc:creator>
 <dc:creator>Petreczky, Mihaly</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In this paper we derive a PAC-Bayesian error bound for autonomous stochastic
LTI state-space models. The motivation for deriving such error bounds is that
they will allow deriving similar error bounds for more general dynamical
systems, including recurrent neural networks. In turn, PACBayesian error bounds
are known to be useful for analyzing machine learning algorithms and for
deriving new ones.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12866</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12868</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A High-order Tuner for Accelerated Learning and Control</dc:title>
 <dc:creator>McDonald, Spencer</dc:creator>
 <dc:creator>Cui, Yingnan</dc:creator>
 <dc:creator>Gaudio, Joseph E.</dc:creator>
 <dc:creator>Annaswamy, Anuradha M.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Gradient-descent based iterative algorithms pervade a variety of problems in
estimation, prediction, learning, control, and optimization. Recently iterative
algorithms based on higher-order information have been explored in an attempt
to lead to accelerated learning. In this paper, we explore a specific a
high-order tuner that has been shown to result in stability with time-varying
regressors in linearly parametrized systems, and accelerated convergence with
constant regressors. We show that this tuner continues to provide bounded
parameter estimates even if the gradients are corrupted by noise. Additionally,
we also show that the parameter estimates converge exponentially to a compact
set whose size is dependent on noise statistics. As the HT algorithms can be
applied to a wide range of problems in estimation, filtering, control, and
machine learning, the result obtained in this paper represents an important
extension to the topic of real-time and fast decision making.
</dc:description>
 <dc:description>Comment: 31 pages</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12868</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12870</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fully-echoed Q-routing with Simulated Annealing Inference for Flying
  Adhoc Networks</dc:title>
 <dc:creator>Rovira-Sugranes, Arnau</dc:creator>
 <dc:creator>Afghah, Fatemeh</dc:creator>
 <dc:creator>Qu, Junsuo</dc:creator>
 <dc:creator>Razi, Abolfazl</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Current networking protocols deem inefficient in accommodating the two key
challenges of Unmanned Aerial Vehicle (UAV) networks, namely the network
connectivity loss and energy limitations. One approach to solve these issues is
using learning-based routing protocols to make close-to-optimal local decisions
by the network nodes, and Q-routing is a bold example of such protocols.
However, the performance of the current implementations of Q-routing algorithms
is not yet satisfactory, mainly due to the lack of adaptability to continued
topology changes. In this paper, we propose a full-echo Q-routing algorithm
with a self-adaptive learning rate that utilizes Simulated Annealing (SA)
optimization to control the exploration rate of the algorithm through the
temperature decline rate, which in turn is regulated by the experienced
variation rate of the Q-values. Our results show that our method adapts to the
network dynamicity without the need for manual re-initialization at transition
points (abrupt network topology changes). Our method exhibits a reduction in
the energy consumption ranging from 7% up to 82%, as well as a 2.6 fold gain in
successful packet delivery rate}, compared to the state of the art Q-routing
protocols
</dc:description>
 <dc:description>Comment: 13 pages, 7 figures, 5 tables</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12870</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12871</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Teacher-Explorer-Student Learning: A Novel Learning Method for Open Set
  Recognition</dc:title>
 <dc:creator>Jang, Jaeyeon</dc:creator>
 <dc:creator>Kim, Chang Ouk</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  If an unknown example that is not seen during training appears, most
recognition systems usually produce overgeneralized results and determine that
the example belongs to one of the known classes. To address this problem,
teacher-explorer-student (T/E/S) learning, which adopts the concept of open set
recognition (OSR) that aims to reject unknown samples while minimizing the loss
of classification performance on known samples, is proposed in this study. In
this novel learning method, overgeneralization of deep learning classifiers is
significantly reduced by exploring various possibilities of unknowns. Here, the
teacher network extracts some hints about unknowns by distilling the pretrained
knowledge about knowns and delivers this distilled knowledge to the student.
After learning the distilled knowledge, the student network shares the learned
information with the explorer network. Then, the explorer network shares its
exploration results by generating unknown-like samples and feeding the samples
to the student network. By repeating this alternating learning process, the
student network experiences a variety of synthetic unknowns, reducing
overgeneralization. Extensive experiments were conducted, and the experimental
results showed that each component proposed in this paper significantly
contributes to the improvement in OSR performance. As a result, the proposed
T/E/S learning method outperformed current state-of-the-art methods.
</dc:description>
 <dc:description>Comment: 12 pages, 13 figures, 4 tables</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12871</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12872</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Formal Model of Narratives</dc:title>
 <dc:creator>Castricato, Louis</dc:creator>
 <dc:creator>Biderman, Stella</dc:creator>
 <dc:creator>Cardona-Rivera, Rogelio E.</dc:creator>
 <dc:creator>Thue, David</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In this paper, we propose the beginnings of a formal framework for modeling
narrative \textit{qua} narrative. Our framework affords the ability to discuss
key qualities of stories and their communication, including the flow of
information from a Narrator to a Reader, the evolution of a Reader's story
model over time, and Reader uncertainty. We demonstrate its applicability to
computational narratology by giving explicit algorithms for measuring the
accuracy with which information was conveyed to the Reader and two novel
measurements of story coherence.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12874</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Meta-learning to Recommend Process Discovery Methods</dc:title>
 <dc:creator>Barbon Jr, Sylvio</dc:creator>
 <dc:creator>Ceravolo, Paolo</dc:creator>
 <dc:creator>Damiani, Ernesto</dc:creator>
 <dc:creator>Tavares, Gabriel Marques</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Process discovery methods have obtained remarkable achievements in Process
Mining, delivering comprehensible process models to enhance management
capabilities. However, selecting the suitable method for a specific event log
highly relies on human expertise, hindering its broad application. Solutions
based on Meta-learning (MtL) have been promising for creating systems with
reduced human assistance. This paper presents a MtL solution for recommending
process discovery methods that maximize model quality according to
complementary dimensions. Thanks to our MtL pipeline, it was possible to
recommend a discovery method with 92% of accuracy using light-weight features
that describe the event log. Our experimental analysis also provided
significant insights on the importance of log features in generating
recommendations, paving the way to a deeper understanding of the discovery
algorithms.
</dc:description>
 <dc:description>Comment: 16 pages, 6 figures</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12874</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12876</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complex Factoid Question Answering with a Free-Text Knowledge Graph</dc:title>
 <dc:creator>Zhao, Chen</dc:creator>
 <dc:creator>Xiong, Chenyan</dc:creator>
 <dc:creator>Qian, Xin</dc:creator>
 <dc:creator>Boyd-Graber, Jordan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  We introduce DELFT, a factoid question answering system which combines the
nuance and depth of knowledge graph question answering approaches with the
broader coverage of free-text. DELFT builds a free-text knowledge graph from
Wikipedia, with entities as nodes and sentences in which entities co-occur as
edges. For each question, DELFT finds the subgraph linking question entity
nodes to candidates using text sentences as edges, creating a dense and high
coverage semantic graph. A novel graph neural network reasons over the
free-text graph-combining evidence on the nodes via information along edge
sentences-to select a final answer. Experiments on three question answering
datasets show DELFT can answer entity-rich questions better than machine
reading based models, bert-based answer ranking and memory networks. DELFT's
advantage comes from both the high coverage of its free-text knowledge
graph-more than double that of dbpedia relations-and the novel graph neural
network which reasons on the rich but noisy free-text evidence.
</dc:description>
 <dc:description>Comment: WWW2020</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12876</dc:identifier>
 <dc:identifier>doi:10.1145/3366423.3380197</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12881</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smoothing-Averse Control: Covertness and Privacy from Smoothers</dc:title>
 <dc:creator>Molloy, Timothy L.</dc:creator>
 <dc:creator>Nair, Girish N.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we investigate the problem of controlling a partially observed
stochastic dynamical system such that its state is difficult to infer using a
(fixed-interval) Bayesian smoother. This problem arises naturally in
applications in which it is desirable to keep the entire state trajectory of a
system concealed. We pose our smoothing-averse control problem as the problem
of maximising the (joint) entropy of smoother state estimates (i.e., the joint
conditional entropy of the state trajectory given the history of measurements
and controls). We show that the entropy of Bayesian smoother estimates for
general nonlinear state-space models can be expressed as the sum of entropies
of marginal state estimates given by Bayesian filters. This novel additive form
allows us to reformulate the smoothing-averse control problem as a fully
observed stochastic optimal control problem in terms of the usual concept of
the information (or belief) state, and solve the resulting problem via dynamic
programming. We illustrate the applicability of smoothing-averse control to
privacy in cloud-based control and covert robotic navigation.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures, accepted for presentation at 2021 American
  Control Conference</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12881</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12882</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TeCoMiner: Topic Discovery Through Term Community Detection</dc:title>
 <dc:creator>Hamm, Andreas</dc:creator>
 <dc:creator>Thelen, Jana</dc:creator>
 <dc:creator>Beckmann, Rasmus</dc:creator>
 <dc:creator>Odrowski, Simon</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.5.3</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:description>  This note is a short description of TeCoMiner, an interactive tool for
exploring the topic content of text collections. Unlike other topic modeling
tools, TeCoMiner is not based on some generative probabilistic model but on
topological considerations about co-occurrence networks of terms. We outline
the methods used for identifying topics, describe the features of the tool, and
sketch an application, using a corpus of policy related scientific news on
environmental issues published by the European Commission over the last decade.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12882</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12883</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Reinforcement Learning for Mapless Navigation of a Hybrid Aerial
  Underwater Vehicle with Medium Transition</dc:title>
 <dc:creator>Grando, Ricardo Bedin</dc:creator>
 <dc:creator>de Jesus, Junior Costa</dc:creator>
 <dc:creator>Kich, Victor Augusto</dc:creator>
 <dc:creator>Kolling, Alisson Henrique</dc:creator>
 <dc:creator>Bortoluzzi, Nicolas Pieper</dc:creator>
 <dc:creator>Pinheiro, Pedro Miranda</dc:creator>
 <dc:creator>Neto, Armando Alves</dc:creator>
 <dc:creator>Drews-Jr, Paulo Lilles Jorge</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Since the application of Deep Q-Learning to the continuous action domain in
Atari-like games, Deep Reinforcement Learning (Deep-RL) techniques for motion
control have been qualitatively enhanced. Nowadays, modern Deep-RL can be
successfully applied to solve a wide range of complex decision-making tasks for
many types of vehicles. Based on this context, in this paper, we propose the
use of Deep-RL to perform autonomous mapless navigation for Hybrid Unmanned
Aerial Underwater Vehicles (HUAUVs), robots that can operate in both, air or
water media. We developed two approaches, one deterministic and the other
stochastic. Our system uses the relative localization of the vehicle and simple
sparse range data to train the network. We compared our approaches with a
traditional geometric tracking controller for mapless navigation. Based on
experimental results, we can conclude that Deep-RL-based approaches can be
successfully used to perform mapless navigation and obstacle avoidance for
HUAUVs. Our vehicle accomplished the navigation in two scenarios, being capable
to achieve the desired target through both environments, and even outperforming
the geometric-based tracking controller on the obstacle-avoidance capability.
</dc:description>
 <dc:description>Comment: Accepted to the IEEE International Conference on Robotics and
  Automation (ICRA) 2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12883</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12886</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weakly Supervised Instance Segmentation for Videos with Temporal Mask
  Consistency</dc:title>
 <dc:creator>Liu, Qing</dc:creator>
 <dc:creator>Ramanathan, Vignesh</dc:creator>
 <dc:creator>Mahajan, Dhruv</dc:creator>
 <dc:creator>Yuille, Alan</dc:creator>
 <dc:creator>Yang, Zhenheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Weakly supervised instance segmentation reduces the cost of annotations
required to train models. However, existing approaches which rely only on
image-level class labels predominantly suffer from errors due to (a) partial
segmentation of objects and (b) missing object predictions. We show that these
issues can be better addressed by training with weakly labeled videos instead
of images. In videos, motion and temporal consistency of predictions across
frames provide complementary signals which can help segmentation. We are the
first to explore the use of these video signals to tackle weakly supervised
instance segmentation. We propose two ways to leverage this information in our
model. First, we adapt inter-pixel relation network (IRN) to effectively
incorporate motion information during training. Second, we introduce a new
MaskConsist module, which addresses the problem of missing object instances by
transferring stable predictions between neighboring frames during training. We
demonstrate that both approaches together improve the instance segmentation
metric $AP_{50}$ on video frames of two datasets: Youtube-VIS and Cityscapes by
$5\%$ and $3\%$ respectively.
</dc:description>
 <dc:description>Comment: 14 pages, 8 figures, accepted by CVPR 2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12886</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12894</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Facility Reallocation on the Line</dc:title>
 <dc:creator>de Keijzer, Bart</dc:creator>
 <dc:creator>Wojtczak, Dominik</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider a multi-stage facility reallocation problems on the real line,
where a facility is being moved between time stages based on the locations
reported by $n$ agents. The aim of the reallocation algorithm is to minimise
the social cost, i.e., the sum over the total distance between the facility and
all agents at all stages, plus the cost incurred for moving the facility. We
study this problem both in the offline setting and online setting. In the
offline case the algorithm has full knowledge of the agent locations in all
future stages, and in the online setting the algorithm does not know these
future locations and must decide the location of the facility on a
stage-per-stage basis. We derive the optimal algorithm in both cases. For the
online setting we show that its competitive ratio is $(n+2)/(n+1)$. As neither
of these algorithms turns out to yield a strategy-proof mechanism, we propose
another strategy-proof mechanism which has a competitive ratio of $(n+3)/(n+1)$
for odd $n$ and $(n+4)/n$ for even $n$, which we conjecture to be the best
possible. We also consider a generalisation with multiple facilities and
weighted agents, for which we show that the optimum can be computed in
polynomial time for a fixed number of facilities.
</dc:description>
 <dc:description>Comment: 28 Pages, 5 Figures. A prelimininary version of the paper, with most
  proofs omitted, has appeared at IJCAI 2018</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12894</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12896</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SETGAN: Scale and Energy Trade-off GANs for Image Applications on Mobile
  Platforms</dc:title>
 <dc:creator>Jayakodi, Nitthilan Kannappan</dc:creator>
 <dc:creator>Doppa, Janardhan Rao</dc:creator>
 <dc:creator>Pande, Partha Pratim</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  We consider the task of photo-realistic unconditional image generation
(generate high quality, diverse samples that carry the same visual content as
the image) on mobile platforms using Generative Adversarial Networks (GANs). In
this paper, we propose a novel approach to trade-off image generation accuracy
of a GAN for the energy consumed (compute) at run-time called Scale-Energy
Tradeoff GAN (SETGAN). GANs usually take a long time to train and consume a
huge memory hence making it difficult to run on edge devices. The key idea
behind SETGAN for an image generation task is for a given input image, we train
a GAN on a remote server and use the trained model on edge devices. We use
SinGAN, a single image unconditional generative model, that contains a pyramid
of fully convolutional GANs, each responsible for learning the patch
distribution at a different scale of the image. During the training process, we
determine the optimal number of scales for a given input image and the energy
constraint from the target edge device. Results show that with SETGAN's unique
client-server-based architecture, we were able to achieve a 56% gain in energy
for a loss of 3% to 12% SSIM accuracy. Also, with the parallel multi-scale
training, we obtain around 4x gain in training time on the server.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12896</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12897</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comments on &quot;A Framework for Control System Design Subject to Average
  Data-Rate Constraints&quot;</dc:title>
 <dc:creator>Derpich, Milan S.</dc:creator>
 <dc:creator>&#xd8;stergaard, Jan</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Theorem~ 4.1 in the 2011 paper &quot;A Framework for Control System Design Subject
to Average Data-Rate Constraints&quot; allows one to lower bound average operational
data rates in feedback loops (including the situation in which encoder and
decoder have side information). Unfortunately, its proof is invalid.
  In this note we first state the theorem and explain why its proof is flawed,
and then provide a correct proof under weaker assumptions.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Automatic Control</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12897</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12899</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Multicolored Graph Realization Problem</dc:title>
 <dc:creator>D&#xed;az, Josep</dc:creator>
 <dc:creator>Diner, &#xd6;znur Ya&#x15f;ar</dc:creator>
 <dc:creator>Serna, Maria</dc:creator>
 <dc:creator>Serra, Oriol</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We introduce the Multicolored Graph Realization problem (MGRP). The input to
the problem is a colored graph $(G,\varphi)$, i.e., a graph together with a
coloring on its vertices. We can associate to each colored graph a cluster
graph ($G_\varphi)$ in which, after collapsing to a node all vertices with the
same color, we remove multiple edges and self-loops. A set of vertices $S$ is
multicolored when $S$ has exactly one vertex from each color class. The problem
is to decide whether there is a multicolored set $S$ such that, after
identifying each vertex in $S$ with its color class, $G[S]$ coincides with
$G_\varphi$.
  The MGR problem is related to the class of generalized network problems, most
of which are NP-hard. For example the generalized MST problem. MGRP is a
generalization of the Multicolored Clique Problem, which is known to be
W[1]-hard when parameterized by the number of colors. Thus MGRP remains
W[1]-hard, when parameterized by the size of the cluster graph and when
parameterized by any graph parameter on $G_\varphi$, among those for treewidth.
We look to instances of the problem in which both the number of color classes
and the treewidth of $G_\varphi$ are unbounded. We show that MGRP is
NP-complete when $G_\varphi$ is either chordal, biconvex bipartite, complete
bipartite or a 2-dimensional grid. Our hardness results follows from suitable
reductions from the 1-in-3 monotone SAT problem. Our reductions show that the
problem remains hard even when the maximum number of vertices in a color class
is 3. In the case of the grid, the hardness holds also graphs with bounded
degree. We complement those results by showing combined parameterizations under
which the MGR problem became tractable.
</dc:description>
 <dc:description>Comment: 23 pages, 9 figures</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12899</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12905</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Offline Delegatable Cryptocurrency System</dc:title>
 <dc:creator>Li, Rujia</dc:creator>
 <dc:creator>Wang, Qin</dc:creator>
 <dc:creator>Zhang, Xinrui</dc:creator>
 <dc:creator>Wang, Qi</dc:creator>
 <dc:creator>Galindo, David</dc:creator>
 <dc:creator>Xiang, Yang</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Blockchain-based cryptocurrencies, facilitating the convenience of payment by
providing a decentralized online solution, have not been widely adopted so far
due to slow confirmation of transactions. Offline delegation offers an
efficient way to exchange coins. However, in such an approach, the coins that
have been delegated confront the risk of being spent twice since the
delegator's behaviour cannot be restricted easily on account of the absence of
effective supervision. Even if a third party can be regarded as a judge between
the delegator and delegatee to secure transactions, she still faces the threat
of being compromised or providing misleading assure. Moreover, the approach
equipped with a third party contradicts the real intention of decentralized
cryptocurrency systems. In this paper, we propose \textit{DelegaCoin}, an
offline delegatable cryptocurrency system to mitigate such an issue. We exploit
trusted execution environments (TEEs) as decentralized &quot;virtual agents&quot; to
prevent malicious delegation. In DelegaCoin, an owner can delegate his coins
through offline-transactions without interacting with the blockchain network. A
formal model and analysis, prototype implementation, and further evaluation
demonstrate that our scheme is provably secure and practically feasible.
</dc:description>
 <dc:description>Comment: ICBC21</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12905</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12908</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Isolating Cuts, (Bi-)Submodularity, and Faster Algorithms for Global
  Connectivity Problems</dc:title>
 <dc:creator>Chekuri, Chandra</dc:creator>
 <dc:creator>Quanrud, Kent</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Li and Panigrahi, in recent work, obtained the first deterministic algorithm
for the global minimum cut of a weighted undirected graph that runs in time
$o(mn)$. They introduced an elegant and powerful technique to find isolating
cuts for a terminal set in a graph via a small number of $s$-$t$ minimum cut
computations.
  In this paper we generalize their isolating cut approach to the abstract
setting of symmetric bisubmodular functions (which also capture symmetric
submodular functions). Our generalization to bisubmodularity is motivated by
applications to element connectivity and vertex connectivity. Utilizing the
general framework and other ideas we obtain significantly faster randomized
algorithms for computing global (and subset) connectivity in a number of
settings including hypergraphs, element connectivity and vertex connectivity in
graphs, and for symmetric submodular functions.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12908</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12910</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AQEyes: Visual Analytics for Anomaly Detection and Examination of Air
  Quality Data</dc:title>
 <dc:creator>Liu, Dongyu</dc:creator>
 <dc:creator>Veeramachaneni, Kalyan</dc:creator>
 <dc:creator>Geiger, Alexander</dc:creator>
 <dc:creator>Li, Victor O. K.</dc:creator>
 <dc:creator>Qu, Huamin</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Anomaly detection plays a key role in air quality analysis by enhancing
situational awareness and alerting users to potential hazards. However,
existing anomaly detection approaches for air quality analysis have their own
limitations regarding parameter selection (e.g., need for extensive domain
knowledge), computational expense, general applicability (e.g., require labeled
data), interpretability, and the efficiency of analysis. Furthermore, the poor
quality of collected air quality data (inconsistently formatted and sometimes
missing) also increases the difficulty of analysis substantially. In this
paper, we systematically formulate design requirements for a system that can
solve these limitations and then propose AQEyes, an integrated visual analytics
system for efficiently monitoring, detecting, and examining anomalies in air
quality data. In particular, we propose a unified end-to-end tunable machine
learning pipeline that includes several data pre-processors and featurizers to
deal with data quality issues. The pipeline integrates an efficient
unsupervised anomaly detection method that works without the use of labeled
data and overcomes the limitations of existing approaches. Further, we develop
an interactive visualization system to visualize the outputs from the pipeline.
The system incorporates a set of novel visualization and interaction designs,
allowing analysts to visually examine air quality dynamics and anomalous events
in multiple scales and from multiple facets. We demonstrate the performance of
this pipeline through a quantitative evaluation and show the effectiveness of
the visualization system using qualitative case studies on real-world datasets.
</dc:description>
 <dc:description>Comment: 11 pages, 6 figures</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12910</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12913</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Estimation of Concentration Under $\ell_p$-Norm Distance
  Metrics Using Half Spaces</dc:title>
 <dc:creator>Prescott, Jack</dc:creator>
 <dc:creator>Zhang, Xiao</dc:creator>
 <dc:creator>Evans, David</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Concentration of measure has been argued to be the fundamental cause of
adversarial vulnerability. Mahloujifar et al. presented an empirical way to
measure the concentration of a data distribution using samples, and employed it
to find lower bounds on intrinsic robustness for several benchmark datasets.
However, it remains unclear whether these lower bounds are tight enough to
provide a useful approximation for the intrinsic robustness of a dataset. To
gain a deeper understanding of the concentration of measure phenomenon, we
first extend the Gaussian Isoperimetric Inequality to non-spherical Gaussian
measures and arbitrary $\ell_p$-norms ($p \geq 2$). We leverage these
theoretical insights to design a method that uses half-spaces to estimate the
concentration of any empirical dataset under $\ell_p$-norm distance metrics.
Our proposed algorithm is more efficient than Mahloujifar et al.'s, and our
experiments on synthetic datasets and image benchmarks demonstrate that it is
able to find much tighter intrinsic robustness bounds. These tighter estimates
provide further evidence that rules out intrinsic dataset concentration as a
possible explanation for the adversarial vulnerability of state-of-the-art
classifiers.
</dc:description>
 <dc:description>Comment: ICLR 2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12913</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12919</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Failure-Tolerant Contract-Based Design of an Automated Valet Parking
  System using a Directive-Response Architecture</dc:title>
 <dc:creator>Graebener, Josefine</dc:creator>
 <dc:creator>Phan-Minh, Tung</dc:creator>
 <dc:creator>Yan, Jiaqi</dc:creator>
 <dc:creator>Zhao, Qiming</dc:creator>
 <dc:creator>Murray, Richard M.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  Increased complexity in cyber-physical systems calls for modular system
design methodologies that guarantee correct and reliable behavior, both in
normal operations and in the presence of failures. This paper aims to extend
the contract-based design approach using a directive-response architecture to
enable reactivity to failure scenarios. The architecture is demonstrated on a
modular automated valet parking (AVP) system. The contracts for the different
components in the AVP system are explicitly defined, implemented, and validated
against a Python implementation.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12919</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12924</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Benchmarking Deep Trackers on Aerial Videos</dc:title>
 <dc:creator>Taufique, Abu Md Niamul</dc:creator>
 <dc:creator>Minnehan, Breton</dc:creator>
 <dc:creator>Savakis, Andreas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4</dc:subject>
 <dc:subject>I.5</dc:subject>
 <dc:description>  In recent years, deep learning-based visual object trackers have achieved
state-of-the-art performance on several visual object tracking benchmarks.
However, most tracking benchmarks are focused on ground level videos, whereas
aerial tracking presents a new set of challenges. In this paper, we compare ten
trackers based on deep learning techniques on four aerial datasets. We choose
top performing trackers utilizing different approaches, specifically tracking
by detection, discriminative correlation filters, Siamese networks and
reinforcement learning. In our experiments, we use a subset of OTB2015 dataset
with aerial style videos; the UAV123 dataset without synthetic sequences; the
UAV20L dataset, which contains 20 long sequences; and DTB70 dataset as our
benchmark datasets. We compare the advantages and disadvantages of different
trackers in different tracking situations encountered in aerial data. Our
findings indicate that the trackers perform significantly worse in aerial
datasets compared to standard ground level videos. We attribute this effect to
smaller target size, camera motion, significant camera rotation with respect to
the target, out of view movement, and clutter in the form of occlusions or
similar looking distractors near tracked object.
</dc:description>
 <dc:description>Comment: 25 pages, 10 figures, 7 tables</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12924</dc:identifier>
 <dc:identifier>Sensors 2020, 20(2), 547</dc:identifier>
 <dc:identifier>doi:10.3390/s20020547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12926</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond Visual Attractiveness: Physically Plausible Single Image HDR
  Reconstruction for Spherical Panoramas</dc:title>
 <dc:creator>Wei, Wei</dc:creator>
 <dc:creator>Guan, Li</dc:creator>
 <dc:creator>Liu, Yue</dc:creator>
 <dc:creator>Kang, Hao</dc:creator>
 <dc:creator>Li, Haoxiang</dc:creator>
 <dc:creator>Wu, Ying</dc:creator>
 <dc:creator>Hua, Gang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  HDR reconstruction is an important task in computer vision with many
industrial needs. The traditional approaches merge multiple exposure shots to
generate HDRs that correspond to the physical quantity of illuminance of the
scene. However, the tedious capturing process makes such multi-shot approaches
inconvenient in practice. In contrast, recent single-shot methods predict a
visually appealing HDR from a single LDR image through deep learning. But it is
not clear whether the previously mentioned physical properties would still
hold, without training the network to explicitly model them. In this paper, we
introduce the physical illuminance constraints to our single-shot HDR
reconstruction framework, with a focus on spherical panoramas. By the proposed
physical regularization, our method can generate HDRs which are not only
visually appealing but also physically plausible. For evaluation, we collect a
large dataset of LDR and HDR images with ground truth illuminance measures.
Extensive experiments show that our HDR images not only maintain high visual
quality but also top all baseline methods in illuminance prediction accuracy.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12926</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12928</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DIALED: Data Integrity Attestation for Low-end Embedded Devices</dc:title>
 <dc:creator>Nunes, Ivan De Oliveira</dc:creator>
 <dc:creator>Jakkamsetti, Sashidhar</dc:creator>
 <dc:creator>Tsudik, Gene</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Verifying integrity of software execution in low-end micro-controller units
(MCUs) is a well-known open problem. The central challenge is how to securely
detect software exploits with minimal overhead, since these MCUs are designed
for low cost, low energy and small size. Some recent work yielded inexpensive
hardware/software co-designs for remotely verifying code and execution
integrity. In particular, a means of detecting unauthorized code modifications
and control-flow attacks were proposed, referred to as Remote Attestation (RA)
and Control-Flow Attestation (CFA), respectively. Despite this progress,
detection of data-only attacks remains elusive. Such attacks exploit software
vulnerabilities to corrupt intermediate computation results stored in data
memory, changing neither the program code nor its control flow. Motivated by
lack of any current techniques (for low-end MCUs) that detect these attacks, in
this paper we propose, implement and evaluate DIALED, the first Data-Flow
Attestation (DFA) technique applicable to the most resource-constrained
embedded devices (e.g., TI MSP430). DIALED works in tandem with a companion CFA
scheme to detect all (currently known) types of runtime software exploits at
fairly low cost.
</dc:description>
 <dc:description>Comment: 6 pages, to be published in DAC 2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12935</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Challenge Obfuscating Interface for Arbiter PUF Variants against
  Machine Learning Attacks</dc:title>
 <dc:creator>Zhuang, Yu</dc:creator>
 <dc:creator>Mursi, Khalid T.</dc:creator>
 <dc:creator>Gaoxiang, Li</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Security is of critical importance for the Internet of Things (IoT). Many IoT
devices are resource-constrained, calling for lightweight security protocols.
Physical unclonable functions (PUFs) leverage integrated circuits' variations
to produce responses unique for individual devices, and hence are not
reproducible even by the manufacturers. Implementable with simplistic circuits
of thousands of transistors and operable with low energy, Physical unclonable
functions are promising candidates as security primitives for
resource-constrained IoT devices. Arbiter PUFs (APUFs) are a group of
delay-based PUFs which are highly lightweight in resource requirements but
suffer from high susceptibility to machine learning attacks. To defend APUF
variants against machine learning attacks, we introduce challenge input
interface, which incurs low resource overhead. With the interface, experimental
attack study shows that all tested PUFs have substantially improved their
resistance against machine learning attacks, rendering interfaced APUF variants
promising candidates for security critical applications.
</dc:description>
 <dc:description>Comment: 7 Pages, 5 figures</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12935</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12940</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exercise with Social Robots: Companion or Coach?</dc:title>
 <dc:creator>Griffiths, Sascha</dc:creator>
 <dc:creator>Alpay, Tayfun</dc:creator>
 <dc:creator>Sutherland, Alexander</dc:creator>
 <dc:creator>Kerzel, Matthias</dc:creator>
 <dc:creator>Eppe, Manfred</dc:creator>
 <dc:creator>Strahl, Erik</dc:creator>
 <dc:creator>Wermter, Stefan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  In this paper, we investigate the roles that social robots can take in
physical exercise with human partners. In related work, robots or virtual
intelligent agents take the role of a coach or instructor whereas in other
approaches they are used as motivational aids. These are two &quot;paradigms&quot;, so to
speak, within the small but growing area of robots for social exercise. We
designed an online questionnaire to test whether the preferred role in which
people want to see robots would be the companion or the coach. The
questionnaire asks people to imagine working out with a robot with the help of
three utilized questionnaires: (1) CART-Q which is used for judging
coach-athlete relationships, (2) the mind perception questionnaire and (3) the
System Usability Scale (SUS). We present the methodology, some preliminary
results as well as our intended future work on personal robots for coaching.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures, Found in Proceedings of Workshop on Personal
  Robots for Exercising and Coaching at the HRI 2018 (HRI2018)</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12944</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scene-Intuitive Agent for Remote Embodied Visual Grounding</dc:title>
 <dc:creator>Lin, Xiangru</dc:creator>
 <dc:creator>Li, Guanbin</dc:creator>
 <dc:creator>Yu, Yizhou</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Humans learn from life events to form intuitions towards the understanding of
visual environments and languages. Envision that you are instructed by a
high-level instruction, &quot;Go to the bathroom in the master bedroom and replace
the blue towel on the left wall&quot;, what would you possibly do to carry out the
task? Intuitively, we comprehend the semantics of the instruction to form an
overview of where a bathroom is and what a blue towel is in mind; then, we
navigate to the target location by consistently matching the bathroom
appearance in mind with the current scene. In this paper, we present an agent
that mimics such human behaviors. Specifically, we focus on the Remote Embodied
Visual Referring Expression in Real Indoor Environments task, called REVERIE,
where an agent is asked to correctly localize a remote target object specified
by a concise high-level natural language instruction, and propose a two-stage
training pipeline. In the first stage, we pretrain the agent with two
cross-modal alignment sub-tasks, namely the Scene Grounding task and the Object
Grounding task. The agent learns where to stop in the Scene Grounding task and
what to attend to in the Object Grounding task respectively. Then, to generate
action sequences, we propose a memory-augmented attentive action decoder to
smoothly fuse the pre-trained vision and language representations with the
agent's past memory experiences. Without bells and whistles, experimental
results show that our method outperforms previous state-of-the-art(SOTA)
significantly, demonstrating the effectiveness of our method.
</dc:description>
 <dc:description>Comment: Accepted by CVPR 2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12944</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12945</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Imitation Learning of Linear Control Policies: Enforcing Stability
  and Robustness Constraints via LMI Conditions</dc:title>
 <dc:creator>Havens, Aaron</dc:creator>
 <dc:creator>Hu, Bin</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  When applying imitation learning techniques to fit a policy from expert
demonstrations, one can take advantage of prior stability/robustness
assumptions on the expert's policy and incorporate such control-theoretic prior
knowledge explicitly into the learning process. In this paper, we formulate the
imitation learning of linear policies as a constrained optimization problem,
and present efficient methods which can be used to enforce stability and
robustness constraints during the learning processes. Specifically, we show
that one can guarantee the closed-loop stability and robustness by posing
linear matrix inequality (LMI) constraints on the fitted policy. Then both the
projected gradient descent method and the alternating direction method of
multipliers (ADMM) method can be applied to solve the resulting constrained
policy fitting problem. Finally, we provide numerical results to demonstrate
the effectiveness of our methods in producing linear polices with various
stability and robustness guarantees.
</dc:description>
 <dc:description>Comment: To appear in ACC 2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12945</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12947</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Meta-Learned Invariant Risk Minimization</dc:title>
 <dc:creator>Bae, Jun-Hyun</dc:creator>
 <dc:creator>Choi, Inchul</dc:creator>
 <dc:creator>Lee, Minho</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Empirical Risk Minimization (ERM) based machine learning algorithms have
suffered from weak generalization performance on data obtained from
out-of-distribution (OOD). To address this problem, Invariant Risk Minimization
(IRM) objective was suggested to find invariant optimal predictor which is less
affected by the changes in data distribution. However, even with such progress,
IRMv1, the practical formulation of IRM, still shows performance degradation
when there are not enough training data, and even fails to generalize to OOD,
if the number of spurious correlations is larger than the number of
environments. In this paper, to address such problems, we propose a novel
meta-learning based approach for IRM. In this method, we do not assume the
linearity of classifier for the ease of optimization, and solve ideal bi-level
IRM objective with Model-Agnostic Meta-Learning (MAML) framework. Our method is
more robust to the data with spurious correlations and can provide an invariant
optimal classifier even when data from each distribution are scarce. In
experiments, we demonstrate that our algorithm not only has better OOD
generalization performance than IRMv1 and all IRM variants, but also addresses
the weakness of IRMv1 with improved stability.
</dc:description>
 <dc:description>Comment: 12 pages, 10 figures</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12955</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Scene Structure Guidance via Cross-Task Knowledge Transfer for
  Single Depth Super-Resolution</dc:title>
 <dc:creator>Sun, Baoli</dc:creator>
 <dc:creator>Ye, Xinchen</dc:creator>
 <dc:creator>Li, Baopu</dc:creator>
 <dc:creator>Li, Haojie</dc:creator>
 <dc:creator>Wang, Zhihui</dc:creator>
 <dc:creator>Xu, Rui</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Existing color-guided depth super-resolution (DSR) approaches require paired
RGB-D data as training samples where the RGB image is used as structural
guidance to recover the degraded depth map due to their geometrical similarity.
However, the paired data may be limited or expensive to be collected in actual
testing environment. Therefore, we explore for the first time to learn the
cross-modality knowledge at training stage, where both RGB and depth modalities
are available, but test on the target dataset, where only single depth modality
exists. Our key idea is to distill the knowledge of scene structural guidance
from RGB modality to the single DSR task without changing its network
architecture. Specifically, we construct an auxiliary depth estimation (DE)
task that takes an RGB image as input to estimate a depth map, and train both
DSR task and DE task collaboratively to boost the performance of DSR. Upon
this, a cross-task interaction module is proposed to realize bilateral cross
task knowledge transfer. First, we design a cross-task distillation scheme that
encourages DSR and DE networks to learn from each other in a teacher-student
role-exchanging fashion. Then, we advance a structure prediction (SP) task that
provides extra structure regularization to help both DSR and DE networks learn
more informative structure representations for depth recovery. Extensive
experiments demonstrate that our scheme achieves superior performance in
comparison with other DSR methods.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12955</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12957</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-view 3D Reconstruction with Transformer</dc:title>
 <dc:creator>Wang, Dan</dc:creator>
 <dc:creator>Cui, Xinrui</dc:creator>
 <dc:creator>Chen, Xun</dc:creator>
 <dc:creator>Zou, Zhengxia</dc:creator>
 <dc:creator>Shi, Tianyang</dc:creator>
 <dc:creator>Salcudean, Septimiu</dc:creator>
 <dc:creator>Wang, Z. Jane</dc:creator>
 <dc:creator>Ward, Rabab</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep CNN-based methods have so far achieved the state of the art results in
multi-view 3D object reconstruction. Despite the considerable progress, the two
core modules of these methods - multi-view feature extraction and fusion, are
usually investigated separately, and the object relations in different views
are rarely explored. In this paper, inspired by the recent great success in
self-attention-based Transformer models, we reformulate the multi-view 3D
reconstruction as a sequence-to-sequence prediction problem and propose a new
framework named 3D Volume Transformer (VolT) for such a task. Unlike previous
CNN-based methods using a separate design, we unify the feature extraction and
view fusion in a single Transformer network. A natural advantage of our design
lies in the exploration of view-to-view relationships using self-attention
among multiple unordered inputs. On ShapeNet - a large-scale 3D reconstruction
benchmark dataset, our method achieves a new state-of-the-art accuracy in
multi-view reconstruction with fewer parameters ($70\%$ less) than other
CNN-based methods. Experimental results also suggest the strong scaling
capability of our method. Our code will be made publicly available.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12957</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12958</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting User-Perceived Failure in Mobile Applications via Mining User
  Traces</dc:title>
 <dc:creator>Tian, Deyu</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Mobile applications (apps) often suffer from failure nowadays. Developers
usually pay more attention to the failure that is perceived by users and
compromises the user experience. Existing approaches focus on mining large
volume logs to detect failure, however, to our best knowledge, there is no
approach focusing on detecting whether users have actually perceived failure,
which directly influence the user experience. In this paper, we propose a novel
approach to detecting user-perceived failure in mobile apps. By leveraging the
frontend user traces, our approach first builds an app page model, and applies
an unsupervised detection algorithm to detect whether a user has perceived
failure. Our insight behind the algorithm is that when user-perceived failure
occurs on an app page, the users will backtrack and revisit the certain page to
retry. Preliminary evaluation results show that our approach can achieve good
detection performance on a dataset collected from real world users.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12958</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12964</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Volumetric Propagation Network: Stereo-LiDAR Fusion for Long-Range Depth
  Estimation</dc:title>
 <dc:creator>Choe, Jaesung</dc:creator>
 <dc:creator>Joo, Kyungdon</dc:creator>
 <dc:creator>Imtiaz, Tooba</dc:creator>
 <dc:creator>Kweon, In So</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Stereo-LiDAR fusion is a promising task in that we can utilize two different
types of 3D perceptions for practical usage -- dense 3D information (stereo
cameras) and highly-accurate sparse point clouds (LiDAR). However, due to their
different modalities and structures, the method of aligning sensor data is the
key for successful sensor fusion. To this end, we propose a geometry-aware
stereo-LiDAR fusion network for long-range depth estimation, called volumetric
propagation network. The key idea of our network is to exploit sparse and
accurate point clouds as a cue for guiding correspondences of stereo images in
a unified 3D volume space. Unlike existing fusion strategies, we directly embed
point clouds into the volume, which enables us to propagate valid information
into nearby voxels in the volume, and to reduce the uncertainty of
correspondences. Thus, it allows us to fuse two different input modalities
seamlessly and regress a long-range depth map. Our fusion is further enhanced
by a newly proposed feature extraction layer for point clouds guided by images:
FusionConv. FusionConv extracts point cloud features that consider both
semantic (2D image domain) and geometric (3D domain) relations and aid fusion
at the volume. Our network achieves state-of-the-art performance on the KITTI
and the Virtual-KITTI datasets among recent stereo-LiDAR fusion methods.
</dc:description>
 <dc:description>Comment: This is a presentation paper for ICRA 2021. Accepted at RA-L 2021</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12964</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12968</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Receding Horizon Motion Planning for Multi-Agent Systems: A Velocity
  Obstacle Based Probabilistic Method</dc:title>
 <dc:creator>Zhang, Xiaoxue</dc:creator>
 <dc:creator>Ma, Jun</dc:creator>
 <dc:creator>Cheng, Zilong</dc:creator>
 <dc:creator>Huang, Sunan</dc:creator>
 <dc:creator>Lee, Tong Heng</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, a novel and innovative methodology for feasible motion
planning in the multi-agent system is developed. On the basis of velocity
obstacles characteristics, the chance constraints are formulated in the
receding horizon control (RHC) problem, and geometric information of collision
cones is used to generate the feasible regions of velocities for the host
agent. By this approach, the motion planning is conducted at the velocity level
instead of the position level. Thus, it guarantees a safer collision-free
trajectory for the multi-agent system, especially for the systems with
high-speed moving agents. Moreover, a probability threshold of potential
collisions can be satisfied during the motion planning process. In order to
validate the effectiveness of the methodology, different scenarios for multiple
agents are investigated, and the simulation results clearly show that the
proposed approach can effectively avoid potential collisions with a collision
probability less than a specific threshold.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12968</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12972</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hetero-Modal Learning and Expansive Consistency Constraints for
  Semi-Supervised Detection from Multi-Sequence Data</dc:title>
 <dc:creator>Lai, Bolin</dc:creator>
 <dc:creator>Wu, Yuhsuan</dc:creator>
 <dc:creator>Zhou, Xiao-Yun</dc:creator>
 <dc:creator>Wang, Peng</dc:creator>
 <dc:creator>Lu, Le</dc:creator>
 <dc:creator>Huang, Lingyun</dc:creator>
 <dc:creator>Han, Mei</dc:creator>
 <dc:creator>Xiao, Jing</dc:creator>
 <dc:creator>Hu, Heping</dc:creator>
 <dc:creator>Harrison, Adam P.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Lesion detection serves a critical role in early diagnosis and has been well
explored in recent years due to methodological advancesand increased data
availability. However, the high costs of annotations hinder the collection of
large and completely labeled datasets, motivating semi-supervised detection
approaches. In this paper, we introduce mean teacher hetero-modal detection
(MTHD), which addresses two important gaps in current semi-supervised
detection. First, it is not obvious how to enforce unlabeled consistency
constraints across the very different outputs of various detectors, which has
resulted in various compromises being used in the state of the art. Using an
anchor-free framework, MTHD formulates a mean teacher approach without such
compromises, enforcing consistency on the soft-output of object centers and
size. Second, multi-sequence data is often critical, e.g., for abdominal lesion
detection, but unlabeled data is often missing sequences. To deal with this,
MTHD incorporates hetero-modal learning in its framework. Unlike prior art,
MTHD is able to incorporate an expansive set of consistency constraints that
include geometric transforms and random sequence combinations. We train and
evaluate MTHD on liver lesion detection using the largest MR lesion dataset to
date (1099 patients with &gt;5000 volumes). MTHD surpasses the best
fully-supervised and semi-supervised competitors by 10.1% and 3.5%,
respectively, in average sensitivity.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12975</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>VLGrammar: Grounded Grammar Induction of Vision and Language</dc:title>
 <dc:creator>Hong, Yining</dc:creator>
 <dc:creator>Li, Qing</dc:creator>
 <dc:creator>Zhu, Song-Chun</dc:creator>
 <dc:creator>Huang, Siyuan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Cognitive grammar suggests that the acquisition of language grammar is
grounded within visual structures. While grammar is an essential representation
of natural language, it also exists ubiquitously in vision to represent the
hierarchical part-whole structure. In this work, we study grounded grammar
induction of vision and language in a joint learning framework. Specifically,
we present VLGrammar, a method that uses compound probabilistic context-free
grammars (compound PCFGs) to induce the language grammar and the image grammar
simultaneously. We propose a novel contrastive learning framework to guide the
joint learning of both modules. To provide a benchmark for the grounded grammar
induction task, we collect a large-scale dataset, \textsc{PartIt}, which
contains human-written sentences that describe part-level semantics for 3D
objects. Experiments on the \textsc{PartIt} dataset show that VLGrammar
outperforms all baselines in image grammar induction and language grammar
induction. The learned VLGrammar naturally benefits related downstream tasks.
Specifically, it improves the image unsupervised clustering accuracy by 30\%,
and performs well in image retrieval and text retrieval. Notably, the induced
grammar shows superior generalizability by easily generalizing to unseen
categories.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12975</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12978</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RPVNet: A Deep and Efficient Range-Point-Voxel Fusion Network for LiDAR
  Point Cloud Segmentation</dc:title>
 <dc:creator>Xu, Jianyun</dc:creator>
 <dc:creator>Zhang, Ruixiang</dc:creator>
 <dc:creator>Dou, Jian</dc:creator>
 <dc:creator>Zhu, Yushi</dc:creator>
 <dc:creator>Sun, Jie</dc:creator>
 <dc:creator>Pu, Shiliang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Point clouds can be represented in many forms (views), typically, point-based
sets, voxel-based cells or range-based images(i.e., panoramic view). The
point-based view is geometrically accurate, but it is disordered, which makes
it difficult to find local neighbors efficiently. The voxel-based view is
regular, but sparse, and computation grows cubically when voxel resolution
increases. The range-based view is regular and generally dense, however
spherical projection makes physical dimensions distorted. Both voxel- and
range-based views suffer from quantization loss, especially for voxels when
facing large-scale scenes. In order to utilize different view's advantages and
alleviate their own shortcomings in fine-grained segmentation task, we propose
a novel range-point-voxel fusion network, namely RPVNet. In this network, we
devise a deep fusion framework with multiple and mutual information
interactions among these three views and propose a gated fusion module (termed
as GFM), which can adaptively merge the three features based on concurrent
inputs. Moreover, the proposed RPV interaction mechanism is highly efficient,
and we summarize it into a more general formulation. By leveraging this
efficient interaction and relatively lower voxel resolution, our method is also
proved to be more efficient. Finally, we evaluated the proposed model on two
large-scale datasets, i.e., SemanticKITTI and nuScenes, and it shows
state-of-the-art performance on both of them. Note that, our method currently
ranks 1st on SemanticKITTI leaderboard without any extra tricks.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12978</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12980</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On a realization of motion and similarity group equivalence classes of
  labeled points in $\mathbb R^k$ with applications to computer vision</dc:title>
 <dc:creator>Damelin, Steven B.</dc:creator>
 <dc:creator>Ragozin, David L.</dc:creator>
 <dc:creator>Werman, Michael</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>70E15, 15A16, 14B16, 68T45, 49K35, 49N15</dc:subject>
 <dc:description>  We study a realization of motion and similarity group equivalence classes of
$n\geq 1$ labeled points in $\mathbb R^k,\, k\geq 1$ as a metric space with a
computable metric. Our study is motivated by applications in computer vision.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12980</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12982</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Semantic Retrieval to Pairwise Ranking: Applying Deep Learning in
  E-commerce Search</dc:title>
 <dc:creator>Li, Rui</dc:creator>
 <dc:creator>Jiang, Yunjiang</dc:creator>
 <dc:creator>Yang, Wenyun</dc:creator>
 <dc:creator>Tang, Guoyu</dc:creator>
 <dc:creator>Wang, Songlin</dc:creator>
 <dc:creator>Ma, Chaoyi</dc:creator>
 <dc:creator>He, Wei</dc:creator>
 <dc:creator>Xiong, Xi</dc:creator>
 <dc:creator>Xiao, Yun</dc:creator>
 <dc:creator>Zhao, Eric Yihong</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We introduce deep learning models to the two most important stages in product
search at JD.com, one of the largest e-commerce platforms in the world.
Specifically, we outline the design of a deep learning system that retrieves
semantically relevant items to a query within milliseconds, and a pairwise deep
re-ranking system, which learns subtle user preferences. Compared to
traditional search systems, the proposed approaches are better at semantic
retrieval and personalized ranking, achieving significant improvements.
</dc:description>
 <dc:description>Comment: Accepted in SIGIR 2019</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12982</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12988</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One to Many: Adaptive Instrument Segmentation via Meta Learning and
  Dynamic Online Adaptation in Robotic Surgical Video</dc:title>
 <dc:creator>Zhao, Zixu</dc:creator>
 <dc:creator>Jin, Yueming</dc:creator>
 <dc:creator>Lu, Bo</dc:creator>
 <dc:creator>Ng, Chi-Fai</dc:creator>
 <dc:creator>Dou, Qi</dc:creator>
 <dc:creator>Liu, Yun-Hui</dc:creator>
 <dc:creator>Heng, Pheng-Ann</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Surgical instrument segmentation in robot-assisted surgery (RAS) - especially
that using learning-based models - relies on the assumption that training and
testing videos are sampled from the same domain. However, it is impractical and
expensive to collect and annotate sufficient data from every new domain. To
greatly increase the label efficiency, we explore a new problem, i.e., adaptive
instrument segmentation, which is to effectively adapt one source model to new
robotic surgical videos from multiple target domains, only given the annotated
instruments in the first frame. We propose MDAL, a meta-learning based dynamic
online adaptive learning scheme with a two-stage framework to fast adapt the
model parameters on the first frame and partial subsequent frames while
predicting the results. MDAL learns the general knowledge of instruments and
the fast adaptation ability through the video-specific meta-learning paradigm.
The added gradient gate excludes the noisy supervision from pseudo masks for
dynamic online adaptation on target videos. We demonstrate empirically that
MDAL outperforms other state-of-the-art methods on two datasets (including a
real-world RAS dataset). The promising performance on ex-vivo scenes also
benefits the downstream tasks such as robot-assisted suturing and camera
control.
</dc:description>
 <dc:description>Comment: Accepted by ICRA 2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12988</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12989</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relation-aware Instance Refinement for Weakly Supervised Visual
  Grounding</dc:title>
 <dc:creator>Liu, Yongfei</dc:creator>
 <dc:creator>Wan, Bo</dc:creator>
 <dc:creator>Ma, Lin</dc:creator>
 <dc:creator>He, Xuming</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Visual grounding, which aims to build a correspondence between visual objects
and their language entities, plays a key role in cross-modal scene
understanding. One promising and scalable strategy for learning visual
grounding is to utilize weak supervision from only image-caption pairs.
Previous methods typically rely on matching query phrases directly to a
precomputed, fixed object candidate pool, which leads to inaccurate
localization and ambiguous matching due to lack of semantic relation
constraints.
  In our paper, we propose a novel context-aware weakly-supervised learning
method that incorporates coarse-to-fine object refinement and entity relation
modeling into a two-stage deep network, capable of producing more accurate
object representation and matching. To effectively train our network, we
introduce a self-taught regression loss for the proposal locations and a
classification loss based on parsed entity relations.
  Extensive experiments on two public benchmarks Flickr30K Entities and
ReferItGame demonstrate the efficacy of our weakly grounding framework. The
results show that we outperform the previous methods by a considerable margin,
achieving 59.27\% top-1 accuracy in Flickr30K Entities and 37.68\% in the
ReferItGame dataset respectively (Code is available at
https://github.com/youngfly11/ReIR-WeaklyGrounding.pytorch.git).
</dc:description>
 <dc:description>Comment: Accepted by CVPR2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12989</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12993</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of QoS in Heterogeneous Networks with Clustered Deployment and
  Caching Aware Capacity Allocation</dc:title>
 <dc:creator>Ohashi, Takehiro</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  In cellular networks, the densification of connected devices and base
stations engender the ever-growing traffic intensity, and caching popular
contents with smart management is a promising way to alleviate such
consequences. Our research extends the previously proposed analysis of
three-tier cache enabled Heterogeneous Networks (HetNets). The main
contributions are threefold. We consider the more realistic assumption; that
is, the distribution of small base stations is following Poisson-Poisson
cluster processes, which reflects the real situations of geographic
restriction, user dense areas, and coverage-holes. We propose the allocation of
downlink data transmission capacity according to the cases of requested
contents which are either cached or non-cached in nearby nodes and elucidate
the traffic efficiency of the allocation under the effect of clustered
deployment of small base stations. The throughput and delay of the allocation
system are derived based on the approximated sojourn time of the Discriminatory
Processor Sharing (DPS) queue. We present the results of achievable efficiency
and such a system's performance for a better caching solution to the challenges
of future cellular networks.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12993</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.12997</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Shadow Generation to Shadow Removal</dc:title>
 <dc:creator>Liu, Zhihao</dc:creator>
 <dc:creator>Yin, Hui</dc:creator>
 <dc:creator>Wu, Xinyi</dc:creator>
 <dc:creator>Wu, Zhenyao</dc:creator>
 <dc:creator>Mi, Yang</dc:creator>
 <dc:creator>Wang, Song</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Shadow removal is a computer-vision task that aims to restore the image
content in shadow regions. While almost all recent shadow-removal methods
require shadow-free images for training, in ECCV 2020 Le and Samaras introduces
an innovative approach without this requirement by cropping patches with and
without shadows from shadow images as training samples. However, it is still
laborious and time-consuming to construct a large amount of such unpaired
patches. In this paper, we propose a new G2R-ShadowNet which leverages shadow
generation for weakly-supervised shadow removal by only using a set of shadow
images and their corresponding shadow masks for training. The proposed
G2R-ShadowNet consists of three sub-networks for shadow generation, shadow
removal and refinement, respectively and they are jointly trained in an
end-to-end fashion. In particular, the shadow generation sub-net stylises
non-shadow regions to be shadow ones, leading to paired data for training the
shadow-removal sub-net. Extensive experiments on the ISTD dataset and the Video
Shadow Removal dataset show that the proposed G2R-ShadowNet achieves
competitive performances against the current state of the arts and outperforms
Le and Samaras' patch-based shadow-removal method.
</dc:description>
 <dc:description>Comment: Accepted by CVPR2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.12997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13001</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>X-view: Non-egocentric Multi-View 3D Object Detector</dc:title>
 <dc:creator>Xie, Liang</dc:creator>
 <dc:creator>Xu, Guodong</dc:creator>
 <dc:creator>Cai, Deng</dc:creator>
 <dc:creator>He, Xiaofei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  3D object detection algorithms for autonomous driving reason about 3D
obstacles either from 3D birds-eye view or perspective view or both. Recent
works attempt to improve the detection performance via mining and fusing from
multiple egocentric views. Although the egocentric perspective view alleviates
some weaknesses of the birds-eye view, the sectored grid partition becomes so
coarse in the distance that the targets and surrounding context mix together,
which makes the features less discriminative. In this paper, we generalize the
research on 3D multi-view learning and propose a novel multi-view-based 3D
detection method, named X-view, to overcome the drawbacks of the multi-view
methods. Specifically, X-view breaks through the traditional limitation about
the perspective view whose original point must be consistent with the 3D
Cartesian coordinate. X-view is designed as a general paradigm that can be
applied on almost any 3D detectors based on LiDAR with only little increment of
running time, no matter it is voxel/grid-based or raw-point-based. We conduct
experiments on KITTI and NuScenes datasets to demonstrate the robustness and
effectiveness of our proposed X-view. The results show that X-view obtains
consistent improvements when combined with four mainstream state-of-the-art 3D
methods: SECOND, PointRCNN, Part-A^2, and PV-RCNN.
</dc:description>
 <dc:description>Comment: 9 pages, 5 figures</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13009</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>UNICORN on RAINBOW: A Universal Commonsense Reasoning Model on a New
  Multitask Benchmark</dc:title>
 <dc:creator>Lourie, Nicholas</dc:creator>
 <dc:creator>Bras, Ronan Le</dc:creator>
 <dc:creator>Bhagavatula, Chandra</dc:creator>
 <dc:creator>Choi, Yejin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Commonsense AI has long been seen as a near impossible goal -- until
recently. Now, research interest has sharply increased with an influx of new
benchmarks and models.
  We propose two new ways to evaluate commonsense models, emphasizing their
generality on new tasks and building on diverse, recently introduced
benchmarks. First, we propose a new multitask benchmark, RAINBOW, to promote
research on commonsense models that generalize well over multiple tasks and
datasets. Second, we propose a novel evaluation, the cost equivalent curve,
that sheds new insight on how the choice of source datasets, pretrained
language models, and transfer learning methods impacts performance and data
efficiency.
  We perform extensive experiments -- over 200 experiments encompassing 4800
models -- and report multiple valuable and sometimes surprising findings, e.g.,
that transfer almost always leads to better or equivalent performance if
following a particular recipe, that QA-based commonsense datasets transfer well
with each other, while commonsense knowledge graphs do not, and that perhaps
counter-intuitively, larger models benefit more from transfer than smaller
ones.
  Last but not least, we introduce a new universal commonsense reasoning model,
UNICORN, that establishes new state-of-the-art performance across 8 popular
commonsense benchmarks, aNLI (87.3%), CosmosQA (91.8%), HellaSWAG (93.9%), PIQA
(90.1%), SocialIQa (83.2%), WinoGrande (86.6%), CycIC (94.0%) and CommonsenseQA
(79.3%).
</dc:description>
 <dc:description>Comment: 27 pages, 19 figures, 34 tables. Accepted to AAAI 2021. For
  associated code and data see https://github.com/allenai/rainbow</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13013</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Multi-parameter Persistence Framework for Mathematical Morphology</dc:title>
 <dc:creator>Chung, Yu-Min</dc:creator>
 <dc:creator>Day, Sarah</dc:creator>
 <dc:creator>Hu, Chuan-Shen</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:description>  The field of mathematical morphology offers well-studied techniques for image
processing. In this work, we view morphological operations through the lens of
persistent homology, a tool at the heart of the field of topological data
analysis. We demonstrate that morphological operations naturally form a
multiparameter filtration and that persistent homology can then be used to
extract information about both topology and geometry in the images as well as
to automate methods for optimizing the study and rendering of structure in
images. For illustration, we apply this framework to analyze noisy binary,
grayscale, and color images.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13017</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Peak Estimation for Uncertain and Switched Systems</dc:title>
 <dc:creator>Miller, Jared</dc:creator>
 <dc:creator>Henrion, Didier</dc:creator>
 <dc:creator>Sznaier, Mario</dc:creator>
 <dc:creator>Korda, Milan</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Peak estimation bounds extreme values of a function of state along
trajectories of a dynamical system. This paper focuses on extending peak
estimation to continuous and discrete settings with time-independent and
time-dependent uncertainty. Techniques from optimal control are used to
incorporate uncertainty into an existing occupation measure-based peak
estimation framework, which includes special consideration for handling
switching uncertainties. The resulting infinite-dimensional linear programs can
be solved approximately with Linear Matrix Inequalities arising from the
moment-SOS hierarchy.
</dc:description>
 <dc:description>Comment: 15 pages, 10 figures</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13019</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topic Modeling Genre: An Exploration of French Classical and
  Enlightenment Drama</dc:title>
 <dc:creator>Sch&#xf6;ch, Christof</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>J.5</dc:subject>
 <dc:description>  The concept of literary genre is a highly complex one: not only are different
genres frequently defined on several, but not necessarily the same levels of
description, but consideration of genres as cognitive, social, or scholarly
constructs with a rich history further complicate the matter. This contribution
focuses on thematic aspects of genre with a quantitative approach, namely Topic
Modeling. Topic Modeling has proven to be useful to discover thematic patterns
and trends in large collections of texts, with a view to class or browse them
on the basis of their dominant themes. It has rarely if ever, however, been
applied to collections of dramatic texts.
  In this contribution, Topic Modeling is used to analyze a collection of
French Drama of the Classical Age and the Enlightenment. The general aim of
this contribution is to discover what semantic types of topics are found in
this collection, whether different dramatic subgenres have distinctive dominant
topics and plot-related topic patterns, and inversely, to what extent
clustering methods based on topic scores per play produce groupings of texts
which agree with more conventional genre distinctions. This contribution shows
that interesting topic patterns can be detected which provide new insights into
the thematic, subgenre-related structure of French drama as well as into the
history of French drama of the Classical Age and the Enlightenment.
</dc:description>
 <dc:description>Comment: 11 figures</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13019</dc:identifier>
 <dc:identifier>Digital Humanities Quarterly, 11.2, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13021</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convex Online Video Frame Subset Selection using Multiple Criteria for
  Data Efficient Autonomous Driving</dc:title>
 <dc:creator>Das, Soumi</dc:creator>
 <dc:creator>Patibandla, Harikrishna</dc:creator>
 <dc:creator>Bhattacharya, Suparna</dc:creator>
 <dc:creator>Bera, Kshounis</dc:creator>
 <dc:creator>Ganguly, Niloy</dc:creator>
 <dc:creator>Bhattacharya, Sourangshu</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  Training vision-based Urban Autonomous driving models is a challenging
problem, which is highly researched in recent times. Training such models is a
data-intensive task requiring the storage and processing of vast volumes of
(possibly redundant) driving video data. In this paper, we study the problem of
developing data-efficient autonomous driving systems. In this context, we study
the problem of multi-criteria online video frame subset selection. We study
convex optimization-based solutions and show that they are unable to provide
solutions with high weightage to the loss of selected video frames. We design a
novel convex optimization-based multi-criteria online subset selection
algorithm that uses a thresholded concave function of selection variables. We
also propose and study a submodular optimization-based algorithm. Extensive
experiments using the driving simulator CARLA show that we are able to drop 80%
of the frames while succeeding to complete 100% of the episodes w.r.t. the
model trained on 100% data, in the most difficult task of taking turns. This
results in a training time of less than 30% compared to training on the whole
dataset. We also perform detailed experiments on prediction performances of
various affordances used by the Conditional Affordance Learning (CAL) model and
show that our subset selection improves performance on the crucial affordance
&quot;Relative Angle&quot; during turns.
</dc:description>
 <dc:description>Comment: Submitted to CVPR 2020</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13023</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can Vision Transformers Learn without Natural Images?</dc:title>
 <dc:creator>Nakashima, Kodai</dc:creator>
 <dc:creator>Kataoka, Hirokatsu</dc:creator>
 <dc:creator>Matsumoto, Asato</dc:creator>
 <dc:creator>Iwata, Kenji</dc:creator>
 <dc:creator>Inoue, Nakamasa</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Can we complete pre-training of Vision Transformers (ViT) without natural
images and human-annotated labels? Although a pre-trained ViT seems to heavily
rely on a large-scale dataset and human-annotated labels, recent large-scale
datasets contain several problems in terms of privacy violations, inadequate
fairness protection, and labor-intensive annotation. In the present paper, we
pre-train ViT without any image collections and annotation labor. We
experimentally verify that our proposed framework partially outperforms
sophisticated Self-Supervised Learning (SSL) methods like SimCLRv2 and MoCov2
without using any natural images in the pre-training phase. Moreover, although
the ViT pre-trained without natural images produces some different
visualizations from ImageNet pre-trained ViT, it can interpret natural image
datasets to a large extent. For example, the performance rates on the CIFAR-10
dataset are as follows: our proposal 97.6 vs. SimCLRv2 97.4 vs. ImageNet 98.0.
</dc:description>
 <dc:description>Comment: Project page:
  https://hirokatsukataoka16.github.io/Vision-Transformers-without-Natural-Images/</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13024</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Stochastic Matching, Poisson Arrivals, and the Natural Linear
  Program</dc:title>
 <dc:creator>Huang, Zhiyi</dc:creator>
 <dc:creator>Shu, Xinkai</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We study the online stochastic matching problem. Consider a bipartite graph
with offline vertices on one side, and with i.i.d.online vertices on the other
side. The offline vertices and the distribution of online vertices are known to
the algorithm beforehand. The realization of the online vertices, however, is
revealed one at a time, upon which the algorithm immediately decides how to
match it. For maximizing the cardinality of the matching, we give a
$0.711$-competitive online algorithm, which improves the best previous ratio of
$0.706$. When the offline vertices are weighted, we introduce a
$0.7009$-competitive online algorithm for maximizing the total weight of the
matched offline vertices, which improves the best previous ratio of $0.662$.
  Conceptually, we find that the analysis of online algorithms simplifies if
the online vertices follow a Poisson process, and establish an approximate
equivalence between this Poisson arrival model and online stochstic matching.
Technically, we propose a natural linear program for the Poisson arrival model,
and demonstrate how to exploit its structure by introducing a converse of
Jensen's inequality. Moreover, we design an algorithmic amortization to replace
the analytic one in previous work, and as a result get the first
vertex-weighted online stochastic matching algorithm that improves the results
in the weaker random arrival model.
</dc:description>
 <dc:description>Comment: 24 pages. Accepted by STOC 2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13029</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Jo-SRC: A Contrastive Approach for Combating Noisy Labels</dc:title>
 <dc:creator>Yao, Yazhou</dc:creator>
 <dc:creator>Sun, Zeren</dc:creator>
 <dc:creator>Zhang, Chuanyi</dc:creator>
 <dc:creator>Shen, Fumin</dc:creator>
 <dc:creator>Wu, Qi</dc:creator>
 <dc:creator>Zhang, Jian</dc:creator>
 <dc:creator>Tang, Zhenmin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Due to the memorization effect in Deep Neural Networks (DNNs), training with
noisy labels usually results in inferior model performance. Existing
state-of-the-art methods primarily adopt a sample selection strategy, which
selects small-loss samples for subsequent training. However, prior literature
tends to perform sample selection within each mini-batch, neglecting the
imbalance of noise ratios in different mini-batches. Moreover, valuable
knowledge within high-loss samples is wasted. To this end, we propose a
noise-robust approach named Jo-SRC (Joint Sample Selection and Model
Regularization based on Consistency). Specifically, we train the network in a
contrastive learning manner. Predictions from two different views of each
sample are used to estimate its &quot;likelihood&quot; of being clean or
out-of-distribution. Furthermore, we propose a joint loss to advance the model
generalization performance by introducing consistency regularization. Extensive
experiments have validated the superiority of our approach over existing
state-of-the-art methods.
</dc:description>
 <dc:description>Comment: accepted by IEEE Conference on Computer Vision and Pattern
  Recognition, 2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13032</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Exploration of Geo-temporal Characteristics of Users' Reactions on
  Social Media During the Pandemic</dc:title>
 <dc:creator>Abdukhamidov, Eldor</dc:creator>
 <dc:creator>Juraev, Firuz</dc:creator>
 <dc:creator>Abuhamad, Mohammed</dc:creator>
 <dc:creator>AbuHmed, Tamer</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  During the outbreak of the COVID-19 pandemic, social networks become the
preeminent medium for communication, social discussion, and entertainment.
Social network users are regularly expressing their opinions about the impacts
of the coronavirus pandemic. Therefore, social networks serve as a reliable
source for studying the topics, emotions, and attitudes of users that are
discussed during the pandemic. In this paper, we investigate the reactions and
attitudes of people towards topics raised on social media platforms. We
collected data of two large-scale COVID-19 datasets from Twitter and Instagram
for six and three months, respectively. The paper analyzes the reaction of
social network users on different aspects including sentiment analysis, topics
detection, emotions, and geo-temporal characteristics of our dataset. We show
that the dominant sentiment reactions on social media are neutral while the
most discussed topics by social network users are about health issues. The
paper examines the countries that attracted more posts and reactions from
people, as well as the distribution of health-related topics discussed in the
most mentioned countries. We shed light on the temporal shift of topics over
countries. Our results show that posts from the top-mentioned countries
influence and attract more reaction worldwide than posts from other parts of
the world.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13033</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning
  Performance of GPT-2</dc:title>
 <dc:creator>Betz, Gregor</dc:creator>
 <dc:creator>Richardson, Kyle</dc:creator>
 <dc:creator>Voigt, Christian</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Thinking aloud is an effective meta-cognitive strategy human reasoners apply
to solve difficult problems. We suggest to improve the reasoning ability of
pre-trained neural language models in a similar way, namely by expanding a
task's context with problem elaborations that are dynamically generated by the
language model itself. Our main result is that dynamic problem elaboration
significantly improves the zero-shot performance of GPT-2 in a deductive
reasoning and natural language inference task: While the model uses a syntactic
heuristic for predicting an answer, it is capable (to some degree) of
generating reasoned additional context which facilitates the successful
application of its heuristic. We explore different ways of generating
elaborations, including fewshot learning, and find that their relative
performance varies with the specific problem characteristics (such as problem
difficulty). Moreover, the effectiveness of an elaboration can be explained in
terms of the degree to which the elaboration semantically coheres with the
corresponding problem. In particular, elaborations that are most faithful to
the original problem description may boost accuracy by up to 24%.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13039</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Note on the offspring distribution for group testing in the linear
  regime</dc:title>
 <dc:creator>Gebhard, Oliver</dc:creator>
 <dc:creator>Loick, Philipp</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  The group testing problem is concerned with identifying a small set of $k$
infected individuals in a large population of $n$ people. At our disposal is a
testing scheme that can test groups of individuals. A test comes back positive
if and only if at least one individual is infected. In this note, we lay
groundwork for analysing belief propagation for group testing when $k$ scales
linearly in $n$. To this end, we derive the offspring distribution for
different types of individuals. With these distributions at hand, one can
employ the population dynamics algorithm to simulate the posterior marginal
distribution resulting from belief propagation.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13040</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flatness-based MPC for underactuated surface vessels in confined areas</dc:title>
 <dc:creator>Helling, Simon</dc:creator>
 <dc:creator>Lutz, Max</dc:creator>
 <dc:creator>Meurer, Thomas</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  A two-phase model predictive controller (MPC) is proposed for underactuated
surface vessel operation in confined environments. For general driving
maneuvers (phase one) the ship's geometry is not considered explicitly while in
more restricted areas (stage two) which occur, e.g., in mooring maneuvers, the
ship's geometry is approximated to ensure collision avoidance. To remove the
dynamical constraint in the problem setup, the differential flatness of the
fully actuated system is exploited and the flat outputs are parameterized using
B-spline functions. Underactuated behavior is retained by means of inequality
constraints that are imposed on the non-controllable input. In an effort to
solve the MPC, a static nonlinear optimization problem is formulated and
feasibility w.r.t. obstacles and actuator constraints is ensured at collocation
points. Static obstacles are considered as constructive solid geometry
functions in the MPC which also takes into account disturbances induced by
wind.
</dc:description>
 <dc:description>Comment: To appear in the proceedings of the 21st IFAC World Congress 2020
  (IFAC2020), Berlin, Germany</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13040</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13041</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coarse-to-Fine Domain Adaptive Semantic Segmentation with Photometric
  Alignment and Category-Center Regularization</dc:title>
 <dc:creator>Ma, Haoyu</dc:creator>
 <dc:creator>Lin, Xiangru</dc:creator>
 <dc:creator>Wu, Zifeng</dc:creator>
 <dc:creator>Yu, Yizhou</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Unsupervised domain adaptation (UDA) in semantic segmentation is a
fundamental yet promising task relieving the need for laborious annotation
works. However, the domain shifts/discrepancies problem in this task compromise
the final segmentation performance. Based on our observation, the main causes
of the domain shifts are differences in imaging conditions, called image-level
domain shifts, and differences in object category configurations called
category-level domain shifts. In this paper, we propose a novel UDA pipeline
that unifies image-level alignment and category-level feature distribution
regularization in a coarse-to-fine manner. Specifically, on the coarse side, we
propose a photometric alignment module that aligns an image in the source
domain with a reference image from the target domain using a set of image-level
operators; on the fine side, we propose a category-oriented triplet loss that
imposes a soft constraint to regularize category centers in the source domain
and a self-supervised consistency regularization method in the target domain.
Experimental results show that our proposed pipeline improves the
generalization capability of the final segmentation model and significantly
outperforms all previous state-of-the-arts.
</dc:description>
 <dc:description>Comment: Accepted to appear in CVPR2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13043</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Light Field Reconstruction Using Convolutional Network on EPI and
  Extended Applications</dc:title>
 <dc:creator>Wu, Gaochang</dc:creator>
 <dc:creator>Liu, Yebin</dc:creator>
 <dc:creator>Fang, Lu</dc:creator>
 <dc:creator>Dai, Qionghai</dc:creator>
 <dc:creator>Chai, Tianyou</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, a novel convolutional neural network (CNN)-based framework is
developed for light field reconstruction from a sparse set of views. We
indicate that the reconstruction can be efficiently modeled as angular
restoration on an epipolar plane image (EPI). The main problem in direct
reconstruction on the EPI involves an information asymmetry between the spatial
and angular dimensions, where the detailed portion in the angular dimensions is
damaged by undersampling. Directly upsampling or super-resolving the light
field in the angular dimensions causes ghosting effects. To suppress these
ghosting effects, we contribute a novel &quot;blur-restoration-deblur&quot; framework.
First, the &quot;blur&quot; step is applied to extract the low-frequency components of
the light field in the spatial dimensions by convolving each EPI slice with a
selected blur kernel. Then, the &quot;restoration&quot; step is implemented by a CNN,
which is trained to restore the angular details of the EPI. Finally, we use a
non-blind &quot;deblur&quot; operation to recover the spatial high frequencies suppressed
by the EPI blur. We evaluate our approach on several datasets, including
synthetic scenes, real-world scenes and challenging microscope light field
data. We demonstrate the high performance and robustness of the proposed
framework compared with state-of-the-art algorithms. We further show extended
applications, including depth enhancement and interpolation for unstructured
input. More importantly, a novel rendering approach is presented by combining
the proposed framework and depth information to handle large disparities.
</dc:description>
 <dc:description>Comment: Published in IEEE TPAMI, 2019</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13043</dc:identifier>
 <dc:identifier>IEEE Transactions on Pattern Analysis and Machine Intelligence,
  2019</dc:identifier>
 <dc:identifier>doi:10.1109/TPAMI.2018.2845393</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13047</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge-aware Contrastive Molecular Graph Learning</dc:title>
 <dc:creator>Fang, Yin</dc:creator>
 <dc:creator>Yang, Haihong</dc:creator>
 <dc:creator>Zhuang, Xiang</dc:creator>
 <dc:creator>Shao, Xin</dc:creator>
 <dc:creator>Fan, Xiaohui</dc:creator>
 <dc:creator>Chen, Huajun</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  Leveraging domain knowledge including fingerprints and functional groups in
molecular representation learning is crucial for chemical property prediction
and drug discovery. When modeling the relation between graph structure and
molecular properties implicitly, existing works can hardly capture structural
or property changes and complex structure, with much smaller atom vocabulary
and highly frequent atoms. In this paper, we propose the Contrastive
Knowledge-aware GNN (CKGNN) for self-supervised molecular representation
learning to fuse domain knowledge into molecular graph representation. We
explicitly encode domain knowledge via knowledge-aware molecular encoder under
the contrastive learning framework, ensuring that the generated molecular
embeddings equipped with chemical domain knowledge to distinguish molecules
with similar chemical formula but dissimilar functions. Extensive experiments
on 8 public datasets demonstrate the effectiveness of our model with a 6\%
absolute improvement on average against strong competitors. Ablation study and
further investigation also verify the best of both worlds: incorporation of
chemical domain knowledge into self-supervised learning.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13047</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13055</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Zeroing in on Port 0 Traffic in the Wild</dc:title>
 <dc:creator>Maghsoudlou, Aniss</dc:creator>
 <dc:creator>Gasser, Oliver</dc:creator>
 <dc:creator>Feldmann, Anja</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Internet services leverage transport protocol port numbers to specify the
source and destination application layer protocols. While using port 0 is not
allowed in most transport protocols, we see a non-negligible share of traffic
using port 0 in the Internet. In this study, we dissect port 0 traffic to infer
its possible origins and causes using five complementing flow-level and
packet-level datasets. We observe 73 GB of port 0 traffic in one week of IXP
traffic, most of which we identify as an artifact of packet fragmentation. In
our packet-level datasets, most traffic is originated from a small number of
hosts and while most of the packets have no payload, a major fraction of
packets containing payload belong to the BitTorrent protocol. Moreover, we find
unique traffic patterns commonly seen in scanning. In addition to analyzing
passive traces, we also conduct an active measurement campaign to study how
different networks react to port 0 traffic. We find an unexpectedly high
response rate for TCP port 0 probes in IPv4, with very low response rates with
other protocol types. Finally, we will be running continuous port 0
measurements and providing the results to the measurement community.
</dc:description>
 <dc:description>Comment: Proceedings of the 2021 Passive and Active Measurement Conference
  (PAM '21)</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13055</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-030-72582-2_32</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13060</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>De-specializing an HLS library for Deep Neural Networks: improvements
  upon hls4ml</dc:title>
 <dc:creator>Curzel, Serena</dc:creator>
 <dc:creator>Ghielmetti, Nicol&#xf2;</dc:creator>
 <dc:creator>Fiorito, Michele</dc:creator>
 <dc:creator>Ferrandi, Fabrizio</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Custom hardware accelerators for Deep Neural Networks are increasingly
popular: in fact, the flexibility and performance offered by FPGAs are
well-suited to the computational effort and low latency constraints required by
many image recognition and natural language processing tasks. The gap between
high-level Machine Learning frameworks (e.g., Tensorflow, Pytorch) and
low-level hardware design in Verilog/VHDL creates a barrier to widespread
adoption of FPGAs, which can be overcome with the help of High-Level Synthesis.
hls4ml is a framework that translates Deep Neural Networks into annotated C++
code for High-Level Synthesis, offering a complete and user-friendly design
process that has been enthusiastically adopted in physics research. We analyze
the strengths and weaknesses of hls4ml, drafting a plan to enhance its core
library of components in order to allow more advanced optimizations, target a
wider selection of FPGAs, and support larger Neural Network models.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13060</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13061</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revamping Cross-Modal Recipe Retrieval with Hierarchical Transformers
  and Self-supervised Learning</dc:title>
 <dc:creator>Salvador, Amaia</dc:creator>
 <dc:creator>Gundogdu, Erhan</dc:creator>
 <dc:creator>Bazzani, Loris</dc:creator>
 <dc:creator>Donoser, Michael</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Cross-modal recipe retrieval has recently gained substantial attention due to
the importance of food in people's lives, as well as the availability of vast
amounts of digital cooking recipes and food images to train machine learning
models. In this work, we revisit existing approaches for cross-modal recipe
retrieval and propose a simplified end-to-end model based on well established
and high performing encoders for text and images. We introduce a hierarchical
recipe Transformer which attentively encodes individual recipe components
(titles, ingredients and instructions). Further, we propose a self-supervised
loss function computed on top of pairs of individual recipe components, which
is able to leverage semantic relationships within recipes, and enables training
using both image-recipe and recipe-only samples. We conduct a thorough analysis
and ablation studies to validate our design choices. As a result, our proposed
method achieves state-of-the-art performance in the cross-modal recipe
retrieval task on the Recipe1M dataset. We make code and models publicly
available.
</dc:description>
 <dc:description>Comment: CVPR 2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13065</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Value of Communication and Cooperation in a Two-Server Service
  System</dc:title>
 <dc:creator>Fackrell, Mark</dc:creator>
 <dc:creator>Li, Cong</dc:creator>
 <dc:creator>Taylor, Peter</dc:creator>
 <dc:creator>Wang, Jiesen</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  In 2015, Guglielmi and Badia discussed optimal strategies in a particular
type of service system with two strategic servers. In their setup, each server
can either be active or inactive and an active server can be requested to
transmit a sequence of packets. The servers have varying probabilities of
successfully transmitting when they are active, and both servers receive a unit
reward if the sequence of packets is transmitted successfully. Guglielmi and
Badia provided an analysis of optimal strategies in four scenarios: where each
server does not know the other's successful transmission probability; one of
the two servers is always inactive; each server knows the other's successful
transmission probability; and they are willing to cooperate.
  Unfortunately the analysis in Guglielmi and Badia contained errors. In this
paper we correct these errors. We discuss three cases where both servers (I)
communicate and cooperate; (II) neither communicate nor cooperate; (III)
communicate but do not cooperate. In particular, we obtain the unique Nash
equilibrium strategy in Case II through a Bayesian game formulation, and
demonstrate that there is a region in the parameter space where there are
multiple Nash equilibria in Case III. We also quantify the value of
communication or cooperation by comparing the social welfare in the three
cases, and propose possible regulations to make the Nash equilibrium strategy
the socially optimal strategy for both Cases II and III.
</dc:description>
 <dc:description>Comment: 25 pages, 7 figures</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13065</dc:identifier>
 <dc:identifier>doi:10.1017/S1446181120000048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13080</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shift-and-Balance Attention</dc:title>
 <dc:creator>Luo, Chunjie</dc:creator>
 <dc:creator>Zhan, Jianfeng</dc:creator>
 <dc:creator>Hao, Tianshu</dc:creator>
 <dc:creator>Wang, Lei</dc:creator>
 <dc:creator>Gao, Wanling</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Attention is an effective mechanism to improve the deep model capability.
Squeeze-and-Excite (SE) introduces a light-weight attention branch to enhance
the network's representational power. The attention branch is gated using the
Sigmoid function and multiplied by the feature map's trunk branch. It is too
sensitive to coordinate and balance the trunk and attention branches'
contributions. To control the attention branch's influence, we propose a new
attention method, called Shift-and-Balance (SB). Different from
Squeeze-and-Excite, the attention branch is regulated by the learned control
factor to control the balance, then added into the feature map's trunk branch.
Experiments show that Shift-and-Balance attention significantly improves the
accuracy compared to Squeeze-and-Excite when applied in more layers, increasing
more size and capacity of a network. Moreover, Shift-and-Balance attention
achieves better or close accuracy compared to the state-of-art Dynamic
Convolution.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13080</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13084</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Paragraph-level Rationale Extraction through Regularization: A case
  study on European Court of Human Rights Cases</dc:title>
 <dc:creator>Chalkidis, Ilias</dc:creator>
 <dc:creator>Fergadiotis, Manos</dc:creator>
 <dc:creator>Tsarapatsanis, Dimitrios</dc:creator>
 <dc:creator>Aletras, Nikolaos</dc:creator>
 <dc:creator>Androutsopoulos, Ion</dc:creator>
 <dc:creator>Malakasiotis, Prodromos</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Interpretability or explainability is an emerging research field in NLP. From
a user-centric point of view, the goal is to build models that provide proper
justification for their decisions, similar to those of humans, by requiring the
models to satisfy additional constraints. To this end, we introduce a new
application on legal text where, contrary to mainstream literature targeting
word-level rationales, we conceive rationales as selected paragraphs in
multi-paragraph structured court cases. We also release a new dataset
comprising European Court of Human Rights cases, including annotations for
paragraph-level rationales. We use this dataset to study the effect of already
proposed rationale constraints, i.e., sparsity, continuity, and
comprehensiveness, formulated as regularizers. Our findings indicate that some
of these constraints are not beneficial in paragraph-level rationale
extraction, while others need re-formulation to better handle the multi-label
nature of the task we consider. We also introduce a new constraint,
singularity, which further improves the quality of rationales, even compared
with noisy rationale supervision. Experimental results indicate that the newly
introduced task is very challenging and there is a large scope for further
research.
</dc:description>
 <dc:description>Comment: 9 pages, long paper at NAACL 2021 proceedings</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13090</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Greedy-Based Feature Selection for Efficient LiDAR SLAM</dc:title>
 <dc:creator>Jiao, Jianhao</dc:creator>
 <dc:creator>Zhu, Yilong</dc:creator>
 <dc:creator>Ye, Haoyang</dc:creator>
 <dc:creator>Huang, Huaiyang</dc:creator>
 <dc:creator>Yun, Peng</dc:creator>
 <dc:creator>Jiang, Linxin</dc:creator>
 <dc:creator>Wang, Lujia</dc:creator>
 <dc:creator>Liu, Ming</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Modern LiDAR-SLAM (L-SLAM) systems have shown excellent results in
large-scale, real-world scenarios. However, they commonly have a high latency
due to the expensive data association and nonlinear optimization. This paper
demonstrates that actively selecting a subset of features significantly
improves both the accuracy and efficiency of an L-SLAM system. We formulate the
feature selection as a combinatorial optimization problem under a cardinality
constraint to preserve the information matrix's spectral attributes. The
stochastic-greedy algorithm is applied to approximate the optimal results in
real-time. To avoid ill-conditioned estimation, we also propose a general
strategy to evaluate the environment's degeneracy and modify the feature number
online. The proposed feature selector is integrated into a multi-LiDAR SLAM
system. We validate this enhanced system with extensive experiments covering
various scenarios on two sensor setups and computation platforms. We show that
our approach exhibits low localization error and speedup compared to the
state-of-the-art L-SLAM systems. To benefit the community, we have released the
source code: https://ram-lab.com/file/site/m-loam.
</dc:description>
 <dc:description>Comment: 7 pages, 6 figures, accepted at 2021 International Conference on
  Robotics and Automation (ICRA 2021)</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13090</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13103</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finnish Paraphrase Corpus</dc:title>
 <dc:creator>Kanerva, Jenna</dc:creator>
 <dc:creator>Ginter, Filip</dc:creator>
 <dc:creator>Chang, Li-Hsin</dc:creator>
 <dc:creator>Rastas, Iiro</dc:creator>
 <dc:creator>Skantsi, Valtteri</dc:creator>
 <dc:creator>Kilpel&#xe4;inen, Jemina</dc:creator>
 <dc:creator>Kupari, Hanna-Mari</dc:creator>
 <dc:creator>Saarni, Jenna</dc:creator>
 <dc:creator>Sev&#xf3;n, Maija</dc:creator>
 <dc:creator>Tarkka, Otto</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we introduce the first fully manually annotated paraphrase
corpus for Finnish containing 53,572 paraphrase pairs harvested from
alternative subtitles and news headings. Out of all paraphrase pairs in our
corpus 98% are manually classified to be paraphrases at least in their given
context, if not in all contexts. Additionally, we establish a manual candidate
selection method and demonstrate its feasibility in high quality paraphrase
selection in terms of both cost and quality.
</dc:description>
 <dc:description>Comment: Accepted to NoDaLiDa 2021, data:
  https://github.com/TurkuNLP/Turku-paraphrase-corpus</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13103</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13111</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MIcro-Surgical Anastomose Workflow recognition challenge report</dc:title>
 <dc:creator>Huaulm&#xe9;, Arnaud</dc:creator>
 <dc:creator>Sarikaya, Duygu</dc:creator>
 <dc:creator>Mut, K&#xe9;vin Le</dc:creator>
 <dc:creator>Despinoy, Fabien</dc:creator>
 <dc:creator>Long, Yonghao</dc:creator>
 <dc:creator>Dou, Qi</dc:creator>
 <dc:creator>Chng, Chin-Boon</dc:creator>
 <dc:creator>Lin, Wenjun</dc:creator>
 <dc:creator>Kondo, Satoshi</dc:creator>
 <dc:creator>Bravo-S&#xe1;nchez, Laura</dc:creator>
 <dc:creator>Arbel&#xe1;ez, Pablo</dc:creator>
 <dc:creator>Reiter, Wolfgang</dc:creator>
 <dc:creator>Mitsuishi, Manoru</dc:creator>
 <dc:creator>Harada, Kanako</dc:creator>
 <dc:creator>Jannin, Pierre</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The &quot;MIcro-Surgical Anastomose Workflow recognition on training sessions&quot;
(MISAW) challenge provided a data set of 27 sequences of micro-surgical
anastomosis on artificial blood vessels. This data set was composed of videos,
kinematics, and workflow annotations described at three different granularity
levels: phase, step, and activity. The participants were given the option to
use kinematic data and videos to develop workflow recognition models. Four
tasks were proposed to the participants: three of them were related to the
recognition of surgical workflow at three different granularity levels, while
the last one addressed the recognition of all granularity levels in the same
model. One ranking was made for each task. We used the average
application-dependent balanced accuracy (AD-Accuracy) as the evaluation metric.
This takes unbalanced classes into account and it is more clinically relevant
than a frame-by-frame score. Six teams, including a non-competing team,
participated in at least one task. All models employed deep learning models,
such as CNN or RNN. The best models achieved more than 95% AD-Accuracy for
phase recognition, 80% for step recognition, 60% for activity recognition, and
75% for all granularity levels. For high levels of granularity (i.e., phases
and steps), the best models had a recognition rate that may be sufficient for
applications such as prediction of remaining surgical time or resource
management. However, for activities, the recognition rate was still low for
applications that can be employed clinically. The MISAW data set is publicly
available to encourage further research in surgical workflow recognition. It
can be found at www.synapse.org/MISAW
</dc:description>
 <dc:description>Comment: MICCAI2020 challenge report, 36 pages including 15 for supplementary
  material (complet results for each participating teams), 17 figures</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13111</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13115</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A relaxed-inertial forward-backward-forward algorithm for Stochastic
  Generalized Nash equilibrium seeking</dc:title>
 <dc:creator>Cui, Shisheng</dc:creator>
 <dc:creator>Franci, Barbara</dc:creator>
 <dc:creator>Grammatico, Sergio</dc:creator>
 <dc:creator>Shanbhag, Uday V.</dc:creator>
 <dc:creator>Staudigl, Mathias</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In this paper we propose a new operator splitting algorithm for distributed
Nash equilibrium seeking under stochastic uncertainty, featuring relaxation and
inertial effects. Our work is inspired by recent deterministic operator
splitting methods, designed for solving structured monotone inclusion problems.
The algorithm is derived from a forward-backward-forward scheme for solving
structured monotone inclusion problems featuring a Lipschitz continuous and
monotone game operator. To the best of our knowledge, this is the first
distributed (generalized) Nash equilibrium seeking algorithm featuring
acceleration techniques in stochastic Nash games without assuming cocoercivity.
Numerical examples illustrate the effect of inertia and relaxation on the
performance of our proposed algorithm.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13121</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotic Security by Model-based Incident Handlers for Markov Decision
  Processes</dc:title>
 <dc:creator>Sasahara, Hampei</dc:creator>
 <dc:creator>Sandberg, Henrik</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  This study investigates general model-based incident handler's asymptotic
behaviors in time against cyber attacks to control systems. The attacker's and
the defender's dynamic decision making is modeled as an equilibrium of a
dynamic signaling game. It is shown that the defender's belief on existence of
an attacker converges over time for any attacker's strategy provided that the
stochastic dynamics of the control system is known to the defender. This fact
implies that the rational behavior of the attacker converges to a harmless
action as long as the defender possesses an effective counteraction. The
obtained result supports the powerful protection capability achieved by
model-based defense mechanisms.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13127</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Black-box Detection of Backdoor Attacks with Limited Information and
  Data</dc:title>
 <dc:creator>Dong, Yinpeng</dc:creator>
 <dc:creator>Yang, Xiao</dc:creator>
 <dc:creator>Deng, Zhijie</dc:creator>
 <dc:creator>Pang, Tianyu</dc:creator>
 <dc:creator>Xiao, Zihao</dc:creator>
 <dc:creator>Su, Hang</dc:creator>
 <dc:creator>Zhu, Jun</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Although deep neural networks (DNNs) have made rapid progress in recent
years, they are vulnerable in adversarial environments. A malicious backdoor
could be embedded in a model by poisoning the training dataset, whose intention
is to make the infected model give wrong predictions during inference when the
specific trigger appears. To mitigate the potential threats of backdoor
attacks, various backdoor detection and defense methods have been proposed.
However, the existing techniques usually require the poisoned training data or
access to the white-box model, which is commonly unavailable in practice. In
this paper, we propose a black-box backdoor detection (B3D) method to identify
backdoor attacks with only query access to the model. We introduce a
gradient-free optimization algorithm to reverse-engineer the potential trigger
for each class, which helps to reveal the existence of backdoor attacks. In
addition to backdoor detection, we also propose a simple strategy for reliable
predictions using the identified backdoored models. Extensive experiments on
hundreds of DNN models trained on several datasets corroborate the
effectiveness of our method under the black-box setting against various
backdoor attacks.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13127</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13128</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Behavior coordination for self-adaptive robots using constraint-based
  configuration</dc:title>
 <dc:creator>Molina, Martin</dc:creator>
 <dc:creator>Santamaria, Pablo</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Autonomous robots may be able to adapt their behavior in response to changes
in the environment. This is useful, for example, to efficiently handle limited
resources or to respond appropriately to unexpected events such as faults. The
architecture of a self-adaptive robot is complex because it should include
automatic mechanisms to dynamically configure the elements that control robot
behaviors. To facilitate the construction of this type of architectures, it is
useful to have general solutions in the form of software tools that may be
applicable to different robotic systems. This paper presents an original
algorithm to dynamically configure the control architecture, which is
applicable to the development of self-adaptive autonomous robots. This
algorithm uses a constraint-based configuration approach to decide which basic
robot behaviors should be activated in response to both reactive and
deliberative events. The algorithm uses specific search heuristics and
initialization procedures to achieve the performance required by robotic
systems. The solution has been implemented as a software development tool
called Behavior Coordinator CBC (Constraint-Based Configuration), which is
based on ROS and open source, available to the general public. This tool has
been successfully used for building multiple applications of autonomous aerial
robots.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13130</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Accommodating Real-time Jobs on HPC Platforms</dc:title>
 <dc:creator>Nickolay, Sam</dc:creator>
 <dc:creator>Jung, Eun-Sung</dc:creator>
 <dc:creator>Kettimuthu, Rajkumar</dc:creator>
 <dc:creator>Foster, Ian</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Increasing data volumes in scientific experiments necessitate the use of
high-performance computing (HPC) resources for data analysis. In many
scientific fields, the data generated from scientific instruments and
supercomputer simulations must be analyzed rapidly. In fact, the requirement
for quasi-instant feedback is growing. Scientists want to use results from one
experiment to guide the selection of the next or even to improve the course of
a single experiment. Current HPC systems are typically batch-scheduled under
policies in which an arriving job is run immediately only if enough resources
are available; otherwise, it is queued. It is hard for these systems to support
real-time jobs. Real-time jobs, in order to meet their requirements, should
sometimes have to preempt batch jobs and/or be scheduled ahead of batch jobs
that were submitted earlier. Accommodating real-time jobs may negatively impact
system utilization also, especially when preemption/restart of batch jobs is
involved. We first explore several existing scheduling strategies to make
real-time jobs more likely to be scheduled in due time. We then rigorously
formulate the problem as a mixed-integer linear programming for offline
scheduling and develop novel scheduling heuristics for online scheduling. We
perform simulation studies using trace logs of Mira, the IBM BG/Q system at
Argonne National Laboratory, to quantify the impact of real-time jobs on batch
job performance for various percentages of real-time jobs in the workload. We
present new insights gained from grouping jobs into different categories based
on runtime and the number of nodes used and studying the performance of each
category. Our results show that with 10% real-time job percentages,
just-in-time checkpointing combined with our heuristic can improve the
slowdowns of real-time jobs by 35% while limiting the increase of the slowdowns
of batch jobs to 10%.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13130</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13134</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vulnerability of Appearance-based Gaze Estimation</dc:title>
 <dc:creator>Xu, Mingjie</dc:creator>
 <dc:creator>Wang, Haofei</dc:creator>
 <dc:creator>Liu, Yunfei</dc:creator>
 <dc:creator>Lu, Feng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Appearance-based gaze estimation has achieved significant improvement by
using deep learning. However, many deep learning-based methods suffer from the
vulnerability property, i.e., perturbing the raw image using noise confuses the
gaze estimation models. Although the perturbed image visually looks similar to
the original image, the gaze estimation models output the wrong gaze direction.
In this paper, we investigate the vulnerability of appearance-based gaze
estimation. To our knowledge, this is the first time that the vulnerability of
gaze estimation to be found. We systematically characterized the vulnerability
property from multiple aspects, the pixel-based adversarial attack, the
patch-based adversarial attack and the defense strategy. Our experimental
results demonstrate that the CA-Net shows superior performance against attack
among the four popular appearance-based gaze estimation networks, Full-Face,
Gaze-Net, CA-Net and RT-GENE. This study draws the attention of researchers in
the appearance-based gaze estimation community to defense from adversarial
attacks.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13134</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13136</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Representing Numbers in NLP: a Survey and a Vision</dc:title>
 <dc:creator>Thawani, Avijit</dc:creator>
 <dc:creator>Pujara, Jay</dc:creator>
 <dc:creator>Szekely, Pedro A.</dc:creator>
 <dc:creator>Ilievski, Filip</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  NLP systems rarely give special consideration to numbers found in text. This
starkly contrasts with the consensus in neuroscience that, in the brain,
numbers are represented differently from words. We arrange recent NLP work on
numeracy into a comprehensive taxonomy of tasks and methods. We break down the
subjective notion of numeracy into 7 subtasks, arranged along two dimensions:
granularity (exact vs approximate) and units (abstract vs grounded). We analyze
the myriad representational choices made by 18 previously published number
encoders and decoders. We synthesize best practices for representing numbers in
text and articulate a vision for holistic numeracy in NLP, comprised of design
trade-offs and a unified evaluation.
</dc:description>
 <dc:description>Comment: Accepted at NAACL 2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13137</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Salient Boundary Feature for Anchor-free Temporal Action
  Localization</dc:title>
 <dc:creator>Lin, Chuming</dc:creator>
 <dc:creator>Xu, Chengming</dc:creator>
 <dc:creator>Luo, Donghao</dc:creator>
 <dc:creator>Wang, Yabiao</dc:creator>
 <dc:creator>Tai, Ying</dc:creator>
 <dc:creator>Wang, Chengjie</dc:creator>
 <dc:creator>Li, Jilin</dc:creator>
 <dc:creator>Huang, Feiyue</dc:creator>
 <dc:creator>Fu, Yanwei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Temporal action localization is an important yet challenging task in video
understanding. Typically, such a task aims at inferring both the action
category and localization of the start and end frame for each action instance
in a long, untrimmed video.While most current models achieve good results by
using pre-defined anchors and numerous actionness, such methods could be
bothered with both large number of outputs and heavy tuning of locations and
sizes corresponding to different anchors. Instead, anchor-free methods is
lighter, getting rid of redundant hyper-parameters, but gains few attention. In
this paper, we propose the first purely anchor-free temporal localization
method, which is both efficient and effective. Our model includes (i) an
end-to-end trainable basic predictor, (ii) a saliency-based refinement module
to gather more valuable boundary features for each proposal with a novel
boundary pooling, and (iii) several consistency constraints to make sure our
model can find the accurate boundary given arbitrary proposals. Extensive
experiments show that our method beats all anchor-based and actionness-guided
methods with a remarkable margin on THUMOS14, achieving state-of-the-art
results, and comparable ones on ActivityNet v1.3. Code is available at
https://github.com/TencentYoutuResearch/ActionDetection-AFSD.
</dc:description>
 <dc:description>Comment: Accepted by CVPR2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13137</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13141</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal Context Aggregation Network for Temporal Action Proposal
  Refinement</dc:title>
 <dc:creator>Qing, Zhiwu</dc:creator>
 <dc:creator>Su, Haisheng</dc:creator>
 <dc:creator>Gan, Weihao</dc:creator>
 <dc:creator>Wang, Dongliang</dc:creator>
 <dc:creator>Wu, Wei</dc:creator>
 <dc:creator>Wang, Xiang</dc:creator>
 <dc:creator>Qiao, Yu</dc:creator>
 <dc:creator>Yan, Junjie</dc:creator>
 <dc:creator>Gao, Changxin</dc:creator>
 <dc:creator>Sang, Nong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Temporal action proposal generation aims to estimate temporal intervals of
actions in untrimmed videos, which is a challenging yet important task in the
video understanding field. The proposals generated by current methods still
suffer from inaccurate temporal boundaries and inferior confidence used for
retrieval owing to the lack of efficient temporal modeling and effective
boundary context utilization. In this paper, we propose Temporal Context
Aggregation Network (TCANet) to generate high-quality action proposals through
&quot;local and global&quot; temporal context aggregation and complementary as well as
progressive boundary refinement. Specifically, we first design a Local-Global
Temporal Encoder (LGTE), which adopts the channel grouping strategy to
efficiently encode both &quot;local and global&quot; temporal inter-dependencies.
Furthermore, both the boundary and internal context of proposals are adopted
for frame-level and segment-level boundary regressions, respectively. Temporal
Boundary Regressor (TBR) is designed to combine these two regression
granularities in an end-to-end fashion, which achieves the precise boundaries
and reliable confidence of proposals through progressive refinement. Extensive
experiments are conducted on three challenging datasets: HACS,
ActivityNet-v1.3, and THUMOS-14, where TCANet can generate proposals with high
precision and recall. By combining with the existing action classifier, TCANet
can obtain remarkable temporal action detection performance compared with other
methods. Not surprisingly, the proposed TCANet won the 1$^{st}$ place in the
CVPR 2020 - HACS challenge leaderboard on temporal action localization task.
</dc:description>
 <dc:description>Comment: Accepted by CVPR2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13141</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13145</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised collaborative learning using privileged information</dc:title>
 <dc:creator>Foucade, Yohan</dc:creator>
 <dc:creator>Bennani, Youn&#xe8;s</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In the collaborative clustering framework, the hope is that by combining
several clustering solutions, each one with its own bias and imperfections, one
will get a better overall solution. The goal is that each local computation,
quite possibly applied to distinct data sets, benefits from the work done by
the other collaborators. This article is dedicated to collaborative clustering
based on the Learning Using Privileged Information paradigm. Local algorithms
weight incoming information at the level of each observation, depending on the
confidence level of the classification of that observation. A comparison
between our algorithm and state of the art implementations shows improvement of
the collaboration process using the proposed approach.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13145</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13146</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-Efficient Resource Allocation in Massive MIMO-NOMA Networks with
  Wireless Power Transfer: A Distributed ADMM Approach</dc:title>
 <dc:creator>Wang, Zhongyu</dc:creator>
 <dc:creator>Lin, Zhipeng</dc:creator>
 <dc:creator>Lv, Tiejun</dc:creator>
 <dc:creator>Ni, Wei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  In multicell massive multiple-input multiple-output (MIMO) non-orthogonal
multiple access (NOMA) networks, base stations (BSs) with multiple antennas
deliver their radio frequency energy in the downlink, and Internet-of-Things
(IoT) devices use their harvested energy to support uplink data transmission.
This paper investigates the energy efficiency (EE) problem for multicell
massive MIMO NOMA networks with wireless power transfer (WPT). To maximize the
EE of the network, we propose a novel joint power, time, antenna selection, and
subcarrier resource allocation scheme, which can properly allocate the time for
energy harvesting and data transmission. Both perfect and imperfect channel
state information (CSI) are considered, and their corresponding EE performance
is analyzed. Under quality-of-service (QoS) requirements, an EE maximization
problem is formulated, which is non-trivial due to non-convexity. We first
adopt nonlinear fraction programming methods to convert the problem to be
convex, and then, develop a distributed alternating direction method of
multipliers (ADMM)- based approach to solve the problem. Simulation results
demonstrate that compared to alternative methods, the proposed algorithm can
converge quickly within fewer iterations, and can achieve better EE
performance.
</dc:description>
 <dc:description>Comment: 15 pages, 11 figures, Accepted by IEEE Internet of Things Journal</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13146</dc:identifier>
 <dc:identifier>doi:10.1109/JIOT.2021.3068721</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13147</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Agent Off-Policy TD Learning: Finite-Time Analysis with
  Near-Optimal Sample Complexity and Communication Complexity</dc:title>
 <dc:creator>Chen, Ziyi</dc:creator>
 <dc:creator>Zhou, Yi</dc:creator>
 <dc:creator>Chen, Rongrong</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The finite-time convergence of off-policy TD learning has been
comprehensively studied recently. However, such a type of convergence has not
been well established for off-policy TD learning in the multi-agent setting,
which covers broader applications and is fundamentally more challenging. This
work develops two decentralized TD with correction (TDC) algorithms for
multi-agent off-policy TD learning under Markovian sampling. In particular, our
algorithms preserve full privacy of the actions, policies and rewards of the
agents, and adopt mini-batch sampling to reduce the sampling variance and
communication frequency. Under Markovian sampling and linear function
approximation, we proved that the finite-time sample complexity of both
algorithms for achieving an $\epsilon$-accurate solution is in the order of
$\mathcal{O}(\epsilon^{-1}\ln \epsilon^{-1})$, matching the near-optimal sample
complexity of centralized TD(0) and TDC. Importantly, the communication
complexity of our algorithms is in the order of $\mathcal{O}(\ln
\epsilon^{-1})$, which is significantly lower than the communication complexity
$\mathcal{O}(\epsilon^{-1}\ln \epsilon^{-1})$ of the existing decentralized
TD(0). Experiments corroborate our theoretical findings.
</dc:description>
 <dc:description>Comment: 34 pages, 3 figures</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13147</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13151</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Polar Encodings for Arbitrary-Oriented Ship Detection in SAR
  Images</dc:title>
 <dc:creator>He, Yishan</dc:creator>
 <dc:creator>Gao, Fei</dc:creator>
 <dc:creator>Wang, Jun</dc:creator>
 <dc:creator>Hussain, Amir</dc:creator>
 <dc:creator>Yang, Erfu</dc:creator>
 <dc:creator>Zhou, Huiyu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Common horizontal bounding box (HBB)-based methods are not capable of
accurately locating slender ship targets with arbitrary orientations in
synthetic aperture radar (SAR) images. Therefore, in recent years, methods
based on oriented bounding box (OBB) have gradually received attention from
researchers. However, most of the recently proposed deep learning-based methods
for OBB detection encounter the boundary discontinuity problem in angle or key
point regression. In order to alleviate this problem, researchers propose to
introduce some manually set parameters or extra network branches for
distinguishing the boundary cases, which make training more diffcult and lead
to performance degradation. In this paper, in order to solve the boundary
discontinuity problem in OBB regression, we propose to detect SAR ships by
learning polar encodings. The encoding scheme uses a group of vectors pointing
from the center of the ship target to the boundary points to represent an OBB.
The boundary discontinuity problem is avoided by training and inference
directly according to the polar encodings. In addition, we propose an Intersect
over Union (IOU) -weighted regression loss, which further guides the training
of polar encodings through the IOU metric and improves the detection
performance. Experiments on the Rotating SAR Ship Detection Dataset (RSSDD)
show that the proposed method can achieve better detection performance over
other comparison algorithms and other OBB encoding schemes, demonstrating the
effectiveness of our method.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13153</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-Effector Stabilization of a 10-DOF Mobile Manipulator using
  Nonlinear Model Predictive Control</dc:title>
 <dc:creator>Osman, Mostafa</dc:creator>
 <dc:creator>Mehrez, Mohamed W.</dc:creator>
 <dc:creator>Yang, Shiyi</dc:creator>
 <dc:creator>Jeon, Soo</dc:creator>
 <dc:creator>Melek, William</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Motion control of mobile manipulators (a robotic arm mounted on a mobile
base) can be challenging for complex tasks such as material and package
handling. In this paper, a task-space stabilization controller based on
Nonlinear Model Predictive Control (NMPC) is designed and implemented to a 10
Degrees of Freedom (DOF) mobile manipulator which consists of a 7-DOF robotic
arm and a 3-DOF mobile base. The system model is based on kinematic models
where the end-effector orientation is parameterized directly by a rotation
matrix. The state and control constraints as well as singularity constraints
are explicitly included in the NMPC formulation. The controller is tested using
real-time simulations, which demonstrate high positioning accuracy with
tractable computational cost.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures, published in the 21st IFAC World Congress (2020)</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13153</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13154</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting the Unique Expression for Improved Sentiment Analysis in
  Software Engineering Text</dc:title>
 <dc:creator>Sun, Kexin</dc:creator>
 <dc:creator>Gao, Hui</dc:creator>
 <dc:creator>Kuang, Hongyu</dc:creator>
 <dc:creator>Ma, Xiaoxing</dc:creator>
 <dc:creator>Rong, Guoping</dc:creator>
 <dc:creator>Shao, Dong</dc:creator>
 <dc:creator>Zhang, He</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Sentiment analysis on software engineering (SE) texts has been widely used in
the SE research, such as evaluating app reviews or analyzing developers
sentiments in commit messages. To better support the use of automated sentiment
analysis for SE tasks, researchers built an SE-domain-specified sentiment
dictionary to further improve the accuracy of the results. Unfortunately,
recent work reported that current mainstream tools for sentiment analysis still
cannot provide reliable results when analyzing the sentiments in SE texts. We
suggest that the reason for this situation is because the way of expressing
sentiments in SE texts is largely different from the way in social network or
movie comments. In this paper, we propose to improve sentiment analysis in SE
texts by using sentence structures, a different perspective from building a
domain dictionary. Specifically, we use sentence structures to first identify
whether the author is expressing her sentiment in a given clause of an SE text,
and to further adjust the calculation of sentiments which are confirmed in the
clause. An empirical evaluation based on four different datasets shows that our
approach can outperform two dictionary-based baseline approaches, and is more
generalizable compared to a learning-based baseline approach.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13154</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13155</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coining goldMEDAL: A New Contribution to Data Lake Generic Metadata
  Modeling</dc:title>
 <dc:creator>Scholly, Etienne</dc:creator>
 <dc:creator>Sawadogo, Pegdwend&#xe9;</dc:creator>
 <dc:creator>Liu, Pengfei</dc:creator>
 <dc:creator>Espinosa-Oviedo, Javier Alfonso</dc:creator>
 <dc:creator>Favre, C&#xe9;cile</dc:creator>
 <dc:creator>Loudcher, Sabine</dc:creator>
 <dc:creator>Darmont, J&#xe9;r&#xf4;me</dc:creator>
 <dc:creator>No&#xfb;s, Camille</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The rise of big data has revolutionized data exploitation practices and led
to the emergence of new concepts. Among them, data lakes have emerged as large
heterogeneous data repositories that can be analyzed by various methods. An
efficient data lake requires a metadata system that addresses the many problems
arising when dealing with big data. In consequence, the study of data lake
metadata models is currently an active research topic and many proposals have
been made in this regard. However, existing metadata models are either tailored
for a specific use case or insufficiently generic to manage different types of
data lakes, including our previous model MEDAL. In this paper, we generalize
MEDAL's concepts in a new metadata model called goldMEDAL. Moreover, we compare
goldMEDAL with the most recent state-of-the-art metadata models aiming at
genericity and show that we can reproduce these metadata models with
goldMEDAL's concepts. As a proof of concept, we also illustrate that goldMEDAL
allows the design of various data lakes by presenting three different use
cases.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13155</dc:identifier>
 <dc:identifier>23rd International Workshop on Design, Optimization, Languages and
  Analytical Processing of Big Data (DOLAP@EDBT/ICDT 2021), Mar 2021, Nicosia,
  Cyprus</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13158</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TRADE: TRusted Anonymous Data Exchange: Threat Sharing Using Blockchain
  Technology</dc:title>
 <dc:creator>Allouche, Yair</dc:creator>
 <dc:creator>Tapas, Nachiket</dc:creator>
 <dc:creator>Longo, Francesco</dc:creator>
 <dc:creator>Shabtai, Asaf</dc:creator>
 <dc:creator>Wolfsthal, Yaron</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Cyber attacks are becoming more frequent and sophisticated, introducing
significant challenges for organizations to protect their systems and data from
threat actors. Today, threat actors are highly motivated, persistent, and
well-founded and operate in a coordinated manner to commit a diversity of
attacks using various sophisticated tactics, techniques, and procedures. Given
the risks these threats present, it has become clear that organizations need to
collaborate and share cyber threat information (CTI) and use it to improve
their security posture. In this paper, we present TRADE -- TRusted Anonymous
Data Exchange -- a collaborative, distributed, trusted, and anonymized CTI
sharing platform based on blockchain technology. TRADE uses a blockchain-based
access control framework designed to provide essential features and
requirements to incentivize and encourage organizations to share threat
intelligence information. In TRADE, organizations can fully control their data
by defining sharing policies enforced by smart contracts used to control and
manage CTI sharing in the network. TRADE allows organizations to preserve their
anonymity while keeping organizations fully accountable for their action in the
network. Finally, TRADE can be easily integrated within existing threat
intelligence exchange protocols - such as trusted automated exchange of
intelligence information (TAXII) and OpenDXL, thereby allowing a fast and
smooth technology adaptation.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13158</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13164</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>M3DSSD: Monocular 3D Single Stage Object Detector</dc:title>
 <dc:creator>Luo, Shujie</dc:creator>
 <dc:creator>Dai, Hang</dc:creator>
 <dc:creator>Shao, Ling</dc:creator>
 <dc:creator>Ding, Yong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a Monocular 3D Single Stage object Detector
(M3DSSD) with feature alignment and asymmetric non-local attention. Current
anchor-based monocular 3D object detection methods suffer from feature
mismatching. To overcome this, we propose a two-step feature alignment
approach. In the first step, the shape alignment is performed to enable the
receptive field of the feature map to focus on the pre-defined anchors with
high confidence scores. In the second step, the center alignment is used to
align the features at 2D/3D centers. Further, it is often difficult to learn
global information and capture long-range relationships, which are important
for the depth prediction of objects. Therefore, we propose a novel asymmetric
non-local attention block with multi-scale sampling to extract depth-wise
features. The proposed M3DSSD achieves significantly better performance than
the monocular 3D object detection methods on the KITTI dataset, in both 3D
object detection and bird's eye view tasks.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13165</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Balancing Improves Self-Admitted Technical Debt Detection</dc:title>
 <dc:creator>Sridharan, Murali</dc:creator>
 <dc:creator>Mantyla, Mika</dc:creator>
 <dc:creator>Rantala, Leevi</dc:creator>
 <dc:creator>Claes, Maelick</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  A high imbalance exists between technical debt and non-technical debt source
code comments. Such imbalance affects Self-Admitted Technical Debt (SATD)
detection performance, and existing literature lacks empirical evidence on the
choice of balancing technique. In this work, we evaluate the impact of multiple
balancing techniques, including Data level, Classifier level, and Hybrid, for
SATD detection in Within-Project and Cross-Project setup. Our results show that
the Data level balancing technique SMOTE or Classifier level Ensemble
approaches Random Forest or XGBoost are reasonable choices depending on whether
the goal is to maximize Precision, Recall, F1, or AUC-ROC. We compared our
best-performing model with the previous SATD detection benchmark
(cost-sensitive Convolution Neural Network). Interestingly the top-performing
XGBoost with SMOTE sampling improved the Within-project F1 score by 10% but
fell short in Cross-Project set up by 9%. This supports the higher
generalization capability of deep learning in Cross-Project SATD detection, yet
while working within individual projects, classical machine learning algorithms
can deliver better performance. We also evaluate and quantify the impact of
duplicate source code comments in SATD detection performance. Finally, we
employ SHAP and discuss the interpreted SATD features. We have included the
replication package and shared a web-based SATD prediction tool with the
balancing techniques in this study.
</dc:description>
 <dc:description>Comment: 11 pages, 1 figure, for conference</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13165</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13166</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Language learnability in the limit for general metrics: a Gold-Angluin
  result</dc:title>
 <dc:creator>Alves, Fernando C.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  In his pioneering work in the field of Inductive Inference, Gold (1967)
proved that a set containing all finite languages and at least one infinite
language over the same fixed alphabet is not learnable in the exact sense.
Within the same framework, Angluin (1980) provided a complete characterization
for the learnability of language families. Mathematically, the concept of exact
learning in that classical setting can be seen as the use of a particular type
of metric for learning in the limit. In this short research note we use
Niyogi's extended version of a theorem by Blum and Blum (1975) on the existence
of locking data sets to prove a necessary condition for learnability in the
limit of any family of languages in any given metric. This recovers Gold's
theorem as a special case. Moreover, when the language family is further
assumed to contain all finite languages, the same condition also becomes
sufficient for learnability in the limit.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13166</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13175</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Uniform Distribution of Regular Expressions</dc:title>
 <dc:creator>Broda, Sabine</dc:creator>
 <dc:creator>Machiavelo, Ant&#xf3;nio</dc:creator>
 <dc:creator>Moreira, Nelma</dc:creator>
 <dc:creator>Reis, Rog&#xe9;rio</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  Although regular expressions do not correspond univocally to regular
languages, it is still worthwhile to study their properties and algorithms. For
the average case analysis one often relies on the uniform random generation
using a specific grammar for regular expressions, that can represent regular
languages with more or less redundancy. Generators that are uniform on the set
of expressions are not necessarily uniform on the set of regular languages.
Nevertheless, it is not straightforward that asymptotic estimates obtained by
considering the whole set of regular expressions are different from those
obtained using a more refined set that avoids some large class of equivalent
expressions. In this paper we study a set of expressions that avoid a given
absorbing pattern. It is shown that, although this set is significantly smaller
than the standard one, the asymptotic average estimates for the size of the
Glushkov automaton for these expressions does not differ from the standard
case.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13175</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13178</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>iMHS: An Incremental Multi-Hypothesis Smoother</dc:title>
 <dc:creator>Jiang, Fan</dc:creator>
 <dc:creator>Agrawal, Varun</dc:creator>
 <dc:creator>Buchanan, Russell</dc:creator>
 <dc:creator>Fallon, Maurice</dc:creator>
 <dc:creator>Dellaert, Frank</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  State estimation of multi-modal hybrid systems is an important problem with
many applications in the field robotics. However, incorporating discrete modes
in the estimation process is hampered by a potentially combinatorial growth in
computation. In this paper we present a novel incremental multi-hypothesis
smoother based on eliminating a hybrid factor graph into a multi-hypothesis
Bayes tree, which represents possible discrete state sequence hypotheses.
Following iSAM, we enable incremental inference by conditioning the past on the
future but we add to that the capability of maintaining multiple discrete mode
histories, exploiting the temporal structure of the problem to obtain a
simplified representation that unifies the multiple hypothesis tree with the
Bayes tree. In the results section we demonstrate the generality of the
algorithm with examples in three problem domains: lane change detection (1D),
aircraft maneuver detection (2D), and contact detection in legged robots (3D).
</dc:description>
 <dc:description>Comment: Submitted to IROS 2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13178</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13179</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multimode piezoelectric shunt damping of thin plates with arrays of
  separately shunted patches, method, and experimental validation</dc:title>
 <dc:creator>Motlagh, Peyman Lahe</dc:creator>
 <dc:creator>Basdogana, Ipek</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Two-dimensional thin plates are widely used in many applications. Shunt
damping is a promising way for the attenuation of vibration of these
electromechanical systems. It enables a compact vibration damping method
without adding significant mass and volumetric occupancy. Analyzing the
dynamics of such electromechanical systems requires precise modeling tools that
properly consider the coupling between the piezoelectric elements and the host
structure. Although the concept of shunt damping has been studied extensively
in the literature, most of the studies do not provide a formulation for
modeling the multiple piezoelectric patches that are scattered on the host
structure and shunted separately. This paper presents a methodology and a
formulation for separately shunted piezoelectric patches for achieving higher
performance on vibration attenuation. The Rayleigh-Ritz method is used for
performing modal analysis and obtaining the frequency response functions of the
electro-mechanical system. The developed model includes mass and stiffness
contribution of the piezoelectric patches as well as the electromechanical
coupling effect. In this study, the piezoelectric patches are shunted via
separate electrical circuits and compared with the ones those are shunted via
interconnected electrical circuits. For verification, system-level finite
element simulations are performed in ANSYS software and compared with the
analytical model results. An experimental setup is also built to validate the
performance of the separately shunted piezoelectric patches. The effectiveness
of the method is investigated for a broader range of frequencies and it was
shown that separately shunted piezoelectric patches are more effective compared
to connected for a wide range of frequencies.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13187</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Influence of Social Networks on Human Society</dc:title>
 <dc:creator>Arya, Shreyash</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  This report gives a brief overview of the origin of social networks and their
most popular manifestation in the modern era - the Online Social Networks
(OSNs) or social media. It further discusses the positive and negative
implications of OSNs on human society. The coupling of Data Science and social
media (social media mining) is then put forward as a powerful tool to overcome
the current challenges and pave the path for futuristic advancements
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13187</dc:identifier>
 <dc:identifier>doi:10.13140/RG.2.2.18060.54408/1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13188</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Message Passing based Adaptive PDA Algorithm for Robust Radio-based
  Localization and Tracking</dc:title>
 <dc:creator>Venus, Alexander</dc:creator>
 <dc:creator>Leitinger, Erik</dc:creator>
 <dc:creator>Tertinek, Stefan</dc:creator>
 <dc:creator>Witrisal, Klaus</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We present a message passing algorithm for localization and tracking in
multipath-prone environments that implicitly considers obstructed line-of-sight
situations. The proposed adaptive probabilistic data association algorithm
infers the position of a mobile agent using multiple anchors by utilizing delay
and amplitude of the multipath components (MPCs) as well as their respective
uncertainties. By employing a nonuniform clutter model, we enable the algorithm
to facilitate the position information contained in the MPCs to support the
estimation of the agent position without exact knowledge about the environment
geometry. Our algorithm adapts in an online manner to both, the time-varying
signal-to-noise-ratio and line-of-sight (LOS) existence probability of each
anchor. In a numerical analysis we show that the algorithm is able to operate
reliably in environments characterized by strong multipath propagation, even if
a temporary obstruction of all anchors occurs simultaneously.
</dc:description>
 <dc:description>Comment: 6 pages (two column), 6 figures, IEEE RadarConf 2021: Synergistic
  Radar Signal Processing and Tracking</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13196</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving the interaction of Older Adults with Socially Assistive Robots
  for Table setting</dc:title>
 <dc:creator>Olatunji, Samuel</dc:creator>
 <dc:creator>Markfeld, Noa</dc:creator>
 <dc:creator>Gutman, Dana</dc:creator>
 <dc:creator>Givati, Shay</dc:creator>
 <dc:creator>Sarne-Fleischmann, Vardit</dc:creator>
 <dc:creator>Oron-Gilad, Tal</dc:creator>
 <dc:creator>Edan, Yael</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This study provides user-studies aimed at exploring factors influencing the
interaction between older adults and a robotic table setting assistant. The
in-fluence of the level of automation (LOA) and level of transparency (LOT) on
the quality of the interaction was considered. Results revealed that the
interaction effect of LOA and LOT significantly influenced the interaction. A
lower LOA which required the user to control some of the actions of the robot
influenced the older adults to participate more in the interaction when the LOT
was low com-pared to situations with higher LOT (more information) and higher
LOA (more robot autonomy). Even though the higher LOA influenced more fluency
in the interaction, the lower LOA encouraged a more collaborative form of
interaction which is a priority in the design of robotic aids for older adult
users. The results provide some insights into shared control designs which
accommodates the preferences of the older adult users as they interact with
robotic aids such as the table setting robot used in this study.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13196</dc:identifier>
 <dc:identifier>Proceedings of the International Conference on Social Robotics (pp
  568-577), 11876 LNAI Lecture Notes in Computer Science. Springer
  International Publishing. 2019</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-030-35888-4_53</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13197</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topology Design for GNSSs Considering Both Inter-satellite Links and
  Ground-satellite Links</dc:title>
 <dc:creator>Yan, Z.</dc:creator>
 <dc:creator>Zhao, K.</dc:creator>
 <dc:creator>Li, W.</dc:creator>
 <dc:creator>Kang, C.</dc:creator>
 <dc:creator>Zheng, J.</dc:creator>
 <dc:creator>Yang, H.</dc:creator>
 <dc:creator>Du, S.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Inter-satellite links (ISLs) are adopted in global navigation satellite
systems (GNSSs) for high-precision orbit determination and space-based
end-to-end telemetry telecommand control and communications. Due to limited
onboard ISL terminals, the polling time division duplex (PTDD) mechanism is
usually proposed for space link layer networking. By extending the polling
mechanism to ground-satellite links (GSLs), a unified management system of the
space segment and the ground segment can be realized. However, under the
polling system how to jointly design the topology of ISLs and GSLs during every
slot to improve data interaction has not been studied. In this paper, we
formulate the topology design problem as an integer linear programming, aiming
at minimizing the average delay of data delivery from satellites to ground
stations while satisfying the ranging requirement for the orbit determination.
To tackle the computational complexity problem, we first present a novel
modeling method of delay to reduce the number of decision variables. Further,
we propose a more efficient heuristic based on maximum weight matching
algorithms. Simulation results demonstrate the feasibility of the proposed
methods for practical operation in GNSSs. Comparing the two methods, the
heuristic can achieve similar performance with respect to average delay but
with significantly less complexity.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13197</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13198</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Use and Perceptions of Multi-Monitor Workstations: A Natural Experiment</dc:title>
 <dc:creator>Amir, Guy</dc:creator>
 <dc:creator>Prusak, Ayala</dc:creator>
 <dc:creator>Reiss, Tal</dc:creator>
 <dc:creator>Zabari, Nir</dc:creator>
 <dc:creator>Feitelson, Dror G.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.3</dc:subject>
 <dc:description>  Using multiple monitors is commonly thought to improve productivity, but this
is hard to check experimentally. We use a survey, taken by 101 practitioners of
which 80% have coded professionally for at least 2 years, to assess subjective
perspectives based on experience. To improve validity, we compare situations in
which developers naturally use different setups -- the difference between
working at home or at the office, and how things changed when developers were
forced to work from home due to the Covid-19 pandemic. The results indicate
that using multiple monitors is indeed perceived as beneficial and desirable.
19% of the respondents reported adding a monitor to their home setup in
response to the Covid-19 situation. At the same time, the single most
influential factor cited as affecting productivity was not the physical setup
but interactions with co-workers -- both reduced productivity due to lack of
connections available at work, and improved productivity due to reduced
interruptions from co-workers. A central implication of our work is that
empirical research on software development should be conducted in settings
similar to those actually used by practitioners, and in particular using
workstations configured with multiple monitors.
</dc:description>
 <dc:description>Comment: 9 pages, 16 figures. Accepted to 8th International Workshop on
  Software Engineering Research and Industrial Practice</dc:description>
 <dc:date>2021-03-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13209</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>User-centered Feedback Design in Person-following Robots for Older
  Adults</dc:title>
 <dc:creator>Olatunji, Samuel</dc:creator>
 <dc:creator>Oron-Gilad, Tal</dc:creator>
 <dc:creator>Sarne-Fleischmann, Vardit</dc:creator>
 <dc:creator>Edan, Yael</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Feedback design is an important aspect of person-following robots for older
adults. This paper presents a user-centred design approach to ensure the design
is focused on the needs and preferences of the users. A sequence of user
studies with a total of 35 older adults (aged 62 years and older) was conducted
to explore their preferences regarding feedback parameters for a socially
assistive person-following robot. The preferred level of robot transparency and
the desired content for the feedback was first explored. This was followed by
an assessment of the preferred mode and timing of feedback. The chosen feedback
parameters were then implemented and evaluated in a final experiment to
evaluate the effectiveness of the design. Results revealed that older adults
preferred to receive only basic status information. They preferred voice
feedback overtone, and at a continuous rate to keep them constantly aware of
the state and actions of the robot. The outcome of the study is a further step
towards feedback design guidelines that could improve interaction quality for
person-following robots for older adults.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13209</dc:identifier>
 <dc:identifier>Paladyn, Journal of Behavioral Robotics, 11(1), 86-103, 2020</dc:identifier>
 <dc:identifier>doi:10.1515/pjbr-2020-0007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13212</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OpenCV2X: Modelling of the V2X Cellular Sidelink and Performance
  Evaluation for Aperiodic Traffic</dc:title>
 <dc:creator>McCarthy, Brian</dc:creator>
 <dc:creator>Burbano-Abril, Andres</dc:creator>
 <dc:creator>Licea, Victor Rangel</dc:creator>
 <dc:creator>O'Driscoll, Aisling</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper presents OpenCV2X, the first publicly available, open-source
simulation model of the Third Generation Partnership Project (3GPP) Release 14
Cellular Vehicle to Everything (C-V2X) sidelink, which forms the basis for 5G
NR Mode 2 under later releases. This model is fully compliant with the existing
vehicular service and application layers, including messaging sets as defined
by the automotive and standards communities providing a fully standardised,
cross-layer communication model. Using this model, we show how the current
sidelink scheduling mechanism performs poorly when scheduling applications with
highly aperiodic communication characteristics, such as ETSI Cooperative
Awareness Messages (CAMs). We then provide the first indepth evaluation of
dedicated per-packet aperiodic scheduling mechanisms, in contrast to schemes
that parameterise the existing algorithm. This paper highlights that the level
of aperiodicity exhibited by the application model greatly impacts scheduling
performance. Finally, we analyse how such scheduling mechanisms might co-exist.
</dc:description>
 <dc:description>Comment: 18 Pages, 20 Figures</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13217</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-layer based intermittent jamming schemes for securing
  energy-constraint networks</dc:title>
 <dc:creator>Gao, Qinghe</dc:creator>
 <dc:creator>Huo, Yan</dc:creator>
 <dc:creator>Jing, Tao</dc:creator>
 <dc:creator>Ma, Liran</dc:creator>
 <dc:creator>Qian, Jin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The Internet-of-Things (IoT) emerges as a paradigm to achieve ubiquitous
connectivity via wireless communications between kinds of physical objects. Due
to the wireless broadcasting nature and the energy constraint of physical
objects, concerns on IoT security have triggered research on cooperative
jamming based physical layer security. With the help of a cooperative jammer,
existing solutions can effectively fight against eavesdroppers. However, these
schemes are of high energy cost due to continuously transmitting jamming
signals. To reduce the energy consumption, we propose a new idea of
intermittent jamming and design five specific intermittent jamming schemes
(IJSs). By taking the transmit frame formate into account, we optimize these
IJSs from three aspects, including the jamming power, the jamming method, and
the jamming positions. Then we analyze the applicability of the proposed IJSs
according to different requirements on the synchronization, the available
jamming energy and the jamming power constraints. Extensive MATLAB experiments
are conducted on the basis of the WLAN Toolbox, which demonstrate the proposed
IJSs can effectively degrade the reception of the eavesdropper and outperform
the widespread continuous jamming scheme (CJS) when the available jamming
energy is limited.
</dc:description>
 <dc:description>Comment: 11 pages,33 subfigures and figures</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13217</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13219</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transfer Learning for Piano Sustain-Pedal Detection</dc:title>
 <dc:creator>Liang, Beici</dc:creator>
 <dc:creator>Fazekas, Gy&#xf6;rgy</dc:creator>
 <dc:creator>Sandler, Mark</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Detecting piano pedalling techniques in polyphonic music remains a
challenging task in music information retrieval. While other piano-related
tasks, such as pitch estimation and onset detection, have seen improvement
through applying deep learning methods, little work has been done to develop
deep learning models to detect playing techniques. In this paper, we propose a
transfer learning approach for the detection of sustain-pedal techniques, which
are commonly used by pianists to enrich the sound. In the source task, a
convolutional neural network (CNN) is trained for learning spectral and
temporal contexts when the sustain pedal is pressed using a large dataset
generated by a physical modelling virtual instrument. The CNN is designed and
experimented through exploiting the knowledge of piano acoustics and physics.
This can achieve an accuracy score of 0.98 in the validation results. In the
target task, the knowledge learned from the synthesised data can be transferred
to detect the sustain pedal in acoustic piano recordings. A concatenated
feature vector using the activations of the trained convolutional layers is
extracted from the recordings and classified into frame-wise pedal press or
release. We demonstrate the effectiveness of our method in acoustic piano
recordings of Chopin's music. From the cross-validation results, the proposed
transfer learning method achieves an average F-measure of 0.89 and an overall
performance of 0.84 obtained using the micro-averaged F-measure. These results
outperform applying the pre-trained CNN model directly or the model with a
fine-tuned last layer.
</dc:description>
 <dc:description>Comment: Published in 2019 International Joint Conference on Neural Networks
  (IJCNN)</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13219</dc:identifier>
 <dc:identifier>doi:10.1109/IJCNN.2019.8851724</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13222</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bingham Fluid Flow through Oscillatory Porous Plate with Ion-Slip and
  Hall Current</dc:title>
 <dc:creator>Mollah, Md. Tusher</dc:creator>
 <dc:creator>Islam, Muhammad Minarul</dc:creator>
 <dc:creator>Ferdows, Mohammad</dc:creator>
 <dc:creator>Alam, Md. Mahmud</dc:creator>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  The numerical approach has been performed to study the Bingham fluid flow
through an oscillatory porous plate with Ion-Slip and Hall current. Initially,
at time; t = 0 both the fluid and the upper plate are at rest. At time; t &gt; 0
the upper plate begins to oscillate in its own plane while the lower plate is
stationary. The lower plate temperature is constant while the upper plate
temperature has oscillated. A uniform magnetic field is applied perpendicular
to the plates. To obtain the dimensionless equations from the governing
non-linear partial differential equations, the usual transformations have been
used. The explicit finite difference technique has been applied to solve the
obtained dimensionless equations. The MATLAB R2015a has been used for numerical
simulation. For the accuracy of the numerical technique, the stability and
convergence criteria have been discussed and the system has found to be
converged for P_r&gt;=0.08, Beta_i&gt;=2, H_a&lt;=20, K_o&lt;=8 (k~=2) and R_e&gt;=0.011 with
Beta_e=0.10, E_c=0.10, Delta(Y)=0.05 and Delta(Tau)=0.0001. The steady-state
solution has achieved at the dimensionless time=2.00. At the steady-state time,
the effect of several parameters on the flow patterns, local shear stress and
the Nusselt number have been shown graphically.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13222</dc:identifier>
 <dc:identifier>8th BSME International Conference on Thermal Engineering, AIP
  Conference Proceedings (2019), 2121, 050011-1 - 050011-6</dc:identifier>
 <dc:identifier>doi:10.1063/1.5115898</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13224</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pole-like Objects Mapping and Long-Term Robot Localization in Dynamic
  Urban Scenarios</dc:title>
 <dc:creator>Wang, Zhihao</dc:creator>
 <dc:creator>Li, Silin</dc:creator>
 <dc:creator>Cao, Ming</dc:creator>
 <dc:creator>Chen, Haoyao</dc:creator>
 <dc:creator>Liu, Yunhui</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Localization on 3D data is a challenging task for unmanned vehicles,
especially in long-term dynamic urban scenarios. Due to the generality and
long-term stability, the pole-like objects are very suitable as landmarks for
unmanned vehicle localization in time-varing scenarios. In this paper, a
long-term LiDAR-only localization algorithm based on semantic cluster map is
proposed. At first, the Convolutional Neural Network(CNN) is used to infer the
semantics of LiDAR point clouds. Combined with the point cloud segmentation,
the long-term static objects pole/trunk in the scene are extracted and
registered into a semantic cluster map. When the unmanned vehicle re-enters the
environment again, the relocalization is completed by matching the clusters of
the local map with the clusters of the global map. Furthermore, the continuous
matching between the local and global maps stably outputs the global pose at
2Hz to correct the drift of the 3D LiDAR odometry. The proposed approach
realizes localization in the long-term scenarios without maintaining the
high-precision point cloud map. The experimental results on our campus dataset
demonstrate that the proposed approach performs better in localization accuracy
compared with the current state-of-the-art methods. The source of this paper is
available at: http://www.github.com/HITSZ-NRSL/long-term-localization.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13225</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structure-Aware Face Clustering on a Large-Scale Graph with
  $\bf{10^{7}}$ Nodes</dc:title>
 <dc:creator>Shen, Shuai</dc:creator>
 <dc:creator>Li, Wanhua</dc:creator>
 <dc:creator>Zhu, Zheng</dc:creator>
 <dc:creator>Huang, Guan</dc:creator>
 <dc:creator>Du, Dalong</dc:creator>
 <dc:creator>Lu, Jiwen</dc:creator>
 <dc:creator>Zhou, Jie</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Face clustering is a promising method for annotating unlabeled face images.
Recent supervised approaches have boosted the face clustering accuracy greatly,
however their performance is still far from satisfactory. These methods can be
roughly divided into global-based and local-based ones. Global-based methods
suffer from the limitation of training data scale, while local-based ones are
difficult to grasp the whole graph structure information and usually take a
long time for inference. Previous approaches fail to tackle these two
challenges simultaneously. To address the dilemma of large-scale training and
efficient inference, we propose the STructure-AwaRe Face Clustering (STAR-FC)
method. Specifically, we design a structure-preserved subgraph sampling
strategy to explore the power of large-scale training data, which can increase
the training data scale from ${10^{5}}$ to ${10^{7}}$. During inference, the
STAR-FC performs efficient full-graph clustering with two steps: graph parsing
and graph refinement. And the concept of node intimacy is introduced in the
second step to mine the local structural information. The STAR-FC gets 91.97
pairwise F-score on partial MS1M within 310s which surpasses the
state-of-the-arts. Furthermore, we are the first to train on very large-scale
graph with 20M nodes, and achieve superior inference results on 12M testing
data. Overall, as a simple and effective method, the proposed STAR-FC provides
a strong baseline for large-scale face clustering. Code is available at
\url{https://sstzal.github.io/STAR-FC/}.
</dc:description>
 <dc:description>Comment: Accepted by the CVPR 2021. Project: https://sstzal.github.io/STAR-FC/</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13226</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Learning for Melanoma Classification using Personal Health
  Train</dc:title>
 <dc:creator>Mou, Yongli</dc:creator>
 <dc:creator>Welten, Sascha</dc:creator>
 <dc:creator>Yediel, Yeliz Ucer</dc:creator>
 <dc:creator>Kirsten, Toralf</dc:creator>
 <dc:creator>Beyan, Oya Deniz</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Skin cancer is the most common cancer type. Usually, patients with suspicion
of cancer are treated by doctors without any aided visual inspection. At this
point, dermoscopy has become a suitable tool to support physicians in their
decision-making. However, clinicians need years of expertise to classify
possibly malicious skin lesions correctly. Therefore, research has applied
image processing and analysis tools to improve the treatment process. In order
to perform image analysis and train a model on dermoscopic images data needs to
be centralized. Nevertheless, data centralization does not often comply with
local data protection regulations due to its sensitive nature and due to the
loss of sovereignty if data providers allow unlimited access to the data. A
method to circumvent all privacy-related challenges of data centralization is
Distributed Analytics (DA) approaches, which bring the analysis to the data
instead of vice versa. This paradigm shift enables data analyses - in our case,
image analysis - with data remaining inside institutional borders, i.e., the
origin. In this documentation, we describe a straightforward use case including
a model training for skin lesion classification based on decentralised data.
</dc:description>
 <dc:description>Comment: 11 pages, 7 figures</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13230</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Assets Defending Differential Games with Partial Information and
  Selected Observations</dc:title>
 <dc:creator>Huang, Yunhan</dc:creator>
 <dc:creator>Chen, Juntao</dc:creator>
 <dc:creator>Zhu, Quanyan</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper, we consider a linear-quadratic-Gaussian defending assets
differential game (DADG) where the attacker and the defender do not know each
other's state information while they know the trajectory of a moving asset.
Both players can choose to observe the other player's state information by
paying a cost. The defender and the attacker have to craft both control
strategies and observation strategies. We obtain a closed-form feedback
solution that characterizes the Nash control strategies. We show that the
trajectory of the asset does not affect both players' observation choices.
Moreover, we show that the observation choices of the defender and the attacker
can be decoupled and the Nash observation strategies can be found by solving
two independent optimization problems. A set of necessary conditions is
developed to characterize the optimal observation instances. Based on the
necessary conditions, an effective algorithm is proposed to numerically compute
the optimal observation instances. A case study is presented to demonstrate the
effectiveness of the optimal observation instances.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13230</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13235</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Web Mining for Estimating Regulatory Blockchain Readiness</dc:title>
 <dc:creator>Iosif, Elias</dc:creator>
 <dc:creator>Christodoulou, Klitos</dc:creator>
 <dc:creator>Vlachos, Andreas</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The regulatory framework of cryptocurrencies (and, in general, blockchain
tokens) is of paramount importance. This framework drives nearly all key
decisions in the respective business areas. In this work, a computational model
is proposed for quantitatively estimating the regulatory stance of countries
with respect to cryptocurrencies. This is conducted via web mining utilizing
web search engines. The proposed model is experimentally validated. In
addition, unsupervised learning (clustering) is applied for better analyzing
the automatically derived estimations. Overall, very good performance is
achieved by the proposed algorithmic approach.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13246</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generic Merging of Structure from Motion Maps with a Low Memory
  Footprint</dc:title>
 <dc:creator>Flood, Gabrielle</dc:creator>
 <dc:creator>Gillsj&#xf6;, David</dc:creator>
 <dc:creator>Persson, Patrik</dc:creator>
 <dc:creator>Heyden, Anders</dc:creator>
 <dc:creator>&#xc5;str&#xf6;m, Kalle</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  With the development of cheap image sensors, the amount of available image
data have increased enormously, and the possibility of using crowdsourced
collection methods has emerged. This calls for development of ways to handle
all these data. In this paper, we present new tools that will enable efficient,
flexible and robust map merging. Assuming that separate optimisations have been
performed for the individual maps, we show how only relevant data can be stored
in a low memory footprint representation. We use these representations to
perform map merging so that the algorithm is invariant to the merging order and
independent of the choice of coordinate system. The result is a robust
algorithm that can be applied to several maps simultaneously. The result of a
merge can also be represented with the same type of low-memory footprint
format, which enables further merging and updating of the map in a hierarchical
way. Furthermore, the method can perform loop closing and also detect changes
in the scene between the capture of the different image sequences. Using both
simulated and real data - from both a hand held mobile phone and from a drone -
we verify the performance of the proposed method.
</dc:description>
 <dc:description>Comment: Accepted at ICPR2020, 9 pages, 8 figures</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13246</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13258</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Slimmable Network</dc:title>
 <dc:creator>Li, Changlin</dc:creator>
 <dc:creator>Wang, Guangrun</dc:creator>
 <dc:creator>Wang, Bing</dc:creator>
 <dc:creator>Liang, Xiaodan</dc:creator>
 <dc:creator>Li, Zhihui</dc:creator>
 <dc:creator>Chang, Xiaojun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Current dynamic networks and dynamic pruning methods have shown their
promising capability in reducing theoretical computation complexity. However,
dynamic sparse patterns on convolutional filters fail to achieve actual
acceleration in real-world implementation, due to the extra burden of indexing,
weight-copying, or zero-masking. Here, we explore a dynamic network slimming
regime, named Dynamic Slimmable Network (DS-Net), which aims to achieve good
hardware-efficiency via dynamically adjusting filter numbers of networks at
test time with respect to different inputs, while keeping filters stored
statically and contiguously in hardware to prevent the extra burden. Our DS-Net
is empowered with the ability of dynamic inference by the proposed
double-headed dynamic gate that comprises an attention head and a slimming head
to predictively adjust network width with negligible extra computation cost. To
ensure generality of each candidate architecture and the fairness of gate, we
propose a disentangled two-stage training scheme inspired by one-shot NAS. In
the first stage, a novel training technique for weight-sharing networks named
In-place Ensemble Bootstrapping is proposed to improve the supernet training
efficacy. In the second stage, Sandwich Gate Sparsification is proposed to
assist the gate training by identifying easy and hard samples in an online way.
Extensive experiments demonstrate our DS-Net consistently outperforms its
static counterparts as well as state-of-the-art static and dynamic model
compression methods by a large margin (up to 5.9%). Typically, DS-Net achieves
2-4x computation reduction and 1.62x real-world acceleration over ResNet-50 and
MobileNet with minimal accuracy drops on ImageNet. Code release:
https://github.com/changlin31/DS-Net .
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2021 as an Oral Presentation</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13258</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13259</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mostly electric assisted airplanes (MEAP) for regional aviation: A South
  Asian perspective</dc:title>
 <dc:creator>Chaturvedi, Vinamra</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Economics - General Economics</dc:subject>
 <dc:description>  Aircraft manufacturing relies on pre-order bookings. The configuration of the
to be assembled aircraft is fixed by the design assisted market surveys. The
sensitivity of the supply chain to the market conditions, makes, the
relationship between the product (aircraft) and the associated service
(aviation), precarious. Traditional model to mitigate this risk to
profitability rely on increasing the scales of operations. However, the
emergence of new standards of air quality monitoring and insistence on the
implementation, demands additional corrective measures. In the quest for a
solution, this research commentary establishes a link, between the airport
taxes and the nature of the transporting unit. It warns, that merely,
increasing the number of mid haulage range aircrafts (MHA) in the fleet, may
not be enough, to overcome this challenge. In a two-pronged approach, the
communication proposes, the use of mostly electric assisted air planes, and
small sized airports as the key to solving this complex problem. As a side-note
the appropriateness of South Asian region, as a test-bed for MEAP based
aircrafts is also investigated. The success of this the idea can be potentially
extended, to any other aviation friendly region of the world.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13262</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FastMoE: A Fast Mixture-of-Expert Training System</dc:title>
 <dc:creator>He, Jiaao</dc:creator>
 <dc:creator>Qiu, Jiezhong</dc:creator>
 <dc:creator>Zeng, Aohan</dc:creator>
 <dc:creator>Yang, Zhilin</dc:creator>
 <dc:creator>Zhai, Jidong</dc:creator>
 <dc:creator>Tang, Jie</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Mixture-of-Expert (MoE) presents a strong potential in enlarging the size of
language model to trillions of parameters. However, training trillion-scale MoE
requires algorithm and system co-design for a well-tuned high performance
distributed training system. Unfortunately, the only existing platform that
meets the requirements strongly depends on Google's hardware (TPU) and software
(Mesh Tensorflow) stack, and is not open and available to the public,
especially GPU and PyTorch communities.
  In this paper, we present FastMoE, a distributed MoE training system based on
PyTorch with common accelerators. The system provides a hierarchical interface
for both flexible model design and easy adaption to different applications,
such as Transformer-XL and Megatron-LM. Different from direct implementation of
MoE models using PyTorch, the training speed is highly optimized in FastMoE by
sophisticated high-performance acceleration skills. The system supports placing
different experts on multiple GPUs across multiple nodes, enabling enlarging
the number of experts linearly against the number of GPUs. The source of
FastMoE is available at https://github.com/laekov/fastmoe under Apache-2
license.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13262</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13265</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Is it Possible to Disregard Obsolete Requirements? A Family of
  Experiments in Software Effort Estimation</dc:title>
 <dc:creator>Gren, Lucas</dc:creator>
 <dc:creator>Svensson, Richard Berntsson</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Context: Expert judgement is a common method for software effort estimations
in practice today. Estimators are often shown extra obsolete requirements
together with the real ones to be implemented. Only one previous study has been
conducted on if such practices bias the estimations. Objective: We conducted
six experiments with both students and practitioners to study, and quantify,
the effects of obsolete requirements on software estimation. Method By
conducting a family of six experiments using both students and practitioners as
research subjects (N = 461), and by using a Bayesian Data Analysis approach, we
investigated different aspects of this effect. We also argue for, and show an
example of, how we by using a Bayesian approach can be more confident in our
results and enable further studies with small sample sizes. Results: We found
that the presence of obsolete requirements triggered an overestimation in
effort across all experiments. The effect, however, was smaller in a field
setting compared to using students as subjects. Still, the over-estimations
triggered by the obsolete requirements were systematically around twice the
percentage of the included obsolete ones, but with a large 95% credible
interval. Conclusions: The results have implications for both research and
practice in that the found systematic error should be accounted for in both
studies on software estimation and, maybe more importantly, in estimation
practices to avoid over-estimation due to this systematic error. We partly
explain this error to be stemming from the cognitive bias of
anchoring-and-adjustment, i.e. the obsolete requirements anchored a much larger
software. However, further studies are needed in order to accurately predict
this effect.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13265</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13266</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Opportunistic Federated Learning: An Exploration of Egocentric
  Collaboration for Pervasive Computing Applications</dc:title>
 <dc:creator>Lee, Sangsu</dc:creator>
 <dc:creator>Zheng, Xi</dc:creator>
 <dc:creator>Hua, Jie</dc:creator>
 <dc:creator>Vikalo, Haris</dc:creator>
 <dc:creator>Julien, Christine</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Pervasive computing applications commonly involve user's personal smartphones
collecting data to influence application behavior. Applications are often
backed by models that learn from the user's experiences to provide personalized
and responsive behavior. While models are often pre-trained on massive
datasets, federated learning has gained attention for its ability to train
globally shared models on users' private data without requiring the users to
share their data directly. However, federated learning requires devices to
collaborate via a central server, under the assumption that all users desire to
learn the same model. We define a new approach, opportunistic federated
learning, in which individual devices belonging to different users seek to
learn robust models that are personalized to their user's own experiences.
However, instead of learning in isolation, these models opportunistically
incorporate the learned experiences of other devices they encounter
opportunistically. In this paper, we explore the feasibility and limits of such
an approach, culminating in a framework that supports encounter-based pairwise
collaborative learning. The use of our opportunistic encounter-based learning
amplifies the performance of personalized learning while resisting overfitting
to encountered data.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13266</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13267</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CLAMGen: Closed-Loop Arm Motion Generation via Multi-view Vision-Based
  RL</dc:title>
 <dc:creator>Akinola, Iretiayo</dc:creator>
 <dc:creator>Wang, Zizhao</dc:creator>
 <dc:creator>Allen, Peter</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We propose a vision-based reinforcement learning (RL) approach for
closed-loop trajectory generation in an arm reaching problem. Arm trajectory
generation is a fundamental robotics problem which entails finding
collision-free paths to move the robot's body (e.g. arm) in order to satisfy a
goal (e.g. place end-effector at a point).
  While classical methods typically require the model of the environment to
solve a planning, search or optimization problem, learning-based approaches
hold the promise of directly mapping from observations to robot actions.
  However, learning a collision-avoidance policy using RL remains a challenge
for various reasons, including, but not limited to, partial observability, poor
exploration, low sample efficiency, and learning instabilities.
  To address these challenges, we present a residual-RL method that leverages a
greedy goal-reaching RL policy as the base to improve exploration, and the base
policy is augmented with residual state-action values and residual actions
learned from images to avoid obstacles. Further more, we introduce novel
learning objectives and techniques to improve 3D understanding from multiple
image views and sample efficiency of our algorithm.
  Compared to RL baselines, our method achieves superior performance in terms
of success rate.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13267</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13275</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When Word Embeddings Become Endangered</dc:title>
 <dc:creator>Alnajjar, Khalid</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Big languages such as English and Finnish have many natural language
processing (NLP) resources and models, but this is not the case for
low-resourced and endangered languages as such resources are so scarce despite
the great advantages they would provide for the language communities. The most
common types of resources available for low-resourced and endangered languages
are translation dictionaries and universal dependencies. In this paper, we
present a method for constructing word embeddings for endangered languages
using existing word embeddings of different resource-rich languages and the
translation dictionaries of resource-poor languages. Thereafter, the embeddings
are fine-tuned using the sentences in the universal dependencies and aligned to
match the semantic spaces of the big languages; resulting in cross-lingual
embeddings. The endangered languages we work with here are Erzya, Moksha,
Komi-Zyrian and Skolt Sami. Furthermore, we build a universal sentiment
analysis model for all the languages that are part of this study, whether
endangered or not, by utilizing cross-lingual word embeddings. The evaluation
conducted shows that our word embeddings for endangered languages are
well-aligned with the resource-rich languages, and they are suitable for
training task-specific models as demonstrated by our sentiment analysis model
which achieved a high accuracy. All our cross-lingual word embeddings and the
sentiment analysis model have been released openly via an easy-to-use Python
library.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13275</dc:identifier>
 <dc:identifier>In M. H\&quot;am\&quot;al\&quot;ainen, N. Partanen, &amp; K. Alnajjar (Eds.),
  Multilingual Facilitation (pp. 275-288). University of Helsinki (2021)</dc:identifier>
 <dc:identifier>doi:10.31885/9789515150257.24</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13283</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information-based Disentangled Representation Learning for Unsupervised
  MR Harmonization</dc:title>
 <dc:creator>Zuo, Lianrui</dc:creator>
 <dc:creator>Dewey, Blake E.</dc:creator>
 <dc:creator>Carass, Aaron</dc:creator>
 <dc:creator>Liu, Yihao</dc:creator>
 <dc:creator>He, Yufan</dc:creator>
 <dc:creator>Calabresi, Peter A.</dc:creator>
 <dc:creator>Prince, Jerry L.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Accuracy and consistency are two key factors in computer-assisted magnetic
resonance (MR) image analysis. However, contrast variation from site to site
caused by lack of standardization in MR acquisition impedes consistent
measurements. In recent years, image harmonization approaches have been
proposed to compensate for contrast variation in MR images. Current
harmonization approaches either require cross-site traveling subjects for
supervised training or heavily rely on site-specific harmonization models to
encourage harmonization accuracy. These requirements potentially limit the
application of current harmonization methods in large-scale multi-site studies.
In this work, we propose an unsupervised MR harmonization framework, CALAMITI
(Contrast Anatomy Learning and Analysis for MR Intensity Translation and
Integration), based on information bottleneck theory. CALAMITI learns a
disentangled latent space using a unified structure for multi-site
harmonization without the need for traveling subjects. Our model is also able
to adapt itself to harmonize MR images from a new site with fine tuning solely
on images from the new site. Both qualitative and quantitative results show
that the proposed method achieves superior performance compared with other
unsupervised harmonization approaches.
</dc:description>
 <dc:description>Comment: Accepted in the 27th International Conference on Information
  Processing in Medical Imaging (IPMI 2021)</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13283</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13287</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human Factors in Security Research: Lessons Learned from 2008-2018</dc:title>
 <dc:creator>Kaur, Mannat</dc:creator>
 <dc:creator>van Eeten, Michel</dc:creator>
 <dc:creator>Janssen, Marijn</dc:creator>
 <dc:creator>Borgolte, Kevin</dc:creator>
 <dc:creator>Fiebig, Tobias</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Instead of only considering technology, computer security research now
strives to also take into account the human factor by studying regular users
and, to a lesser extent, experts like operators and developers of systems. We
focus our analysis on the research on the crucial population of experts, whose
human errors can impact many systems at once, and compare it to research on
regular users. To understand how far we advanced in the area of human factors,
how the field can further mature, and to provide a point of reference for
researchers new to this field, we analyzed the past decade of human factors
research in security and privacy, identifying 557 relevant publications. Of
these, we found 48 publications focused on expert users and analyzed all in
depth. For additional insights, we compare them to a stratified sample of 48
end-user studies.
  In this paper we investigate:
  (i) The perspective on human factors, and how we can learn from safety
science (ii) How and who are the participants recruited, and how this -- as we
find -- creates a western-centric perspective (iii) Research objectives, and
how to align these with the chosen research methods (iv) How theories can be
used to increase rigor in the communities scientific work, including
limitations to the use of Grounded Theory, which is often incompletely applied
(v) How researchers handle ethical implications, and what we can do to account
for them more consistently
  Although our literature review has limitations, new insights were revealed
and avenues for further research identified.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13287</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13289</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatisierte Verwaltung von ITS Roadside Stations f\&quot;ur den simTD
  Feldversuch</dc:title>
 <dc:creator>Wieker, Horst</dc:creator>
 <dc:creator>Allani, Bechir</dc:creator>
 <dc:creator>Baum, Thomas</dc:creator>
 <dc:creator>F&#xfc;nfrocken, Manuel</dc:creator>
 <dc:creator>Hinsberger, Arno</dc:creator>
 <dc:creator>Vogt, Jonas</dc:creator>
 <dc:creator>Weber, Sebastian</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The simTD project is the first large-scale field trial for vehicle-to-vehicle
and vehicle-to-infrastructure communication in Europe. It consists of up to 400
vehicles and over 100 infrastructure-side communication units, so-called ITS
Roadside Stations (IRS). With the large number of remote units, a powerful
management system is needed to ensure that all necessary administrative tasks
for the IRS can be performed: from basic configuration, to installation and
management of applications, to handling and troubleshooting of the IRS
themselves. Furthermore, a graphical interface for administration will be
created, an encrypted communication channel will be implemented, and a
framework for third-party applications will be developed. Due to the importance
of management for the entire project, the management system must be highly
available.
</dc:description>
 <dc:description>Comment: in German. Presented at Automatisierungs-, Assistenzsysteme und
  eingebettete Systeme f\&quot;ur Transportmittel - AAET, Braunschweig, Germany,
  10-11 February 2010</dc:description>
 <dc:date>2021-02-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13289</dc:identifier>
 <dc:language>de</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13293</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-aware Resource Management for Federated Learning in Multi-access
  Edge Computing Systems</dc:title>
 <dc:creator>Zaw, Chit Wutyee</dc:creator>
 <dc:creator>Pandey, Shashi Raj</dc:creator>
 <dc:creator>Kim, Kitae</dc:creator>
 <dc:creator>Hong, Choong Seon</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  In Federated Learning (FL), a global statistical model is developed by
encouraging mobile users to perform the model training on their local data and
aggregating the output local model parameters in an iterative manner. However,
due to limited energy and computation capability at the mobile devices, the
performance of the model training is always at stake to meet the objective of
local energy minimization. In this regard, Multi-access Edge Computing
(MEC)-enabled FL addresses the tradeoff between the model performance and the
energy consumption of the mobile devices by allowing users to offload a portion
of their local dataset to an edge server for the model training. Since the edge
server has high computation capability, the time consumption of the model
training at the edge server is insignificant. However, the time consumption for
dataset offloading from mobile users to the edge server has a significant
impact on the total time consumption. Thus, resource management in MEC-enabled
FL is challenging, where the objective is to reduce the total time consumption
while saving the energy consumption of the mobile devices. In this paper, we
formulate an energy-aware resource management for MEC-enabled FL in which the
model training loss and the total time consumption are jointly minimized, while
considering the energy limitation of mobile devices. In addition, we recast the
formulated problem as a Generalized Nash Equilibrium Problem (GNEP) to capture
the coupling constraints between the radio resource management and dataset
offloading. We then analyze the impact of the dataset offloading and computing
resource allocation on the model training loss, time, and the energy
consumption.
</dc:description>
 <dc:date>2021-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13293</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13294</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling of crisis periods in stock markets</dc:title>
 <dc:creator>Chalkis, Apostolos</dc:creator>
 <dc:creator>Christoforou, Emmanouil</dc:creator>
 <dc:creator>Dalamagkas, Theodore</dc:creator>
 <dc:creator>Emiris, Ioannis Z.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Quantitative Finance - Statistical Finance</dc:subject>
 <dc:subject>62-08, 51.08</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>I.0</dc:subject>
 <dc:description>  We exploit a recent computational framework to model and detect financial
crises in stock markets, as well as shock events in cryptocurrency markets,
which are characterized by a sudden or severe drop in prices. Our method
manages to detect all past crises in the French industrial stock market
starting with the crash of 1929, including financial crises after 1990 (e.g.
dot-com bubble burst of 2000, stock market downturn of 2002), and all past
crashes in the cryptocurrency market, namely in 2018, and also in 2020 due to
covid-19. We leverage copulae clustering, based on the distance between
probability distributions, in order to validate the reliability of the
framework; we show that clusters contain copulae from similar market states
such as normal states, or crises. Moreover, we propose a novel regression model
that can detect successfully all past events using less than 10% of the
information that the previous framework requires. We train our model by
historical data on the industry assets, and we are able to detect all past
shock events in the cryptocurrency market. Our tools provide the essential
components of our software framework that offers fast and reliable detection,
or even prediction, of shock events in stock and cryptocurrency markets of
hundreds of assets.
</dc:description>
 <dc:description>Comment: 11 pages, 10 figures, 1 table</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13298</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Reinforcement Learning with Symmetric Prior for Predictive Power
  Allocation to Mobile Users</dc:title>
 <dc:creator>Zhao, Jianyu</dc:creator>
 <dc:creator>Yang, Chenyang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Deep reinforcement learning has been applied for a variety of wireless tasks,
which is however known with high training and inference complexity. In this
paper, we resort to deep deterministic policy gradient (DDPG) algorithm to
optimize predictive power allocation among K mobile users requesting video
streaming, which minimizes the energy consumption of the network under the
no-stalling constraint of each user. To reduce the sampling complexity and
model size of the DDPG, we exploit a kind of symmetric prior inherent in the
actor and critic networks: permutation invariant and equivariant properties, to
design the neural networks. Our analysis shows that the free model parameters
of the DDPG can be compressed by 2/K^2. Simulation results demonstrate that the
episodes required by the learning model with the symmetric prior to achieve the
same performance as the vanilla policy reduces by about one third when K = 10.
</dc:description>
 <dc:date>2021-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13298</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13303</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IoT Data Quality Issues and Potential Solutions: A Literature Review</dc:title>
 <dc:creator>Mansouri, Taha</dc:creator>
 <dc:creator>Moghadam, Mohammad Reza Sadeghi</dc:creator>
 <dc:creator>Monshizadeh, Fatemeh</dc:creator>
 <dc:creator>Zareravasan, Ahad</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The Internet of Things (IoT) is a paradigm that connects everyday items to
the Internet. In the recent decade, the IoT's spreading popularity is a
promising opportunity for people and industries. IoT utilizes in a wide range
of respects such as agriculture, healthcare, smart cities, and manufacturing
sectors. IoT data quality is crucial in IoT real-life applications. IoT data
quality dimensions and issues should be considered because we require data to
make accurate and timely decisions, produce commodities, and gain insights
about events, people, and the environment. It is essential to point out that we
cannot reach valuable results by using poor quality data. This paper aims to
develop a new category for IoT data quality. Hence, we examine existing IoT
data quality dimensions and IoT data quality issues in general and specific
domains and IoT data quality dimensions' categories. It is worth considering
that categories in the context of IoT are not many. We developed a new category
in which IoT data quality dimensions and issues are separated. Concerning this
category, we can get familiar with related dimensions and issues in each
category. To enhance data quality dimensions and minimize data quality issues,
we suggest potential solutions using Blockchain to overcome IoT's security
issues.
</dc:description>
 <dc:date>2021-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13303</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13306</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Delay and Power consumption Analysis for Queue State Dependent Service
  Rate Control in WirelessHart System</dc:title>
 <dc:creator>Guha, Dibyajyoti</dc:creator>
 <dc:creator>Chen, Jie</dc:creator>
 <dc:creator>Banik, Abhijit Dutta</dc:creator>
 <dc:creator>Sikdar, Biplab</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  To solve the problem of power supply limitation of machines working in
wireless industry automation, we evaluated the workload aware service rate
control design implanted in the medium access control component of these small
devices and proposed a bio-intelligence based algorithm to optimise the design
regarding the delay constraint while minimizing power consumption. To achieve
this, we provide an accurate analysis of the delay cost of this design and for
the first time pinpoint an exact departure process model in order to evaluate
the overall delay cost in consideration of the medium access time.
</dc:description>
 <dc:date>2021-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13306</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13309</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Are Multilingual Models Effective in Code-Switching?</dc:title>
 <dc:creator>Winata, Genta Indra</dc:creator>
 <dc:creator>Cahyawijaya, Samuel</dc:creator>
 <dc:creator>Liu, Zihan</dc:creator>
 <dc:creator>Lin, Zhaojiang</dc:creator>
 <dc:creator>Madotto, Andrea</dc:creator>
 <dc:creator>Fung, Pascale</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Multilingual language models have shown decent performance in multilingual
and cross-lingual natural language understanding tasks. However, the power of
these multilingual models in code-switching tasks has not been fully explored.
In this paper, we study the effectiveness of multilingual language models to
understand their capability and adaptability to the mixed-language setting by
considering the inference speed, performance, and number of parameters to
measure their practicality. We conduct experiments in three language pairs on
named entity recognition and part-of-speech tagging and compare them with
existing methods, such as using bilingual embeddings and multilingual
meta-embeddings. Our findings suggest that pre-trained multilingual models do
not necessarily guarantee high-quality representations on code-switching, while
using meta-embeddings achieves similar results with significantly fewer
parameters.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13314</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MONAIfbs: MONAI-based fetal brain MRI deep learning segmentation</dc:title>
 <dc:creator>Ranzini, Marta B. M.</dc:creator>
 <dc:creator>Fidon, Lucas</dc:creator>
 <dc:creator>Ourselin, S&#xe9;bastien</dc:creator>
 <dc:creator>Modat, Marc</dc:creator>
 <dc:creator>Vercauteren, Tom</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In fetal Magnetic Resonance Imaging, Super Resolution Reconstruction (SRR)
algorithms are becoming popular tools to obtain high-resolution 3D volume
reconstructions from low-resolution stacks of 2D slices, acquired at different
orientations. To be effective, these algorithms often require accurate
segmentation of the region of interest, such as the fetal brain in suspected
pathological cases. In the case of Spina Bifida, Ebner, Wang et al.
(NeuroImage, 2020) combined their SRR algorithm with a 2-step segmentation
pipeline (2D localisation followed by a 2D segmentation network). However, if
the localisation step fails, the second network is not able to recover a
correct brain mask, thus requiring manual corrections for an effective SRR. In
this work, we aim at improving the fetal brain segmentation for SRR in Spina
Bifida. We hypothesise that a well-trained single-step UNet can achieve
accurate performance, avoiding the need of a 2-step approach. We propose a new
tool for fetal brain segmentation called MONAIfbs, which takes advantage of the
Medical Open Network for Artificial Intelligence (MONAI) framework. Our network
is based on the dynamic UNet (dynUNet), an adaptation of the nnU-Net framework.
When compared to the original 2-step approach proposed in Ebner-Wang, and the
same Ebner-Wang approach retrained with the expanded dataset available for this
work, the dynUNet showed to achieve higher performance using a single step
only. It also showed to reduce the number of outliers, as only 28 stacks
obtained Dice score less than 0.9, compared to 68 for Ebner-Wang and 53
Ebner-Wang expanded. The proposed dynUNet model thus provides an improvement of
the state-of-the-art fetal brain segmentation techniques, reducing the need for
manual correction in automated SRR pipelines. Our code and our trained model
are made publicly available at https://github.com/gift-surg/MONAIfbs.
</dc:description>
 <dc:description>Comment: Abstract accepted at IEEE International Symposium on Biomedical
  Imaging (ISBI) 2021</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13314</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13315</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model Independent Error Bound Estimation for Conformance Checking
  Approximation</dc:title>
 <dc:creator>Sani, Mohammadreza Fani</dc:creator>
 <dc:creator>Kabierski, Martin</dc:creator>
 <dc:creator>van Zelst, Sebastiaan J.</dc:creator>
 <dc:creator>van der Aalst, Wil M. P.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Conformance checking techniques allow us to quantify the correspondence of a
process's execution, captured in event data, w.r.t., a reference process model.
In this context, alignments have proven to be useful for calculating
conformance statistics. However, for extensive event data and complex process
models, the computation time of alignments is considerably high, hampering
their practical use. Simultaneously, it suffices to approximate either
alignments or their corresponding conformance value(s) for many applications.
Recent work has shown that using subsets of the process model behavior leads to
accurate conformance approximations. The accuracy of such an approximation
heavily depends on the selected subset of model behavior. Thus, in this paper,
we show that we can derive a priori error bounds for conformance checking
approximation based on arbitrary activity sequences, independently of the given
process model. Such error bounds subsequently let us select the most relevant
subset of process model behavior for the alignment approximation. Experiments
confirm that conformance approximation accuracy improves when using the
proposed error bound approximation to guide the selection of relevant subsets
of process model behavior.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13317</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-End Quality of Service Management in the Physical Internet: a
  Digital Internet Inspired Multi-Domain Approach</dc:title>
 <dc:creator>Phillipson, Frank</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  For the layer 'System Level Functionality' of the Phyisical Internet, it is
needed to estimate end-to-end performance characteristics of transportations
that visit multiple logistic domains. This paper proposes an approach based on
a Digital Internet functionality: a combination of a Service Level Agreement
registry and a Quality of Service processor. Existing SLA-calculus gives tools
for the QoS-processor to combine the SLA-parameters for all possible end-to-end
paths and gives the QoS-processor the possibility to propose the best path
given the required performance. A realistic implementation is proposed using a
multi objective/constraint approach and a related communication form between
the domain owner and the QoS Processor.
</dc:description>
 <dc:description>Comment: 11 pages, 3 figures</dc:description>
 <dc:date>2021-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13321</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network Reconfiguration Impact on Renewable Energy System and Energy
  Storage System in Day-Ahead Scheduling</dc:title>
 <dc:creator>Ramesh, Arun Venkatesh</dc:creator>
 <dc:creator>Li, Xingpeng</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Renewable energy sources (RES) has gained significant interest in recent
years. However, due to favourable weather conditions, the RES is installed in
remote locations with limited transmission capacity. As a result, it can lead
to major curtailments of the free resource when the network is congested.
Therefore, energy storage system (ESS) is considered as a viable solution to
store energy and address the intermittent nature of RES though ESS is often
distributed and may not be geographically close to RES. Therefore, ESS may also
suffer from limited transmission capacity due to network congestion. Currently,
grid operators overlook network flexibility as a congestion management tool in
day-ahead scheduling. This paper addresses these issues and studies the
benefits of introducing network reconfiguration (NR) as a preventive and
corrective action for transmission flexibility in day-ahead stochastic
security-constrained unit-commitment (SSCUC-PC) while considering a
multi-scenario RES output. Simulation results demonstrate that NR can lower
total system cost, reduce RES curtailments and utilize ESS for better impact by
alleviating network congestion in both base-case and post-contingency networks.
</dc:description>
 <dc:date>2021-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13322</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DNN Quantization with Attention</dc:title>
 <dc:creator>Hacene, Ghouthi Boukli</dc:creator>
 <dc:creator>Mauch, Lukas</dc:creator>
 <dc:creator>Uhlich, Stefan</dc:creator>
 <dc:creator>Cardinaux, Fabien</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Low-bit quantization of network weights and activations can drastically
reduce the memory footprint, complexity, energy consumption and latency of Deep
Neural Networks (DNNs). However, low-bit quantization can also cause a
considerable drop in accuracy, in particular when we apply it to complex
learning tasks or lightweight DNN architectures. In this paper, we propose a
training procedure that relaxes the low-bit quantization. We call this
procedure \textit{DNN Quantization with Attention} (DQA). The relaxation is
achieved by using a learnable linear combination of high, medium and low-bit
quantizations. Our learning procedure converges step by step to a low-bit
quantization using an attention mechanism with temperature scheduling. In
experiments, our approach outperforms other low-bit quantization techniques on
various object recognition benchmarks such as CIFAR10, CIFAR100 and ImageNet
ILSVRC 2012, achieves almost the same accuracy as a full precision DNN, and
considerably reduces the accuracy drop when quantizing lightweight DNN
architectures.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13322</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13329</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fine-tuning of Pre-trained End-to-end Speech Recognition with Generative
  Adversarial Networks</dc:title>
 <dc:creator>Haidar, Md Akmal</dc:creator>
 <dc:creator>Rezagholizadeh, Mehdi</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Adversarial training of end-to-end (E2E) ASR systems using generative
adversarial networks (GAN) has recently been explored for low-resource ASR
corpora. GANs help to learn the true data representation through a two-player
min-max game. However, training an E2E ASR model using a large ASR corpus with
a GAN framework has never been explored, because it might take excessively long
time due to high-variance gradient updates and face convergence issues. In this
paper, we introduce a novel framework for fine-tuning a pre-trained ASR model
using the GAN objective where the ASR model acts as a generator and a
discriminator tries to distinguish the ASR output from the real data. Since the
ASR model is pre-trained, we hypothesize that the ASR model output (soft
distribution vectors) helps to get higher scores from the discriminator and
makes the task of the discriminator harder within our GAN framework, which in
turn improves the performance of the ASR model in the fine-tuning stage. Here,
the pre-trained ASR model is fine-tuned adversarially against the discriminator
using an additional adversarial loss. Experiments on full LibriSpeech dataset
show that our proposed approach outperforms baselines and conventional
GAN-based adversarial models.
</dc:description>
 <dc:description>Comment: Accepted in ICASSP 2021 conference</dc:description>
 <dc:date>2021-03-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13331</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Complexity of Dependency Detection and Discovery in Relational
  Databases</dc:title>
 <dc:creator>Bl&#xe4;sius, Thomas</dc:creator>
 <dc:creator>Friedrich, Tobias</dc:creator>
 <dc:creator>Schirneck, Martin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Multi-column dependencies in relational databases come associated with two
different computational tasks. The detection problem is to decide whether a
dependency of a certain type and size holds in a given database, the discovery
problem asks to enumerate all valid dependencies of that type. We settle the
complexity of both of these problems for unique column combinations (UCCs),
functional dependencies (FDs), and inclusion dependencies (INDs). We show that
the detection of UCCs and FDs is W[2]-complete when parameterized by the
solution size. The discovery of inclusion-wise minimal UCCs is proven to be
equivalent under parsimonious reductions to the transversal hypergraph problem
of enumerating the minimal hitting sets of a hypergraph. The discovery of FDs
is equivalent to the simultaneous enumeration of the hitting sets of multiple
input hypergraphs. We further identify the detection of INDs as one of the
first natural W[3]-complete problems. The discovery of maximal INDs is shown to
be equivalent to enumerating the maximal satisfying assignments of
antimonotone, 3-normalized Boolean formulas.
</dc:description>
 <dc:description>Comment: 39 pages, 5 figures</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13331</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13333</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Multi-Tenant Framework for Cloud Container Services</dc:title>
 <dc:creator>Zheng, Chao</dc:creator>
 <dc:creator>Zhuang, Qinghui</dc:creator>
 <dc:creator>Guo, Fei</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Container technologies have been evolving rapidly in the cloud-native era.
Kubernetes, as a production-grade container orchestration platform, has been
proven to be successful at managing containerized applications in on-premises
datacenters. However, Kubernetes lacks sufficient multi-tenant supports by
design, meaning in cloud environments, dedicated clusters are required to serve
multiple users, i.e., tenants. This limitation significantly diminishes the
benefits of cloud computing, and makes it difficult to build multi-tenant
software as a service (SaaS) products using Kubernetes. In this paper, we
propose Virtual-Cluster, a new multi-tenant framework that extends Kubernetes
with adequate multi-tenant supports. Basically, VirtualCluster provides both
control plane and data plane isolations while sharing the underlying compute
resources among tenants. The new framework preserves the API compatibility by
avoiding modifying the Kubernetes core components. Hence, it can be easily
integrated with existing Kubernetes use cases. Our experimental results show
that the overheads introduced by VirtualCluster, in terms of latency and
throughput, is moderate.
</dc:description>
 <dc:description>Comment: ICDCS 21 industry track</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13333</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13348</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beamforming in LEO Constellations for NB-IoT Services in 6G
  Communications</dc:title>
 <dc:creator>Guidotti, Alessandro</dc:creator>
 <dc:creator>Conti, Matteo</dc:creator>
 <dc:creator>Vanelli-Coralli, Alessandro</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  With the first commercializations of 5G networks, Beyond 5G (B5G), or 6G,
systems are starting to be defined. In this context, Internet of Things (IoT)
services will be even more impactful with respect to 5G systems. In order to
cope with the huge amount of IoT devices, and the potentially large capacity
requirements for the most advanced of them (e.g., live camera feeds from first
responders in emergency scenarios), non-terrestrial systems will be pivotal to
assist and complement the terrestrial networks. In this paper, we propose a
multi-layer non-terrestrial architecture for NarrowBand-IoT (NB-IoT) services
based on Geosynchronous Orbit (GSO) and Non GSO (NGSO) nodes. To cope with both
the number of devices and the potentially large capacities, we propose to
implement Minimum Mean Square Error (MMSE) beamforming in an aggressive full
frequency reuse scenario. The performance assessment shows the significant
benefits of the proposed solution.
</dc:description>
 <dc:description>Comment: Submitted to IEEE ICC'21 Workshop - SatMegaConst 2021</dc:description>
 <dc:date>2021-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13348</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13350</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Frequency and Impact of Technical Debt Characteristics in Companies
  Producing Mechatronic Products</dc:title>
 <dc:creator>Bi, Fandi</dc:creator>
 <dc:creator>Vogel-Heuser, Birgit</dc:creator>
 <dc:creator>Xu, Litong</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Complexity of products, volatility in global markets, and the increasingly
rapid pace of innovations may make it difficult to know how to approach
challenging situations in mechatronic design and production. Technical Debt
(TD) is a metaphor that describes the practical bargain of exchanging
short-term benefits for long-term negative consequences. Oftentimes, the scope
and impact of TD, as well as the cost of corrective measures, are
underestimated. Especially for mechatronic teams in the mechanical, electrical,
and software disciplines, the adverse interdisciplinary ripple effects of TD
incidents are passed on throughout the life cycle. The analysis of the first
comprehensive survey showed that not only do the TD types differ in
cross-disciplinary comparisons, but different characteristics can also be
observed depending on whether a discipline is studied in isolation or in
combination with others. To validate the study results and to report on a
general consciousness of TD in the disciplines, this follow-up study involves
15 of the 50 experts of the predecessor study and reflects the frequency and
impact of technical debt in industrial experts' daily work using a
questionnaire. These experts rate 14 TD types, 47 TD causes, and 33 TD symptoms
in terms of their frequency and impact. Detailed analyses reveal consistent
results for the most frequent TD types and causes, yet they show divergent
characteristics in a profound exploration of discipline-specific phenomena.
Thus, this study has the potential to set the foundations for future automated
TD identification analyses in mechatronics.
</dc:description>
 <dc:description>Comment: TechDebt 2021 Conference, 10 pages, 4 figures, 2 tables</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13353</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovering Multiple Design Approaches in Programming Assignment
  Submissions</dc:title>
 <dc:creator>KN, Nikhila</dc:creator>
 <dc:creator>Chakrabarti, Sujit Kumar</dc:creator>
 <dc:creator>Gupta, Manish</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In this paper, we present a novel approach of automated evaluation of
programming assignments~(AEPA) the highlight of which is that it automatically
identifies multiple solution approaches to the programming question from the
set of submitted solutions. Our approach does not require the instructor to
foresee all the possible solution approaches and accomplishes this task with
little or no human intervention. This paves the way to multiple fundamental
improvements in the way automated evaluation of programming assignments is done
today. We have applied our method on multiple data sets of practical scale. In
all cases, our method was able to detect the solution approaches employed by
the students.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13353</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13356</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Efficient Auctions in an Auto-bidding World</dc:title>
 <dc:creator>Deng, Yuan</dc:creator>
 <dc:creator>Mao, Jieming</dc:creator>
 <dc:creator>Mirrokni, Vahab</dc:creator>
 <dc:creator>Zuo, Song</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Auto-bidding has become one of the main options for bidding in online
advertisements, in which advertisers only need to specify high-level objectives
and leave the complex task of bidding to auto-bidders. In this paper, we
propose a family of auctions with boosts to improve welfare in auto-bidding
environments with both return on ad spend constraints and budget constraints.
Our empirical results validate our theoretical findings and show that both the
welfare and revenue can be improved by selecting the weight of the boosts
properly.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13361</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structured Co-reference Graph Attention for Video-grounded Dialogue</dc:title>
 <dc:creator>Kim, Junyeong</dc:creator>
 <dc:creator>Yoon, Sunjae</dc:creator>
 <dc:creator>Kim, Dahyun</dc:creator>
 <dc:creator>Yoo, Chang D.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A video-grounded dialogue system referred to as the Structured Co-reference
Graph Attention (SCGA) is presented for decoding the answer sequence to a
question regarding a given video while keeping track of the dialogue context.
Although recent efforts have made great strides in improving the quality of the
response, performance is still far from satisfactory. The two main challenging
issues are as follows: (1) how to deduce co-reference among multiple modalities
and (2) how to reason on the rich underlying semantic structure of video with
complex spatial and temporal dynamics. To this end, SCGA is based on (1)
Structured Co-reference Resolver that performs dereferencing via building a
structured graph over multiple modalities, (2) Spatio-temporal Video Reasoner
that captures local-to-global dynamics of video via gradually neighboring graph
attention. SCGA makes use of pointer network to dynamically replicate parts of
the question for decoding the answer sequence. The validity of the proposed
SCGA is demonstrated on AVSD@DSTC7 and AVSD@DSTC8 datasets, a challenging
video-grounded dialogue benchmarks, and TVQA dataset, a large-scale videoQA
benchmark. Our empirical results show that SCGA outperforms other
state-of-the-art dialogue systems on both benchmarks, while extensive ablation
study and qualitative analysis reveal performance gain and improved
interpretability.
</dc:description>
 <dc:description>Comment: Accepted to AAAI2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13361</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13372</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Affective Processes: stochastic modelling of temporal context for
  emotion and facial expression recognition</dc:title>
 <dc:creator>Sanchez, Enrique</dc:creator>
 <dc:creator>Tellamekala, Mani Kumar</dc:creator>
 <dc:creator>Valstar, Michel</dc:creator>
 <dc:creator>Tzimiropoulos, Georgios</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Temporal context is key to the recognition of expressions of emotion.
Existing methods, that rely on recurrent or self-attention models to enforce
temporal consistency, work on the feature level, ignoring the task-specific
temporal dependencies, and fail to model context uncertainty. To alleviate
these issues, we build upon the framework of Neural Processes to propose a
method for apparent emotion recognition with three key novel components: (a)
probabilistic contextual representation with a global latent variable model;
(b) temporal context modelling using task-specific predictions in addition to
features; and (c) smart temporal context selection. We validate our approach on
four databases, two for Valence and Arousal estimation (SEWA and AffWild2), and
two for Action Unit intensity estimation (DISFA and BP4D). Results show a
consistent improvement over a series of strong baselines as well as over
state-of-the-art methods.
</dc:description>
 <dc:description>Comment: Accepted at CVPR 2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13372</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13381</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Are energy savings the only reason for the emergence of bird echelon
  formation?</dc:title>
 <dc:creator>Shi, Mingming</dc:creator>
 <dc:creator>Hendrickx, Julien M.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We analyze the conditions under which the emergence of frequently observed
echelon formation can be explained solely by the maximization of energy
savings. We consider a two-dimensional multi-agent echelon formation, where
each agent receives a benefit that depends on its position relative to the
others, and adjusts its position to increase this benefit. We analyze the
selfish case where each agent maximizes its own benefit, leading to a
Nash-equilibrium problem, and the collaborative case in which agents maximize
the global benefit of the group. We provide conditions on the benefit function
under which the frequently observed echelon formations cannot be Nash
equilbriums or group optimums.
  We then show that these conditions are satisfied by the conventionally used
fixed-wing wake benefit model. This implies that energy saving alone is not
sufficient to explain the emergence of the migratory formations observed, based
on the fixed-wing model. Hence, either non-aerodynamic aspects or a more
accurate model of bird dynamics should be considered to construct such
formations.
</dc:description>
 <dc:description>Comment: 8 pages, 12 figures, submitted to a conference</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13390</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Row-Polymorphic Types for Strategic Rewriting</dc:title>
 <dc:creator>Fu, Rongxiao</dc:creator>
 <dc:creator>Qin, Xueying</dc:creator>
 <dc:creator>Dardha, Ornela</dc:creator>
 <dc:creator>Steuwer, Michel</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We present a type system for strategy languages that express program
transformations as compositions of rewrite rules. Our row-polymorphic type
system assists compiler engineers to write correct strategies by statically
rejecting non meaningful compositions of rewrites that otherwise would fail
during rewriting at runtime. Furthermore, our type system enables reasoning
about how rewriting transforms the shape of the computational program. We
present a formalization of our language at its type system and demonstrate its
practical use for expressing compiler optimization strategies. Our type system
builds the foundation for many interesting future applications, including
verifying the correctness of program transformations and synthesizing program
transformations from specifications encoded as types.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13390</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13391</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Female ICT participation in South-Eastern Nigerian Tertiary
  Institutions: Inhibiting Factors</dc:title>
 <dc:creator>Nwajiuba, Chinyere A.</dc:creator>
 <dc:creator>Ukwandu, Elochukwu</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The study examined the participation of female students of South Eastern
Nigerian tertiary institutions in Information and Communication Technologies
(ICTs). The study discussed the attendant gender divide in ICTs participation,
reasons for low female participation in ICT, consequences of not bridging the
divide and ways of encouraging female participation in ICT. A structured
questionnaire was used to elicit information from respondents. A multi stage
random sampling technique was used in the selection of respondents. One hundred
and thirty six (136) undergraduate female students of tertiary institutions in
South Eastern Nigeria constituted the study sample. Data collected was analysed
using descriptive statistics. Findings suggest that high cost of ICT and high
level of male dominance, which made females think that ICT is for males were
the major reasons for low female participation in ICT. Reducing the cost of
Information Technology, and parental involvement in their children selection
choice of study were suggested to encourage female participation in Information
and Communication Technologies.
</dc:description>
 <dc:description>Comment: 16 pages, conference paper</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13391</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13413</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vision Transformers for Dense Prediction</dc:title>
 <dc:creator>Ranftl, Ren&#xe9;</dc:creator>
 <dc:creator>Bochkovskiy, Alexey</dc:creator>
 <dc:creator>Koltun, Vladlen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce dense vision transformers, an architecture that leverages vision
transformers in place of convolutional networks as a backbone for dense
prediction tasks. We assemble tokens from various stages of the vision
transformer into image-like representations at various resolutions and
progressively combine them into full-resolution predictions using a
convolutional decoder. The transformer backbone processes representations at a
constant and relatively high resolution and has a global receptive field at
every stage. These properties allow the dense vision transformer to provide
finer-grained and more globally coherent predictions when compared to
fully-convolutional networks. Our experiments show that this architecture
yields substantial improvements on dense prediction tasks, especially when a
large amount of training data is available. For monocular depth estimation, we
observe an improvement of up to 28% in relative performance when compared to a
state-of-the-art fully-convolutional network. When applied to semantic
segmentation, dense vision transformers set a new state of the art on ADE20K
with 49.02% mIoU. We further show that the architecture can be fine-tuned on
smaller datasets such as NYUv2, KITTI, and Pascal Context where it also sets
the new state of the art. Our models are available at
https://github.com/intel-isl/DPT.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13413</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13419</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the $\ell^\infty$-norms of the Singular Vectors of Arbitrary Powers
  of a Difference Matrix with Applications to Sigma-Delta Quantization</dc:title>
 <dc:creator>Faust, Theodore</dc:creator>
 <dc:creator>Iwen, Mark</dc:creator>
 <dc:creator>Saab, Rayan</dc:creator>
 <dc:creator>Wang, Rongrong</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>15A42 (Primary) 15A18, 94A12, 39A22 (Secondary)</dc:subject>
 <dc:description>  Let $\| A \|_{\max} := \max_{i,j} |A_{i,j}|$ denote the maximum magnitude of
entries of a given matrix $A$. In this paper we show that $$\max \left\{ \|U_r
\|_{\max},\|V_r\|_{\max} \right\} \le \frac{(Cr)^{6r}}{\sqrt{N}},$$ where $U_r$
and $V_r$ are the matrices whose columns are, respectively, the left and right
singular vectors of the $r$-th order finite difference matrix $D^{r}$ with $r
\geq 2$, and where $D$ is the $N\times N$ finite difference matrix with $1$ on
the diagonal, $-1$ on the sub-diagonal, and $0$ elsewhere. Here $C$ is a
universal constant that is independent of both $N$ and $r$. Among other things,
this establishes that both the right and left singular vectors of such finite
difference matrices are Bounded Orthonormal Systems (BOSs) with known upper
bounds on their BOS constants, objects of general interest in classical
compressive sensing theory. Such finite difference matrices are also
fundamental to standard $r^{\rm th}$ order Sigma-Delta quantization schemes
more specifically, and as a result the new bounds provided herein on the
maximum $\ell^{\infty}$-norms of their $\ell^2$-normalized singular vectors
allow for several previous Sigma-Delta quantization results to be generalized
and improved.
</dc:description>
 <dc:description>Comment: 24 pages not including appendices, 54 pages with appendices</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13419</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13420</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Multitask Learning with Committees</dc:title>
 <dc:creator>Xu, Jingxi</dc:creator>
 <dc:creator>Tang, Da</dc:creator>
 <dc:creator>Jebara, Tony</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The cost of annotating training data has traditionally been a bottleneck for
supervised learning approaches. The problem is further exacerbated when
supervised learning is applied to a number of correlated tasks simultaneously
since the amount of labels required scales with the number of tasks. To
mitigate this concern, we propose an active multitask learning algorithm that
achieves knowledge transfer between tasks. The approach forms a so-called
committee for each task that jointly makes decisions and directly shares data
across similar tasks. Our approach reduces the number of queries needed during
training while maintaining high accuracy on test data. Empirical results on
benchmark datasets show significant improvements on both accuracy and number of
query requests.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13423</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Foreground color prediction through inverse compositing</dc:title>
 <dc:creator>Lutz, Sebastian</dc:creator>
 <dc:creator>Smolic, Aljosa</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In natural image matting, the goal is to estimate the opacity of the
foreground object in the image. This opacity controls the way the foreground
and background is blended in transparent regions. In recent years, advances in
deep learning have led to many natural image matting algorithms that have
achieved outstanding performance in a fully automatic manner. However, most of
these algorithms only predict the alpha matte from the image, which is not
sufficient to create high-quality compositions. Further, it is not possible to
manually interact with these algorithms in any way except by directly changing
their input or output. We propose a novel recurrent neural network that can be
used as a post-processing method to recover the foreground and background
colors of an image, given an initial alpha estimation. Our method outperforms
the state-of-the-art in color estimation for natural image matting and show
that the recurrent nature of our method allows users to easily change candidate
solutions that lead to superior color estimations.
</dc:description>
 <dc:description>Comment: To be published in WACV 2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13423</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13425</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diverse Branch Block: Building a Convolution as an Inception-like Unit</dc:title>
 <dc:creator>Ding, Xiaohan</dc:creator>
 <dc:creator>Zhang, Xiangyu</dc:creator>
 <dc:creator>Han, Jungong</dc:creator>
 <dc:creator>Ding, Guiguang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We propose a universal building block of Convolutional Neural Network
(ConvNet) to improve the performance without any inference-time costs. The
block is named Diverse Branch Block (DBB), which enhances the representational
capacity of a single convolution by combining diverse branches of different
scales and complexities to enrich the feature space, including sequences of
convolutions, multi-scale convolutions, and average pooling. After training, a
DBB can be equivalently converted into a single conv layer for deployment.
Unlike the advancements of novel ConvNet architectures, DBB complicates the
training-time microstructure while maintaining the macro architecture, so that
it can be used as a drop-in replacement for regular conv layers of any
architecture. In this way, the model can be trained to reach a higher level of
performance and then transformed into the original inference-time structure for
inference. DBB improves ConvNets on image classification (up to 1.9% higher
top-1 accuracy on ImageNet), object detection and semantic segmentation. The
PyTorch code and models are released at
https://github.com/DingXiaoH/DiverseBranchBlock.
</dc:description>
 <dc:description>Comment: CVPR 2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13428</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TagMe: GPS-Assisted Automatic Object Annotation in Videos</dc:title>
 <dc:creator>He, Songtao</dc:creator>
 <dc:creator>Bastani, Favyen</dc:creator>
 <dc:creator>Alizadeh, Mohammad</dc:creator>
 <dc:creator>Balakrishnan, Hari</dc:creator>
 <dc:creator>Cafarella, Michael</dc:creator>
 <dc:creator>Kraska, Tim</dc:creator>
 <dc:creator>Madden, Sam</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Training high-accuracy object detection models requires large and diverse
annotated datasets. However, creating these data-sets is time-consuming and
expensive since it relies on human annotators. We design, implement, and
evaluate TagMe, a new approach for automatic object annotation in videos that
uses GPS data. When the GPS trace of an object is available, TagMe matches the
object's motion from GPS trace and the pixels' motions in the video to find the
pixels belonging to the object in the video and creates the bounding box
annotations of the object. TagMe works using passive data collection and can
continuously generate new object annotations from outdoor video streams without
any human annotators. We evaluate TagMe on a dataset of 100 video clips. We
show TagMe can produce high-quality object annotations in a fully-automatic and
low-cost way. Compared with the traditional human-in-the-loop solution, TagMe
can produce the same amount of annotations at a much lower cost, e.g., up to
110x.
</dc:description>
 <dc:description>Comment: https://people.csail.mit.edu/songtao/tagme.html</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13428</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13429</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A High-Gain Observer Approach to Robust Trajectory Estimation and
  Tracking for a Multi-rotor UAV</dc:title>
 <dc:creator>Boss, Connor J</dc:creator>
 <dc:creator>Srivastava, Vaibhav</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  We study the problem of estimating and tracking an unknown trajectory with a
multi-rotor UAV in the presence of modeling error and external disturbances.
The reference trajectory is unknown and generated from a reference system with
unknown or partially known dynamics. We assume the only measurements that are
available are the position and orientation of the multi-rotor and the position
of the reference system. We adopt an extended high-gain observer (EHGO)
estimation framework to estimate the unmeasured multi-rotor states, modeling
error, external disturbances, and the reference trajectory. We design a robust
output feedback controller for trajectory tracking that comprises a feedback
linearizing controller and the EHGO. The proposed control method is rigorously
analyzed to establish its stability properties. Finally, we illustrate our
theoretical results through numerical simulation and experimental validation in
which a multi-rotor tracks a moving ground vehicle with unknown trajectory and
dynamics and successfully lands on the vehicle while in motion.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Control Systems Technology.
  Experiment video available at: https://youtu.be/oWcl4ydNLDs. arXiv admin
  note: text overlap with arXiv:2003.06390</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13429</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13445</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple and Efficient Stochastic Rounding Method for Training Neural
  Networks in Low Precision</dc:title>
 <dc:creator>Xia, Lu</dc:creator>
 <dc:creator>Anthonissen, Martijn</dc:creator>
 <dc:creator>Hochstenbach, Michiel</dc:creator>
 <dc:creator>Koren, Barry</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Conventional stochastic rounding (CSR) is widely employed in the training of
neural networks (NNs), showing promising training results even in low-precision
computations. We introduce an improved stochastic rounding method, that is
simple and efficient. The proposed method succeeds in training NNs with 16-bit
fixed-point numbers and provides faster convergence and higher classification
accuracy than both CSR and deterministic rounding-to-the-nearest method.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13445</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13447</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DRANet: Disentangling Representation and Adaptation Networks for
  Unsupervised Cross-Domain Adaptation</dc:title>
 <dc:creator>Lee, Seunghun</dc:creator>
 <dc:creator>Cho, Sunghyun</dc:creator>
 <dc:creator>Im, Sunghoon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we present DRANet, a network architecture that disentangles
image representations and transfers the visual attributes in a latent space for
unsupervised cross-domain adaptation. Unlike the existing domain adaptation
methods that learn associated features sharing a domain, DRANet preserves the
distinctiveness of each domain's characteristics. Our model encodes individual
representations of content (scene structure) and style (artistic appearance)
from both source and target images. Then, it adapts the domain by incorporating
the transferred style factor into the content factor along with learnable
weights specified for each domain. This learning framework allows
bi-/multi-directional domain adaptation with a single encoder-decoder network
and aligns their domain shift. Additionally, we propose a content-adaptive
domain transfer module that helps retain scene structure while transferring
style. Extensive experiments show our model successfully separates
content-style factors and synthesizes visually pleasing domain-transferred
images. The proposed method demonstrates state-of-the-art performance on
standard digit classification tasks as well as semantic segmentation tasks.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13447</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13453</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CrossFix: Collaborative bug fixing by recommending similar bugs</dc:title>
 <dc:creator>Tan, Shin Hwei</dc:creator>
 <dc:creator>Li, Ziqiang</dc:creator>
 <dc:creator>Yan, Lu</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Many automated program repair techniques have been proposed for fixing bugs.
Some of these techniques use the information beyond the given buggy program and
test suite to improve the quality of generated patches. However, there are
several limitations that hinder the wide adoption of these techniques,
including (1) they rely on a fixed set of repair templates for patch generation
or reference implementation, (2) searching for the suitable reference
implementation is challenging, (3) generated patches are not explainable.
Meanwhile, a recent approach shows that similar bugs exist across different
projects and one could use the GitHub issue from a different project for
finding new bugs for a related project. We propose collaborative bug fixing, a
novelapproach that suggests bug reports that describe a similar bug. Our
studyredefines similar bugs as bugs that share the (1) same libraries, (2) same
functionalities, (3) same reproduction steps, (4) same configurations, (5)
sameoutcomes, or (6) same errors. Moreover, our study revealed the usefulness
of similar bugs in helping developers in finding more context about the bug and
fixing. Based on our study, we design CrossFix, a tool that automatically
suggests relevant GitHub issues based on an open GitHub issue. Our evaluation
on 249 open issues from Java and Android projects shows that CrossFix could
suggest similar bugs to help developers in debugging and fixing.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13453</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13455</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Matched sample selection with GANs for mitigating attribute confounding</dc:title>
 <dc:creator>Singh, Chandan</dc:creator>
 <dc:creator>Balakrishnan, Guha</dc:creator>
 <dc:creator>Perona, Pietro</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Measuring biases of vision systems with respect to protected attributes like
gender and age is critical as these systems gain widespread use in society.
However, significant correlations between attributes in benchmark datasets make
it difficult to separate algorithmic bias from dataset bias. To mitigate such
attribute confounding during bias analysis, we propose a matching approach that
selects a subset of images from the full dataset with balanced attribute
distributions across protected attributes. Our matching approach first projects
real images onto a generative adversarial network (GAN)'s latent space in a
manner that preserves semantic attributes. It then finds image matches in this
latent space across a chosen protected attribute, yielding a dataset where
semantic and perceptual attributes are balanced across the protected attribute.
We validate projection and matching strategies with qualitative, quantitative,
and human annotation experiments. We demonstrate our work in the context of
gender bias in multiple open-source facial-recognition classifiers and find
that bias persists after removing key confounders via matching. Code and
documentation to reproduce the results here and apply the methods to new data
is available at https://github.com/csinva/matching-with-gans .
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13455</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13462</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Why Do Local Methods Solve Nonconvex Problems?</dc:title>
 <dc:creator>Ma, Tengyu</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Non-convex optimization is ubiquitous in modern machine learning. Researchers
devise non-convex objective functions and optimize them using off-the-shelf
optimizers such as stochastic gradient descent and its variants, which leverage
the local geometry and update iteratively. Even though solving non-convex
functions is NP-hard in the worst case, the optimization quality in practice is
often not an issue -- optimizers are largely believed to find approximate
global minima. Researchers hypothesize a unified explanation for this
intriguing phenomenon: most of the local minima of the practically-used
objectives are approximately global minima. We rigorously formalize it for
concrete instances of machine learning problems.
</dc:description>
 <dc:description>Comment: This is the Chapter 21 of the book &quot;Beyond the Worst-Case Analysis of
  Algorithms&quot;</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13462</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13477</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of Multimedia Technologies and Robust Algorithms</dc:title>
 <dc:creator>Kuang, Zijian</dc:creator>
 <dc:creator>Tie, Xinran</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Multimedia technologies are now more practical and deployable in real life,
and the algorithms are widely used in various researching areas such as deep
learning, signal processing, haptics, computer vision, robotics, and medical
multimedia processing. This survey provides an overview of multimedia
technologies and robust algorithms in multimedia data processing, medical
multimedia processing, human facial expression tracking and pose recognition,
and multimedia in education and training. This survey will also analyze and
propose a future research direction based on the overview of current robust
algorithms and multimedia technologies. We want to thank the research and
previous work done by the Multimedia Research Centre (MRC), the University of
Alberta, which is the inspiration and starting point for future research.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:2010.12968</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13477</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13481</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hall Effects on Casson Fluid Flow along a Vertical Plate</dc:title>
 <dc:creator>Akter, Mst. Sonia</dc:creator>
 <dc:creator>Islam, Mohammad Rafiqul</dc:creator>
 <dc:creator>Mollah, Md. Tusher</dc:creator>
 <dc:creator>Alam, Md. Mahmud</dc:creator>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  The Hall effects on Casson fluid flow along a vertical plate has been
investigated numerically. The governing equations have been derived from
Navier-Stokes' equation and boundary layer approximation has been employed. By
using usual transformations, the obtained non-linear coupled partial
differential equations have been transformed into dimensionless governing
equations. These equations have been solved by applying the explicit finite
difference method. The MATLAB R2015a tool has been used for numerical
simulation. The stability and convergence criteria have been analyzed. The
effect of some important parameters on the primary velocity, secondary
velocity, temperature and concentration distributions as well as local shear
stress, Nusselt number and Sherwood number have been shown graphically.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13481</dc:identifier>
 <dc:identifier>8th BSME International Conference on Thermal Engineering, AIP
  Conf. Proc. (2019) 2121, 040004-1 - 040004-7</dc:identifier>
 <dc:identifier>doi:10.1063/1.5115875</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13483</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Meta-ViterbiNet: Online Meta-Learned Viterbi Equalization for
  Non-Stationary Channels</dc:title>
 <dc:creator>Raviv, Tomer</dc:creator>
 <dc:creator>Park, Sangwoo</dc:creator>
 <dc:creator>Shlezinger, Nir</dc:creator>
 <dc:creator>Simeone, Osvaldo</dc:creator>
 <dc:creator>Eldar, Yonina C.</dc:creator>
 <dc:creator>Kang, Joonhyuk</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  Deep neural networks (DNNs) based digital receivers can potentially operate
in complex environments. However, the dynamic nature of communication channels
implies that in some scenarios, DNN-based receivers should be periodically
retrained in order to track temporal variations in the channel conditions. To
this aim, frequent transmissions of lengthy pilot sequences are generally
required, at the cost of substantial overhead. In this work we propose a
DNN-aided symbol detector, Meta-ViterbiNet, that tracks channel variations with
reduced overhead by integrating three complementary techniques: 1) We leverage
domain knowledge to implement a model-based/data-driven equalizer, ViterbiNet,
that operates with a relatively small number of trainable parameters; 2) We
tailor a meta-learning procedure to the symbol detection problem, optimizing
the hyperparameters of the learning algorithm to facilitate rapid online
adaptation; and 3) We adopt a decision-directed approach based on coded
communications to enable online training with short-length pilot blocks.
Numerical results demonstrate that Meta-ViterbiNet operates accurately in
rapidly-varying channels, outperforming the previous best approach, based on
ViterbiNet or conventional recurrent neural networks without meta-learning, by
a margin of up to 0.6dB in bit error rate in various challenging scenarios.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13487</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entropy Minimizing Matrix Factorization</dc:title>
 <dc:creator>Chen, Mulin</dc:creator>
 <dc:creator>Li, Xuelong</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Nonnegative Matrix Factorization (NMF) is a widely-used data analysis
technique, and has yielded impressive results in many real-world tasks.
Generally, existing NMF methods represent each sample with several centroids,
and find the optimal centroids by minimizing the sum of the approximation
errors. However, the outliers deviating from the normal data distribution may
have large residues, and then dominate the objective value seriously. In this
study, an Entropy Minimizing Matrix Factorization framework (EMMF) is developed
to tackle the above problem. Considering that the outliers are usually much
less than the normal samples, a new entropy loss function is established for
matrix factorization, which minimizes the entropy of the residue distribution
and allows a few samples to have large approximation errors. In this way, the
outliers do not affect the approximation of the normal samples. The
multiplicative updating rules for EMMF are also designed, and the convergence
is proved both theoretically and experimentally. In addition, a Graph
regularized version of EMMF (G-EMMF) is also presented to deal with the complex
data structure. Clustering results on various synthetic and real-world datasets
demonstrate the reasonableness of the proposed models, and the effectiveness is
also verified through the comparison with the state-of-the-arts.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13487</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13491</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature Weighted Non-negative Matrix Factorization</dc:title>
 <dc:creator>Chen, Mulin</dc:creator>
 <dc:creator>Gong, Maoguo</dc:creator>
 <dc:creator>Li, Xuelong</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Non-negative Matrix Factorization (NMF) is one of the most popular techniques
for data representation and clustering, and has been widely used in machine
learning and data analysis. NMF concentrates the features of each sample into a
vector, and approximates it by the linear combination of basis vectors, such
that the low-dimensional representations are achieved. However, in real-world
applications, the features are usually with different importances. To exploit
the discriminative features, some methods project the samples into the subspace
with a transformation matrix, which disturbs the original feature attributes
and neglects the diversity of samples. To alleviate the above problems, we
propose the Feature weighted Non-negative Matrix Factorization (FNMF) in this
paper. The salient properties of FNMF can be summarized as threefold: 1) it
learns the weights of features adaptively according to their importances; 2) it
utilizes multiple feature weighting components to preserve the diversity; 3) it
can be solved efficiently with the suggested optimization algorithm.
Performance on synthetic and real-world datasets demonstrate that the proposed
method obtains the state-of-the-art performance.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13491</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13493</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Newton-like Algorithms and Learning for Optimized Power
  Dispatch</dc:title>
 <dc:creator>Anderson, Tor</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This thesis explores a particular class of distributed optimization methods
for various separable resource allocation problems, which are of high interest
in a wide array of multi-agent settings. A distinctly motivating application
for this thesis is real-time power dispatch of distributed energy resources for
providing frequency control in a distribution grid or microgrid with high
renewable energy penetration. In this application, it is paramount that agent
data be shared as sparsely as possible in the interest of conserving user
privacy, and it is required that algorithms scale gracefully as the network
size increases to the order of thousands or millions of resources and devices.
Distributed algorithms are naturally well-poised to address these challenges,
in contrast to more traditional centralized algorithms which scale poorly and
require global access to information.
  The class of distributed optimization methods explored here can be broadly
described as Newton-like or second-order, implying utilization of
second-derivative information of the cost functions, in contrast to
well-studied gradient-based or first-order methods. We consider three
formulations of separable resource-allocation problems and develop a
Newton-like algorithm for each. The analysis and simulation studies in the
subsequent chapters demonstrate the advantages of our approaches over existing
methods; most commonly, we note that convergence rates are substantially
improved. We supplement our algorithm development for these three problem
formulations with a network design technique, in which we can construct a
maximally-connected network by adding some edges to the underlying
communication graph, and a real demonstration of distributed algorithms on a
large set of heterogeneous devices on the UC San Diego microgrid.
</dc:description>
 <dc:description>Comment: PhD thesis</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13493</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13495</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Learning-based Automatic Graphene Detection with Color
  Correction for Optical Microscope Images</dc:title>
 <dc:creator>Siao, Hui-Ying</dc:creator>
 <dc:creator>Qi, Siyu</dc:creator>
 <dc:creator>Ding, Zhi</dc:creator>
 <dc:creator>Lin, Chia-Yu</dc:creator>
 <dc:creator>Hsieh, Yu-Chiang</dc:creator>
 <dc:creator>Chen, Tse-Ming</dc:creator>
 <dc:subject>Physics - Applied Physics</dc:subject>
 <dc:subject>Condensed Matter - Mesoscale and Nanoscale Physics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  Graphene serves critical application and research purposes in various fields.
However, fabricating high-quality and large quantities of graphene is
time-consuming and it requires heavy human resource labor costs. In this paper,
we propose a Machine Learning-based Automatic Graphene Detection Method with
Color Correction (MLA-GDCC), a reliable and autonomous graphene detection from
microscopic images. The MLA-GDCC includes a white balance (WB) to correct the
color imbalance on the images, a modified U-Net and a support vector machine
(SVM) to segment the graphene flakes. Considering the color shifts of the
images caused by different cameras, we apply WB correction to correct the
imbalance of the color pixels. A modified U-Net model, a convolutional neural
network (CNN) architecture for fast and precise image segmentation, is
introduced to segment the graphene flakes from the background. In order to
improve the pixel-level accuracy, we implement a SVM after the modified U-Net
model to separate the monolayer and bilayer graphene flakes. The MLA-GDCC
achieves flake-level detection rates of 87.09% for monolayer and 90.41% for
bilayer graphene, and the pixel-level accuracy of 99.27% for monolayer and
98.92% for bilayer graphene. MLA-GDCC not only achieves high detection rates of
the graphene flakes but also speeds up the latency for the graphene detection
process from hours to seconds.
</dc:description>
 <dc:description>Comment: 14 pages, 8 figures</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13495</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13497</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D Reasoning for Unsupervised Anomaly Detection in Pediatric WbMRI</dc:title>
 <dc:creator>Chang, Alex</dc:creator>
 <dc:creator>Suriyakumar, Vinith</dc:creator>
 <dc:creator>Moturu, Abhishek</dc:creator>
 <dc:creator>Tu, James</dc:creator>
 <dc:creator>Tewattanarat, Nipaporn</dc:creator>
 <dc:creator>Joshi, Sayali</dc:creator>
 <dc:creator>Doria, Andrea</dc:creator>
 <dc:creator>Goldenberg, Anna</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Modern deep unsupervised learning methods have shown great promise for
detecting diseases across a variety of medical imaging modalities. While
previous generative modeling approaches successfully perform anomaly detection
by learning the distribution of healthy 2D image slices, they process such
slices independently and ignore the fact that they are correlated, all being
sampled from a 3D volume. We show that incorporating the 3D context and
processing whole-body MRI volumes is beneficial to distinguishing anomalies
from their benign counterparts. In our work, we introduce a multi-channel
sliding window generative model to perform lesion detection in whole-body MRI
(wbMRI). Our experiments demonstrate that our proposed method significantly
outperforms processing individual images in isolation and our ablations clearly
show the importance of 3D reasoning. Moreover, our work also shows that it is
beneficial to include additional patient-specific features to further improve
anomaly detection in pediatric scans.
</dc:description>
 <dc:description>Comment: 10 pages, 2 tables, 3 figures, in submission</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13497</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13501</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The combinatorial game nofil played on Steiner Triple Systems</dc:title>
 <dc:creator>Huggan, Melissa A.</dc:creator>
 <dc:creator>Huntemann, Svenja</dc:creator>
 <dc:creator>Stevens, Brett</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>91A46, 05B07</dc:subject>
 <dc:subject>F.2</dc:subject>
 <dc:subject>G.2</dc:subject>
 <dc:description>  We introduce an impartial combinatorial game on Steiner triple systems called
Nofil. Players move alternately, choosing points of the triple system. If a
player is forced to fill a block on their turn, they lose. We explore the play
of Nofil on all Steiner triple systems up to order 15 and a sampling for orders
19, 21, and 25. We determine the optimal strategies by computing the nim-values
for each game and its subgames. The game Nofil can be thought of in terms of
play on a corresponding hypergraph. As game play progresses, the hypergraph
shrinks and will eventually be equivalent to playing the game Node Kayles on an
isomorphic graph. Node Kayles is well studied and understood. Motivated by
this, we study which Node Kayles positions can be reached, i.e. embedded into a
Steiner triple system. We prove necessary conditions and sufficient conditions
for the existence of such graph embeddings and conclude that the complexity of
determining the outcome of the game Nofil on Steiner triple systems is
PSPACE-complete.
</dc:description>
 <dc:description>Comment: 34 pages, 6 figures, 6 tables</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13505</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ripple-Type Control for Enhancing Resilience of Networked Physical
  Systems</dc:title>
 <dc:creator>Singh, Manish K.</dc:creator>
 <dc:creator>Cavraro, Guido</dc:creator>
 <dc:creator>Bernstein, Andrey</dc:creator>
 <dc:creator>Kekatos, Vassilis</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Distributed control agents have been advocated as an effective means for
improving the resiliency of our physical infrastructures under unexpected
events. Purely local control has been shown to be insufficient, centralized
optimal resource allocation approaches can be slow. In this context, we put
forth a hybrid low-communication saturation-driven protocol for the
coordination of control agents that are distributed over a physical system and
are allowed to communicate with peers over a &quot;hotline&quot; communication network.
According to this protocol, agents act on local readings unless their control
resources have been depleted, in which case they send a beacon for assistance
to peer agents. Our ripple-type scheme triggers communication locally only for
the agents with saturated resources and it is proved to converge. Moreover,
under a monotonicity assumption on the underlying physical law coupling control
outputs to inputs, the devised control is proved to converge to a configuration
satisfying safe operational constraints. The assumption is shown to hold for
voltage control in electric power systems and pressure control in water
distribution networks. Numerical tests corroborate the efficacy of the novel
scheme.
</dc:description>
 <dc:description>Comment: Accepted for presentation at the American Control Conference (ACC)
  2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13505</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13511</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Addressing catastrophic forgetting for medical domain expansion</dc:title>
 <dc:creator>Gupta, Sharut</dc:creator>
 <dc:creator>Singh, Praveer</dc:creator>
 <dc:creator>Chang, Ken</dc:creator>
 <dc:creator>Qu, Liangqiong</dc:creator>
 <dc:creator>Aggarwal, Mehak</dc:creator>
 <dc:creator>Arun, Nishanth</dc:creator>
 <dc:creator>Vaswani, Ashwin</dc:creator>
 <dc:creator>Raghavan, Shruti</dc:creator>
 <dc:creator>Agarwal, Vibha</dc:creator>
 <dc:creator>Gidwani, Mishka</dc:creator>
 <dc:creator>Hoebel, Katharina</dc:creator>
 <dc:creator>Patel, Jay</dc:creator>
 <dc:creator>Lu, Charles</dc:creator>
 <dc:creator>Bridge, Christopher P.</dc:creator>
 <dc:creator>Rubin, Daniel L.</dc:creator>
 <dc:creator>Kalpathy-Cramer, Jayashree</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Model brittleness is a key concern when deploying deep learning models in
real-world medical settings. A model that has high performance at one
institution may suffer a significant decline in performance when tested at
other institutions. While pooling datasets from multiple institutions and
retraining may provide a straightforward solution, it is often infeasible and
may compromise patient privacy. An alternative approach is to fine-tune the
model on subsequent institutions after training on the original institution.
Notably, this approach degrades model performance at the original institution,
a phenomenon known as catastrophic forgetting. In this paper, we develop an
approach to address catastrophic forget-ting based on elastic weight
consolidation combined with modulation of batch normalization statistics under
two scenarios: first, for expanding the domain from one imaging system's data
to another imaging system's, and second, for expanding the domain from a large
multi-institutional dataset to another single institution dataset. We show that
our approach outperforms several other state-of-the-art approaches and provide
theoretical justification for the efficacy of batch normalization modulation.
The results of this study are generally applicable to the deployment of any
clinical deep learning model which requires domain expansion.
</dc:description>
 <dc:description>Comment: First three authors contributed equally</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13511</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13516</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracking Pedestrian Heads in Dense Crowd</dc:title>
 <dc:creator>Sundararaman, Ramana</dc:creator>
 <dc:creator>Braga, Cedric De Almeida</dc:creator>
 <dc:creator>Marchand, Eric</dc:creator>
 <dc:creator>Pettre, Julien</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Tracking humans in crowded video sequences is an important constituent of
visual scene understanding. Increasing crowd density challenges visibility of
humans, limiting the scalability of existing pedestrian trackers to higher
crowd densities. For that reason, we propose to revitalize head tracking with
Crowd of Heads Dataset (CroHD), consisting of 9 sequences of 11,463 frames with
over 2,276,838 heads and 5,230 tracks annotated in diverse scenes. For
evaluation, we proposed a new metric, IDEucl, to measure an algorithm's
efficacy in preserving a unique identity for the longest stretch in image
coordinate space, thus building a correspondence between pedestrian crowd
motion and the performance of a tracking algorithm. Moreover, we also propose a
new head detector, HeadHunter, which is designed for small head detection in
crowded scenes. We extend HeadHunter with a Particle Filter and a color
histogram based re-identification module for head tracking. To establish this
as a strong baseline, we compare our tracker with existing state-of-the-art
pedestrian trackers on CroHD and demonstrate superiority, especially in
identity preserving tracking metrics. With a light-weight head detector and a
tracker which is efficient at identity preservation, we believe our
contributions will serve useful in advancement of pedestrian tracking in dense
crowds.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13516</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13523</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Truncated Orthogonal Iteration for Sparse Eigenvector
  Problems</dc:title>
 <dc:creator>Liu, Hexuan</dc:creator>
 <dc:creator>Aravkin, Aleksandr</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  A wide range of problems in computational science and engineering require
estimation of sparse eigenvectors for high dimensional systems. Here, we
propose two variants of the Truncated Orthogonal Iteration to compute multiple
leading eigenvectors with sparsity constraints simultaneously. We establish
numerical convergence results for the proposed algorithms using a perturbation
framework, and extend our analysis to other existing alternatives for sparse
eigenvector estimation. We then apply our algorithms to solve the sparse
principle component analysis problem for a wide range of test datasets, from
simple simulations to real-world datasets including MNIST, sea surface
temperature and 20 newsgroups. In all these cases, we show that the new methods
get state of the art results quickly and with minimal parameter tuning.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13523</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13526</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ontology-Based Recommendation of Editorial Products</dc:title>
 <dc:creator>Thanapalasingam, Thiviyan</dc:creator>
 <dc:creator>Osborne, Francesco</dc:creator>
 <dc:creator>Birukou, Aliaksandr</dc:creator>
 <dc:creator>Motta, Enrico</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Major academic publishers need to be able to analyse their vast catalogue of
products and select the best items to be marketed in scientific venues. This is
a complex exercise that requires characterising with a high precision the
topics of thousands of books and matching them with the interests of the
relevant communities. In Springer Nature, this task has been traditionally
handled manually by publishing editors. However, the rapid growth in the number
of scientific publications and the dynamic nature of the Computer Science
landscape has made this solution increasingly inefficient. We have addressed
this issue by creating Smart Book Recommender (SBR), an ontology-based
recommender system developed by The Open University (OU) in collaboration with
Springer Nature, which supports their Computer Science editorial team in
selecting the products to market at specific venues. SBR recommends books,
journals, and conference proceedings relevant to a conference by taking
advantage of a semantically enhanced representation of about 27K editorial
products. This is based on the Computer Science Ontology, a very large-scale,
automatically generated taxonomy of research areas. SBR also allows users to
investigate why a certain publication was suggested by the system. It does so
by means of an interactive graph view that displays the topic taxonomy of the
recommended editorial product and compares it with the topic-centric
characterization of the input conference. An evaluation carried out with seven
Springer Nature editors and seven OU researchers has confirmed the
effectiveness of the solution.
</dc:description>
 <dc:description>Comment: In: The Semantic Web - ISWC 2018. Lecture Notes in Computer Science,
  vol 11137. Springer, Cham</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13526</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-030-00668-6_21</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13527</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Editorial Workflow and Metadata Quality at Springer Nature</dc:title>
 <dc:creator>Salatino, Angelo A.</dc:creator>
 <dc:creator>Osborne, Francesco</dc:creator>
 <dc:creator>Birukou, Aliaksandr</dc:creator>
 <dc:creator>Motta, Enrico</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Identifying the research topics that best describe the scope of a scientific
publication is a crucial task for editors, in particular because the quality of
these annotations determine how effectively users are able to discover the
right content in online libraries. For this reason, Springer Nature, the
world's largest academic book publisher, has traditionally entrusted this task
to their most expert editors. These editors manually analyse all new books,
possibly including hundreds of chapters, and produce a list of the most
relevant topics. Hence, this process has traditionally been very expensive,
time-consuming, and confined to a few senior editors. For these reasons, back
in 2016 we developed Smart Topic Miner (STM), an ontology-driven application
that assists the Springer Nature editorial team in annotating the volumes of
all books covering conference proceedings in Computer Science. Since then STM
has been regularly used by editors in Germany, China, Brazil, India, and Japan,
for a total of about 800 volumes per year. Over the past three years the
initial prototype has iteratively evolved in response to feedback from the
users and evolving requirements. In this paper we present the most recent
version of the tool and describe the evolution of the system over the years,
the key lessons learnt, and the impact on the Springer Nature workflow. In
particular, our solution has drastically reduced the time needed to annotate
proceedings and significantly improved their discoverability, resulting in 9.3
million additional downloads. We also present a user study involving 9 editors,
which yielded excellent results in term of usability, and report an evaluation
of the new topic classifier used by STM, which outperforms previous versions in
recall and F-measure.
</dc:description>
 <dc:description>Comment: In: The Semantic Web - ISWC 2019. Lecture Notes in Computer Science,
  vol 11779. Springer, Cham</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13527</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-030-30796-7_31</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13532</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Error Identification and Recovery in Robotic Snap Assembly</dc:title>
 <dc:creator>Hayami, Yusuke</dc:creator>
 <dc:creator>Wan, Weiwei</dc:creator>
 <dc:creator>Koyama, Keisuke</dc:creator>
 <dc:creator>Shi, Peihao</dc:creator>
 <dc:creator>Rojas, Juan</dc:creator>
 <dc:creator>Harada, Kensuke</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Existing methods for predicting robotic snap joint assembly cannot predict
failures before their occurrence. To address this limitation, this paper
proposes a method for predicting error states before the occurence of error,
thereby enabling timely recovery. Robotic snap joint assembly requires precise
positioning; therefore, even a slight offset between parts can lead to assembly
failure. To correctly predict error states, we apply functional principal
component analysis (fPCA) to 6D force/torque profiles that are terminated
before the occurence of an error. The error state is identified by applying a
feature vector to a decision tree, wherein the support vector machine (SVM) is
employed at each node. If the estimation accuracy is low, we perform additional
probing to more correctly identify the error state. Finally, after identifying
the error state, a robot performs the error recovery motion based on the
identified error state. Through the experimental results of assembling plastic
parts with four snap joints, we show that the error states can be correctly
estimated and a robot can recover from the identified error state.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13532</dc:identifier>
 <dc:identifier>IEEE Int. Symposium on System Integration, 2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13533</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Symmetry-Preserving Paths in Integrated Gradients</dc:title>
 <dc:creator>Lerma, Miguel</dc:creator>
 <dc:creator>Lucas, Mirtha</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>68T07</dc:subject>
 <dc:subject>I.2.m</dc:subject>
 <dc:description>  We provide rigorous proofs that the Integrated Gradients (IG) attribution
method for deep networks satisfies completeness and symmetry-preserving
properties. We also study the uniqueness of IG as a path method preserving
symmetry.
</dc:description>
 <dc:description>Comment: 7 pages, 1 figure</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13533</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13534</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A formal proof of the Lax equivalence theorem for finite difference
  schemes</dc:title>
 <dc:creator>Tekriwal, Mohit</dc:creator>
 <dc:creator>Duraisamy, Karthik</dc:creator>
 <dc:creator>Jeannin, Jean-Baptiste</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  The behavior of physical systems is typically modeled using differential
equations which are too complex to solve analytically. In practical problems,
these equations are discretized on a computational domain, and numerical
solutions are computed. A numerical scheme is called convergent, if in the
limit of infinitesimal discretization, the bounds on the discretization error
is also infinitesimally small. The approximate solution converges to the &quot;true
solution&quot; in this limit. The Lax equivalence theorem enables a proof of
convergence given consistency and stability of the method. In this work, we
formally prove the Lax equivalence theorem using the Coq Proof Assistant. We
assume a continuous linear differential operator between complete normed
spaces, and define an equivalent mapping in the discretized space. Given that
the numerical method is consistent (i.e., the discretization error tends to
zero as the discretization step tends to zero), and the method is stable (i.e.,
the error is uniformly bounded), we formally prove that the approximate
solution converges to the true solution. We then demonstrate convergence of the
difference scheme on an example problem by proving both its consistency and
stability, and then applying the Lax equivalence theorem. In order to prove
consistency, we use the Taylor-Lagrange theorem by formally showing that the
discretization error is bounded above by the nth power of the discretization
step, where n is the order of the truncated Taylor polynomial.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13534</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13546</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Benchmarking Modern Named Entity Recognition Techniques for Free-text
  Health Record De-identification</dc:title>
 <dc:creator>Ahmed, Abdullah</dc:creator>
 <dc:creator>Abbasi, Adeel</dc:creator>
 <dc:creator>Eickhoff, Carsten</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Electronic Health Records (EHRs) have become the primary form of medical
data-keeping across the United States. Federal law restricts the sharing of any
EHR data that contains protected health information (PHI). De-identification,
the process of identifying and removing all PHI, is crucial for making EHR data
publicly available for scientific research. This project explores several deep
learning-based named entity recognition (NER) methods to determine which
method(s) perform better on the de-identification task. We trained and tested
our models on the i2b2 training dataset, and qualitatively assessed their
performance using EHR data collected from a local hospital. We found that 1)
BiLSTM-CRF represents the best-performing encoder/decoder combination, 2)
character-embeddings and CRFs tend to improve precision at the price of recall,
and 3) transformers alone under-perform as context encoders. Future work
focused on structuring medical text may improve the extraction of semantic and
syntactic information for the purposes of EHR de-identification.
</dc:description>
 <dc:description>Comment: Presented at AMIA Informatics Summit 2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13546</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13548</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Better Approach to Track the Evolution of Static Code Warnings</dc:title>
 <dc:creator>Li, Junjie</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Static bug detection tools help developers detect code problems. However, it
is known that they remain underutilized due to various reasons. Recent advances
to incorporate static bug detectors in modern software development workflows
can better motivate developers to fix the reported warnings on the fly.
  In this paper, we study the effectiveness of the state-of-the-art (SOA)
solution in tracking warnings by static bug detectors and propose a better
solution based on our analysis of the insufficiencies of the SOA solution. In
particular, we examined four large-scale open-source systems and crafted a data
set of 3,452 static code warnings by two static bug detectors. We manually
uncover the ground-truth evolution status of the selected warnings: persistent,
resolved, or newly-introduced. Moreover, upon manual analysis, we identified
the critical reasons behind the insufficiencies of the SOA matching algorithm.
Finally, we propose a better approach to improve the tracking of static
warnings over software development history. Our evaluation shows that our
proposed approach provides a significant improvement in the precision of the
tracking, i.e., from 66.9% to 90.0%.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13555</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prediction in the presence of response-dependent missing labels</dc:title>
 <dc:creator>Song, Hyebin</dc:creator>
 <dc:creator>Raskutti, Garvesh</dc:creator>
 <dc:creator>Willett, Rebecca</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In a variety of settings, limitations of sensing technologies or other
sampling mechanisms result in missing labels, where the likelihood of a missing
label in the training set is an unknown function of the data. For example,
satellites used to detect forest fires cannot sense fires below a certain size
threshold. In such cases, training datasets consist of positive and
pseudo-negative observations where pseudo-negative observations can be either
true negatives or undetected positives with small magnitudes. We develop a new
methodology and non-convex algorithm P(ositive) U(nlabeled) - O(ccurrence)
M(agnitude) M(ixture) which jointly estimates the occurrence and detection
likelihood of positive samples, utilizing prior knowledge of the detection
mechanism. Our approach uses ideas from positive-unlabeled (PU)-learning and
zero-inflated models that jointly estimate the magnitude and occurrence of
events. We provide conditions under which our model is identifiable and prove
that even though our approach leads to a non-convex objective, any local
minimizer has optimal statistical error (up to a log term) and projected
gradient descent has geometric convergence rates. We demonstrate on both
synthetic data and a California wildfire dataset that our method out-performs
existing state-of-the-art approaches.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13555</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13558</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Feature Transformations for Discriminative and Generative
  Continual Learning</dc:title>
 <dc:creator>Verma, Vinay Kumar</dc:creator>
 <dc:creator>Liang, Kevin J</dc:creator>
 <dc:creator>Mehta, Nikhil</dc:creator>
 <dc:creator>Rai, Piyush</dc:creator>
 <dc:creator>Carin, Lawrence</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  As neural networks are increasingly being applied to real-world applications,
mechanisms to address distributional shift and sequential task learning without
forgetting are critical. Methods incorporating network expansion have shown
promise by naturally adding model capacity for learning new tasks while
simultaneously avoiding catastrophic forgetting. However, the growth in the
number of additional parameters of many of these types of methods can be
computationally expensive at larger scales, at times prohibitively so. Instead,
we propose a simple task-specific feature map transformation strategy for
continual learning, which we call Efficient Feature Transformations (EFTs).
These EFTs provide powerful flexibility for learning new tasks, achieved with
minimal parameters added to the base architecture. We further propose a feature
distance maximization strategy, which significantly improves task prediction in
class incremental settings, without needing expensive generative models. We
demonstrate the efficacy and efficiency of our method with an extensive set of
experiments in discriminative (CIFAR-100 and ImageNet-1K) and generative (LSUN,
CUB-200, Cats) sequences of tasks. Even with low single-digit parameter growth
rates, EFTs can outperform many other continual learning methods in a wide
range of settings.
</dc:description>
 <dc:description>Comment: Accepted in CVPR 2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13559</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rethinking Self-Supervised Learning: Small is Beautiful</dc:title>
 <dc:creator>Cao, Yun-Hao</dc:creator>
 <dc:creator>Wu, Jianxin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Self-supervised learning (SSL), in particular contrastive learning, has made
great progress in recent years. However, a common theme in these methods is
that they inherit the learning paradigm from the supervised deep learning
scenario. Current SSL methods are often pretrained for many epochs on
large-scale datasets using high resolution images, which brings heavy
computational cost and lacks flexibility. In this paper, we demonstrate that
the learning paradigm for SSL should be different from supervised learning and
the information encoded by the contrastive loss is expected to be much less
than that encoded in the labels in supervised learning via the cross entropy
loss. Hence, we propose scaled-down self-supervised learning (S3L), which
include 3 parts: small resolution, small architecture and small data. On a
diverse set of datasets, SSL methods and backbone architectures, S3L achieves
higher accuracy consistently with much less training cost when compared to
previous SSL learning paradigm. Furthermore, we show that even without a large
pretraining dataset, S3L can achieve impressive results on small data alone.
Our code has been made publically available at
https://github.com/CupidJay/Scaled-down-self-supervised-learning.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13561</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Evolving Attention Towards Domain Adaptation</dc:title>
 <dc:creator>Sheng, Kekai</dc:creator>
 <dc:creator>Li, Ke</dc:creator>
 <dc:creator>Zheng, Xiawu</dc:creator>
 <dc:creator>Liang, Jian</dc:creator>
 <dc:creator>Dong, Weiming</dc:creator>
 <dc:creator>Huang, Feiyue</dc:creator>
 <dc:creator>Ji, Rongrong</dc:creator>
 <dc:creator>Sun, Xing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Towards better unsupervised domain adaptation (UDA). Recently, researchers
propose various domain-conditioned attention modules and make promising
progresses. However, considering that the configuration of attention, i.e., the
type and the position of attention module, affects the performance
significantly, it is more generalized to optimize the attention configuration
automatically to be specialized for arbitrary UDA scenario. For the first time,
this paper proposes EvoADA: a novel framework to evolve the attention
configuration for a given UDA task without human intervention. In particular,
we propose a novel search space containing diverse attention configurations.
Then, to evaluate the attention configurations and make search procedure
UDA-oriented (transferability + discrimination), we apply a simple and
effective evaluation strategy: 1) training the network weights on two domains
with off-the-shelf domain adaptation methods; 2) evolving the attention
configurations under the guide of the discriminative ability on the target
domain. Experiments on various kinds of cross-domain benchmarks, i.e.,
Office-31, Office-Home, CUB-Paintings, and Duke-Market-1510, reveal that the
proposed EvoADA consistently boosts multiple state-of-the-art domain adaptation
approaches, and the optimal attention configurations help them achieve better
performance.
</dc:description>
 <dc:description>Comment: Among the first to study arbitrary domain adaptation from the
  perspective of network architecture design</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13561</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13569</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximating Instance-Dependent Noise via Instance-Confidence Embedding</dc:title>
 <dc:creator>Zhang, Yivan</dc:creator>
 <dc:creator>Sugiyama, Masashi</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Label noise in multiclass classification is a major obstacle to the
deployment of learning systems. However, unlike the widely used
class-conditional noise (CCN) assumption that the noisy label is independent of
the input feature given the true label, label noise in real-world datasets can
be aleatory and heavily dependent on individual instances. In this work, we
investigate the instance-dependent noise (IDN) model and propose an efficient
approximation of IDN to capture the instance-specific label corruption.
Concretely, noting the fact that most columns of the IDN transition matrix have
only limited influence on the class-posterior estimation, we propose a
variational approximation that uses a single-scalar confidence parameter. To
cope with the situation where the mapping from the instance to its confidence
value could vary significantly for two adjacent instances, we suggest using
instance embedding that assigns a trainable parameter to each instance. The
resulting instance-confidence embedding (ICE) method not only performs well
under label noise but also can effectively detect ambiguous or mislabeled
instances. We validate its utility on various image and text classification
tasks.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13569</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13570</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantifying the efficacy of childcare services on women employment</dc:title>
 <dc:creator>Liao, Jing-Yi</dc:creator>
 <dc:creator>Kong, Ying</dc:creator>
 <dc:creator>Zhou, Tao</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Women are set back in the labor market after becoming mother. Intuitively,
childcare services are able to promote women employment as they may
reconciliate the motherhood penalty. However, most known studies concentrated
on the effects of childcare services on fertility rate, instead of quantitative
analyses about the effects on women employment. Using worldwide panel data and
Chinese data at province level, this paper unfolds the quantitative
relationship between childcare services and women employment, that is, the
attendance rate of childcare services is positively correlated with the
relative employment rate of women to men. Further analysis suggests that such a
positive impact may largely resulted from breaking the vulnerable employment
dilemma.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13570</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13573</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computationally-Efficient Roadmap-based Inspection Planning via
  Incremental Lazy Search</dc:title>
 <dc:creator>Fu, Mengyu</dc:creator>
 <dc:creator>Salzman, Oren</dc:creator>
 <dc:creator>Alterovitz, Ron</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The inspection-planning problem calls for computing motions for a robot that
allow it to inspect a set of points of interest (POIs) while considering plan
quality (e.g., plan length). This problem has applications across many domains
where robots can help with inspection, including infrastructure maintenance,
construction, and surgery. Incremental Random Inspection-roadmap Search (IRIS)
is an asymptotically-optimal inspection planner that was shown to compute
higher-quality inspection plans orders of magnitudes faster than the prior
state-of-the-art method. In this paper, we significantly accelerate the
performance of IRIS to broaden its applicability to more challenging real-world
applications. A key computational challenge that IRIS faces is effectively
searching roadmaps for inspection plans -- a procedure that dominates its
running time. In this work, we show how to incorporate lazy edge-evaluation
techniques into \iris's search algorithm and how to reuse search efforts when a
roadmap undergoes local changes. These enhancements, which do not compromise
IRIS's asymptotic optimality, enable us to compute inspection plans much faster
than the original IRIS. We apply IRIS with the enhancements to simulated bridge
inspection and surgical inspection tasks and show that our new algorithm for
some scenarios can compute similar-quality inspection plans 570x faster than
prior work.
</dc:description>
 <dc:description>Comment: to be published in ICRA 2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13573</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13575</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MetaAlign: Coordinating Domain Alignment and Classification for
  Unsupervised Domain Adaptation</dc:title>
 <dc:creator>Wei, Guoqiang</dc:creator>
 <dc:creator>Lan, Cuiling</dc:creator>
 <dc:creator>Zeng, Wenjun</dc:creator>
 <dc:creator>Chen, Zhibo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  For unsupervised domain adaptation (UDA), to alleviate the effect of domain
shift, many approaches align the source and target domains in the feature space
by adversarial learning or by explicitly aligning their statistics. However,
the optimization objective of such domain alignment is generally not
coordinated with that of the object classification task itself such that their
descent directions for optimization may be inconsistent. This will reduce the
effectiveness of domain alignment in improving the performance of UDA. In this
paper, we aim to study and alleviate the optimization inconsistency problem
between the domain alignment and classification tasks. We address this by
proposing an effective meta-optimization based strategy dubbed MetaAlign, where
we treat the domain alignment objective and the classification objective as the
meta-train and meta-test tasks in a meta-learning scheme. MetaAlign encourages
both tasks to be optimized in a coordinated way, which maximizes the inner
product of the gradients of the two tasks during training. Experimental results
demonstrate the effectiveness of our proposed method on top of various
alignment-based baseline approaches, for tasks of object classification and
object detection. MetaAlign helps achieve the state-of-the-art performance.
</dc:description>
 <dc:description>Comment: Accepted by CVPR2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13575</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13577</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ButterFly BFS -- An Efficient Communication Pattern for Multi Node
  Traversals</dc:title>
 <dc:creator>Green, Oded</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Breadth-First Search (BFS) is a building block used in a wide array of graph
analytics and is used in various network analysis domains: social, road,
transportation, communication, and much more. Over the last two decades,
network sizes have continued to grow. The popularity of BFS has brought with it
a need for significantly faster traversals. Thus, BFS algorithms have been
designed to exploit shared-memory and shared-nothing systems -- this includes
algorithms for accelerators such as the GPU. GPUs offer extremely fast
traversals at the cost of processing smaller graphs due to their limited memory
size. In contrast, CPU shared-memory systems can scale to graphs with several
billion edges but do not have enough compute resources needed for fast
traversals. This paper introduces ButterFly BFS, a multi-GPU traversal
algorithm that allows analyzing significantly larger networks at high rates.
ButterFly BFS scales to the similar-sized graphs processed by shared-memory
systems while improving performance by more than 10X compared to CPUs. We
evaluate our new algorithm on an NVIDIA DGX-2 server with 16 V100 GPUS and show
that our algorithm scales with an increase in the number of GPUS. We show that
we can achieve a roughly $70\%$ performance linear speedup, which is
non-trivial for BFS. For a scale 29 Kronecker graph and edge factor of 8, our
new algorithm traverses the graph at a rate of over 300 GTEP/s. That is a high
traversal rate for a single server.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13577</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13578</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Test-Time Training for Deformable Multi-Scale Image Registration</dc:title>
 <dc:creator>Zhu, Wentao</dc:creator>
 <dc:creator>Huang, Yufang</dc:creator>
 <dc:creator>Xu, Daguang</dc:creator>
 <dc:creator>Qian, Zhen</dc:creator>
 <dc:creator>Fan, Wei</dc:creator>
 <dc:creator>Xie, Xiaohui</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Registration is a fundamental task in medical robotics and is often a crucial
step for many downstream tasks such as motion analysis, intra-operative
tracking and image segmentation. Popular registration methods such as ANTs and
NiftyReg optimize objective functions for each pair of images from scratch,
which are time-consuming for 3D and sequential images with complex
deformations. Recently, deep learning-based registration approaches such as
VoxelMorph have been emerging and achieve competitive performance. In this
work, we construct a test-time training for deep deformable image registration
to improve the generalization ability of conventional learning-based
registration model. We design multi-scale deep networks to consecutively model
the residual deformations, which is effective for high variational
deformations. Extensive experiments validate the effectiveness of multi-scale
deep registration with test-time training based on Dice coefficient for image
segmentation and mean square error (MSE), normalized local cross-correlation
(NLCC) for tissue dense tracking tasks. Two videos are in
https://www.youtube.com/watch?v=NvLrCaqCiAE and
https://www.youtube.com/watch?v=pEA6ZmtTNuQ
</dc:description>
 <dc:description>Comment: ICRA 2021; 8 pages, 4 figures, 2 big tables</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13578</dc:identifier>
 <dc:identifier>ICRA 2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13579</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Convexity of Discrete Time Covariance Steering in Stochastic
  Linear Systems with Wasserstein Terminal Cost</dc:title>
 <dc:creator>Balci, Isin M.</dc:creator>
 <dc:creator>Halder, Abhishek</dc:creator>
 <dc:creator>Bakolas, Efstathios</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:description>  In this work, we analyze the properties of the solution to the covariance
steering problem for discrete time Gaussian linear systems with a squared
Wasserstein distance terminal cost. In our previous work, we have shown that by
utilizing the state feedback control policy parametrization, this stochastic
optimal control problem can be associated with a difference of convex functions
program. Here, we revisit the same covariance control problem but this time we
focus on the analysis of the problem. Specifically, we establish the existence
of solutions to the optimization problem and derive the first and second order
conditions for optimality. We provide analytic expressions for the gradient and
the Hessian of the performance index by utilizing specialized tools from matrix
calculus. Subsequently, we prove that the optimization problem always admits a
global minimizer, and finally, we provide a sufficient condition for the
performance index to be a strictly convex function (under the latter condition,
the problem admits a unique global minimizer). In particular, we show that when
the terminal state covariance is upper bounded, with respect to the L\&quot;{o}wner
partial order, by the covariance matrix of the desired terminal normal
distribution, then our problem admits a unique global minimizing state feedback
gain. The results of this paper set the stage for the development of
specialized control design tools that exploit the structure of the solution to
the covariance steering problem with a squared Wasserstein distance terminal
cost.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13579</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13582</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Dynamic Alignment via Meta-filter for Few-shot Learning</dc:title>
 <dc:creator>Xu, Chengming</dc:creator>
 <dc:creator>Liu, Chen</dc:creator>
 <dc:creator>Zhang, Li</dc:creator>
 <dc:creator>Wang, Chengjie</dc:creator>
 <dc:creator>Li, Jilin</dc:creator>
 <dc:creator>Huang, Feiyue</dc:creator>
 <dc:creator>Xue, Xiangyang</dc:creator>
 <dc:creator>Fu, Yanwei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Few-shot learning (FSL), which aims to recognise new classes by adapting the
learned knowledge with extremely limited few-shot (support) examples, remains
an important open problem in computer vision. Most of the existing methods for
feature alignment in few-shot learning only consider image-level or
spatial-level alignment while omitting the channel disparity. Our insight is
that these methods would lead to poor adaptation with redundant matching, and
leveraging channel-wise adjustment is the key to well adapting the learned
knowledge to new classes. Therefore, in this paper, we propose to learn a
dynamic alignment, which can effectively highlight both query regions and
channels according to different local support information. Specifically, this
is achieved by first dynamically sampling the neighbourhood of the feature
position conditioned on the input few shot, based on which we further predict a
both position-dependent and channel-dependent Dynamic Meta-filter. The filter
is used to align the query feature with position-specific and channel-specific
knowledge. Moreover, we adopt Neural Ordinary Differential Equation (ODE) to
enable a more accurate control of the alignment. In such a sense our model is
able to better capture fine-grained semantic context of the few-shot example
and thus facilitates dynamical knowledge adaptation for few-shot learning. The
resulting framework establishes the new state-of-the-arts on major few-shot
visual recognition benchmarks, including miniImageNet and tieredImageNet.
</dc:description>
 <dc:description>Comment: accepted by CVPR2021</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13582</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13588</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Artificial Intelligence in Tumor Subregion Analysis Based on Medical
  Imaging: A Review</dc:title>
 <dc:creator>Lin, Mingquan</dc:creator>
 <dc:creator>Wynne, Jacob</dc:creator>
 <dc:creator>Lei, Yang</dc:creator>
 <dc:creator>Wang, Tonghe</dc:creator>
 <dc:creator>Curran, Walter J.</dc:creator>
 <dc:creator>Liu, Tian</dc:creator>
 <dc:creator>Yang, Xiaofeng</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:description>  Medical imaging is widely used in cancer diagnosis and treatment, and
artificial intelligence (AI) has achieved tremendous success in various tasks
of medical image analysis. This paper reviews AI-based tumor subregion analysis
in medical imaging. We summarize the latest AI-based methods for tumor
subregion analysis and their applications. Specifically, we categorize the
AI-based methods by training strategy: supervised and unsupervised. A detailed
review of each category is presented, highlighting important contributions and
achievements. Specific challenges and potential AI applications in tumor
subregion analysis are discussed.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13588</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13590</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Engineering an Intelligent Essay Scoring and Feedback System: An
  Experience Report</dc:title>
 <dc:creator>Chadda, Akriti</dc:creator>
 <dc:creator>Song, Kelly</dc:creator>
 <dc:creator>Chandrasekar, Raman</dc:creator>
 <dc:creator>Gorton, Ian</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Artificial Intelligence (AI) / Machine Learning (ML)-based systems are widely
sought-after commercial solutions that can automate and augment core business
services. Intelligent systems can improve the quality of services offered and
support scalability through automation. In this paper we describe our
experience in engineering an exploratory system for assessing the quality of
essays supplied by customers of a specialized recruitment support service. The
problem domain is challenging because the open-ended customer-supplied source
text has considerable scope for ambiguity and error, making models for analysis
hard to build. There is also a need to incorporate specialized business domain
knowledge into the intelligent processing systems. To address these challenges,
we experimented with and exploited a number of cloud-based machine learning
models and composed them into an application-specific processing pipeline. This
design allows for modification of the underlying algorithms as more data and
improved techniques become available. We describe our design, and the main
challenges we faced, namely keeping a check on the quality control of the
models, testing the software and deploying the computationally expensive ML
models on the cloud.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13590</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13597</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mask Attention Networks: Rethinking and Strengthen Transformer</dc:title>
 <dc:creator>Fan, Zhihao</dc:creator>
 <dc:creator>Gong, Yeyun</dc:creator>
 <dc:creator>Liu, Dayiheng</dc:creator>
 <dc:creator>Wei, Zhongyu</dc:creator>
 <dc:creator>Wang, Siyuan</dc:creator>
 <dc:creator>Jiao, Jian</dc:creator>
 <dc:creator>Duan, Nan</dc:creator>
 <dc:creator>Zhang, Ruofei</dc:creator>
 <dc:creator>Huang, Xuanjing</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Transformer is an attention-based neural network, which consists of two
sublayers, namely, Self-Attention Network (SAN) and Feed-Forward Network (FFN).
Existing research explores to enhance the two sublayers separately to improve
the capability of Transformer for text representation. In this paper, we
present a novel understanding of SAN and FFN as Mask Attention Networks (MANs)
and show that they are two special cases of MANs with static mask matrices.
However, their static mask matrices limit the capability for localness modeling
in text representation learning. We therefore introduce a new layer named
dynamic mask attention network (DMAN) with a learnable mask matrix which is
able to model localness adaptively. To incorporate advantages of DMAN, SAN, and
FFN, we propose a sequential layered structure to combine the three types of
layers. Extensive experiments on various tasks, including neural machine
translation and text summarization demonstrate that our model outperforms the
original Transformer.
</dc:description>
 <dc:description>Comment: Accepted as a long paper to NAACL 2021</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13597</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13606</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Directionality in Causal Relations in Text</dc:title>
 <dc:creator>Hosseini, Pedram</dc:creator>
 <dc:creator>Broniatowski, David A.</dc:creator>
 <dc:creator>Diab, Mona</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this work, we test the performance of two bidirectional transformer-based
language models, BERT and SpanBERT, on predicting directionality in causal
pairs in the textual content. Our preliminary results show that predicting
direction for inter-sentence and implicit causal relations is more challenging.
And, SpanBERT performs better than BERT on causal samples with longer span
length. We also introduce CREST which is a framework for unifying a collection
of scattered datasets of causal relations.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13607</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Class Similarity for Machine Learning with Confidence Labels
  and Projective Loss Functions</dc:title>
 <dc:creator>Gare, Gautam Rajendrakumar</dc:creator>
 <dc:creator>Galeotti, John Michael</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Class labels used for machine learning are relatable to each other, with
certain class labels being more similar to each other than others (e.g. images
of cats and dogs are more similar to each other than those of cats and cars).
Such similarity among classes is often the cause of poor model performance due
to the models confusing between them. Current labeling techniques fail to
explicitly capture such similarity information. In this paper, we instead
exploit the similarity between classes by capturing the similarity information
with our novel confidence labels. Confidence labels are probabilistic labels
denoting the likelihood of similarity, or confusability, between the classes.
Often even after models are trained to differentiate between classes in the
feature space, the similar classes' latent space still remains clustered. We
view this type of clustering as valuable information and exploit it with our
novel projective loss functions. Our projective loss functions are designed to
work with confidence labels with an ability to relax the loss penalty for
errors that confuse similar classes. We use our approach to train neural
networks with noisy labels, as we believe noisy labels are partly a result of
confusability arising from class similarity. We show improved performance
compared to the use of standard loss functions. We conduct a detailed analysis
using the CIFAR-10 dataset and show our proposed methods' applicability to
larger datasets, such as ImageNet and Food-101N.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13610</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Approach to Improve Robustness of NLP Systems against ASR Errors</dc:title>
 <dc:creator>Cui, Tong</dc:creator>
 <dc:creator>Xiao, Jinghui</dc:creator>
 <dc:creator>Li, Liangyou</dc:creator>
 <dc:creator>Jiang, Xin</dc:creator>
 <dc:creator>Liu, Qun</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Speech-enabled systems typically first convert audio to text through an
automatic speech recognition (ASR) model and then feed the text to downstream
natural language processing (NLP) modules. The errors of the ASR system can
seriously downgrade the performance of the NLP modules. Therefore, it is
essential to make them robust to the ASR errors. Previous work has shown it is
effective to employ data augmentation methods to solve this problem by
injecting ASR noise during the training process. In this paper, we utilize the
prevalent pre-trained language model to generate training samples with
ASR-plausible noise. Compare to the previous methods, our approach generates
ASR noise that better fits the real-world error distribution. Experimental
results on spoken language translation(SLT) and spoken language understanding
(SLU) show that our approach effectively improves the system robustness against
the ASR errors and achieves state-of-the-art results on both tasks.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13610</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13612</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>THAT: Two Head Adversarial Training for Improving Robustness at Scale</dc:title>
 <dc:creator>Wu, Zuxuan</dc:creator>
 <dc:creator>Goldstein, Tom</dc:creator>
 <dc:creator>Davis, Larry S.</dc:creator>
 <dc:creator>Lim, Ser-Nam</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Many variants of adversarial training have been proposed, with most research
focusing on problems with relatively few classes. In this paper, we propose Two
Head Adversarial Training (THAT), a two-stream adversarial learning network
that is designed to handle the large-scale many-class ImageNet dataset. The
proposed method trains a network with two heads and two loss functions; one to
minimize feature-space domain shift between natural and adversarial images, and
one to promote high classification accuracy. This combination delivers a
hardened network that achieves state of the art robust accuracy while
maintaining high natural accuracy on ImageNet. Through extensive experiments,
we demonstrate that the proposed framework outperforms alternative methods
under both standard and &quot;free&quot; adversarial training settings.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13612</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13613</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gaussian Guided IoU: A Better Metric for Balanced Learning on Object
  Detection</dc:title>
 <dc:creator>Wu, Shengkai</dc:creator>
 <dc:creator>Yang, Jinrong</dc:creator>
 <dc:creator>Yu, Hangcheng</dc:creator>
 <dc:creator>Gou, Lijun</dc:creator>
 <dc:creator>Li, Xiaoping</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  For most of the anchor-based detectors, Intersection over Union(IoU) is
widely utilized to assign targets for the anchors during training. However, IoU
pays insufficient attention to the closeness of the anchor's center to the
truth box's center. This results in two problems: (1) only one anchor is
assigned to most of the slender objects which leads to insufficient supervision
information for the slender objects during training and the performance on the
slender objects is hurt; (2) IoU can not accurately represent the alignment
degree between the receptive field of the feature at the anchor's center and
the object. Thus during training, some features whose receptive field aligns
better with objects are missing while some features whose receptive field
aligns worse with objects are adopted. This hurts the localization accuracy of
models. To solve these problems, we firstly design Gaussian Guided IoU(GGIoU)
which focuses more attention on the closeness of the anchor's center to the
truth box's center. Then we propose GGIoU-balanced learning method including
GGIoU-guided assignment strategy and GGIoU-balanced localization loss. The
method can assign multiple anchors for each slender object and bias the
training process to the features well-aligned with objects. Extensive
experiments on the popular benchmarks such as PASCAL VOC and MS COCO
demonstrate GGIoU-balanced learning can solve the above problems and
substantially improve the performance of the object detection model, especially
in the localization accuracy.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13613</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13614</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards improving architectural diagram consistency using system
  descriptors</dc:title>
 <dc:creator>Nicacio, Jalves</dc:creator>
 <dc:creator>Petrillo, Fabio</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Communication between practitioners is essential for the system's quality in
the DevOps context. To improve this communication, practitioners often use
informal diagrams to represent the components of a system. However, as systems
evolve, it is a challenge to synchronize diagrams with production environments
consistently. Hence, the inconsistency of architectural diagrams can affect
communication between practitioner and their understanding of systems. In this
paper, we propose the use of system descriptors to improve deployment diagram
consistency. We state two main hypotheses: (1) if an architectural diagram is
generated from a valid system descriptor, then the diagram is consistent; (2)
if a valid system descriptor is generated from an architectural diagram, then
the diagram is consistent. We report a case study to explore our hypotheses.
Furthermore, we constructed a system descriptor from the Netflix deployment
diagram, and we applied our tool to generate a new architectural diagram.
Finally, we compare the original and generated diagrams to evaluate our
proposal. Our case study shows all Docker compose description elements can be
graphically represented in the generated architectural diagram, and the
generated diagram does not present inconsistent aspects of the original
diagram. Thus, our preliminary results lead to further evaluation in controlled
and empirical experiments to test our hypotheses.
</dc:description>
 <dc:description>Comment: 5 pages. This is the camera ready version to be published in
  proceedings of 29th IEEE/ACM International Conference on Program
  Comprehension (ICPC 2021). arXiv admin note: text overlap with
  arXiv:2008.11060</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13614</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13620</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SubSpectral Normalization for Neural Audio Data Processing</dc:title>
 <dc:creator>Chang, Simyung</dc:creator>
 <dc:creator>Park, Hyoungwoo</dc:creator>
 <dc:creator>Cho, Janghoon</dc:creator>
 <dc:creator>Park, Hyunsin</dc:creator>
 <dc:creator>Yun, Sungrack</dc:creator>
 <dc:creator>Hwang, Kyuwoong</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Convolutional Neural Networks are widely used in various machine learning
domains. In image processing, the features can be obtained by applying 2D
convolution to all spatial dimensions of the input. However, in the audio case,
frequency domain input like Mel-Spectrogram has different and unique
characteristics in the frequency dimension. Thus, there is a need for a method
that allows the 2D convolution layer to handle the frequency dimension
differently. In this work, we introduce SubSpectral Normalization (SSN), which
splits the input frequency dimension into several groups (sub-bands) and
performs a different normalization for each group. SSN also includes an affine
transformation that can be applied to each group. Our method removes the
inter-frequency deflection while the network learns a frequency-aware
characteristic. In the experiments with audio data, we observed that SSN can
efficiently improve the network's performance.
</dc:description>
 <dc:description>Comment: 4 pages, ICASSP '21 accepted</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13620</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13622</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contextual Information Enhanced Convolutional Neural Networks for
  Retinal Vessel Segmentation in Color Fundus Images</dc:title>
 <dc:creator>Sun, Muyi</dc:creator>
 <dc:creator>Zhang, Guanhong</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Accurate retinal vessel segmentation is a challenging problem in color fundus
image analysis. An automatic retinal vessel segmentation system can effectively
facilitate clinical diagnosis and ophthalmological research. Technically, this
problem suffers from various degrees of vessel thickness, perception of
details, and contextual feature fusion. For addressing these challenges, a deep
learning based method has been proposed and several customized modules have
been integrated into the well-known encoder-decoder architecture U-net, which
is mainly employed in medical image segmentation. Structurally, cascaded
dilated convolutional modules have been integrated into the intermediate
layers, for obtaining larger receptive field and generating denser encoded
feature maps. Also, the advantages of the pyramid module with spatial
continuity have been taken, for multi-thickness perception, detail refinement,
and contextual feature fusion. Additionally, the effectiveness of different
normalization approaches has been discussed in network training for different
datasets with specific properties. Experimentally, sufficient comparative
experiments have been enforced on three retinal vessel segmentation datasets,
DRIVE, CHASEDB1, and the unhealthy dataset STARE. As a result, the proposed
method outperforms the work of predecessors and achieves state-of-the-art
performance in Sensitivity/Recall, F1-score and MCC.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13622</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13628</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HufuNet: Embedding the Left Piece as Watermark and Keeping the Right
  Piece for Ownership Verification in Deep Neural Networks</dc:title>
 <dc:creator>Lv, Peizhuo</dc:creator>
 <dc:creator>Li, Pan</dc:creator>
 <dc:creator>Zhang, Shengzhi</dc:creator>
 <dc:creator>Chen, Kai</dc:creator>
 <dc:creator>Liang, Ruigang</dc:creator>
 <dc:creator>Zhao, Yue</dc:creator>
 <dc:creator>Li, Yingjiu</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Due to the wide use of highly-valuable and large-scale deep neural networks
(DNNs), it becomes crucial to protect the intellectual property of DNNs so that
the ownership of disputed or stolen DNNs can be verified. Most existing
solutions embed backdoors in DNN model training such that DNN ownership can be
verified by triggering distinguishable model behaviors with a set of secret
inputs. However, such solutions are vulnerable to model fine-tuning and
pruning. They also suffer from fraudulent ownership claim as attackers can
discover adversarial samples and use them as secret inputs to trigger
distinguishable behaviors from stolen models. To address these problems, we
propose a novel DNN watermarking solution, named HufuNet, for protecting the
ownership of DNN models. We evaluate HufuNet rigorously on four benchmark
datasets with five popular DNN models, including convolutional neural network
(CNN) and recurrent neural network (RNN). The experiments demonstrate HufuNet
is highly robust against model fine-tuning/pruning, kernels cutoff/supplement,
functionality-equivalent attack, and fraudulent ownership claims, thus highly
promising to protect large-scale DNN models in the real-world.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13628</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13629</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Probabilistic Ordinal Embeddings for Uncertainty-Aware
  Regression</dc:title>
 <dc:creator>Li, Wanhua</dc:creator>
 <dc:creator>Huang, Xiaoke</dc:creator>
 <dc:creator>Lu, Jiwen</dc:creator>
 <dc:creator>Feng, Jianjiang</dc:creator>
 <dc:creator>Zhou, Jie</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Uncertainty is the only certainty there is. Modeling data uncertainty is
essential for regression, especially in unconstrained settings. Traditionally
the direct regression formulation is considered and the uncertainty is modeled
by modifying the output space to a certain family of probabilistic
distributions. On the other hand, classification based regression and ranking
based solutions are more popular in practice while the direct regression
methods suffer from the limited performance. How to model the uncertainty
within the present-day technologies for regression remains an open issue. In
this paper, we propose to learn probabilistic ordinal embeddings which
represent each data as a multivariate Gaussian distribution rather than a
deterministic point in the latent space. An ordinal distribution constraint is
proposed to exploit the ordinal nature of regression. Our probabilistic ordinal
embeddings can be integrated into popular regression approaches and empower
them with the ability of uncertainty estimation. Experimental results show that
our approach achieves competitive performance. Code is available at
https://github.com/Li-Wanhua/POEs.
</dc:description>
 <dc:description>Comment: Accepted by CVPR2021. Code is available at
  https://github.com/Li-Wanhua/POEs</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13629</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13633</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A family of projective two-weight linear codes</dc:title>
 <dc:creator>Heng, Ziling</dc:creator>
 <dc:creator>Li, Dexiang</dc:creator>
 <dc:creator>Du, Jiao</dc:creator>
 <dc:creator>Chen, Fuling</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94B05, 05E30, 15A03</dc:subject>
 <dc:description>  Projective two-weight linear codes are closely related to finite projective
spaces and strongly regular graphs. In this paper, a family of $q$-ary
projective two-weight linear codes is presented, where $q$ is a power of 2. The
parameters of both the codes and their duals are excellent. As applications,
the codes are used to derive strongly regular graphs with new parameters and
secret sharing schemes with interesting access structures.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13633</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13647</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modulated MPC for Arm Inductor-less MVDC MMC with Reduced Computational
  Burden</dc:title>
 <dc:creator>Martin, Sandro</dc:creator>
 <dc:creator>Li, Hui</dc:creator>
 <dc:creator>Anubi, Olugbenga Moses</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  A modulated model predictive controller is designed for an inductor-less
modular multilevel converter targeting an MVDC solid-state transformer
application. The underlying optimization problem is formulated such that a
unique closed-form solution is derived from a highly accurate dynamic system
model, which significantly reduces computation time. Unlike other closed-form
methods, the proposed controller achieves inductor-less current control, has a
reduced sampling speed enabled by a novel model-based circulating energy
compensator, and does not require tuned PI controllers to generate current
references. Simulation and experimental results demonstrate that the proposed
controller achieves transient power flow control and steady state circulating
energy control despite the low system inertia.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13647</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13648</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Semidefinite Optimization-based Branch-and-Bound Algorithm for Several
  Reactive Optimal Power Flow Problems</dc:title>
 <dc:creator>Sliwak, Julie</dc:creator>
 <dc:creator>Anjos, Miguel</dc:creator>
 <dc:creator>L&#xe9;tocart, Lucas</dc:creator>
 <dc:creator>Traversi, Emiliano</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The Reactive Optimal Power Flow (ROPF) problem consists in computing an
optimal power generation dispatch for an alternating current transmission
network that respects power flow equations and operational constraints. Some
means of action on the voltage are modelled in the ROPF problem such as the
possible activation of shunts, which implies discrete variables. The ROPF
problem belongs to the class of nonconvex MINLPs (Mixed-Integer Nonlinear
Problems), which are NP-hard problems. In this paper, we solve three new
variants of the ROPF problem by using a semidefinite optimization-based
Branch-and-Bound algorithm. We present results on MATPOWER instances and we
show that this method can solve to global optimality most instances. On the
instances not solved to optimality, our algorithm is able to find solutions
with a value better than the ones obtained by a rounding algorithm. We also
demonstrate that applying an appropriate clique merging algorithm can
significantly speed up the resolution of semidefinite relaxations of ROPF large
instances.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13648</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13660</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Closing the Loop: Joint Rain Generation and Removal via Disentangled
  Image Translation</dc:title>
 <dc:creator>Ye, Yuntong</dc:creator>
 <dc:creator>Chang, Yi</dc:creator>
 <dc:creator>Zhou, Hanyu</dc:creator>
 <dc:creator>Yan, Luxin</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Existing deep learning-based image deraining methods have achieved promising
performance for synthetic rainy images, typically rely on the pairs of sharp
images and simulated rainy counterparts. However, these methods suffer from
significant performance drop when facing the real rain, because of the huge gap
between the simplified synthetic rain and the complex real rain. In this work,
we argue that the rain generation and removal are the two sides of the same
coin and should be tightly coupled. To close the loop, we propose to jointly
learn real rain generation and removal procedure within a unified disentangled
image translation framework. Specifically, we propose a bidirectional
disentangled translation network, in which each unidirectional network contains
two loops of joint rain generation and removal for both the real and synthetic
rain image, respectively. Meanwhile, we enforce the disentanglement strategy by
decomposing the rainy image into a clean background and rain layer (rain
removal), in order to better preserve the identity background via both the
cycle-consistency loss and adversarial loss, and ease the rain layer
translating between the real and synthetic rainy image. A counterpart
composition with the entanglement strategy is symmetrically applied for rain
generation. Extensive experiments on synthetic and real-world rain datasets
show the superiority of proposed method compared to state-of-the-arts.
</dc:description>
 <dc:description>Comment: 10 pages, Accepted by 2021 CVPR</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13666</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation of Sampling-Based Optimizing Planners for Outdoor Robot
  Navigation</dc:title>
 <dc:creator>Atas, Fetullah</dc:creator>
 <dc:creator>Grimstad, Lars</dc:creator>
 <dc:creator>Cielniak, Grzegorz</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Sampling-Based Optimal(SBO) path planning has been mainly used for robotic
arm manipulation tasks. Several research works have been carried out in order
to evaluate performances of various SBO planners for arm manipulation. However,
not much of work is available that highlights performances of SBO planners in
context of mobile robot navigation in outdoor 3D environments. This paper
evaluates performances of major SBO planners in Open Motion Planning
Library(OMPL) for that purpose. Due to large number of existing SBO planners,
experimenting and selecting a proper planner for a planning problem can be
burdensome and ambiguous. SBO planner's probabilistic nature can also add a
bias to this procedure. To address this, we evaluate performances of all
available SBO planners in OMPL with a randomized planning problem generation
method iteratively. Evaluations are done in various state spaces suiting for
different differential constraints of mobile robots. The planning setups are
focused for navigation of mobile robots in outdoor environments. The outdoor
environment representation is done with prebuilt OctoMaps, collision checks are
performed between a 3D box representing robot body and OctoMap for validation
of sampled states. Several evaluation metrics such as resulting path's length,
smoothness and status of acquired final solutions are selected. According to
selected metrics, performances from different SBO planners are presented
comparatively. Experimental results shows the significance of parallel
computing towards quicker convergence rates for optimal solutions. Several SBO
methods that takes advantage of parallel computing produced better results
consistently in all state spaces for different planning inquiries.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13666</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13667</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Execution Lattices Fast and Slow</dc:title>
 <dc:creator>Algehed, Maximilian</dc:creator>
 <dc:creator>Flanagan, Cormac</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Methods for automatically, soundly, and precisely guaranteeing the
noninterference security policy are predominantly based on multi-execution. All
other methods are either based on undecidable theorem proving or suffer from
false alarms. The multi-execution mechanisms, meanwhile, work by isolating
security levels during program execution and running multiple copies of the
target program, once for each security level with carefully tailored inputs
that ensure both soundness and precision. When security levels are
hierarchically organised in a lattice, this may lead to an exponential number
of executions of the target program as the number of possible ways of combining
security levels grows. In this paper we study how the lattice structure for
security levels influences the runtime overhead of multi-execution. We
additionally show how to use Galois connections to gain speedups in
multi-execution by switching from lattices with high overhead to lattices with
low overhead. Additionally, we give an empirical evaluation that corroborates
our analysis and shows how Galois connections have potential to speed up
multi-execution.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13667</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13669</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Systematic Study on Weak Galerkin Finite Element Method for Second
  Order Parabolic Problems</dc:title>
 <dc:creator>Deka, Bhupen</dc:creator>
 <dc:creator>Kumar, Naresh</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  A systematic numerical study on weak Galerkin (WG) finite element method for
second order linear parabolic problems is presented by allowing polynomial
approximations with various degrees for each local element. Convergence of both
semidiscrete and fully discrete WG solutions are established in
$L^{\infty}(L^2)$ and $L^{\infty}(H^1)$ norms for a general WG element $({\cal
P}_{k}(K),\;{\cal P}_{j}(\partial K),\;\big[{\cal P}_{l}(K)\big]^2)$, where
$k\ge 1$, $j\ge 0$ and $l\ge 0$ are arbitrary integers. The fully discrete
space-time discretization is based on a first order in time Euler scheme. Our
results are intended to extend the numerical analysis of WG methods for
elliptic problems [J. Sci. Comput., 74 (2018), 1369-1396] to parabolic
problems. Numerical experiments are reported to justify the robustness,
reliability and accuracy of the WG finite element method.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13669</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13674</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Frame-rate Up-conversion Detection Based on Convolutional Neural Network
  for Learning Spatiotemporal Features</dc:title>
 <dc:creator>Yoon, Minseok</dc:creator>
 <dc:creator>Nam, Seung-Hun</dc:creator>
 <dc:creator>Yu, In-Jae</dc:creator>
 <dc:creator>Ahn, Wonhyuk</dc:creator>
 <dc:creator>Kwon, Myung-Joon</dc:creator>
 <dc:creator>Lee, Heung-Kyu</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  With the advance in user-friendly and powerful video editing tools, anyone
can easily manipulate videos without leaving prominent visual traces.
Frame-rate up-conversion (FRUC), a representative temporal-domain operation,
increases the motion continuity of videos with a lower frame-rate and is used
by malicious counterfeiters in video tampering such as generating fake
frame-rate video without improving the quality or mixing temporally spliced
videos. FRUC is based on frame interpolation schemes and subtle artifacts that
remain in interpolated frames are often difficult to distinguish. Hence,
detecting such forgery traces is a critical issue in video forensics. This
paper proposes a frame-rate conversion detection network (FCDNet) that learns
forensic features caused by FRUC in an end-to-end fashion. The proposed network
uses a stack of consecutive frames as the input and effectively learns
interpolation artifacts using network blocks to learn spatiotemporal features.
This study is the first attempt to apply a neural network to the detection of
FRUC. Moreover, it can cover the following three types of frame interpolation
schemes: nearest neighbor interpolation, bilinear interpolation, and
motion-compensated interpolation. In contrast to existing methods that exploit
all frames to verify integrity, the proposed approach achieves a high detection
speed because it observes only six frames to test its authenticity. Extensive
experiments were conducted with conventional forensic methods and neural
networks for video forensic tasks to validate our research. The proposed
network achieved state-of-the-art performance in terms of detecting the
interpolated artifacts of FRUC. The experimental results also demonstrate that
our trained model is robust for an unseen dataset, unlearned frame-rate, and
unlearned quality factor.
</dc:description>
 <dc:description>Comment: preprint; under review</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13677</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Explainability Guided Multi-Site COVID-19 CT Classification</dc:title>
 <dc:creator>Ali, Ameen</dc:creator>
 <dc:creator>Shaharabany, Tal</dc:creator>
 <dc:creator>Wolf, Lior</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Radiologist examination of chest CT is an effective way for screening
COVID-19 cases. In this work, we overcome three challenges in the automation of
this process: (i) the limited number of supervised positive cases, (ii) the
lack of region-based supervision, and (iii) the variability across acquisition
sites. These challenges are met by incorporating a recent augmentation solution
called SnapMix, by a new patch embedding technique, and by performing a
test-time stability analysis. The three techniques are complementary and are
all based on utilizing the heatmaps produced by the Class Activation Mapping
(CAM) explainability method. Compared to the current state of the art, we
obtain an increase of five percent in the F1 score on a site with a relatively
high number of cases, and a gap twice as large for a site with much fewer
training images.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13677</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13681</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>[Technical Report] Combining Sampling and Synopses with Worst-Case
  Optimal Runtime and Quality Guarantees for Graph Pattern Cardinality
  Estimation</dc:title>
 <dc:creator>Kim, Kyoungmin</dc:creator>
 <dc:creator>Kim, Hyeonji</dc:creator>
 <dc:creator>Fletcher, George</dc:creator>
 <dc:creator>Han, Wook-Shin</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Graph pattern cardinality estimation is the problem of estimating the number
of embeddings of a query graph in a data graph. This fundamental problem
arises, for example, during query planning in subgraph matching algorithms.
There are two major approaches to solving the problem: sampling and synopsis.
Synopsis (or summary)-based methods are fast and accurate if synopses capture
information of graphs well. However, these methods suffer from large errors due
to loss of information during summarization and inherent assumptions.
Sampling-based methods are unbiased but suffer from large estimation variance
due to large sample space.
  To address these limitations, we propose Alley, a hybrid method that combines
both sampling and synopses. Alley employs 1) a novel sampling strategy, random
walk with intersection, which effectively reduces the sample space, 2)
branching to further reduce variance, and 3) a novel mining approach that
extracts and indexes tangled patterns as synopses which are inherently
difficult to estimate by sampling. By using them in the online estimation
phase, we can effectively reduce the sample space while still ensuring
unbiasedness. We establish that Alley has worst-case optimal runtime and
approximation quality guarantees for any given error bound $\epsilon$ and
required confidence $\mu$. In addition to the theoretical aspect of Alley, our
extensive experiments show that Alley outperforms the state-of-the-art methods
by up to orders of magnitude higher accuracy with similar efficiency.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13684</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MBA-VO: Motion Blur Aware Visual Odometry</dc:title>
 <dc:creator>Liu, Peidong</dc:creator>
 <dc:creator>Zuo, Xingxing</dc:creator>
 <dc:creator>Larsson, Viktor</dc:creator>
 <dc:creator>Pollefeys, Marc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Motion blur is one of the major challenges remaining for visual odometry
methods. In low-light conditions where longer exposure times are necessary,
motion blur can appear even for relatively slow camera motions. In this paper
we present a novel hybrid visual odometry pipeline with direct approach that
explicitly models and estimates the camera's local trajectory within the
exposure time. This allows us to actively compensate for any motion blur that
occurs due to the camera motion. In addition, we also contribute a novel
benchmarking dataset for motion blur aware visual odometry. In experiments we
show that by directly modeling the image formation process, we are able to
improve robustness of the visual odometry, while keeping comparable accuracy as
that for images without motion blur.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13684</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13694</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Complexity of Learning Description Logic Ontologies</dc:title>
 <dc:creator>Ozaki, Ana</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Ontologies are a popular way of representing domain knowledge, in particular,
knowledge in domains related to life sciences. (Semi-)automating the process of
building an ontology has attracted researchers from different communities into
a field called &quot;Ontology Learning&quot;. We provide a formal specification of the
exact and the probably approximately correct learning models from computational
learning theory. Then, we recall from the literature complexity results for
learning lightweight description logic (DL) ontologies in these models.
Finally, we highlight other approaches proposed in the literature for learning
DL ontologies.
</dc:description>
 <dc:description>Comment: Presented at the Reasoning Web Summer School 2020</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13694</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13710</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial-spectral Hyperspectral Image Classification via Multiple Random
  Anchor Graphs Ensemble Learning</dc:title>
 <dc:creator>Miao, Yanling</dc:creator>
 <dc:creator>Wang, Qi</dc:creator>
 <dc:creator>Chen, Mulin</dc:creator>
 <dc:creator>Li, Xuelong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Graph-based semi-supervised learning methods, which deal well with the
situation of limited labeled data, have shown dominant performance in practical
applications. However, the high dimensionality of hyperspectral images (HSI)
makes it hard to construct the pairwise adjacent graph. Besides, the fine
spatial features that help improve the discriminability of the model are often
overlooked. To handle the problems, this paper proposes a novel
spatial-spectral HSI classification method via multiple random anchor graphs
ensemble learning (RAGE). Firstly, the local binary pattern is adopted to
extract the more descriptive features on each selected band, which preserves
local structures and subtle changes of a region. Secondly, the adaptive
neighbors assignment is introduced in the construction of anchor graph, to
reduce the computational complexity. Finally, an ensemble model is built by
utilizing multiple anchor graphs, such that the diversity of HSI is learned.
Extensive experiments show that RAGE is competitive against the
state-of-the-art approaches.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13710</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13716</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vectorization and Rasterization: Self-Supervised Learning for Sketch and
  Handwriting</dc:title>
 <dc:creator>Bhunia, Ayan Kumar</dc:creator>
 <dc:creator>Chowdhury, Pinaki Nath</dc:creator>
 <dc:creator>Yang, Yongxin</dc:creator>
 <dc:creator>Hospedales, Timothy M.</dc:creator>
 <dc:creator>Xiang, Tao</dc:creator>
 <dc:creator>Song, Yi-Zhe</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Self-supervised learning has gained prominence due to its efficacy at
learning powerful representations from unlabelled data that achieve excellent
performance on many challenging downstream tasks. However supervision-free
pre-text tasks are challenging to design and usually modality specific.
Although there is a rich literature of self-supervised methods for either
spatial (such as images) or temporal data (sound or text) modalities, a common
pre-text task that benefits both modalities is largely missing. In this paper,
we are interested in defining a self-supervised pre-text task for sketches and
handwriting data. This data is uniquely characterised by its existence in dual
modalities of rasterized images and vector coordinate sequences. We address and
exploit this dual representation by proposing two novel cross-modal translation
pre-text tasks for self-supervised feature learning: Vectorization and
Rasterization. Vectorization learns to map image space to vector coordinates
and rasterization maps vector coordinates to image space. We show that the our
learned encoder modules benefit both raster-based and vector-based downstream
approaches to analysing hand-drawn data. Empirical evidence shows that our
novel pre-text tasks surpass existing single and multi-modal self-supervision
methods.
</dc:description>
 <dc:description>Comment: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2021
  Code : https://github.com/AyanKumarBhunia/Self-Supervised-Learning-for-Sketch</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13716</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13719</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi Sensor Fusion for Navigation and Mapping in Autonomous Vehicles:
  Accurate Localization in Urban Environments</dc:title>
 <dc:creator>Qingqing, Li</dc:creator>
 <dc:creator>Queralta, Jorge Pe&#xf1;a</dc:creator>
 <dc:creator>Gia, Tuan Nguyen</dc:creator>
 <dc:creator>Zou, Zhuo</dc:creator>
 <dc:creator>Westerlund, Tomi</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The combination of data from multiple sensors, also known as sensor fusion or
data fusion, is a key aspect in the design of autonomous robots. In particular,
algorithms able to accommodate sensor fusion techniques enable increased
accuracy, and are more resilient against the malfunction of individual sensors.
The development of algorithms for autonomous navigation, mapping and
localization have seen big advancements over the past two decades. Nonetheless,
challenges remain in developing robust solutions for accurate localization in
dense urban environments, where the so called last-mile delivery occurs. In
these scenarios, local motion estimation is combined with the matching of
real-time data with a detailed pre-built map. In this paper, we utilize data
gathered with an autonomous delivery robot to compare different sensor fusion
techniques and evaluate which are the algorithms providing the highest accuracy
depending on the environment. The techniques we analyze and propose in this
paper utilize 3D lidar data, inertial data, GNSS data and wheel encoder
readings. We show how lidar scan matching combined with other sensor data can
be used to increase the accuracy of the robot localization and, in consequence,
its navigation. Moreover, we propose a strategy to reduce the impact on
navigation performance when a change in the environment renders map data
invalid or part of the available map is corrupted.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13719</dc:identifier>
 <dc:identifier>Unmanned.System,Flight.08,no.03,pp229-237(2020)</dc:identifier>
 <dc:identifier>doi:10.1142/S2301385020500168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13743</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Verifying Compositional Refinement of Assume/Guarantee Contracts using
  Linear Programming</dc:title>
 <dc:creator>Sharf, Miel</dc:creator>
 <dc:creator>Besselink, Bart</dc:creator>
 <dc:creator>Johansson, Karl Henrik</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Verifying specifications for large-scale modern engineering systems can be a
time-consuming task, as most formal verification methods are limited to systems
of modest size. Recently, contract-based design and verification has been
proposed as a modular framework for specifications, and
linear-programming-based techniques have been presented for verifying that a
given system satisfies a given contract. In this paper, we extend this
assume/guarantee framework by presenting necessary and sufficient conditions
for a collection of contracts on individual components to refine a contract on
the composed system. These conditions can be verified by solving linear
programs, whose number grows linearly with the number of specifications defined
by the contracts. We exemplify the tools developed using a case study
considering safety in a car-following scenario, where noise and time-varying
delay are considered.
</dc:description>
 <dc:description>Comment: 7 pages, 6 figures</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13743</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13747</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical Modeling of the Human Body as an Extended Antenna</dc:title>
 <dc:creator>Wilding, Thomas</dc:creator>
 <dc:creator>Leitinger, Erik</dc:creator>
 <dc:creator>Muehlmann, Ulrich</dc:creator>
 <dc:creator>Witrisal, Klaus</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  In this paper we investigate the possibility of modeling a single antenna
alone and in close proximity to a physical object by means of discrete point
source scatterers. The scatter point model allows joint modeling of a physical
antenna and the human body as a single extended object with direction dependent
scattering coefficients for the scatter points. We introduce the term extended
antenna describing antenna and human body together. To investigate the
identifiability of the model parameters we make use of ultrawideband channel
measurements and accurate ground truth position and orientation measurements
obtained with an optical tracking system. By comparing measurements of the
antenna attached directly to the user with measurements for the antenna without
the user nearby, we show the shadowing and scattering effects of the human body
and the antenna.
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures. To be published in Proc. IEEE EuCAP-21</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13752</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating Koopman operators for nonlinear dynamical systems: a
  nonparametric approach</dc:title>
 <dc:creator>Zanini, Francesco</dc:creator>
 <dc:creator>Chiuso, Alessandro</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The Koopman operator is a mathematical tool that allows for a linear
description of non-linear systems, but working in infinite dimensional spaces.
Dynamic Mode Decomposition and Extended Dynamic Mode Decomposition are amongst
the most popular finite dimensional approximation. In this paper we capture
their core essence as a dual version of the same framework, incorporating them
into the Kernel framework. To do so, we leverage the RKHS as a suitable space
for learning the Koopman dynamics, thanks to its intrinsic finite-dimensional
nature, shaped by data. We finally establish a strong link between kernel
methods and Koopman operators, leading to the estimation of the latter through
Kernel functions. We provide also simulations for comparison with standard
procedures.
</dc:description>
 <dc:description>Comment: Pre-print submitted for 19th IFAC Symposium, System Identification:
  learning models for decision and control</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13752</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13754</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Latus Incentive Scheme: Enabling Decentralization in Blockchains based
  on Recursive SNARKs</dc:title>
 <dc:creator>Garoffolo, Alberto</dc:creator>
 <dc:creator>Kaidalov, Dmytro</dc:creator>
 <dc:creator>Oliynykov, Roman</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In the Zendoo whitepaper we introduced a novel SNARK-based construction that
allows Bitcoin-like blockchains to create and communicate with sidechains of
different types without knowing their internal structure. We also introduced a
specific construction, called Latus, allowing creation of fully verifiable
sidechains. In the paper we omitted a detailed description of an incentive
scheme for Latus that is an essential element of a real decentralized system.
This paper fills the gap by introducing details of the incentive scheme for the
Latus sidechain. The represented ideas can also be adopted by other SNARK-based
blockchains to incentivize decentralized proofs creation.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13755</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Software Models: The Density Matrix for Classical and Quantum
  Software Systems Design</dc:title>
 <dc:creator>Exman, Iaakov</dc:creator>
 <dc:creator>Shmilovich, Alon Tsalik</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  Linear Software Models enable rigorous linear algebraic procedures for
modular design of classical software systems. These procedures apply a spectral
approach to matrix representations - e.g. the Laplacian - of the software
system. Recent intensive research efforts towards quantum computers have
increased expectations that quantum computing could in due time materialize as
a practical alternative to classical computing. It is reasonable to inquire
about quantum software desirable features and prepare in advance modular design
procedures for quantum software systems. However, it does not make sense to
have two totally separate procedures for modular design, one for classical
software systems and another for quantum software systems. This paper claims
that there should be just a single unified and rigorous design procedure for
both classical and quantum software systems. Our common design procedure
starting point for both classical and quantum software systems is Von Neumann
quantum notion of Density Operator and its Density Matrix representation. This
paper formulates and demonstrates modular design in terms of projection
operators obtained from a design Density Matrix and shows their equivalence to
the Linear Software Models results of the Laplacian matrix spectrum for the
classical case. The application in practice of the design procedure for both
classical and quantum software is illustrated by case studies.
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures, This is a preprint of a paper accepted for the
  2nd International Workshop on Quantum Software Engineering (Q-SE 2021)
  co-located with ICSE 2021, to be published in the corresponding proceedings</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13755</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13762</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mining Energy-Related Practices in Robotics Software</dc:title>
 <dc:creator>Albonico, Michel</dc:creator>
 <dc:creator>Malavolta, Ivano</dc:creator>
 <dc:creator>Pinto, Gustavo</dc:creator>
 <dc:creator>Guzman, Emitza</dc:creator>
 <dc:creator>Chinnappan, Katerina</dc:creator>
 <dc:creator>Lago, Patricia</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Robots are becoming more and more commonplace in many industry settings. This
successful adoption can be partly attributed to (1) their increasingly
affordable cost and (2) the possibility of developing intelligent,
software-driven robots. Unfortunately, robotics software consumes significant
amounts of energy. Moreover, robots are often battery-driven, meaning that even
a small energy improvement can help reduce its energy footprint and increase
its autonomy and user experience. In this paper, we study the Robot Operating
System (ROS) ecosystem, the de-facto standard for developing and prototyping
robotics software. We analyze 527 energy-related data points (including
commits, pull-requests, and issues on ROS-related repositories, ROS-related
questions on StackOverflow, ROS Discourse, ROS Answers, and the official ROS
Wiki). Our results include a quantification of the interest of roboticists on
software energy efficiency, 10 recurrent causes, and 14 solutions of
energy-related issues, and their implied trade-offs with respect to other
quality attributes. Those contributions support roboticists and researchers
towards having energy-efficient software in future robotics projects.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13762</dc:identifier>
 <dc:identifier>MSR 2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13800</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Experimental Validation of Linear and Nonlinear MPC on an Articulated
  Unmanned Ground Vehicle</dc:title>
 <dc:creator>Kayacan, Erkan</dc:creator>
 <dc:creator>Saeys, Wouter</dc:creator>
 <dc:creator>Ramon, Herman</dc:creator>
 <dc:creator>Belta, Calin</dc:creator>
 <dc:creator>Peschel, Joshua M.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper focuses on the trajectory tracking control problem for an
articulated unmanned ground vehicle. We propose and compare two approaches in
terms of performance and computational complexity. The first uses a nonlinear
mathematical model derived from first principles and combines a nonlinear model
predictive controller (NMPC) with a nonlinear moving horizon estimator (NMHE)
to produce a control strategy. The second is based on an input-state
linearization (ISL) of the original model followed by linear model predictive
control (LMPC). A fast real-time iteration scheme is proposed, implemented for
the NMHE-NMPC framework and benchmarked against the ISL-LMPC framework, which
is a traditional and cheap method. The experimental results for a time-based
trajectory show that the NMHE-NMPC framework with the proposed real-time
iteration scheme gives better trajectory tracking performance than the ISL-LMPC
framework and the required computation time is feasible for real-time
applications. Moreover, the ISL-LMPC produces results of a quality comparable
to the NMHE-NMPC framework at a significantly reduced computational cost.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13800</dc:identifier>
 <dc:identifier>IEEE/ASME Transactions on Mechatronics, vol. 23, issue 5, 2018</dc:identifier>
 <dc:identifier>doi:10.1109/TMECH.2018.2854877</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13802</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Harvested Power Region of Two-user MISO WPT Systems With Non-linear EH
  Nodes</dc:title>
 <dc:creator>Shanin, Nikita</dc:creator>
 <dc:creator>Cottatellucci, Laura</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we determine the harvested power region of a two-user
multiple-input single-output (MISO) wireless power transfer (WPT) system for a
non-linear model of the rectennas at the energy harvester (EH) nodes. To this
end, we characterize the distributions of the transmit symbol vector that
achieve individual points on the boundary of this region. Each distribution is
obtained as solution of an optimization problem where we maximize a weighted
sum of the average harvested powers at the EH nodes under a constraint on the
power budget of the transmitter. We prove that the optimal transmit strategy
employs two beamforming vectors and scalar unit norm transmit symbols with
arbitrary phase. To determine the beamforming vectors, we propose an iterative
algorithm based on a two-dimensional grid search, semi-definite relaxation, and
successive convex approximation. Our numerical results reveal that the proposed
design outperforms two baseline schemes based on a linear EH model and a single
beamforming vector, respectively. Finally, we observe that the harvested power
region is convex and the power harvested at one EH node can be traded for a
higher harvested power at the other node.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure, submitted for possible conference publication</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13802</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13809</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TrustCross: Enabling Confidential Interoperability across Blockchains
  Using Trusted Hardware</dc:title>
 <dc:creator>Lan, Ying</dc:creator>
 <dc:creator>Gao, Jianbo</dc:creator>
 <dc:creator>Wang, Ke</dc:creator>
 <dc:creator>Zhang, Jiashuo</dc:creator>
 <dc:creator>Wu, Zhenhao</dc:creator>
 <dc:creator>Zhu, Yuesheng</dc:creator>
 <dc:creator>Chen, Zhong</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  With the rapid development of blockchain technology, different types of
blockchains are adopted and interoperability across blockchains has received
widespread attention. There have been many cross-chain solutions proposed in
recent years, including notary scheme, sidechain, and relay chain. However,
most of the existing platforms do not take confidentiality into account,
although privacy has become an important concern for blockchain. In this paper,
we present TrustCross, a privacy-preserving cross-chain platform to enable
confidential interoperability across blockchains. The key insight behind
TrustCross is to encrypt cross-chain communication data on the relay chain with
the assistance of trusted execution environment and employ fine-grained access
control to protect user privacy. Our experimental results show that TrustCross
achieves reasonable latency and high scalability on the contract calls across
heterogeneous blockchains.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13809</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13810</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Any Part of Bayesian Network Structure Learning</dc:title>
 <dc:creator>Ling, Zhaolong</dc:creator>
 <dc:creator>Yu, Kui</dc:creator>
 <dc:creator>Wang, Hao</dc:creator>
 <dc:creator>Liu, Lin</dc:creator>
 <dc:creator>Li, Jiuyong</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study an interesting and challenging problem, learning any part of a
Bayesian network (BN) structure. In this challenge, it will be computationally
inefficient using existing global BN structure learning algorithms to find an
entire BN structure to achieve the part of a BN structure in which we are
interested. And local BN structure learning algorithms encounter the false edge
orientation problem when they are directly used to tackle this challenging
problem. In this paper, we first present a new concept of Expand-Backtracking
to explain why local BN structure learning methods have the false edge
orientation problem, then propose APSL, an efficient and accurate Any Part of
BN Structure Learning algorithm. Specifically, APSL divides the V-structures in
a Markov blanket (MB) into two types: collider V-structure and non-collider
V-structure, then it starts from a node of interest and recursively finds both
collider V-structures and non-collider V-structures in the found MBs, until the
part of a BN structure in which we are interested are oriented. To improve the
efficiency of APSL, we further design the APSL-FS algorithm using Feature
Selection, APSL-FS. Using six benchmark BNs, the extensive experiments have
validated the efficiency and accuracy of our methods.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13811</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Student Network Learning via Evolutionary Knowledge Distillation</dc:title>
 <dc:creator>Zhang, Kangkai</dc:creator>
 <dc:creator>Zhang, Chunhui</dc:creator>
 <dc:creator>Li, Shikun</dc:creator>
 <dc:creator>Zeng, Dan</dc:creator>
 <dc:creator>Ge, Shiming</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Knowledge distillation provides an effective way to transfer knowledge via
teacher-student learning, where most existing distillation approaches apply a
fixed pre-trained model as teacher to supervise the learning of student
network. This manner usually brings in a big capability gap between teacher and
student networks during learning. Recent researches have observed that a small
teacher-student capability gap can facilitate knowledge transfer. Inspired by
that, we propose an evolutionary knowledge distillation approach to improve the
transfer effectiveness of teacher knowledge. Instead of a fixed pre-trained
teacher, an evolutionary teacher is learned online and consistently transfers
intermediate knowledge to supervise student network learning on-the-fly. To
enhance intermediate knowledge representation and mimicking, several simple
guided modules are introduced between corresponding teacher-student blocks. In
this way, the student can simultaneously obtain rich internal knowledge and
capture its growth process, leading to effective student network learning.
Extensive experiments clearly demonstrate the effectiveness of our approach as
well as good adaptability in the low-resolution and few-sample visual
recognition scenarios.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13812</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reframing demand forecasting: a two-fold approach for lumpy and
  intermittent demand</dc:title>
 <dc:creator>Ro&#x17e;anec, Jo&#x17e;e M.</dc:creator>
 <dc:creator>Mladeni&#x107;, Dunja</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Demand forecasting is a crucial component of demand management. While
shortening the forecasting horizon allows for more recent data and less
uncertainty, this frequently means lower data aggregation levels and a more
significant data sparsity. Sparse demand data usually results in lumpy or
intermittent demand patterns, which have sparse and irregular demand intervals.
Usual statistical and machine learning models fail to provide good forecasts in
such scenarios. Our research shows that competitive demand forecasts can be
obtained through two models: predicting the demand occurrence and estimating
the demand size. We analyze the usage of local and global machine learning
models for both cases and compare results against baseline methods. Finally, we
propose a novel evaluation criterion of lumpy and intermittent demand
forecasting models' performance. Our research shows that global classification
models are the best choice when predicting demand event occurrence. When
predicting demand sizes, we achieved the best results using Simple Exponential
Smoothing forecast. We tested our approach on real-world data consisting of 516
three-year-long time series corresponding to European automotive original
equipment manufacturers' daily demand.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13812</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13813</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RA-BNN: Constructing Robust &amp; Accurate Binary Neural Network to
  Simultaneously Defend Adversarial Bit-Flip Attack and Improve Accuracy</dc:title>
 <dc:creator>Rakin, Adnan Siraj</dc:creator>
 <dc:creator>Yang, Li</dc:creator>
 <dc:creator>Li, Jingtao</dc:creator>
 <dc:creator>Yao, Fan</dc:creator>
 <dc:creator>Chakrabarti, Chaitali</dc:creator>
 <dc:creator>Cao, Yu</dc:creator>
 <dc:creator>Seo, Jae-sun</dc:creator>
 <dc:creator>Fan, Deliang</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Recently developed adversarial weight attack, a.k.a. bit-flip attack (BFA),
has shown enormous success in compromising Deep Neural Network (DNN)
performance with an extremely small amount of model parameter perturbation. To
defend against this threat, we propose RA-BNN that adopts a complete binary
(i.e., for both weights and activation) neural network (BNN) to significantly
improve DNN model robustness (defined as the number of bit-flips required to
degrade the accuracy to as low as a random guess). However, such an aggressive
low bit-width model suffers from poor clean (i.e., no attack) inference
accuracy. To counter this, we propose a novel and efficient two-stage network
growing method, named Early-Growth. It selectively grows the channel size of
each BNN layer based on channel-wise binary masks training with Gumbel-Sigmoid
function. Apart from recovering the inference accuracy, our RA-BNN after
growing also shows significantly higher resistance to BFA. Our evaluation of
the CIFAR-10 dataset shows that the proposed RA-BNN can improve the clean model
accuracy by ~2-8 %, compared with a baseline BNN, while simultaneously
improving the resistance to BFA by more than 125 x. Moreover, on ImageNet, with
a sufficiently large (e.g., 5,000) amount of bit-flips, the baseline BNN
accuracy drops to 4.3 % from 51.9 %, while our RA-BNN accuracy only drops to
37.1 % from 60.9 % (9 % clean accuracy improvement).
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13814</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Weighted Learning for Unsupervised Domain Adaptation</dc:title>
 <dc:creator>Xiao, Ni</dc:creator>
 <dc:creator>Zhang, Lei</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Unsupervised domain adaptation (UDA) aims to improve the classification
performance on an unlabeled target domain by leveraging information from a
fully labeled source domain. Recent approaches explore domain-invariant and
class-discriminant representations to tackle this task. These methods, however,
ignore the interaction between domain alignment learning and class
discrimination learning. As a result, the missing or inadequate tradeoff
between domain alignment and class discrimination are prone to the problem of
negative transfer. In this paper, we propose Dynamic Weighted Learning (DWL) to
avoid the discriminability vanishing problem caused by excessive alignment
learning and domain misalignment problem caused by excessive discriminant
learning. Technically, DWL dynamically weights the learning losses of alignment
and discriminability by introducing the degree of alignment and
discriminability. Besides, the problem of sample imbalance across domains is
first considered in our work, and we solve the problem by weighing the samples
to guarantee information balance across domains. Extensive experiments
demonstrate that DWL has an excellent performance in several benchmark
datasets.
</dc:description>
 <dc:description>Comment: This paper has been accepted by CVPR2021</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13814</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13815</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Approximate Spectral Normalization for Robust Deep Neural Networks</dc:title>
 <dc:creator>Pan, Zhixin</dc:creator>
 <dc:creator>Mishra, Prabhat</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Deep neural networks (DNNs) play an important role in machine learning due to
its outstanding performance compared to other alternatives. However, DNNs are
not suitable for safety-critical applications since DNNs can be easily fooled
by well-crafted adversarial examples. One promising strategy to counter
adversarial attacks is to utilize spectral normalization, which ensures that
the trained model has low sensitivity towards the disturbance of input samples.
Unfortunately, this strategy requires exact computation of spectral norm, which
is computation intensive and impractical for large-scale networks. In this
paper, we introduce an approximate algorithm for spectral normalization based
on Fourier transform and layer separation. The primary contribution of our work
is to effectively combine the sparsity of weight matrix and decomposability of
convolution layers. Extensive experimental evaluation demonstrates that our
framework is able to significantly improve both time efficiency (up to 60\%)
and model robustness (61\% on average) compared with the state-of-the-art
spectral normalization.
</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13815</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13816</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the relation between the degree of internationalization of cited and
  citing publications: A field level analysis, including and excluding
  self-citations</dc:title>
 <dc:creator>Abramo, Giovanni</dc:creator>
 <dc:creator>D'Angelo, Ciriaco Andrea</dc:creator>
 <dc:creator>Di Costa, Flavia</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  The growing complexity of scientific challenges demands increasingly intense
research collaboration, both domestic and international. The resulting trend
affects not only the modes of producing new knowledge, but also the way it is
disseminated within scientific communities. This paper analyses the
relationship between the &quot;degree of internationalization&quot; of a country's
scientific production and that of the relevant citing publications. The
empirical analysis is based on 2010-2012 Italian publications. Findings show:
i) the probability of being cited increases with the degree of
internationalization of the research team; ii) totally domestic research teams
tend to cite to a greater extent totally domestic publications; iii) vice
versa, publications resulting from international collaborations tend to be more
cited by totally foreign publications rather than by publications including
domestic authors. These results emerge both at overall and at discipline level.
Findings might inform research policies geared towards internationalization.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13816</dc:identifier>
 <dc:identifier>Journal of Informetrics, 2021, 15(1), 101101</dc:identifier>
 <dc:identifier>doi:10.1016/j.joi.2020.101101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13817</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The domestic localization of knowledge flows as evidenced by publication
  citation: The case of Italy</dc:title>
 <dc:creator>Abramo, Giovanni</dc:creator>
 <dc:creator>D'Angelo, Ciriaco Andrea</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  This work applies a new approach to measure knowledge flows. Assuming that
citation linkages between articles imply a flow of knowledge from the cited to
the citing authors, we investigate the geographic flows of scientific knowledge
produced in Italy across its regions, at both overall and field level.
Furthermore, we measure the the specialization indexes for outflows and inflows
of knowledge by a given region. Findings show that larger regions in terms of
research output are more likely net exporters of new knowledge. At the same
time, we register a positive correlation between the share of intraregional
flows and the size of overall scientific output of a region.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1909.08911</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13817</dc:identifier>
 <dc:identifier>The case of Italy. Scientometrics, 125(2), 1305-1329</dc:identifier>
 <dc:identifier>doi:10.1007/s11192-020-03487-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13818</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Informed peer review for publication assessments: Are improved impact
  measures worth the hassle?</dc:title>
 <dc:creator>Abramo, Giovanni</dc:creator>
 <dc:creator>D'Angelo, Ciriaco Andrea</dc:creator>
 <dc:creator>Felici, Giovanni</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  In this work we ask whether and to what extent applying a predictor of
publications' impact better than early citations, has an effect on the
assessment of research performance of individual scientists. Specifically, we
measure the total impact of Italian professors in the sciences and economics in
a period of time, valuing their publications first by early citations and then
by a weighted combination of early citations and impact factor of the hosting
journal. As expected, scores and ranks by the two indicators show a very strong
correlation, but there occur also significant shifts in many fields, mainly in
Economics and statistics, and Mathematics and computer science. The higher the
share of uncited professors in a field and the shorter the citation time
window, the more recommendable the recourse to the above combination.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13818</dc:identifier>
 <dc:identifier>Quantitative Science Studies, 1(3), 1321-1333 (2020)</dc:identifier>
 <dc:identifier>doi:10.1162/qss_a_00051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13819</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge spillovers: does the geographic proximity effect decay over
  time? A discipline-level analysis, accounting for cognitive proximity, with
  and without self-citations</dc:title>
 <dc:creator>Abramo, Giovanni</dc:creator>
 <dc:creator>D'Angelo, Ciriaco Andrea</dc:creator>
 <dc:creator>Di Costa, Flavia</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  This work analyzes the variation over time of the effect of geographic
distance on knowledge flows. The flows are measured through the citations
exchanged between scientific publications, including and excluding
self-citations. To calculate geographic distances between citing and cited
publication, each publication is associated with a &quot;prevailing&quot; territory,
according to the authors' affiliations. We then apply a gravity model to
account for the research size of the territories, in terms of cognitive
proximity of citing-cited publications. The field of observation is the
2010-2017 world publications citing the 2010-2012 Italian publications, as
indexed in the Web of Science. The results show that in domestic knowledge
flows, geographic proximity remains an influential factor through time,
although with differences among disciplines and trends of attenuating effects.
Finally, we replicate the analyses of knowledge flows but with the exclusion of
self-citations: in this manner the effect of geographic proximity seems
reduced, particularly at the national scale, but the differences (with vs
without self-citations) lessen through time. As shown in previous works, the
effect of distance on continental flows is modest (imperceptible for
intercontinental flows), yet here too time has some influence, including
concerning exclusion of self-citations.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13819</dc:identifier>
 <dc:identifier>Journal of Informetrics, 14(4), 2020, 101072</dc:identifier>
 <dc:identifier>doi:10.1016/j.joi.2020.101072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13820</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CNN vs ELM for Image-Based Malware Classification</dc:title>
 <dc:creator>Jain, Mugdha</dc:creator>
 <dc:creator>Andreopoulos, William</dc:creator>
 <dc:creator>Stamp, Mark</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Research in the field of malware classification often relies on machine
learning models that are trained on high-level features, such as opcodes,
function calls, and control flow graphs. Extracting such features is costly,
since disassembly or code execution is generally required. In this paper, we
conduct experiments to train and evaluate machine learning models for malware
classification, based on features that can be obtained without disassembly or
execution of code. Specifically, we visualize malware samples as images and
employ image analysis techniques. In this context, we focus on two machine
learning models, namely, Convolutional Neural Networks (CNN) and Extreme
Learning Machines (ELM). Surprisingly, we find that ELMs can achieve accuracies
on par with CNNs, yet ELM training requires less than~2\%\ of the time needed
to train a comparable CNN.
</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13820</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13823</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Adaptive Minority Oversampling Technique for Improved
  Classification in Data Imbalanced Scenarios</dc:title>
 <dc:creator>Tripathi, Ayush</dc:creator>
 <dc:creator>Chakraborty, Rupayan</dc:creator>
 <dc:creator>Kopparapu, Sunil Kumar</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Imbalance in the proportion of training samples belonging to different
classes often poses performance degradation of conventional classifiers. This
is primarily due to the tendency of the classifier to be biased towards the
majority classes in the imbalanced dataset. In this paper, we propose a novel
three step technique to address imbalanced data. As a first step we
significantly oversample the minority class distribution by employing the
traditional Synthetic Minority OverSampling Technique (SMOTE) algorithm using
the neighborhood of the minority class samples and in the next step we
partition the generated samples using a Gaussian-Mixture Model based clustering
algorithm. In the final step synthetic data samples are chosen based on the
weight associated with the cluster, the weight itself being determined by the
distribution of the majority class samples. Extensive experiments on several
standard datasets from diverse domains shows the usefulness of the proposed
technique in comparison with the original SMOTE and its state-of-the-art
variants algorithms.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13823</dc:identifier>
 <dc:identifier>ICPR 2020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13826</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prototyping and Evaluation of Infrastructure-Assisted Transition of
  Control for Cooperative Automated Vehicles</dc:title>
 <dc:creator>Coll-Perales, Baldomero</dc:creator>
 <dc:creator>Schulte-Tigges, Joschua</dc:creator>
 <dc:creator>Rondinone, Michele</dc:creator>
 <dc:creator>Gozalvez, Javier</dc:creator>
 <dc:creator>Reke, Michael</dc:creator>
 <dc:creator>Matheis, Dominik</dc:creator>
 <dc:creator>Walter, Thomas</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Automated driving is now possible in diverse road and traffic conditions.
However, there are still situations that automated vehicles cannot handle
safely and efficiently. In this case, a Transition of Control (ToC) is
necessary so that the driver takes control of the driving. Executing a ToC
requires the driver to get full situation awareness of the driving environment.
If the driver fails to get back the control in a limited time, a Minimum Risk
Maneuver (MRM) is executed to bring the vehicle into a safe state (e.g.,
decelerating to full stop). The execution of ToCs requires some time and can
cause traffic disruption and safety risks that increase if several vehicles
execute ToCs/MRMs at similar times and in the same area. This study proposes to
use novel C-ITS traffic management measures where the infrastructure exploits
V2X communications to assist Connected and Automated Vehicles (CAVs) in the
execution of ToCs. The infrastructure can suggest a spatial distribution of
ToCs, and inform vehicles of the locations where they could execute a safe stop
in case of MRM. This paper reports the first field operational tests that
validate the feasibility and quantify the benefits of the proposed
infrastructure-assisted ToC and MRM management. The paper also presents the CAV
and roadside infrastructure prototypes implemented and used in the trials. The
conducted field trials demonstrate that infrastructure-assisted traffic
management solutions can reduce safety risks and traffic disruptions.
</dc:description>
 <dc:description>Comment: 16 pages, 15 figures, 3 tables. in IEEE Transactions on Intelligent
  Transportation Systems, 04 March 2021 (Early Access)</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13826</dc:identifier>
 <dc:identifier>doi:10.1109/TITS.2021.3061085</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13827</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Empirical Analysis of Image-Based Learning Techniques for Malware
  Classification</dc:title>
 <dc:creator>Prajapati, Pratikkumar</dc:creator>
 <dc:creator>Stamp, Mark</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In this paper, we consider malware classification using deep learning
techniques and image-based features. We employ a wide variety of deep learning
techniques, including multilayer perceptrons (MLP), convolutional neural
networks (CNN), long short-term memory (LSTM), and gated recurrent units (GRU).
Amongst our CNN experiments, transfer learning plays a prominent role
specifically, we test the VGG-19 and ResNet152 models. As compared to previous
work, the results presented in this paper are based on a larger and more
diverse malware dataset, we consider a wider array of features, and we
experiment with a much greater variety of learning techniques. Consequently,
our results are the most comprehensive and complete that have yet been
published.
</dc:description>
 <dc:description>Comment: 20 pages, 8 figures, 7 tables</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13827</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13830</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Objective $H_{\infty}$ Control for String Stability of Cooperative
  Adaptive Cruise Control Systems</dc:title>
 <dc:creator>Kayacan, Erkan</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Autonomous vehicle following systems are playing a decisive role to increase
vehicle density on roads by shortening inter-vehicle time gaps. However,
disturbance attenuation along a platoon of vehicles, i.e., string stability, is
being a challenging task while time gap is getting shorter. In order to
guarantee the string stability of a vehicle platoon, a multi-objective
$H_{\infty}$ control formulation for adaptive cruise control and cooperative
adaptive cruise control structures has been investigated in this paper. The
proposed control method solves an optimization problem and achieves a
controller that is able to provide not only the system stability, but also the
string stability as distinct from the traditional $H_{\infty}$ control.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13830</dc:identifier>
 <dc:identifier>IEEE Transactions on Intelligent Vehicles, Volume 2, Issue 1, 2017</dc:identifier>
 <dc:identifier>doi:10.1109/TIV.2017.2708607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13831</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterization and computation of control invariant sets within target
  regions for linear impulsive control systems</dc:title>
 <dc:creator>Sanchez, Ignacio</dc:creator>
 <dc:creator>Louembet, Christophe</dc:creator>
 <dc:creator>Actis, Marcelo</dc:creator>
 <dc:creator>Gonzalez, Alejandro H.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Linear impulsively controlled systems are suitable to describe a venue of
real-life problems, going from disease treatment to aerospace guidance. The
main characteristic of such systems is that they remain uncontrolled for
certain periods of time. As a consequence, punctual equilibria
characterizations outside the origin are no longer useful, and the whole
concept of equilibrium and its natural extension, the controlled invariant
sets, needs to be redefined. Also, an exact characterization of the admissible
states, i.e., states such that their uncontrolled evolution between impulse
times remain within a predefined set, is required. An approach to such tasks --
based on the Markov-Lukasz theorem -- is presented, providing a tractable and
non-conservative characterization, emerging from polynomial positivity that has
application to systems with rational eigenvalues. This is in turn the basis for
obtaining a tractable approximation to the maximal admissible invariant sets.
In this work, it is also demonstrated that, in order for the problem to have a
solution, an invariant set (and moreover, an equilibrium set) must be contained
within the target zone. To assess the proposal, the so-obtained impulsive
invariant set is explicitly used in the formulation of a set-based model
predictive controller, with application to zone tracking. In this context,
specific MPC theory needs to be considered, as the target is not necessarily
stable in the sense of Lyapunov. A zone MPC formulation is proposed, which is
able to i) track an invariant set such that the uncontrolled propagation
fulfills the zone constraint at all times and ii) converge asymptotically to
the set of periodic orbits completely contained within the target zone.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13831</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13832</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Cost of OSCORE and EDHOC for Constrained Devices</dc:title>
 <dc:creator>Hristozov, Stefan</dc:creator>
 <dc:creator>Huber, Manuel</dc:creator>
 <dc:creator>Xu, Lei</dc:creator>
 <dc:creator>Fietz, Jaro</dc:creator>
 <dc:creator>Liess, Marco</dc:creator>
 <dc:creator>Sigl, Georg</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Many modern IoT applications rely on the Constrained Application Protocol
(CoAP) because of its efficiency and seamless integrability in the existing
Internet infrastructure. One of the strategies that CoAP leverages to achieve
these characteristics is the usage of proxies. Unfortunately, in order for a
proxy to operate, it needs to terminate the (D)TLS channels between clients and
servers. Therefore, end-to-end confidentiality, integrity and authenticity of
the exchanged data cannot be achieved. In order to overcome this problem, an
alternative to (D)TLS was recently proposed by the Internet Engineering Task
Force (IETF). This alternative consists of two novel protocols: 1) Object
Security for Constrained RESTful Environments (OSCORE) providing authenticated
encryption for the payload data and 2) Ephemeral Diffie-Hellman Over COSE
(EDHOC) providing the symmetric session keys required for OSCORE. In this
paper, we present the design of four firmware libraries for these protocols
especially targeted for constrained microcontrollers and their detailed
evaluation. More precisely, we present the design of uOSCORE and uEDHOC
libraries for regular microcontrollers and uOSCORE-TEE and uEDHOC-TEE libraries
for microcontrollers with a Trusted Execution Environment (TEE), such as
microcontrollers featuring ARM TrustZone-M. Our firmware design for the later
class of devices concerns the fact that attackers may exploit common software
vulnerabilities, e.g., buffer overflows in the protocol logic, OS or
application to compromise the protocol security. uOSCORE-TEE and uEDHOC-TEE
achieve separation of the cryptographic operations and keys from the remainder
of the firmware, which could be vulnerable. We present an evaluation of our
implementations in terms of RAM/FLASH requirements, execution speed and energy
on a broad range of microcontrollers.
</dc:description>
 <dc:description>Comment: A short version of this paper will appear on CODASPY 2021</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13832</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13834</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Imitation Learning by Planning</dc:title>
 <dc:creator>Luo, Sha</dc:creator>
 <dc:creator>Kasaei, Hamidreza</dc:creator>
 <dc:creator>Schomaker, Lambert</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Imitation learning (IL) enables robots to acquire skills quickly by
transferring expert knowledge, which is widely adopted in reinforcement
learning (RL) to initialize exploration. However, in long-horizon motion
planning tasks, a challenging problem in deploying IL and RL methods is how to
generate and collect massive, broadly distributed data such that these methods
can generalize effectively. In this work, we solve this problem using our
proposed approach called {self-imitation learning by planning (SILP)}, where
demonstration data are collected automatically by planning on the visited
states from the current policy. SILP is inspired by the observation that
successfully visited states in the early reinforcement learning stage are
collision-free nodes in the graph-search based motion planner, so we can plan
and relabel robot's own trials as demonstrations for policy learning. Due to
these self-generated demonstrations, we relieve the human operator from the
laborious data preparation process required by IL and RL methods in solving
complex motion planning tasks. The evaluation results show that our SILP method
achieves higher success rates and enhances sample efficiency compared to
selected baselines, and the policy learned in simulation performs well in a
real-world placement task with changing goals and obstacles.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13834</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13835</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Space-time hexahedral finite element methods for parabolic evolution
  problems</dc:title>
 <dc:creator>Langer, Ulrich</dc:creator>
 <dc:creator>Schafelner, Andreas</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>35K20, 65M60, 65M50, 65M15</dc:subject>
 <dc:description>  We present locally stabilized, conforming space-time finite element methods
for parabolic evolution equations on hexahedral decompositions of the
space-time cylinder. Tensor-product decompositions allow for anisotropic a
priori error estimates, that are explicit in spatial and temporal meshsizes.
Moreover, tensor-product finite elements are suitable for anisotropic adaptive
mesh refinement strategies provided that an appropriate a posteriori
discretization error estimator is available. We present such anisotropic
adaptive strategies together with numerical experiments.
</dc:description>
 <dc:description>Comment: 8 pages, 1 figure</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13841</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Universal Representation Learning from Multiple Domains for Few-shot
  Classification</dc:title>
 <dc:creator>Li, Wei-Hong</dc:creator>
 <dc:creator>Liu, Xialei</dc:creator>
 <dc:creator>Bilen, Hakan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we look at the problem of few-shot classification that aims to
learn a classifier for previously unseen classes and domains from few labeled
samples. Recent methods use adaptation networks for aligning their features to
new domains or select the relevant features from multiple domain-specific
feature extractors. In this work, we propose to learn a single set of universal
deep representations by distilling knowledge of multiple separately trained
networks after co-aligning their features with the help of adapters and
centered kernel alignment. We show that the universal representations can be
further refined for previously unseen domains by an efficient adaptation step
in a similar spirit to distance learning methods. We rigorously evaluate our
model in the recent Meta-Dataset benchmark and demonstrate that it
significantly outperforms the previous methods while being more efficient. Our
code will be available at https://github.com/VICO-UoE/URL.
</dc:description>
 <dc:description>Comment: Code will be available at https://github.com/VICO-UoE/URL</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13841</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13843</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OTCE: A Transferability Metric for Cross-Domain Cross-Task
  Representations</dc:title>
 <dc:creator>Tan, Yang</dc:creator>
 <dc:creator>Li, Yang</dc:creator>
 <dc:creator>Huang, Shao-Lun</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Transfer learning across heterogeneous data distributions (a.k.a. domains)
and distinct tasks is a more general and challenging problem than conventional
transfer learning, where either domains or tasks are assumed to be the same.
While neural network based feature transfer is widely used in transfer learning
applications, finding the optimal transfer strategy still requires
time-consuming experiments and domain knowledge. We propose a transferability
metric called Optimal Transport based Conditional Entropy (OTCE), to
analytically predict the transfer performance for supervised classification
tasks in such cross-domain and cross-task feature transfer settings. Our OTCE
score characterizes transferability as a combination of domain difference and
task difference, and explicitly evaluates them from data in a unified
framework. Specifically, we use optimal transport to estimate domain difference
and the optimal coupling between source and target distributions, which is then
used to derive the conditional entropy of the target task (task difference).
Experiments on the largest cross-domain dataset DomainNet and Office31
demonstrate that OTCE shows an average of 21% gain in the correlation with the
ground truth transfer accuracy compared to state-of-the-art methods. We also
investigate two applications of the OTCE score including source model selection
and multi-source feature fusion.
</dc:description>
 <dc:description>Comment: 13 pages, accepted by CVPR2021</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13843</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13850</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Autism Spectrum Disorder Screening Using Discriminative Brain
  Sub-Networks: An Entropic Approach</dc:title>
 <dc:creator>Amin, Mohammad</dc:creator>
 <dc:creator>Safaei, Farshad</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Autism is one of the most important neurological disorders which leads to
problems in a person's social interactions. Improvement of brain imaging
technologies and techniques help us to build brain structural and functional
networks. Finding networks topology pattern in each of the groups (autism and
healthy control) can aid us to achieve an autism disorder screening model. In
the present study, we have utilized the genetic algorithm to extract a
discriminative sub-network that represents differences between two groups
better. In the fitness evaluation phase, for each sub-network, a machine
learning model was trained using various entropy features of the sub-network
and its performance was measured. Proper model performance implies extracting a
good discriminative sub-network. Network entropies can be used as network
topological descriptors. The evaluation results indicate the acceptable
performance of the proposed screening method based on extracted discriminative
sub-networks and the machine learning models succeeded in obtaining a maximum
accuracy of 73.1% in structural networks of the UCLA dataset, 82.2% in
functional networks of the UCLA dataset, and 66.1% in functional networks of
ABIDE datasets.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13850</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13851</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Deep CNN Feature Set-Based Representation Learning for
  Robust Cross-Resolution Face Recognition</dc:title>
 <dc:creator>Gao, Guangwei</dc:creator>
 <dc:creator>Yu, Yi</dc:creator>
 <dc:creator>Yang, Jian</dc:creator>
 <dc:creator>Qi, Guo-Jun</dc:creator>
 <dc:creator>Yang, Meng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Cross-resolution face recognition (CRFR), which is important in intelligent
surveillance and biometric forensics, refers to the problem of matching a
low-resolution (LR) probe face image against high-resolution (HR) gallery face
images. Existing shallow learning-based and deep learning-based methods focus
on mapping the HR-LR face pairs into a joint feature space where the resolution
discrepancy is mitigated. However, little works consider how to extract and
utilize the intermediate discriminative features from the noisy LR query faces
to further mitigate the resolution discrepancy due to the resolution
limitations. In this study, we desire to fully exploit the multi-level deep
convolutional neural network (CNN) feature set for robust CRFR. In particular,
our contributions are threefold. (i) To learn more robust and discriminative
features, we desire to adaptively fuse the contextual features from different
layers. (ii) To fully exploit these contextual features, we design a feature
set-based representation learning (FSRL) scheme to collaboratively represent
the hierarchical features for more accurate recognition. Moreover, FSRL
utilizes the primitive form of feature maps to keep the latent structural
information, especially in noisy cases. (iii) To further promote the
recognition performance, we desire to fuse the hierarchical recognition outputs
from different stages. Meanwhile, the discriminability from different scales
can also be fully integrated. By exploiting these advantages, the efficiency of
the proposed method can be delivered. Experimental results on several face
datasets have verified the superiority of the presented algorithm to the other
competitive CRFR approaches.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Circuits and Systems for Video Technology, 11
  pages, 9 figures</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13851</dc:identifier>
 <dc:identifier>doi:10.1109/TCSVT.2020.3042178</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13865</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Model to Appraise and Suggest Identifier Names</dc:title>
 <dc:creator>Peruma, Anthony</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Unknowingly, identifiers in the source code of a software system play a vital
role in determining the quality of the system. Ambiguous and confusing
identifier names lead developers to not only misunderstand the behavior of the
code but also increases comprehension time and thereby causes a loss in
productivity. Even though correcting poor names through rename operations is a
viable option for solving this problem, renaming itself is an act of rework and
is not immune to defect injection.
  In this study, we aim to understand the motivations that drive developers to
name and rename identifiers and the decisions they make in determining the
name. Using our results, we propose the development of a linguistic model that
determines identifier names based on the behavior of the identifier. As a
prerequisite to constructing the model, we conduct multiple studies to
determine the features that should feed into the model. In this paper, we
discuss findings from our completed studies and justify the continuation of
research on this topic through further studies.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13865</dc:identifier>
 <dc:identifier>doi:10.1109/ICSME.2019.00103</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13868</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Equality before the Law: Legal Judgment Consistency Analysis for
  Fairness</dc:title>
 <dc:creator>Wang, Yuzhong</dc:creator>
 <dc:creator>Xiao, Chaojun</dc:creator>
 <dc:creator>Ma, Shirong</dc:creator>
 <dc:creator>Zhong, Haoxi</dc:creator>
 <dc:creator>Tu, Cunchao</dc:creator>
 <dc:creator>Zhang, Tianyang</dc:creator>
 <dc:creator>Liu, Zhiyuan</dc:creator>
 <dc:creator>Sun, Maosong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In a legal system, judgment consistency is regarded as one of the most
important manifestations of fairness. However, due to the complexity of factual
elements that impact sentencing in real-world scenarios, few works have been
done on quantitatively measuring judgment consistency towards real-world data.
In this paper, we propose an evaluation metric for judgment inconsistency,
Legal Inconsistency Coefficient (LInCo), which aims to evaluate inconsistency
between data groups divided by specific features (e.g., gender, region, race).
We propose to simulate judges from different groups with legal judgment
prediction (LJP) models and measure the judicial inconsistency with the
disagreement of the judgment results given by LJP models trained on different
groups. Experimental results on the synthetic data verify the effectiveness of
LInCo. We further employ LInCo to explore the inconsistency in real cases and
come to the following observations: (1) Both regional and gender inconsistency
exist in the legal system, but gender inconsistency is much less than regional
inconsistency; (2) The level of regional inconsistency varies little across
different time periods; (3) In general, judicial inconsistency is negatively
correlated with the severity of the criminal charges. Besides, we use LInCo to
evaluate the performance of several de-bias methods, such as adversarial
learning, and find that these mechanisms can effectively help LJP models to
avoid suffering from data bias.
</dc:description>
 <dc:description>Comment: 15 pages, 4 figures, 10 tables</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13868</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13871</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impact of the COVID-19 outbreak on Italy's country reputation and stock
  market performance: a sentiment analysis approach</dc:title>
 <dc:creator>Zammarchi, Gianpaolo</dc:creator>
 <dc:creator>Mola, Francesco</dc:creator>
 <dc:creator>Conversano, Claudio</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  During the recent Coronavirus disease 2019 (COVID-19) outbreak, the
microblogging service Twitter has been widely used to share opinions and
reactions to events. Italy was one of the first European countries to be
severely affected by the outbreak and to establish lockdown and stay-at-home
orders, potentially leading to country reputation damage. We resort to
sentiment analysis to investigate changes in opinions about Italy reported on
Twitter before and after the COVID-19 outbreak. Using different lexicons-based
methods, we find a breakpoint corresponding to the date of the first
established case of COVID-19 in Italy that causes a relevant change in
sentiment scores used as proxy of the country reputation. Next, we demonstrate
that sentiment scores about Italy are strongly associated with the levels of
the FTSE-MIB index, the Italian Stock Exchange main index, as they serve as
early detection signals of changes in the values of FTSE-MIB. Finally, we make
a content-based classification of tweets into positive and negative and use two
machine learning classifiers to validate the assigned polarity of tweets posted
before and after the outbreak.
</dc:description>
 <dc:description>Comment: 25 pages, 8 figures</dc:description>
 <dc:date>2021-03-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13871</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13872</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transform consistency for learning with noisy labels</dc:title>
 <dc:creator>Yi, Rumeng</dc:creator>
 <dc:creator>Huang, Yaping</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  It is crucial to distinguish mislabeled samples for dealing with noisy
labels. Previous methods such as Coteaching and JoCoR introduce two different
networks to select clean samples out of the noisy ones and only use these clean
ones to train the deep models. Different from these methods which require to
train two networks simultaneously, we propose a simple and effective method to
identify clean samples only using one single network. We discover that the
clean samples prefer to reach consistent predictions for the original images
and the transformed images while noisy samples usually suffer from inconsistent
predictions. Motivated by this observation, we introduce to constrain the
transform consistency between the original images and the transformed images
for network training, and then select small-loss samples to update the
parameters of the network. Furthermore, in order to mitigate the negative
influence of noisy labels, we design a classification loss by using the
off-line hard labels and on-line soft labels to provide more reliable
supervisions for training a robust model. We conduct comprehensive experiments
on CIFAR-10, CIFAR-100 and Clothing1M datasets. Compared with the baselines, we
achieve the state-of-the-art performance. Especially, in most cases, our
proposed method outperforms the baselines by a large margin.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13873</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inferring Latent Domains for Unsupervised Deep Domain Adaptation</dc:title>
 <dc:creator>Mancini, Massimiliano</dc:creator>
 <dc:creator>Porzi, Lorenzo</dc:creator>
 <dc:creator>Bul&#xf2;, Samuel Rota</dc:creator>
 <dc:creator>Caputo, Barbara</dc:creator>
 <dc:creator>Ricci, Elisa</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Unsupervised Domain Adaptation (UDA) refers to the problem of learning a
model in a target domain where labeled data are not available by leveraging
information from annotated data in a source domain. Most deep UDA approaches
operate in a single-source, single-target scenario, i.e. they assume that the
source and the target samples arise from a single distribution. However, in
practice most datasets can be regarded as mixtures of multiple domains. In
these cases, exploiting traditional single-source, single-target methods for
learning classification models may lead to poor results. Furthermore, it is
often difficult to provide the domain labels for all data points, i.e. latent
domains should be automatically discovered. This paper introduces a novel deep
architecture which addresses the problem of UDA by automatically discovering
latent domains in visual datasets and exploiting this information to learn
robust target classifiers. Specifically, our architecture is based on two main
components, i.e. a side branch that automatically computes the assignment of
each sample to its latent domain and novel layers that exploit domain
membership information to appropriately align the distribution of the CNN
internal feature representations to a reference distribution. We evaluate our
approach on publicly available benchmarks, showing that it outperforms
state-of-the-art domain adaptation methods.
</dc:description>
 <dc:description>Comment: IEEE T-PAMI, https://ieeexplore.ieee.org/document/8792192</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13873</dc:identifier>
 <dc:identifier>doi:10.1109/TPAMI.2019.2933829</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13878</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Physics-Informed Neural Network Framework For Partial Differential
  Equations on 3D Surfaces: Time-Dependent Problems</dc:title>
 <dc:creator>Fang, Zhiwei</dc:creator>
 <dc:creator>Zhang, Justin</dc:creator>
 <dc:creator>Yang, Xiu</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  In this paper, we show a physics-informed neural network solver for the
time-dependent surface PDEs. Unlike the traditional numerical solver, no
extension of PDE and mesh on the surface is needed. We show a simplified prior
estimate of the surface differential operators so that PINN's loss value will
be an indicator of the residue of the surface PDEs. Numerical experiments
verify efficacy of our algorithm.
</dc:description>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13878</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13879</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Examining mobility data justice during 2017 Hurricane Harvey</dc:title>
 <dc:creator>Deng, Hengfang</dc:creator>
 <dc:creator>Wang, Qi</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Natural disasters can significantly disrupt human mobility in urban areas.
Studies have attempted to understand and quantify such disruptions using
crowdsourced mobility data sets. However, limited research has studied the
justice issues of mobility data in the context of natural disasters. The lack
of research leaves us without an empirical foundation to quantify and control
the possible biases in the data. This study, using 2017 Hurricane Harvey as a
case study, explores three aspects of mobility data that could potentially
cause injustice: representativeness, quality, and precision. We find
representativeness being a major factor contributing to mobility data
injustice. There is a persistent disparity of representativeness across
neighborhoods of different socioeconomic characteristics before, during, and
after the hurricane's landfall. Additionally, we observed significant drops of
data precision during the hurricane, adding uncertainty to locate people and
understand their movements during extreme weather events. The findings
highlight the necessity in understanding and controlling the possible bias of
mobility data as well as developing practical tools through data justice lenses
in collecting and analyzing data during disasters.
</dc:description>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13879</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13882</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>If You Must Choose Among Your Children, Pick the Right One</dc:title>
 <dc:creator>Holmgren, Benjamin</dc:creator>
 <dc:creator>McCoy, Bradley</dc:creator>
 <dc:creator>Fasy, Brittany</dc:creator>
 <dc:creator>Millman, David</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:description>  Given a simplicial complex $K$ and an injective function $f$ from the
vertices of $K$ to $\mathbb{R}$, we consider algorithms that extend $f$ to a
discrete Morse function on $K$. We show that an algorithm of King, Knudson and
Mramor can be described on the directed Hasse diagram of $K$. Our description
has a faster runtime for high dimensional data with no increase in space.
</dc:description>
 <dc:description>Comment: Proceedings of the Canadian Conference on Computational Geometry,
  2020</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13882</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13883</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Risk Bounds and Rademacher Complexity in Batch Reinforcement Learning</dc:title>
 <dc:creator>Duan, Yaqi</dc:creator>
 <dc:creator>Jin, Chi</dc:creator>
 <dc:creator>Li, Zhiyuan</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper considers batch Reinforcement Learning (RL) with general value
function approximation. Our study investigates the minimal assumptions to
reliably estimate/minimize Bellman error, and characterizes the generalization
performance by (local) Rademacher complexities of general function classes,
which makes initial steps in bridging the gap between statistical learning
theory and batch RL. Concretely, we view the Bellman error as a surrogate loss
for the optimality gap, and prove the followings: (1) In double sampling
regime, the excess risk of Empirical Risk Minimizer (ERM) is bounded by the
Rademacher complexity of the function class. (2) In the single sampling regime,
sample-efficient risk minimization is not possible without further assumptions,
regardless of algorithms. However, with completeness assumptions, the excess
risk of FQI and a minimax style algorithm can be again bounded by the
Rademacher complexity of the corresponding function classes. (3) Fast
statistical rates can be achieved by using tools of local Rademacher
complexity. Our analysis covers a wide range of function classes, including
finite classes, linear spaces, kernel spaces, sparse linear features, etc.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13883</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13886</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust and Accurate Object Detection via Adversarial Learning</dc:title>
 <dc:creator>Chen, Xiangning</dc:creator>
 <dc:creator>Xie, Cihang</dc:creator>
 <dc:creator>Tan, Mingxing</dc:creator>
 <dc:creator>Zhang, Li</dc:creator>
 <dc:creator>Hsieh, Cho-Jui</dc:creator>
 <dc:creator>Gong, Boqing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Data augmentation has become a de facto component for training
high-performance deep image classifiers, but its potential is under-explored
for object detection. Noting that most state-of-the-art object detectors
benefit from fine-tuning a pre-trained classifier, we first study how the
classifiers' gains from various data augmentations transfer to object
detection. The results are discouraging; the gains diminish after fine-tuning
in terms of either accuracy or robustness. This work instead augments the
fine-tuning stage for object detectors by exploring adversarial examples, which
can be viewed as a model-dependent data augmentation. Our method dynamically
selects the stronger adversarial images sourced from a detector's
classification and localization branches and evolves with the detector to
ensure the augmentation policy stays current and relevant. This model-dependent
augmentation generalizes to different object detectors better than AutoAugment,
a model-agnostic augmentation policy searched based on one particular detector.
Our approach boosts the performance of state-of-the-art EfficientDets by +1.1
mAP on the COCO object detection benchmark. It also improves the detectors'
robustness against natural distortions by +3.8 mAP and against domain shift by
+1.3 mAP. Models are available at
https://github.com/google/automl/tree/master/efficientdet/Det-AdvProp.md
</dc:description>
 <dc:description>Comment: CVPR 2021. Models are available at
  https://github.com/google/automl/tree/master/efficientdet/Det-AdvProp.md</dc:description>
 <dc:date>2021-03-23</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13886</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13887</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Imitation Learning with Trajectorial Augmentation and
  Correction</dc:title>
 <dc:creator>Antotsiou, Dafni</dc:creator>
 <dc:creator>Ciliberto, Carlo</dc:creator>
 <dc:creator>Kim, Tae-Kyun</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Deep Imitation Learning requires a large number of expert demonstrations,
which are not always easy to obtain, especially for complex tasks. A way to
overcome this shortage of labels is through data augmentation. However, this
cannot be easily applied to control tasks due to the sequential nature of the
problem. In this work, we introduce a novel augmentation method which preserves
the success of the augmented trajectories. To achieve this, we introduce a
semi-supervised correction network that aims to correct distorted expert
actions. To adequately test the abilities of the correction network, we develop
an adversarial data augmented imitation architecture to train an imitation
agent using synthetic experts. Additionally, we introduce a metric to measure
diversity in trajectory datasets. Experiments show that our data augmentation
strategy can improve accuracy and convergence time of adversarial imitation
while preserving the diversity between the generated and real trajectories.
</dc:description>
 <dc:description>Comment: Accepted in ICRA 2021</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13894</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boosting Binary Masks for Multi-Domain Learning through Affine
  Transformations</dc:title>
 <dc:creator>Mancini, Massimiliano</dc:creator>
 <dc:creator>Ricci, Elisa</dc:creator>
 <dc:creator>Caputo, Barbara</dc:creator>
 <dc:creator>Bul&#xf3;, Samuel Rota</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we present a new, algorithm for multi-domain learning. Given a
pretrained architecture and a set of visual domains received sequentially, the
goal of multi-domain learning is to produce a single model performing a task in
all the domains together. Recent works showed how we can address this problem
by masking the internal weights of a given original conv-net through learned
binary variables. In this work, we provide a general formulation of binary mask
based models for multi-domain learning by affine transformations of the
original network parameters. Our formulation obtains significantly higher
levels of adaptation to new domains, achieving performances comparable to
domain-specific models while requiring slightly more than 1 bit per network
parameter per additional domain. Experiments on two popular benchmarks showcase
the power of our approach, achieving performances close to state-of-the-art
methods on the Visual Decathlon Challenge.
</dc:description>
 <dc:description>Comment: Accepted for publication by Machine Vision and Applications on May
  21, 2020. arXiv admin note: substantial text overlap with arXiv:1805.11119</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13894</dc:identifier>
 <dc:identifier>doi:10.1007/S00138-020-01090-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13901</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measure Theoretic Weighted Model Integration</dc:title>
 <dc:creator>Miosic, Ivan</dc:creator>
 <dc:creator>Martires, Pedro Zuidberg Dos</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Weighted model counting (WMC) is a popular framework to perform probabilistic
inference with discrete random variables. Recently, WMC has been extended to
weighted model integration (WMI) in order to additionally handle continuous
variables. At their core, WMI problems consist of computing integrals and sums
over weighted logical formulas. From a theoretical standpoint, WMI has been
formulated by patching the sum over weighted formulas, which is already present
in WMC, with Riemann integration. A more principled approach to integration,
which is rooted in measure theory, is Lebesgue integration. Lebesgue
integration allows one to treat discrete and continuous variables on equal
footing in a principled fashion. We propose a theoretically sound measure
theoretic formulation of weighted model integration, which naturally reduces to
weighted model counting in the absence of continuous variables. Instead of
regarding weighted model integration as an extension of weighted model
counting, WMC emerges as a special case of WMI in our formulation.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13901</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13902</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Near Real-time Learning and Extraction of Attack Models from Intrusion
  Alerts</dc:title>
 <dc:creator>Yang, Shanchieh Jay</dc:creator>
 <dc:creator>Okutan, Ahmet</dc:creator>
 <dc:creator>Werner, Gordon</dc:creator>
 <dc:creator>Su, Shao-Hsuan</dc:creator>
 <dc:creator>Goel, Ayush</dc:creator>
 <dc:creator>Cahill, Nathan D.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Critical and sophisticated cyberattacks often take multitudes of
reconnaissance, exploitations, and obfuscation techniques to penetrate through
well protected enterprise networks. The discovery and detection of attacks,
though needing continuous efforts, is no longer sufficient. Security Operation
Center (SOC) analysts are overwhelmed by the significant volume of intrusion
alerts without being able to extract actionable intelligence. Recognizing this
challenge, this paper describes the advances and findings through deploying
ASSERT to process intrusion alerts from OmniSOC in collaboration with the
Center for Applied Cybersecurity Research (CACR) at Indiana University. ASSERT
utilizes information theoretic unsupervised learning to extract and update
`attack models' in near real-time without expert knowledge. It consumes
streaming intrusion alerts and generates a small number of statistical models
for SOC analysts to comprehend ongoing and emerging attacks in a timely manner.
This paper presents the architecture and key processes of ASSERT and discusses
a few real-world attack models to highlight the use-cases that benefit SOC
operations. The research team is developing a light-weight containerized ASSERT
that will be shared through a public repository to help the community combat
the overwhelming intrusion alerts.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13902</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13905</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>StyleLess layer: Improving robustness for real-world driving</dc:title>
 <dc:creator>Rebut, Julien</dc:creator>
 <dc:creator>Bursuc, Andrei</dc:creator>
 <dc:creator>P&#xe9;rez, Patrick</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep Neural Networks (DNNs) are a critical component for self-driving
vehicles. They achieve impressive performance by reaping information from high
amounts of labeled data. Yet, the full complexity of the real world cannot be
encapsulated in the training data, no matter how big the dataset, and DNNs can
hardly generalize to unseen conditions. Robustness to various image
corruptions, caused by changing weather conditions or sensor degradation and
aging, is crucial for safety when such vehicles are deployed in the real world.
We address this problem through a novel type of layer, dubbed StyleLess, which
enables DNNs to learn robust and informative features that can cope with
varying external conditions. We propose multiple variations of this layer that
can be integrated in most of the architectures and trained jointly with the
main task. We validate our contribution on typical autonomous-driving tasks
(detection, semantic segmentation), showing that in most cases, this approach
improves predictive performance on unseen conditions (fog, rain), while
preserving performance on seen conditions and objects.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures, 2 tables</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13905</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13909</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regularization by Denoising Sub-sampled Newton Method for Spectral CT
  Multi-Material Decomposition</dc:title>
 <dc:creator>Perelli, Alessandro</dc:creator>
 <dc:creator>Andersen, Martin S.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Spectral Computed Tomography (CT) is an emerging technology that enables to
estimate the concentration of basis materials within a scanned object by
exploiting different photon energy spectra. In this work, we aim at efficiently
solving a model-based maximum-a-posterior problem to reconstruct
multi-materials images with application to spectral CT. In particular, we
propose to solve a regularized optimization problem based on a plug-in
image-denoising function using a randomized second order method. By
approximating the Newton step using a sketching of the Hessian of the
likelihood function, it is possible to reduce the complexity while retaining
the complex prior structure given by the data-driven regularizer. We exploit a
non-uniform block sub-sampling of the Hessian with inexact but efficient
Conjugate gradient updates that require only Jacobian-vector products for
denoising term. Finally, we show numerical and experimental results for
spectral CT materials decomposition.
</dc:description>
 <dc:description>Comment: Accepted in Philosophical Transactions A, issue &quot;Synergistic
  tomographic image reconstruction (Part 1)&quot;</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13909</dc:identifier>
 <dc:identifier>doi:10.1098/rsta.2020.0191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13917</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Disentanglement-based Cross-Domain Feature Augmentation for Effective
  Unsupervised Domain Adaptive Person Re-identification</dc:title>
 <dc:creator>Zhang, Zhizheng</dc:creator>
 <dc:creator>Lan, Cuiling</dc:creator>
 <dc:creator>Zeng, Wenjun</dc:creator>
 <dc:creator>You, Quanzeng</dc:creator>
 <dc:creator>Liu, Zicheng</dc:creator>
 <dc:creator>Zheng, Kecheng</dc:creator>
 <dc:creator>Chen, Zhibo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Unsupervised domain adaptive (UDA) person re-identification (ReID) aims to
transfer the knowledge from the labeled source domain to the unlabeled target
domain for person matching. One challenge is how to generate target domain
samples with reliable labels for training. To address this problem, we propose
a Disentanglement-based Cross-Domain Feature Augmentation (DCDFA) strategy,
where the augmented features characterize well the target and source domain
data distributions while inheriting reliable identity labels. Particularly, we
disentangle each sample feature into a robust domain-invariant/shared feature
and a domain-specific feature, and perform cross-domain feature recomposition
to enhance the diversity of samples used in the training, with the constraints
of cross-domain ReID loss and domain classification loss. Each recomposed
feature, obtained based on the domain-invariant feature (which enables a
reliable inheritance of identity) and an enhancement from a domain specific
feature (which enables the approximation of real distributions), is thus an
&quot;ideal&quot; augmentation. Extensive experimental results demonstrate the
effectiveness of our method, which achieves the state-of-the-art performance.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13917</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13921</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Resh Programming Language for Multirobot Orchestration</dc:title>
 <dc:creator>Carroll, Martin</dc:creator>
 <dc:creator>Namjoshi, Kedar S.</dc:creator>
 <dc:creator>Segall, Itai</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  This paper describes Resh, a new, statically typed, interpreted programming
language and associated runtime for orchestrating multirobot systems. The main
features of Resh are: (1) It offloads much of the tedious work of programming
such systems away from the programmer and into the language runtime; (2) It is
based on a small set of temporal and locational operators; and (3) It is not
restricted to specific robot types or tasks. The Resh runtime consists of three
engines that collaborate to run a Resh program using the available robots in
their current environment. This paper describes both Resh and its runtime and
gives examples of its use.
</dc:description>
 <dc:description>Comment: Accepted for publication at ICRA'21</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13921</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13922</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ScanGAN360: A Generative Model of Realistic Scanpaths for 360$^{\circ}$
  Images</dc:title>
 <dc:creator>Martin, Daniel</dc:creator>
 <dc:creator>Serrano, Ana</dc:creator>
 <dc:creator>Bergman, Alexander W.</dc:creator>
 <dc:creator>Wetzstein, Gordon</dc:creator>
 <dc:creator>Masia, Belen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Understanding and modeling the dynamics of human gaze behavior in 360$^\circ$
environments is a key challenge in computer vision and virtual reality.
Generative adversarial approaches could alleviate this challenge by generating
a large number of possible scanpaths for unseen images. Existing methods for
scanpath generation, however, do not adequately predict realistic scanpaths for
360$^\circ$ images. We present ScanGAN360, a new generative adversarial
approach to address this challenging problem. Our network generator is tailored
to the specifics of 360$^\circ$ images representing immersive environments.
Specifically, we accomplish this by leveraging the use of a spherical
adaptation of dynamic-time warping as a loss function and proposing a novel
parameterization of 360$^\circ$ scanpaths. The quality of our scanpaths
outperforms competing approaches by a large margin and is almost on par with
the human baseline. ScanGAN360 thus allows fast simulation of large numbers of
virtual observers, whose behavior mimics real users, enabling a better
understanding of gaze behavior and novel applications in virtual scene design.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13922</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13924</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Mechanism for the Effect of Psychosis Community Treatment:
  A Conceptual Review from Neurobiology to Social Interaction</dc:title>
 <dc:creator>Benrimoh, David</dc:creator>
 <dc:creator>Sibarium, Ely</dc:creator>
 <dc:creator>Sheldon, Andrew</dc:creator>
 <dc:creator>Powers, Albert</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The computational underpinnings of positive psychotic symptoms have recently
received significant attention. Candidate mechanisms include some combination
of maladaptive priors and reduced updating of these priors during perception. A
potential benefit of models with such mechanisms is their ability to link
multiple levels of explanation. This is key to improving how we understand the
experience of psychosis. Moreover, it points us towards more comprehensive
avenues for therapeutic research by providing a putative mechanism that could
allow for the generation of new treatments from first principles. In order to
demonstrate this, our conceptual paper will discuss the application of the
insights from previous computational models to an important and complex set of
evidence-based clinical interventions with strong social elements, such as
coordinated specialty care clinics in early psychosis and assertive community
treatment. These interventions may include but also go beyond
psychopharmacology, providing, we argue, structure and predictability for
patients experiencing psychosis. We develop the argument that this structure
and predictability directly counteract the relatively low precision afforded to
sensory information in psychosis, while also providing the patient more access
to external cognitive resources in the form of providers and the structure of
the programs themselves. We discuss how computational models explain the
resulting reduction in symptoms, as well as the predictions these models make
about potential responses of patients to modifications or to different
variations of these interventions. We also link, via the framework of
computational models, the experiences of patients and response to interventions
to putative neurobiology.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13924</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13926</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gamma-convergent projection-free finite element methods for nematic
  liquid crystals: The Ericksen model</dc:title>
 <dc:creator>Nochetto, Ricardo H.</dc:creator>
 <dc:creator>Ruggeri, Michele</dc:creator>
 <dc:creator>Yang, Shuo</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  The Ericksen model for nematic liquid crystals couples a director field with
a scalar degree of orientation variable, and allows the formation of various
defects with finite energy. We propose a simple but novel finite element
approximation of the problem that can be implemented easily within standard
finite element packages. Our scheme is projection-free and thus circumvents the
use of weakly acute meshes, which are quite restrictive in 3D but are required
by recent algorithms for convergence. We prove stability and
$\Gamma$-convergence properties of the new method in the presence of defects.
We also design an effective nested gradient flow algorithm for computing
minimizers that controls the violation of the unit-length constraint of the
director. We present several simulations in 2D and 3D that document the
performance of the proposed scheme and its ability to capture quite intriguing
defects.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13926</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13929</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multinomial Logit Contextual Bandits: Provable Optimality and
  Practicality</dc:title>
 <dc:creator>Oh, Min-hwan</dc:creator>
 <dc:creator>Iyengar, Garud</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We consider a sequential assortment selection problem where the user choice
is given by a multinomial logit (MNL) choice model whose parameters are
unknown. In each period, the learning agent observes a $d$-dimensional
contextual information about the user and the $N$ available items, and offers
an assortment of size $K$ to the user, and observes the bandit feedback of the
item chosen from the assortment. We propose upper confidence bound based
algorithms for this MNL contextual bandit. The first algorithm is a simple and
practical method which achieves an $\tilde{\mathcal{O}}(d\sqrt{T})$ regret over
$T$ rounds. Next, we propose a second algorithm which achieves a
$\tilde{\mathcal{O}}(\sqrt{dT})$ regret. This matches the lower bound for the
MNL bandit problem, up to logarithmic terms, and improves on the best known
result by a $\sqrt{d}$ factor. To establish this sharper regret bound, we
present a non-asymptotic confidence bound for the maximum likelihood estimator
of the MNL model that may be of independent interest as its own theoretical
contribution. We then revisit the simpler, significantly more practical, first
algorithm and show that a simple variant of the algorithm achieves the optimal
regret for a broad class of important applications.
</dc:description>
 <dc:description>Comment: Accepted in AAAI 2021 (Main Technical Track)</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13929</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13935</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Near-optimal approximation methods for elliptic PDEs with lognormal
  coefficients</dc:title>
 <dc:creator>Cohen, Albert</dc:creator>
 <dc:creator>Migliorati, Giovanni</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  This paper studies numerical methods for the approximation of elliptic PDEs
with lognormal coefficients of the form $-{\rm div}(a\nabla u)=f$ where
$a=\exp(b)$ and $b$ is a Gaussian random field. The approximant of the solution
$u$ is an $n$-term polynomial expansion in the scalar Gaussian random variables
that parametrize $b$. We present a general convergence analysis of weighted
least-squares approximants for smooth and arbitrarily rough random field, using
a suitable random design, for which we prove optimality in the following sense:
their convergence rate matches exactly or closely the rate that has been
established in \cite{BCDM} for best $n$-term approximation by Hermite
polynomials, under the same minimial assumptions on the Gaussian random field.
This is in contrast with the current state of the art results for the
stochastic Galerkin method that suffers the lack of coercivity due to the
lognormal nature of the diffusion field. Numerical tests with $b$ as the
Brownian bridge confirm our theoretical findings.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13935</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13941</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SMILE: Self-Distilled MIxup for Efficient Transfer LEarning</dc:title>
 <dc:creator>Li, Xingjian</dc:creator>
 <dc:creator>Xiong, Haoyi</dc:creator>
 <dc:creator>Xu, Chengzhong</dc:creator>
 <dc:creator>Dou, Dejing</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  To improve the performance of deep learning, mixup has been proposed to force
the neural networks favoring simple linear behaviors in-between training
samples. Performing mixup for transfer learning with pre-trained models however
is not that simple, a high capacity pre-trained model with a large
fully-connected (FC) layer could easily overfit to the target dataset even with
samples-to-labels mixed up. In this work, we propose SMILE - Self-Distilled
Mixup for EffIcient Transfer LEarning. With mixed images as inputs, SMILE
regularizes the outputs of CNN feature extractors to learn from the mixed
feature vectors of inputs (sample-to-feature mixup), in addition to the mixed
labels. Specifically, SMILE incorporates a mean teacher, inherited from the
pre-trained model, to provide the feature vectors of input samples in a
self-distilling fashion, and mixes up the feature vectors accordingly via a
novel triplet regularizer. The triple regularizer balances the mixup effects in
both feature and label spaces while bounding the linearity in-between samples
for pre-training tasks. Extensive experiments have been done to verify the
performance improvement made by SMILE, in comparisons with a wide spectrum of
transfer learning algorithms, including fine-tuning, L2-SP, DELTA, and RIFLE,
even with mixup strategies combined. Ablation studies show that the vanilla
sample-to-label mixup strategies could marginally increase the linearity
in-between training samples but lack of generalizability, while SMILE
significantly improve the mixup effects in both label and feature spaces with
both training and testing datasets. The empirical observations backup our
design intuition and purposes.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13941</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13942</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual Grounding Strategies for Text-Only Natural Language Processing</dc:title>
 <dc:creator>Sileo, Damien</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Visual grounding is a promising path toward more robust and accurate Natural
Language Processing (NLP) models. Many multimodal extensions of BERT (e.g.,
VideoBERT, LXMERT, VL-BERT) allow a joint modeling of texts and images that
lead to state-of-the-art results on multimodal tasks such as Visual Question
Answering. Here, we leverage multimodal modeling for purely textual tasks
(language modeling and classification) with the expectation that the multimodal
pretraining provides a grounding that can improve text processing accuracy. We
propose possible strategies in this respect. A first type of strategy, referred
to as {\it transferred grounding} consists in applying multimodal models to
text-only tasks using a placeholder to replace image input. The second one,
which we call {\it associative grounding}, harnesses image retrieval to match
texts with related images during both pretraining and text-only downstream
tasks. We draw further distinctions into both strategies and then compare them
according to their impact on language modeling and commonsense-related
downstream tasks, showing improvement over text-only baselines.
</dc:description>
 <dc:description>Comment: Accepted at LANTERN2021</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13942</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13944</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preserve, Promote, or Attack? GNN Explanation via Topology Perturbation</dc:title>
 <dc:creator>Sun, Yi</dc:creator>
 <dc:creator>Valente, Abel</dc:creator>
 <dc:creator>Liu, Sijia</dc:creator>
 <dc:creator>Wang, Dakuo</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Prior works on formalizing explanations of a graph neural network (GNN) focus
on a single use case - to preserve the prediction results through identifying
important edges and nodes. In this paper, we develop a multi-purpose
interpretation framework by acquiring a mask that indicates topology
perturbations of the input graphs. We pack the framework into an interactive
visualization system (GNNViz) which can fulfill multiple purposes:
Preserve,Promote, or Attack GNN's predictions. We illustrate our approach's
novelty and effectiveness with three case studies: First, GNNViz can assist non
expert users to easily explore the relationship between graph topology and
GNN's decision (Preserve), or to manipulate the prediction (Promote or Attack)
for an image classification task on MS-COCO; Second, on the Pokec social
network dataset, our framework can uncover unfairness and demographic biases;
Lastly, it compares with state-of-the-art GNN explainer baseline on a synthetic
dataset.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13944</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13946</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A comparative analysis of local network similarity measurements:
  application to author citation networks</dc:title>
 <dc:creator>Vital Jr., Adilson</dc:creator>
 <dc:creator>Amancio, Diego R.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Understanding the evolution of paper and author citations is of paramount
importance for the design of research policies and evaluation criteria that can
promote and accelerate scientific discoveries. Recently many studies on the
evolution of science have been conducted in the context of the emergent science
of science field. While many studies have probed the link problem in citation
networks, only a few works have analyzed the temporal nature of link prediction
in author citation networks. In this study we compared the performance of 10
well-known local network similarity measurements to predict future links in
author citations networks. Differently from traditional link prediction
methods, the temporal nature of the predict links is relevant for our approach.
Our analysis revealed interesting results. The Jaccard coefficient was found to
be among the most relevant measurements. The preferential attachment
measurement, conversely, displayed the worst performance. We also found that
the extension of local measurements to their weighted version do not
significantly improved the performance of predicting citations. Finally, we
also found that a neural network approach summarizing the information from all
10 considered similarity measurements was not able to provide the highest
prediction performance.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13949</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate GCD in Lagrange bases</dc:title>
 <dc:creator>Sevyeri, Leili Rafiee</dc:creator>
 <dc:creator>Corless, Robert M.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>68W25</dc:subject>
 <dc:description>  For a pair of polynomials with real or complex coefficients, given in any
particular basis, the problem of finding their GCD is known to be ill-posed. An
answer is still desired for many applications, however. Hence, looking for a
GCD of so-called approximate polynomials where this term explicitly denotes
small uncertainties in the coefficients has received significant attention in
the field of hybrid symbolic-numeric computation. In this paper we give an
algorithm, based on one of Victor Ya. Pan, to find an approximate GCD for a
pair of approximate polynomials given in a Lagrange basis. More precisely, we
suppose that these polynomials are given by their approximate values at
distinct known points. We first find each of their roots by using a Lagrange
basis companion matrix for each polynomial, cluster the roots of each
polynomial to identify multiple roots, and then &quot;marry&quot; the two polynomials to
find their GCD. At no point do we change to the monomial basis, thus preserving
the good conditioning properties of the original Lagrange basis. We discuss
advantages and drawbacks of this method. The computational cost is dominated by
the rootfinding step; unless special-purpose eigenvalue algorithms are used,
the cost is cubic in the degrees of the polynomials. In principle, this cost
could be reduced but we do not do so here.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13949</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13952</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimation of Closest In-Path Vehicle (CIPV) by Low-Channel LiDAR and
  Camera Sensor Fusion for Autonomous Vehicle</dc:title>
 <dc:creator>Bae, Hyunjin</dc:creator>
 <dc:creator>Lee, Gu</dc:creator>
 <dc:creator>Yang, Jaeseung</dc:creator>
 <dc:creator>Shin, Gwanjun</dc:creator>
 <dc:creator>Lim, Yongseob</dc:creator>
 <dc:creator>Choi, Gyeungho</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  In autonomous driving, using a variety of sensors to recognize preceding
vehicles in middle and long distance is helpful for improving driving
performance and developing various functions. However, if only LiDAR or camera
is used in the recognition stage, it is difficult to obtain necessary data due
to the limitations of each sensor. In this paper, we proposed a method of
converting the tracking data of vision into bird's eye view (BEV) coordinates
using an equation that projects LiDAR points onto an image, and a method of
fusion between LiDAR and vision tracked data. Thus, the newly proposed method
was effective through the results of detecting closest in-path vehicle (CIPV)
in various situations. In addition, even when experimenting with the EuroNCAP
autonomous emergency braking (AEB) test protocol using the result of fusion,
AEB performance is improved through improved cognitive performance than when
using only LiDAR. In experimental results, the performance of the proposed
method was proved through actual vehicle tests in various scenarios.
Consequently, it is convincing that the newly proposed sensor fusion method
significantly improves the ACC function in autonomous maneuvering. We expect
that this improvement in perception performance will contribute to improving
the overall stability of ACC.
</dc:description>
 <dc:description>Comment: 13 pages, 19 figures, submitted to MDPI Sensors</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13952</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13954</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Developing Apps for Researching the COVID-19 Pandemic with the
  TrackYourHealth Platform</dc:title>
 <dc:creator>Vogel, Carsten</dc:creator>
 <dc:creator>Pryss, R&#xfc;diger</dc:creator>
 <dc:creator>Schobel, Johannes</dc:creator>
 <dc:creator>Schlee, Winfried</dc:creator>
 <dc:creator>Beierle, Felix</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>D.2.13</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:subject>H.4.0</dc:subject>
 <dc:description>  Through lockdowns and other severe changes to daily life, almost everyone is
affected by the COVID-19 pandemic. Scientists and medical doctors are - among
others - mainly interested in researching, monitoring, and improving physical
and mental health of the general population. Mobile health apps (mHealth), and
apps conducting ecological momentary assessments (EMA) respectively, can help
in this context. However, developing such mobile applications poses many
challenges like costly software development efforts, strict privacy rules,
compliance with ethical guidelines, local laws, and regulations. In this paper,
we present TrackYourHealth (TYH), a highly configurable, generic, and modular
mobile data collection and EMA platform, which enabled us to develop and
release two mobile multi-platform applications related to COVID-19 in just a
few weeks. We present TYH and highlight specific challenges researchers and
developers of similar apps may also face, especially when developing apps
related to the medical field.
</dc:description>
 <dc:description>Comment: Accepted for publication in the proceedings of the 2021 IEEE/ACM 8th
  International Conference on Mobile Software Engineering and Systems
  (MobileSoft)</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13954</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13955</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonlinear Estimation for Position-Aided Inertial Navigation Systems</dc:title>
 <dc:creator>Berkane, Soulaimane</dc:creator>
 <dc:creator>Tayebi, Abdelhamid</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this work we solve the position-aided 3D navigation problem using a
nonlinear estimation scheme. More precisely, we propose a nonlinear observer to
estimate the full state of the vehicle (position, velocity, orientation and
gyro bias) from IMU and position measurements. The proposed observer does not
introduce additional auxiliary states and is shown to guarantee semi-global
exponential stability without any assumption on the acceleration of the
vehicle. The performance of the observer is shown, through simulation, to
overcome the state-of-the-art approach that assumes negligible accelerations.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:2006.14056</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13955</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13970</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Target Domain Adaptation via Unsupervised Domain Classification
  for Weather Invariant Object Detection</dc:title>
 <dc:creator>Sun, Ting</dc:creator>
 <dc:creator>Chen, Jinlin</dc:creator>
 <dc:creator>Ng, Francis</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Object detection is an essential technique for autonomous driving. The
performance of an object detector significantly degrades if the weather of the
training images is different from that of test images. Domain adaptation can be
used to address the domain shift problem so as to improve the robustness of an
object detector. However, most existing domain adaptation methods either handle
single target domain or require domain labels. We propose a novel unsupervised
domain classification method which can be used to generalize single-target
domain adaptation methods to multi-target domains, and design a
weather-invariant object detector training framework based on it. We conduct
the experiments on Cityscapes dataset and its synthetic variants, i.e. foggy,
rainy, and night. The experimental results show that the object detector
trained by our proposed method realizes robust object detection under different
weather conditions.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13970</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13987</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collision-Free MPC for Legged Robots in Static and Dynamic Scenes</dc:title>
 <dc:creator>Gaertner, Magnus</dc:creator>
 <dc:creator>Bjelonic, Marko</dc:creator>
 <dc:creator>Farshidian, Farbod</dc:creator>
 <dc:creator>Hutter, Marco</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  We present a model predictive controller (MPC) that automatically discovers
collision-free locomotion while simultaneously taking into account the system
dynamics, friction constraints, and kinematic limitations. A relaxed barrier
function is added to the optimization's cost function, leading to collision
avoidance behavior without increasing the problem's computational complexity.
Our holistic approach does not require any heuristics and enables legged robots
to find whole-body motions in the presence of static and dynamic obstacles. We
use a dynamically generated euclidean signed distance field for static
collision checking. Collision checking for dynamic obstacles is modeled with
moving cylinders, increasing the responsiveness to fast-moving agents.
Furthermore, we include a Kalman filter motion prediction for moving obstacles
into our receding horizon planning, enabling the robot to anticipate possible
future collisions. Our experiments demonstrate collision-free motions on a
quadrupedal robot in challenging indoor environments. The robot handles complex
scenes like overhanging obstacles and dynamic agents by exploring motions at
the robot's dynamic and kinematic limits.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13987</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13989</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Attacks on Deep Learning Based mmWave Beam Prediction in 5G
  and Beyond</dc:title>
 <dc:creator>Kim, Brian</dc:creator>
 <dc:creator>Sagduyu, Yalin E.</dc:creator>
 <dc:creator>Erpek, Tugba</dc:creator>
 <dc:creator>Ulukus, Sennur</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep learning provides powerful means to learn from spectrum data and solve
complex tasks in 5G and beyond such as beam selection for initial access (IA)
in mmWave communications. To establish the IA between the base station (e.g.,
gNodeB) and user equipment (UE) for directional transmissions, a deep neural
network (DNN) can predict the beam that is best slanted to each UE by using the
received signal strengths (RSSs) from a subset of possible narrow beams. While
improving the latency and reliability of beam selection compared to the
conventional IA that sweeps all beams, the DNN itself is susceptible to
adversarial attacks. We present an adversarial attack by generating adversarial
perturbations to manipulate the over-the-air captured RSSs as the input to the
DNN. This attack reduces the IA performance significantly and fools the DNN
into choosing the beams with small RSSs compared to jamming attacks with
Gaussian or uniform noise.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13989</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13990</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>More Photos are All You Need: Semi-Supervised Learning for Fine-Grained
  Sketch Based Image Retrieval</dc:title>
 <dc:creator>Bhunia, Ayan Kumar</dc:creator>
 <dc:creator>Chowdhury, Pinaki Nath</dc:creator>
 <dc:creator>Sain, Aneeshan</dc:creator>
 <dc:creator>Yang, Yongxin</dc:creator>
 <dc:creator>Xiang, Tao</dc:creator>
 <dc:creator>Song, Yi-Zhe</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A fundamental challenge faced by existing Fine-Grained Sketch-Based Image
Retrieval (FG-SBIR) models is the data scarcity -- model performances are
largely bottlenecked by the lack of sketch-photo pairs. Whilst the number of
photos can be easily scaled, each corresponding sketch still needs to be
individually produced. In this paper, we aim to mitigate such an upper-bound on
sketch data, and study whether unlabelled photos alone (of which they are many)
can be cultivated for performances gain. In particular, we introduce a novel
semi-supervised framework for cross-modal retrieval that can additionally
leverage large-scale unlabelled photos to account for data scarcity. At the
centre of our semi-supervision design is a sequential photo-to-sketch
generation model that aims to generate paired sketches for unlabelled photos.
Importantly, we further introduce a discriminator guided mechanism to guide
against unfaithful generation, together with a distillation loss based
regularizer to provide tolerance against noisy training samples. Last but not
least, we treat generation and retrieval as two conjugate problems, where a
joint learning procedure is devised for each module to mutually benefit from
each other. Extensive experiments show that our semi-supervised model yields
significant performance boost over the state-of-the-art supervised
alternatives, as well as existing methods that can exploit unlabelled photos
for FG-SBIR.
</dc:description>
 <dc:description>Comment: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2021
  Code : https://github.com/AyanKumarBhunia/semisupervised-FGSBIR</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13990</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.13997</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-time low-resource phoneme recognition on edge devices</dc:title>
 <dc:creator>Alon, Yonatan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  While speech recognition has seen a surge in interest and research over the
last decade, most machine learning models for speech recognition either require
large training datasets or lots of storage and memory. Combined with the
prominence of English as the number one language in which audio data is
available, this means most other languages currently lack good speech
recognition models.
  The method presented in this paper shows how to create and train models for
speech recognition in any language which are not only highly accurate, but also
require very little storage, memory and training data when compared with
traditional models. This allows training models to recognize any language and
deploying them on edge devices such as mobile phones or car displays for fast
real-time speech recognition.
</dc:description>
 <dc:description>Comment: The model and code described in this paper are publicly available at
  https://github.com/yonatankarimish/YonaVox</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.13997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14003</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rethinking Deep Contrastive Learning with Embedding Memory</dc:title>
 <dc:creator>Zhang, Haozhi</dc:creator>
 <dc:creator>Wang, Xun</dc:creator>
 <dc:creator>Huang, Weilin</dc:creator>
 <dc:creator>Scott, Matthew R.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Pair-wise loss functions have been extensively studied and shown to
continuously improve the performance of deep metric learning (DML). However,
they are primarily designed with intuition based on simple toy examples, and
experimentally identifying the truly effective design is difficult in
complicated, real-world cases. In this paper, we provide a new methodology for
systematically studying weighting strategies of various pair-wise loss
functions, and rethink pair weighting with an embedding memory. We delve into
the weighting mechanisms by decomposing the pair-wise functions, and study
positive and negative weights separately using direct weight assignment. This
allows us to study various weighting functions deeply and systematically via
weight curves, and identify a number of meaningful, comprehensive and
insightful facts, which come up with our key observation on memory-based DML:
it is critical to mine hard negatives and discard easy negatives which are less
informative and redundant, but weighting on positive pairs is not helpful. This
results in an efficient but surprisingly simple rule to design the weighting
scheme, making it significantly different from existing mini-batch based
methods which design various sophisticated loss functions to weight pairs
carefully. Finally, we conduct extensive experiments on three large-scale
visual retrieval benchmarks, and demonstrate the superiority of memory-based
DML over recent mini-batch based approaches, by using a simple contrastive loss
with momentum-updated memory.
</dc:description>
 <dc:description>Comment: Under review</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14007</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enabling Incremental Training with Forward Pass for Edge Devices</dc:title>
 <dc:creator>AbdulQader, Dana</dc:creator>
 <dc:creator>Krishnan, Shoba</dc:creator>
 <dc:creator>Coelho Jr, Claudionor N.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Deep Neural Networks (DNNs) are commonly deployed on end devices that exist
in constantly changing environments. In order for the system to maintain it's
accuracy, it is critical that it is able to adapt to changes and recover by
retraining parts of the network. However, end devices have limited resources
making it challenging to train on the same device. Moreover, training deep
neural networks is both memory and compute intensive due to the backpropagation
algorithm. In this paper we introduce a method using evolutionary strategy (ES)
that can partially retrain the network enabling it to adapt to changes and
recover after an error has occurred. This technique enables training on an
inference-only hardware without the need to use backpropagation and with
minimal resource overhead. We demonstrate the ability of our technique to
retrain a quantized MNIST neural network after injecting noise to the input.
Furthermore, we present the micro-architecture required to enable training on
HLS4ML (an inference hardware architecture) and implement it in Verilog. We
synthesize our implementation for a Xilinx Kintex Ultrascale Field Programmable
Gate Array (FPGA) resulting in less than 1% resource utilization required to
implement the incremental training.
</dc:description>
 <dc:description>Comment: 6 pages, 7 figures</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14011</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>De Finetti-Style Results for Wishart Matrices: Combinatorial Structure
  and Phase Transitions</dc:title>
 <dc:creator>Brennan, Matthew</dc:creator>
 <dc:creator>Bresler, Guy</dc:creator>
 <dc:creator>Huang, Brice</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>60B20 (Primary), 62B10 (Secondary)</dc:subject>
 <dc:description>  A recent line of work has studied the relationship between the Wishart matrix
$X^\top X$, where $X\in \mathbb{R}^{d\times n}$ has i.i.d. standard Gaussian
entries, and the corresponding Gaussian matrix with independent entries above
the diagonal. Jiang and Li (2015) and Bubeck et al. (2016) showed that these
two matrix ensembles converge in total variation whenever $d/n^3\to \infty$,
and Bubeck et al. (2016) showed this to be sharp. In this paper we aim to
identify the precise threshold for $d$ in terms of $n$ for subsets of Wishart
matrices to converge in total variation to independent Gaussians. It turns out
that the combinatorial structure of the revealed entries, viewed as the
adjacency matrix of a graph $G$, characterizes the distance from fully
independent. Specifically, we show that the threshold for $d$ depends on the
number of various small subgraphs in $G$. So, even when the number of revealed
entries is fixed, the threshold can vary wildly depending on their
configuration. Convergence of masked Wishart to independent Gaussians thus
inherently involves an interplay between both probabilistic and combinatorial
phenomena. Our results determine the sharp threshold for a large family of $G$,
including Erd\H{o}s-R\'enyi $G\sim \mathcal{G}(n,p)$ at all values $p\gtrsim
n^{-2}\mathrm{polylog}(n)$. Our proof techniques are both combinatorial and
information theoretic, which together allow us to carefully unravel the
dependencies in the masked Wishart ensemble.
</dc:description>
 <dc:description>Comment: 115 pages, 8 figures</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14013</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Set Turing Machines</dc:title>
 <dc:creator>Melles, Garvin</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We define a generalization of the Turing machine that computes on general
sets. Our main theorem states that the class of generalized Turing machine
computable functions and the class of Set Recursive functions coincide.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14015</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Zero-shot super-resolution with a physically-motivated downsampling
  kernel for endomicroscopy</dc:title>
 <dc:creator>Szczotka, Agnieszka Barbara</dc:creator>
 <dc:creator>Shakir, Dzhoshkun Ismail</dc:creator>
 <dc:creator>Clarkson, Matthew J.</dc:creator>
 <dc:creator>Pereira, Stephen P.</dc:creator>
 <dc:creator>Vercauteren, Tom</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Super-resolution (SR) methods have seen significant advances thanks to the
development of convolutional neural networks (CNNs). CNNs have been
successfully employed to improve the quality of endomicroscopy imaging. Yet,
the inherent limitation of research on SR in endomicroscopy remains the lack of
ground truth high-resolution (HR) images, commonly used for both supervised
training and reference-based image quality assessment (IQA). Therefore,
alternative methods, such as unsupervised SR are being explored. To address the
need for non-reference image quality improvement, we designed a novel zero-shot
super-resolution (ZSSR) approach that relies only on the endomicroscopy data to
be processed in a self-supervised manner without the need for ground-truth HR
images. We tailored the proposed pipeline to the idiosyncrasies of
endomicroscopy by introducing both: a physically-motivated Voronoi downscaling
kernel accounting for the endomicroscope's irregular fibre-based sampling
pattern, and realistic noise patterns. We also took advantage of video
sequences to exploit a sequence of images for self-supervised zero-shot image
quality improvement. We run ablation studies to assess our contribution in
regards to the downscaling kernel and noise simulation. We validate our
methodology on both synthetic and original data. Synthetic experiments were
assessed with reference-based IQA, while our results for original images were
evaluated in a user study conducted with both expert and non-expert observers.
The results demonstrated superior performance in image quality of ZSSR
reconstructions in comparison to the baseline method. The ZSSR is also
competitive when compared to supervised single-image SR, especially being the
preferred reconstruction technique by experts.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14015</dc:identifier>
 <dc:identifier>IEEE Transactions on Medical Imaging, 2021</dc:identifier>
 <dc:identifier>doi:10.1109/TMI.2021.3067512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14021</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Orthogonal Projection Loss</dc:title>
 <dc:creator>Ranasinghe, Kanchana</dc:creator>
 <dc:creator>Naseer, Muzammal</dc:creator>
 <dc:creator>Hayat, Munawar</dc:creator>
 <dc:creator>Khan, Salman</dc:creator>
 <dc:creator>Khan, Fahad Shahbaz</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep neural networks have achieved remarkable performance on a range of
classification tasks, with softmax cross-entropy (CE) loss emerging as the
de-facto objective function. The CE loss encourages features of a class to have
a higher projection score on the true class-vector compared to the negative
classes. However, this is a relative constraint and does not explicitly force
different class features to be well-separated. Motivated by the observation
that ground-truth class representations in CE loss are orthogonal (one-hot
encoded vectors), we develop a novel loss function termed `Orthogonal
Projection Loss' (OPL) which imposes orthogonality in the feature space. OPL
augments the properties of CE loss and directly enforces inter-class separation
alongside intra-class clustering in the feature space through orthogonality
constraints on the mini-batch level. As compared to other alternatives of CE,
OPL offers unique advantages e.g., no additional learnable parameters, does not
require careful negative mining and is not sensitive to the batch size. Given
the plug-and-play nature of OPL, we evaluate it on a diverse range of tasks
including image recognition (CIFAR-100), large-scale classification (ImageNet),
domain generalization (PACS) and few-shot learning (miniImageNet, CIFAR-FS,
tiered-ImageNet and Meta-dataset) and demonstrate its effectiveness across the
board. Furthermore, OPL offers better robustness against practical nuisances
such as adversarial attacks and label noise. Code is available at:
https://github.com/kahnchana/opl.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14025</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The ThreeDWorld Transport Challenge: A Visually Guided Task-and-Motion
  Planning Benchmark for Physically Realistic Embodied AI</dc:title>
 <dc:creator>Gan, Chuang</dc:creator>
 <dc:creator>Zhou, Siyuan</dc:creator>
 <dc:creator>Schwartz, Jeremy</dc:creator>
 <dc:creator>Alter, Seth</dc:creator>
 <dc:creator>Bhandwaldar, Abhishek</dc:creator>
 <dc:creator>Gutfreund, Dan</dc:creator>
 <dc:creator>Yamins, Daniel L. K.</dc:creator>
 <dc:creator>DiCarlo, James J</dc:creator>
 <dc:creator>McDermott, Josh</dc:creator>
 <dc:creator>Torralba, Antonio</dc:creator>
 <dc:creator>Tenenbaum, Joshua B.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We introduce a visually-guided and physics-driven task-and-motion planning
benchmark, which we call the ThreeDWorld Transport Challenge. In this
challenge, an embodied agent equipped with two 9-DOF articulated arms is
spawned randomly in a simulated physical home environment. The agent is
required to find a small set of objects scattered around the house, pick them
up, and transport them to a desired final location. We also position containers
around the house that can be used as tools to assist with transporting objects
efficiently. To complete the task, an embodied agent must plan a sequence of
actions to change the state of a large number of objects in the face of
realistic physical constraints. We build this benchmark challenge using the
ThreeDWorld simulation: a virtual 3D environment where all objects respond to
physics, and where can be controlled using fully physics-driven navigation and
interaction API. We evaluate several existing agents on this benchmark.
Experimental results suggest that: 1) a pure RL model struggles on this
challenge; 2) hierarchical planning-based agents can transport some objects but
still far from solving this task. We anticipate that this benchmark will
empower researchers to develop more intelligent physics-driven robots for the
physical world.
</dc:description>
 <dc:description>Comment: Project page: http://tdw-transport.csail.mit.edu/</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14026</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AutoLoss-Zero: Searching Loss Functions from Scratch for Generic Tasks</dc:title>
 <dc:creator>Li, Hao</dc:creator>
 <dc:creator>Fu, Tianwen</dc:creator>
 <dc:creator>Dai, Jifeng</dc:creator>
 <dc:creator>Li, Hongsheng</dc:creator>
 <dc:creator>Huang, Gao</dc:creator>
 <dc:creator>Zhu, Xizhou</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Significant progress has been achieved in automating the design of various
components in deep networks. However, the automatic design of loss functions
for generic tasks with various evaluation metrics remains under-investigated.
Previous works on handcrafting loss functions heavily rely on human expertise,
which limits their extendibility. Meanwhile, existing efforts on searching loss
functions mainly focus on specific tasks and particular metrics, with
task-specific heuristics. Whether such works can be extended to generic tasks
is not verified and questionable. In this paper, we propose AutoLoss-Zero, the
first general framework for searching loss functions from scratch for generic
tasks. Specifically, we design an elementary search space composed only of
primitive mathematical operators to accommodate the heterogeneous tasks and
evaluation metrics. A variant of the evolutionary algorithm is employed to
discover loss functions in the elementary search space. A loss-rejection
protocol and a gradient-equivalence-check strategy are developed so as to
improve the search efficiency, which are applicable to generic tasks. Extensive
experiments on various computer vision tasks demonstrate that our searched loss
functions are on par with or superior to existing loss functions, which
generalize well to different datasets and networks. Code shall be released.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14031</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Fidelity Pluralistic Image Completion with Transformers</dc:title>
 <dc:creator>Wan, Ziyu</dc:creator>
 <dc:creator>Zhang, Jingbo</dc:creator>
 <dc:creator>Chen, Dongdong</dc:creator>
 <dc:creator>Liao, Jing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Image completion has made tremendous progress with convolutional neural
networks (CNNs), because of their powerful texture modeling capacity. However,
due to some inherent properties (e.g., local inductive prior, spatial-invariant
kernels), CNNs do not perform well in understanding global structures or
naturally support pluralistic completion. Recently, transformers demonstrate
their power in modeling the long-term relationship and generating diverse
results, but their computation complexity is quadratic to input length, thus
hampering the application in processing high-resolution images. This paper
brings the best of both worlds to pluralistic image completion: appearance
prior reconstruction with transformer and texture replenishment with CNN. The
former transformer recovers pluralistic coherent structures together with some
coarse textures, while the latter CNN enhances the local texture details of
coarse priors guided by the high-resolution masked images. The proposed method
vastly outperforms state-of-the-art methods in terms of three aspects: 1) large
performance boost on image fidelity even compared to deterministic completion
methods; 2) better diversity and higher fidelity for pluralistic completion; 3)
exceptional generalization ability on large masks and generic dataset, like
ImageNet.
</dc:description>
 <dc:description>Comment: Project Page: http://raywzy.com/ICT</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14033</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Methodology For Crowdsourcing AI Models in an Enterprise</dc:title>
 <dc:creator>Suryanarayanan, Parthasarathy</dc:creator>
 <dc:creator>Saranathan, Sundar</dc:creator>
 <dc:creator>Mahatma, Shilpa</dc:creator>
 <dc:creator>Pathak, Divya</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The evolution of AI is advancing rapidly, creating both challenges and
opportunities for industry-community collaboration. In this work, we present a
novel methodology aiming to facilitate this collaboration through crowdsourcing
of AI models. Concretely, we have implemented a system and a process that any
organization can easily adopt to host AI competitions. The system allows them
to automatically harvest and evaluate the submitted models against in-house
proprietary data and also to incorporate them as reusable services in a
product.
</dc:description>
 <dc:description>Comment: Presented at Challenges in Machine Learning workshop 2020 (CiML2020)
  @NeurIPS (http://ciml.chalearn.org/)</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14034</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fluid Flow along the Riga Plate with the Influence of Magnetic Force in
  a Rotating System</dc:title>
 <dc:creator>Islam, Muhammad Minarul</dc:creator>
 <dc:creator>Khatun, Sheela</dc:creator>
 <dc:creator>Mollah, Md. Tusher</dc:creator>
 <dc:creator>Alam, Md. Mahmud</dc:creator>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  The fluid flow along the Riga plate with the influence of magnetic force in a
rotating system has been investigated numerically. The governing equations have
been derived from Navier-Stokes equations. Applying the boundary layer
approximation, the appropriate boundary layer equations have been obtained. By
using usual transformation, the obtained governing equations have been
transformed into a coupled dimensionless non-linear partial differential
equation. The obtained dimensionless equations have been solved numerically by
explicit finite difference scheme. The simulated results have been obtained by
using MATLAB R2015a. Also the stability and convergence criteria have been
analyzed. The effect of several parameters on the primary velocity, secondary
velocity, temperature distributions as well as local shear stress and Nusselt
number have been shown graphically.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:2103.13481</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14034</dc:identifier>
 <dc:identifier>8th BSME International Conference on Thermal Engineering, AIP
  Conf. Proc. (2019) 2121, 050002-1 - 050002-6</dc:identifier>
 <dc:identifier>doi:10.1063/1.5115889</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14036</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Realistic Differentially-Private Transmission Power Flow Data Release</dc:title>
 <dc:creator>Smith, David</dc:creator>
 <dc:creator>Geth, Frederik</dc:creator>
 <dc:creator>Vercoe, Elliott</dc:creator>
 <dc:creator>Feutrill, Andrew</dc:creator>
 <dc:creator>Ding, Ming</dc:creator>
 <dc:creator>Chan, Jonathan</dc:creator>
 <dc:creator>Foster, James</dc:creator>
 <dc:creator>Rakotoarivelo, Thierry</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  For the modeling, design and planning of future energy transmission networks,
it is vital for stakeholders to access faithful and useful power flow data,
while provably maintaining the privacy of business confidentiality of service
providers. This critical challenge has recently been somewhat addressed in [1].
This paper significantly extends this existing work. First, we reduce the
potential leakage information by proposing a fundamentally different
post-processing method, using public information of grid losses rather than
power dispatch, which achieve a higher level of privacy protection. Second, we
protect more sensitive parameters, i.e., branch shunt susceptance in addition
to series impedance (complete pi-model). This protects power flow data for the
transmission high-voltage networks, using differentially private
transformations that maintain the optimal power flow consistent with, and
faithful to, expected model behaviour. Third, we tested our approach at a
larger scale than previous work, using the PGLib-OPF test cases [10]. This
resulted in the successful obfuscation of up to a 4700-bus system, which can be
successfully solved with faithfulness of parameters and good utility to data
analysts. Our approach addresses a more feasible and realistic scenario, and
provides higher than state-of-the-art privacy guarantees, while maintaining
solvability, fidelity and feasibility of the system.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14051</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tilted Cross Entropy (TCE): Promoting Fairness in Semantic Segmentation</dc:title>
 <dc:creator>Szabo, Attila</dc:creator>
 <dc:creator>Jamali-Rad, Hadi</dc:creator>
 <dc:creator>Mannava, Siva-Datta</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Traditional empirical risk minimization (ERM) for semantic segmentation can
disproportionately advantage or disadvantage certain target classes in favor of
an (unfair but) improved overall performance. Inspired by the recently
introduced tilted ERM (TERM), we propose tilted cross-entropy (TCE) loss and
adapt it to the semantic segmentation setting to minimize performance disparity
among target classes and promote fairness. Through quantitative and qualitative
performance analyses, we demonstrate that the proposed Stochastic TCE for
semantic segmentation can efficiently improve the low-performing classes of
Cityscapes and ADE20k datasets trained with multi-class cross-entropy (MCCE),
and also results in improved overall fairness.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14053</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum-inspired identification of complex cellular automata</dc:title>
 <dc:creator>Ho, Matthew</dc:creator>
 <dc:creator>Pradana, Andri</dc:creator>
 <dc:creator>Elliott, Thomas J.</dc:creator>
 <dc:creator>Chew, Lock Yue</dc:creator>
 <dc:creator>Gu, Mile</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Nonlinear Sciences - Cellular Automata and Lattice Gases</dc:subject>
 <dc:description>  Elementary cellular automata (ECA) present iconic examples of complex
systems. Though described only by one-dimensional strings of binary cells
evolving according to nearest-neighbour update rules, certain ECA rules
manifest complex dynamics capable of universal computation. Yet, the
classification of precisely which rules exhibit complex behaviour remains a
significant challenge. Here we approach this question using tools from quantum
stochastic modelling, where quantum statistical memory -- the memory required
to model a stochastic process using a class of quantum machines -- can be used
to quantify the structure of a stochastic process. By viewing ECA rules as
transformations of stochastic patterns, we ask: Does an ECA generate structure
as quantified by the quantum statistical memory, and if so, how quickly? We
illustrate how the growth of this measure over time correctly distinguishes
simple ECA from complex counterparts. Moreover, it provides a more refined
means for quantitatively identifying complex ECAs -- providing a spectrum on
which we can rank the complexity of ECA by the rate in which they generate
structure.
</dc:description>
 <dc:description>Comment: 12 pages, 11 figures</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14056</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement Learning for Deceiving Reactive Jammers in Wireless
  Networks</dc:title>
 <dc:creator>Pourranjbar, Ali</dc:creator>
 <dc:creator>Kaddoum, Georges</dc:creator>
 <dc:creator>Ferdowsi, Aidin</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Conventional anti-jamming method mostly rely on frequency hopping to hide or
escape from jammer. These approaches are not efficient in terms of bandwidth
usage and can also result in a high probability of jamming. Different from
existing works, in this paper, a novel anti-jamming strategy is proposed based
on the idea of deceiving the jammer into attacking a victim channel while
maintaining the communications of legitimate users in safe channels. Since the
jammer's channel information is not known to the users, an optimal channel
selection scheme and a sub optimal power allocation are proposed using
reinforcement learning (RL). The performance of the proposed anti-jamming
technique is evaluated by deriving the statistical lower bound of the total
received power (TRP). Analytical results show that, for a given access point,
over 50 % of the highest achievable TRP, i.e. in the absence of jammers, is
achieved for the case of a single user and three frequency channels. Moreover,
this value increases with the number of users and available channels. The
obtained results are compared with two existing RL based anti-jamming
techniques, and random channel allocation strategy without any jamming attacks.
Simulation results show that the proposed anti-jamming method outperforms the
compared RL based anti-jamming methods and random search method, and yields
near optimal achievable TRP.
</dc:description>
 <dc:description>Comment: in IEEE Transactions on Communications</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14056</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2021.3062854</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14065</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantitative Prediction on the Enantioselectivity of Multiple Chiral
  Iodoarene Scaffolds Based on Whole Geometry</dc:title>
 <dc:creator>Lama, Prema Dhorma</dc:creator>
 <dc:creator>Kumar, Surendra</dc:creator>
 <dc:creator>Kim, Kang</dc:creator>
 <dc:creator>Ahn, Sangjin</dc:creator>
 <dc:creator>Kim, Mi-hyun</dc:creator>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>00A05, 81Vxx</dc:subject>
 <dc:subject>I.6.5</dc:subject>
 <dc:subject>I.6.4</dc:subject>
 <dc:subject>H.1.0</dc:subject>
 <dc:subject>I.6.6</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:subject>E.5</dc:subject>
 <dc:description>  The mechanistic underpinnings of asymmetric catalysis at atomic levels
provide shortcuts for developing the potential value of chiral catalysts beyond
the current state-of-the-art. In the enantioselective redox transformations,
the present intuition-driven studies require a systematic approach to support
their intuitive idea. Arguably, the most systematic approach would be based on
the reliable quantitative structure-selectivity relationship of diverse and
dissimilar chiral scaffolds in an optimal feature space that is universally
applied to reactions. Here, we introduce a predictive workflow for the
extension of the reaction scope of chiral catalysts across name reactions. For
this purpose, whole geometry descriptors were encoded from DFT optimized 3D
structures of multiple catalyst scaffolds, 113 catalysts in 9 clusters. The
molecular descriptors were verified by the statistical comparison of the
enantioselective predictive classification models built from each descriptors
of chiral iodoarenes. More notably, capturing the whole molecular geometry
through one hot encoding of split three-dimensional molecular fingerprints
presented reliable enantioselective predictive regression models for three
different name reactions by recycling the data and metadata obtained across
reactions. The potential use value of this workflow and the advantages of
recyclability, compatibility, and generality proved that the workflow can be
applied for name reactions other than the aforementioned name reactions (out of
samples). Furthermore, for the consensus prediction of ensemble models, this
global descriptor can be compared with sterimol parameters and noncovalent
interaction vectors. This study is one case showing how to overcome the
sparsity of experimental data in organic reactions, especially asymmetric
catalysis.
</dc:description>
 <dc:description>Comment: 73 pages, 27 figures, It described the enantioselective
  transformational potency of catalysts across reactions and introduced a
  predictive workflow to extend the reaction scope of chiral catalysts based on
  whole molecular geometry. Though the work is technically sound &amp;
  well-presented, it is too focused on the enantioselective prediction of
  iodoarenes with favorable statistical performance</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14068</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differentially Private Normalizing Flows for Privacy-Preserving Density
  Estimation</dc:title>
 <dc:creator>Waites, Chris</dc:creator>
 <dc:creator>Cummings, Rachel</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Normalizing flow models have risen as a popular solution to the problem of
density estimation, enabling high-quality synthetic data generation as well as
exact probability density evaluation. However, in contexts where individuals
are directly associated with the training data, releasing such a model raises
privacy concerns. In this work, we propose the use of normalizing flow models
that provide explicit differential privacy guarantees as a novel approach to
the problem of privacy-preserving density estimation. We evaluate the efficacy
of our approach empirically using benchmark datasets, and we demonstrate that
our method substantially outperforms previous state-of-the-art approaches. We
additionally show how our algorithm can be applied to the task of
differentially private anomaly detection.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14068</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14071</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerating Big-Data Sorting Through Programmable Switches</dc:title>
 <dc:creator>Barshatz-Schneor, Yamit</dc:creator>
 <dc:creator>Friedman, Roy</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Sorting is a fundamental and well studied problem that has been studied
extensively. Sorting plays an important role in the area of databases, as many
queries can be served much faster if the relations are first sorted. One of the
most popular sorting algorithm in databases is merge sort.
  In modern data-centers, data is stored in storage servers, while processing
takes place in compute servers. Hence, in order to compute queries on the data,
it must travel through the network from the storage servers to the compute
servers. This creates a potential for utilizing programmable switches to
perform partial sorting in order to accelerate the sorting process at the
server side. This is possible because, as mentioned above, data packets pass
through the switch in any case on their way to the server. Alas, programmable
switches offer a very restricted and non-intuitive programming model, which is
why realizing this is not-trivial.
  We devised a novel partial sorting algorithm that fits the programming model
and restrictions of programmable switches and can expedite merge sort at the
server. We also utilize built-in parallelism in the switch to divide the data
into sequential ranges. Thus, the server needs to sort each range separately
and then concatenate them to one sorted stream. This way, the server needs to
sort smaller sections and each of these sections is already partially sorted.
Hence, the server does less work, and the access pattern becomes more
virtual-memory friendly.
  We evaluated the performance improvements obtained when utilizing our partial
sorting algorithm over several data stream compositions with various switch
configurations. Our study exhibits an improvement of 20%-75% in the sorting
run-time when using our approach compared to plain sorting on the original
stream.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14071</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14072</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On multi-conditioned conic fitting in Geometric algebra for conics</dc:title>
 <dc:creator>Lou&#x10d;ka, Pavel</dc:creator>
 <dc:creator>Va&#x161;&#xed;k, Petr</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We introduce several modifications of conic fitting in Geometric algebra for
conics by incorporating additional conditions into the optimisation problem.
Each of these extra conditions ensure additional geometric properties of a
fitted conic, in particular, centre point position at the origin of coordinate
system, axial alignment with coordinate axes, or, eventually, combination of
both. All derived algorithms are accompanied by a discussion of the underlying
algebra and optimisation issues, together with the implementation in MATLAB.
Finally, we present examples on a sample dataset and offer possible use of the
algorithms.
</dc:description>
 <dc:description>Comment: 40 pages, 6 figures</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14076</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning landmark geodesics using Kalman ensembles</dc:title>
 <dc:creator>Bock, Andreas</dc:creator>
 <dc:creator>Cotter, Colin J.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We study the problem of diffeomorphometric geodesic landmark matching where
the objective is to find a diffeomorphism that via its group action maps
between two sets of landmarks. It is well-known that the motion of the
landmarks, and thereby the diffeomorphism, can be encoded by an initial
momentum leading to a formulation where the landmark matching problem can be
solved as an optimisation problem over such momenta. The novelty of our work
lies in the application of a derivative-free Bayesian inverse method for
learning the optimal momentum encoding the diffeomorphic mapping between the
template and the target. The method we apply is the ensemble Kalman filter, an
extension of the Kalman filter to nonlinear observation operators. We describe
an efficient implementation of the algorithm and show several numerical results
for various target shapes.
</dc:description>
 <dc:description>Comment: 19 pages, 8 figures</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14078</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hastily Formed Knowledge Networks and Distributed Situation Awareness
  for Collaborative Robotics</dc:title>
 <dc:creator>Berger, Cyrille</dc:creator>
 <dc:creator>Doherty, Patrick</dc:creator>
 <dc:creator>Rudol, Piotr</dc:creator>
 <dc:creator>Wzorek, Mariusz</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:description>  In the context of collaborative robotics, distributed situation awareness is
essential for supporting collective intelligence in teams of robots and human
agents where it can be used for both individual and collective decision
support. This is particularly important in applications pertaining to emergency
rescue and crisis management. During operational missions, data and knowledge
is gathered incrementally and in different ways by heterogeneous robots and
humans. We describe this as the creation of \emph{Hastily Formed Knowledge
Networks} (HFKNs). The focus of this paper is the specification and prototyping
of a general distributed system architecture that supports the creation of
HFKNs by teams of robots and humans. The information collected ranges from
low-level sensor data to high-level semantic knowledge, the latter represented
in part as RDF Graphs. The framework includes a synchronization protocol and
associated algorithms that allow for the automatic distribution and sharing of
data and knowledge between agents. This is done through the distributed
synchronization of RDF Graphs shared between agents. High-level semantic
queries specified in SPARQL can be used by robots and humans alike to acquire
both knowledge and data content from team members. The system is empirically
validated and complexity results of the proposed algorithms are provided.
Additionally, a field robotics case study is described, where a 3D mapping
mission has been executed using several UAVs in a collaborative emergency
rescue scenario while using the full HFKN Framework.
</dc:description>
 <dc:description>Comment: 68 pages 37 figures</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14080</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Forecasting with Deep Learning: S&amp;P 500 index</dc:title>
 <dc:creator>Kamalov, Firuz</dc:creator>
 <dc:creator>Smail, Linda</dc:creator>
 <dc:creator>Gurrib, Ikhlaas</dc:creator>
 <dc:subject>Quantitative Finance - Statistical Finance</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Stock price prediction has been the focus of a large amount of research but
an acceptable solution has so far escaped academics. Recent advances in deep
learning have motivated researchers to apply neural networks to stock
prediction. In this paper, we propose a convolution-based neural network model
for predicting the future value of the S&amp;P 500 index. The proposed model is
capable of predicting the next-day direction of the index based on the previous
values of the index. Experiments show that our model outperforms a number of
benchmarks achieving an accuracy rate of over 55%.
</dc:description>
 <dc:description>Comment: Published in: 2020 13th International Symposium on Computational
  Intelligence and Design (ISCID)</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14080</dc:identifier>
 <dc:identifier>doi:10.1109/ISCID51228.2020.00102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14081</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stock price forecast with deep learning</dc:title>
 <dc:creator>Kamalov, Firuz</dc:creator>
 <dc:creator>Smail, Linda</dc:creator>
 <dc:creator>Gurrib, Ikhlaas</dc:creator>
 <dc:subject>Quantitative Finance - Statistical Finance</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In this paper, we compare various approaches to stock price prediction using
neural networks. We analyze the performance fully connected, convolutional, and
recurrent architectures in predicting the next day value of S&amp;P 500 index based
on its previous values. We further expand our analysis by including three
different optimization techniques: Stochastic Gradient Descent, Root Mean
Square Propagation, and Adaptive Moment Estimation. The numerical experiments
reveal that a single layer recurrent neural network with RMSprop optimizer
produces optimal results with validation and test Mean Absolute Error of 0.0150
and 0.0148 respectively.
</dc:description>
 <dc:description>Comment: Published in: 2020 International Conference on Decision Aid Sciences
  and Application (DASA)</dc:description>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14081</dc:identifier>
 <dc:identifier>doi:10.1109/DASA51403.2020.9317260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14091</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information theoretic parameters of non-commutative graphs and convex
  corners</dc:title>
 <dc:creator>Boreland, Gareth</dc:creator>
 <dc:creator>Todorov, Ivan G.</dc:creator>
 <dc:creator>Winter, Andreas</dc:creator>
 <dc:subject>Mathematics - Operator Algebras</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  We establish a second anti-blocker theorem for non-commutative convex
corners, show that the anti-blocking operation is continuous on bounded sets of
convex corners, and define optimisation parameters for a given convex corner
that generalise well-known graph theoretic quantities. We define the entropy of
a state with respect to a convex corner, characterise its maximum value in
terms of a generalised fractional chromatic number and establish entropy
splitting results that demonstrate the entropic complementarity between a
convex corner and its anti-blocker. We identify two extremal tensor products of
convex corners and examine the behaviour of the introduced parameters with
respect to tensoring. Specialising to non-commutative graphs, we obtain quantum
versions of the fractional chromatic number and the clique covering number, as
well as a notion of non-commutative graph entropy of a state, which we show to
be continuous with respect to the state and the graph. We define the
Witsenhausen rate of a non-commutative graph and compute the values of our
parameters in some specific cases.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14092</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unit Disk Visibility Graphs</dc:title>
 <dc:creator>&#xc7;a&#x11f;&#x131;r&#x131;c&#x131;, Onur</dc:creator>
 <dc:creator>A&#x11f;ao&#x11f;lu, Deniz</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We study unit disk visibility graphs, where the visibility relation between a
pair of geometric entities is defined by not only obstacles, but also the
distance between them. That is, two entities are not mutually visible if they
are too far apart, regardless of having an obstacle between them. This
particular graph class models real world scenarios more accurately compared to
the conventional visibility graphs. We first define and classify the unit disk
visibility graphs, and then show that the 3-coloring problem is NP-complete
when unit disk visibility model is used for a set of line segments (which
applies to a set of points) and for a polygon with holes.
</dc:description>
 <dc:description>Comment: 16 pages, full paper</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14100</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Expanding Frontiers: Settling an Understanding of Systems-of-Information
  Systems</dc:title>
 <dc:creator>Neto, Valdemar Vicente Graciano</dc:creator>
 <dc:creator>Lebtag, Bruno Gabriel Ara&#xfa;jo</dc:creator>
 <dc:creator>Teixeira, Paulo Gabriel</dc:creator>
 <dc:creator>Batista, Priscilla</dc:creator>
 <dc:creator>Lopes, Vin&#xed;cius Carvalho</dc:creator>
 <dc:creator>El-Hachem, Jamal</dc:creator>
 <dc:creator>Buisson, J&#xe9;r&#xe9;my</dc:creator>
 <dc:creator>Oquendo, Flavio</dc:creator>
 <dc:creator>Fernandes, Juliana</dc:creator>
 <dc:creator>Ferreira, Francisco</dc:creator>
 <dc:creator>Santos, Rodrigo Peireira dos</dc:creator>
 <dc:creator>Viana, Davi</dc:creator>
 <dc:creator>Cavalcante, Everton</dc:creator>
 <dc:creator>Kassab, Mohamad</dc:creator>
 <dc:creator>Mohsin, Ahmad</dc:creator>
 <dc:creator>Oliveira, Roberto</dc:creator>
 <dc:creator>Neves, V&#xe2;nia</dc:creator>
 <dc:creator>Cagnin, Maria Istela</dc:creator>
 <dc:creator>Nakagawa, Elisa Yumi</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  System-of-Systems (SoS) has consolidated itself as a special type of
software-intensive systems. As such, subtypes of SoS have also emerged, such as
Cyber-Physical SoS (CPSoS) that are formed essentially of cyber-physical
constituent systems and Systems-of-Information Systems (SoIS) that contain
information systems as their constituents. In contrast to CPSoS that have been
investigated and covered in the specialized literature, SoIS still lack
critical discussion about their fundamentals. The main contribution of this
paper is to present those fundamentals to set an understanding of SoIS. By
offering a discussion and examining literature cases, we draw an essential
settlement on SoIS definition, basics, and practical implications. The
discussion herein presented results from research conducted on SoIS over the
past years in interinstitutional and multinational research collaborations. The
knowledge gathered in this paper arises from several scientific discussion
meetings among the authors. As a result, we aim to contribute to the state of
the art of SoIS besides paving the research avenues for the forthcoming years.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures, 28 references</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14101</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterizing and Detecting Mismatch in Machine-Learning-Enabled
  Systems</dc:title>
 <dc:creator>Lewis, Grace A.</dc:creator>
 <dc:creator>Bellomo, Stephany</dc:creator>
 <dc:creator>Ozkaya, Ipek</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Increasing availability of machine learning (ML) frameworks and tools, as
well as their promise to improve solutions to data-driven decision problems,
has resulted in popularity of using ML techniques in software systems. However,
end-to-end development of ML-enabled systems, as well as their seamless
deployment and operations, remain a challenge. One reason is that development
and deployment of ML-enabled systems involves three distinct workflows,
perspectives, and roles, which include data science, software engineering, and
operations. These three distinct perspectives, when misaligned due to incorrect
assumptions, cause ML mismatches which can result in failed systems. We
conducted an interview and survey study where we collected and validated common
types of mismatches that occur in end-to-end development of ML-enabled systems.
Our analysis shows that how each role prioritizes the importance of relevant
mismatches varies, potentially contributing to these mismatched assumptions. In
addition, the mismatch categories we identified can be specified as machine
readable descriptors contributing to improved ML-enabled system development. In
this paper, we report our findings and their implications for improving
end-to-end ML-enabled system development.
</dc:description>
 <dc:description>Comment: 1st Workshop on AI Engineering: Software Engineering for AI (WAIN
  2021) held at the 2021 IEEE/ACM 43rd International Conference on Software
  Engineering</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14111</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial and Temporal Splitting Heuristics for Multi-Robot Motion
  Planning</dc:title>
 <dc:creator>Guo, Teng</dc:creator>
 <dc:creator>Han, Shuai D.</dc:creator>
 <dc:creator>Yu, Jingjin</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this work, we systematically examine the application of spatio-temporal
splitting heuristics to the Multi-Robot Motion Planning (MRMP) problem in a
graph-theoretic setting: a problem known to be NP-hard to optimally solve.
Following the divide-and-conquer principle, we design multiple spatial and
temporal splitting schemes that can be applied to any existing MRMP algorithm,
including integer programming solvers and Enhanced Conflict Based Search, in an
orthogonal manner. The combination of a good baseline MRMP algorithm with a
proper splitting heuristic proves highly effective, allowing the resolution of
problems 10+ times than what is possible previously, as corroborated by
extensive numerical evaluations. Notably, spatial partition of problem fusing
with the temporal splitting heuristic and the enhanced conflict based search
(ECBS) algorithm increases the scalability of ECBS on large and challenging DAO
maps by 5--15 folds with negligible impact on solution optimality.
</dc:description>
 <dc:description>Comment: Accepted by ICRA 2021</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14111</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14112</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classification of Local Problems on Paths from the Perspective of
  Descriptive Combinatorics</dc:title>
 <dc:creator>Greb&#xed;k, Jan</dc:creator>
 <dc:creator>Rozho&#x148;, V&#xe1;clav</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We classify which local problems with inputs on oriented paths have so-called
Borel solution and show that this class of problems remains the same if we
instead require a measurable solution, a factor of iid solution, or a solution
with the property of Baire.
  Together with the work from the field of distributed computing [Balliu et al.
PODC 2019], the work from the field of descriptive combinatorics [Gao et al.
arXiv:1803.03872, Bernshteyn arXiv:2004.04905] and the work from the field of
random processes [Holroyd et al. Annals of Prob. 2017, Greb\'ik, Rozho\v{n}
arXiv:2103.08394], this finishes the classification of local problems with
inputs on oriented paths using complexity classes from these three fields.
  A simple picture emerges: there are four classes of local problems and most
classes have natural definitions in all three fields.
  Moreover, we now know that randomness does \emph{not} help with solving local
problems on oriented paths.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14112</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14113</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GPRAR: Graph Convolutional Network based Pose Reconstruction and Action
  Recognition for Human Trajectory Prediction</dc:title>
 <dc:creator>Huynh, Manh</dc:creator>
 <dc:creator>Alaghband, Gita</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Prediction with high accuracy is essential for various applications such as
autonomous driving. Existing prediction models are easily prone to errors in
real-world settings where observations (e.g. human poses and locations) are
often noisy. To address this problem, we introduce GPRAR, a graph convolutional
network based pose reconstruction and action recognition for human trajectory
prediction. The key idea of GPRAR is to generate robust features: human poses
and actions, under noisy scenarios. To this end, we design GPRAR using two
novel sub-networks: PRAR (Pose Reconstruction and Action Recognition) and FA
(Feature Aggregator). PRAR aims to simultaneously reconstruct human poses and
action features from the coherent and structural properties of human skeletons.
It is a network of an encoder and two decoders, each of which comprises
multiple layers of spatiotemporal graph convolutional networks. Moreover, we
propose a Feature Aggregator (FA) to channel-wise aggregate the learned
features: human poses, actions, locations, and camera motion using
encoder-decoder based temporal convolutional neural networks to predict future
locations. Extensive experiments on the commonly used datasets: JAAD [13] and
TITAN [19] show accuracy improvements of GPRAR over state-of-theart models.
Specifically, GPRAR improves the prediction accuracy up to 22% and 50% under
noisy observations on JAAD and TITAN datasets, respectively
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14113</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14115</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training Neural Networks Using the Property of Negative Feedback to
  Inverse a Function</dc:title>
 <dc:creator>Hasan, Md Munir</dc:creator>
 <dc:creator>Holleman, Jeremy</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  With high forward gain, a negative feedback system has the ability to perform
the inverse of a linear or non linear function that is in the feedback path.
This property of negative feedback systems has been widely used in analog
circuits to construct precise closed-loop functions. This paper describes how
the property of a negative feedback system to perform inverse of a function can
be used for training neural networks. This method does not require that the
cost or activation functions be differentiable. Hence, it is able to learn a
class of non-differentiable functions as well where a gradient descent-based
method fails. We also show that gradient descent emerges as a special case of
the proposed method. We have applied this method to the MNIST dataset and
obtained results that shows the method is viable for neural network training.
This method, to the best of our knowledge, is novel in machine learning.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14123</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preliminary Experimental Results of Context-Aware Teams of Multiple
  Autonomous Agents Operating under Constrained Communications</dc:title>
 <dc:creator>Martinez-Lorenzo, Jose</dc:creator>
 <dc:creator>Hudack, Jeff</dc:creator>
 <dc:creator>Jing, Yutao</dc:creator>
 <dc:creator>Shaham, Michael</dc:creator>
 <dc:creator>Liang, Zixuan</dc:creator>
 <dc:creator>Bashit, Abdullah Al</dc:creator>
 <dc:creator>Wu, Yushu</dc:creator>
 <dc:creator>Zhang, Weite</dc:creator>
 <dc:creator>Skopin, Matthew</dc:creator>
 <dc:creator>Heredia-Juesas, Juan</dc:creator>
 <dc:creator>Ma, Yuntao</dc:creator>
 <dc:creator>Sweeney, Tristan</dc:creator>
 <dc:creator>Ares, Nicolas</dc:creator>
 <dc:creator>Fox, Ari</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  This work presents and experimentally test the framework used by our
context-aware, distributed team of small Unmanned Aerial Systems (SUAS) capable
of operating in real-time, in an autonomous fashion, and under constrained
communications. Our framework relies on three layered approach: (1) Operational
layer, where fast temporal and narrow spatial decisions are made; (2) Tactical
Layer, where temporal and spatial decisions are made for a team of agents; and
(3) Strategical Layer, where slow temporal and wide spatial decisions are made
for the team of agents. These three layers are coordinated by an ad-hoc,
software-defined communications network, which ensures sparse, but timely
delivery of messages amongst groups and teams of agents at each layer even
under constrained communications. Experimental results are presented for a team
of 10 small unmanned aerial systems tasked with searching and monitoring a
person in an open area. At the operational layer, our use case presents an
agent autonomously performing searching, detection, localization,
classification, identification, tracking, and following of the person, while
avoiding malicious collisions. At the tactical layer, our experimental use case
presents the cooperative interaction of a group of multiple agents that enable
the monitoring of the targeted person over a wider spatial and temporal
regions. At the strategic layer, our use case involves the detection of complex
behaviors-i.e. the person being followed enters a car and runs away, or the
person being followed exits the car and runs away-that requires strategic
responses to successfully accomplish the mission.
</dc:description>
 <dc:description>Comment: 7 pages, 6 figures</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14123</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14125</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can Twitter Give Insights into International Differences in Covid-19
  Vaccination? Eight countries' English tweets to 21 March 2021</dc:title>
 <dc:creator>Thelwall, Mike</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Vaccination programs may help the world to reduce or eliminate Covid-19.
Information about them may help countries to design theirs more effectively,
with important benefits for public health. This article investigates whether it
is possible to get insights into national vaccination programmes from a quick
international comparison of public comments on Twitter. For this, word
association thematic analysis (WATA) was applied to English-language
vaccine-related tweets from eight countries gathered between 5 December 2020
and 21 March 2021. The method was able to quickly identify multiple
international differences. Whilst some were irrelevant, potentially non-trivial
differences include differing extents to which non-government scientific
experts are important to national vaccination discussions. For example, Ireland
seemed to be the only country in which university presidents were widely
tweeted about in vaccine discussions. India's vaccine kindness term
#VaccineMaitri was another interesting difference, highlighting the need for
international sharing.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14127</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contact-GraspNet: Efficient 6-DoF Grasp Generation in Cluttered Scenes</dc:title>
 <dc:creator>Sundermeyer, Martin</dc:creator>
 <dc:creator>Mousavian, Arsalan</dc:creator>
 <dc:creator>Triebel, Rudolph</dc:creator>
 <dc:creator>Fox, Dieter</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Grasping unseen objects in unconstrained, cluttered environments is an
essential skill for autonomous robotic manipulation. Despite recent progress in
full 6-DoF grasp learning, existing approaches often consist of complex
sequential pipelines that possess several potential failure points and
run-times unsuitable for closed-loop grasping. Therefore, we propose an
end-to-end network that efficiently generates a distribution of 6-DoF
parallel-jaw grasps directly from a depth recording of a scene. Our novel grasp
representation treats 3D points of the recorded point cloud as potential grasp
contacts. By rooting the full 6-DoF grasp pose and width in the observed point
cloud, we can reduce the dimensionality of our grasp representation to 4-DoF
which greatly facilitates the learning process. Our class-agnostic approach is
trained on 17 million simulated grasps and generalizes well to real world
sensor data. In a robotic grasping study of unseen objects in structured
clutter we achieve over 90% success rate, cutting the failure rate in half
compared to a recent state-of-the-art method.
</dc:description>
 <dc:description>Comment: ICRA 2021. Video of the real world experiments and code are available
  at
  https://research.nvidia.com/publication/2021-03_Contact-GraspNet%3A--Efficient</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14127</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14131</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Persistence Homology of TEDtalk: Do Sentence Embeddings Have a
  Topological Shape?</dc:title>
 <dc:creator>Das, Shouman</dc:creator>
 <dc:creator>Haque, Syed A.</dc:creator>
 <dc:creator>Tanveer, Md. Iftekhar</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  \emph{Topological data analysis} (TDA) has recently emerged as a new
technique to extract meaningful discriminitve features from high dimensional
data. In this paper, we investigate the possibility of applying TDA to improve
the classification accuracy of public speaking rating. We calculated
\emph{persistence image vectors} for the sentence embeddings of TEDtalk data
and feed this vectors as additional inputs to our machine learning models. We
have found a negative result that this topological information does not improve
the model accuracy significantly. In some cases, it makes the accuracy slightly
worse than the original one. From our results, we could not conclude that the
topological shapes of the sentence embeddings can help us train a better model
for public speaking rating.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14131</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14137</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimized Coverage Planning for UV Surface Disinfection</dc:title>
 <dc:creator>Marques, Joao Marcos Correia</dc:creator>
 <dc:creator>Ramalingam, Ramya</dc:creator>
 <dc:creator>Pan, Zherong</dc:creator>
 <dc:creator>Hauser, Kris</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:description>  UV radiation has been used as a disinfection strategy to deactivate a wide
range of pathogens, but existing irradiation strategies do not ensure
sufficient exposure of all environmental surfaces and/or require long
disinfection times. We present a near-optimal coverage planner for mobile UV
disinfection robots. The formulation optimizes the irradiation time efficiency,
while ensuring that a sufficient dosage of radiation is received by each
surface. The trajectory and dosage plan are optimized taking collision and
light occlusion constraints into account. We propose a two-stage scheme to
approximate the solution of the induced NP-hard optimization, and, for
efficiency, perform key irradiance and occlusion calculations on a GPU.
Empirical results show that our technique achieves more coverage for the same
exposure time as strategies for existing UV robots, can be used to compare UV
robot designs, and produces near-optimal plans. This is an extended version of
the paper originally contributed to ICRA2021.
</dc:description>
 <dc:description>Comment: 13 pages, 18 figures</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14137</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14142</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vehicle Following On A Ring Road Under Safety Constraints: Role of
  Connectivity and Coordination</dc:title>
 <dc:creator>Pooladsanj, Milad</dc:creator>
 <dc:creator>Savla, Ketan</dc:creator>
 <dc:creator>Ioannou, Petros A.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  A fundamental problem in traffic networks is driving under safety and limited
physical space constraints. In this paper, we design longitudinal vehicle
controllers and study the dynamics of a system of homogeneous vehicles on a
single-lane ring road in order to understand the interplay of limited space,
speed, and safety. Each vehicle in the system either operates in the cruise
control mode or follows a vehicle ahead by keeping a safe time headway. We show
that if the number of vehicles is less than a certain critical threshold,
vehicles can occupy the limited space in many different configurations, i.e.,
different platoons of different sizes, and they converge to a uniform maximum
speed while attenuating errors in the relative spacing upstream a platoon. If
the number of vehicles exceeds the threshold, vehicles converge to a unique
symmetric configuration and the equilibrium speed decreases as the number of
vehicles increases. Next, we consider vehicle-to-vehicle (V2V) communication
and show that it increases the critical number of vehicles that can travel with
the maximum speed. Finally, we consider central coordination and show that the
proposed controllers can force vehicles to converge to a desired configuration
specified by the coordinator while maintaining safety and comfort. We
demonstrate the performance of the proposed controllers via simulation.
</dc:description>
 <dc:description>Comment: 17 pages, 13 figures; submitted to IEEE IV</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14142</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14157</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Thermodynamically-informed Air-based Soft Heat Engine Design</dc:title>
 <dc:creator>Xiao, Charles</dc:creator>
 <dc:creator>Gockowski, Luke F.</dc:creator>
 <dc:creator>Liao, Bolin</dc:creator>
 <dc:creator>Valentine, Megan T.</dc:creator>
 <dc:creator>Hawkes, Elliot W.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Soft heat engines are poised to play a vital role in future soft robots due
to their easy integration into soft structures and low-voltage power
requirements. Recent works have demonstrated soft heat engines relying on
liquid-to-gas phase change materials. However, despite the fact that many soft
robots have air as a primary component, soft air cycles are not a focus of the
field. In this paper, we develop theory for air-based soft heat engines design
and efficiency, and demonstrate experimentally that efficiency can be improved
through careful cycle design. We compare a simple constant-load cycle to a
designed decreasing-load cycle, inspired by the Otto cycle. While both
efficiencies are relatively low, the Otto-like cycle improves efficiency by a
factor of 11.3, demonstrating the promise of this approach. Our results lay the
foundation for the development of air-based soft heat engines as a new option
for powering soft robots.
</dc:description>
 <dc:description>Comment: IROS 2021 Conference submission</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14157</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14160</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design and Test of an adaptive augmented reality interface to manage
  systems to assist critical missions</dc:title>
 <dc:creator>Addin, Dany Naser</dc:creator>
 <dc:creator>Ozell, Benoit</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>68U35 (Primary) 68M10 (Secondary)</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:subject>I.3.4</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We present a user interface (UI) based on augmented reality (AR) with
head-mounted display (HMD) for improving situational awareness during critical
operation and improve human efficiency on operations. The UI displays
contextual information as well as accepts orders given from the headset to
control unmanned aerial vehicles (UAVs) for assisting the rescue team. We
established experiments where people had been put in a stressful situation and
are asked to resolve a complex mission using a headset and a computer.
Comparing both technologies, our results show that augmented reality has the
potential to be an important tool to help those involved in the emergency
situation.
</dc:description>
 <dc:description>Comment: For associated mpeg files, see
  https://www.polymtl.ca/rv/Activites/Drones/arxiv/</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14160</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14162</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Few-shot Weakly-Supervised Object Detection via Directional Statistics</dc:title>
 <dc:creator>Shaban, Amirreza</dc:creator>
 <dc:creator>Rahimi, Amir</dc:creator>
 <dc:creator>Ajanthan, Thalaiyasingam</dc:creator>
 <dc:creator>Boots, Byron</dc:creator>
 <dc:creator>Hartley, Richard</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Detecting novel objects from few examples has become an emerging topic in
computer vision recently. However, these methods need fully annotated training
images to learn new object categories which limits their applicability in real
world scenarios such as field robotics. In this work, we propose a
probabilistic multiple instance learning approach for few-shot Common Object
Localization (COL) and few-shot Weakly Supervised Object Detection (WSOD). In
these tasks, only image-level labels, which are much cheaper to acquire, are
available. We find that operating on features extracted from the last layer of
a pre-trained Faster-RCNN is more effective compared to previous episodic
learning based few-shot COL methods. Our model simultaneously learns the
distribution of the novel objects and localizes them via
expectation-maximization steps. As a probabilistic model, we employ von
Mises-Fisher (vMF) distribution which captures the semantic information better
than Gaussian distribution when applied to the pre-trained embedding space.
When the novel objects are localized, we utilize them to learn a linear
appearance model to detect novel classes in new images. Our extensive
experiments show that the proposed method, despite being simple, outperforms
strong baselines in few-shot COL and WSOD, as well as large-scale WSOD tasks.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14162</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14169</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Internet of Things from Space: Transforming LTE Machine Type
  Communications for Non-terrestrial Networks</dc:title>
 <dc:creator>Khan, Talha Ahmed</dc:creator>
 <dc:creator>Lin, Xingqin</dc:creator>
 <dc:creator>L&#xf6;wenmark, Stefan Eriksson</dc:creator>
 <dc:creator>Liberg, Olof</dc:creator>
 <dc:creator>Euler, Sebastian</dc:creator>
 <dc:creator>Sedin, Jonas</dc:creator>
 <dc:creator>Yavuz, Emre A.</dc:creator>
 <dc:creator>Shokri-Razaghi, Hazhir</dc:creator>
 <dc:creator>M&#xe4;&#xe4;tt&#xe4;nen, Helka-Liina</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Satellite communication is experiencing a new dawn thanks to low earth orbit
mega constellations being deployed at an unprecedented speed. Fueled by the
renewed interest in non-terrestrial networks (NTN), the Third Generation
Partnership Project (3GPP) is preparing 5G NR, NB-IoT and LTE-M for NTN
operation. This article is focused on LTE-M and the essential adaptations
needed for supporting satellite communication. Specifically, the major
challenges facing LTE-M NTN at the physical and higher layers are discussed and
potential solutions are outlined.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14177</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding the Challenges and Assisting Developers with Developing
  Spark Applications</dc:title>
 <dc:creator>Wang, Zehao</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  To process data more efficiently, big data frameworks provide data
abstractions to developers. However, due to the abstraction, there may be many
challenges for developers to understand and debug the data processing code. To
uncover the challenges in using big data frameworks, we first conduct an
empirical study on 1,000 Apache Spark-related questions on Stack Overflow. We
find that most of the challenges are related to data transformation and API
usage. To solve these challenges, we design an approach, which assists
developers with understanding and debugging data processing in Spark. Our
approach leverages statistical sampling to minimize performance overhead, and
provides intermediate information and hint messages for each data processing
step of a chained method pipeline. The preliminary evaluation of our approach
shows that it has low performance overhead and we receive good feedback from
developers.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14177</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14184</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deformable Linear Object Prediction Using Locally Linear Latent Dynamics</dc:title>
 <dc:creator>Zhang, Wenbo</dc:creator>
 <dc:creator>Schmeckpeper, Karl</dc:creator>
 <dc:creator>Chaudhari, Pratik</dc:creator>
 <dc:creator>Daniilidis, Kostas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a framework for deformable linear object prediction. Prediction of
deformable objects (e.g., rope) is challenging due to their non-linear dynamics
and infinite-dimensional configuration spaces. By mapping the dynamics from a
non-linear space to a linear space, we can use the good properties of linear
dynamics for easier learning and more efficient prediction. We learn a locally
linear, action-conditioned dynamics model that can be used to predict future
latent states. Then, we decode the predicted latent state into the predicted
state. We also apply a sampling-based optimization algorithm to select the
optimal control action. We empirically demonstrate that our approach can
predict the rope state accurately up to ten steps into the future and that our
algorithm can find the optimal action given an initial state and a goal state.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14184</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14189</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DBATES: DataBase of Audio features, Text, and visual Expressions in
  competitive debate Speeches</dc:title>
 <dc:creator>Sen, Taylan K.</dc:creator>
 <dc:creator>Naven, Gazi</dc:creator>
 <dc:creator>Gerstner, Luke</dc:creator>
 <dc:creator>Bagley, Daryl</dc:creator>
 <dc:creator>Baten, Raiyan Abdul</dc:creator>
 <dc:creator>Rahman, Wasifur</dc:creator>
 <dc:creator>Hasan, Kamrul</dc:creator>
 <dc:creator>Haut, Kurtis G.</dc:creator>
 <dc:creator>Mamun, Abdullah</dc:creator>
 <dc:creator>Samrose, Samiha</dc:creator>
 <dc:creator>Solbu, Anne</dc:creator>
 <dc:creator>Barnes, R. Eric</dc:creator>
 <dc:creator>Frank, Mark G.</dc:creator>
 <dc:creator>Hoque, Ehsan</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In this work, we present a database of multimodal communication features
extracted from debate speeches in the 2019 North American Universities Debate
Championships (NAUDC). Feature sets were extracted from the visual (facial
expression, gaze, and head pose), audio (PRAAT), and textual (word sentiment
and linguistic category) modalities of raw video recordings of competitive
collegiate debaters (N=717 6-minute recordings from 140 unique debaters). Each
speech has an associated competition debate score (range: 67-96) from expert
judges as well as competitor demographic and per-round reflection surveys. We
observe the fully multimodal model performs best in comparison to models
trained on various compositions of modalities. We also find that the weights of
some features (such as the expression of joy and the use of the word we) change
in direction between the aforementioned models. We use these results to
highlight the value of a multimodal dataset for studying competitive,
collegiate debate.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures, 4 tables, under-going major revision for TAC</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14191</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Infinity: A Scalable Infrastructure for In-Network Applications</dc:title>
 <dc:creator>Abranches, Marcelo</dc:creator>
 <dc:creator>Olson, Karl</dc:creator>
 <dc:creator>Keller, Eric</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Network programmability is an area of research both defined by its potential
and its current limitations. While programmable hardware enables customization
of device operation, tailoring processing to finely tuned objectives, limited
resources stifle much of the capability and scalability desired for future
technologies. Current solutions to overcome these limitations simply shift the
problem, temporarily offloading memory needs or processing to other systems
while incurring both round-trip time and complexity costs. To overcome these
unnecessary costs, we introduce Infinity, a resource disaggregation method to
move processing to capable devices while continuing to forward as the original
owner, limiting unnecessary buffering and round-trip processing. By forwarding
both the processing need and associated data simultaneously we are able to
scale operation with minimal overhead and delay, improving both capability and
performance objectives for in-network processing.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14193</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Control Synthesis using Signal Temporal Logic Specifications with
  Integral and Derivative Predicates</dc:title>
 <dc:creator>Buyukkocak, Ali Tevfik</dc:creator>
 <dc:creator>Aksaray, Derya</dc:creator>
 <dc:creator>Yaz&#x131;c&#x131;o&#x11f;lu, Yasin</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In many applications, the integrals and derivatives of signals carry valuable
information (e.g., cumulative success over a time window, the rate of change)
regarding the behavior of the underlying system. In this paper, we extend the
expressiveness of Signal Temporal Logic (STL) by introducing predicates that
can define rich properties related to the integral and derivative of a signal.
For control synthesis, the new predicates are encoded into mixed-integer linear
inequalities and are used in the formulation of a mixed-integer linear program
to find a trajectory that satisfies an STL specification. We discuss the
benefits of using the new predicates and illustrate them in a case study
showing the influence of the new predicates on the trajectories of an
autonomous robot.
</dc:description>
 <dc:description>Comment: Accepted to the 2021 American Control Conference (ACC)</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14193</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14202</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Hybrid Queuing Model for Coordinated Vehicle Platooning on
  Mixed-Autonomy Highways: Training and Validation</dc:title>
 <dc:creator>Su, Haoran</dc:creator>
 <dc:creator>Ji, Zhengjie</dc:creator>
 <dc:creator>Johansson, Karl. H.</dc:creator>
 <dc:creator>Jin, Li</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Platooning of connected and autonomous vehicles (CAVs) is an emerging
technology with a strong potential for throughput improvement and fuel
reduction. Adequate macroscopic models are critical for system-level efficiency
and reliability of platooning. In this paper, we consider a hybrid queuing
model for a mixed-autonomy highway section and develop an easy-to-use training
algorithm. The model predicts CAV and non-CAV counts according to the traffic
demand as well as key parameters of the highway section. The training algorithm
learns the highway parameters from observed data in real time. We test the
model and the algorithm in Simulation of Urban Mobility (SUMO) and show that
the prediction error is around 15% in a stationary setting and around 25% in a
non-stationary setting. We also show that the trained model leads to a platoon
headway regulation policy very close to the simulated optimum. The proposed
model and algorithm can directly support model-predictive decision-making for
platooning in mixed autonomy.
</dc:description>
 <dc:description>Comment: 12 pages, 9 figures</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14204</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Unified Approach to Single Image Deraining and Dehazing</dc:title>
 <dc:creator>Liu, Xiaohong</dc:creator>
 <dc:creator>Ma, Yongrui</dc:creator>
 <dc:creator>Shi, Zhihao</dc:creator>
 <dc:creator>Dai, Linhui</dc:creator>
 <dc:creator>Chen, Jun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We develop a new physical model for the rain effect and show that the
well-known atmosphere scattering model (ASM) for the haze effect naturally
emerges as its homogeneous continuous limit. Via depth-aware fusion of
multi-layer rain streaks according to the camera imaging mechanism, the new
model can better capture the sophisticated non-deterministic degradation
patterns commonly seen in real rainy images. We also propose a Densely
Scale-Connected Attentive Network (DSCAN) that is suitable for both deraining
and dehazing tasks. Our design alleviates the bottleneck issue existent in
conventional multi-scale networks and enables more effective information
exchange and aggregation. Extensive experimental results demonstrate that the
proposed DSCAN is able to deliver superior derained/dehazed results on both
synthetic and real images as compared to the state-of-the-art. Moreover, it is
shown that for our DSCAN, the synthetic dataset built using the new physical
model yields better generalization performance on real images in comparison
with the existing datasets based on over-simplified models.
</dc:description>
 <dc:description>Comment: 10 pages, 11 figures</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14206</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Three dimensional higher-order raypath separation in a shallow-water
  waveguide</dc:title>
 <dc:creator>Longyu, Jiang</dc:creator>
 <dc:creator>Zhe, Zhang</dc:creator>
 <dc:creator>Philippe, Roux</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Separating raypaths in a multipath shallow-water environment is a challenge
problem due to the interferences between them and colored noise existing in
ocean environment, especially for two raypaths arrive close to each other.
Thus, in this paper, a three dimensional (3D) higher-order raypath separation
in an array to array configuration is proposed. Performance tests using
simulation data in a multipath environment, real data obtained in an ultrasonic
waveguide and ocean shallow-water data, respectively, illustrate that the
proposed algorithm achieves a higher resolution and a stronger robustness
comparing to the existing algorithms.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14208</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling the Compatibility of Stem Tracks to Generate Music Mashups</dc:title>
 <dc:creator>Huang, Jiawen</dc:creator>
 <dc:creator>Wang, Ju-Chiang</dc:creator>
 <dc:creator>Smith, Jordan B. L.</dc:creator>
 <dc:creator>Song, Xuchen</dc:creator>
 <dc:creator>Wang, Yuxuan</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  A music mashup combines audio elements from two or more songs to create a new
work. To reduce the time and effort required to make them, researchers have
developed algorithms that predict the compatibility of audio elements. Prior
work has focused on mixing unaltered excerpts, but advances in source
separation enable the creation of mashups from isolated stems (e.g., vocals,
drums, bass, etc.). In this work, we take advantage of separated stems not just
for creating mashups, but for training a model that predicts the mutual
compatibility of groups of excerpts, using self-supervised and semi-supervised
methods. Specifically, we first produce a random mashup creation pipeline that
combines stem tracks obtained via source separation, with key and tempo
automatically adjusted to match, since these are prerequisites for high-quality
mashups. To train a model to predict compatibility, we use stem tracks obtained
from the same song as positive examples, and random combinations of stems with
key and/or tempo unadjusted as negative examples. To improve the model and use
more data, we also train on &quot;average&quot; examples: random combinations with
matching key and tempo, where we treat them as unlabeled data as their true
compatibility is unknown. To determine whether the combined signal or the set
of stem signals is more indicative of the quality of the result, we experiment
on two model architectures and train them using semi-supervised learning
technique. Finally, we conduct objective and subjective evaluations of the
system, comparing them to a standard rule-based system.
</dc:description>
 <dc:description>Comment: This is a preprint of the paper accepted by AAAI-21. Please cite the
  version included in the Proceedings of the 35th AAAI Conference on Artificial
  Intelligence</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14208</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14211</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MagDR: Mask-guided Detection and Reconstruction for Defending Deepfakes</dc:title>
 <dc:creator>Chen, Zhikai</dc:creator>
 <dc:creator>Xie, Lingxi</dc:creator>
 <dc:creator>Pang, Shanmin</dc:creator>
 <dc:creator>He, Yong</dc:creator>
 <dc:creator>Zhang, Bo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deepfakes raised serious concerns on the authenticity of visual contents.
Prior works revealed the possibility to disrupt deepfakes by adding adversarial
perturbations to the source data, but we argue that the threat has not been
eliminated yet. This paper presents MagDR, a mask-guided detection and
reconstruction pipeline for defending deepfakes from adversarial attacks. MagDR
starts with a detection module that defines a few criteria to judge the
abnormality of the output of deepfakes, and then uses it to guide a learnable
reconstruction procedure. Adaptive masks are extracted to capture the change in
local facial regions. In experiments, MagDR defends three main tasks of
deepfakes, and the learned reconstruction pipeline transfers across input data,
showing promising performance in defending both black-box and white-box
attacks.
</dc:description>
 <dc:description>Comment: Accepted to CVPR2021</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14212</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synthesize-It-Classifier: Learning a Generative Classifier through
  RecurrentSelf-analysis</dc:title>
 <dc:creator>Pal, Arghya</dc:creator>
 <dc:creator>Phan, Rapha</dc:creator>
 <dc:creator>Wong, KokSheik</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we show the generative capability of an image classifier
network by synthesizing high-resolution, photo-realistic, and diverse images at
scale. The overall methodology, called Synthesize-It-Classifier (STIC), does
not require an explicit generator network to estimate the density of the data
distribution and sample images from that, but instead uses the classifier's
knowledge of the boundary to perform gradient ascent w.r.t. class logits and
then synthesizes images using Gram Matrix Metropolis Adjusted Langevin
Algorithm (GRMALA) by drawing on a blank canvas. During training, the
classifier iteratively uses these synthesized images as fake samples and
re-estimates the class boundary in a recurrent fashion to improve both the
classification accuracy and quality of synthetic images. The STIC shows the
mixing of the hard fake samples (i.e. those synthesized by the one hot class
conditioning), and the soft fake samples (which are synthesized as a convex
combination of classes, i.e. a mixup of classes) improves class interpolation.
We demonstrate an Attentive-STIC network that shows an iterative drawing of
synthesized images on the ImageNet dataset that has thousands of classes. In
addition, we introduce the synthesis using a class conditional score classifier
(Score-STIC) instead of a normal image classifier and show improved results on
several real-world datasets, i.e. ImageNet, LSUN, and CIFAR 10.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14215</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Complete Affine Automorphism Group of Polar Codes</dc:title>
 <dc:creator>Li, Yuan</dc:creator>
 <dc:creator>Zhang, Huazi</dc:creator>
 <dc:creator>Li, Rong</dc:creator>
 <dc:creator>Wang, Jun</dc:creator>
 <dc:creator>Tong, Wen</dc:creator>
 <dc:creator>Yan, Guiying</dc:creator>
 <dc:creator>Ma, Zhiming</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Recently, a permutation-based successive cancellation (PSC) decoding
framework for polar codes attaches much attention. It decodes several permuted
codewords with independent successive cancellation (SC) decoders. Its latency
thus can be reduced to that of SC decoding. However, the PSC framework is
ineffective for permutations falling into the lower-triangular affine (LTA)
automorphism group, as they are invariant under SC decoding. As such, a larger
block lower-triangular affine (BLTA) group that contains SC-variant
permutations was discovered for decreasing polar codes. But it was unknown
whether BLTA equals the complete automorphism group. In this paper, we prove
that BLTA equals the complete automorphisms of decreasing polar codes that can
be formulated as affine trasformations.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14217</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Internet of Things Malware by Analyzing Endpoints in their
  Static Artifacts</dc:title>
 <dc:creator>Anwar, Afsah</dc:creator>
 <dc:creator>Choi, Jinchun</dc:creator>
 <dc:creator>Alabduljabbar, Abdulrahman</dc:creator>
 <dc:creator>Alasmary, Hisham</dc:creator>
 <dc:creator>Spaulding, Jeffrey</dc:creator>
 <dc:creator>Wang, An</dc:creator>
 <dc:creator>Chen, Songqing</dc:creator>
 <dc:creator>Nyang, DaeHun</dc:creator>
 <dc:creator>Awad, Amro</dc:creator>
 <dc:creator>Mohaisen, David</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The lack of security measures among the Internet of Things (IoT) devices and
their persistent online connection gives adversaries a prime opportunity to
target them or even abuse them as intermediary targets in larger attacks such
as distributed denial-of-service (DDoS) campaigns. In this paper, we analyze
IoT malware and focus on the endpoints reachable on the public Internet, that
play an essential part in the IoT malware ecosystem. Namely, we analyze
endpoints acting as dropzones and their targets to gain insights into the
underlying dynamics in this ecosystem, such as the affinity between the
dropzones and their target IP addresses, and the different patterns among
endpoints. Towards this goal, we reverse-engineer 2,423 IoT malware samples and
extract strings from them to obtain IP addresses. We further gather information
about these endpoints from public Internet-wide scanners, such as Shodan and
Censys. For the masked IP addresses, we examine the Classless Inter-Domain
Routing (CIDR) networks accumulating to more than 100 million (78.2% of total
active public IPv4 addresses) endpoints. Our investigation from four different
perspectives provides profound insights into the role of endpoints in IoT
malware attacks, which deepens our understanding of IoT malware ecosystems and
can assist future defenses.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14217</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14221</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ShellCore: Automating Malicious IoT Software Detection by Using Shell
  Commands Representation</dc:title>
 <dc:creator>Alasmary, Hisham</dc:creator>
 <dc:creator>Anwar, Afsah</dc:creator>
 <dc:creator>Abusnaina, Ahmed</dc:creator>
 <dc:creator>Alabduljabbar, Abdulrahman</dc:creator>
 <dc:creator>Abuhamad, Mohammad</dc:creator>
 <dc:creator>Wang, An</dc:creator>
 <dc:creator>Nyang, DaeHun</dc:creator>
 <dc:creator>Awad, Amro</dc:creator>
 <dc:creator>Mohaisen, David</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The Linux shell is a command-line interpreter that provides users with a
command interface to the operating system, allowing them to perform a variety
of functions. Although very useful in building capabilities at the edge, the
Linux shell can be exploited, giving adversaries a prime opportunity to use
them for malicious activities. With access to IoT devices, malware authors can
abuse the Linux shell of those devices to propagate infections and launch
large-scale attacks, e.g., DDoS. In this work, we provide a first look at shell
commands used in Linux-based IoT malware towards detection. We analyze
malicious shell commands found in IoT malware and build a neural network-based
model, ShellCore, to detect malicious shell commands. Namely, we collected a
large dataset of shell commands, including malicious commands extracted from
2,891 IoT malware samples and benign commands collected from real-world network
traffic analysis and volunteered data from Linux users. Using conventional
machine and deep learning-based approaches trained with term- and
character-level features, ShellCore is shown to achieve an accuracy of more
than 99% in detecting malicious shell commands and files (i.e., binaries).
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14221</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14225</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SD-VEC: Software-Defined Vehicular Edge Computing with Ultra-Low Latency</dc:title>
 <dc:creator>Lin, Shih-Chun</dc:creator>
 <dc:creator>Chen, Kwang-Cheng</dc:creator>
 <dc:creator>Karimoddini, Ali</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  New paradigm shifts and 6G technological revolution in vehicular services
have emerged toward unmanned driving, automated transportation, and
self-driving vehicles. As the technology for autonomous vehicles becomes
mature, real challenges come from reliable, safe, real-time connected
transportation operations to achieve ubiquitous and prompt information
exchanges with massive connected and autonomous vehicles. This article aims at
introducing novel wireless distributed architectures that embed the edge
computing capability inside software-defined vehicular networking
infrastructure. Such edge networks consist of open-loop grant-free
communications and computing-based control frameworks, which enable dynamic
eco-routing with ultra-low latency and mobile data-driven orchestration. Thus,
this work advances the frontiers of machine learning potentials and
next-generation mobile system realization in vehicular networking applications.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14231</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Congestion-aware Multi-agent Trajectory Prediction for Collision
  Avoidance</dc:title>
 <dc:creator>Xie, Xu</dc:creator>
 <dc:creator>Zhang, Chi</dc:creator>
 <dc:creator>Zhu, Yixin</dc:creator>
 <dc:creator>Wu, Ying Nian</dc:creator>
 <dc:creator>Zhu, Song-Chun</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Predicting agents' future trajectories plays a crucial role in modern AI
systems, yet it is challenging due to intricate interactions exhibited in
multi-agent systems, especially when it comes to collision avoidance. To
address this challenge, we propose to learn congestion patterns as contextual
cues explicitly and devise a novel &quot;Sense--Learn--Reason--Predict&quot; framework by
exploiting advantages of three different doctrines of thought, which yields the
following desirable benefits: (i) Representing congestion as contextual cues
via latent factors subsumes the concept of social force commonly used in
physics-based approaches and implicitly encodes the distance as a cost, similar
to the way a planning-based method models the environment. (ii) By decomposing
the learning phases into two stages, a &quot;student&quot; can learn contextual cues from
a &quot;teacher&quot; while generating collision-free trajectories. To make the framework
computationally tractable, we formulate it as an optimization problem and
derive an upper bound by leveraging the variational parametrization. In
experiments, we demonstrate that the proposed model is able to generate
collision-free trajectory predictions in a synthetic dataset designed for
collision avoidance evaluation and remains competitive on the commonly used
NGSIM US-101 highway dataset.
</dc:description>
 <dc:description>Comment: ICRA 2021 paper. Project:
  https://xuxie1031.github.io/projects/GTA/GTAProj.html</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14232</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ACRE: Abstract Causal REasoning Beyond Covariation</dc:title>
 <dc:creator>Zhang, Chi</dc:creator>
 <dc:creator>Jia, Baoxiong</dc:creator>
 <dc:creator>Edmonds, Mark</dc:creator>
 <dc:creator>Zhu, Song-Chun</dc:creator>
 <dc:creator>Zhu, Yixin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Causal induction, i.e., identifying unobservable mechanisms that lead to the
observable relations among variables, has played a pivotal role in modern
scientific discovery, especially in scenarios with only sparse and limited
data. Humans, even young toddlers, can induce causal relationships surprisingly
well in various settings despite its notorious difficulty. However, in contrast
to the commonplace trait of human cognition is the lack of a diagnostic
benchmark to measure causal induction for modern Artificial Intelligence (AI)
systems. Therefore, in this work, we introduce the Abstract Causal REasoning
(ACRE) dataset for systematic evaluation of current vision systems in causal
induction. Motivated by the stream of research on causal discovery in Blicket
experiments, we query a visual reasoning system with the following four types
of questions in either an independent scenario or an interventional scenario:
direct, indirect, screening-off, and backward-blocking, intentionally going
beyond the simple strategy of inducing causal relationships by covariation. By
analyzing visual reasoning architectures on this testbed, we notice that pure
neural models tend towards an associative strategy under their chance-level
performance, whereas neuro-symbolic combinations struggle in backward-blocking
reasoning. These deficiencies call for future research in models with a more
comprehensive capability of causal induction.
</dc:description>
 <dc:description>Comment: CVPR 2021 paper. Supplementary:
  http://wellyzhang.github.io/attach/cvpr21zhang_acre_supp.pdf Project:
  http://wellyzhang.github.io/project/acre.html</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14236</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Subspace-based compressive sensing algorithm for raypath separation in a
  shallow-water waveguide</dc:title>
 <dc:creator>Jiang, Longyu</dc:creator>
 <dc:creator>Zhang, Zhe</dc:creator>
 <dc:creator>Jin, Rui</dc:creator>
 <dc:creator>Zhou, Xiao</dc:creator>
 <dc:creator>Roux, Philippe</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Compressive sensing (CS) has been applied to estimate the direction of
arrival (DOA) in underwater acoustics. However, the key problem needed to be
resolved in a {multipath} propagation environment is to suppress the
interferences between the raypaths. Thus, in this paper, {a subspace-based
compressive sensing algorithm that formulates the statistic information of the
signal subspace in a CS framework is proposed.} The experiment results show
that (1) the proposed algorithm enables the separation of raypaths that arrive
closely at the {receiver} array and (2) the existing algorithms fail,
especially in a low signal-to-noise ratio (SNR) environment.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14236</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14238</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FRITL: A Hybrid Method for Causal Discovery in the Presence of Latent
  Confounders</dc:title>
 <dc:creator>Chen, Wei</dc:creator>
 <dc:creator>Zhang, Kun</dc:creator>
 <dc:creator>Cai, Ruichu</dc:creator>
 <dc:creator>Huang, Biwei</dc:creator>
 <dc:creator>Ramsey, Joseph</dc:creator>
 <dc:creator>Hao, Zhifeng</dc:creator>
 <dc:creator>Glymour, Clark</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of estimating a particular type of linear
non-Gaussian model. Without resorting to the overcomplete Independent Component
Analysis (ICA), we show that under some mild assumptions, the model is uniquely
identified by a hybrid method. Our method leverages the advantages of
constraint-based methods and independent noise-based methods to handle both
confounded and unconfounded situations. The first step of our method uses the
FCI procedure, which allows confounders and is able to produce asymptotically
correct results. The results, unfortunately, usually determine very few
unconfounded direct causal relations, because whenever it is possible to have a
confounder, it will indicate it. The second step of our procedure finds the
unconfounded causal edges between observed variables among only those adjacent
pairs informed by the FCI results. By making use of the so-called Triad
condition, the third step is able to find confounders and their causal
relations with other variables. Afterward, we apply ICA on a notably smaller
set of graphs to identify remaining causal relationships if needed. Extensive
experiments on simulated data and real-world data validate the correctness and
effectiveness of the proposed method.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14238</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14244</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of Microarchitectural Side-channel Vulnerabilities, Attacks and
  Defenses in Cryptography</dc:title>
 <dc:creator>Lou, Xiaoxuan</dc:creator>
 <dc:creator>Zhang, Tianwei</dc:creator>
 <dc:creator>Jiang, Jun</dc:creator>
 <dc:creator>Zhang, Yinqian</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Side-channel attacks have become a severe threat to the confidentiality of
computer applications and systems. One popular type of such attacks is the
microarchitectural attack, where the adversary exploits the hardware features
to break the protection enforced by the operating system and steal the secrets
from the program. In this paper, we systematize microarchitectural side
channels with a focus on attacks and defenses in cryptographic applications. We
make three contributions. (1) We survey past research literature to categorize
microarchitectural side-channel attacks. Since these are hardware attacks
targeting software, we summarize the vulnerable implementations in software, as
well as flawed designs in hardware. (2) We identify common strategies to
mitigate microarchitectural attacks, from the application, OS and hardware
levels. (3) We conduct a large-scale evaluation on popular cryptographic
applications in the real world, and analyze the severity, practicality and
impact of side-channel vulnerabilities. This survey is expected to inspire
side-channel research community to discover new attacks, and more importantly,
propose new defense solutions against them.
</dc:description>
 <dc:description>Comment: In processings of the ACM Computing Surveys. arXiv admin note:
  substantial text overlap with arXiv:1911.09312</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14244</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14245</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improve GAN-based Neural Vocoder using Pointwise Relativistic
  LeastSquare GAN</dc:title>
 <dc:creator>Wang, Congyi</dc:creator>
 <dc:creator>Chen, Yu</dc:creator>
 <dc:creator>Wang, Bin</dc:creator>
 <dc:creator>Shi, Yi</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  GAN-based neural vocoders, such as Parallel WaveGAN and MelGAN have attracted
great interest due to their lightweight and parallel structures, enabling them
to generate high fidelity waveform in a real-time manner. In this paper,
inspired by Relativistic GAN, we introduce a novel variant of the LSGAN
framework under the context of waveform synthesis, named Pointwise Relativistic
LSGAN (PRLSGAN). In this approach, we take the truism score distribution into
consideration and combine the original MSE loss with the proposed pointwise
relative discrepancy loss to increase the difficulty of the generator to fool
the discriminator, leading to improved generation quality. Moreover, PRLSGAN is
a general-purposed framework that can be combined with any GAN-based neural
vocoder to enhance its generation quality. Experiments have shown a consistent
performance boost based on Parallel WaveGAN and MelGAN, demonstrating the
effectiveness and strong generalization ability of our proposed PRLSGAN neural
vocoders.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14245</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14247</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Super-Resolving Compressed Video in Coding Chain</dc:title>
 <dc:creator>Hou, Dewang</dc:creator>
 <dc:creator>Zhao, Yang</dc:creator>
 <dc:creator>Ye, Yuyao</dc:creator>
 <dc:creator>Yang, Jiayu</dc:creator>
 <dc:creator>Zhang, Jian</dc:creator>
 <dc:creator>Wang, Ronggang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Scaling and lossy coding are widely used in video transmission and storage.
Previous methods for enhancing the resolution of such videos often ignore the
inherent interference between resolution loss and compression artifacts, which
compromises perceptual video quality. To address this problem, we present a
mixed-resolution coding framework, which cooperates with a reference-based
DCNN. In this novel coding chain, the reference-based DCNN learns the direct
mapping from low-resolution (LR) compressed video to their high-resolution (HR)
clean version at the decoder side. We further improve reconstruction quality by
devising an efficient deformable alignment module with receptive field block to
handle various motion distances and introducing a disentangled loss that helps
networks distinguish the artifact patterns from texture. Extensive experiments
demonstrate the effectiveness of proposed innovations by comparing with
state-of-the-art single image, video and reference-based restoration methods.
</dc:description>
 <dc:description>Comment: Technical report</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14247</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14251</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Embedding Power Flow into Machine Learning for Parameter and State
  Estimation</dc:title>
 <dc:creator>Pagnier, Laurent</dc:creator>
 <dc:creator>Chertkov, Michael</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Modern state and parameter estimations in power systems consist of two
stages: the outer problem of minimizing the mismatch between network
observation and prediction over the network parameters, and the inner problem
of predicting the system state for given values of the parameters. The standard
solution of the combined problem is iterative: (a) set the parameters, e.g. to
priors on the power line characteristics, (b) map input observation to
prediction of the output, (c) compute the mismatch between predicted and
observed output, (d) make a gradient descent step in the space of parameters to
minimize the mismatch, and loop back to (a). We show how modern Machine
Learning (ML), and specifically training guided by automatic differentiation,
allows to resolve the iterative loop more efficiently. Moreover, we extend the
scheme to the case of incomplete observations, where Phasor Measurement Units
(reporting real and reactive powers, voltage and phase) are available only at
the generators (PV buses), while loads (PQ buses) report (via SCADA controls)
only active and reactive powers. Considering it from the implementation
perspective, our methodology of resolving the parameter and state estimation
problem can be viewed as embedding of the Power Flow (PF) solver into the
training loop of the Machine Learning framework (PyTorch, in this study). We
argue that this embedding can help to resolve high-level optimization problems
in power system operations and planning.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures, 1 table</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14251</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14252</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward Safety-Aware Informative Motion Planning for Legged Robots</dc:title>
 <dc:creator>Teng, Sangli</dc:creator>
 <dc:creator>Gong, Yukai</dc:creator>
 <dc:creator>Grizzle, Jessy W.</dc:creator>
 <dc:creator>Ghaffari, Maani</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper reports on developing an integrated framework for safety-aware
informative motion planning suitable for legged robots. The
information-gathering planner takes a dense stochastic map of the environment
into account, while safety constraints are enforced via Control Barrier
Functions (CBFs). The planner is based on the Incrementally-exploring
Information Gathering (IIG) algorithm and allows closed-loop kinodynamic node
expansion using a Model Predictive Control (MPC) formalism. Robotic exploration
and information gathering problems are inherently path-dependent problems. That
is, the information collected along a path depends on the state and observation
history. As such, motion planning solely based on a modular cost does not lead
to suitable plans for exploration. We propose SAFE-IIG, an integrated
informative motion planning algorithm that takes into account: 1) a robot's
perceptual field of view via a submodular information function computed over a
stochastic map of the environment, 2) a robot's dynamics and safety constraints
via discrete-time CBFs and MPC for closed-loop multi-horizon node expansions,
and 3) an automatic stopping criterion via setting an information-theoretic
planning horizon. The simulation results show that SAFE-IIG can plan a safe and
dynamically feasible path while exploring a dense map.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14252</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14256</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Reactive and Predictive Differentiable Controllers for
  Switching Linear Dynamical Models</dc:title>
 <dc:creator>Saxena, Saumya</dc:creator>
 <dc:creator>LaGrassa, Alex</dc:creator>
 <dc:creator>Kroemer, Oliver</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Humans leverage the dynamics of the environment and their own bodies to
accomplish challenging tasks such as grasping an object while walking past it
or pushing off a wall to turn a corner. Such tasks often involve switching
dynamics as the robot makes and breaks contact. Learning these dynamics is a
challenging problem and prone to model inaccuracies, especially near contact
regions. In this work, we present a framework for learning composite dynamical
behaviors from expert demonstrations. We learn a switching linear dynamical
model with contacts encoded in switching conditions as a close approximation of
our system dynamics. We then use discrete-time LQR as the differentiable policy
class for data-efficient learning of control to develop a control strategy that
operates over multiple dynamical modes and takes into account discontinuities
due to contact. In addition to predicting interactions with the environment,
our policy effectively reacts to inaccurate predictions such as unanticipated
contacts. Through simulation and real world experiments, we demonstrate
generalization of learned behaviors to different scenarios and robustness to
model inaccuracies during execution.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14256</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14259</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OTA: Optimal Transport Assignment for Object Detection</dc:title>
 <dc:creator>Ge, Zheng</dc:creator>
 <dc:creator>Liu, Songtao</dc:creator>
 <dc:creator>Li, Zeming</dc:creator>
 <dc:creator>Yoshie, Osamu</dc:creator>
 <dc:creator>Sun, Jian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent advances in label assignment in object detection mainly seek to
independently define positive/negative training samples for each ground-truth
(gt) object. In this paper, we innovatively revisit the label assignment from a
global perspective and propose to formulate the assigning procedure as an
Optimal Transport (OT) problem -- a well-studied topic in Optimization Theory.
Concretely, we define the unit transportation cost between each demander
(anchor) and supplier (gt) pair as the weighted summation of their
classification and regression losses. After formulation, finding the best
assignment solution is converted to solve the optimal transport plan at minimal
transportation costs, which can be solved via Sinkhorn-Knopp Iteration. On
COCO, a single FCOS-ResNet-50 detector equipped with Optimal Transport
Assignment (OTA) can reach 40.7% mAP under 1X scheduler, outperforming all
other existing assigning methods. Extensive experiments conducted on COCO and
CrowdHuman further validate the effectiveness of our proposed OTA, especially
its superiority in crowd scenarios. The code is available at
https://github.com/Megvii-BaseDetection/OTA.
</dc:description>
 <dc:description>Comment: CVPR2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14261</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Persistent and Context-aware Behavior Tree Framework for Multi Sensor
  Localization in Autonomous Driving</dc:title>
 <dc:creator>Yi, Siqi</dc:creator>
 <dc:creator>Worrall, Stewart</dc:creator>
 <dc:creator>Nebot, Eduardo</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Robust and persistent localisation is essential for ensuring the safe
operation of autonomous vehicles. When operating in large and diverse urban
driving environments, autonomous vehicles are frequently exposed to situations
that violate the assumptions of algorithms, suffer from the failure of one or
more sensors, or other events that lead to a loss of localisation.
  This paper proposes the use of a behavior tree framework that can monitor the
performance of localisation health metrics and triggers intelligent responses
such as sensor switching and loss recovery. The algorithm presented selects the
best available sensor data at given time and location, and can perform a series
of actions to react to adverse situations. The behavior tree encapsulates the
system-level logic to give commands that make up the intelligent behaviors, so
that the localisation &quot;actuators&quot; (data association, optimisation, filters,
etc) can perform decoupled actions without needing context. Experimental
results to validate the algorithms are presented using the University of Sydney
Campus dataset which was taken weekly over an 18 month period. A video showing
the online localisation process can be found here: https://youtu.be/353uKqXLV5g
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14261</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14262</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Pandemic Control Synthesis with Formal Specifications: A Case
  Study on COVID-19 Pandemic</dc:title>
 <dc:creator>Xu, Zhe</dc:creator>
 <dc:creator>Duan, Xiaoming</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Pandemics can bring a range of devastating consequences to public health and
the world economy. Identifying the most effective control strategies has been
the imperative task all around the world. Various public health control
strategies have been proposed and tested against pandemic diseases (e.g.,
COVID-19). We study two specific pandemic control models: the susceptible,
exposed, infectious, recovered (SEIR) model with vaccination control; and the
SEIR model with shield immunity control. We express the pandemic control
requirement in metric temporal logic (MTL) formulas. We then develop an
iterative approach for synthesizing the optimal control strategies with MTL
specifications. We provide simulation results in two different scenarios for
robust control of the COVID-19 pandemic: one for vaccination control, and
another for shield immunity control, with the model parameters estimated from
data in Lombardy, Italy. The results show that the proposed synthesis approach
can generate control inputs such that the time-varying numbers of individuals
in each category (e.g., infectious, immune) satisfy the MTL specifications with
robustness against initial state and parameter uncertainties.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:2007.15114</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14262</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14264</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Provably Correct Controller Synthesis of Switched Stochastic Systems
  with Metric Temporal Logic Specifications: A Case Study on Power Systems</dc:title>
 <dc:creator>Xu, Zhe</dc:creator>
 <dc:creator>Zhang, Yichen</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper, we present a provably correct controller synthesis approach
for switched stochastic control systems with metric temporal logic (MTL)
specifications with provable probabilistic guarantees. We first present the
stochastic control bisimulation function for switched stochastic control
systems, which bounds the trajectory divergence between the switched stochastic
control system and its nominal deterministic control system in a probabilistic
fashion. We then develop a method to compute optimal control inputs by solving
an optimization problem for the nominal trajectory of the deterministic control
system with robustness against initial state variations and stochastic
uncertainties. We implement our robust stochastic controller synthesis approach
on both a four-bus power system and a nine-bus power system under generation
loss disturbances, with MTL specifications expressing requirements for the grid
frequency deviations, wind turbine generator rotor speed variations and the
power flow constraints at different power lines.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1911.11347</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14264</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14267</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contrastive Learning based Hybrid Networks for Long-Tailed Image
  Classification</dc:title>
 <dc:creator>Wang, Peng</dc:creator>
 <dc:creator>Han, Kai</dc:creator>
 <dc:creator>Wei, Xiu-Shen</dc:creator>
 <dc:creator>Zhang, Lei</dc:creator>
 <dc:creator>Wang, Lei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Learning discriminative image representations plays a vital role in
long-tailed image classification because it can ease the classifier learning in
imbalanced cases. Given the promising performance contrastive learning has
shown recently in representation learning, in this work, we explore effective
supervised contrastive learning strategies and tailor them to learn better
image representations from imbalanced data in order to boost the classification
accuracy thereon. Specifically, we propose a novel hybrid network structure
being composed of a supervised contrastive loss to learn image representations
and a cross-entropy loss to learn classifiers, where the learning is
progressively transited from feature learning to the classifier learning to
embody the idea that better features make better classifiers. We explore two
variants of contrastive loss for feature learning, which vary in the forms but
share a common idea of pulling the samples from the same class together in the
normalized embedding space and pushing the samples from different classes
apart. One of them is the recently proposed supervised contrastive (SC) loss,
which is designed on top of the state-of-the-art unsupervised contrastive loss
by incorporating positive samples from the same class. The other is a
prototypical supervised contrastive (PSC) learning strategy which addresses the
intensive memory consumption in standard SC loss and thus shows more promise
under limited memory budget. Extensive experiments on three long-tailed
classification datasets demonstrate the advantage of the proposed contrastive
learning based hybrid networks in long-tailed classification.
</dc:description>
 <dc:description>Comment: CVPR 2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14267</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14268</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Confluent Vessel Trees with Accurate Bifurcations</dc:title>
 <dc:creator>Zhang, Zhongwen</dc:creator>
 <dc:creator>Marin, Dmitrii</dc:creator>
 <dc:creator>Drangova, Maria</dc:creator>
 <dc:creator>Boykov, Yuri</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We are interested in unsupervised reconstruction of complex near-capillary
vasculature with thousands of bifurcations where supervision and learning are
infeasible. Unsupervised methods can use many structural constraints, e.g.
topology, geometry, physics. Common techniques use variants of MST on geodesic
tubular graphs minimizing symmetric pairwise costs, i.e. distances. We show
limitations of such standard undirected tubular graphs producing typical errors
at bifurcations where flow &quot;directedness&quot; is critical. We introduce a new
general concept of confluence for continuous oriented curves forming vessel
trees and show how to enforce it on discrete tubular graphs. While confluence
is a high-order property, we present an efficient practical algorithm for
reconstructing confluent vessel trees using minimum arborescence on a directed
graph enforcing confluence via simple flow-extrapolating arc construction.
Empirical tests on large near-capillary sub-voxel vasculature volumes
demonstrate significantly improved reconstruction accuracy at bifurcations. Our
code has also been made publicly available.
</dc:description>
 <dc:description>Comment: 13 pages, 14 figures, CVPR2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14268</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14269</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Input-Output Balanced Framework for Long-tailed LiDAR Semantic
  Segmentation</dc:title>
 <dc:creator>Cong, Peishan</dc:creator>
 <dc:creator>Zhu, Xinge</dc:creator>
 <dc:creator>Ma, Yuexin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A thorough and holistic scene understanding is crucial for autonomous
vehicles, where LiDAR semantic segmentation plays an indispensable role.
However, most existing methods focus on the network design while neglecting the
inherent difficulty, imbalanced data distribution in the realistic dataset
(also named long-tailed distribution), which narrows down the capability of
state-of-the-art methods. In this paper, we propose an input-output balanced
framework to handle the issue of long-tailed distribution. Specifically, for
the input space, we synthesize these tailed instances from mesh models and well
simulate the position and density distribution of LiDAR scan, which enhances
the input data balance and improves the data diversity. For the output space, a
multi-head block is proposed to group different categories based on their
shapes and instance amounts, which alleviates the biased representation of
dominating category during the feature learning. We evaluate the proposed model
on two large-scale datasets, SemanticKITTI and nuScenes, where state-of-the-art
results demonstrate its effectiveness. The proposed new modules can also be
used as a plug-and-play, and we apply them on various backbones and datasets,
showing its good generalization ability.
</dc:description>
 <dc:description>Comment: Accepted by ICME 2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14269</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14274</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Character Controllers Using Motion VAEs</dc:title>
 <dc:creator>Ling, Hung Yu</dc:creator>
 <dc:creator>Zinno, Fabio</dc:creator>
 <dc:creator>Cheng, George</dc:creator>
 <dc:creator>van de Panne, Michiel</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  A fundamental problem in computer animation is that of realizing purposeful
and realistic human movement given a sufficiently-rich set of motion capture
clips. We learn data-driven generative models of human movement using
autoregressive conditional variational autoencoders, or Motion VAEs. The latent
variables of the learned autoencoder define the action space for the movement
and thereby govern its evolution over time. Planning or control algorithms can
then use this action space to generate desired motions. In particular, we use
deep reinforcement learning to learn controllers that achieve goal-directed
movements. We demonstrate the effectiveness of the approach on multiple tasks.
We further evaluate system-design choices and describe the current limitations
of Motion VAEs.
</dc:description>
 <dc:description>Comment: Project page: https://www.cs.ubc.ca/~hyuling/projects/mvae/ ; Code:
  https://github.com/electronicarts/character-motion-vaes</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14274</dc:identifier>
 <dc:identifier>doi:10.1145/3386569.3392422</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14275</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DDR-Net: Learning Multi-Stage Multi-View Stereo With Dynamic Depth Range</dc:title>
 <dc:creator>Yi, Puyuan</dc:creator>
 <dc:creator>Tang, Shengkun</dc:creator>
 <dc:creator>Yao, Jian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  To obtain high-resolution depth maps, some previous learning-based multi-view
stereo methods build a cost volume pyramid in a coarse-to-fine manner. These
approaches leverage fixed depth range hypotheses to construct cascaded plane
sweep volumes. However, it is inappropriate to set identical range hypotheses
for each pixel since the uncertainties of previous per-pixel depth predictions
are spatially varying. Distinct from these approaches, we propose a Dynamic
Depth Range Network (DDR-Net) to determine the depth range hypotheses
dynamically by applying a range estimation module (REM) to learn the
uncertainties of range hypotheses in the former stages. Specifically, in our
DDR-Net, we first build an initial depth map at the coarsest resolution of an
image across the entire depth range. Then the range estimation module (REM)
leverages the probability distribution information of the initial depth to
estimate the depth range hypotheses dynamically for the following stages.
Moreover, we develop a novel loss strategy, which utilizes learned dynamic
depth ranges to generate refined depth maps, to keep the ground truth value of
each pixel covered in the range hypotheses of the next stage. Extensive
experimental results show that our method achieves superior performance over
other state-of-the-art methods on the DTU benchmark and obtains comparable
results on the Tanks and Temples benchmark. The code is available at
https://github.com/Tangshengku/DDR-Net.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14275</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14283</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OmniHang: Learning to Hang Arbitrary Objects using Contact Point
  Correspondences and Neural Collision Estimation</dc:title>
 <dc:creator>You, Yifan</dc:creator>
 <dc:creator>Shao, Lin</dc:creator>
 <dc:creator>Migimatsu, Toki</dc:creator>
 <dc:creator>Bohg, Jeannette</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In this paper, we explore whether a robot can learn to hang arbitrary objects
onto a diverse set of supporting items such as racks or hooks. Endowing robots
with such an ability has applications in many domains such as domestic
services, logistics, or manufacturing. Yet, it is a challenging manipulation
task due to the large diversity of geometry and topology of everyday objects.
In this paper, we propose a system that takes partial point clouds of an object
and a supporting item as input and learns to decide where and how to hang the
object stably. Our system learns to estimate the contact point correspondences
between the object and supporting item to get an estimated stable pose. We then
run a deep reinforcement learning algorithm to refine the predicted stable
pose. Then, the robot needs to find a collision-free path to move the object
from its initial pose to stable hanging pose. To this end, we train a neural
network based collision estimator that takes as input partial point clouds of
the object and supporting item. We generate a new and challenging, large-scale,
synthetic dataset annotated with stable poses of objects hung on various
supporting items and their contact point correspondences. In this dataset, we
show that our system is able to achieve a 68.3% success rate of predicting
stable object poses and has a 52.1% F1 score in terms of finding feasible
paths. Supplemental material and videos are available on our project webpage.
</dc:description>
 <dc:description>Comment: Accepted to IEEE International Conference on Robotics and Automation
  (ICRA) 2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14283</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14286</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IMU Data Processing For Inertial Aided Navigation: A Recurrent Neural
  Network Based Approach</dc:title>
 <dc:creator>Zhang, Ming</dc:creator>
 <dc:creator>Zhang, Mingming</dc:creator>
 <dc:creator>Chen, Yiming</dc:creator>
 <dc:creator>Li, Mingyang</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we propose a novel method for performing inertial aided
navigation, by using deep neural networks (DNNs). To date, most DNN inertial
navigation methods focus on the task of inertial odometry, by taking gyroscope
and accelerometer readings as input and regressing for integrated IMU poses
(i.e., position and orientation). While this design has been successfully
applied on a number of applications, it is not of theoretical performance
guarantee unless patterned motion is involved. This inevitably leads to
significantly reduced accuracy and robustness in certain use cases. To solve
this problem, we design a framework to compute observable IMU integration terms
using DNNs, followed by the numerical pose integration and sensor fusion to
achieve the performance gain. Specifically, we perform detailed analysis on the
motion terms in IMU kinematic equations, propose a dedicated network design,
loss functions, and training strategies for the IMU data processing, and
conduct extensive experiments. The results show that our method is generally
applicable and outperforms both traditional and DNN methods by wide margins.
</dc:description>
 <dc:description>Comment: IEEE International Conference on Robotics and Automation (ICRA),
  Xi'an, China, 2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14286</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14291</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vulnerability Due to Training Order in Split Learning</dc:title>
 <dc:creator>Madaan, Harshit</dc:creator>
 <dc:creator>Gawali, Manish</dc:creator>
 <dc:creator>Kulkarni, Viraj</dc:creator>
 <dc:creator>Pant, Aniruddha</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Split learning (SL) is a privacy-preserving distributed deep learning method
used to train a collaborative model without the need for sharing of patient's
raw data between clients. In split learning, an additional privacy-preserving
algorithm called no-peek algorithm can be incorporated, which is robust to
adversarial attacks. The privacy benefits offered by split learning make it
suitable for practice in the healthcare domain. However, the split learning
algorithm is flawed as the collaborative model is trained sequentially, i.e.,
one client trains after the other. We point out that the model trained using
the split learning algorithm gets biased towards the data of the clients used
for training towards the end of a round. This makes SL algorithms highly
susceptible to the order in which clients are considered for training. We
demonstrate that the model trained using the data of all clients does not
perform well on the client's data which was considered earliest in a round for
training the model. Moreover, we show that this effect becomes more prominent
with the increase in the number of clients. We also demonstrate that the
SplitFedv3 algorithm mitigates this problem while still leveraging the privacy
benefits provided by split learning.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14291</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14294</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HUGE: An Efficient and Scalable Subgraph Enumeration System</dc:title>
 <dc:creator>Yang, Zhengyi</dc:creator>
 <dc:creator>Lai, Longbin</dc:creator>
 <dc:creator>Lin, Xuemin</dc:creator>
 <dc:creator>Hao, Kongzhang</dc:creator>
 <dc:creator>Zhang, Wenjie</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Subgraph enumeration is a fundamental problem in graph analytics, which aims
to find all instances of a given query graph on a large data graph. In this
paper, we propose a system called HUGE to efficiently process subgraph
enumeration at scale in the distributed context. HUGE features 1) an optimiser
to compute an advanced execution plan without the constraints of existing
works; 2) a hybrid communication layer that supports both pushing and pulling
communication; 3) a novel two-stage execution mode with a lock-free and
zero-copy cache design, 4) a BFS/DFS-adaptive scheduler to bound memory
consumption, and 5) two-layer intra- and inter-machine load balancing. HUGE is
generic such that all existing distributed subgraph enumeration algorithms can
be plugged in to enjoy automatic speed up and bounded-memory execution.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14295</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement Learning for Robust Parameterized Locomotion Control of
  Bipedal Robots</dc:title>
 <dc:creator>Li, Zhongyu</dc:creator>
 <dc:creator>Cheng, Xuxin</dc:creator>
 <dc:creator>Peng, Xue Bin</dc:creator>
 <dc:creator>Abbeel, Pieter</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:creator>Berseth, Glen</dc:creator>
 <dc:creator>Sreenath, Koushil</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Developing robust walking controllers for bipedal robots is a challenging
endeavor. Traditional model-based locomotion controllers require simplifying
assumptions and careful modelling; any small errors can result in unstable
control. To address these challenges for bipedal locomotion, we present a
model-free reinforcement learning framework for training robust locomotion
policies in simulation, which can then be transferred to a real bipedal Cassie
robot. To facilitate sim-to-real transfer, domain randomization is used to
encourage the policies to learn behaviors that are robust across variations in
system dynamics. The learned policies enable Cassie to perform a set of diverse
and dynamic behaviors, while also being more robust than traditional
controllers and prior learning-based methods that use residual control. We
demonstrate this on versatile walking behaviors such as tracking a target
walking velocity, walking height, and turning yaw.
</dc:description>
 <dc:description>Comment: To appear on 2021 International Conference on Robotics and Automation
  (ICRA 2021)</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14295</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14297</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CNN-based Discriminative Training for Domain Compensation in Acoustic
  Event Detection with Frame-wise Classifier</dc:title>
 <dc:creator>Tang, Tiantian</dc:creator>
 <dc:creator>Zhou, Xinyuan</dc:creator>
 <dc:creator>Long, Yanhua</dc:creator>
 <dc:creator>Li, Yijie</dc:creator>
 <dc:creator>Liang, Jiaen</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Domain mismatch is a noteworthy issue in acoustic event detection tasks, as
the target domain data is difficult to access in most real applications. In
this study, we propose a novel CNN-based discriminative training framework as a
domain compensation method to handle this issue. It uses a parallel CNN-based
discriminator to learn a pair of high-level intermediate acoustic
representations. Together with a binary discriminative loss, the discriminators
are forced to maximally exploit the discrimination of heterogeneous acoustic
information in each audio clip with target events, which results in a robust
paired representations that can well discriminate the target events and
background/domain variations separately. Moreover, to better learn the
transient characteristics of target events, a frame-wise classifier is designed
to perform the final classification. In addition, a two-stage training with the
CNN-based discriminator initialization is further proposed to enhance the
system training. All experiments are performed on the DCASE 2018 Task3
datasets. Results show that our proposal significantly outperforms the official
baseline on cross-domain conditions in AUC by relative $1.8-12.1$% without any
performance degradation on in-domain evaluation conditions.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14297</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14301</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation of Preprocessing Techniques for U-Net Based Automated Liver
  Segmentation</dc:title>
 <dc:creator>Islam, Muhammad</dc:creator>
 <dc:creator>Khan, Kaleem Nawaz</dc:creator>
 <dc:creator>Khan, Muhammad Salman</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  To extract liver from medical images is a challenging task due to similar
intensity values of liver with adjacent organs, various contrast levels,
various noise associated with medical images and irregular shape of liver. To
address these issues, it is important to preprocess the medical images, i.e.,
computerized tomography (CT) and magnetic resonance imaging (MRI) data prior to
liver analysis and quantification. This paper investigates the impact of
permutation of various preprocessing techniques for CT images, on the automated
liver segmentation using deep learning, i.e., U-Net architecture. The study
focuses on Hounsfield Unit (HU) windowing, contrast limited adaptive histogram
equalization (CLAHE), z-score normalization, median filtering and
Block-Matching and 3D (BM3D) filtering. The segmented results show that
combination of three techniques; HU-windowing, median filtering and z-score
normalization achieve optimal performance with Dice coefficient of 96.93%,
90.77% and 90.84% for training, validation and testing respectively.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14302</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mutually-Constrained Monotonic Multihead Attention for Online ASR</dc:title>
 <dc:creator>Song, Jaeyun</dc:creator>
 <dc:creator>Shim, Hajin</dc:creator>
 <dc:creator>Yang, Eunho</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Despite the feature of real-time decoding, Monotonic Multihead Attention
(MMA) shows comparable performance to the state-of-the-art offline methods in
machine translation and automatic speech recognition (ASR) tasks. However, the
latency of MMA is still a major issue in ASR and should be combined with a
technique that can reduce the test latency at inference time, such as
head-synchronous beam search decoding, which forces all non-activated heads to
activate after a small fixed delay from the first head activation. In this
paper, we remove the discrepancy between training and test phases by
considering, in the training of MMA, the interactions across multiple heads
that will occur in the test time. Specifically, we derive the expected
alignments from monotonic attention by considering the boundaries of other
heads and reflect them in the learning process. We validate our proposed method
on the two standard benchmark datasets for ASR and show that our approach, MMA
with the mutually-constrained heads from the training stage, provides better
performance than baselines.
</dc:description>
 <dc:description>Comment: Accepted at IEEE ICASSP 2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14303</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Client-Server Optimization for SLAM with Limited On-Device
  Resources</dc:title>
 <dc:creator>Zhang, Yetong</dc:creator>
 <dc:creator>Hsiao, Ming</dc:creator>
 <dc:creator>Zhao, Yipu</dc:creator>
 <dc:creator>Dong, Jing</dc:creator>
 <dc:creator>Enge, Jakob J.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Simultaneous localization and mapping (SLAM) is a crucial functionality for
exploration robots and virtual/augmented reality (VR/AR) devices. However, some
of such devices with limited resources cannot afford the computational or
memory cost to run full SLAM algorithms. We propose a general client-server
SLAM optimization framework that achieves accurate real-time state estimation
on the device with low requirements of on-board resources. The resource-limited
device (the client) only works on a small part of the map, and the rest of the
map is processed by the server. By sending the summarized information of the
rest of map to the client, the on-device state estimation is more accurate.
Further improvement of accuracy is achieved in the presence of on-device early
loop closures, which enables reloading useful variables from the server to the
client. Experimental results from both synthetic and real-world datasets
demonstrate that the proposed optimization framework achieves accurate
estimation in real-time with limited computation and memory budget of the
device.
</dc:description>
 <dc:description>Comment: accepted in ICRA 2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14303</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14314</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>City-scale Scene Change Detection using Point Clouds</dc:title>
 <dc:creator>Yew, Zi Jian</dc:creator>
 <dc:creator>Lee, Gim Hee</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a method for detecting structural changes in a city using images
captured from vehicular mounted cameras over traversals at two different times.
We first generate 3D point clouds for each traversal from the images and
approximate GNSS/INS readings using Structure-from-Motion (SfM). A direct
comparison of the two point clouds for change detection is not ideal due to
inaccurate geo-location information and possible drifts in the SfM. To
circumvent this problem, we propose a deep learning-based non-rigid
registration on the point clouds which allows us to compare the point clouds
for structural change detection in the scene. Furthermore, we introduce a dual
thresholding check and post-processing step to enhance the robustness of our
method. We collect two datasets for the evaluation of our approach. Experiments
show that our method is able to detect scene changes effectively, even in the
presence of viewpoint and illumination differences.
</dc:description>
 <dc:description>Comment: 8 pages, 10 figures. To be presented at ICRA2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14314</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14326</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bidirectional Projection Network for Cross Dimension Scene Understanding</dc:title>
 <dc:creator>Hu, Wenbo</dc:creator>
 <dc:creator>Zhao, Hengshuang</dc:creator>
 <dc:creator>Jiang, Li</dc:creator>
 <dc:creator>Jia, Jiaya</dc:creator>
 <dc:creator>Wong, Tien-Tsin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  2D image representations are in regular grids and can be processed
efficiently, whereas 3D point clouds are unordered and scattered in 3D space.
The information inside these two visual domains is well complementary, e.g., 2D
images have fine-grained texture while 3D point clouds contain plentiful
geometry information. However, most current visual recognition systems process
them individually. In this paper, we present a \emph{bidirectional projection
network (BPNet)} for joint 2D and 3D reasoning in an end-to-end manner. It
contains 2D and 3D sub-networks with symmetric architectures, that are
connected by our proposed \emph{bidirectional projection module (BPM)}. Via the
\emph{BPM}, complementary 2D and 3D information can interact with each other in
multiple architectural levels, such that advantages in these two visual domains
can be combined for better scene recognition. Extensive quantitative and
qualitative experimental evaluations show that joint reasoning over 2D and 3D
visual domains can benefit both 2D and 3D scene understanding simultaneously.
Our \emph{BPNet} achieves top performance on the ScanNetV2 benchmark for both
2D and 3D semantic segmentation. Code is available at
\url{https://github.com/wbhu/BPNet}.
</dc:description>
 <dc:description>Comment: CVPR 2021 (Oral)</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14326</dc:identifier>
 <dc:identifier>CVPR 2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14328</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online structural health monitoring by model order reduction and deep
  learning algorithms</dc:title>
 <dc:creator>Rosafalco, Luca</dc:creator>
 <dc:creator>Torzoni, Matteo</dc:creator>
 <dc:creator>Manzoni, Andrea</dc:creator>
 <dc:creator>Mariani, Stefano</dc:creator>
 <dc:creator>Corigliano, Alberto</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Within a structural health monitoring (SHM) framework, we propose a
simulation-based classification strategy to move towards online damage
localization. The procedure combines parametric Model Order Reduction (MOR)
techniques and Fully Convolutional Networks (FCNs) to analyze raw vibration
measurements recorded on the monitored structure. First, a dataset of possible
structural responses under varying operational conditions is built through a
physics-based model, allowing for a finite set of predefined damage scenarios.
Then, the dataset is used for the offline training of the FCN. Because of the
extremely large number of model evaluations required by the dataset
construction, MOR techniques are employed to reduce the computational burden.
The trained classifier is shown to be able to map unseen vibrational
recordings, e.g. collected on-the-fly from sensors placed on the structure, to
the actual damage state, thus providing information concerning the presence and
also the location of damage. The proposed strategy has been validated by means
of two case studies, concerning a 2D portal frame and a 3D portal frame railway
bridge; MOR techniques have allowed us to respectively speed up the analyses
about 30 and 420 times. For both the case studies, after training the
classifier has attained an accuracy greater than 85%.
</dc:description>
 <dc:description>Comment: 30 pages, 32 figures</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14328</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14330</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Guided Training: A Simple Method for Single-channel Speaker Separation</dc:title>
 <dc:creator>Li, Hao</dc:creator>
 <dc:creator>Zhang, Xueliang</dc:creator>
 <dc:creator>Gao, Guanglai</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Deep learning has shown a great potential for speech separation, especially
for speech and non-speech separation. However, it encounters permutation
problem for multi-speaker separation where both target and interference are
speech. Permutation Invariant training (PIT) was proposed to solve this problem
by permuting the order of the multiple speakers. Another way is to use an
anchor speech, a short speech of the target speaker, to model the speaker
identity. In this paper, we propose a simple strategy to train a long
short-term memory (LSTM) model to solve the permutation problem in speaker
separation. Specifically, we insert a short speech of target speaker at the
beginning of a mixture as guide information. So, the first appearing speaker is
defined as the target. Due to the powerful capability on sequence modeling,
LSTM can use its memory cells to track and separate target speech from
interfering speech. Experimental results show that the proposed training
strategy is effective for speaker separation.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14330</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14332</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building Reliable Explanations of Unreliable Neural Networks: Locally
  Smoothing Perspective of Model Interpretation</dc:title>
 <dc:creator>Lim, Dohun</dc:creator>
 <dc:creator>Lee, Hyeonseok</dc:creator>
 <dc:creator>Kim, Sungchan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We present a novel method for reliably explaining the predictions of neural
networks. We consider an explanation reliable if it identifies input features
relevant to the model output by considering the input and the neighboring data
points. Our method is built on top of the assumption of smooth landscape in a
loss function of the model prediction: locally consistent loss and gradient
profile. A theoretical analysis established in this study suggests that those
locally smooth model explanations are learned using a batch of noisy copies of
the input with the L1 regularization for a saliency map. Extensive experiments
support the analysis results, revealing that the proposed saliency maps
retrieve the original classes of adversarial examples crafted against both
naturally and adversarially trained models, significantly outperforming
previous methods. We further demonstrated that such good performance results
from the learning capability of this method to identify input features that are
truly relevant to the model output of the input and the neighboring data
points, fulfilling the requirements of a reliable explanation.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2021. The supplementary materials are included</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14332</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14333</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometry-Aware Unsupervised Domain Adaptation for Stereo Matching</dc:title>
 <dc:creator>Sakuma, Hiroki</dc:creator>
 <dc:creator>Konishi, Yoshinori</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Recently proposed DNN-based stereo matching methods that learn priors
directly from data are known to suffer a drastic drop in accuracy in new
environments. Although supervised approaches with ground truth disparity maps
often work well, collecting them in each deployment environment is cumbersome
and costly. For this reason, many unsupervised domain adaptation methods based
on image-to-image translation have been proposed, but these methods do not
preserve the geometric structure of a stereo image pair because the
image-to-image translation is applied to each view separately. To address this
problem, in this paper, we propose an attention mechanism that aggregates
features in the left and right views, called Stereoscopic Cross Attention
(SCA). Incorporating SCA to an image-to-image translation network makes it
possible to preserve the geometric structure of a stereo image pair in the
process of the image-to-image translation. We empirically demonstrate the
effectiveness of the proposed unsupervised domain adaptation based on the
image-to-image translation with SCA.
</dc:description>
 <dc:description>Comment: Accepted to ICRA 2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14333</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14338</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Few-Shot Human Motion Transfer by Personalized Geometry and Texture
  Modeling</dc:title>
 <dc:creator>Huang, Zhichao</dc:creator>
 <dc:creator>Han, Xintong</dc:creator>
 <dc:creator>Xu, Jia</dc:creator>
 <dc:creator>Zhang, Tong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We present a new method for few-shot human motion transfer that achieves
realistic human image generation with only a small number of appearance inputs.
Despite recent advances in single person motion transfer, prior methods often
require a large number of training images and take long training time. One
promising direction is to perform few-shot human motion transfer, which only
needs a few of source images for appearance transfer. However, it is
particularly challenging to obtain satisfactory transfer results. In this
paper, we address this issue by rendering a human texture map to a surface
geometry (represented as a UV map), which is personalized to the source person.
Our geometry generator combines the shape information from source images, and
the pose information from 2D keypoints to synthesize the personalized UV map. A
texture generator then generates the texture map conditioned on the texture of
source images to fill out invisible parts. Furthermore, we may fine-tune the
texture map on the manifold of the texture generator from a few source images
at the test time, which improves the quality of the texture map without
over-fitting or artifacts. Extensive experiments show the proposed method
outperforms state-of-the-art methods both qualitatively and quantitatively. Our
code is available at https://github.com/HuangZhiChao95/FewShotMotionTransfer.
</dc:description>
 <dc:description>Comment: CVPR 2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14339</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MedSelect: Selective Labeling for Medical Image Classification Combining
  Meta-Learning with Deep Reinforcement Learning</dc:title>
 <dc:creator>Smit, Akshay</dc:creator>
 <dc:creator>Vrabac, Damir</dc:creator>
 <dc:creator>He, Yujie</dc:creator>
 <dc:creator>Ng, Andrew Y.</dc:creator>
 <dc:creator>Beam, Andrew L.</dc:creator>
 <dc:creator>Rajpurkar, Pranav</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We propose a selective learning method using meta-learning and deep
reinforcement learning for medical image interpretation in the setting of
limited labeling resources. Our method, MedSelect, consists of a trainable deep
learning selector that uses image embeddings obtained from contrastive
pretraining for determining which images to label, and a non-parametric
selector that uses cosine similarity to classify unseen images. We demonstrate
that MedSelect learns an effective selection strategy outperforming baseline
selection strategies across seen and unseen medical conditions for chest X-ray
interpretation. We also perform an analysis of the selections performed by
MedSelect comparing the distribution of latent embeddings and clinical
features, and find significant differences compared to the strongest performing
baseline. We believe that our method may be broadly applicable across medical
imaging settings where labels are expensive to acquire.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14342</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-User Programming of Low- and High-Level Actions for Robotic Task
  Planning</dc:title>
 <dc:creator>Liang, Ying Siu</dc:creator>
 <dc:creator>Pellier, Damien</dc:creator>
 <dc:creator>Fiorino, Humbert</dc:creator>
 <dc:creator>Pesty, Sylvie</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Programming robots for general purpose applications is extremely challenging
due to the great diversity of end-user tasks ranging from manufacturing
environments to personal homes. Recent work has focused on enabling end-users
to program robots using Programming by Demonstration. However, teaching robots
new actions from scratch that can be reused for unseen tasks remains a
difficult challenge and is generally left up to robotic experts. We propose
iRoPro, an interactive Robot Programming framework that allows end-users to
teach robots new actions from scratch and reuse them with a task planner. In
this work we provide a system implementation on a two-armed Baxter robot that
(i) allows simultaneous teaching of low- and high-level actions by
demonstration, (ii) includes a user interface for action creation with
condition inference and modification, and (iii) allows creating and solving
previously unseen problems using a task planner for the robot to execute in
real-time. We evaluate the generalisation power of the system on six benchmark
tasks and show how taught actions can be easily reused for complex tasks. We
further demonstrate its usability with a user study (N=21), where users
completed eight tasks to teach the robot new actions that are reused with a
task planner. The study demonstrates that users with any programming level and
educational background can easily learn and use the system.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures, 2019 28th IEEE International Conference on Robot
  and Human Interactive Communication (RO-MAN)</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14342</dc:identifier>
 <dc:identifier>2019 28th IEEE International Conference on Robot and Human
  Interactive Communication (RO-MAN) (pp. 1-8). IEEE</dc:identifier>
 <dc:identifier>doi:10.1109/RO-MAN46459.2019.8956327</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14348</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Requirements Engineering Technology for the IoT Software Systems</dc:title>
 <dc:creator>da Silva, Danyllo Valente</dc:creator>
 <dc:creator>de Souza, Bruno Pedra&#xe7;a</dc:creator>
 <dc:creator>Gon&#xe7;alves, Taisa Guidini</dc:creator>
 <dc:creator>Travassos, Guilherme Horta</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Contemporary software systems (CSS), such as the internet of things (IoT)
based software systems, incorporate new concerns and characteristics inherent
to the network, software, hardware, context awareness, interoperability, and
others, compared to conventional software systems. In this sense, requirements
engineering (RE) plays a fundamental role in ensuring these software systems'
correct development looking for the business and end-user needs. Several
software technologies supporting RE are available in the literature, but many
do not cover all CSS specificities, notably those based on IoT. This research
article presents RETIoT (Requirements Engineering Technology for the Internet
of Things based software systems), aiming to provide methodological, technical,
and tooling support to produce IoT software system requirements document. It is
composed of an IoT scenario description technique, a checklist to verify IoT
scenarios, construction processes, and templates for IoT software systems. A
feasibility study was carried out in IoT system projects to observe its
templates and identify improvement opportunities. The results indicate the
feasibility of RETIoT templates' when used to capture IoT characteristics.
However, further experimental studies represent research opportunities,
strengthen confidence in its elements (construction process, techniques, and
templates), and capture end-user perception.
</dc:description>
 <dc:description>Comment: Preprint submitted to the Journal of Software Engineering Research
  and Development. Date of current version: March 2021. 15 pages</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14348</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14357</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>VDM-DA: Virtual Domain Modeling for Source Data-free Domain Adaptation</dc:title>
 <dc:creator>Tian, Jiayi</dc:creator>
 <dc:creator>Zhang, Jing</dc:creator>
 <dc:creator>Li, Wen</dc:creator>
 <dc:creator>Xu, Dong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Domain adaptation aims to leverage a label-rich domain (the source domain) to
help model learning in a label-scarce domain (the target domain). Most domain
adaptation methods require the co-existence of source and target domain samples
to reduce the distribution mismatch, however, access to the source domain
samples may not always be feasible in the real world applications due to
different problems (e.g., storage, transmission, and privacy issues). In this
work, we deal with the source data-free unsupervised domain adaptation problem,
and propose a novel approach referred to as Virtual Domain Modeling (VDM-DA).
The virtual domain acts as a bridge between the source and target domains. On
one hand, we generate virtual domain samples based on an approximated Gaussian
Mixture Model (GMM) in the feature space with the pre-trained source model,
such that the virtual domain maintains a similar distribution with the source
domain without accessing to the original source data. On the other hand, we
also design an effective distribution alignment method to reduce the
distribution divergence between the virtual domain and the target domain by
gradually improving the compactness of the target domain distribution through
model learning. In this way, we successfully achieve the goal of distribution
alignment between the source and target domains by training deep networks
without accessing to the source domain data. We conduct extensive experiments
on benchmark datasets for both 2D image-based and 3D point cloud-based
cross-domain object recognition tasks, where the proposed method referred to
Domain Adaptation with Virtual Domain Modeling (VDM-DA) achieves the
state-of-the-art performances on all datasets.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14359</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Tactile Sensing Foot for Single Robot Leg Stabilization</dc:title>
 <dc:creator>Zhang, Guanlan</dc:creator>
 <dc:creator>Du, Yipai</dc:creator>
 <dc:creator>Zhan, Yazhan</dc:creator>
 <dc:creator>Wang, Michael Yu</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Tactile sensing on human feet is crucial for motion control, however, has not
been explored in robotic counterparts. This work is dedicated to endowing
tactile sensing to legged robot's feet and showing that a single-legged robot
can be stabilized with only tactile sensing signals from its foot. We propose a
robot leg with a novel vision-based tactile sensing foot system and implement a
processing algorithm to extract contact information for feedback control in
stabilizing tasks. A pipeline to convert images of the foot skin into
high-level contact information using a deep learning framework is presented.
The leg was quantitatively evaluated in a stabilization task on a tilting
surface to show that the tactile foot was able to estimate both the surface
tilting angle and the foot poses. Feasibility and effectiveness of the tactile
system were investigated qualitatively in comparison with conventional
single-legged robotic systems using inertia measurement units (IMU).
Experiments demonstrate the capability of vision-based tactile sensors in
assisting legged robots to maintain stability on unknown terrains and the
potential for regulating more complex motions for humanoid robots.
</dc:description>
 <dc:description>Comment: 7 pages, 9 figures, ICRA2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14359</dc:identifier>
 <dc:identifier>ICRA2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14362</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Base Station Network Traffic Prediction Approach Based on LMA-DeepAR</dc:title>
 <dc:creator>Zhang, Jiachen</dc:creator>
 <dc:creator>zuo, Xingquan</dc:creator>
 <dc:creator>Xu, Mingying</dc:creator>
 <dc:creator>Han, Jing</dc:creator>
 <dc:creator>Zhang, Baisheng</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Accurate network traffic prediction of base station cell is very vital for
the expansion and reduction of wireless devices in base station cell. The burst
and uncertainty of base station cell network traffic makes the network traffic
nonlinear and non-stationary, which brings challenges to the long-term
prediction of network traffic. In this paper, the traffic model LMA-DeepAR for
base station network is established based on DeepAR. Acordding to the
distribution characteristics of network traffic, this paper proposes an
artificial feature sequence calculation method based on local moving average
(LMA). The feature sequence is input into DeepAR as covariant, which makes the
statistical characteristics of network traffic near a period of time in the
past be considered when updating parameters, and the interference of
non-stationary network traffic on model training will be reduced. Experimental
results show that the proposed prediction approach (LMA-DeepAR) outperforms
other methods in the overall long-term prediction performance and stability of
multi cell network traffic.
</dc:description>
 <dc:description>Comment: 7 pages,4 figures,2 tables</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14362</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14371</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A PSO Strategy of Finding Relevant Web Documents using a New Similarity
  Measure</dc:title>
 <dc:creator>C, Dr. Ramya</dc:creator>
 <dc:creator>S, Dr. Shreedhara K</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  In the world of the Internet and World Wide Web, which offers a tremendous
amount of information, an increasing emphasis is being given to searching
services and functionality. Currently, a majority of web portals offer their
searching utilities, be it better or worse. These can search for the content
within the sites, mainly text the textual content of documents. In this paper a
novel similarity measure called SMDR (Similarity Measure for Documents
Retrieval) is proposed to help retrieve more similar documents from the
repository thus contributing considerably to the effectiveness of Web
Information Retrieval (WIR) process. Bio-inspired PSO methodology is used with
the intent to reduce the response time of the system and optimizes WIR process,
hence contributes to the efficiency of the system. This paper also demonstrates
a comparative study of the proposed system with the existing method in terms of
accuracy, sensitivity, F-measure and specificity. Finally, extensive
experiments are conducted on CACM collections. Better precision-recall rates
are achieved than the existing system. Experimental results demonstrate the
effectiveness and efficiency of the proposed system.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14371</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14372</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Genetic Algorithm approach to Asymmetrical Blotto Games with
  Heterogeneous Valuations</dc:title>
 <dc:creator>Vie, Aymeric</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Economics - General Economics</dc:subject>
 <dc:description>  Blotto Games are a popular model of multi-dimensional strategic resource
allocation. Two players allocate resources in different battlefields in an
auction setting. While competition with equal budgets is well understood,
little is known about strategic behavior under asymmetry of resources. We
introduce a genetic algorithm, a search heuristic inspired from biological
evolution, interpreted as social learning, to solve this problem. Most
performant strategies are combined to create more performant strategies.
Mutations allow the algorithm to efficiently scan the space of possible
strategies, and consider a wide diversity of deviations. We show that our
genetic algorithm converges to the analytical Nash equilibrium of the symmetric
Blotto game. We present the solution concept it provides for asymmetrical
Blotto games. It notably sees the emergence of &quot;guerilla warfare&quot; strategies,
consistent with empirical and experimental findings. The player with less
resources learns to concentrate its resources to compensate for the asymmetry
of competition. When players value battlefields heterogeneously, counter
strategies and bidding focus is obtained in equilibrium. These features are
consistent with empirical and experimental findings, and provide a learning
foundation for their existence.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14372</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<resumptionToken cursor="1000" completeListSize="2358">6965856|2001</resumptionToken>
</ListRecords>
</OAI-PMH>
