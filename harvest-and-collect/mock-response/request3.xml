<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2024-01-30T08:21:02Z</responseDate>
<request verb="ListRecords" resumptionToken="6965856|2001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14379</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evolutionary Strategies with Analogy Partitions in p-guessing Games</dc:title>
 <dc:creator>Vie, Aymeric</dc:creator>
 <dc:subject>Economics - General Economics</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In Keynesian Beauty Contests notably modeled by p-guessing games, players try
to guess the average of guesses multiplied by p. Convergence of plays to Nash
equilibrium has often been justified by agents' learning. However,
interrogations remain on the origin of reasoning types and equilibrium behavior
when learning takes place in unstable environments. When successive values of p
can take values above and below 1, bounded rational agents may learn about
their environment through simplified representations of the game, reasoning
with analogies and constructing expectations about the behavior of other
players. We introduce an evolutionary process of learning to investigate the
dynamics of learning and the resulting optimal strategies in unstable
p-guessing games environments with analogy partitions. As a validation of the
approach, we first show that our genetic algorithm behaves consistently with
previous results in persistent environments, converging to the Nash
equilibrium. We characterize strategic behavior in mixed regimes with unstable
values of p. Varying the number of iterations given to the genetic algorithm to
learn about the game replicates the behavior of agents with different levels of
reasoning of the level k approach. This evolutionary process hence proposes a
learning foundation for endogenizing existence and transitions between levels
of reasoning in cognitive hierarchy models.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14389</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online learning with exponential weights in metric spaces</dc:title>
 <dc:creator>Paris, Quentin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  This paper addresses the problem of online learning in metric spaces using
exponential weights. We extend the analysis of the exponentially weighted
average forecaster, traditionally studied in a Euclidean settings, to a more
abstract framework. Our results rely on the notion of barycenters, a suitable
version of Jensen's inequality and a synthetic notion of lower curvature bound
in metric spaces known as the measure contraction property. We also adapt the
online-to-batch conversion principle to apply our results to a statistical
learning framework.
</dc:description>
 <dc:description>Comment: 33 pages, 1 figure</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14389</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14409</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LS-CAT: A Large-Scale CUDA AutoTuning Dataset</dc:title>
 <dc:creator>Bjertnes, Lars</dc:creator>
 <dc:creator>T&#xf8;rring, Jacob O.</dc:creator>
 <dc:creator>Elster, Anne C.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The effectiveness of Machine Learning (ML) methods depend on access to large
suitable datasets. In this article, we present how we build the LS-CAT
(Large-Scale CUDA AutoTuning) dataset sourced from GitHub for the purpose of
training NLP-based ML models. Our dataset includes 19 683 CUDA kernels focused
on linear algebra. In addition to the CUDA codes, our LS-CAT dataset contains 5
028 536 associated runtimes, with different combinations of kernels, block
sizes and matrix sizes. The runtime are GPU benchmarks on both Nvidia GTX 980
and Nvidia T4 systems. This information creates a foundation upon which
NLP-based models can find correlations between source-code features and optimal
choice of thread block sizes.
  There are several results that can be drawn out of our LS-CAT database. E.g.,
our experimental results show that an optimal choice in thread block size can
gain an average of 6% for the average case. We thus also analyze how much
performance increase can be achieved in general, finding that in 10% of the
cases more than 20% performance increase can be achieved by using the optimal
block. A description of current and future work is also included.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14409</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14410</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Embedding-based Joint Sentiment-Topic Model for Short Texts</dc:title>
 <dc:creator>Sengupta, Ayan</dc:creator>
 <dc:creator>Paka, William Scott</dc:creator>
 <dc:creator>Roy, Suman</dc:creator>
 <dc:creator>Ranjan, Gaurav</dc:creator>
 <dc:creator>Chakraborty, Tanmoy</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Short text is a popular avenue of sharing feedback, opinions and reviews on
social media, e-commerce platforms, etc. Many companies need to extract
meaningful information (which may include thematic content as well as semantic
polarity) out of such short texts to understand users' behaviour. However,
obtaining high quality sentiment-associated and human interpretable themes
still remains a challenge for short texts. In this paper we develop ELJST, an
embedding enhanced generative joint sentiment-topic model that can discover
more coherent and diverse topics from short texts. It uses Markov Random Field
Regularizer that can be seen as a generalisation of skip-gram based models.
Further, it can leverage higher-order semantic information appearing in word
embedding, such as self-attention weights in graphical models. Our results show
an average improvement of 10% in topic coherence and 5% in topic
diversification over baselines. Finally, ELJST helps understand users'
behaviour at more granular levels which can be explained. All these can bring
significant values to the service and healthcare industries often dealing with
customers.
</dc:description>
 <dc:description>Comment: Accepted in International AAAI Conference on Web and Social Media
  (ICWSM), 2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14410</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14411</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Functorial Language Models</dc:title>
 <dc:creator>Toumi, Alexis</dc:creator>
 <dc:creator>Koziell-Pipe, Alex</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:description>  We introduce functorial language models: a principled way to compute
probability distributions over word sequences given a monoidal functor from
grammar to meaning. This yields a method for training categorical compositional
distributional (DisCoCat) models on raw text data. We provide a
proof-of-concept implementation in DisCoPy, the Python toolbox for monoidal
categories.
</dc:description>
 <dc:description>Comment: Submitted to SemSpace 2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14411</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14414</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HyperSec: Visual Analytics for blockchain security monitoring</dc:title>
 <dc:creator>Putz, Benedikt</dc:creator>
 <dc:creator>B&#xf6;hm, Fabian</dc:creator>
 <dc:creator>Pernul, G&#xfc;nther</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Today, permissioned blockchains are being adopted by large organizations for
business critical operations. Consequently, they are subject to attacks by
malicious actors. Researchers have discovered and enumerated a number of
attacks that could threaten availability, integrity and confidentiality of
blockchain data. However, currently it remains difficult to detect these
attacks. We argue that security experts need appropriate visualizations to
assist them in detecting attacks on blockchain networks. To achieve this, we
develop HyperSec, a visual analytics monitoring tool that provides relevant
information at a glance to detect ongoing attacks on Hyperledger Fabric. For
evaluation, we connect the HyperSec prototype to a Hyperledger Fabric test
network. The results show that common attacks on Fabric can be detected by a
security expert using HyperSec's visualizations.
</dc:description>
 <dc:description>Comment: Accepted at the IFIP TC 11 36th International Information Security
  Conference (SEC 2021), June 22-24 2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14414</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14422</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SegVisRL: Visuomotor Development for a Lunar Rover for Hazard Avoidance
  using Camera Images</dc:title>
 <dc:creator>Blum, Tamir</dc:creator>
 <dc:creator>Paillet, Gabin</dc:creator>
 <dc:creator>Masawat, Watcharawut</dc:creator>
 <dc:creator>Laine, Mickael</dc:creator>
 <dc:creator>Yoshida, Kazuya</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  The visuomotor system of any animal is critical for its survival, and the
development of a complex one within humans is large factor in our success as a
species on Earth. This system is an essential part of our ability to adapt to
our environment. We use this system continuously throughout the day, when
picking something up, or walking around while avoiding bumping into objects.
Equipping robots with such capabilities will help produce more intelligent
locomotion with the ability to more easily understand their surroundings and to
move safely. In particular, such capabilities are desirable for traversing the
lunar surface, as it is full of hazardous obstacles, such as rocks. These
obstacles need to be identified and avoided in real time. This paper seeks to
demonstrate the development of a visuomotor system within a robot for
navigation and obstacle avoidance, with complex rock shaped objects
representing hazards. Our approach uses deep reinforcement learning with only
image data. In this paper, we compare the results from several neural network
architectures and a preprocessing methodology which includes producing a
segmented image and downsampling.
</dc:description>
 <dc:description>Comment: 9 pages including references. 8 images, 2 tables. Workshop submission</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14422</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14423</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Theory of Stochastic Automata</dc:title>
 <dc:creator>Cakir, Merve Nur</dc:creator>
 <dc:creator>Saleemi, Mehwish</dc:creator>
 <dc:creator>Zimmermann, Karl-Heinz</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>68Q70, 68Q87, 20M35</dc:subject>
 <dc:description>  The theory of discrete stochastic systems has been initiated by the work of
Shannon and von Neumann. While Shannon has considered memory-less communication
channels and their generalization by introducing states, von Neumann has
studied the synthesis of reliable systems from unreliable components. The
fundamental work of Rabin and Scott about deterministic finite-state automata
has led to two generalizations. First, the generalization of transition
functions to conditional distributions studied by Carlyle and Starke. This in
turn has led to a generalization of time-discrete Markov chains in which the
chains are governed by more than one transition probability matrix. Second, the
generalization of regular sets by introducing stochastic automata as described
by Rabin. Stochastic automata are well-investigated. This report provides a
short introduction to stochastic automata based on the valuable book of Claus.
This includes the basic topics of the theory of stochastic automata:
equivalence, minimization, reduction, covering, observability, and determinism.
Then stochastic versions of Mealy and Moore automata are studied and finally
stochastic language acceptors are considered as a generalization of
nondeterministic finite-state acceptors.
</dc:description>
 <dc:description>Comment: 50 pages, 11 figures, index included</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14423</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14424</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Node metadata can produce predictability transitions in network
  inference problems</dc:title>
 <dc:creator>Fajardo-Fontiveros, Oscar</dc:creator>
 <dc:creator>Sales-Pardo, Marta</dc:creator>
 <dc:creator>Guimera, Roger</dc:creator>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Network inference is the process of learning the properties of complex
networks from data. Besides using information about known links in the network,
node attributes and other forms of network metadata can help to solve network
inference problems. Indeed, several approaches have been proposed to introduce
metadata into probabilistic network models and to use them to make better
inferences. However, we know little about the effect of such metadata in the
inference process. Here, we investigate this issue. We find that, rather than
affecting inference gradually, adding metadata causes abrupt transitions in the
inference process and in our ability to make accurate predictions, from a
situation in which metadata does not play any role to a situation in which
metadata completely dominates the inference process. When network data and
metadata are partly correlated, metadata optimally contributes to the inference
process at the transition between data-dominated and metadata-dominated
regimes.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14424</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14433</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A novel S-shape based NURBS interpolation with acc-jerk- Continuity and
  round-off error elimination</dc:title>
 <dc:creator>Hu, Yifei</dc:creator>
 <dc:creator>Jiang, Xin</dc:creator>
 <dc:creator>Huo, Guanying</dc:creator>
 <dc:creator>Su, Cheng</dc:creator>
 <dc:creator>Wang, Bolun</dc:creator>
 <dc:creator>Li, Hexiong</dc:creator>
 <dc:creator>Zheng, Zhiming</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Feedrate scheduling is a key step in computer numerical control (CNC)
machining, as it has a close relationship with machining time and surface
quality, and has now become a hot issue in industry and academia. To reduce
high chord errors and round-off errors, and generate continuous velocity,
acceleration, and jerk profile of parametric interpolation, a novel and
complete S-shape based feedrate scheduling algorithm is presented in this
paper. The algorithm consists of three modules: bidirectional scanning module,
velocity scheduling module and round-off error elimination module. The
bidirectional scanning module with the limitations of chord error, normal
acceleration/jerk and command feedrate aims to guarantee the continuity of the
feed rate at the junctions between successive NURBS sub-curves. After the NURBS
sub-curves have been classified into two cases, the velocity scheduling module
firstly calculates the actual maximum federate, and then generates the feed
rate profiles of all NURBS sub-curves according to our velocity scheduling
function. Later, the round-off error elimination module is proposed to make the
total interpolating time become an integer multiple of the interpolation
period, which leads to the elimination of round-off errors. Finally, benchmarks
are conducted to verify the applicability of the proposed method compared with
some other methods.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14433</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14434</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Planning as Heuristic Search</dc:title>
 <dc:creator>Segovia-Aguas, Javier</dc:creator>
 <dc:creator>Jim&#xe9;nez, Sergio</dc:creator>
 <dc:creator>Jonsson, Anders</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Although heuristic search is one of the most successful approaches to
classical planning, this planning paradigm does not apply straightforwardly to
Generalized Planning (GP). Planning as heuristic search traditionally addresses
the computation of sequential plans by searching in a grounded state-space. On
the other hand GP aims at computing algorithm-like plans, that can branch and
loop, and that generalize to a (possibly infinite) set of classical planning
instances. This paper adapts the planning as heuristic search paradigm to the
particularities of GP, and presents the first native heuristic search approach
to GP. First, the paper defines a novel GP solution space that is independent
of the number of planning instances in a GP problem, and the size of these
instances. Second, the paper defines different evaluation and heuristic
functions for guiding a combinatorial search in our GP solution space. Lastly
the paper defines a GP algorithm, called Best-First Generalized Planning
(BFGP), that implements a best-first search in the solution space guided by our
evaluation/heuristic functions.
</dc:description>
 <dc:description>Comment: Accepted at ICAPS-21</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14434</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14435</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synthesizing Linked Data Under Cardinality and Integrity Constraints</dc:title>
 <dc:creator>Gilad, Amir</dc:creator>
 <dc:creator>Patwa, Shweta</dc:creator>
 <dc:creator>Machanavajjhala, Ashwin</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The generation of synthetic data is useful in multiple aspects, from testing
applications to benchmarking to privacy preservation. Generating the links
between relations, subject to cardinality constraints (CCs) and integrity
constraints (ICs) is an important aspect of this problem. Given instances of
two relations, where one has a foreign key dependence on the other and is
missing its foreign key ($FK$) values, and two types of constraints: (1) CCs
that apply to the join view and (2) ICs that apply to the table with missing
$FK$ values, our goal is to impute the missing $FK$ values such that the
constraints are satisfied. We provide a novel framework for the problem based
on declarative CCs and ICs. We further show that the problem is NP-hard and
propose a novel two-phase solution that guarantees the satisfaction of the ICs.
Phase I yields an intermediate solution accounting for the CCs alone, and
relies on a hybrid approach based on CC types. For one type, the problem is
modeled as an Integer Linear Program. For the others, we describe an efficient
and accurate solution. We then combine the two solutions. Phase II augments
this solution by incorporating the ICs and uses a coloring of the conflict
hypergraph to infer the values of the $FK$ column. Our extensive experimental
study shows that our solution scales well when the data and number of
constraints increases. We further show that our solution maintains low error
rates for the CCs.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14435</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14437</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the numerical accuracy of the method of multiple scales for nonlinear
  dispersive wave equations</dc:title>
 <dc:creator>Juhasz, David</dc:creator>
 <dc:creator>Jakobsen, Per Kristen</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Nonlinear Sciences - Pattern Formation and Solitons</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  In this paper we study dispersive wave equation using the method of multiple
scales (MMS) and perform several numerical tests to investigate its accuracy.
The key feature of our MMS solution is the linearity of the amplitude equation
and the complex nature of the time-frequency. The MMS is tested as an initial
value problem using three choices of the dispersion model, one toy and two
Lorentz models. Depending on the parameters of the problem, the amplitude
equation can be both well- or ill-posed. Despite the ill-posedness, the MMS
solution remains a valid approximation of the solution to the original
nonlinear model.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14437</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14438</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gated Transformer Networks for Multivariate Time Series Classification</dc:title>
 <dc:creator>Liu, Minghao</dc:creator>
 <dc:creator>Ren, Shengqi</dc:creator>
 <dc:creator>Ma, Siyuan</dc:creator>
 <dc:creator>Jiao, Jiahui</dc:creator>
 <dc:creator>Chen, Yizhou</dc:creator>
 <dc:creator>Wang, Zhiguang</dc:creator>
 <dc:creator>Song, Wei</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Deep learning model (primarily convolutional networks and LSTM) for time
series classification has been studied broadly by the community with the wide
applications in different domains like healthcare, finance, industrial
engineering and IoT. Meanwhile, Transformer Networks recently achieved frontier
performance on various natural language processing and computer vision tasks.
In this work, we explored a simple extension of the current Transformer
Networks with gating, named Gated Transformer Networks (GTN) for the
multivariate time series classification problem. With the gating that merges
two towers of Transformer which model the channel-wise and step-wise
correlations respectively, we show how GTN is naturally and effectively
suitable for the multivariate time series classification task. We conduct
comprehensive experiments on thirteen dataset with full ablation study. Our
results show that GTN is able to achieve competing results with current
state-of-the-art deep learning models. We also explored the attention map for
the natural interpretability of GTN on time series modeling. Our preliminary
results provide a strong baseline for the Transformer Networks on multivariate
time series classification task and grounds the foundation for future research.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14438</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14439</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Empirical Study of the Characteristics of Popular Minecraft Mods</dc:title>
 <dc:creator>Lee, Daniel</dc:creator>
 <dc:creator>Rajbahadur, Gopi Krishnan</dc:creator>
 <dc:creator>Lin, Dayi</dc:creator>
 <dc:creator>Sayagh, Mohammed</dc:creator>
 <dc:creator>Bezemer, Cor-Paul</dc:creator>
 <dc:creator>Hassan, Ahmed E.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  It is becoming increasingly difficult for game developers to manage the cost
of developing a game, while meeting the high expectations of gamers. One way to
balance the increasing gamer expectation and development stress is to build an
active modding community around the game. There exist several examples of games
with an extremely active and successful modding community, with the Minecraft
game being one of the most notable ones.
  This paper reports on an empirical study of 1,114 popular and 1,114 unpopular
Minecraft mods from the CurseForge mod distribution platform, one of the
largest distribution platforms for Minecraft mods. We analyzed the relationship
between 33 features across 5 dimensions of mod characteristics and the
popularity of mods (i.e., mod category, mod documentation, environmental
context of the mod, remuneration for the mod, and community contribution for
the mod), to understand the characteristics of popular Minecraft mods. We
firstly verify that the studied dimensions have significant explanatory power
in distinguishing the popularity of the studied mods. Then we evaluated the
contribution of each of the 33 features across the 5 dimensions. We observed
that popular mods tend to have a high quality description and promote community
contribution.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14439</dc:identifier>
 <dc:identifier>Empirical Software Engineering, 25, 2020, 3396-3429</dc:identifier>
 <dc:identifier>doi:10.1007/s10664-020-09840-9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14443</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incorporating Connections Beyond Knowledge Embeddings: A Plug-and-Play
  Module to Enhance Commonsense Reasoning in Machine Reading Comprehension</dc:title>
 <dc:creator>Dai, Damai</dc:creator>
 <dc:creator>Zheng, Hua</dc:creator>
 <dc:creator>Sui, Zhifang</dc:creator>
 <dc:creator>Chang, Baobao</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Conventional Machine Reading Comprehension (MRC) has been well-addressed by
pattern matching, but the ability of commonsense reasoning remains a gap
between humans and machines. Previous methods tackle this problem by enriching
word representations via pre-trained Knowledge Graph Embeddings (KGE). However,
they make limited use of a large number of connections between nodes in
Knowledge Graphs (KG), which could be pivotal cues to build the commonsense
reasoning chains. In this paper, we propose a Plug-and-play module to
IncorporatE Connection information for commonsEnse Reasoning (PIECER). Beyond
enriching word representations with knowledge embeddings, PIECER constructs a
joint query-passage graph to explicitly guide commonsense reasoning by the
knowledge-oriented connections between words. Further, PIECER has high
generalizability since it can be plugged into suitable positions in any MRC
model. Experimental results on ReCoRD, a large-scale public MRC dataset
requiring commonsense reasoning, show that PIECER introduces stable performance
improvements for four representative base MRC models, especially in
low-resource settings.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14443</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14455</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Projected Hamming Dissimilarity for Bit-Level Importance Coding in
  Collaborative Filtering</dc:title>
 <dc:creator>Hansen, Christian</dc:creator>
 <dc:creator>Hansen, Casper</dc:creator>
 <dc:creator>Simonsen, Jakob Grue</dc:creator>
 <dc:creator>Lioma, Christina</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  When reasoning about tasks that involve large amounts of data, a common
approach is to represent data items as objects in the Hamming space where
operations can be done efficiently and effectively. Object similarity can then
be computed by learning binary representations (hash codes) of the objects and
computing their Hamming distance. While this is highly efficient, each bit
dimension is equally weighted, which means that potentially discriminative
information of the data is lost. A more expressive alternative is to use
real-valued vector representations and compute their inner product; this allows
varying the weight of each dimension but is many magnitudes slower. To fix
this, we derive a new way of measuring the dissimilarity between two objects in
the Hamming space with binary weighting of each dimension (i.e., disabling
bits): we consider a field-agnostic dissimilarity that projects the vector of
one object onto the vector of the other. When working in the Hamming space,
this results in a novel projected Hamming dissimilarity, which by choice of
projection, effectively allows a binary importance weighting of the hash code
of one object through the hash code of the other. We propose a variational
hashing model for learning hash codes optimized for this projected Hamming
dissimilarity, and experimentally evaluate it in collaborative filtering
experiments. The resultant hash codes lead to effectiveness gains of up to +7%
in NDCG and +14% in MRR compared to state-of-the-art hashing-based
collaborative filtering baselines, while requiring no additional storage and no
computational overhead compared to using the Hamming distance.
</dc:description>
 <dc:description>Comment: Proceedings of the 2021 World Wide Web Conference, published under
  Creative Commons CC-BY 4.0 License</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14455</dc:identifier>
 <dc:identifier>doi:10.1145/3442381.3450011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14456</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Authorship ethics: an overview of research on the state of practice</dc:title>
 <dc:creator>Minhas, Nasir Mehmood</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Authorship ethics is a central topic of discussion in research ethics fora.
There are various guidelines for authorship (i.e., naming and order). It is not
easy to decide the authorship in the presence of varying authorship guidelines.
This paper gives an overview of research on authorship practices and issues. It
presents a review of 16 empirical research papers published between 2014 --
2020. The objective is to learn how various research disciplines handle
authorship. What are the authorship practices in various research disciplines,
and what are the issues associated with these practices?
</dc:description>
 <dc:description>Comment: 10 pages, 6 tables, paper is accepted in ICSE 2021 Workshop SEthics
  (2nd Workshop on Ethics in Software Engineering Research and Practice)</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14456</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14460</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Multi-Index Semantic Hashing</dc:title>
 <dc:creator>Hansen, Christian</dc:creator>
 <dc:creator>Hansen, Casper</dc:creator>
 <dc:creator>Simonsen, Jakob Grue</dc:creator>
 <dc:creator>Alstrup, Stephen</dc:creator>
 <dc:creator>Lioma, Christina</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Semantic hashing represents documents as compact binary vectors (hash codes)
and allows both efficient and effective similarity search in large-scale
information retrieval. The state of the art has primarily focused on learning
hash codes that improve similarity search effectiveness, while assuming a
brute-force linear scan strategy for searching over all the hash codes, even
though much faster alternatives exist. One such alternative is multi-index
hashing, an approach that constructs a smaller candidate set to search over,
which depending on the distribution of the hash codes can lead to sub-linear
search time. In this work, we propose Multi-Index Semantic Hashing (MISH), an
unsupervised hashing model that learns hash codes that are both effective and
highly efficient by being optimized for multi-index hashing. We derive novel
training objectives, which enable to learn hash codes that reduce the candidate
sets produced by multi-index hashing, while being end-to-end trainable. In
fact, our proposed training objectives are model agnostic, i.e., not tied to
how the hash codes are generated specifically in MISH, and are straight-forward
to include in existing and future semantic hashing models. We experimentally
compare MISH to state-of-the-art semantic hashing baselines in the task of
document similarity search. We find that even though multi-index hashing also
improves the efficiency of the baselines compared to a linear scan, they are
still upwards of 33% slower than MISH, while MISH is still able to obtain
state-of-the-art effectiveness.
</dc:description>
 <dc:description>Comment: Proceedings of the 2021 World Wide Web Conference, published under
  Creative Commons CC-BY 4.0 License</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14460</dc:identifier>
 <dc:identifier>doi:10.1145/3442381.3450014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14464</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reactive Task and Motion Planning under Temporal Logic Specifications</dc:title>
 <dc:creator>Li, Shen</dc:creator>
 <dc:creator>Park, Daehyung</dc:creator>
 <dc:creator>Sung, Yoonchang</dc:creator>
 <dc:creator>Shah, Julie A.</dc:creator>
 <dc:creator>Roy, Nicholas</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present a task-and-motion planning (TAMP) algorithm robust against a human
operator's cooperative or adversarial interventions. Interventions often
invalidate the current plan and require replanning on the fly. Replanning can
be computationally expensive and often interrupts seamless task execution. We
introduce a dynamically reconfigurable planning methodology with behavior
tree-based control strategies toward reactive TAMP, which takes the advantage
of previous plans and incremental graph search during temporal logic-based
reactive synthesis. Our algorithm also shows efficient recovery functionalities
that minimize the number of replanning steps. Finally, our algorithm produces a
robust, efficient, and complete TAMP solution. Our experimental results show
the algorithm results in superior manipulation performance in both simulated
and real-world tasks.
</dc:description>
 <dc:description>Comment: 7 pages, 6 figures, Published in IEEE International Conference on
  Robotics and Automation (ICRA), 2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14464</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14469</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NonlinearSchrodinger: Higher-Order Algorithms and Darboux
  Transformations for Nonlinear Schr\&quot;odinger Equations</dc:title>
 <dc:creator>Ashour, Omar A.</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Nonlinear Sciences - Exactly Solvable and Integrable Systems</dc:subject>
 <dc:description>  NonlinearSchrodinger.jl is a Julia package with a simple interface for
studying solutions of nonlinear Schr\&quot;odinger equations (NLSEs). In
approximately ten lines of code, one can perform a simulation of the cubic NLSE
using one of 32 algorithms, including symplectic and Runge-Kutta-Nystr\&quot;om
integrators up to eighth order. Furthermore, it is possible to compute
analytical solutions via a numerical implementation of the Darboux
transformation for extended NLSEs up to fifth order, with an equally simple
interface. In what follows, we review the fundamentals of solving this class of
equations numerically and analytically, discuss the implementation, and provide
several examples.
</dc:description>
 <dc:description>Comment: 43 pages, 15 figures. Submitted to Scipost Physics Codebases</dc:description>
 <dc:date>2021-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14469</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14470</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial Dual-Modality Graph Reasoning for Key Information Extraction</dc:title>
 <dc:creator>Sun, Hongbin</dc:creator>
 <dc:creator>Kuang, Zhanghui</dc:creator>
 <dc:creator>Yue, Xiaoyu</dc:creator>
 <dc:creator>Lin, Chenhao</dc:creator>
 <dc:creator>Zhang, Wayne</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Key information extraction from document images is of paramount importance in
office automation. Conventional template matching based approaches fail to
generalize well to document images of unseen templates, and are not robust
against text recognition errors. In this paper, we propose an end-to-end
Spatial Dual-Modality Graph Reasoning method (SDMG-R) to extract key
information from unstructured document images. We model document images as
dual-modality graphs, nodes of which encode both the visual and textual
features of detected text regions, and edges of which represent the spatial
relations between neighboring text regions. The key information extraction is
solved by iteratively propagating messages along graph edges and reasoning the
categories of graph nodes. In order to roundly evaluate our proposed method as
well as boost the future research, we release a new dataset named WildReceipt,
which is collected and annotated tailored for the evaluation of key information
extraction from document images of unseen templates in the wild. It contains 25
key information categories, a total of about 69000 text boxes, and is about 2
times larger than the existing public datasets. Extensive experiments validate
that all information including visual features, textual features and spatial
relations can benefit key information extraction. It has been shown that SDMG-R
can effectively extract key information from document images of unseen
templates, and obtain new state-of-the-art results on the recent popular
benchmark SROIE and our WildReceipt. Our code and dataset will be publicly
released.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14470</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14474</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Composable Learning with Sparse Kernel Representations</dc:title>
 <dc:creator>Tolstaya, Ekaterina</dc:creator>
 <dc:creator>Stump, Ethan</dc:creator>
 <dc:creator>Koppel, Alec</dc:creator>
 <dc:creator>Ribeiro, Alejandro</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We present a reinforcement learning algorithm for learning sparse
non-parametric controllers in a Reproducing Kernel Hilbert Space. We improve
the sample complexity of this approach by imposing a structure of the
state-action function through a normalized advantage function (NAF). This
representation of the policy enables efficiently composing multiple learned
models without additional training samples or interaction with the environment.
We demonstrate the performance of this algorithm on learning obstacle-avoidance
policies in multiple simulations of a robot equipped with a laser scanner while
navigating in a 2D environment. We apply the composition operation to various
policy combinations and test them to show that the composed policies retain the
performance of their components. We also transfer the composed policy directly
to a physical platform operating in an arena with obstacles in order to
demonstrate a degree of generalization.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14474</dc:identifier>
 <dc:identifier>doi:10.1109/IROS.2018.8594065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14475</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distilling Object Detectors via Decoupled Features</dc:title>
 <dc:creator>Guo, Jianyuan</dc:creator>
 <dc:creator>Han, Kai</dc:creator>
 <dc:creator>Wang, Yunhe</dc:creator>
 <dc:creator>Wu, Han</dc:creator>
 <dc:creator>Chen, Xinghao</dc:creator>
 <dc:creator>Xu, Chunjing</dc:creator>
 <dc:creator>Xu, Chang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Knowledge distillation is a widely used paradigm for inheriting information
from a complicated teacher network to a compact student network and maintaining
the strong performance. Different from image classification, object detectors
are much more sophisticated with multiple loss functions in which features that
semantic information rely on are tangled. In this paper, we point out that the
information of features derived from regions excluding objects are also
essential for distilling the student detector, which is usually ignored in
existing approaches. In addition, we elucidate that features from different
regions should be assigned with different importance during distillation. To
this end, we present a novel distillation algorithm via decoupled features
(DeFeat) for learning a better student detector. Specifically, two levels of
decoupled features will be processed for embedding useful information into the
student, i.e., decoupled features from neck and decoupled proposals from
classification head. Extensive experiments on various detectors with different
backbones show that the proposed DeFeat is able to surpass the state-of-the-art
distillation methods for object detection. For example, DeFeat improves
ResNet50 based Faster R-CNN from 37.4% to 40.9% mAP, and improves ResNet50
based RetinaNet from 36.5% to 39.7% mAP on COCO benchmark. Our implementation
is available at https://github.com/ggjy/DeFeat.pytorch.
</dc:description>
 <dc:description>Comment: Accepted in CVPR 2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14475</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14477</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Semi-Decidability of Remote State Estimation and Stabilization
  via Noisy Communication Channels</dc:title>
 <dc:creator>Boche, Holger</dc:creator>
 <dc:creator>B&#xf6;ck, Yannik</dc:creator>
 <dc:creator>Deppe, Christian</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the task of remote state estimation and stabilization of
disturbed linear plants via noisy communication channels. In 2007 Matveev and
Savkin established a surprising link between this problem and Shannon's theory
of zero-error communication. By applying very recent results of computability
of the channel reliability function and computability of the zero-error
capacity of noisy channels by Boche and Deppe, we analyze if, on the set of
linear time-invariant systems paired with a noisy communication channel, it is
uniformly decidable by means of a Turing machine whether remote state
estimation and stabilization is possible. The answer to this question largely
depends on whether the plant is disturbed by random noise or not. Our analysis
incorporates scenarios both with and without channel feedback, as well as a
weakened form of state estimation and stabilization. In the broadest sense, our
results yield a fundamental limit to the capabilities of computer-aided design
and autonomous systems, assuming they are based on real-world digital
computers.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14477</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14481</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deadlock-Free Session Types in Linear Haskell</dc:title>
 <dc:creator>Kokke, Wen</dc:creator>
 <dc:creator>Dardha, Ornela</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Priority Sesh is a library for session-typed communication in Linear Haskell
which offers strong compile-time correctness guarantees. Priority Sesh offers
two deadlock-free APIs for session-typed communication. The first guarantees
deadlock freedom by restricting the process structure to trees and forests. It
is simple and composeable, but rules out cyclic structures. The second
guarantees deadlock freedom via priorities, which allows the programmer to
safely use cyclic structures as well.
  Our library relies on Linear Haskell to guarantee linearity, which leads to
easy-to-write session types and highly idiomatic code, and lets us avoid the
complex encodings of linearity in the Haskell type system that made previous
libraries difficult to use.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14489</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Planning with Preferences over Temporal Goals</dc:title>
 <dc:creator>Fu, Jie</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>90C40, 03B44, 68T27</dc:subject>
 <dc:description>  We present a formal language for specifying qualitative preferences over
temporal goals and a preference-based planning method in stochastic systems.
Using automata-theoretic modeling, the proposed specification allows us to
express preferences over different sets of outcomes, where each outcome
describes a set of temporal sequences of subgoals. We define the value of
preference satisfaction given a stochastic process over possible outcomes and
develop an algorithm for time-constrained probabilistic planning in labeled
Markov decision processes where an agent aims to maximally satisfy its
preference formula within a pre-defined finite time duration. We present
experimental results using a stochastic gridworld example and discuss possible
extensions of the proposed preference model.
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures, Accepted by American Control Conference (ACC)
  2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14489</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14491</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Say It All: Feedback for Improving Non-Visual Presentation Accessibility</dc:title>
 <dc:creator>Peng, Yi-Hao</dc:creator>
 <dc:creator>Jang, JiWoong</dc:creator>
 <dc:creator>Bigham, Jeffrey P.</dc:creator>
 <dc:creator>Pavel, Amy</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Presenters commonly use slides as visual aids for informative talks. When
presenters fail to verbally describe the content on their slides, blind and
visually impaired audience members lose access to necessary content, making the
presentation difficult to follow. Our analysis of 90 presentation videos
revealed that 72% of 610 visual elements (e.g., images, text) were
insufficiently described. To help presenters create accessible presentations,
we introduce Presentation A11y, a system that provides real-time and
post-presentation accessibility feedback. Our system analyzes visual elements
on the slide and the transcript of the verbal presentation to provide
element-level feedback on what visual content needs to be further described or
even removed. Presenters using our system with their own slide-based
presentations described more of the content on their slides, and identified
3.26 times more accessibility problems to fix after the talk than when using a
traditional slide-based presentation interface. Integrating accessibility
feedback into content creation tools will improve the accessibility of
informational content for all.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14491</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14493</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RCT: Resource Constrained Training for Edge AI</dc:title>
 <dc:creator>Huang, Tian</dc:creator>
 <dc:creator>Luo, Tao</dc:creator>
 <dc:creator>Yan, Ming</dc:creator>
 <dc:creator>Zhou, Joey Tianyi</dc:creator>
 <dc:creator>Goh, Rick</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>68T07 (Primary) 68T05 (Secondary)</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  Neural networks training on edge terminals is essential for edge AI
computing, which needs to be adaptive to evolving environment. Quantised models
can efficiently run on edge devices, but existing training methods for these
compact models are designed to run on powerful servers with abundant memory and
energy budget. For example, quantisation-aware training (QAT) method involves
two copies of model parameters, which is usually beyond the capacity of on-chip
memory in edge devices. Data movement between off-chip and on-chip memory is
energy demanding as well. The resource requirements are trivial for powerful
servers, but critical for edge devices. To mitigate these issues, We propose
Resource Constrained Training (RCT). RCT only keeps a quantised model
throughout the training, so that the memory requirements for model parameters
in training is reduced. It adjusts per-layer bitwidth dynamically in order to
save energy when a model can learn effectively with lower precision. We carry
out experiments with representative models and tasks in image application and
natural language processing. Experiments show that RCT saves more than 86\%
energy for General Matrix Multiply (GEMM) and saves more than 46\% memory for
model parameters, with limited accuracy loss. Comparing with QAT-based method,
RCT saves about half of energy on moving model parameters.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14493</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14494</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Challenges for Optical Flow Estimates in Elastography</dc:title>
 <dc:creator>Sherina, Ekaterina</dc:creator>
 <dc:creator>Krainz, Lisa</dc:creator>
 <dc:creator>Hubmer, Simon</dc:creator>
 <dc:creator>Drexler, Wolfgang</dc:creator>
 <dc:creator>Scherzer, Otmar</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  In this paper, we consider visualization of displacement fields via optical
flow methods in elastographic experiments consisting of a static compression of
a sample. We propose an elastographic optical flow method (EOFM) which takes
into account experimental constraints, such as appropriate boundary conditions,
the use of speckle information, as well as the inclusion of structural
information derived from knowledge of the background material. We present
numerical results based on both simulated and experimental data from an
elastography experiment in order to demonstrate the relevance of our proposed
approach.
</dc:description>
 <dc:description>Comment: 12 pages, 8 figures</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14494</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14497</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Overview of Collision Avoidance Approaches and Network Architecture
  of Unmanned Aerial Vehicles (UAVs)</dc:title>
 <dc:creator>Sawalmeh, Ahmad H.</dc:creator>
 <dc:creator>Othman, Noor Shamsiah</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  As an autonomous vehicles, Unmanned Aerial Vehicles (UAVs) are subjected to
several challenges. One of the challenges is for UAV to be able to avoid
collision. Many collision avoidance methods have been proposed to address this
issue. Furthermore, in a multi-UAV system, it is also important to address
communication issue among UAVs for cooperation and collaboration. This issue
can be addressed by setting up an ad-hoc network among UAVs. There is also a
need to consider the challenges in the deployment of UAVs, as well as, in the
development of collision avoidance methods and the establishment of
communication for cooperation and collaboration in a multi-UAV system. In this
paper, we present general challenges in the deployment of UAV and comparison of
UAV communication services based on its operating frequency. We also present
major collision avoidance approaches, and specifically discuss collision
avoidance approaches that are suitable for indoor applications. We also present
the Flying Ad-hoc Networks (FANET) network architecture, communication and
routing protocols for each Open System Interconnection (OSI) communication
layers.
</dc:description>
 <dc:description>Comment: 24 pages, 13 Figures, 5 Tables</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14497</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14502</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Agent with Warm Start and Adaptive Dynamic Termination for Plane
  Localization in 3D Ultrasound</dc:title>
 <dc:creator>Yang, Xin</dc:creator>
 <dc:creator>Dou, Haoran</dc:creator>
 <dc:creator>Huang, Ruobing</dc:creator>
 <dc:creator>Xue, Wufeng</dc:creator>
 <dc:creator>Huang, Yuhao</dc:creator>
 <dc:creator>Qian, Jikuan</dc:creator>
 <dc:creator>Zhang, Yuanji</dc:creator>
 <dc:creator>Luo, Huanjia</dc:creator>
 <dc:creator>Guo, Huizhi</dc:creator>
 <dc:creator>Wang, Tianfu</dc:creator>
 <dc:creator>Xiong, Yi</dc:creator>
 <dc:creator>Ni, Dong</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Accurate standard plane (SP) localization is the fundamental step for
prenatal ultrasound (US) diagnosis. Typically, dozens of US SPs are collected
to determine the clinical diagnosis. 2D US has to perform scanning for each SP,
which is time-consuming and operator-dependent. While 3D US containing multiple
SPs in one shot has the inherent advantages of less user-dependency and more
efficiency. Automatically locating SP in 3D US is very challenging due to the
huge search space and large fetal posture variations. Our previous study
proposed a deep reinforcement learning (RL) framework with an alignment module
and active termination to localize SPs in 3D US automatically. However,
termination of agent search in RL is important and affects the practical
deployment. In this study, we enhance our previous RL framework with a newly
designed adaptive dynamic termination to enable an early stop for the agent
searching, saving at most 67% inference time, thus boosting the accuracy and
efficiency of the RL framework at the same time. Besides, we validate the
effectiveness and generalizability of our algorithm extensively on our in-house
multi-organ datasets containing 433 fetal brain volumes, 519 fetal abdomen
volumes, and 683 uterus volumes. Our approach achieves localization error of
2.52mm/10.26 degrees, 2.48mm/10.39 degrees, 2.02mm/10.48 degrees, 2.00mm/14.57
degrees, 2.61mm/9.71 degrees, 3.09mm/9.58 degrees, 1.49mm/7.54 degrees for the
transcerebellar, transventricular, transthalamic planes in fetal brain,
abdominal plane in fetal abdomen, and mid-sagittal, transverse and coronal
planes in uterus, respectively. Experimental results show that our method is
general and has the potential to improve the efficiency and standardization of
US scanning.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Transactions on Medical Imaging (12 pages, 8
  figures, 11 tabels)</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14502</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14507</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AVATAR: Blender add-on for fast creation of 3D human models</dc:title>
 <dc:creator>Sanchez-Riera, Jordi</dc:creator>
 <dc:creator>Civit, Aniol</dc:creator>
 <dc:creator>Altarriba, Marta</dc:creator>
 <dc:creator>Moreno-Noguer, Francesc</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Create an articulated and realistic human 3D model is a complicated task, not
only get a model with the right body proportions but also to the whole process
of rigging the model with correct articulation points and vertices weights.
Having a tool that can create such a model with just a few clicks will be very
advantageous for amateurs developers to use in their projects, researchers to
easily generate datasets to train neural networks and industry for game
development. We present a software that is integrated in Blender in form of
add-on that allows us to design and animate a dressed 3D human models based on
Makehuman with just a few clicks. Moreover, as it is already integrated in
Blender, python scripts can be created to animate, render and further customize
the current available options.
</dc:description>
 <dc:description>Comment: 7 pages, 2 figures, software description</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14507</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14516</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Initialization of State-Space Artificial Neural Networks</dc:title>
 <dc:creator>Schoukens, Maarten</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  The identification of black-box nonlinear state-space models requires a
flexible representation of the state and output equation. Artificial neural
networks have proven to provide such a representation. However, as in many
identification problems, a nonlinear optimization problem needs to be solved to
obtain the model parameters (layer weights and biases). A well-thought
initialization of these model parameters can often avoid that the nonlinear
optimization algorithm converges to a poorly performing local minimum of the
considered cost function. This paper introduces an improved initialization
approach for nonlinear state-space models represented as a recurrent artificial
neural network and emphasizes the importance of including an explicit linear
term in the model structure. Some of the neural network weights are initialized
starting from a linear approximation of the nonlinear system, while others are
initialized using random values or zeros. The effectiveness of the proposed
initialization approach over previously proposed methods is illustrated on two
benchmark examples.
</dc:description>
 <dc:description>Comment: Accepted for presentation at the European Control Conference 2021,
  Rotterdam, The Netherlands</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14516</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14528</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model-based Reconstruction with Learning: From Unsupervised to
  Supervised and Beyond</dc:title>
 <dc:creator>Huang, Zhishen</dc:creator>
 <dc:creator>Ye, Siqi</dc:creator>
 <dc:creator>McCann, Michael T.</dc:creator>
 <dc:creator>Ravishankar, Saiprasad</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Many techniques have been proposed for image reconstruction in medical
imaging that aim to recover high-quality images especially from limited or
corrupted measurements. Model-based reconstruction methods have been
particularly popular (e.g., in magnetic resonance imaging and tomographic
modalities) and exploit models of the imaging system's physics together with
statistical models of measurements, noise and often relatively simple object
priors or regularizers. For example, sparsity or low-rankness based
regularizers have been widely used for image reconstruction from limited data
such as in compressed sensing. Learning-based approaches for image
reconstruction have garnered much attention in recent years and have shown
promise across biomedical imaging applications. These methods include synthesis
dictionary learning, sparsifying transform learning, and different forms of
deep learning involving complex neural networks. We briefly discuss classical
model-based reconstruction methods and then review reconstruction methods at
the intersection of model-based and learning-based paradigms in detail. This
review includes many recent methods based on unsupervised learning, and
supervised learning, as well as a framework to combine multiple types of
learned models together.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14528</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14529</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-Time and Accurate Object Detection in Compressed Video by Long
  Short-term Feature Aggregation</dc:title>
 <dc:creator>Wang, Xinggang</dc:creator>
 <dc:creator>Huang, Zhaojin</dc:creator>
 <dc:creator>Liao, Bencheng</dc:creator>
 <dc:creator>Huang, Lichao</dc:creator>
 <dc:creator>Gong, Yongchao</dc:creator>
 <dc:creator>Huang, Chang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Video object detection is a fundamental problem in computer vision and has a
wide spectrum of applications. Based on deep networks, video object detection
is actively studied for pushing the limits of detection speed and accuracy. To
reduce the computation cost, we sparsely sample key frames in video and treat
the rest frames are non-key frames; a large and deep network is used to extract
features for key frames and a tiny network is used for non-key frames. To
enhance the features of non-key frames, we propose a novel short-term feature
aggregation method to propagate the rich information in key frame features to
non-key frame features in a fast way. The fast feature aggregation is enabled
by the freely available motion cues in compressed videos. Further, key frame
features are also aggregated based on optical flow. The propagated deep
features are then integrated with the directly extracted features for object
detection. The feature extraction and feature integration parameters are
optimized in an end-to-end manner. The proposed video object detection network
is evaluated on the large-scale ImageNet VID benchmark and achieves 77.2\% mAP,
which is on-par with state-of-the-art accuracy, at the speed of 30 FPS using a
Titan X GPU. The source codes are available at
\url{https://github.com/hustvl/LSFA}.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14529</dc:identifier>
 <dc:identifier>Computer Vision and Image Understanding,Volume 206, May 2021</dc:identifier>
 <dc:identifier>doi:10.1016/j.cviu.2021.103188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14536</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Mechanics and Machine Learning Synergies: Graph Attention Neural
  Networks to Predict Chemical Reactivity</dc:title>
 <dc:creator>Tavakoli, Mohammadamin</dc:creator>
 <dc:creator>Mood, Aaron</dc:creator>
 <dc:creator>Van Vranken, David</dc:creator>
 <dc:creator>Baldi, Pierre</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  There is a lack of scalable quantitative measures of reactivity for
functional groups in organic chemistry. Measuring reactivity experimentally is
costly and time-consuming and does not scale to the astronomical size of
chemical space. In previous quantum chemistry studies, we have introduced
Methyl Cation Affinities (MCA*) and Methyl Anion Affinities (MAA*), using a
solvation model, as quantitative measures of reactivity for organic functional
groups over the broadest range. Although MCA* and MAA* offer good estimates of
reactivity parameters, their calculation through Density Functional Theory
(DFT) simulations is time-consuming. To circumvent this problem, we first use
DFT to calculate MCA* and MAA* for more than 2,400 organic molecules thereby
establishing a large dataset of chemical reactivity scores. We then design deep
learning methods to predict the reactivity of molecular structures and train
them using this curated dataset in combination with different representations
of molecular structures. Using ten-fold cross-validation, we show that graph
attention neural networks applied to informative input fingerprints produce the
most accurate estimates of reactivity, achieving over 91% test accuracy for
predicting the MCA* plus-minus 3.0 or MAA* plus-minus 3.0, over 50 orders of
magnitude. Finally, we demonstrate the application of these reactivity scores
to two tasks: (1) chemical reaction prediction; (2) combinatorial generation of
reaction mechanisms. The curated dataset of MCA* and MAA* scores is available
through the ChemDB chemoinformatics web portal at www.cdb.ics.uci.edu.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14537</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection, growth quantification and malignancy prediction of pulmonary
  nodules using deep convolutional networks in follow-up CT scans</dc:title>
 <dc:creator>Rafael-Palou, Xavier</dc:creator>
 <dc:creator>Aubanell, Anton</dc:creator>
 <dc:creator>Ceresa, Mario</dc:creator>
 <dc:creator>Ribas, Vicent</dc:creator>
 <dc:creator>Piella, Gemma</dc:creator>
 <dc:creator>Ballester, Miguel A. Gonz&#xe1;lez</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>65D19, 68T10</dc:subject>
 <dc:subject>I.3</dc:subject>
 <dc:subject>I.4</dc:subject>
 <dc:description>  We address the problem of supporting radiologists in the longitudinal
management of lung cancer. Therefore, we proposed a deep learning pipeline,
composed of four stages that completely automatized from the detection of
nodules to the classification of cancer, through the detection of growth in the
nodules. In addition, the pipeline integrated a novel approach for nodule
growth detection, which relied on a recent hierarchical probabilistic U-Net
adapted to report uncertainty estimates. Also, a second novel method was
introduced for lung cancer nodule classification, integrating into a two stream
3D-CNN network the estimated nodule malignancy probabilities derived from a
pretrained nodule malignancy network. The pipeline was evaluated in a
longitudinal cohort and reported comparable performances to the state of art.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14537</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14538</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Individual Altruism Cannot Overcome Congestion Effects in a Global
  Pandemic Game</dc:title>
 <dc:creator>Brown, Philip N.</dc:creator>
 <dc:creator>Collins, Brandon</dc:creator>
 <dc:creator>Hill, Colton</dc:creator>
 <dc:creator>Barboza, Gia</dc:creator>
 <dc:creator>Hines, Lisa</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  A key challenge in responding to public health crises such as COVID-19 is the
difficulty of predicting the results of feedback interconnections between the
disease and society. As a step towards understanding these interconnections, we
pose a simple game-theoretic model of a global pandemic in which individuals
can choose where to live, and we investigate the global behavior that may
emerge as a result of individuals reacting locally to the competing costs of
isolation and infection. We study the game-theoretic equilibria that emerge
from this setup when the population is composed of either selfish or altruistic
individuals. First, we demonstrate that as is typical in these types of games,
selfish equilibria are in general not optimal, but that all stable selfish
equilibria are within a constant factor of optimal. Second, there exist
infinitely-many stable altruistic equilibria; all but finitely-many of these
are worse than the worst selfish equilibrium, and the social cost of altruistic
equilibria is unbounded. Our work is in sharp contrast to recent work in
network congestion games in which all altruistic equilibria are socially
optimal. This suggests that a population without central coordination may react
very poorly to a pandemic, and that individual altruism could even exacerbate
the problem.
</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14538</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14540</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NL-EDIT: Correcting semantic parse errors through natural language
  interaction</dc:title>
 <dc:creator>Elgohary, Ahmed</dc:creator>
 <dc:creator>Meek, Christopher</dc:creator>
 <dc:creator>Richardson, Matthew</dc:creator>
 <dc:creator>Fourney, Adam</dc:creator>
 <dc:creator>Ramos, Gonzalo</dc:creator>
 <dc:creator>Awadallah, Ahmed Hassan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We study semantic parsing in an interactive setting in which users correct
errors with natural language feedback. We present NL-EDIT, a model for
interpreting natural language feedback in the interaction context to generate a
sequence of edits that can be applied to the initial parse to correct its
errors. We show that NL-EDIT can boost the accuracy of existing text-to-SQL
parsers by up to 20% with only one turn of correction. We analyze the
limitations of the model and discuss directions for improvement and evaluation.
The code and datasets used in this paper are publicly available at
http://aka.ms/NLEdit.
</dc:description>
 <dc:description>Comment: NAACL 2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14540</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14542</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Document Embedding via Contrastive Augmentation</dc:title>
 <dc:creator>Luo, Dongsheng</dc:creator>
 <dc:creator>Cheng, Wei</dc:creator>
 <dc:creator>Ni, Jingchao</dc:creator>
 <dc:creator>Yu, Wenchao</dc:creator>
 <dc:creator>Zhang, Xuchao</dc:creator>
 <dc:creator>Zong, Bo</dc:creator>
 <dc:creator>Liu, Yanchi</dc:creator>
 <dc:creator>Chen, Zhengzhang</dc:creator>
 <dc:creator>Song, Dongjin</dc:creator>
 <dc:creator>Chen, Haifeng</dc:creator>
 <dc:creator>Zhang, Xiang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a contrasting learning approach with data augmentation techniques
to learn document representations in an unsupervised manner. Inspired by recent
contrastive self-supervised learning algorithms used for image and NLP
pretraining, we hypothesize that high-quality document embedding should be
invariant to diverse paraphrases that preserve the semantics of the original
document. With different backbones and contrastive learning frameworks, our
study reveals the enormous benefits of contrastive augmentation for document
representation learning with two additional insights: 1) including data
augmentation in a contrastive way can substantially improve the embedding
quality in unsupervised document representation learning, and 2) in general,
stochastic augmentations generated by simple word-level manipulation work much
better than sentence-level and document-level ones. We plug our method into a
classifier and compare it with a broad range of baseline methods on six
benchmark datasets. Our method can decrease the classification error rate by up
to 6.4% over the SOTA approaches on the document classification task, matching
or even surpassing fully-supervised methods.
</dc:description>
 <dc:description>Comment: 13 pages; under review</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14542</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14548</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Unsupervised Learning for Generalized Assignment Problems: A
  Case-Study of User-Association in Wireless Networks</dc:title>
 <dc:creator>Kaushik, Arjun</dc:creator>
 <dc:creator>Alizadeh, Mehrazin</dc:creator>
 <dc:creator>Waqar, Omer</dc:creator>
 <dc:creator>Tabassum, Hina</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  There exists many resource allocation problems in the field of wireless
communications which can be formulated as the generalized assignment problems
(GAP). GAP is a generic form of linear sum assignment problem (LSAP) and is
more challenging to solve owing to the presence of both equality and inequality
constraints. We propose a novel deep unsupervised learning (DUL) approach to
solve GAP in a time-efficient manner. More specifically, we propose a new
approach that facilitates to train a deep neural network (DNN) using a
customized loss function. This customized loss function constitutes the
objective function and penalty terms corresponding to both equality and
inequality constraints. Furthermore, we propose to employ a Softmax activation
function at the output of DNN along with tensor splitting which simplifies the
customized loss function and guarantees to meet the equality constraint. As a
case-study, we consider a typical user-association problem in a wireless
network, formulate it as GAP, and consequently solve it using our proposed DUL
approach. Numerical results demonstrate that the proposed DUL approach provides
near-optimal results with significantly lower time-complexity.
</dc:description>
 <dc:description>Comment: Accepted in IEEE ICC Workshops, 2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14552</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multilevel Active-Set Trust-Region (MASTR) Method for Bound Constrained
  Minimization</dc:title>
 <dc:creator>Kopani&#x10d;&#xe1;kov&#xe1;, Alena</dc:creator>
 <dc:creator>Krause, Rolf</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We introduce a novel variant of the recursive multilevel trust-region (RMTR)
method, called MASTR. The method is designed for solving non-convex
bound-constrained minimization problems, which arise from the finite element
discretization of partial differential equations. MASTR utilizes an active-set
strategy based on the truncated basis approach in order to preserve the
variable bounds defined on the finest level by the coarser levels. Usage of
this approach allows for fast convergence of the MASTR method, especially once
the exact active-set is detected. The efficiency of the method is demonstrated
by means of numerical examples.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14556</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting the future success of scientific publications through social
  network and semantic analysis</dc:title>
 <dc:creator>Colladon, Andrea Fronzetti</dc:creator>
 <dc:creator>D'Angelo, Ciriaco Andrea</dc:creator>
 <dc:creator>Gloor, Peter A.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Citations acknowledge the impact a scientific publication has on subsequent
work. At the same time, deciding how and when to cite a paper, is also heavily
influenced by social factors. In this work, we conduct an empirical analysis
based on a dataset of 2010-2012 global publications in chemical engineering. We
use social network analysis and text mining to measure publication attributes
and understand which variables can better help predicting their future success.
Controlling for intrinsic quality of a publication and for the number of
authors in the byline, we are able to predict scholarly impact of a paper in
terms of citations received six years after publication with almost 80 percent
accuracy. Results suggest that, all other things being equal, it is better to
co-publish with rotating co-authors and write the papers' abstract using more
positive words, and a more complex, thus more informative, language.
Publications that result from the collaboration of different social groups also
attract more citations.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14556</dc:identifier>
 <dc:identifier>Scientometrics, 124(1), 357-377(2020)</dc:identifier>
 <dc:identifier>doi:10.1007/s11192-020-03479-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14557</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Does the geographic proximity effect on knowledge spillovers vary across
  research fields?</dc:title>
 <dc:creator>Abramo, Giovanni</dc:creator>
 <dc:creator>D'Angelo, Ciriaco Andrea</dc:creator>
 <dc:creator>Di Costa, Flavia</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Policy makers are interested in the influence of geographic distance on
knowledge flows, however these can be expected to vary across research fields.
The effects of geographic distance on flows are analyzed by means of citations
to scientific literature. The field of observation consists of the 2010-2012
Italian publications and relevant citations up to the close of 2017. The
geographic proximity effect is analyzed at national, continental, and
intercontinental level in 244 fields, and results as evident at national level
and in some cases at continental level, but not at intercontinental level. For
flows between Italian municipalities, citations decrease with distance in all
fields. At continental level, four fields are identified having knowledge flows
that grow with distance; at intercontinental level, this occurs in 26 fields.
The influence of distance is more limited in the fields of Humanities and
Social sciences, much more significant in the Sciences, mainly in the Natural
sciences.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:2002.00742,
  arXiv:2103.13819</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14557</dc:identifier>
 <dc:identifier>Scientometrics, 123(2), 1021-1036 (2020)</dc:identifier>
 <dc:identifier>doi:10.1007/s11192-020-03411-x</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14558</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collecting large-scale publication data at the level of individual
  researchers: A practical proposal for author name disambiguation</dc:title>
 <dc:creator>D'Angelo, Ciriaco Andrea</dc:creator>
 <dc:creator>van Eck, Nees Jan</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  The disambiguation of author names is an important and challenging task in
bibliometrics. We propose an approach that relies on an external source of
information for selecting and validating clusters of publications identified
through an unsupervised author name disambiguation method. The application of
the proposed approach to a random sample of Italian scholars shows encouraging
results, with an overall precision, recall, and F-Measure of over 96%. The
proposed approach can serve as a starting point for large-scale census of
publication portfolios for bibliometric analyses at the level of individual
researchers.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14558</dc:identifier>
 <dc:identifier>Scientometrics, 123(2), 883-907 (2020)</dc:identifier>
 <dc:identifier>doi:10.1007/s11192-020-03410-y</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14560</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A novel methodology to assess the scientific standing of nations at
  field level</dc:title>
 <dc:creator>Abramo, Giovanni</dc:creator>
 <dc:creator>D'Angelo, Ciriaco Andrea</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  The formulation of national research policies would benefit greatly from
reliable strategic analysis of the scientific infrastructure, aimed at
identifying the relevant strengths and weaknesses at field level. Bibliometric
methodologies thus far proposed in the literature are not completely
satisfactory. This work proposes a novel &quot;output-to-input-oriented&quot; approach,
which permits identification of research strengths and weaknesses on the basis
of the ratios of top scientists and highly cited articles to research
expenditures in each field. The proposed approach is applied to the Italian
academic system. 2012-2016 scientific publications are analyzed, in the 218
research fields where bibliometric assessment is appropriate.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14560</dc:identifier>
 <dc:identifier>AJournal of Informetrics, 14(1) 100986 (2020)</dc:identifier>
 <dc:identifier>doi:10.1016/j.joi.2019.100986</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14562</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classification of Pneumonia and Tuberculosis from Chest X-rays</dc:title>
 <dc:creator>Abubakar, M.</dc:creator>
 <dc:creator>Shah, I.</dc:creator>
 <dc:creator>Ali, W.</dc:creator>
 <dc:creator>bashir, F.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>J.3.7</dc:subject>
 <dc:description>  Artificial intelligence (AI) and specifically machine learning is making
inroads into number of fields. Machine learning is replacing and/or
complementing humans in a certain type of domain to make systems perform tasks
more efficiently and independently. Healthcare is a worthy domain to merge with
AI and Machine learning to get things to work smoother and efficiently. The
X-ray based detection and classification of diseases related to chest is much
needed in this modern era due to the low number of quality radiologists. This
thesis focuses on the classification of Pneumonia and Tuberculosis two major
chest diseases from the chest X-rays. This system provides an opinion to the
user whether one is having a disease or not, thereby helping doctors and
medical staff to make a quick and informed decision about the presence of
disease. As compared to previous work our model can detect two types of
abnormality. Our model can detect whether X-ray is normal or having abnormality
which can be pneumonia and tuberculosis 92.97% accurately.
</dc:description>
 <dc:description>Comment: 6 pages, 10 figures, 2 tables, conference</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14562</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14571</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-time implementation of MPC for tracking in embedded systems:
  Application to a two-wheeled inverted pendulum</dc:title>
 <dc:creator>Krupa, Pablo</dc:creator>
 <dc:creator>Camara, Jose</dc:creator>
 <dc:creator>Alvarado, Ignacio</dc:creator>
 <dc:creator>Limon, Daniel</dc:creator>
 <dc:creator>Alamo, Teodoro</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This article presents the real-time implementation of the model predictive
control for tracking formulation to control a two-wheeled inverted pendulum
robot. This formulation offers several advantages over standard MPC
formulations at the expense of the addition of a small number of decision
variables, which complicates the inner structure of the matrices of the
optimization problem. We implement a sparse solver, based on an extension of
the alternating direction method of multipliers, in the system's embedded
hardware. The results indicate that the solver is suitable for controlling a
real system with sample times in the range of milliseconds using current,
readily-available hardware.
</dc:description>
 <dc:description>Comment: 6 pages, 9 figures</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14571</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14576</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Verification of Eventual Consensus in Synod Using a Failure-Aware Actor
  Model</dc:title>
 <dc:creator>Paul, Saswata</dc:creator>
 <dc:creator>Agha, Gul A.</dc:creator>
 <dc:creator>Patterson, Stacy</dc:creator>
 <dc:creator>Varela, Carlos A.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Successfully attaining consensus in the absence of a centralized coordinator
is a fundamental problem in distributed multi-agent systems. We analyze
progress in the Synod consensus protocol -- which does not assume a unique
leader -- under the assumptions of asynchronous communication and potential
agent failures. We identify a set of sufficient conditions under which it is
possible to guarantee that a set of agents will eventually attain consensus.
First, a subset of the agents must behave correctly and not permanently fail
until consensus is reached, and second, at least one proposal must be
eventually uninterrupted by higher-numbered proposals. To formally reason about
agent failures, we introduce a failure-aware actor model (FAM). Using FAM, we
model the identified conditions and provide a formal proof of eventual progress
in Synod. Our proof has been mechanically verified using the Athena proof
assistant and, to the best of our knowledge, it is the first machine-checked
proof of eventual progress in Synod.
</dc:description>
 <dc:description>Comment: This technical report is an extended version of the NASA Formal
  Methods Symposium 2021 proceedings paper with the same name</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14576</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14577</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Robust Domain Adaptation without Source Data</dc:title>
 <dc:creator>Agarwal, Peshal</dc:creator>
 <dc:creator>Paudel, Danda Pani</dc:creator>
 <dc:creator>Zaech, Jan-Nico</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We study the problem of robust domain adaptation in the context of
unavailable target labels and source data. The considered robustness is against
adversarial perturbations. This paper aims at answering the question of finding
the right strategy to make the target model robust and accurate in the setting
of unsupervised domain adaptation without source data. The major findings of
this paper are: (i) robust source models can be transferred robustly to the
target; (ii) robust domain adaptation can greatly benefit from non-robust
pseudo-labels and the pair-wise contrastive loss. The proposed method of using
non-robust pseudo-labels performs surprisingly well on both clean and
adversarial samples, for the task of image classification. We show a consistent
performance improvement of over $10\%$ in accuracy against the tested baselines
on four benchmark datasets.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14577</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14579</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GeoSP: A parallel method for a cortical surface parcellation based on
  geodesic distance</dc:title>
 <dc:creator>L&#xf3;pez-L&#xf3;pez, Narciso</dc:creator>
 <dc:creator>V&#xe1;zquez, Andrea</dc:creator>
 <dc:creator>Poupon, Cyril</dc:creator>
 <dc:creator>Mangin, Jean-Fran&#xe7;ois</dc:creator>
 <dc:creator>Ladra, Susana</dc:creator>
 <dc:creator>Guevara, Pamela</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present GeoSP, a parallel method that creates a parcellation of the
cortical mesh based on a geodesic distance, in order to consider gyri and sulci
topology. The method represents the mesh with a graph and performs a K-means
clustering in parallel. It has two modes of use, by default, it performs the
geodesic cortical parcellation based on the boundaries of the anatomical
parcels provided by the Desikan-Killiany atlas. The other mode performs the
complete parcellation of the cortex. Results for both modes and with different
values for the total number of sub-parcels show homogeneous sub-parcels.
Furthermore, the execution time is 82 s for the whole cortex mode and 18 s for
the Desikan-Killiany atlas subdivision, for a parcellation into 350
sub-parcels. The proposed method will be available to the community to perform
the evaluation of data-driven cortical parcellations. As an example, we
compared GeoSP parcellation with Desikan-Killiany and Destrieux atlases in 50
subjects, obtaining more homogeneous parcels for GeoSP and minor differences in
structural connectivity reproducibility across subjects.
</dc:description>
 <dc:description>Comment: This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sklodowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941, ANID PFCHA/DOCTORADO
  NACIONAL/2016-21160342, ANID FONDECYT 1190701, ANID PIA/Anillo de
  Investigaci\'on en Ciencia y Tecnolog\'ia ACT172121, and ANID Basal Project
  FB0008</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14579</dc:identifier>
 <dc:identifier>doi:10.1109/EMBC44109.2020.9175779</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14580</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Correcting Automated and Manual Speech Transcription Errors using Warped
  Language Models</dc:title>
 <dc:creator>Namazifar, Mahdi</dc:creator>
 <dc:creator>Malik, John</dc:creator>
 <dc:creator>Li, Li Erran</dc:creator>
 <dc:creator>Tur, Gokhan</dc:creator>
 <dc:creator>T&#xfc;r, Dilek Hakkani</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Masked language models have revolutionized natural language processing
systems in the past few years. A recently introduced generalization of masked
language models called warped language models are trained to be more robust to
the types of errors that appear in automatic or manual transcriptions of spoken
language by exposing the language model to the same types of errors during
training. In this work we propose a novel approach that takes advantage of the
robustness of warped language models to transcription noise for correcting
transcriptions of spoken language. We show that our proposed approach is able
to achieve up to 10% reduction in word error rates of both automatic and manual
transcriptions of spoken language.
</dc:description>
 <dc:description>Comment: Submitted to INTERSPEECH</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14580</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14581</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Salient Region Object Mining for Weakly Supervised Semantic
  Segmentation</dc:title>
 <dc:creator>Yao, Yazhou</dc:creator>
 <dc:creator>Chen, Tao</dc:creator>
 <dc:creator>Xie, Guosen</dc:creator>
 <dc:creator>Zhang, Chuanyi</dc:creator>
 <dc:creator>Shen, Fumin</dc:creator>
 <dc:creator>Wu, Qi</dc:creator>
 <dc:creator>Tang, Zhenmin</dc:creator>
 <dc:creator>Zhang, Jian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Semantic segmentation aims to classify every pixel of an input image.
Considering the difficulty of acquiring dense labels, researchers have recently
been resorting to weak labels to alleviate the annotation burden of
segmentation. However, existing works mainly concentrate on expanding the seed
of pseudo labels within the image's salient region. In this work, we propose a
non-salient region object mining approach for weakly supervised semantic
segmentation. We introduce a graph-based global reasoning unit to strengthen
the classification network's ability to capture global relations among disjoint
and distant regions. This helps the network activate the object features
outside the salient area. To further mine the non-salient region objects, we
propose to exert the segmentation network's self-correction ability.
Specifically, a potential object mining module is proposed to reduce the
false-negative rate in pseudo labels. Moreover, we propose a non-salient region
masking module for complex images to generate masked pseudo labels. Our
non-salient region masking module helps further discover the objects in the
non-salient region. Extensive experiments on the PASCAL VOC dataset demonstrate
state-of-the-art results compared to current methods.
</dc:description>
 <dc:description>Comment: accepted by IEEE Conference on Computer Vision and Pattern
  Recognition, 2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14581</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14587</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep-AIR: A Hybrid CNN-LSTM Framework for Air Quality Modeling in
  Metropolitan Cities</dc:title>
 <dc:creator>Han, Yang</dc:creator>
 <dc:creator>Zhang, Qi</dc:creator>
 <dc:creator>Li, Victor O. K.</dc:creator>
 <dc:creator>Lam, Jacqueline C. K.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Air pollution has long been a serious environmental health challenge,
especially in metropolitan cities, where air pollutant concentrations are
exacerbated by the street canyon effect and high building density. Whilst
accurately monitoring and forecasting air pollution are highly crucial,
existing data-driven models fail to fully address the complex interaction
between air pollution and urban dynamics. Our Deep-AIR, a novel hybrid deep
learning framework that combines a convolutional neural network with a long
short-term memory network, aims to address this gap to provide fine-grained
city-wide air pollution estimation and station-wide forecast. Our proposed
framework creates 1x1 convolution layers to strengthen the learning of
cross-feature spatial interaction between air pollution and important urban
dynamic features, particularly road density, building density/height, and
street canyon effect. Using Hong Kong and Beijing as case studies, Deep-AIR
achieves a higher accuracy than our baseline models. Our model attains an
accuracy of 67.6%, 77.2%, and 66.1% in fine-grained hourly estimation, 1-hr,
and 24-hr air pollution forecast for Hong Kong, and an accuracy of 65.0%,
75.3%, and 63.5% for Beijing. Our saliency analysis has revealed that for Hong
Kong, street canyon and road density are the best estimators for NO2, while
meteorology is the best estimator for PM2.5.
</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14587</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14595</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed formation control of manipulators' end-effector with
  internal model-based disturbance rejection</dc:title>
 <dc:creator>Wu, Haiwen</dc:creator>
 <dc:creator>Jayawardhana, Bayu</dc:creator>
 <dc:creator>de Marina, Hector Garcia</dc:creator>
 <dc:creator>Xu, Dabo</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper addresses the problem of end-effector formation control for
manipulators that are subjected to external disturbances: input disturbance
torques and disturbance forces at each end-effector. The disturbances are
assumed to be non-vanishing and are superposition of finite number of
sinusoidal and step signals. The formation control objective is achieved by
assigning virtual springs between end-effectors, by adding damping terms at
joints, and by incorporating internal model-based dynamic compensators to
counteract the effect of the disturbances; all of which presents a clear
physical interpretation of the proposed approach. Simulation results are
presented to illustrate the effectiveness of the proposed approach.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14595</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14596</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An ns-3 implementation of a battery-less node for energy-harvesting
  Internet of Things</dc:title>
 <dc:creator>Capuzzo, Martina</dc:creator>
 <dc:creator>Delgado, Carmen</dc:creator>
 <dc:creator>Famaey, Jeroen</dc:creator>
 <dc:creator>Zanella, Andrea</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In the Internet of Things (IoT), thousands of devices can be deployed to
acquire data from the environment and provide service to several applications
in different fields. In many cases, it is desirable that devices are
self-sustainable in terms of energy. Therefore,the research community is
exploring the possibility of employing battery-less devices, where the energy
is derived solely from external and/or environmental sources, such as solar
panels. In this work, we propose an ns-3 model of a (super) capacitor, which
can be used as the storage of the harvested energy in a battery-less IoT
device, and add the support for the intermittent behavior of devices, turning
off/on according to their energy level. To exemplify the use of the model, we
apply it to a LoRaWAN node, and compare the simulation outcomes with results in
the literature obtained with mathematical analysis, confirming the accuracy of
the implementation. Then, we show the importance of analyzing the interaction
between energy availability and communication performance, paving the way for
more accurate and realistic simulations in the field. The implemented code is
made available as open source.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14599</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimum Scan Cover and Variants -- Theory and Experiments</dc:title>
 <dc:creator>Buchin, Kevin</dc:creator>
 <dc:creator>Fekete, S&#xe1;ndor P.</dc:creator>
 <dc:creator>Hill, Alexander</dc:creator>
 <dc:creator>Kleist, Linda</dc:creator>
 <dc:creator>Kostitsyna, Irina</dc:creator>
 <dc:creator>Krupke, Dominik</dc:creator>
 <dc:creator>Lambers, Roel</dc:creator>
 <dc:creator>Struijs, Martijn</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We consider a spectrum of geometric optimization problems motivated by
contexts such as satellite communication and astrophysics. In the problem
Minimum Scan Cover with Angular Costs, we are given a graph $G$ that is
embedded in Euclidean space. The edges of $G$ need to be scanned, i.e., probed
from both of their vertices. In order to scan their edge, two vertices need to
face each other; changing the heading of a vertex incurs some cost in terms of
energy or rotation time that is proportional to the corresponding rotation
angle. Our goal is to compute schedules that minimize the following objective
functions: (i) in Minimum Makespan Scan Cover (MSC-MS), this is the time until
all edges are scanned; (ii) in Minimum Total Energy Scan Cover (MSC-TE), the
sum of all rotation angles; (iii) in Minimum Bottleneck Energy Scan Cover
(MSC-BE), the maximum total rotation angle at one vertex.
  Previous theoretical work on MSC-MS revealed a close connection to graph
coloring and the cut cover problem, leading to hardness and approximability
results. In this paper, we present polynomial-time algorithms for 1D instances
of MSC-TE and MSC-BE, but NP-hardness proofs for bipartite 2D instances. For
bipartite graphs in 2D, we also give 2-approximation algorithms for both MSC-TE
and MSC-BE. Most importantly, we provide a comprehensive study of practical
methods for all three problems. We compare three different mixed-integer
programming and two constraint programming approaches, and show how to compute
provably optimal solutions for geometric instances with up to 300 edges.
Additionally, we compare the performance of different meta-heuristics for even
larger instances.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14599</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14601</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>YouTubing at Home: Media Sharing Behavior Change as Proxy for
  MobilityAround COVID-19 Lockdowns</dc:title>
 <dc:creator>Mejova, Yelena</dc:creator>
 <dc:creator>Kourtellis, Nicolas</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Compliance with public health measures, such as restrictions on movement and
socialization, is paramount in limiting the spread of diseases such as the
severe acute respiratory syndrome coronavirus 2 (also referred to as COVID-19).
Although large population datasets, such as phone-based mobility data, may
provide some glimpse into such compliance, it is often proprietary, and may not
be available for all locales. In this work, we examine the usefulness of video
sharing on social media as a proxy of the amount of time Internet users spend
at home. In particular, we focus on the number of people sharing YouTube videos
on Twitter before and during COVID-19 lockdown measures were imposed by 109
countries. We find that the media sharing behavior differs widely between
countries, in some having immediate response to the lockdown decrees - mostly
by increasing the sharing volume dramatically - while in others having a
substantial lag. We confirm that these insights correlate strongly with
mobility, as measured using phone data. Finally, we illustrate that both media
sharing and mobility behaviors change more drastically around mandated
lockdowns, and less so around more lax recommendations. We make the media
sharing volume data available to the research community for continued
monitoring of behavior change around public health measures.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14603</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dispersion-Minimizing Motion Primitives for Search-Based Motion Planning</dc:title>
 <dc:creator>Jarin-Lipschitz, Laura</dc:creator>
 <dc:creator>Paulos, James</dc:creator>
 <dc:creator>Bjorkman, Raymond</dc:creator>
 <dc:creator>Kumar, Vijay</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Search-based planning with motion primitives is a powerful motion planning
technique that can provide dynamic feasibility, optimality, and real-time
computation times on size, weight, and power-constrained platforms in
unstructured environments. However, optimal design of the motion planning
graph, while crucial to the performance of the planner, has not been a main
focus of prior work. This paper proposes to address this by introducing a
method of choosing vertices and edges in a motion primitive graph that is
grounded in sampling theory and leads to theoretical guarantees on planner
completeness. By minimizing dispersion of the graph vertices in the metric
space induced by trajectory cost, we optimally cover the space of feasible
trajectories with our motion primitive graph. In comparison with baseline
motion primitives defined by uniform input space sampling, our motion primitive
graphs have lower dispersion, find a plan with fewer iterations of the graph
search, and have only one parameter to tune.
</dc:description>
 <dc:description>Comment: 7 pages, final version accepted at ICRA 2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14603</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14604</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Demand for Air Taxi Urban Aviation Services using Machine
  Learning Algorithms</dc:title>
 <dc:creator>Rajendran, Suchithra</dc:creator>
 <dc:creator>Srinivas, Sharan</dc:creator>
 <dc:creator>Grimshaw, Trenton</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  This research focuses on predicting the demand for air taxi urban air
mobility (UAM) services during different times of the day in various geographic
regions of New York City using machine learning algorithms (MLAs). Several
ride-related factors (such as month of the year, day of the week and time of
the day) and weather-related variables (such as temperature, weather conditions
and visibility) are used as predictors for four popular MLAs, namely, logistic
regression, artificial neural networks, random forests, and gradient boosting.
Experimental results suggest gradient boosting to consistently provide higher
prediction performance. Specific locations, certain time periods and weekdays
consistently emerged as critical predictors.
</dc:description>
 <dc:description>Comment: 24 pages, 3 figures, 4 tables</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14604</dc:identifier>
 <dc:identifier>Journal of Air Transport Management 92 (2021): 102043</dc:identifier>
 <dc:identifier>doi:10.1016/j.jairtraman.2021.102043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14606</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Convex Programming Approach to Data-Driven Risk-Averse Reinforcement
  Learning</dc:title>
 <dc:creator>Han, Yuzhen</dc:creator>
 <dc:creator>Mazouchi, Majid</dc:creator>
 <dc:creator>Nageshrao, Subramanya</dc:creator>
 <dc:creator>Modares, Hamidreza</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents a model-free reinforcement learning (RL) algorithm to
solve the risk-averse optimal control (RAOC) problem for discrete-time
nonlinear systems. While successful RL algorithms have been presented to learn
optimal control solutions under epistemic uncertainties (i.e., lack of
knowledge of system dynamics), they do so by optimizing the expected utility of
outcomes, which ignores the variance of cost under aleatory uncertainties
(i.e., randomness). Performance-critical systems, however, must not only
optimize the expected performance, but also reduce its variance to avoid
performance fluctuation during RL's course of operation. To solve the RAOC
problem, this paper presents the following three variants of RL algorithms and
analyze their advantages and preferences for different situations/systems: 1) a
one-shot static convex program -based RL, 2) an iterative value iteration (VI)
algorithm that solves a linear programming (LP) optimization at each iteration,
and 3) an iterative policy iteration (PI) algorithm that solves a convex
optimization at each iteration and guarantees the stability of the consecutive
control policies. Convergence of the exact optimization problems, which are
infinite-dimensional in all three cases, to the optimal risk-averse value
function is shown. To turn these optimization problems into standard
optimization problems with finite decision variables and constraints, function
approximation for value estimations as well as constraint sampling are
leveraged. Data-driven implementations of these algorithms are provided based
on Q-function which enables learning the optimal value without any knowledge of
the system dynamics. The performance of the approximated solutions is also
verified through a weighted sup-norm bound and the Lyapunov bound. A simulation
example is provided to verify the effectiveness of the presented approach.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14610</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SKID RAW: Skill Discovery from Raw Trajectories</dc:title>
 <dc:creator>Tanneberg, Daniel</dc:creator>
 <dc:creator>Ploeger, Kai</dc:creator>
 <dc:creator>Rueckert, Elmar</dc:creator>
 <dc:creator>Peters, Jan</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Integrating robots in complex everyday environments requires a multitude of
problems to be solved. One crucial feature among those is to equip robots with
a mechanism for teaching them a new task in an easy and natural way. When
teaching tasks that involve sequences of different skills, with varying order
and number of these skills, it is desirable to only demonstrate full task
executions instead of all individual skills. For this purpose, we propose a
novel approach that simultaneously learns to segment trajectories into
reoccurring patterns and the skills to reconstruct these patterns from
unlabelled demonstrations without further supervision. Moreover, the approach
learns a skill conditioning that can be used to understand possible sequences
of skills, a practical mechanism to be used in, for example,
human-robot-interactions for a more intelligent and adaptive robot behaviour.
The Bayesian and variational inference based approach is evaluated on synthetic
and real human demonstrations with varying complexities and dimensionality,
showing the successful learning of segmentations and skill libraries from
unlabelled data.
</dc:description>
 <dc:description>Comment: IEEE Robotics and Automation Letters</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14610</dc:identifier>
 <dc:identifier>doi:10.1109/LRA.2021.3068891</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14622</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LPV Modeling of Nonlinear Systems: A Multi-Path Feedback Linearization
  Approach</dc:title>
 <dc:creator>Abbas, Hossam S.</dc:creator>
 <dc:creator>T&#xf3;th, Roland</dc:creator>
 <dc:creator>Petreczky, Mih&#xe1;ly</dc:creator>
 <dc:creator>Meskin, Nader</dc:creator>
 <dc:creator>Velni, Javad Mohammadpour</dc:creator>
 <dc:creator>Koelewijn, Patrick J. W.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper introduces a systematic approach to synthesize linear
parameter-varying (LPV) representations of nonlinear (NL) systems which are
described by input affine state-space (SS) representations. The conversion
approach results in LPV-SS representations in the observable canonical form.
Based on the relative degree concept, first the SS description of a given NL
representation is transformed to a normal form. In the SISO case, all
nonlinearities of the original system are embedded into one NL function, which
is factorized, based on a proposed algorithm, to construct an LPV
representation of the original NL system. The overall procedure yields an LPV
model in which the scheduling variable depends on the inputs and outputs of the
system and their derivatives, achieving a practically applicable transformation
of the model in case of low order derivatives. In addition, if the states of
the NL model can be measured or estimated, then a modified procedure is
proposed to provide LPV models scheduled by these states. Examples are included
to demonstrate both approaches.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14622</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14624</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomization-based Machine Learning in Renewable Energy Prediction
  Problems: Critical Literature Review, New Results and Perspectives</dc:title>
 <dc:creator>Del Ser, Javier</dc:creator>
 <dc:creator>Casillas-Perez, David</dc:creator>
 <dc:creator>Cornejo-Bueno, Laura</dc:creator>
 <dc:creator>Prieto-Godino, Luis</dc:creator>
 <dc:creator>Sanz-Justo, Julia</dc:creator>
 <dc:creator>Casanova-Mateo, Carlos</dc:creator>
 <dc:creator>Salcedo-Sanz, Sancho</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Randomization-based Machine Learning methods for prediction are currently a
hot topic in Artificial Intelligence, due to their excellent performance in
many prediction problems, with a bounded computation time. The application of
randomization-based approaches to renewable energy prediction problems has been
massive in the last few years, including many different types of
randomization-based approaches, their hybridization with other techniques and
also the description of new versions of classical randomization-based
algorithms, including deep and ensemble approaches. In this paper we review the
most important characteristics of randomization-based machine learning
approaches and their application to renewable energy prediction problems. We
describe the most important methods and algorithms of this family of modeling
methods, and perform a critical literature review, examining prediction
problems related to solar, wind, marine/ocean and hydro-power renewable
sources. We support our critical analysis with an extensive experimental study,
comprising real-world problems related to solar, wind and hydro-power energy,
where randomization-based algorithms are found to achieve superior results at a
significantly lower computational cost than other modeling counterparts. We end
our survey with a prospect of the most important challenges and research
directions that remain open this field, along with an outlook motivating
further research efforts in this exciting research field.
</dc:description>
 <dc:description>Comment: 88 pages, 14 figures, 12 tables. Under review</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14627</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Higher Dimensional Graphics: Conceiving Worlds in Four Spatial
  Dimensions and Beyond</dc:title>
 <dc:creator>Cavallo, Marco</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  While the interpretation of high-dimensional datasets has become a necessity
in most industries, and is supported by continuous advances in data science and
machine learning, the spatial visualization of higher-dimensional geometry has
mostly remained a niche research topic for mathematicians and physicists.
Intermittent contributions to this field date back more than a century, and
have had a non-negligible influence on contemporary art and philosophy.
However, most contributions have focused on the understanding of specific
mathematical shapes, with few concrete applications. In this work, we attempt
to revive the community's interest in visualizing higher dimensional geometry
by shifting the focus from the visualization of abstract shapes to the design
of a broader hyper-universe concept, wherein 3D and 4D objects can coexist and
interact with each other. Specifically, we discuss the content definition,
authoring patterns, and technical implementations associated with the process
of extending standard 3D applications as to support 4D mechanics. We
operationalize our ideas through the introduction of a new hybrid 3D/4D
videogame called Across Dimensions, which we developed in Unity3D through the
integration of our own 4D plugin.
</dc:description>
 <dc:description>Comment: Eurographics 2021 / Computer Graphics Forum</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14627</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14628</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Stage Attack Detection via Kill Chain State Machines</dc:title>
 <dc:creator>Wilkens, Florian</dc:creator>
 <dc:creator>Ortmann, Felix</dc:creator>
 <dc:creator>Haas, Steffen</dc:creator>
 <dc:creator>Vallentin, Matthias</dc:creator>
 <dc:creator>Fischer, Mathias</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Today, human security analysts collapse under the sheer volume of alerts they
have to triage during investigations. The inability to cope with this load,
coupled with a high false positive rate of alerts, creates alert fatigue. This
results in failure to detect complex attacks, such as advanced persistent
threats (APTs), because they manifest over long time frames and attackers tread
carefully to evade detection mechanisms. In this paper, we contribute a new
method to synthesize attack graphs from state machines. We use the network
direction to derive potential attack stages from single and meta-alerts and
model resulting attack scenarios in a kill chain state machine (KCSM). Our
algorithm yields a graphical summary of the attack, APT scenario graphs, where
nodes represent involved hosts and edges infection activity. We evaluate the
feasibility of our approach in multiple experiments based on the
CSE-CIC-IDS2018 data set. We obtain up to 446 458 singleton alerts that our
algorithm condenses into 700 APT scenario graphs resulting in a reduction of up
to three orders of magnitude. This reduction makes it feasible for human
analysts to effectively triage potential incidents. An evaluation on the same
data set, in which we embedded a synthetic yet realistic APT campaign, supports
the applicability of our approach of detecting and contextualizing complex
attacks. The APT scenario graphs constructed by our algorithm correctly link
large parts of the APT campaign and present a coherent view to support the
human analyst in further analyses.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14628</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14629</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid analysis and modeling, eclecticism, and multifidelity computing
  toward digital twin revolution</dc:title>
 <dc:creator>San, Omer</dc:creator>
 <dc:creator>Rasheed, Adil</dc:creator>
 <dc:creator>Kvamsdal, Trond</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:description>  Most modeling approaches lie in either of the two categories: physics-based
or data-driven. Recently, a third approach which is a combination of these
deterministic and statistical models is emerging for scientific applications.
To leverage these developments, our aim in this perspective paper is centered
around exploring numerous principle concepts to address the challenges of (i)
trustworthiness and generalizability in developing data-driven models to shed
light on understanding the fundamental trade-offs in their accuracy and
efficiency, and (ii) seamless integration of interface learning and
multifidelity coupling approaches that transfer and represent information
between different entities, particularly when different scales are governed by
different physics, each operating on a different level of abstraction.
Addressing these challenges could enable the revolution of digital twin
technologies for scientific and engineering applications.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14629</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14633</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visionary: Vision architecture discovery for robot learning</dc:title>
 <dc:creator>Akinola, Iretiayo</dc:creator>
 <dc:creator>Angelova, Anelia</dc:creator>
 <dc:creator>Lu, Yao</dc:creator>
 <dc:creator>Chebotar, Yevgen</dc:creator>
 <dc:creator>Kalashnikov, Dmitry</dc:creator>
 <dc:creator>Varley, Jacob</dc:creator>
 <dc:creator>Ibarz, Julian</dc:creator>
 <dc:creator>Ryoo, Michael S.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We propose a vision-based architecture search algorithm for robot
manipulation learning, which discovers interactions between low dimension
action inputs and high dimensional visual inputs. Our approach automatically
designs architectures while training on the task - discovering novel ways of
combining and attending image feature representations with actions as well as
features from previous layers. The obtained new architectures demonstrate
better task success rates, in some cases with a large margin, compared to a
recent high performing baseline. Our real robot experiments also confirm that
it improves grasping performance by 6%. This is the first approach to
demonstrate a successful neural architecture search and attention connectivity
search for a real-robot task.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14633</dc:identifier>
 <dc:identifier>ICRA 2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14645</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Baking Neural Radiance Fields for Real-Time View Synthesis</dc:title>
 <dc:creator>Hedman, Peter</dc:creator>
 <dc:creator>Srinivasan, Pratul P.</dc:creator>
 <dc:creator>Mildenhall, Ben</dc:creator>
 <dc:creator>Barron, Jonathan T.</dc:creator>
 <dc:creator>Debevec, Paul</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Neural volumetric representations such as Neural Radiance Fields (NeRF) have
emerged as a compelling technique for learning to represent 3D scenes from
images with the goal of rendering photorealistic images of the scene from
unobserved viewpoints. However, NeRF's computational requirements are
prohibitive for real-time applications: rendering views from a trained NeRF
requires querying a multilayer perceptron (MLP) hundreds of times per ray. We
present a method to train a NeRF, then precompute and store (i.e. &quot;bake&quot;) it as
a novel representation called a Sparse Neural Radiance Grid (SNeRG) that
enables real-time rendering on commodity hardware. To achieve this, we
introduce 1) a reformulation of NeRF's architecture, and 2) a sparse voxel grid
representation with learned feature vectors. The resulting scene representation
retains NeRF's ability to render fine geometric details and view-dependent
appearance, is compact (averaging less than 90 MB per scene), and can be
rendered in real-time (higher than 30 frames per second on a laptop GPU).
Actual screen captures are shown in our video.
</dc:description>
 <dc:description>Comment: Project page: https://nerf.live</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14645</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14650</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Approach to Scalar, Vector, and Tensor Slepian Functions on
  the Sphere and Their Construction by a Commuting Operator</dc:title>
 <dc:creator>Michel, Volker</dc:creator>
 <dc:creator>Plattner, Alain</dc:creator>
 <dc:creator>Seibert, Katrin</dc:creator>
 <dc:subject>Mathematics - Classical Analysis and ODEs</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>33C55, 41A10, 41A63, 42C05, 42C10, 42C25, 43A90, 45C05, 86-08</dc:subject>
 <dc:description>  We present a unified approach for constructing Slepian functions - also known
as prolate spheroidal wave functions - on the sphere for arbitrary tensor ranks
including scalar, vectorial, and rank 2 tensorial Slepian functions, using
spin-weighted spherical harmonics. For the special case of spherical cap
regions, we derived commuting operators, allowing for a numerically stable and
computationally efficient construction of the spin-weighted
spherical-harmonic-based Slepian functions. Linear relationships between the
spin-weighted and the classical scalar, vectorial, tensorial, and higher-rank
spherical harmonics allow the construction of classical
spherical-harmonic-based Slepian functions from their spin-weighted
counterparts, effectively rendering the construction of spherical-cap Slepian
functions for any tensorial rank a computationally fast and numerically stable
task.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14650</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14659</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Alignment of Language Agents</dc:title>
 <dc:creator>Kenton, Zachary</dc:creator>
 <dc:creator>Everitt, Tom</dc:creator>
 <dc:creator>Weidinger, Laura</dc:creator>
 <dc:creator>Gabriel, Iason</dc:creator>
 <dc:creator>Mikulik, Vladimir</dc:creator>
 <dc:creator>Irving, Geoffrey</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  For artificial intelligence to be beneficial to humans the behaviour of AI
agents needs to be aligned with what humans want. In this paper we discuss some
behavioural issues for language agents, arising from accidental
misspecification by the system designer. We highlight some ways that
misspecification can occur and discuss some behavioural issues that could arise
from misspecification, including deceptive or manipulative language, and review
some approaches for avoiding these issues.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14659</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14660</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Disease Detection in Retinal Imaging based on Ensembling
  Heterogeneous Deep Learning Models</dc:title>
 <dc:creator>M&#xfc;ller, Dominik</dc:creator>
 <dc:creator>Soto-Rey, I&#xf1;aki</dc:creator>
 <dc:creator>Kramer, Frank</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Preventable or undiagnosed visual impairment and blindness affect billion of
people worldwide. Automated multi-disease detection models offer great
potential to address this problem via clinical decision support in diagnosis.
In this work, we proposed an innovative multi-disease detection pipeline for
retinal imaging which utilizes ensemble learning to combine the predictive
capabilities of several heterogeneous deep convolutional neural network models.
Our pipeline includes state-of-the-art strategies like transfer learning, class
weighting, real-time image augmentation and Focal loss utilization.
Furthermore, we integrated ensemble learning techniques like heterogeneous deep
learning models, bagging via 5-fold cross-validation and stacked logistic
regression models. Through internal and external evaluation, we were able to
validate and demonstrate high accuracy and reliability of our pipeline, as well
as the comparability with other state-of-the-art pipelines for retinal disease
prediction.
</dc:description>
 <dc:description>Comment: Code repository: https://github.com/frankkramer-lab/riadd.aucmedi
  Appendix: https://doi.org/10.5281/zenodo.4573990</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14679</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Platform for Processing Sensitive Data on Shared HPC Systems</dc:title>
 <dc:creator>Scheerman, Michel</dc:creator>
 <dc:creator>Zarrabi, Narges</dc:creator>
 <dc:creator>Kruiten, Martijn</dc:creator>
 <dc:creator>Mog&#xe9;, Maxime</dc:creator>
 <dc:creator>Voort, Lykle</dc:creator>
 <dc:creator>Langedijk, Annette</dc:creator>
 <dc:creator>Schoonhoven, Ruurd</dc:creator>
 <dc:creator>Emery, Tom</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  High performance computing clusters operating in shared and batch mode pose
challenges for processing sensitive data. In the meantime, the need for secure
processing of sensitive data on HPC system is growing. In this work we present
a novel method for creating secure computing environments on traditional
multi-tenant high-performance computing clusters. Our platform as a service
provides a customizable, virtualized solution using PCOCC and SLURM to meet
strict security requirements without modifying the exist-ing HPC
infrastructure. We show how this platform has been used in real-world research
applications from different research domains. The solution is scalable by
design with low performance overhead and can be generalized for processing
sensitive data on shared HPC systems imposing high security criteria
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14679</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14688</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One Algorithm to Evaluate Them All: Unified Linear Algebra Based
  Approach to Evaluate Both Regular and Context-Free Path Queries</dc:title>
 <dc:creator>Shemetova, Ekaterina</dc:creator>
 <dc:creator>Azimov, Rustam</dc:creator>
 <dc:creator>Orachev, Egor</dc:creator>
 <dc:creator>Epelbaum, Ilya</dc:creator>
 <dc:creator>Grigorev, Semyon</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  The Kronecker product-based algorithm for context-free path querying (CFPQ)
was proposed by Orachev et al. (2020). We reduce this algorithm to operations
over Boolean matrices and extend it with the mechanism to extract all paths of
interest. We also prove $O(n^3/\log{n})$ time complexity of the proposed
algorithm, where n is a number of vertices of the input graph. Thus, we provide
the alternative way to construct a slightly subcubic algorithm for CFPQ which
is based on linear algebra and incremental transitive closure (a classic
graph-theoretic problem), as opposed to the algorithm with the same complexity
proposed by Chaudhuri (2008). Our evaluation shows that our algorithm is a good
candidate to be the universal algorithm for both regular and context-free path
querying.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14688</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14689</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Adam-like Optimization Algorithms to Improve the Performance
  of Convolutional Neural Networks</dc:title>
 <dc:creator>Nanni, Loris</dc:creator>
 <dc:creator>Maguolo, Gianluca</dc:creator>
 <dc:creator>Lumini, Alessandra</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Stochastic gradient descent (SGD) is the main approach for training deep
networks: it moves towards the optimum of the cost function by iteratively
updating the parameters of a model in the direction of the gradient of the loss
evaluated on a minibatch. Several variants of SGD have been proposed to make
adaptive step sizes for each parameter (adaptive gradient) and take into
account the previous updates (momentum). Among several alternative of SGD the
most popular are AdaGrad, AdaDelta, RMSProp and Adam which scale coordinates of
the gradient by square roots of some form of averaging of the squared
coordinates in the past gradients and automatically adjust the learning rate on
a parameter basis. In this work, we compare Adam based variants based on the
difference between the present and the past gradients, the step size is
adjusted for each parameter. We run several tests benchmarking proposed methods
using medical image data. The experiments are performed using ResNet50
architecture neural network. Moreover, we have tested ensemble of networks and
the fusion with ResNet50 trained with stochastic gradient descent. To combine
the set of ResNet50 the simple sum rule has been applied. Proposed ensemble
obtains very high performance, it obtains accuracy comparable or better than
actual state of the art. To improve reproducibility and research efficiency the
MATLAB source code used for this research is available at GitHub:
https://github.com/LorisNanni.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14689</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14695</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MultiScope: Efficient Video Pre-processing for Exploratory Video
  Analytics</dc:title>
 <dc:creator>Bastani, Favyen</dc:creator>
 <dc:creator>Madden, Sam</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Performing analytics tasks over large-scale video datasets is increasingly
common in a wide range of applications. These tasks generally involve object
detection and tracking operations that require applying expensive machine
learning models, and several systems have recently been proposed to optimize
the execution of video queries to reduce their cost. However, prior work
generally optimizes execution speed in only one dimension, focusing on one
optimization technique while ignoring other potential avenues for accelerating
execution, thereby delivering an unsatisfactory tradeoff between speed and
accuracy. We propose MultiScope, a general-purpose video pre-processor for
object detection and tracking that explores multiple avenues for optimizing
video queries to extract tracks from video with a superior tradeoff between
speed and accuracy over prior work. We compare MultiScope against three recent
systems on seven diverse datasets, and find that it provides a 2.9x average
speedup over the next best baseline at the same accuracy level.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14696</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BrainPainter v2: Mouse Brain Visualization Software</dc:title>
 <dc:creator>Mallela, Vedvayas</dc:creator>
 <dc:creator>Golland, Polina</dc:creator>
 <dc:creator>Marinescu, Razvan V.</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:description>  BrainPainter is a software for the 3D visualization of human brain
structures; it generates colored brain images using user-defined biomarker data
for each brain region. However, BrainPainter is only able to generate human
brain images. In this paper, we present updates to the existing BrainPainter
software which enables the generation of mouse brain images. We load meshes for
each mouse brain region, based on the Allen Mouse Brain Atlas, into Blender, a
powerful 3D computer graphics engine. We then use Blender to color each region
and generate images of subcortical, outer-cortical, inner-cortical, top and
bottom view renders. In addition to those views, we add new render angles and
separate visualization settings for the left and right hemispheres. While
BrainPainter traditionally ran from the browser (
https://brainpainter.csail.mit.edu ), we also created a graphical user
interface that launches image-generation requests in a user-friendly way, by
connecting to the Blender backend via a Docker API. We illustrate a use case of
BrainPainter for modeling the progression of tau protein accumulation in a
mouse study. Our contributions can help neuroscientists visualize brains in
mouse studies and show disease progression. In addition, integration into
Blender can subsequently enable the generation of complex animations using a
moving camera, generation of complex mesh deformations that simulate tumors and
other pathologies, as well as visualization of toxic proteins using Blender's
particle system.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures, 2 movies (see ancillary files)</dc:description>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14697</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Focused LRP: Explainable AI for Face Morphing Attack Detection</dc:title>
 <dc:creator>Seibold, Clemens</dc:creator>
 <dc:creator>Hilsmann, Anna</dc:creator>
 <dc:creator>Eisert, Peter</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The task of detecting morphed face images has become highly relevant in
recent years to ensure the security of automatic verification systems based on
facial images, e.g. automated border control gates. Detection methods based on
Deep Neural Networks (DNN) have been shown to be very suitable to this end.
However, they do not provide transparency in the decision making and it is not
clear how they distinguish between genuine and morphed face images. This is
particularly relevant for systems intended to assist a human operator, who
should be able to understand the reasoning. In this paper, we tackle this
problem and present Focused Layer-wise Relevance Propagation (FLRP). This
framework explains to a human inspector on a precise pixel level, which image
regions are used by a Deep Neural Network to distinguish between a genuine and
a morphed face image. Additionally, we propose another framework to objectively
analyze the quality of our method and compare FLRP to other DNN
interpretability methods. This evaluation framework is based on removing
detected artifacts and analyzing the influence of these changes on the decision
of the DNN. Especially, if the DNN is uncertain in its decision or even
incorrect, FLRP performs much better in highlighting visible artifacts compared
to other methods.
</dc:description>
 <dc:description>Comment: Published at WACVW 2021</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14697</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14698</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implementing G-Machine in HyperLMNtal</dc:title>
 <dc:creator>Sano, Jin</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Since language processing systems generally allocate/discard memory with
complex reference relationships, including circular and indirect references,
their implementation is often not trivial. Here, the allocated memory and the
references can be abstracted to the labeled vertices and edges of a graph. And
there exists a graph rewriting language, a programming language or a
calculation model that can handle graph intuitively, safely and efficiently.
Therefore, the implementation of a language processing system can be highly
expected as an application field of graph rewriting language. To show this, in
this research, we implemented G-machine, the virtual machine for lazy
evaluation, in hypergraph rewriting language, HyperLMNtal.
</dc:description>
 <dc:date>2021-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14698</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14701</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extending Classic Paxos for High-performance Read-Modify-Write Registers</dc:title>
 <dc:creator>Gavrielatos, Vasilis</dc:creator>
 <dc:creator>Katsarakis, Antonios</dc:creator>
 <dc:creator>Nagarajan, Vijay</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this work we provide a detailed specification of how we extended and
implemented Classic Paxos (CP) to execute Read-Modify-Writes. In addition, we
also specify how we implemented All-aboard Paxos over CP and how we use
carstamps, to also add ABD reads and writes, to accelerate the common case,
where RMWs are not needed. Our specification targets a Key-Value-Store that is
deployed within the datacenter, is replicated across 3 to 7 machines and
supports reads, writes and RMWs.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14701</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14703</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model-Free Optimal Voltage Control via Continuous-Time Zeroth-Order
  Methods</dc:title>
 <dc:creator>Chen, Xin</dc:creator>
 <dc:creator>Poveda, Jorge I.</dc:creator>
 <dc:creator>Li, Na</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  In power distribution systems, the growing penetration of renewable energy
resources brings new challenges to maintaining voltage safety, which is further
complicated by the limited model information of distribution systems. To
address these challenges, we develop a model-free optimal voltage control
algorithm based on projected primal-dual gradient dynamics and continuous-time
zeroth-order method (extreme seeking control). This proposed algorithm i)
operates purely based on voltage measurements and does not require any other
model information, ii) can drive the voltage magnitudes back to the acceptable
range, iii) satisfies the power capacity constraints all the time, iv)
minimizes the total operating cost, and v) is implemented in a decentralized
fashion where the privacy of controllable devices is preserved and
plug-and-play operation is enabled. We prove that the proposed algorithm is
semi-globally practically asymptotically stable and is structurally robust to
measurement noises. Lastly, the performance of the proposed algorithm is
further demonstrated via numerical simulations.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14708</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tuning IR-cut Filter for Illumination-aware Spectral Reconstruction from
  RGB</dc:title>
 <dc:creator>Sun, Bo</dc:creator>
 <dc:creator>Yan, Junchi</dc:creator>
 <dc:creator>Zhou, Xiao</dc:creator>
 <dc:creator>Zheng, Yinqiang</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  To reconstruct spectral signals from multi-channel observations, in
particular trichromatic RGBs, has recently emerged as a promising alternative
to traditional scanning-based spectral imager. It has been proven that the
reconstruction accuracy relies heavily on the spectral response of the RGB
camera in use. To improve accuracy, data-driven algorithms have been proposed
to retrieve the best response curves of existing RGB cameras, or even to design
brand new three-channel response curves. Instead, this paper explores the
filter-array based color imaging mechanism of existing RGB cameras, and
proposes to design the IR-cut filter properly for improved spectral recovery,
which stands out as an in-between solution with better trade-off between
reconstruction accuracy and implementation complexity. We further propose a
deep learning based spectral reconstruction method, which allows to recover the
illumination spectrum as well. Experiment results with both synthetic and real
images under daylight illumination have shown the benefits of our IR-cut filter
tuning method and our illumination-aware spectral reconstruction method.
</dc:description>
 <dc:description>Comment: CVPR 2021 - Oral</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14708</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14709</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Coverage Path Planning of Multi-Robot Teams for Monitoring
  Non-Convex Areas</dc:title>
 <dc:creator>Collins, Leighton</dc:creator>
 <dc:creator>Ghassemi, Payam</dc:creator>
 <dc:creator>Esfahani, Ehsan T.</dc:creator>
 <dc:creator>Doermann, David</dc:creator>
 <dc:creator>Dantu, Karthik</dc:creator>
 <dc:creator>Chowdhury, Souma</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  This paper presents a novel multi-robot coverage path planning (CPP)
algorithm - aka SCoPP - that provides a time-efficient solution, with workload
balanced plans for each robot in a multi-robot system, based on their initial
states. This algorithm accounts for discontinuities (e.g., no-fly zones) in a
specified area of interest, and provides an optimized ordered list of
way-points per robot using a discrete, computationally efficient, nearest
neighbor path planning algorithm. This algorithm involves five main stages,
which include the transformation of the user's input as a set of vertices in
geographical coordinates, discretization, load-balanced partitioning,
auctioning of conflict cells in a discretized space, and a path planning
procedure. To evaluate the effectiveness of the primary algorithm, a
multi-unmanned aerial vehicle (UAV) post-flood assessment application is
considered, and the performance of the algorithm is tested on three test maps
of varying sizes. Additionally, our method is compared with a state-of-the-art
method created by Guasella et al. Further analyses on scalability and
computational time of SCoPP are conducted. The results show that SCoPP is
superior in terms of mission completion time; its computing time is found to be
under 2 mins for a large map covered by a 150-robot team, thereby demonstrating
its computationally scalability.
</dc:description>
 <dc:description>Comment: Accepted for publication in the proceedings of the 2021 IEEE
  International Conference on Robotics and Automation (ICRA)</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14722</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Almost Surely Stable Deep Dynamics</dc:title>
 <dc:creator>Lawrence, Nathan P.</dc:creator>
 <dc:creator>Loewen, Philip D.</dc:creator>
 <dc:creator>Forbes, Michael G.</dc:creator>
 <dc:creator>Backstr&#xf6;m, Johan U.</dc:creator>
 <dc:creator>Gopaluni, R. Bhushan</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We introduce a method for learning provably stable deep neural network based
dynamic models from observed data. Specifically, we consider discrete-time
stochastic dynamic models, as they are of particular interest in practical
applications such as estimation and control. However, these aspects exacerbate
the challenge of guaranteeing stability. Our method works by embedding a
Lyapunov neural network into the dynamic model, thereby inherently satisfying
the stability criterion. To this end, we propose two approaches and apply them
in both the deterministic and stochastic settings: one exploits convexity of
the Lyapunov function, while the other enforces stability through an implicit
output layer. We demonstrate the utility of each approach through numerical
examples.
</dc:description>
 <dc:description>Comment: NeurIPS 2020; Spotlight Paper</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14722</dc:identifier>
 <dc:identifier>Advances in Neural Information Processing Systems, volume 33,
  pages 18942--18953, 2020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14726</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond the adjacency matrix: random line graphs and inference for
  networks with edge attributes</dc:title>
 <dc:creator>Lubberts, Zachary</dc:creator>
 <dc:creator>Athreya, Avanti</dc:creator>
 <dc:creator>Park, Youngser</dc:creator>
 <dc:creator>Priebe, Carey E.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>05C80, 15A52, 62F12</dc:subject>
 <dc:description>  Any modern network inference paradigm must incorporate multiple aspects of
network structure, including information that is often encoded both in vertices
and in edges. Methodology for handling vertex attributes has been developed for
a number of network models, but comparable techniques for edge-related
attributes remain largely unavailable. We address this gap in the literature by
extending the latent position random graph model to the line graph of a random
graph, which is formed by creating a vertex for each edge in the original
random graph, and connecting each pair of edges incident to a common vertex in
the original graph. We prove concentration inequalities for the spectrum of a
line graph, and then establish that although naive spectral decompositions can
fail to extract necessary signal for edge clustering, there exist
signal-preserving singular subspaces of the line graph that can be recovered
through a carefully-chosen projection. Moreover, we can consistently estimate
edge latent positions in a random line graph, even though such graphs are of a
random size, typically have high rank, and possess no spectral gap. Our results
also demonstrate that the line graph of a stochastic block model exhibits
underlying block structure, and we synthesize and test our methods in
simulations for cluster recovery and edge covariate inference in stochastic
block model graphs.
</dc:description>
 <dc:description>Comment: 32 pages, 3 figures</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14726</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14727</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Risk-Averse Stochastic Shortest Path Planning</dc:title>
 <dc:creator>Ahmadi, Mohamadreza</dc:creator>
 <dc:creator>Dixit, Anushri</dc:creator>
 <dc:creator>Burdick, Joel W.</dc:creator>
 <dc:creator>Ames, Aaron D.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We consider the stochastic shortest path planning problem in MDPs, i.e., the
problem of designing policies that ensure reaching a goal state from a given
initial state with minimum accrued cost. In order to account for rare but
important realizations of the system, we consider a nested dynamic coherent
risk total cost functional rather than the conventional risk-neutral total
expected cost. Under some assumptions, we show that optimal, stationary,
Markovian policies exist and can be found via a special Bellman's equation. We
propose a computational technique based on difference convex programs (DCPs) to
find the associated value functions and therefore the risk-averse policies. A
rover navigation MDP is used to illustrate the proposed methodology with
conditional-value-at-risk (CVaR) and entropic-value-at-risk (EVaR) coherent
risk measures.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14727</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14729</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deception in Social Learning</dc:title>
 <dc:creator>Ntemos, Konstantinos</dc:creator>
 <dc:creator>Bordignon, Virginia</dc:creator>
 <dc:creator>Vlaski, Stefan</dc:creator>
 <dc:creator>Sayed, Ali H.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  A common assumption in the social learning literature is that agents exchange
information in an unselfish manner. In this work, we consider the scenario
where a subset of agents aims at deceiving the network, meaning they aim at
driving the network beliefs to the wrong hypothesis. The adversaries are
unaware of the true hypothesis. However, they will &quot;blend in&quot; by behaving
similarly to the other agents and will manipulate the likelihood functions used
in the belief update process to launch inferential attacks. We will
characterize the conditions under which the network is misled. Then, we will
explain that it is possible for such attacks to succeed by showing that
strategies exist that can be adopted by the malicious agents for this purpose.
We examine both situations in which the agents have access to information about
the network model as well as the case in which they do not. For the first case,
we show that there always exists a way to construct fake likelihood functions
such that the network is deceived regardless of the true hypothesis. For the
latter case, we formulate an optimization problem and investigate the
performance of the derived attack strategy by establishing conditions under
which the network is deceived. We illustrate the learning performance of the
network in the aforementioned adversarial setting via simulations. In a
nutshell, we clarify when and how a network is deceived in the context of
non-Bayesian social learning.
</dc:description>
 <dc:description>Comment: 19 pages, 11 figures, submitted for publication</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14729</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14731</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling the Nonsmoothness of Modern Neural Networks</dc:title>
 <dc:creator>Liu, Runze</dc:creator>
 <dc:creator>Wong, Chau-Wai</dc:creator>
 <dc:creator>Dai, Huaiyu</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Modern neural networks have been successful in many regression-based tasks
such as face recognition, facial landmark detection, and image generation. In
this work, we investigate an intuitive but understudied characteristic of
modern neural networks, namely, the nonsmoothness. The experiments using
synthetic data confirm that such operations as ReLU and max pooling in modern
neural networks lead to nonsmoothness. We quantify the nonsmoothness using a
feature named the sum of the magnitude of peaks (SMP) and model the
input-output relationships for building blocks of modern neural networks.
Experimental results confirm that our model can accurately predict the
statistical behaviors of the nonsmoothness as it propagates through such
building blocks as the convolutional layer, the ReLU activation, and the max
pooling layer. We envision that the nonsmoothness feature can potentially be
used as a forensic tool for regression-based applications of neural networks.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14731</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14735</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel $p$-Harmonic Descent Approach Applied to Fluid Dynamic Shape
  Optimization</dc:title>
 <dc:creator>M&#xfc;ller, Peter Marvin</dc:creator>
 <dc:creator>K&#xfc;hl, Niklas</dc:creator>
 <dc:creator>Siebenborn, Martin</dc:creator>
 <dc:creator>Deckelnick, Klaus</dc:creator>
 <dc:creator>Hinze, Michael</dc:creator>
 <dc:creator>Rung, Thomas</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>35Q93, 49Q10, 35R30, 49K20</dc:subject>
 <dc:description>  We introduce a novel method for the implementation of shape optimziation in
fluid dynamics applications, where we propose to use the shape derivative to
determine deformation fields with the help of the $p-$ Laplacian for $p &gt; 2$.
This approach is closely related to the computation of steepest descent
directions of the shape functional in the $W^{1,\infty}-$ topology. Our
approach is demonstrated for shape optimization related to drag-minimal free
floating bodies. The method is validated against existing approaches with
respect to convergence of the optimization algorithm, the obtained shape, and
regarding the quality of the computational grid after large deformations. Our
numerical results strongly indicate that shape optimization related to the
$W^{1,\infty}$-topology -- though numerically more demanding -- seems to be
superior over the classical approaches invoking Hilbert space methods,
concerning the convergence, the obtained shapes and the mesh quality after
large deformations, in particular when the optimal shape features sharp
corners.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14735</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14736</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Construction of a Large-scale Japanese ASR Corpus on TV Recordings</dc:title>
 <dc:creator>Ando, Shintaro</dc:creator>
 <dc:creator>Fujihara, Hiromasa</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  This paper presents a new large-scale Japanese speech corpus for training
automatic speech recognition (ASR) systems. This corpus contains over 2,000
hours of speech with transcripts built on Japanese TV recordings and their
subtitles. We develop herein an iterative workflow to extract matching audio
and subtitle segments from TV recordings based on a conventional method for
lightly-supervised audio-to-text alignment. We evaluate a model trained with
our corpus using an evaluation dataset built on Japanese TEDx presentation
videos and confirm that the performance is better than that trained with the
Corpus of Spontaneous Japanese (CSJ). The experiment results show the
usefulness of our corpus for training ASR systems. This corpus is made public
for the research community along with Kaldi scripts for training the models
reported in this paper.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14736</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14739</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leaky Nets: Recovering Embedded Neural Network Models and Inputs through
  Simple Power and Timing Side-Channels -- Attacks and Defenses</dc:title>
 <dc:creator>Maji, Saurav</dc:creator>
 <dc:creator>Banerjee, Utsav</dc:creator>
 <dc:creator>Chandrakasan, Anantha P.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  With the recent advancements in machine learning theory, many commercial
embedded micro-processors use neural network models for a variety of signal
processing applications. However, their associated side-channel security
vulnerabilities pose a major concern. There have been several proof-of-concept
attacks demonstrating the extraction of their model parameters and input data.
But, many of these attacks involve specific assumptions, have limited
applicability, or pose huge overheads to the attacker. In this work, we study
the side-channel vulnerabilities of embedded neural network implementations by
recovering their parameters using timing-based information leakage and simple
power analysis side-channel attacks. We demonstrate our attacks on popular
micro-controller platforms over networks of different precisions such as
floating point, fixed point, binary networks. We are able to successfully
recover not only the model parameters but also the inputs for the above
networks. Countermeasures against timing-based attacks are implemented and
their overheads are analyzed.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14739</dc:identifier>
 <dc:identifier>IEEE Internet of Things Journal, 2021</dc:identifier>
 <dc:identifier>doi:10.1109/JIOT.2021.3061314.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14741</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Genomic Encryption of Biometric Information for Privacy-Preserving
  Forensics</dc:title>
 <dc:creator>Jung, Taeho</dc:creator>
 <dc:creator>Karl, Ryan</dc:creator>
 <dc:creator>Siwo, Geoffrey H.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:description>  DNA fingerprinting is a cornerstone for human identification in forensics,
where the sequence of highly polymorphic short tandem repeats (STRs) from an
individual is compared against a DNA database. This presents significant
privacy risks to individuals with DNA profiles in the database due to hacking
by malicious attackers who may access the data and misuse it for secondary
purposes. In this paper, we propose a novel cryptographic framework for jointly
encrypting DNA-based fingerprints (STRs) with other biometric data, for
example, facial images, such that the STRs and biometrics information of an
individual are revealed only when a positive match is found, i.e. the STRs act
as decryption keys. Specifically, when a search is performed on the encrypted
database using STR sequences of an individual in the database, a perfect match
generates the facial image and/ or other biometrics of the individual while the
lack of a match returns a null result. By jointly encrypting DNA fingerprints
and other biometrics using the unique STRs generated keys, our approach ensures
perfect privacy of the encrypted information with decryption of only the record
with STRs matching the query. This safeguards the information of other
individuals in the same database. The proposed approach can also be used to
securely authenticate the identity of individuals or biological material in
scenarios beyond forensics including tracking the identity of samples for
clinical genetics and cell therapies.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14741</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14748</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysing the Effect of Recommendation Algorithms on the Amplification
  of Misinformation</dc:title>
 <dc:creator>Fern&#xe1;ndez, Miriam</dc:creator>
 <dc:creator>Bellog&#xed;n, Alejandro</dc:creator>
 <dc:creator>Cantador, Iv&#xe1;n</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Recommendation algorithms have been pointed out as one of the major culprits
of misinformation spreading in the digital sphere. However, it is still unclear
how these algorithms really propagate misinformation, e.g., it has not been
shown which particular recommendation approaches are more prone to suggest
misinforming items, or which internal parameters of the algorithms could be
influencing more on their misinformation propagation capacity.
  Motivated by this fact, in this paper we present an analysis of the effect of
some of the most popular recommendation algorithms on the spread of
misinformation in Twitter. A set of guidelines on how to adapt these algorithms
is provided based on such analysis and a comprehensive review of the research
literature. A dataset is also generated and released to the scientific
community to stimulate discussions on the future design and development of
recommendation algorithms to counter misinformation. The dataset includes
editorially labelled news items and claims regarding their misinformation
nature.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14748</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14761</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Augmenting Text Mining Approaches with Social Network Analysis to
  Understand the Complex Relationships among Users' Requests: a Case Study of
  the Android Operating System</dc:title>
 <dc:creator>Lee, Chan Won</dc:creator>
 <dc:creator>Licorish, Sherlock A.</dc:creator>
 <dc:creator>Savarimuthu, Bastin Tony Roy</dc:creator>
 <dc:creator>MacDonell, Stephen G.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Text mining approaches are being used increasingly for business analytics. In
particular, such approaches are now central to understanding users' feedback
regarding systems delivered via online application distribution platforms such
as Google Play. In such settings, large volumes of reviews of potentially
numerous apps and systems means that it is infeasible to use manual mechanisms
to extract insights and knowledge that could inform product improvement. In
this context of identifying software system improvement options, text mining
techniques are used to reveal the features that are mentioned most often as
being in need of correction (e.g., GPS), and topics that are associated with
features perceived as being defective (e.g., inaccuracy of GPS). Other
approaches may supplement such techniques to provide further insights for
online communities and solution providers. In this work we augment text mining
approaches with social network analysis to demonstrate the utility of using
multiple techniques. Our outcomes suggest that text mining approaches may
indeed be supplemented with other methods to deliver a broader range of
insights.
</dc:description>
 <dc:description>Comment: Conference paper, 9 pages, 2 figures, 5 tables</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14761</dc:identifier>
 <dc:identifier>Proceedings of the 49th Hawaii International Conference on System
  Sciences (HICSS2016). Koloa HI, USA, AIS, pp.1144-1153</dc:identifier>
 <dc:identifier>doi:10.1109/HICSS.2016.145</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14774</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Generalized Multivariable Newton Method</dc:title>
 <dc:creator>Burachik, Regina S.</dc:creator>
 <dc:creator>Caldwell, Bethany I.</dc:creator>
 <dc:creator>Kaya, C. Yal&#xe7;&#x131;n</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>49M15, 65H04, 65H10</dc:subject>
 <dc:description>  It is well known that the Newton method may not converge when the initial
guess does not belong to a specific quadratic convergence region. We propose a
family of new variants of the Newton method with the potential advantage of
having a larger convergence region as well as more desirable properties near a
solution. We prove quadratic convergence of the new family, and provide
specific bounds for the asymptotic error constant. We illustrate the advantages
of the new methods by means of test problems, including two and six variable
polynomial systems, as well as a challenging signal processing example. We
present a numerical experimental methodology which uses a large number of
randomized initial guesses for a number of methods from the new family, in turn
providing advice as to which of the methods employed is preferable to use in a
particular search domain.
</dc:description>
 <dc:description>Comment: 29 pages, 4 figures, 19 tables</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14774</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14781</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An empirical study into the relationship between class features and test
  smells</dc:title>
 <dc:creator>Tahir, Amjed</dc:creator>
 <dc:creator>Counsell, Steve</dc:creator>
 <dc:creator>MacDonell, Stephen G.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  While a substantial body of prior research has investigated the form and
nature of production code, comparatively little attention has examined
characteristics of test code, and, in particular, test smells in that code. In
this paper, we explore the relationship between production code properties (at
the class level) and a set of test smells, in five open source systems.
Specifically, we examine whether complexity properties of a production class
can be used as predictors of the presence of test smells in the associated unit
test. Our results, derived from the analysis of 975 production class-unit test
pairs, show that the Cyclomatic Complexity (CC) and Weighted Methods per Class
(WMC) of production classes are strong indicators of the presence of smells in
their associated unit tests. The Lack of Cohesion of Methods in a production
class (LCOM) also appears to be a good indicator of the presence of test
smells. Perhaps more importantly, all three metrics appear to be good
indicators of particular test smells, especially Eager Test and Duplicated
Code. The Depth of the Inheritance Tree (DIT), on the other hand, was not found
to be significantly related to the incidence of test smells. The results have
important implications for large-scale software development, particularly in a
context where organizations are increasingly using, adopting or adapting open
source code as part of their development strategy and need to ensure that
classes and methods are kept as simple as possible.
</dc:description>
 <dc:description>Comment: Conference paper, 9 pages, 4 figures, 6 tables</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14781</dc:identifier>
 <dc:identifier>Proceedings of the 23rd Asia-Pacific Software Engineering
  Conference (APSEC2016). Hamilton, New Zealand, IEEE, pp.137-144</dc:identifier>
 <dc:identifier>doi:10.1109/APSEC.2016.34</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14783</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Synergistic Approach to Digital Privacy</dc:title>
 <dc:creator>Gorog, Christopher</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This paper outlines an approach for IEEE to take leadership for digital
privacy to align many existing IEEE Societies and efforts in the areas of
computer systems &amp; applications security, organizational &amp; global
architectures, policy-supporting legislation, originating new standards,
integrating compliance into technologies, and helping design decision-board
infrastructures for governance bodies. Much of the current emphasis on evolving
privacy technologies centers on big corporate enterprises and institutions,
causing the industry to support corporate assets protection mainly. Fostering
technology to empower individual privacy-enabling tools has lagged, and
personal privacy has diminished because corporate big data applications have
made sizable investments into exploiting private data. As one of the largest
individual-member-based organizations, IEEE is urged to develop a collaborative
approach for digital privacy with privacy-enabling technologies to benefit its
members. The recommendations outlined define a prospective course that could
result in future global individualized privacy capabilities which employ a
combination of synergistic technologies such as distributed ledgers,
differential privacy, homomorphic encryption, secure distributed multi-party
computation, zero-trust architectures, proof-of-origin of data, software, or
other techniques. Such an effort would involve community engagement and
outreach, academic peer-review events, the establishment of governance bodies,
coordination &amp; expansion of existing standards, and the development of
publicly-accessible prototypes. Collaboration with other IEEE-sponsored efforts
for transactive energy systems, confidentiality and security of healthcare
records and devices, and other IEEE-funded projects will help magnify digital
privacy investments already in progress in these applications of emerging
technologies.
</dc:description>
 <dc:description>Comment: This paper has been produced at the request of the IEEE Future
  Directions Committee as a response to a call for expertise on evolving
  privacy empowering technology</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14783</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14792</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Eye-tracking Data to Predict Situation Awareness in Real Time
  during Takeover Transitions in Conditionally Automated Driving</dc:title>
 <dc:creator>Zhou, Feng</dc:creator>
 <dc:creator>Yang, X. Jessie</dc:creator>
 <dc:creator>de Winter, Joost</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Situation awareness (SA) is critical to improving takeover performance during
the transition period from automated driving to manual driving. Although many
studies measured SA during or after the driving task, few studies have
attempted to predict SA in real time in automated driving. In this work, we
propose to predict SA during the takeover transition period in conditionally
automated driving using eye-tracking and self-reported data. First, a tree
ensemble machine learning model, named LightGBM (Light Gradient Boosting
Machine), was used to predict SA. Second, in order to understand what factors
influenced SA and how, SHAP (SHapley Additive exPlanations) values of
individual predictor variables in the LightGBM model were calculated. These
SHAP values explained the prediction model by identifying the most important
factors and their effects on SA, which further improved the model performance
of LightGBM through feature selection. We standardized SA between 0 and 1 by
aggregating three performance measures (i.e., placement, distance, and speed
estimation of vehicles with regard to the ego-vehicle) of SA in recreating
simulated driving scenarios, after 33 participants viewed 32 videos with six
lengths between 1 and 20 s. Using only eye-tracking data, our proposed model
outperformed other selected machine learning models, having a root-mean-squared
error (RMSE) of 0.121, a mean absolute error (MAE) of 0.096, and a 0.719
correlation coefficient between the predicted SA and the ground truth. The code
is available at https://github.com/refengchou/Situation-awareness-prediction.
Our proposed model provided important implications on how to monitor and
predict SA in real time in automated driving using eye-tracking data.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14793</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CalibDNN: Multimodal Sensor Calibration for Perception Using Deep Neural
  Networks</dc:title>
 <dc:creator>Zhao, Ganning</dc:creator>
 <dc:creator>Hu, Jiesi</dc:creator>
 <dc:creator>You, Suya</dc:creator>
 <dc:creator>Kuo, C. -C. Jay</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Current perception systems often carry multimodal imagers and sensors such as
2D cameras and 3D LiDAR sensors. To fuse and utilize the data for downstream
perception tasks, robust and accurate calibration of the multimodal sensor data
is essential. We propose a novel deep learning-driven technique (CalibDNN) for
accurate calibration among multimodal sensor, specifically LiDAR-Camera pairs.
The key innovation of the proposed work is that it does not require any
specific calibration targets or hardware assistants, and the entire processing
is fully automatic with a single model and single iteration. Results comparison
among different methods and extensive experiments on different datasets
demonstrates the state-of-the-art performance.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14794</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Efficient Photometric Feature Transform for Multi-view Stereo</dc:title>
 <dc:creator>Kang, Kaizhang</dc:creator>
 <dc:creator>Xie, Cihui</dc:creator>
 <dc:creator>Zhu, Ruisheng</dc:creator>
 <dc:creator>Ma, Xiaohe</dc:creator>
 <dc:creator>Tan, Ping</dc:creator>
 <dc:creator>Wu, Hongzhi</dc:creator>
 <dc:creator>Zhou, Kun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We present a novel framework to learn to convert the perpixel photometric
information at each view into spatially distinctive and view-invariant
low-level features, which can be plugged into existing multi-view stereo
pipeline for enhanced 3D reconstruction. Both the illumination conditions
during acquisition and the subsequent per-pixel feature transform can be
jointly optimized in a differentiable fashion. Our framework automatically
adapts to and makes efficient use of the geometric information available in
different forms of input data. High-quality 3D reconstructions of a variety of
challenging objects are demonstrated on the data captured with an illumination
multiplexing device, as well as a point light. Our results compare favorably
with state-of-the-art techniques.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14795</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ensemble-in-One: Learning Ensemble within Random Gated Networks for
  Enhanced Adversarial Robustness</dc:title>
 <dc:creator>Cai, Yi</dc:creator>
 <dc:creator>Ning, Xuefei</dc:creator>
 <dc:creator>Yang, Huazhong</dc:creator>
 <dc:creator>Wang, Yu</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Adversarial attacks have rendered high security risks on modern deep learning
systems. Adversarial training can significantly enhance the robustness of
neural network models by suppressing the non-robust features. However, the
models often suffer from significant accuracy loss on clean data. Ensemble
training methods have emerged as promising solutions for defending against
adversarial attacks by diversifying the vulnerabilities among the sub-models,
simultaneously maintaining comparable accuracy as standard training. However,
existing ensemble methods are with poor scalability, owing to the rapid
complexity increase when including more sub-models in the ensemble. Moreover,
in real-world applications, it is difficult to deploy an ensemble with multiple
sub-models, owing to the tight hardware resource budget and latency
requirement. In this work, we propose ensemble-in-one (EIO), a simple but
efficient way to train an ensemble within one random gated network (RGN). EIO
augments the original model by replacing the parameterized layers with
multi-path random gated blocks (RGBs) to construct a RGN. By diversifying the
vulnerability of the numerous paths within the RGN, better robustness can be
achieved. It provides high scalability because the paths within an EIO network
exponentially increase with the network depth. Our experiments demonstrate that
EIO consistently outperforms previous ensemble training methods with even less
computational overhead.
</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14795</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14805</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Robot Distributed Semantic Mapping in Unfamiliar Environments
  through Online Matching of Learned Representations</dc:title>
 <dc:creator>Jamieson, Stewart</dc:creator>
 <dc:creator>Fathian, Kaveh</dc:creator>
 <dc:creator>Khosoussi, Kasra</dc:creator>
 <dc:creator>How, Jonathan P.</dc:creator>
 <dc:creator>Girdhar, Yogesh</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  We present a solution to multi-robot distributed semantic mapping of novel
and unfamiliar environments. Most state-of-the-art semantic mapping systems are
based on supervised learning algorithms that cannot classify novel observations
online. While unsupervised learning algorithms can invent labels for novel
observations, approaches to detect when multiple robots have independently
developed their own labels for the same new class are prone to erroneous or
inconsistent matches. These issues worsen as the number of robots in the system
increases and prevent fusing the local maps produced by each robot into a
consistent global map, which is crucial for cooperative planning and joint
mission summarization. Our proposed solution overcomes these obstacles by
having each robot learn an unsupervised semantic scene model online and use a
multiway matching algorithm to identify consistent sets of matches between
learned semantic labels belonging to different robots. Compared to the state of
the art, the proposed solution produces 20-60% higher quality global maps that
do not degrade even as many more local maps are fused.
</dc:description>
 <dc:description>Comment: 7 pages, 6 figures, 1 table; accepted for presentation in IEEE Int.
  Conf. on Robotics and Automation, ICRA '21, Xi'an, China, June 2021</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14805</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14807</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Introduction to Robust Graph Convolutional Networks</dc:title>
 <dc:creator>Najafi, Mehrnaz</dc:creator>
 <dc:creator>Yu, Philip S.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Graph convolutional neural networks (GCNs) generalize tradition convolutional
neural networks (CNNs) from low-dimensional regular graphs (e.g., image) to
high dimensional irregular graphs (e.g., text documents on word embeddings).
Due to inevitable faulty data collection instruments, deceptive data
manipulation, or other system errors, the data might be error-contaminated.
Even a small amount of error such as noise can compromise the ability of GCNs
and render them inadmissible to a large extent. The key challenge is how to
effectively and efficiently employ GCNs in the presence of erroneous data. In
this paper, we propose a novel Robust Graph Convolutional Neural Networks for
possible erroneous single-view or multi-view data where data may come from
multiple sources. By incorporating an extra layers via Autoencoders into
traditional graph convolutional networks, we characterize and handle typical
error models explicitly. Experimental results on various real-world datasets
demonstrate the superiority of the proposed model over the baseline methods and
its robustness against different types of error.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14808</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reducing Load Latency with Cache Level Prediction</dc:title>
 <dc:creator>Jalili, Majid</dc:creator>
 <dc:creator>Erez, Mattan</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  High load latency that results from deep cache hierarchies and relatively
slow main memory is an important limiter of single-thread performance. Data
prefetch helps reduce this latency by fetching data up the hierarchy before it
is requested by load instructions. However, data prefetching has shown to be
imperfect in many situations. We propose cache-level prediction to complement
prefetchers. Our method predicts which memory hierarchy level a load will
access allowing the memory loads to start earlier, and thereby saves many
cycles. The predictor provides high prediction accuracy at the cost of just one
cycle added latency to L1 misses. Experimental results show speedup of 7.8\% on
generic, graph, and HPC applications over a baseline with aggressive
prefetchers.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14808</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14811</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SelfGait: A Spatiotemporal Representation Learning Method for
  Self-supervised Gait Recognition</dc:title>
 <dc:creator>Liu, Yiqun</dc:creator>
 <dc:creator>Zeng, Yi</dc:creator>
 <dc:creator>Pu, Jian</dc:creator>
 <dc:creator>Shan, Hongming</dc:creator>
 <dc:creator>He, Peiyang</dc:creator>
 <dc:creator>Zhang, Junping</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Gait recognition plays a vital role in human identification since gait is a
unique biometric feature that can be perceived at a distance. Although existing
gait recognition methods can learn gait features from gait sequences in
different ways, the performance of gait recognition suffers from insufficient
labeled data, especially in some practical scenarios associated with short gait
sequences or various clothing styles. It is unpractical to label the numerous
gait data. In this work, we propose a self-supervised gait recognition method,
termed SelfGait, which takes advantage of the massive, diverse, unlabeled gait
data as a pre-training process to improve the representation abilities of
spatiotemporal backbones. Specifically, we employ the horizontal pyramid
mapping (HPM) and micro-motion template builder (MTB) as our spatiotemporal
backbones to capture the multi-scale spatiotemporal representations.
Experiments on CASIA-B and OU-MVLP benchmark gait datasets demonstrate the
effectiveness of the proposed SelfGait compared with four state-of-the-art gait
recognition methods. The source code has been released at
https://github.com/EchoItLiu/SelfGait.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14819</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Backup Plan Constrained Model Predictive Control</dc:title>
 <dc:creator>Kim, Hunmin</dc:creator>
 <dc:creator>Yoon, Hyungjin</dc:creator>
 <dc:creator>Wan, Wenbin</dc:creator>
 <dc:creator>Hovakimyan, Naira</dc:creator>
 <dc:creator>Sha, Lui</dc:creator>
 <dc:creator>Voulgaris, Petros</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This article proposes a new safety concept: backup plan safety. The backup
plan safety is defined as the ability to complete one of the alternative
missions in the case of primary mission abortion. To incorporate this new
safety concept in control problems, we formulate a feasibility maximization
problem that adopts additional (virtual) input horizons toward the alternative
missions on top of the input horizon toward the primary mission. Cost functions
for the primary and alternative missions construct multiple objectives, and
multi-horizon inputs evaluate them. To address the feasibility maximization
problem, we develop a multi-horizon multi-objective model predictive path
integral control (3M) algorithm. Model predictive path integral control (MPPI)
is a sampling-based scheme that can help the proposed algorithm deal with
nonlinear dynamic systems and achieve computational efficiency by parallel
computation. Simulations of the aerial vehicle and ground vehicle control
problems demonstrate the new concept of backup plan safety and the performance
of the proposed algorithm.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14821</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Self-Learning Disturbance Observer for Nonlinear Systems in
  Feedback-Error Learning Scheme</dc:title>
 <dc:creator>Kayacan, Erkan</dc:creator>
 <dc:creator>Peschel, Joshua M.</dc:creator>
 <dc:creator>Chowdhary, Girish</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper represents a novel online self-learning disturbance observer
(SLDO) by benefiting from the combination of a type-2 neuro-fuzzy structure
(T2NFS), feedback-error learning scheme and sliding mode control (SMC) theory.
The SLDO is developed within a framework of feedback-error learning scheme in
which a conventional estimation law and a T2NFS work in parallel. In this
scheme, the latter learns uncertainties and becomes the leading estimator
whereas the former provides the learning error to the T2NFS for learning system
dynamics. A learning algorithm established on SMC theory is derived for an
interval type-2 fuzzy logic system. In addition to the stability of the
learning algorithm, the stability of the SLDO and the stability of the overall
system are proven in the presence of time-varying disturbances. Thanks to
learning process by the T2NFS, the simulation results show that the SLDO is
able to estimate time-varying disturbances precisely as distinct from the basic
nonlinear disturbance observer (BNDO) so that the controller based on the SLDO
ensures robust control performance for systems with time-varying uncertainties,
and maintains nominal performance in the absence of uncertainties.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:2103.11292</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14821</dc:identifier>
 <dc:identifier>Engineering Applications of Artificial Intelligence, vol. 62, pp.
  276-285, 2017</dc:identifier>
 <dc:identifier>doi:10.1016/j.engappai.2017.04.013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14824</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Model Robustness by Adaptively Correcting Perturbation Levels
  with Active Queries</dc:title>
 <dc:creator>Ning, Kun-Peng</dc:creator>
 <dc:creator>Tao, Lue</dc:creator>
 <dc:creator>Chen, Songcan</dc:creator>
 <dc:creator>Huang, Sheng-Jun</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In addition to high accuracy, robustness is becoming increasingly important
for machine learning models in various applications. Recently, much research
has been devoted to improving the model robustness by training with noise
perturbations. Most existing studies assume a fixed perturbation level for all
training examples, which however hardly holds in real tasks. In fact, excessive
perturbations may destroy the discriminative content of an example, while
deficient perturbations may fail to provide helpful information for improving
the robustness. Motivated by this observation, we propose to adaptively adjust
the perturbation levels for each example in the training process. Specifically,
a novel active learning framework is proposed to allow the model to
interactively query the correct perturbation level from human experts. By
designing a cost-effective sampling strategy along with a new query type, the
robustness can be significantly improved with a few queries. Both theoretical
analysis and experimental studies validate the effectiveness of the proposed
approach.
</dc:description>
 <dc:description>Comment: To be published in AAAI-21</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14824</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14826</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compact 3D Map-Based Monocular Localization Using Semantic Edge
  Alignment</dc:title>
 <dc:creator>Qiu, Kejie</dc:creator>
 <dc:creator>Chen, Shenzhou</dc:creator>
 <dc:creator>Zhang, Jiahui</dc:creator>
 <dc:creator>Huang, Rui</dc:creator>
 <dc:creator>Cui, Le</dc:creator>
 <dc:creator>Zhu, Siyu</dc:creator>
 <dc:creator>Tan, Ping</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Accurate localization is fundamental to a variety of applications, such as
navigation, robotics, autonomous driving, and Augmented Reality (AR). Different
from incremental localization, global localization has no drift caused by error
accumulation, which is desired in many application scenarios. In addition to
GPS used in the open air, 3D maps are also widely used as alternative global
localization references. In this paper, we propose a compact 3D map-based
global localization system using a low-cost monocular camera and an IMU
(Inertial Measurement Unit). The proposed compact map consists of two types of
simplified elements with multiple semantic labels, which is well adaptive to
various man-made environments like urban environments. Also, semantic edge
features are used for the key image-map registration, which is robust against
occlusion and long-term appearance changes in the environments. To further
improve the localization performance, the key semantic edge alignment is
formulated as an optimization problem based on initial poses predicted by an
independent VIO (Visual-Inertial Odometry) module. The localization system is
realized with modular design in real time. We evaluate the localization
accuracy through real-world experimental results compared with ground truth,
long-term localization performance is also demonstrated.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14826</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14830</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimum directed information: A design principle for compliant robots</dc:title>
 <dc:creator>Haninger, Kevin</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  A robot's dynamics -- especially the degree and location of compliance -- can
significantly affect performance and control complexity. Passive dynamics can
be designed with good regions of attraction or limit cycles for a specific
task, but achieving flexibility on a range of tasks requires co-design of
control. This paper takes an information perspective: the robot dynamics should
reduce the amount of information required for a controller to achieve a
threshold of performance in a range of tasks. Towards this goal, an iterative
method is proposed to minimize the directed information from state to control
on discrete-time nonlinear systems. iLQG is used to find a controller and value
of information, then the design parameters of the dynamics (e.g. stiffness of
end-effector or joint) are optimized to reduce directed information while
maintaining a minimum bound on performance. The approach is validated in
simulation, on a two-mass system in contact with an uncertain wall position and
a high-DOF door opening task, and shown to improve noise robustness and reduce
time variance of control gains.
</dc:description>
 <dc:description>Comment: To be presented, ICRA 2021. Code at
  https://github.com/khaninger/info_min</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14830</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14833</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Determination of weight coefficients for additive fitness function of
  genetic algorithm</dc:title>
 <dc:creator>Ivanov, V. K.</dc:creator>
 <dc:creator>Dumina, D. S.</dc:creator>
 <dc:creator>Semenov, N. A.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The paper presents a solution for the problem of choosing a method for
analytical determining of weight factors for a genetic algorithm additive
fitness function. This algorithm is the basis for an evolutionary process,
which forms a stable and effective query population in a search engine to
obtain highly relevant results. The paper gives a formal description of an
algorithm fitness function, which is a weighted sum of three heterogeneous
criteria. The selected methods for analytical determining of weight factors are
described in detail. It is noted that expert assessment methods are impossible
to use. The authors present a research methodology using the experimental
results from earlier in the discussed project &quot;Data Warehouse Support on the
Base Intellectual Web Crawler and Evolutionary Model for Target Information
Selection&quot;. There is a description of an initial dataset with data ranges for
calculating weights. The calculation order is illustrated by examples. The
research results in graphical form demonstrate the fitness function behavior
during the genetic algorithm operation using various weighting options.
</dc:description>
 <dc:description>Comment: 9 pages, in Russian</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14833</dc:identifier>
 <dc:identifier>Software &amp; Systems 2020, vol. 33, no. 1</dc:identifier>
 <dc:identifier>doi:10.15827/0236-235X.129.047-053</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14837</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Peculiarities of organization of data storage based on intelligent
  search agent and evolutionary model selection the target information</dc:title>
 <dc:creator>Ivanov, V. K.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The article presents a systematic review of the results of the development of
the theoretical basis and the pilot implementation of data storage technology
with automatic replenishment of data from sources belonging to different
thematic segments. It is expected that the repository will contain information
about objects with significant innovative potential. The mechanism of selection
of such information is based on the determination of its semantic relevance to
the generated search queries. At the same time, a quantitative assessment of
the innovation of objects, in particular their technological novelty and demand
is given. The article describes the accepted indicators of innovation,
discusses the application of the theory of evidence for the processing of
incomplete and fuzzy information, identifies the main ideas of the method of
processing the results of measurements for the calculation of the probabilistic
value of the components of innovation, briefly describes the application of the
evolutionary approach in the formation of the linguistic model of the archetype
of the object, provides information about the experimental verification of the
adequacy of the developed computational model. The research results that are
described in the article can be used for business planning, forecasting of
technological development, information support of investment projects
expertise.
</dc:description>
 <dc:description>Comment: 12 pages, in Russian</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14837</dc:identifier>
 <dc:identifier>Bulletin of the Tver State Technical University. Series
  &quot;Engineering Sciences&quot;. 2019. N 1 (1)</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14838</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Teaching Information Security Management Using an Incident of
  Intellectual Property Leakage</dc:title>
 <dc:creator>Ahmad, Atif</dc:creator>
 <dc:creator>Maynard, Sean B.</dc:creator>
 <dc:creator>Motahhir, Sameen</dc:creator>
 <dc:creator>Alshaikh, Moneer</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Case-based learning is a powerful pedagogical method of creating dialogue
between theory and practice. CBL is particularly suited to executive learning
as it instigates critical discussion and draws out relevant experiences. In
this paper we used a real-world case to teach Information Security Management
to students in Management Information Systems. The real-world case is described
in a legal indictment, T-mobile USA Inc v Huawei Device USA Inc. and Huawei
Technologies Co. LTD, alleging theft of intellectual property and breaches of
contract concerning confidentiality and disclosure of sensitive information.
The incident scenario is interesting as it relates to a business asset that has
both digital and physical components that has been compromised through an
unconventional cyber-physical attack facilitated by insiders. The scenario
sparked an interesting debate among students about the scope and definition of
security incidents, the role and structure of the security unit, the utility of
compliance-based approaches to security, and the inadequate use of threat
intelligence in modern security strategies.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14838</dc:identifier>
 <dc:identifier>Australasian Conference on Information Systems, Wellington, 2020,
  pp. 1-11</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14839</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Teaching Information Security Management in Postgraduate Tertiary
  Education: The Case of Horizon Automotive Industries</dc:title>
 <dc:creator>Ahmad, Atif</dc:creator>
 <dc:creator>Maynard, Sean B.</dc:creator>
 <dc:creator>Motahhir, Sameen</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Teaching cases based on stories about real organizations are a powerful means
of storytelling. These cases closely parallel real-world situations and can
deliver on pedagogical objectives as writers can use their creative license to
craft a storyline that better focuses on the specific principles, concepts, and
challenges they want to address in their teaching. The method instigates
critical discussion, draws out relevant experiences from students, encourages
questioning of accepted practices, and creates dialogue between theory and
practice. We present Horizon, a case study of a firm that suffers a
catastrophic incident of Intellectual Property (IP) theft. The case study was
developed to teach information security management (ISM) principles in key
areas such as strategy, risk, policy and training to postgraduate Information
Systems and Information Technology students at the University of Melbourne,
Australia.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14839</dc:identifier>
 <dc:identifier>Australasian Conference on Information Systems, Wellington, 2020,
  pp. 1-12</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14843</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Synthetic to Real: Unsupervised Domain Adaptation for Animal Pose
  Estimation</dc:title>
 <dc:creator>Li, Chen</dc:creator>
 <dc:creator>Lee, Gim Hee</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Animal pose estimation is an important field that has received increasing
attention in the recent years. The main challenge for this task is the lack of
labeled data. Existing works circumvent this problem with pseudo labels
generated from data of other easily accessible domains such as synthetic data.
However, these pseudo labels are noisy even with consistency check or
confidence-based filtering due to the domain shift in the data. To solve this
problem, we design a multi-scale domain adaptation module (MDAM) to reduce the
domain gap between the synthetic and real data. We further introduce an online
coarse-to-fine pseudo label updating strategy. Specifically, we propose a
self-distillation module in an inner coarse-update loop and a mean-teacher in
an outer fine-update loop to generate new pseudo labels that gradually replace
the old ones. Consequently, our model is able to learn from the old pseudo
labels at the early stage, and gradually switch to the new pseudo labels to
prevent overfitting in the later stage. We evaluate our approach on the TigDog
and VisDA 2019 datasets, where we outperform existing approaches by a large
margin. We also demonstrate the generalization ability of our model by testing
extensively on both unseen domains and unseen animal categories. Our code is
available at the project website.
</dc:description>
 <dc:description>Comment: CVPR2021</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14843</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14845</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Ensemble Collaborative Learning by using Knowledge-transfer Graph
  for Fine-grained Object Classification</dc:title>
 <dc:creator>Okamoto, Naoki</dc:creator>
 <dc:creator>Minami, Soma</dc:creator>
 <dc:creator>Hirakawa, Tsubasa</dc:creator>
 <dc:creator>Yamashita, Takayoshi</dc:creator>
 <dc:creator>Fujiyoshi, Hironobu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Mutual learning, in which multiple networks learn by sharing their knowledge,
improves the performance of each network. However, the performance of ensembles
of networks that have undergone mutual learning does not improve significantly
from that of normal ensembles without mutual learning, even though the
performance of each network has improved significantly. This may be due to the
relationship between the knowledge in mutual learning and the individuality of
the networks in the ensemble. In this study, we propose an ensemble method
using knowledge transfer to improve the accuracy of ensembles by introducing a
loss design that promotes diversity among networks in mutual learning. We use
an attention map as knowledge, which represents the probability distribution
and information in the middle layer of a network. There are many ways to
combine networks and loss designs for knowledge transfer methods. Therefore, we
use the automatic optimization of knowledge-transfer graphs to consider a
variety of knowledge-transfer methods by graphically representing conventional
mutual-learning and distillation methods and optimizing each element through
hyperparameter search. The proposed method consists of a mechanism for
constructing an ensemble in a knowledge-transfer graph, attention loss, and a
loss design that promotes diversity among networks. We explore optimal ensemble
learning by optimizing a knowledge-transfer graph to maximize ensemble
accuracy. From exploration of graphs and evaluation experiments using the
datasets of Stanford Dogs, Stanford Cars, and CUB-200-2011, we confirm that the
proposed method is more accurate than a conventional ensemble method.
</dc:description>
 <dc:description>Comment: 10 pages, 8 figures</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14845</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14846</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AR Mapping: Accurate and Efficient Mapping for Augmented Reality</dc:title>
 <dc:creator>Huang, Rui</dc:creator>
 <dc:creator>Fang, Chuan</dc:creator>
 <dc:creator>Qiu, Kejie</dc:creator>
 <dc:creator>Cui, Le</dc:creator>
 <dc:creator>Dong, Zilong</dc:creator>
 <dc:creator>Zhu, Siyu</dc:creator>
 <dc:creator>Tan, Ping</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Augmented reality (AR) has gained increasingly attention from both research
and industry communities. By overlaying digital information and content onto
the physical world, AR enables users to experience the world in a more
informative and efficient manner. As a major building block for AR systems,
localization aims at determining the device's pose from a pre-built &quot;map&quot;
consisting of visual and depth information in a known environment. While the
localization problem has been widely studied in the literature, the &quot;map&quot; for
AR systems is rarely discussed. In this paper, we introduce the AR Map for a
specific scene to be composed of 1) color images with 6-DOF poses; 2) dense
depth maps for each image and 3) a complete point cloud map. We then propose an
efficient end-to-end solution to generating and evaluating AR Maps. Firstly,
for efficient data capture, a backpack scanning device is presented with a
unified calibration pipeline. Secondly, we propose an AR mapping pipeline which
takes the input from the scanning device and produces accurate AR Maps.
Finally, we present an approach to evaluating the accuracy of AR Maps with the
help of the highly accurate reconstruction result from a high-end laser
scanner. To the best of our knowledge, it is the first time to present an
end-to-end solution to efficient and accurate mapping for AR applications.
</dc:description>
 <dc:description>Comment: 8 pages, 14 figures</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14846</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14848</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the effect of boundary conditions on the scalability of Schwarz
  methods</dc:title>
 <dc:creator>Ciaramella, Gabriele</dc:creator>
 <dc:creator>Mechelli, Luca</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  In contrast with classical Schwarz theory, recent results have shown that for
special domain geometries, one-level Schwarz methods can be scalable. This
property has been proved for the Laplace equation and external Dirichlet
boundary conditions. Much less is known if mixed boundary conditions are
considered. This short manuscript focuses on the convergence and scalability
analysis of one-level parallel Schwarz method and optimized Schwarz method for
several different external configurations of boundary conditions, i.e., mixed
Dirichlet, Neumann and Robin conditions.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14849</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An overlapping waveform-relaxation preconditioner for economic optimal
  control problems with state constraints</dc:title>
 <dc:creator>Ciaramella, Gabriele</dc:creator>
 <dc:creator>Mechelli, Luca</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  In this work, a class of parabolic economic optimal control problems is
considered. These problems are characterized by pointwise state constraints
regularized by a parameter, which transforms the pure state constraints in
mixed control-state ones. However, the convergence of classical (semismooth)
Newton methods deteriorates for decreasing values of the regularization
parameter. To tackle this problem, a nonlinear preconditioner is introduced.
This is based on an overlapping optimized waveform-relaxation method
characterized by Robin transmission conditions. Numerical experiments show that
appropriate choices of the overlap and of the Robin parameter lead to a
preconditioned Newton method with a robust convergence against the state
constraints regularization parameter.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14849</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14852</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Tool-Support for Interactive-Machine Learning Applications in
  the Android Ecosystem</dc:title>
 <dc:creator>Sunny, Muhammad Mehran</dc:creator>
 <dc:creator>Berghofer, Moritz</dc:creator>
 <dc:creator>Aslan, Ilhan</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Consumer applications are becoming increasingly smarter and most of them have
to run on device ecosystems. Potential benefits are for example enabling
cross-device interaction and seamless user experiences. Essential for today's
smart solutions with high performance are machine learning models. However,
these models are often developed separately by AI engineers for one specific
device and do not consider the challenges and potentials associated with a
device ecosystem in which their models have to run. We believe that there is a
need for tool-support for AI engineers to address the challenges of
implementing, testing, and deploying machine learning models for a next
generation of smart interactive consumer applications. This paper presents
preliminary results of a series of inquiries, including interviews with AI
engineers and experiments for an interactive machine learning use case with a
Smartwatch and Smartphone. We identified the themes through interviews and
hands-on experience working on our use case and proposed features, such as data
collection from sensors and easy testing of the resources consumption of
running pre-processing code on the target device, which will serve as
tool-support for AI engineers.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14852</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14853</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hand tracking for immersive virtual reality: opportunities and
  challenges</dc:title>
 <dc:creator>Buckingham, Gavin</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Hand tracking has become an integral feature of recent generations of
immersive virtual reality head-mounted displays. With the widespread adoption
of this feature, hardware engineers and software developers are faced with an
exciting array of opportunities and a number of challenges, mostly in relation
to the human user. In this article, I outline what I see as the main
possibilities for hand tracking to add value to immersive virtual reality as
well as some of the potential challenges in the context of the psychology and
neuroscience of the human user. It is hoped that this paper serves as a roadmap
for the development of best practices in the field for the development of
subsequent generations of hand tracking and virtual reality technologies.
</dc:description>
 <dc:description>Comment: 8 Pages</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14855</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gender differences in research performance within and between countries:
  Italy vs Norway</dc:title>
 <dc:creator>Abramo, Giovanni</dc:creator>
 <dc:creator>Aksnes, Dag W.</dc:creator>
 <dc:creator>D'Angelo, Ciriaco Andrea</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  In this study, the scientific performance of Italian and Norwegian university
professors is analysed using bibliometric indicators. The study is based on
over 36,000 individuals and their publication output during the period
2011-2015. Applying a multidimensional indicator in which several aspects of
the research performance are captured, we find large differences in the
performance of men and women. These gender differences are evident across all
analysed levels, such as country, field, and academic position. However, most
of the gender differences can be explained by the tails of the distributions-in
particular, there is a much higher proportion of men among the top 10%
performing scientists. For the remaining 90% of the population, the gender
differences are practically non-existent. The results of the two countries,
which differ in terms of the societal role of women, are contrasting. Further,
we discuss possible biases that are intrinsic in quantitative performance
indicators, which might disfavour female researchers.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14855</dc:identifier>
 <dc:identifier>Journal of Informetrics, 15(2), 101144 (2021)</dc:identifier>
 <dc:identifier>doi:10.1016/j.joi.2021.101144</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14856</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A comparison of two approaches for measuring interdisciplinary research
  output: the disciplinary diversity of authors vs the disciplinary diversity
  of the reference list</dc:title>
 <dc:creator>Abramo, Giovanni</dc:creator>
 <dc:creator>D'Angelo, Ciriaco Andrea</dc:creator>
 <dc:creator>Zhang, Lin</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  This study investigates the convergence of two bibliometric approaches to the
measurement of interdisciplinary research: one based on analyzing disciplinary
diversity in the reference list of publications, the other based on the
disciplinary diversity of authors of publications. In particular we measure the
variety, balance, disparity and integrated diversity index of, respectively,
single-author, multi-author single-field, and multi-author multi-field
publications. We find that, in general, the diversity of the reference list
grows with the number of fields reflected in a paper's authors' list and, to a
lesser extent, with the number of authors being equal the number of fields.
Further, we find that when fields belonging to different disciplines are
reflected in the authors' list, the disparity in the reference list is higher
than in the case of fields belonging to the same discipline. However, this
general tendency varies across disciplines, and noticeable exceptions are found
at individual paper level.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14856</dc:identifier>
 <dc:identifier>Journal of Informetrics, 12(4), 2018, 1182-1193</dc:identifier>
 <dc:identifier>doi:10.1016/j.joi.2018.09.001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14858</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Video Rescaling Networks with Joint Optimization Strategies for
  Downscaling and Upscaling</dc:title>
 <dc:creator>Huang, Yan-Cheng</dc:creator>
 <dc:creator>Chen, Yi-Hsin</dc:creator>
 <dc:creator>Lu, Cheng-You</dc:creator>
 <dc:creator>Wang, Hui-Po</dc:creator>
 <dc:creator>Peng, Wen-Hsiao</dc:creator>
 <dc:creator>Huang, Ching-Chun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper addresses the video rescaling task, which arises from the needs of
adapting the video spatial resolution to suit individual viewing devices. We
aim to jointly optimize video downscaling and upscaling as a combined task.
Most recent studies focus on image-based solutions, which do not consider
temporal information. We present two joint optimization approaches based on
invertible neural networks with coupling layers. Our Long Short-Term Memory
Video Rescaling Network (LSTM-VRN) leverages temporal information in the
low-resolution video to form an explicit prediction of the missing
high-frequency information for upscaling. Our Multi-input Multi-output Video
Rescaling Network (MIMO-VRN) proposes a new strategy for downscaling and
upscaling a group of video frames simultaneously. Not only do they outperform
the image-based invertible model in terms of quantitative and qualitative
results, but also show much improved upscaling quality than the video rescaling
methods without joint optimization. To our best knowledge, this work is the
first attempt at the joint optimization of video downscaling and upscaling.
</dc:description>
 <dc:description>Comment: Accepted by CVPR 2021</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14858</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14860</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Team-oriented Consistency Checking of Heterogeneous Engineering
  Artifacts</dc:title>
 <dc:creator>Tr&#xf6;ls, Michael Alexander</dc:creator>
 <dc:creator>Mashkoor, Atif</dc:creator>
 <dc:creator>Egyed, Alexander</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:description>  Consistency checking of interdependent heterogeneous engineering artifacts,
such as requirements, specifications, and code, is a challenging task in
large-scale engineering projects. The lack of team-oriented solutions allowing
a multitude of project stakeholders to collaborate in a consistent manner is
thus becoming a critical problem. In this context, this work proposes an
approach for team-oriented consistency checking of collaboratively developed
heterogeneous engineering artifacts.
</dc:description>
 <dc:description>Comment: 2 pages, 1 figure, ICSE Poster Exhibit</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14866</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Facet Recommender Networks with Spherical Optimization</dc:title>
 <dc:creator>Tan, Yanchao</dc:creator>
 <dc:creator>Yang, Carl</dc:creator>
 <dc:creator>Wei, Xiangyu</dc:creator>
 <dc:creator>Ma, Yun</dc:creator>
 <dc:creator>Zheng, Xiaolin</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Implicit feedback is widely explored by modern recommender systems. Since the
feedback is often sparse and imbalanced, it poses great challenges to the
learning of complex interactions among users and items. Metric learning has
been proposed to capture user-item interactions from implicit feedback, but
existing methods only represent users and items in a single metric space,
ignoring the fact that users can have multiple preferences and items can have
multiple properties, which leads to potential conflicts limiting their
performance in recommendation. To capture the multiple facets of user
preferences and item properties while resolving their potential conflicts, we
propose the novel framework of Multi-fAcet Recommender networks with Spherical
optimization (MARS). By designing a cross-facet similarity measurement, we
project users and items into multiple metric spaces for fine-grained
representation learning, and compare them only in the proper spaces.
Furthermore, we devise a spherical optimization strategy to enhance the
effectiveness and robustness of the multi-facet recommendation framework.
Extensive experiments on six real-world benchmark datasets show drastic
performance gains brought by MARS, which constantly achieves up to 40\%
improvements over the state-of-the-art baselines regarding both HR and nDCG
metrics.
</dc:description>
 <dc:description>Comment: Accept by ICDE 2021</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14866</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14869</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Instance segmentation with the number of clusters incorporated in
  embedding learning</dc:title>
 <dc:creator>Cao, Jianfeng</dc:creator>
 <dc:creator>Yan, Hong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Semantic and instance segmentation algorithms are two general yet distinct
image segmentation solutions powered by Convolution Neural Network. While
semantic segmentation benefits extensively from the end-to-end training
strategy, instance segmentation is frequently framed as a multi-stage task,
supported by learning-based discrimination and post-process clustering.
Independent optimizations on substages instigate the accumulation of
segmentation errors. In this work, we propose to embed prior clustering
information into an embedding learning framework FCRNet, stimulating the
one-stage instance segmentation. FCRNet relieves the complexity of post process
by incorporating the number of clustering groups into the embedding space. The
superior performance of FCRNet is verified and compared with other methods on
the nucleus dataset BBBC006.
</dc:description>
 <dc:description>Comment: Accepted by ICASSP2021</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14869</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14872</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning Techniques for In-Crop Weed Identification: A Review</dc:title>
 <dc:creator>Hu, Kun</dc:creator>
 <dc:creator>Wang, Zhiyong</dc:creator>
 <dc:creator>Coleman, Guy</dc:creator>
 <dc:creator>Bender, Asher</dc:creator>
 <dc:creator>Yao, Tingting</dc:creator>
 <dc:creator>Zeng, Shan</dc:creator>
 <dc:creator>Song, Dezhen</dc:creator>
 <dc:creator>Schumann, Arnold</dc:creator>
 <dc:creator>Walsh, Michael</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Weeds are a significant threat to the agricultural productivity and the
environment. The increasing demand for sustainable agriculture has driven
innovations in accurate weed control technologies aimed at reducing the
reliance on herbicides. With the great success of deep learning in various
vision tasks, many promising image-based weed detection algorithms have been
developed. This paper reviews recent developments of deep learning techniques
in the field of image-based weed detection. The review begins with an
introduction to the fundamentals of deep learning related to weed detection.
Next, recent progresses on deep weed detection are reviewed with the discussion
of the research materials including public weed datasets. Finally, the
challenges of developing practically deployable weed detection methods are
summarized, together with the discussions of the opportunities for future
research.We hope that this review will provide a timely survey of the field and
attract more researchers to address this inter-disciplinary research problem.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14874</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human-in-the-loop Handling of Knowledge Drift</dc:title>
 <dc:creator>Bontempelli, Andrea</dc:creator>
 <dc:creator>Giunchiglia, Fausto</dc:creator>
 <dc:creator>Passerini, Andrea</dc:creator>
 <dc:creator>Teso, Stefano</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We introduce and study knowledge drift (KD), a complex form of drift that
occurs in hierarchical classification. Under KD the vocabulary of concepts,
their individual distributions, and the is-a relations between them can all
change over time. The main challenge is that, since the ground-truth concept
hierarchy is unobserved, it is hard to tell apart different forms of KD. For
instance, introducing a new is-a relation between two concepts might be
confused with individual changes to those concepts, but it is far from
equivalent. Failure to identify the right kind of KD compromises the concept
hierarchy used by the classifier, leading to systematic prediction errors. Our
key observation is that in many human-in-the-loop applications (like smart
personal assistants) the user knows whether and what kind of drift occurred
recently. Motivated by this, we introduce TRCKD, a novel approach that combines
automated drift detection and adaptation with an interactive stage in which the
user is asked to disambiguate between different kinds of KD. In addition, TRCKD
implements a simple but effective knowledge-aware adaptation strategy. Our
simulations show that often a handful of queries to the user are enough to
substantially improve prediction performance on both synthetic and realistic
data.
</dc:description>
 <dc:description>Comment: 8 pages, figures 4, includes supplementary material (3 pages, 4
  figures), code: https://gitlab.com/abonte/handling-knowledge-drift</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14874</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14878</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>COVID-19 personal protective equipment detection using real-time deep
  learning methods</dc:title>
 <dc:creator>Khosravipour, Shayan</dc:creator>
 <dc:creator>Taghvaei, Erfan</dc:creator>
 <dc:creator>Charkari, Nasrollah Moghadam</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  The exponential spread of COVID-19 in over 215 countries has led WHO to
recommend face masks and gloves for a safe return to school or work. We used
artificial intelligence and deep learning algorithms for automatic face masks
and gloves detection in public areas. We investigated and assessed the efficacy
of two popular deep learning algorithms of YOLO (You Only Look Once) and SSD
MobileNet for the detection and proper wearing of face masks and gloves trained
over a data set of 8250 images imported from the internet. YOLOv3 is
implemented using the DarkNet framework, and the SSD MobileNet algorithm is
applied for the development of accurate object detection. The proposed models
have been developed to provide accurate multi-class detection (Mask vs. No-Mask
vs. Gloves vs. No-Gloves vs. Improper). When people wear their masks
improperly, the method detects them as an improper class. The introduced models
provide accuracies of (90.6% for YOLO and 85.5% for SSD) for multi-class
detection. The systems' results indicate the efficiency and validity of
detecting people who do not wear masks and gloves in public.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14878</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14882</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On TasNet for Low-Latency Single-Speaker Speech Enhancement</dc:title>
 <dc:creator>Kolb&#xe6;k, Morten</dc:creator>
 <dc:creator>Tan, Zheng-Hua</dc:creator>
 <dc:creator>Jensen, S&#xf8;ren Holdt</dc:creator>
 <dc:creator>Jensen, Jesper</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  In recent years, speech processing algorithms have seen tremendous progress
primarily due to the deep learning renaissance. This is especially true for
speech separation where the time-domain audio separation network (TasNet) has
led to significant improvements. However, for the related task of
single-speaker speech enhancement, which is of obvious importance, it is yet
unknown, if the TasNet architecture is equally successful. In this paper, we
show that TasNet improves state-of-the-art also for speech enhancement, and
that the largest gains are achieved for modulated noise sources such as speech.
Furthermore, we show that TasNet learns an efficient inner-domain
representation, where target and noise signal components are highly separable.
This is especially true for noise in terms of interfering speech signals, which
might explain why TasNet performs so well on the separation task. Additionally,
we show that TasNet performs poorly for large frame hops and conjecture that
aliasing might be the main cause of this performance drop. Finally, we show
that TasNet consistently outperforms a state-of-the-art single-speaker speech
enhancement system.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14882</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14884</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuous Conditional Generative Adversarial Networks (cGAN) with
  Generator Regularization</dc:title>
 <dc:creator>Zheng, Yufeng</dc:creator>
 <dc:creator>Zhang, Yunkai</dc:creator>
 <dc:creator>Zheng, Zeyu</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Conditional Generative Adversarial Networks are known to be difficult to
train, especially when the conditions are continuous and high-dimensional. To
partially alleviate this difficulty, we propose a simple generator
regularization term on the GAN generator loss in the form of Lipschitz penalty.
Thus, when the generator is fed with neighboring conditions in the continuous
space, the regularization term will leverage the neighbor information and push
the generator to generate samples that have similar conditional distributions
for each neighboring condition. We analyze the effect of the proposed
regularization term and demonstrate its robust performance on a range of
synthetic and real-world tasks.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14884</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14892</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-adaptive Torque Vectoring Controller Using Reinforcement Learning</dc:title>
 <dc:creator>Taherian, Shayan</dc:creator>
 <dc:creator>Kuutti, Sampo</dc:creator>
 <dc:creator>Visca, Marco</dc:creator>
 <dc:creator>Fallah, Saber</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Continuous direct yaw moment control systems such as torque-vectoring
controller are an essential part for vehicle stabilization. This controller has
been extensively researched with the central objective of maintaining the
vehicle stability by providing consistent stable cornering response. The
ability of careful tuning of the parameters in a torque-vectoring controller
can significantly enhance vehicle's performance and stability. However, without
any re-tuning of the parameters, especially in extreme driving conditions e.g.
low friction surface or high velocity, the vehicle fails to maintain the
stability. In this paper, the utility of Reinforcement Learning (RL) based on
Deep Deterministic Policy Gradient (DDPG) as a parameter tuning algorithm for
torque-vectoring controller is presented. It is shown that, torque-vectoring
controller with parameter tuning via reinforcement learning performs well on a
range of different driving environment e.g., wide range of friction conditions
and different velocities, which highlight the advantages of reinforcement
learning as an adaptive algorithm for parameter tuning. Moreover, the
robustness of DDPG algorithm are validated under scenarios which are beyond the
training environment of the reinforcement learning algorithm. The simulation
has been carried out using a four wheels vehicle model with nonlinear tire
characteristics. We compare our DDPG based parameter tuning against a genetic
algorithm and a conventional trial-and-error tunning of the torque vectoring
controller, and the results demonstrated that the reinforcement learning based
parameter tuning significantly improves the stability of the vehicle.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14892</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14895</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature-based Representation for Violin Bridge Admittances</dc:title>
 <dc:creator>Malvermi, R.</dc:creator>
 <dc:creator>Gonzalez, S.</dc:creator>
 <dc:creator>Quintavalla, M.</dc:creator>
 <dc:creator>Antonacci, F.</dc:creator>
 <dc:creator>Sarti, A.</dc:creator>
 <dc:creator>Torres, J. A.</dc:creator>
 <dc:creator>Corradi, R.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  Frequency Response Functions (FRFs) are one of the cornerstones of musical
acoustic experimental research. They describe the way in which musical
instruments vibrate in a wide range of frequencies and are used to predict and
understand the acoustic differences between them. In the specific case of
stringed musical instruments such as violins, FRFs evaluated at the bridge are
known to capture the overall body vibration. These indicators, also called
bridge admittances, are widely used in the literature for comparative analyses.
However, due to their complex structure they are rather difficult to
quantitatively compare and study. In this manuscript we present a way to
quantify differences between FRFs, in particular violin bridge admittances,
that separates the effects in frequency, amplitude and quality factor of the
first resonance peaks characterizing the responses. This approach allows us to
define a distance between FRFs and clusterise measurements according to this
distance. We use two case studies, one based on Finite Element Analysis and
another exploiting measurements on real violins, to prove the effectiveness of
such representation. In particular, for simulated bridge admittances the
proposed distance is able to highlight the different impact of consecutive
simulation `steps' on specific vibrational properties and, for real violins,
gives a first insight on similar styles of making, as well as opposite ones.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures, submitted to &quot;The 27th International Congress on
  Sound and Vibration&quot; (ICSV)</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14895</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14896</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Representation, Analysis of Bayesian Refinement Approximation Network: A
  Survey</dc:title>
 <dc:creator>Zhu, Ningbo</dc:creator>
 <dc:creator>Yang, Fei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  After an artificial model background subtraction, the pixels have been
labelled as foreground and background. Previous approaches to secondary
processing the output for denoising usually use traditional methods such as the
Bayesian refinement method. In this paper, we focus on using a modified U-Net
model to approximate the result of the Bayesian refinement method and improve
the result. In our modified U-Net model, the result of background subtraction
from other models will be combined with the source image as input for learning
the statistical distribution. Thus, the losing information caused by the
background subtraction model can be restored from the source image. Moreover,
since the part of the input image is already the output of the other background
subtraction model, the feature extraction should be convenient, it only needs
to change the labels of the noise pixels. Compare with traditional methods,
using deep learning methods superiority in keeping details.
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14896</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14902</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scheduling of Wireless Edge Networks for Feedback-Based Interactive
  Applications</dc:title>
 <dc:creator>Zoppi, Samuele</dc:creator>
 <dc:creator>Champati, Jaya Prakash</dc:creator>
 <dc:creator>Gross, James</dc:creator>
 <dc:creator>Kellerer, Wolfgang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Interactive applications with automated feedback will largely influence the
design of future networked infrastructures. In such applications, status
information about an environment of interest is captured and forwarded to a
compute node, which analyzes the information and generates a feedback message.
Timely processing and forwarding must ensure the feedback information to be
still applicable; thus, the quality-of-service parameter for such applications
is the end-to-end latency over the entire loop. By modelling the communication
of a feedback loop as a two-hop network, we address the problem of allocating
network resources in order to minimize the delay violation probability (DVP),
i.e. the probability of the end-to-end latency exceeding a target value. We
investigate the influence of the network queue states along the network path on
the performance of semi-static and dynamic scheduling policies. The former
determine the schedule prior to the transmission of the packet, while the
latter benefit from feedback on the queue states as time evolves and reallocate
time slots depending on the queue's evolution. The performance of the proposed
policies is evaluated for variations in several system parameters and
comparison baselines. Results show that the proposed semi-static policy
achieves close-to-optimal DVP and the dynamic policy outperforms the
state-of-the-art algorithms.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14902</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14907</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Frequency-specific segregation and integration of human cerebral cortex:
  an intrinsic functional atlas</dc:title>
 <dc:creator>Luo, Zhiguo</dc:creator>
 <dc:creator>Zeng, Ling-Li</dc:creator>
 <dc:creator>Shen, Hui</dc:creator>
 <dc:creator>Hu, Dewen</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The frequency-specific coupling mechanism of the functional human brain
networks underpins its complex cognitive and behavioral functions.
Nevertheless, it is not well unveiled what are the frequency-specific
subdivisions and network topologies of the human brain. In this study, we
estimated functional connectivity of the human cerebral cortex using spectral
connection, and conducted frequency-specific parcellation using
eigen-clustering and gradient-based methods, and then explored their
topological structures. 7T fMRI data of 184 subjects in the HCP dataset were
used for parcellation and exploring the topological properties of the
functional networks, and 3T fMRI data of another 890 subjects were used to
confirm the stability of the frequency-specific topologies. Seven to ten
functional networks were stably integrated by two to four dissociable hub
categories at specific frequencies, and we proposed an intrinsic functional
atlas containing 456 parcels according to the parcellations across frequencies.
The results revealed that the functional networks contained stable
frequency-specific topologies, which may imply more abundant roles of the
functional units and more complex interactions among them.
</dc:description>
 <dc:description>Comment: 43 pages, 14 figures</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14907</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14908</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Embedding Transfer with Label Relaxation for Improved Metric Learning</dc:title>
 <dc:creator>Kim, Sungyeon</dc:creator>
 <dc:creator>Kim, Dongwon</dc:creator>
 <dc:creator>Cho, Minsu</dc:creator>
 <dc:creator>Kwak, Suha</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  This paper presents a novel method for embedding transfer, a task of
transferring knowledge of a learned embedding model to another. Our method
exploits pairwise similarities between samples in the source embedding space as
the knowledge, and transfers them through a loss used for learning target
embedding models. To this end, we design a new loss called relaxed contrastive
loss, which employs the pairwise similarities as relaxed labels for
inter-sample relations. Our loss provides a rich supervisory signal beyond
class equivalence, enables more important pairs to contribute more to training,
and imposes no restriction on manifolds of target embedding spaces. Experiments
on metric learning benchmarks demonstrate that our method largely improves
performance, or reduces sizes and output dimensions of target models
effectively. We further show that it can be also used to enhance quality of
self-supervised representation and performance of classification models. In all
the experiments, our method clearly outperforms existing embedding transfer
techniques.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2021</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14908</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14916</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Abuse is Contextual, What about NLP? The Role of Context in Abusive
  Language Annotation and Detection</dc:title>
 <dc:creator>Menini, Stefano</dc:creator>
 <dc:creator>Aprosio, Alessio Palmero</dc:creator>
 <dc:creator>Tonelli, Sara</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The datasets most widely used for abusive language detection contain lists of
messages, usually tweets, that have been manually judged as abusive or not by
one or more annotators, with the annotation performed at message level. In this
paper, we investigate what happens when the hateful content of a message is
judged also based on the context, given that messages are often ambiguous and
need to be interpreted in the context of occurrence. We first re-annotate part
of a widely used dataset for abusive language detection in English in two
conditions, i.e. with and without context. Then, we compare the performance of
three classification algorithms obtained on these two types of dataset, arguing
that a context-aware classification is more challenging but also more similar
to a real application scenario.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14916</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14918</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IEEE 802.11bf: Toward Ubiquitous Wi-Fi Sensing</dc:title>
 <dc:creator>Restuccia, Francesco</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Wi-Fi is among the most successful wireless technologies ever invented. As
Wi-Fi becomes more and more present in public and private spaces, it becomes
natural to leverage its ubiquitousness to implement groundbreaking wireless
sensing applications such as human presence detection, activity recognition,
and object tracking, just to name a few. This paper reports ongoing efforts by
the IEEE 802.11bf Task Group (TGbf), which is defining the appropriate
modifications to existing Wi-Fi standards to enhance sensing capabilities
through 802.11-compliant waveforms. We summarize objectives and timeline of
TGbf, and discuss some of the most interesting proposed technical features
discussed so far. We also introduce a roadmap of research challenges pertaining
to Wi-Fi sensing and its integration with future Wi-Fi technologies and
emerging spectrum bands, hoping to elicit further activities by both the
research community and TGbf.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14918</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14933</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>$\{log\}$: Applications to Software Specification, Prototyping and
  Verification</dc:title>
 <dc:creator>Cristi&#xe1;, Maximiliano</dc:creator>
 <dc:creator>Rossi, Gianfranco</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  This document shows how Z specifications can be translated into $\{log\}$
and, later, on how $\{log\}$ can be used to run simulations and automated
proofs. This can help users of other specification languages such as B and VDM
to use $\{log\}$ along the same lines. The presentation is rather informal and
user-oriented. More technical and formal presentations can be found in the
papers published by the authors. We also assume the reader has at least a basic
knowledge of the Z notation.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14933</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14934</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Community-based Cyberreading for Information Understanding</dc:title>
 <dc:creator>Jiang, Zhuoren</dc:creator>
 <dc:creator>Liu, Xiaozhong</dc:creator>
 <dc:creator>Gao, Liangcai</dc:creator>
 <dc:creator>Tang, Zhi</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Although the content in scientific publications is increasingly challenging,
it is necessary to investigate another important problem, that of scientific
information understanding. For this proposed problem, we investigate novel
methods to assist scholars (readers) to better understand scientific
publications by enabling physical and virtual collaboration. For physical
collaboration, an algorithm will group readers together based on their profiles
and reading behavior, and will enable the cyberreading collaboration within a
online reading group. For virtual collaboration, instead of pushing readers to
communicate with others, we cluster readers based on their estimated
information needs. For each cluster, a learning to rank model will be generated
to recommend readers' communitized resources (i.e., videos, slides, and wikis)
to help them understand the target publication.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14934</dc:identifier>
 <dc:identifier>SIGIR 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14938</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IoU Attack: Towards Temporally Coherent Black-Box Adversarial Attack for
  Visual Object Tracking</dc:title>
 <dc:creator>Jia, Shuai</dc:creator>
 <dc:creator>Song, Yibing</dc:creator>
 <dc:creator>Ma, Chao</dc:creator>
 <dc:creator>Yang, Xiaokang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Adversarial attack arises due to the vulnerability of deep neural networks to
perceive input samples injected with imperceptible perturbations. Recently,
adversarial attack has been applied to visual object tracking to evaluate the
robustness of deep trackers. Assuming that the model structures of deep
trackers are known, a variety of white-box attack approaches to visual tracking
have demonstrated promising results. However, the model knowledge about deep
trackers is usually unavailable in real applications. In this paper, we propose
a decision-based black-box attack method for visual object tracking. In
contrast to existing black-box adversarial attack methods that deal with static
images for image classification, we propose IoU attack that sequentially
generates perturbations based on the predicted IoU scores from both current and
historical frames. By decreasing the IoU scores, the proposed attack method
degrades the accuracy of temporal coherent bounding boxes (i.e., object
motions) accordingly. In addition, we transfer the learned perturbations to the
next few frames to initialize temporal motion attack. We validate the proposed
IoU attack on state-of-the-art deep trackers (i.e., detection based,
correlation filter based, and long-term trackers). Extensive experiments on the
benchmark datasets indicate the effectiveness of the proposed IoU attack
method. The source code is available at
https://github.com/VISION-SJTU/IoUattack.
</dc:description>
 <dc:description>Comment: Accepted by CVPR2021</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14938</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14941</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Networking and Computing in Biomechanical Research: Challenges and
  Directions</dc:title>
 <dc:creator>Mastorakis, Spyridon</dc:creator>
 <dc:creator>Skiadopoulos, Andreas</dc:creator>
 <dc:creator>Shannigrahi, Susmit</dc:creator>
 <dc:creator>Likens, Aaron</dc:creator>
 <dc:creator>Nour, Boubakr</dc:creator>
 <dc:creator>Stergiou, Nicholas</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Biomechanics is a scientific discipline that studies the forces acting on a
body and the effects they produce. In this paper, we bring together
biomechanists and networking researchers to shed light into how research
efforts in biomechanics, primarily related to the study of the human body, can
be facilitated through networking and computing technologies, such as edge and
cloud computing, Software Defined Networking, and Information-Centric
Networking. We first present challenges related to networking and computing
that biomechanists face today and we then describe how networking and computing
technologies can address them. Finally, we identify directions for future
networking research with a focus on biomechanics to facilitate and encourage
interdisciplinary collaborations between biomechanists and networking
researchers.
</dc:description>
 <dc:description>Comment: Accepted for publication by the IEEE Communications Magazine</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14941</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14946</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple Logic of Functional Dependence</dc:title>
 <dc:creator>Baltag, Alexandru</dc:creator>
 <dc:creator>van Benthem, Johan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>03B45</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  This paper presents a simple decidable logic of functional dependence LFD,
based on an extension of classical propositional logic with dependence atoms
plus dependence quantifiers treated as modalities, within the setting of
generalized assignment semantics for first order logic. The expressive
strength, complete proof calculus and meta-properties of LFD are explored.
Various language extensions are presented as well, up to undecidable
modal-style logics for independence and dynamic logics of changing dependence
models. Finally, more concrete settings for dependence are discussed:
continuous dependence in topological models, linear dependence in vector
spaces, and temporal dependence in dynamical systems and games.
</dc:description>
 <dc:description>Comment: 56 pages. Journal of Philosophical Logic (2021)</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14946</dc:identifier>
 <dc:identifier>doi:10.1007/s10992-020-09588-z</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14949</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Backend-Aware Post-Training Quantization</dc:title>
 <dc:creator>Jiang, Ziheng</dc:creator>
 <dc:creator>Jain, Animesh</dc:creator>
 <dc:creator>Liu, Andrew</dc:creator>
 <dc:creator>Fromm, Josh</dc:creator>
 <dc:creator>Ma, Chengqian</dc:creator>
 <dc:creator>Chen, Tianqi</dc:creator>
 <dc:creator>Ceze, Luis</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Quantization is a key technique to reduce the resource requirement and
improve the performance of neural network deployment. However, different
hardware backends such as x86 CPU, NVIDIA GPU, ARM CPU, and accelerators may
demand different implementations for quantized networks. This diversity calls
for specialized post-training quantization pipelines to built for each hardware
target, an engineering effort that is often too large for developers to keep up
with. We tackle this problem with an automated post-training quantization
framework called HAGO. HAGO provides a set of general quantization graph
transformations based on a user-defined hardware specification and implements a
search mechanism to find the optimal quantization strategy while satisfying
hardware constraints for any model. We observe that HAGO achieves speedups of
2.09x, 1.97x, and 2.48x on Intel Xeon Cascade Lake CPUs, NVIDIA Tesla T4 GPUs,
ARM Cortex-A CPUs on Raspberry Pi4 relative to full precision respectively,
while maintaining the highest reported post-training quantization accuracy in
each case.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14949</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14950</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The AI Settlement Generation Challenge in Minecraft: First Year Report</dc:title>
 <dc:creator>Salge, Christoph</dc:creator>
 <dc:creator>Green, Michael Cerny</dc:creator>
 <dc:creator>Canaan, Rodrigo</dc:creator>
 <dc:creator>Skwarski, Filip</dc:creator>
 <dc:creator>Fritsch, Rafael</dc:creator>
 <dc:creator>Brightmoore, Adrian</dc:creator>
 <dc:creator>Ye, Shaofang</dc:creator>
 <dc:creator>Cao, Changxing</dc:creator>
 <dc:creator>Togelius, Julian</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This article outlines what we learned from the first year of the AI
Settlement Generation Competition in Minecraft, a competition about producing
AI programs that can generate interesting settlements in Minecraft for an
unseen map. This challenge seeks to focus research into adaptive and holistic
procedural content generation. Generating Minecraft towns and villages given
existing maps is a suitable task for this, as it requires the generated content
to be adaptive, functional, evocative and aesthetic at the same time. Here, we
present the results from the first iteration of the competition. We discuss the
evaluation methodology, present the different technical approaches by the
competitors, and outline the open problems.
</dc:description>
 <dc:description>Comment: 14 pages, 9 figures, published in KI-K\&quot;unstliche Intelligenz</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14950</dc:identifier>
 <dc:identifier>KI-K\&quot;unstliche Intelligenz 2020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14956</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dark Patterns in the Interaction with Cookie Banners</dc:title>
 <dc:creator>Hausner, Philip</dc:creator>
 <dc:creator>Gertz, Michael</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Dark patterns are interface designs that nudge users towards behavior that is
against their best interests. Since humans are often not even aware that they
are influenced by these malicious patterns, research has to identify ways to
protect web users against them. One approach to this is the automatic detection
of dark patterns which enables the development of tools that are able to
protect users by proactively warning them in cases where they face a dark
pattern. In this paper, we present ongoing work in the direction of automatic
detection of dark patterns, and outline an example to detect malicious patterns
within the domain of cookie banners.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, Position Paper at the Workshop &quot;What Can CHI Do
  About Dark Patterns?&quot; at the CHI Conference on Human Factors in Computing
  Systems (CHI 2021), May 8-13, 2021, Yokohama, Japan</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14956</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14961</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Supersense and Sensibility: Proxy Tasks for Semantic Annotation of
  Prepositions</dc:title>
 <dc:creator>Gessler, Luke</dc:creator>
 <dc:creator>Wein, Shira</dc:creator>
 <dc:creator>Schneider, Nathan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Prepositional supersense annotation is time-consuming and requires expert
training. Here, we present two sensible methods for obtaining prepositional
supersense annotations by eliciting surface substitution and similarity
judgments. Four pilot studies suggest that both methods have potential for
producing prepositional supersense annotations that are comparable in quality
to expert annotations.
</dc:description>
 <dc:description>Comment: Presented at LAW XIV in 2020</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14961</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14962</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Panoptic-PolarNet: Proposal-free LiDAR Point Cloud Panoptic Segmentation</dc:title>
 <dc:creator>Zhou, Zixiang</dc:creator>
 <dc:creator>Zhang, Yang</dc:creator>
 <dc:creator>Foroosh, Hassan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Panoptic segmentation presents a new challenge in exploiting the merits of
both detection and segmentation, with the aim of unifying instance segmentation
and semantic segmentation in a single framework. However, an efficient solution
for panoptic segmentation in the emerging domain of LiDAR point cloud is still
an open research problem and is very much under-explored. In this paper, we
present a fast and robust LiDAR point cloud panoptic segmentation framework,
referred to as Panoptic-PolarNet. We learn both semantic segmentation and
class-agnostic instance clustering in a single inference network using a polar
Bird's Eye View (BEV) representation, enabling us to circumvent the issue of
occlusion among instances in urban street scenes. To improve our network's
learnability, we also propose an adapted instance augmentation technique and a
novel adversarial point cloud pruning method. Our experiments show that
Panoptic-PolarNet outperforms the baseline methods on SemanticKITTI and
nuScenes datasets with an almost real-time inference speed. Panoptic-PolarNet
achieved 54.1% PQ in the public SemanticKITTI panoptic segmentation leaderboard
and leading performance for the validation set of nuScenes.
</dc:description>
 <dc:description>Comment: Accepted by CVPR 2021</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14962</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14963</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Particle Filter Bridge Interpolation</dc:title>
 <dc:creator>Lindhe, Adam</dc:creator>
 <dc:creator>Ringqvist, Carl</dc:creator>
 <dc:creator>Hult, Henrik</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Auto encoding models have been extensively studied in recent years. They
provide an efficient framework for sample generation, as well as for analysing
feature learning. Furthermore, they are efficient in performing interpolations
between data-points in semantically meaningful ways. In this paper, we build
further on a previously introduced method for generating canonical, dimension
independent, stochastic interpolations. Here, the distribution of interpolation
paths is represented as the distribution of a bridge process constructed from
an artificial random data generating process in the latent space, having the
prior distribution as its invariant distribution. As a result the stochastic
interpolation paths tend to reside in regions of the latent space where the
prior has high mass. This is a desirable feature since, generally, such areas
produce semantically meaningful samples. In this paper, we extend the bridge
process method by introducing a discriminator network that accurately
identifies areas of high latent representation density. The discriminator
network is incorporated as a change of measure of the underlying bridge process
and sampling of interpolation paths is implemented using sequential Monte
Carlo. The resulting sampling procedure allows for greater variability in
interpolation paths and stronger drift towards areas of high data density.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14965</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transmitter Discovery through Radio-Visual Probabilistic Active Sensing</dc:title>
 <dc:creator>Varotto, Luca</dc:creator>
 <dc:creator>Cenedese, Angelo</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Multi-modal Probabilistic Active Sensing (MMPAS) uses sensor fusion and
probabilistic models to control the perception process of robotic sensing
platforms. MMPAS is successfully employed in environmental exploration,
collaborative mobile robotics, and target tracking, being fostered by the high
performance guarantees on autonomous perception. In this context, we propose a
bi-Radio-Visual PAS scheme to solve the transmitter discovery problem.
Specifically, we firstly exploit the correlation between radio and visual
measurements to learn a target detection model in a self-supervised manner.
Then, the model is combined with antenna radiation anisotropies into a Bayesian
Optimization framework that controls the platform. We show that the proposed
algorithm attains an accuracy of 92%, overcoming two other probabilistic active
sensing baselines.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures, 1 table, submitted to MMAR 2021</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14965</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14970</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A variational minimization formulation for hydraulically induced
  fracturing in elastic-plastic solids</dc:title>
 <dc:creator>Kienle, Daniel</dc:creator>
 <dc:creator>Keip, Marc-Andre</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Condensed Matter - Other Condensed Matter</dc:subject>
 <dc:description>  A variational modeling framework for hydraulically induced fracturing of
elastic-plastic solids is developed in the present work. The developed
variational structure provides a global minimization problem. While fracture
propagation is modeled by means of a phase-field approach to fracture, plastic
effects are taken into account by using a Drucker-Prager-type yield-criterion
function. This yield-criterion function governs the plastic evolution of the
fluid-solid mixture. Fluid storage and transport are described by a
Darcy-Biot-type formulation. Thereby the fluid storage is decomposed into a
contribution due to the elastic deformations and one due to the plastic
deformations. A local return mapping scheme is used for the update of the
plastic quantities. The global minimization structure demands a
$H($div$)$-conforming finite-element formulation. Furthermore this is combined
with an enhanced-assumed-strain formulation in order to overcome locking
phenomena arising from the plastic deformations. The robustness and
capabilities of the presented framework will be shown in a sequence of
numerical examples.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14970</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14971</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transient stability analysis of composite hydrogel structures based on a
  minimization-type variational formulation</dc:title>
 <dc:creator>Sriram, Siddharth</dc:creator>
 <dc:creator>Polukhov, Elten</dc:creator>
 <dc:creator>Keip, Marc-Andre</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Condensed Matter - Soft Condensed Matter</dc:subject>
 <dc:description>  We employ a canonical variational framework for the predictive
characterization of structural instabilities that develop during the
diffusion-driven transient swelling of hydrogels under geometrical constraints.
The variational formulation of finite elasticity coupled with Fickian diffusion
has a two-field minimization structure, wherein the deformation map and the
fluid-volume flux are obtained as minimizers of a time-discrete potential
involving internal and external energetic contributions. Following spatial
discretization, the minimization principle is implemented using a conforming
Q$_1$RT$_0$ finite-element design, making use of the lowest-order
Raviart-Thomas-type interpolations for the fluid-volume flux. To analyze the
structural stability of a certain equilibrium state of the gel satisfying the
minimization principle, we apply the local stability criterion on the
incremental potential, which is based on the idea that a stable equilibrium
state has the lowest potential energy among all possible states within an
infinitesimal neighborhood. Using this criterion, it is understood that
bifurcation-type structural instabilities are activated when the coupled global
finite-element stiffness matrix loses its positive definiteness. This concept
is then applied to determine the onset and nature of wrinkling instabilities
occurring in a pair of representative film-substrate hydrogel systems. In
particular, we analyze the dependencies of the critical buckling load and mode
shape on the system geometry and material parameters.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14971</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14977</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the benefits of robust models in modulation recognition</dc:title>
 <dc:creator>Maroto, Javier</dc:creator>
 <dc:creator>Bovet, G&#xe9;r&#xf4;me</dc:creator>
 <dc:creator>Frossard, Pascal</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Given the rapid changes in telecommunication systems and their higher
dependence on artificial intelligence, it is increasingly important to have
models that can perform well under different, possibly adverse, conditions.
Deep Neural Networks (DNNs) using convolutional layers are state-of-the-art in
many tasks in communications. However, in other domains, like image
classification, DNNs have been shown to be vulnerable to adversarial
perturbations, which consist of imperceptible crafted noise that when added to
the data fools the model into misclassification. This puts into question the
security of DNNs in communication tasks, and in particular in modulation
recognition. We propose a novel framework to test the robustness of current
state-of-the-art models where the adversarial perturbation strength is
dependent on the signal strength and measured with the &quot;signal to perturbation
ratio&quot; (SPR). We show that current state-of-the-art models are susceptible to
these perturbations. In contrast to current research on the topic of image
classification, modulation recognition allows us to have easily accessible
insights on the usefulness of the features learned by DNNs by looking at the
constellation space. When analyzing these vulnerable models we found that
adversarial perturbations do not shift the symbols towards the nearest classes
in constellation space. This shows that DNNs do not base their decisions on
signal statistics that are important for the Bayes-optimal modulation
recognition model, but spurious correlations in the training data. Our feature
analysis and proposed framework can help in the task of finding better models
for communication systems.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14977</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14979</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Information Sharing and Punishment Strategies</dc:title>
 <dc:creator>Ntemos, Konstantinos</dc:creator>
 <dc:creator>Pikramenos, George</dc:creator>
 <dc:creator>Kalouptsidis, Nicholas</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  In this paper we study the problem of information sharing among rational
self-interested agents as a dynamic game of asymmetric information. We assume
that the agents imperfectly observe a Markov chain and they are called to
decide whether they will share their noisy observations or not at each time
instant. We utilize the notion of conditional mutual information to evaluate
the information being shared among the agents. The challenges that arise due to
the inter-dependence of agents' information structure and decision-making are
exhibited. For the finite horizon game we prove that agents do not have
incentive to share information. In contrast, we show that cooperation can be
sustained in the infinite horizon case by devising appropriate punishment
strategies which are defined over the agents' beliefs on the system state. We
show that these strategies are closed under the best-response mapping and that
cooperation can be the optimal choice in some subsets of the state belief
simplex. We characterize these equilibrium regions, prove uniqueness of a
maximal equilibrium region and devise an algorithm for its approximate
computation.
</dc:description>
 <dc:description>Comment: 16 pages, 2 figures</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14979</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14984</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Realistic face animation generation from videos</dc:title>
 <dc:creator>Jian, Zihao</dc:creator>
 <dc:creator>Xie, Minshan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  3D face reconstruction and face alignment are two fundamental and highly
related topics in computer vision. Recently, some works start to use deep
learning models to estimate the 3DMM coefficients to reconstruct 3D face
geometry. However, the performance is restricted due to the limitation of the
pre-defined face templates. To address this problem, some end-to-end methods,
which can completely bypass the calculation of 3DMM coefficients, are proposed
and attract much attention. In this report, we introduce and analyse three
state-of-the-art methods in 3D face reconstruction and face alignment. Some
potential improvement on PRN are proposed to further enhance its accuracy and
speed.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14984</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14986</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generating Negations of Probability Distributions</dc:title>
 <dc:creator>Batyrshin, Ildar</dc:creator>
 <dc:creator>Villa-Vargas, Luis Alfonso</dc:creator>
 <dc:creator>Ramirez-Salinas, Marco Antonio</dc:creator>
 <dc:creator>Salinas-Rosales, Moises</dc:creator>
 <dc:creator>Kubysheva, Nailya</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Recently it was introduced a negation of a probability distribution. The need
for such negation arises when a knowledge-based system can use the terms like
NOT HIGH, where HIGH is represented by a probability distribution (pd). For
example, HIGH PROFIT or HIGH PRICE can be considered. The application of this
negation in Dempster-Shafer theory was considered in many works. Although
several negations of probability distributions have been proposed, it was not
clear how to construct other negations. In this paper, we consider negations of
probability distributions as point-by-point transformations of pd using
decreasing functions defined on [0,1] called negators. We propose the general
method of generation of negators and corresponding negations of pd, and study
their properties. We give a characterization of linear negators as a convex
combination of Yager and uniform negators.
</dc:description>
 <dc:description>Comment: 10 pages, 1 figure</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14986</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14988</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NMRPy: a novel NMR scripting system to implement artificial intelligence
  and advanced applications</dc:title>
 <dc:creator>Liu, Zao</dc:creator>
 <dc:creator>Song, Kan</dc:creator>
 <dc:creator>Chen, Zhiwei</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Background: Software is an important windows to offer a variety of complex
instrument control and data processing for nuclear magnetic resonance (NMR)
spectrometer. NMR software should allow researchers to flexibly implement
various functionality according to the requirement of applications. Scripting
system can offer an open environment for NMR users to write custom programs
with basic libraries. Emerging technologies, especially multivariate
statistical analysis and artificial intelligence, have been successfully
applied to NMR applications such as metabolomics and biomacromolecules.
Scripting system should support more complex NMR libraries, which will enable
the emerging technologies to be easily implemented in the scripting
environment. Result: Here, a novel NMR scripting system named &quot;NMRPy&quot; is
introduced. In the scripting system, both Java based NMR methods and original
CPython based libraries are supported. A module was built as a bridge to
integrate the runtime environment of Java and CPython. It works as an extension
in CPython environment, as well as interacts with Java part by Java Native
Interface. Leveraging the bridge, Java based instrument control and data
processing methods can be called as a CPython style. Compared with traditional
scripting system, NMRPy is easier for NMR researchers to develop complex
functionality with fast numerical computation, multivariate statistical
analysis, deep learning etc. Non-uniform sampling and protein structure
prediction methods based on deep learning can be conveniently integrated into
NMRPy. Conclusion: NMRPy offers a user-friendly environment to implement custom
functionality leveraging its powerful basic NMR and rich CPython libraries. NMR
applications with emerging technologies can be easily integrated. The scripting
system is free of charge and can be downloaded by visiting
http://www.spinstudioj.net/nmrpy.
</dc:description>
 <dc:description>Comment: 19 pages, 6 figures</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14988</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14990</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effective GPU Parallelization of Distributed and Localized Model
  Predictive Control</dc:title>
 <dc:creator>Alonso, Carmen Amo</dc:creator>
 <dc:creator>Tseng, Shih-Hao</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  To effectively control large-scale distributed systems online, model
predictive control (MPC) has to swiftly solve the underlying high-dimensional
optimization. There are multiple techniques applied to accelerate the solving
process in the literature, mainly attributed to software-based algorithmic
advancements and hardware-assisted computation enhancements. However, those
methods focus on arithmetic accelerations and overlook the benefits of the
underlying system's structure. In particular, the existing decoupled
software-hardware algorithm design that naively parallelizes the arithmetic
operations by the hardware does not tackle the hardware overheads such as
CPU-GPU and thread-to-thread communications in a principled manner. Also, the
advantages of parallelizable subproblem decomposition in distributed MPC are
not well recognized and exploited. As a result, we have not reached the full
potential of hardware acceleration for MPC. In this paper, we explore those
opportunities by leveraging GPU to parallelize the distributed and localized
MPC (DLMPC) algorithm. We exploit the locality constraints embedded in the
DLMPC formulation to reduce the hardware-intrinsic communication overheads. Our
parallel implementation achieves up to 50x faster runtime than its CPU
counterparts under various parameters. Furthermore, we find that the
locality-aware GPU parallelization could halve the optimization runtime
comparing to the naive acceleration. Overall, our results demonstrate the
performance gains brought by software-hardware co-design with the information
exchange structure in mind.
</dc:description>
 <dc:description>Comment: Submitted to 2021 Control and Decision Conference</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14990</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14994</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two-Stage Clustering of Human Preferences for Action Prediction in
  Assembly Tasks</dc:title>
 <dc:creator>Nemlekar, Heramb</dc:creator>
 <dc:creator>Modi, Jignesh</dc:creator>
 <dc:creator>Gupta, Satyandra K.</dc:creator>
 <dc:creator>Nikolaidis, Stefanos</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  To effectively assist human workers in assembly tasks a robot must
proactively offer support by inferring their preferences in sequencing the task
actions. Previous work has focused on learning the dominant preferences of
human workers for simple tasks largely based on their intended goal. However,
people may have preferences at different resolutions: they may share the same
high-level preference for the order of the sub-tasks but differ in the sequence
of individual actions. We propose a two-stage approach for learning and
inferring the preferences of human operators based on the sequence of sub-tasks
and actions. We conduct an IKEA assembly study and demonstrate how our approach
is able to learn the dominant preferences in a complex task. We show that our
approach improves the prediction of human actions through cross-validation.
Lastly, we show that our two-stage approach improves the efficiency of task
execution in an online experiment, and demonstrate its applicability in a
real-world robot-assisted IKEA assembly.
</dc:description>
 <dc:description>Comment: 8 pages, 8 figures, 2021 International Conference on Robotics and
  Automation (ICRA)</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14994</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.14998</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tensor Networks for Multi-Modal Non-Euclidean Data</dc:title>
 <dc:creator>Xu, Yao Lei</dc:creator>
 <dc:creator>Konstantinidis, Kriton</dc:creator>
 <dc:creator>Mandic, Danilo P.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Modern data sources are typically of large scale and multi-modal natures, and
acquired on irregular domains, which poses serious challenges to traditional
deep learning models. These issues are partially mitigated by either extending
existing deep learning algorithms to irregular domains through graphs, or by
employing tensor methods to alleviate the computational bottlenecks imposed by
the Curse of Dimensionality. To simultaneously resolve both these issues, we
introduce a novel Multi-Graph Tensor Network (MGTN) framework, which leverages
on the desirable properties of graphs, tensors and neural networks in a
physically meaningful and compact manner. This equips MGTNs with the ability to
exploit local information in irregular data sources at a drastically reduced
parameter complexity, and over a range of learning paradigms such as
regression, classification and reinforcement learning. The benefits of the MGTN
framework, especially its ability to avoid overfitting through the inherent
low-rank regularization properties of tensor networks, are demonstrated through
its superior performance against competing models in the individual tensor,
graph, and neural network domains.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:2010.13209</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.14998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15005</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strategically-Motivated Advanced Persistent Threat: Definition, Process,
  Tactics and a Disinformation Model of Counterattack</dc:title>
 <dc:creator>Ahmad, Atif</dc:creator>
 <dc:creator>Webb, Jeb</dc:creator>
 <dc:creator>Desouza, Kevin C.</dc:creator>
 <dc:creator>Boorman, James</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Advanced persistent threat (APT) is widely acknowledged to be the most
sophisticated and potent class of security threat. APT refers to knowledgeable
human attackers that are organized, highly sophisticated and motivated to
achieve their objectives against a targeted organization(s) over a prolonged
period. Strategically-motivated APTs or S-APTs are distinct in that they draw
their objectives from the broader strategic agenda of third parties such as
criminal syndicates, nation-states, and rival corporations. In this paper we
review the use of the term - Advanced Persistent Threat - and present a formal
definition. We then draw on military science, the science of organized
conflict, for a theoretical basis to develop a rigorous and holistic model of
the stages of an APT operation which we subsequently use to explain how S-APTs
execute their strategically motivated operations using tactics, techniques and
procedures. Finally, we present a general disinformation model, derived from
situation awareness theory, and explain how disinformation can be used to
attack the situation awareness and decision making of not only S-APT operators,
but also the entities that back them.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15005</dc:identifier>
 <dc:identifier>Computers &amp; Security, 2019, Vol 86, pp. 402-418</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15008</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning Schemes For Parabolic Nonlocal Integro-Differential
  Equations</dc:title>
 <dc:creator>Castro, Javier</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  In this paper we consider the numerical approximation of nonlocal integro
differential parabolic equations via neural networks. These equations appear in
many recent applications, including finance, biology and others, and have been
recently studied in great generality starting from the work of Caffarelli and
Silvestre. Based in the work by Hure, Pham and Warin, we generalize their Euler
scheme and consistency result for Backward Forward Stochastic Differential
Equations to the nonlocal case. We rely on L\`evy processes and a new neural
network approximation of the nonlocal part to overcome the lack of a suitable
good approximation of the nonlocal part of the solution.
</dc:description>
 <dc:description>Comment: 28 pages</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15024</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MT-lib: A Topology-aware Message Transfer Library for Graph500 on
  Supercomputers</dc:title>
 <dc:creator>Gan, Xinbiao</dc:creator>
 <dc:creator>Tan, Wen</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  We present MT-lib, an efficient message transfer library for messages gather
and scatter in benchmarks like Graph500 for Supercomputers. Our library
includes MST version as well as new-MST version. The MT-lib is deliberately
kept light-weight, efficient and friendly interfaces for massive graph
traverse. MST provides (1) a novel non-blocking communication scheme with
sending and receiving messages asynchronously to overlap calculation and
communication;(2) merging messages according to the target process for reducing
communication overhead;(3) a new communication mode of gathering intra-group
messages before forwarding between groups for reducing communication traffic.
In MT-lib, there are (1) one-sided message; (2) two-sided messages; and (3)
two-sided messages with buffer, in which dynamic buffer expansion is built for
messages delivery. We experimented with MST and then testing Graph500 with MST
on Tianhe supercomputers. Experimental results show high communication
efficiency and high throughputs for both BFS and SSSP communication operations.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15025</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Hallucination and Predictive Uncertainty in Conditional Language
  Generation</dc:title>
 <dc:creator>Xiao, Yijun</dc:creator>
 <dc:creator>Wang, William Yang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Despite improvements in performances on different natural language generation
tasks, deep neural models are prone to hallucinating facts that are incorrect
or nonexistent. Different hypotheses are proposed and examined separately for
different tasks, but no systematic explanations are available across these
tasks. In this study, we draw connections between hallucinations and predictive
uncertainty in conditional language generation. We investigate their
relationship in both image captioning and data-to-text generation and propose a
simple extension to beam search to reduce hallucination. Our analysis shows
that higher predictive uncertainty corresponds to a higher chance of
hallucination. Epistemic uncertainty is more indicative of hallucination than
aleatoric or total uncertainties. It helps to achieve better results of trading
performance in standard metric for less hallucination with the proposed beam
search variant.
</dc:description>
 <dc:description>Comment: EACL 2021</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15027</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Noise Injection-based Regularization for Point Cloud Processing</dc:title>
 <dc:creator>Zang, Xiao</dc:creator>
 <dc:creator>Xie, Yi</dc:creator>
 <dc:creator>Liao, Siyu</dc:creator>
 <dc:creator>Chen, Jie</dc:creator>
 <dc:creator>Yuan, Bo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Noise injection-based regularization, such as Dropout, has been widely used
in image domain to improve the performance of deep neural networks (DNNs).
However, efficient regularization in the point cloud domain is rarely
exploited, and most of the state-of-the-art works focus on data
augmentation-based regularization. In this paper, we, for the first time,
perform systematic investigation on noise injection-based regularization for
point cloud-domain DNNs. To be specific, we propose a series of regularization
techniques, namely DropFeat, DropPoint and DropCluster, to perform noise
injection on the point feature maps at the feature level, point level and
cluster level, respectively. We also empirically analyze the impacts of
different factors, including dropping rate, cluster size and dropping position,
to obtain useful insights and general deployment guidelines, which can
facilitate the adoption of our approaches across different datasets and DNN
architectures.
  We evaluate our proposed approaches on various DNN models for different point
cloud processing tasks. Experimental results show our approaches enable
significant performance improvement. Notably, our DropCluster brings 1.5%, 1.3%
and 0.8% higher overall accuracy for PointNet, PointNet++ and DGCNN,
respectively, on ModelNet40 shape classification dataset. On ShapeNet part
segmentation dataset, DropCluster brings 0.5%, 0.5% and 0.2% mean
Intersection-over-union (IoU) increase for PointNet, PointNet++ and DGCNN,
respectively. On S3DIS semantic segmentation dataset, DropCluster improves the
mean IoU of PointNet, PointNet++ and DGCNN by 3.2%, 2.9% and 3.7%,
respectively. Meanwhile, DropCluster also enables the overall accuracy increase
for these three popular backbone DNNs by 2.4%, 2.2% and 1.8%, respectively.
</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15038</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Control Ability with Time Attributy for Linear Continous-time Systems</dc:title>
 <dc:creator>Zhao, Mingwang</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper, the control ability with time attributy for the linear
continuous-time (LCT) systems are defined and analyzed by the volume computing
for the controllability region. Firstly, a relation theorem about the open-loop
control ability, the control strategy space (\textit{i.e.}, the solution space
of the input variable for control problems), and the some closed-loop
performance for the LCT systems is purposed and proven. This theorem shows us
the necessity to optimize the control ability for the practical engineering
problems. Secondly, recurssive volume-computing algorithms with the low
computing complexities for the finite-time controllability region are
discussed. Finally, two analytical volume computations of the infinite-time
controllability region for the systems with $n$ different and repeated real
eigenvalues are deduced, and then by deconstructing the volume computing
equations, 3 classes of the shape factors are constructed. These analytical
volume and shape factors can describe accurately the size and shape of the
controllability region. Because the time-attribute control ability for LCT
systems is directly related to the controllability region with the unit input
variables, based on these analytical expressions on the volume and shape
factors, the time-attribute control ability can be computed and optimized
conveniently.
</dc:description>
 <dc:description>Comment: 23 pages, 7 figures. arXiv admin note: substantial text overlap with
  arXiv:2004.07982, arXiv:2004.05619</dc:description>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15041</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accurate and Reliable Forecasting using Stochastic Differential
  Equations</dc:title>
 <dc:creator>Cui, Peng</dc:creator>
 <dc:creator>Deng, Zhijie</dc:creator>
 <dc:creator>Hu, Wenbo</dc:creator>
 <dc:creator>Zhu, Jun</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  It is critical yet challenging for deep learning models to properly
characterize uncertainty that is pervasive in real-world environments. Although
a lot of efforts have been made, such as heteroscedastic neural networks
(HNNs), little work has demonstrated satisfactory practicability due to the
different levels of compromise on learning efficiency, quality of uncertainty
estimates, and predictive performance. Moreover, existing HNNs typically fail
to construct an explicit interaction between the prediction and its associated
uncertainty. This paper aims to remedy these issues by developing SDE-HNN, a
new heteroscedastic neural network equipped with stochastic differential
equations (SDE) to characterize the interaction between the predictive mean and
variance of HNNs for accurate and reliable regression. Theoretically, we show
the existence and uniqueness of the solution to the devised neural SDE.
Moreover, based on the bias-variance trade-off for the optimization in SDE-HNN,
we design an enhanced numerical SDE solver to improve the learning stability.
Finally, to more systematically evaluate the predictive uncertainty, we present
two new diagnostic uncertainty metrics. Experiments on the challenging datasets
show that our method significantly outperforms the state-of-the-art baselines
in terms of both predictive performance and uncertainty quantification,
delivering well-calibrated and sharp prediction intervals.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15046</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Definition and Analytical Expression on State Observe Ability for Linear
  Discrete-time Systems with the Bounded Noise Energy</dc:title>
 <dc:creator>Zhao, Mingwang</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this article, the definition on the observe ability and its relation to
the signal detecting performance are studied systematically for the linear
discrete-time(LDT) systems. Firstly, to define and analyze the observe ability
for the practical systems with the measured noise, six kinds of bounded noise
models are classified. For the noise energy bounded case, the observability
ellipsoid and the image observability ellipsoid are defined by the state
observed error and then a novel concept on the LDT systems, called as the
observe ability, is proposed. Based on that, some theorems and properties about
the observe ability and the signal detecting performances are given and proven,
and then the reason that to maximize the observe ability is to optimize the
signal detecting performances is established. Secondly, a dual relation between
the observability ellipsoid and the controllability ellipsoid, which volumes
and radii are respectively with some inverse relations, is stated and proven.
Accordingly, the analytical computing equations for the volume of the two
observability ellipsoids are got and some analytical shape factors of these
ellipsoids are deconstructed. Based on these effective compting for the
volumes, radii, and shape factors, analyzing and optimizing for the observe
ability can be carried out. Thirdly, to compare rationally the state observe
ability between the different systems or different system parameters, the
normalization of the output variables, the state variables, and the system
models are discussed. Finally, some numerical experiments and their results
show the effectiveness of the computing and comparing methods for the observe
ability.
</dc:description>
 <dc:description>Comment: 31pages, 8figures</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15048</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Affective Approach for Behavioral Performance Estimation and
  Induction</dc:title>
 <dc:creator>Alfatlawi, Mustaffa</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>68T07 65C20 60G15</dc:subject>
 <dc:description>  Emotions have a major interactive role in defining how humans interact with
their environment by encoding their perception to external events and
accordingly, influencing their cognition and decision-making process.
Therefore, increasing attention has been directed toward integrating human
affective states into system design in order to optimize the quality of task
performance. In this work, we seize on the significant correlation between
emotions and behavioral performance that is reported in several psychological
studies and develop an online closed-loop design framework for Human-Robot
Interaction (HRI). The proposed approach monitors the behavioral performance
based on the levels of Pleasure, Arousal, and Dominance (PAD) states for the
human operator and when required, applies an external stimulus which is
selected to induce an improvement in performance. The framework is implemented
on an HRI task involving a human operator teleoperating an articulated robotic
manipulator. Our statistical analysis shows a significant decrease in pleasure,
arousal, and dominance states as the behavioral performance deteriorates $(p &lt;
0.05)$. Our closed-loop experiment that uses an audio stimulus to improve
emotional state shows a significant improvement in the behavioral performance
of certain subjects.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15053</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Autonomy in Human-on-the-Loop Vision-Based Robotics Systems</dc:title>
 <dc:creator>Abraham, Sophia</dc:creator>
 <dc:creator>Carmichael, Zachariah</dc:creator>
 <dc:creator>Banerjee, Sreya</dc:creator>
 <dc:creator>VidalMata, Rosaura</dc:creator>
 <dc:creator>Agrawal, Ankit</dc:creator>
 <dc:creator>Islam, Md Nafee Al</dc:creator>
 <dc:creator>Scheirer, Walter</dc:creator>
 <dc:creator>Cleland-Huang, Jane</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Computer vision approaches are widely used by autonomous robotic systems to
sense the world around them and to guide their decision making as they perform
diverse tasks such as collision avoidance, search and rescue, and object
manipulation. High accuracy is critical, particularly for Human-on-the-loop
(HoTL) systems where decisions are made autonomously by the system, and humans
play only a supervisory role. Failures of the vision model can lead to
erroneous decisions with potentially life or death consequences. In this paper,
we propose a solution based upon adaptive autonomy levels, whereby the system
detects loss of reliability of these models and responds by temporarily
lowering its own autonomy levels and increasing engagement of the human in the
decision-making process. Our solution is applicable for vision-based tasks in
which humans have time to react and provide guidance. When implemented, our
approach would estimate the reliability of the vision task by considering
uncertainty in its model, and by performing covariate analysis to determine
when the current operating environment is ill-matched to the model's training
data. We provide examples from DroneResponse, in which small Unmanned Aerial
Systems are deployed for Emergency Response missions, and show how the vision
model's reliability would be used in addition to confidence scores to drive and
specify the behavior and adaptation of the system's autonomy. This workshop
paper outlines our proposed approach and describes open challenges at the
intersection of Computer Vision and Software Engineering for the safe and
reliable deployment of vision models in the decision making of autonomous
systems.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15055</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Friends and Foes in Learning from Noisy Labels</dc:title>
 <dc:creator>Zhou, Yifan</dc:creator>
 <dc:creator>Ge, Yifan</dc:creator>
 <dc:creator>Wu, Jianxin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Learning from examples with noisy labels has attracted increasing attention
recently. But, this paper will show that the commonly used CIFAR-based datasets
and the accuracy evaluation metric used in the literature are both
inappropriate in this context. An alternative valid evaluation metric and new
datasets are proposed in this paper to promote proper research and evaluation
in this area. Then, friends and foes are identified from existing methods as
technical components that are either beneficial or detrimental to deep learning
from noisy labeled examples, respectively, and this paper improves and combines
technical components from the friends category, including self-supervised
learning, new warmup strategy, instance filtering and label correction. The
resulting F&amp;F method significantly outperforms existing methods on the proposed
nCIFAR datasets and the real-world Clothing1M dataset.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15062</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coordinated Motion Planning Through Randomized k-Opt</dc:title>
 <dc:creator>Liu, Paul</dc:creator>
 <dc:creator>Spalding-Jamieson, Jack</dc:creator>
 <dc:creator>Zhang, Brandon</dc:creator>
 <dc:creator>Zheng, Da Wei</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper examines the approach taken by team gitastrophe in the CG:SHOP
2021 challenge. The challenge was to find a sequence of simultaneous moves of
square robots between two given configurations that minimized either total
distance travelled or makespan (total time). Our winning approach has two main
components: an initialization phase that finds a good initial solution, and a
$k$-opt local search phase which optimizes this solution. This led to a first
place finish in the distance category and a third place finish in the makespan
category.
</dc:description>
 <dc:description>Comment: To appear in SoCG 2021</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15068</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ManhattanSLAM: Robust Planar Tracking and Mapping Leveraging Mixture of
  Manhattan Frames</dc:title>
 <dc:creator>Yunus, Raza</dc:creator>
 <dc:creator>Li, Yanyan</dc:creator>
 <dc:creator>Tombari, Federico</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper, a robust RGB-D SLAM system is proposed to utilize the
structural information in indoor scenes, allowing for accurate tracking and
efficient dense mapping on a CPU. Prior works have used the Manhattan World
(MW) assumption to estimate low-drift camera pose, in turn limiting the
applications of such systems. This paper, in contrast, proposes a novel
approach delivering robust tracking in MW and non-MW environments. We check
orthogonal relations between planes to directly detect Manhattan Frames,
modeling the scene as a Mixture of Manhattan Frames. For MW scenes, we decouple
pose estimation and provide a novel drift-free rotation estimation based on
Manhattan Frame observations. For translation estimation in MW scenes and full
camera pose estimation in non-MW scenes, we make use of point, line and plane
features for robust tracking in challenging scenes. %mapping Additionally, by
exploiting plane features detected in each frame, we also propose an efficient
surfel-based dense mapping strategy, which divides each image into planar and
non-planar regions. Planar surfels are initialized directly from sparse planes
in our map while non-planar surfels are built by extracting superpixels. We
evaluate our method on public benchmarks for pose estimation, drift and
reconstruction accuracy, achieving superior performance compared to other
state-of-the-art methods. We will open-source our code in the future.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15068</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15072</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Ethical Hacking: Issues and Challenges</dc:title>
 <dc:creator>Yaacoub, Jean-Paul A.</dc:creator>
 <dc:creator>Noura, Hassan N.</dc:creator>
 <dc:creator>Salman, Ola</dc:creator>
 <dc:creator>Chehab, Ali</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Security attacks are growing in an exponential manner and their impact on
existing systems is seriously high and can lead to dangerous consequences.
However, in order to reduce the effect of these attacks, penetration tests are
highly required, and can be considered as a suitable solution for this task.
Therefore, the main focus of this paper is to explain the technical and
non-technical steps of penetration tests. The objective of penetration tests is
to make existing systems and their corresponding data more secure, efficient
and resilient. In other terms, pen testing is a simulated attack with the goal
of identifying any exploitable vulnerability or/and a security gap. In fact,
any identified exploitable vulnerability will be used to conduct attacks on
systems, devices, or personnel. This growing problem should be solved and
mitigated to reach better resistance against these attacks. Moreover, the
advantages and limitations of penetration tests are also listed. The main issue
of penetration tests that it is efficient to detect known vulnerabilities.
Therefore, in order to resist unknown vulnerabilities, a new kind of modern
penetration tests is required, in addition to reinforcing the use of shadows
honeypots. This can also be done by reinforcing the anomaly detection of
intrusion detection/prevention system. In fact, security is increased by
designing an efficient cooperation between the different security elements and
penetration tests.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15073</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IUP: An Intelligent Utility Prediction Scheme for Solid-State
  Fermentation in 5G IoT</dc:title>
 <dc:creator>Wang, Min</dc:creator>
 <dc:creator>Pang, Shanchen</dc:creator>
 <dc:creator>Ding, Tong</dc:creator>
 <dc:creator>Qiao, Sibo</dc:creator>
 <dc:creator>Zhai, Xue</dc:creator>
 <dc:creator>Wang, Shuo</dc:creator>
 <dc:creator>Xiong, Neal N.</dc:creator>
 <dc:creator>Huang, Zhengwen</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  At present, SOILD-STATE Fermentation (SSF) is mainly controlled by artificial
experience, and the product quality and yield are not stable. Accurately
predicting the quality and yield of SSF is of great significance for improving
human food security and supply. In this paper, we propose an Intelligent
Utility Prediction (IUP) scheme for SSF in 5G Industrial Internet of Things
(IoT), including parameter collection and utility prediction of SSF process.
This IUP scheme is based on the environmental perception and intelligent
learning algorithms of the 5G Industrial IoT. We build a workflow model based
on rewritable petri net to verify the correctness of the system model function
and process. In addition, we design a utility prediction model for SSF based on
the Generative Adversarial Networks (GAN) and Fully Connected Neural Network
(FCNN). We design a GAN with constraint of mean square error (MSE-GAN) to solve
the problem of few-shot learning of SSF, and then combine with the FCNN to
realize the utility prediction (usually use the alcohol) of SSF. Based on the
production of liquor in laboratory, the experiments show that the proposed
method is more accurate than the other prediction methods in the utility
prediction of SSF, and provide the basis for the numerical analysis of the
proportion of preconfigured raw materials and the appropriate setting of cellar
temperature.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15073</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15075</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PENELOPIE: Enabling Open Information Extraction for the Greek Language
  through Machine Translation</dc:title>
 <dc:creator>Papadopoulos, Dimitris</dc:creator>
 <dc:creator>Papadakis, Nikolaos</dc:creator>
 <dc:creator>Matsatsinis, Nikolaos</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper we present our submission for the EACL 2021 SRW; a methodology
that aims at bridging the gap between high and low-resource languages in the
context of Open Information Extraction, showcasing it on the Greek language.
The goals of this paper are twofold: First, we build Neural Machine Translation
(NMT) models for English-to-Greek and Greek-to-English based on the Transformer
architecture. Second, we leverage these NMT models to produce English
translations of Greek text as input for our NLP pipeline, to which we apply a
series of pre-processing and triple extraction tasks. Finally, we
back-translate the extracted triples to Greek. We conduct an evaluation of both
our NMT and OIE methods on benchmark datasets and demonstrate that our approach
outperforms the current state-of-the-art for the Greek natural language.
</dc:description>
 <dc:description>Comment: 16th conference of the European Chapter of the Association for
  Computational Linguistics Student Research Workshop (EACL 2021 SRW)</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15075</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15076</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Picasso: A CUDA-based Library for Deep Learning over 3D Meshes</dc:title>
 <dc:creator>Lei, Huan</dc:creator>
 <dc:creator>Akhtar, Naveed</dc:creator>
 <dc:creator>Mian, Ajmal</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present Picasso, a CUDA-based library comprising novel modules for deep
learning over complex real-world 3D meshes. Hierarchical neural architectures
have proved effective in multi-scale feature extraction which signifies the
need for fast mesh decimation. However, existing methods rely on CPU-based
implementations to obtain multi-resolution meshes. We design GPU-accelerated
mesh decimation to facilitate network resolution reduction efficiently
on-the-fly. Pooling and unpooling modules are defined on the vertex clusters
gathered during decimation. For feature learning over meshes, Picasso contains
three types of novel convolutions namely, facet2vertex, vertex2facet, and
facet2facet convolution. Hence, it treats a mesh as a geometric structure
comprising vertices and facets, rather than a spatial graph with edges as
previous methods do. Picasso also incorporates a fuzzy mechanism in its filters
for robustness to mesh sampling (vertex density). It exploits Gaussian mixtures
to define fuzzy coefficients for the facet2vertex convolution, and barycentric
interpolation to define the coefficients for the remaining two convolutions. In
this release, we demonstrate the effectiveness of the proposed modules with
competitive segmentation results on S3DIS. The library will be made public
through https://github.com/hlei-ziyan/Picasso.
</dc:description>
 <dc:description>Comment: Accepted to CVPR2021</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15076</dc:identifier>
 <dc:identifier>CVPR,2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15086</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Placeholders for Open-Set Recognition</dc:title>
 <dc:creator>Zhou, Da-Wei</dc:creator>
 <dc:creator>Ye, Han-Jia</dc:creator>
 <dc:creator>Zhan, De-Chuan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Traditional classifiers are deployed under closed-set setting, with both
training and test classes belong to the same set. However, real-world
applications probably face the input of unknown categories, and the model will
recognize them as known ones. Under such circumstances, open-set recognition is
proposed to maintain classification performance on known classes and reject
unknowns. The closed-set models make overconfident predictions over familiar
known class instances, so that calibration and thresholding across categories
become essential issues when extending to an open-set environment. To this end,
we proposed to learn PlaceholdeRs for Open-SEt Recognition (Proser), which
prepares for the unknown classes by allocating placeholders for both data and
classifier. In detail, learning data placeholders tries to anticipate open-set
class data, thus transforms closed-set training into open-set training.
Besides, to learn the invariant information between target and non-target
classes, we reserve classifier placeholders as the class-specific boundary
between known and unknown. The proposed Proser efficiently generates novel
class by manifold mixup, and adaptively sets the value of reserved open-set
classifier during training. Experiments on various datasets validate the
effectiveness of our proposed method.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2021 as an Oral Presentation</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15086</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15088</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ACSNet: Action-Context Separation Network for Weakly Supervised Temporal
  Action Localization</dc:title>
 <dc:creator>Liu, Ziyi</dc:creator>
 <dc:creator>Wang, Le</dc:creator>
 <dc:creator>Zhang, Qilin</dc:creator>
 <dc:creator>Tang, Wei</dc:creator>
 <dc:creator>Yuan, Junsong</dc:creator>
 <dc:creator>Zheng, Nanning</dc:creator>
 <dc:creator>Hua, Gang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The object of Weakly-supervised Temporal Action Localization (WS-TAL) is to
localize all action instances in an untrimmed video with only video-level
supervision. Due to the lack of frame-level annotations during training,
current WS-TAL methods rely on attention mechanisms to localize the foreground
snippets or frames that contribute to the video-level classification task. This
strategy frequently confuse context with the actual action, in the localization
result. Separating action and context is a core problem for precise WS-TAL, but
it is very challenging and has been largely ignored in the literature. In this
paper, we introduce an Action-Context Separation Network (ACSNet) that
explicitly takes into account context for accurate action localization. It
consists of two branches (i.e., the Foreground-Background branch and the
Action-Context branch). The Foreground- Background branch first distinguishes
foreground from background within the entire video while the Action-Context
branch further separates the foreground as action and context. We associate
video snippets with two latent components (i.e., a positive component and a
negative component), and their different combinations can effectively
characterize foreground, action and context. Furthermore, we introduce extended
labels with auxiliary context categories to facilitate the learning of
action-context separation. Experiments on THUMOS14 and ActivityNet v1.2/v1.3
datasets demonstrate the ACSNet outperforms existing state-of-the-art WS-TAL
methods by a large margin.
</dc:description>
 <dc:description>Comment: Accepted by the 35th AAAI Conference on Artificial Intelligence (AAAI
  2021)</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15088</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15089</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Autoregressive Modeling with Distribution Smoothing</dc:title>
 <dc:creator>Meng, Chenlin</dc:creator>
 <dc:creator>Song, Jiaming</dc:creator>
 <dc:creator>Song, Yang</dc:creator>
 <dc:creator>Zhao, Shengjia</dc:creator>
 <dc:creator>Ermon, Stefano</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While autoregressive models excel at image compression, their sample quality
is often lacking. Although not realistic, generated images often have high
likelihood according to the model, resembling the case of adversarial examples.
Inspired by a successful adversarial defense method, we incorporate randomized
smoothing into autoregressive generative modeling. We first model a smoothed
version of the data distribution, and then reverse the smoothing process to
recover the original data distribution. This procedure drastically improves the
sample quality of existing autoregressive models on several synthetic and
real-world image datasets while obtaining competitive likelihoods on synthetic
datasets.
</dc:description>
 <dc:description>Comment: ICLR 2021 (Oral)</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15089</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15090</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Playing Against the Board: Rolling Horizon Evolutionary Algorithms
  Against Pandemic</dc:title>
 <dc:creator>Sfikas, Konstantinos</dc:creator>
 <dc:creator>Liapis, Antonios</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Competitive board games have provided a rich and diverse testbed for
artificial intelligence. This paper contends that collaborative board games
pose a different challenge to artificial intelligence as it must balance
short-term risk mitigation with long-term winning strategies. Collaborative
board games task all players to coordinate their different powers or pool their
resources to overcome an escalating challenge posed by the board and a
stochastic ruleset. This paper focuses on the exemplary collaborative board
game Pandemic and presents a rolling horizon evolutionary algorithm designed
specifically for this game. The complex way in which the Pandemic game state
changes in a stochastic but predictable way required a number of specially
designed forward models, macro-action representations for decision-making, and
repair functions for the genetic operations of the evolutionary algorithm.
Variants of the algorithm which explore optimistic versus pessimistic game
state evaluations, different mutation rates and event horizons are compared
against a baseline hierarchical policy agent. Results show that an evolutionary
approach via short-horizon rollouts can better account for the future dangers
that the board may introduce, and guard against them. Results highlight the
types of challenges that collaborative board games pose to artificial
intelligence, especially for handling multi-player collaboration interactions.
</dc:description>
 <dc:description>Comment: Accepted to IEEE Transactions on Games, 11 pages, 7 figures. arXiv
  admin note: text overlap with arXiv:2103.11388</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15090</dc:identifier>
 <dc:identifier>doi:10.1109/TG.2021.3069766</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15093</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Representation Learning by Ranking under multiple tasks</dc:title>
 <dc:creator>Gu, Lifeng</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In recent years, representation learning has become the research focus of the
machine learning community. Large-scale pre-training neural networks have
become the first step to realize general intelligence. The key to the success
of neural networks lies in their abstract representation capabilities for data.
Several learning fields are actually discussing how to learn representations
and there lacks a unified perspective. We convert the representation learning
problem under multiple tasks into a ranking problem, taking the ranking problem
as a unified perspective, the representation learning under different tasks is
solved by optimizing the approximate NDCG loss. Experiments under different
learning tasks like classification, retrieval, multi-label learning,
regression, self-supervised learning prove the superiority of approximate NDCG
loss. Further, under the self-supervised learning task, the training data is
transformed by data augmentation method to improve the performance of the
approximate NDCG loss, which proves that the approximate NDCG loss can make
full use of the information of the unsupervised training data.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15093</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15099</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BA^2M: A Batch Aware Attention Module for Image Classification</dc:title>
 <dc:creator>Cheng, Qishang</dc:creator>
 <dc:creator>Li, Hongliang</dc:creator>
 <dc:creator>Wu, Qingbo</dc:creator>
 <dc:creator>Ngan, King Ngi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The attention mechanisms have been employed in Convolutional Neural Network
(CNN) to enhance the feature representation. However, existing attention
mechanisms only concentrate on refining the features inside each sample and
neglect the discrimination between different samples. In this paper, we propose
a batch aware attention module (BA2M) for feature enrichment from a distinctive
perspective. More specifically, we first get the sample-wise attention
representation (SAR) by fusing the channel, local spatial and global spatial
attention maps within each sample. Then, we feed the SARs of the whole batch to
a normalization function to get the weights for each sample. The weights serve
to distinguish the features' importance between samples in a training batch
with different complexity of content. The BA2M could be embedded into different
parts of CNN and optimized with the network in an end-to-end manner. The design
of BA2M is lightweight with few extra parameters and calculations. We validate
BA2M through extensive experiments on CIFAR-100 and ImageNet-1K for the image
recognition task. The results show that BA2M can boost the performance of
various network architectures and outperforms many classical attention methods.
Besides, BA2M exceeds traditional methods of re-weighting samples based on the
loss value.
</dc:description>
 <dc:description>Comment: 11 pages, 5 figures</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15103</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phism: Polyhedral High-Level Synthesis in MLIR</dc:title>
 <dc:creator>Zhao, Ruizhe</dc:creator>
 <dc:creator>Cheng, Jianyi</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Polyhedral optimisation, a methodology that views nested loops as polyhedra
and searches for their optimal transformation regarding specific objectives
(parallelism, locality, etc.), sounds promising for mitigating difficulties in
automatically optimising hardware designs described by high-level synthesis
(HLS), which are typically software programs with nested loops. Nevertheless,
existing polyhedral tools cannot meet the requirements from HLS developers for
platform-specific customisation and software/hardware co-optimisation. This
paper proposes $\phi_{sm}$ (phism), a polyhedral HLS framework built on MLIR,
to address these challenges through progressive lowering multi-level
intermediate representations (IRs) from polyhedra to HLS designs.
</dc:description>
 <dc:description>Comment: Will be presented at LATTE'21</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15103</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15105</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Single Object Tracking through a Fast and Effective Single-Multiple
  Model Convolutional Neural Network</dc:title>
 <dc:creator>Lotfi, Faraz</dc:creator>
 <dc:creator>Taghirad, Hamid D.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Object tracking becomes critical especially when similar objects are present
in the same area. Recent state-of-the-art (SOTA) approaches are proposed based
on taking a matching network with a heavy structure to distinguish the target
from other objects in the area which indeed drastically downgrades the
performance of the tracker in terms of speed. Besides, several candidates are
considered and processed to localize the intended object in a region of
interest for each frame which is time-consuming. In this article, a special
architecture is proposed based on which in contrast to the previous approaches,
it is possible to identify the object location in a single shot while taking
its template into account to distinguish it from the similar objects in the
same area. In brief, first of all, a window containing the object with twice
the target size is considered. This window is then fed into a fully
convolutional neural network (CNN) to extract a region of interest (RoI) in a
form of a matrix for each of the frames. In the beginning, a template of the
target is also taken as the input to the CNN. Considering this RoI matrix, the
next movement of the tracker is determined based on a simple and fast method.
Moreover, this matrix helps to estimate the object size which is crucial when
it changes over time. Despite the absence of a matching network, the presented
tracker performs comparatively with the SOTA in challenging situations while
having a super speed compared to them (up to $120 FPS$ on 1080ti). To
investigate this claim, a comparison study is carried out on the GOT-10k
dataset. Results reveal the outstanding performance of the proposed method in
fulfilling the task.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15107</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Relationship Alignment Metric Learning</dc:title>
 <dc:creator>Gu, Lifeng</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Most existing metric learning methods focus on learning a similarity or
distance measure relying on similar and dissimilar relations between sample
pairs. However, pairs of samples cannot be simply identified as similar or
dissimilar in many real-world applications, e.g., multi-label learning, label
distribution learning. To this end, relation alignment metric learning (RAML)
framework is proposed to handle the metric learning problem in those scenarios.
But RAML learn a linear metric, which can't model complex datasets. Combining
with deep learning and RAML framework, we propose a hierarchical relationship
alignment metric leaning model HRAML, which uses the concept of relationship
alignment to model metric learning problems under multiple learning tasks, and
makes full use of the consistency between the sample pair relationship in the
feature space and the sample pair relationship in the label space. Further we
organize several experiment divided by learning tasks, and verified the better
performance of HRAML against many popular methods and RAML framework.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15107</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15108</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Meta-Mining Discriminative Samples for Kinship Verification</dc:title>
 <dc:creator>Li, Wanhua</dc:creator>
 <dc:creator>Wang, Shiwei</dc:creator>
 <dc:creator>Lu, Jiwen</dc:creator>
 <dc:creator>Feng, Jianjiang</dc:creator>
 <dc:creator>Zhou, Jie</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Kinship verification aims to find out whether there is a kin relation for a
given pair of facial images. Kinship verification databases are born with
unbalanced data. For a database with N positive kinship pairs, we naturally
obtain N(N-1) negative pairs. How to fully utilize the limited positive pairs
and mine discriminative information from sufficient negative samples for
kinship verification remains an open issue. To address this problem, we propose
a Discriminative Sample Meta-Mining (DSMM) approach in this paper. Unlike
existing methods that usually construct a balanced dataset with fixed negative
pairs, we propose to utilize all possible pairs and automatically learn
discriminative information from data. Specifically, we sample an unbalanced
train batch and a balanced meta-train batch for each iteration. Then we learn a
meta-miner with the meta-gradient on the balanced meta-train batch. In the end,
the samples in the unbalanced train batch are re-weighted by the learned
meta-miner to optimize the kinship models. Experimental results on the widely
used KinFaceW-I, KinFaceW-II, TSKinFace, and Cornell Kinship datasets
demonstrate the effectiveness of the proposed approach.
</dc:description>
 <dc:description>Comment: Accepted by CVPR2021</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15108</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15113</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Short Introduction to Information-Theoretic Cost-Benefit Analysis</dc:title>
 <dc:creator>Chen, Min</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  This arXiv report provides a short introduction to the information-theoretic
measure proposed by Chen and Golan in 2016 for analyzing machine- and
human-centric processes in data intelligence workflows. This introduction was
compiled based on several appendices written to accompany a few research papers
on topics of data visualization and visual analytics. Although the original
2016 paper and the follow-on papers were mostly published in the field of
visualization and visual analytics, the cost-benefit measure can help explain
the informative trade-off in a wide range of data intelligence phenomena
including machine learning, human cognition, language development, and so on.
Meanwhile, there is an ongoing effort to improve its mathematical properties in
order to make it more intuitive and usable in practical applications as a
measurement tool.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:2103.02502;
  text overlap with arXiv:2103.02505</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15113</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15114</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Explaining Representation by Mutual Information</dc:title>
 <dc:creator>Gu, Lifeng</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Science is used to discover the law of world. Machine learning can be used to
discover the law of data. In recent years, there are more and more research
about interpretability in machine learning community. We hope the machine
learning methods are safe, interpretable, and they can help us to find
meaningful pattern in data. In this paper, we focus on interpretability of deep
representation. We propose a interpretable method of representation based on
mutual information, which summarizes the interpretation of representation into
three types of information between input data and representation. We further
proposed MI-LR module, which can be inserted into the model to estimate the
amount of information to explain the model's representation. Finally, we verify
the method through the visualization of the prototype network.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15125</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Bose-Einstein Statistics for Indistinguishable Concepts in Human
  Language</dc:title>
 <dc:creator>Beltran, Lester</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  We investigate the hypothesis that within a combination of a 'number concept'
plus a 'substantive concept', such as 'eleven animals,' the identity and
indistinguishability present on the level of the concepts, i.e., all eleven
animals are identical and indistinguishable, gives rise to a statistical
structure of the Bose-Einstein type similar to how Bose-Einstein statistics is
present for identical and indistinguishable quantum particles. We proceed by
identifying evidence for this hypothesis by extracting the statistical data
from the World-Wide-Web utilizing the Google Search tool. By using the
Kullback-Leibler divergence method, we then compare the obtained distribution
with the Maxwell-Boltzmann as well as with the Bose-Einstein distributions and
show that the Bose-Einstein's provides a better fit as compared to the
Maxwell-Boltzmanns.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15128</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressibility of Network Opinion and Spread States in the
  Laplacian-Eigenvector Basis</dc:title>
 <dc:creator>Roy, Sandip</dc:creator>
 <dc:creator>Xue, Mengran</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Opinion-evolution and spread processes on networks (e.g., infectious disease
spread, opinion formation in social networks) are not only high dimensional but
also volatile and multiscale in nature. In this study, we explore whether
snapshot data from these processes can admit terse representations.
Specifically, using three case studies, we explore whether the data are
compressible in the Laplacian-eigenvector basis, in the sense that each
snapshot can be approximated well using a (possibly different) small set of
basis vectors. The first case study is concerned with a linear consensus model
that is subject to a stochastic input at an unknown location; both empirical
and formal analyses are used to characterize compressibility. Second,
compressibility of state snapshots for a stochastic voter model is assessed via
an empirical study. Finally, compressibility is studied for state-level daily
COVID-19 positivity-rate data. The three case studies indicate that state
snapshots from opinion-evolution and spread processes allow terse
representations, which nevertheless capture their rich propagative dynamics.
</dc:description>
 <dc:description>Comment: Submitted to the 2021 IEEE Conference on Decision and Control</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15136</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Imponderous Net for Facial Expression Recognition in the Wild</dc:title>
 <dc:creator>Gera, Darshan</dc:creator>
 <dc:creator>Balasubramanian, S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Since the renaissance of deep learning (DL), facial expression recognition
(FER) has received a lot of interest, with continual improvement in the
performance. Hand-in-hand with performance, new challenges have come up. Modern
FER systems deal with face images captured under uncontrolled conditions (also
called in-the-wild scenario) including occlusions and pose variations. They
successfully handle such conditions using deep networks that come with various
components like transfer learning, attention mechanism and local-global context
extractor. However, these deep networks are highly complex with large number of
parameters, making them unfit to be deployed in real scenarios. Is it possible
to build a light-weight network that can still show significantly good
performance on FER under in-the-wild scenario? In this work, we methodically
build such a network and call it as Imponderous Net. We leverage on the
aforementioned components of deep networks for FER, and analyse, carefully
choose and fit them to arrive at Imponderous Net. Our Imponderous Net is a low
calorie net with only 1.45M parameters, which is almost 50x less than that of a
state-of-the-art (SOTA) architecture. Further, during inference, it can process
at the real time rate of 40 frames per second (fps) in an intel-i7 cpu. Though
it is low calorie, it is still power packed in its performance, overpowering
other light-weight architectures and even few high capacity architectures.
Specifically, Imponderous Net reports 87.09\%, 88.17\% and 62.06\% accuracies
on in-the-wild datasets RAFDB, FERPlus and AffectNet respectively. It also
exhibits superior robustness under occlusions and pose variations in comparison
to other light-weight architectures from the literature.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15144</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Face Recognition as a Method of Authentication in a Web-Based System</dc:title>
 <dc:creator>Mugalu, Ben Wycliff</dc:creator>
 <dc:creator>Wamala, Rodrick Calvin</dc:creator>
 <dc:creator>Serugunda, Jonathan</dc:creator>
 <dc:creator>Katumba, Andrew</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Online information systems currently heavily rely on the username and
password traditional method for protecting information and controlling access.
With the advancement in biometric technology and popularity of fields like AI
and Machine Learning, biometric security is becoming increasingly popular
because of the usability advantage. This paper reports how machine learning
based face recognition can be integrated into a web-based system as a method of
authentication to reap the benefits of improved usability. This paper includes
a comparison of combinations of detection and classification algorithms with
FaceNet for face recognition. The results show that a combination of MTCNN for
detection, Facenet for generating embeddings, and LinearSVC for classification
outperforms other combinations with a 95% accuracy. The resulting classifier is
integrated into the web-based system and used for authenticating users.
</dc:description>
 <dc:description>Comment: 7 pages, 9 figures, National Conference on Communications</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15144</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15152</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Processing Techniques for identifying tumors in an MRI image</dc:title>
 <dc:creator>John, Jacob</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Medical Resonance Imaging or MRI is a medical image processing technique that
used radio waves to scan the body. It is a tomographic imaging technique,
principally used in the field of radiology. With the advantage of being a
painless diagnostic procedure, MRI allows medical personnel to illustrate clear
pictures of the anatomy and the physiological processes occurring in the body,
thus allowing early detection and treatment of diseases. These images, combined
with image processing techniques may be used in the detection of tumors,
difficult to identify with the naked eye. This digital assignment surveys the
different image processing techniques used in Automated Tumor Detection (ATD).
This assignment initiates the discussion with a comparison of traditional
techniques such as Morphological Tools (MT) and Region Growing Technique (RGT).
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15152</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15157</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entropy methods for the confidence assessment of probabilistic
  classification models</dc:title>
 <dc:creator>Tornetta, Gabriele N.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  Many classification models produce a probability distribution as the outcome
of a prediction. This information is generally compressed down to the single
class with the highest associated probability. In this paper, we argue that
part of the information that is discarded in this process can be in fact used
to further evaluate the goodness of models, and in particular the confidence
with which each prediction is made. As an application of the ideas presented in
this paper, we provide a theoretical explanation of a confidence degradation
phenomenon observed in the complement approach to the (Bernoulli) Naive Bayes
generative model.
</dc:description>
 <dc:description>Comment: 12 pages, 7 figures</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15157</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15158</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Defect-GAN: High-Fidelity Defect Synthesis for Automated Defect
  Inspection</dc:title>
 <dc:creator>Zhang, Gongjie</dc:creator>
 <dc:creator>Cui, Kaiwen</dc:creator>
 <dc:creator>Hung, Tzu-Yi</dc:creator>
 <dc:creator>Lu, Shijian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automated defect inspection is critical for effective and efficient
maintenance, repair, and operations in advanced manufacturing. On the other
hand, automated defect inspection is often constrained by the lack of defect
samples, especially when we adopt deep neural networks for this task. This
paper presents Defect-GAN, an automated defect synthesis network that generates
realistic and diverse defect samples for training accurate and robust defect
inspection networks. Defect-GAN learns through defacement and restoration
processes, where the defacement generates defects on normal surface images
while the restoration removes defects to generate normal images. It employs a
novel compositional layer-based architecture for generating realistic defects
within various image backgrounds with different textures and appearances. It
can also mimic the stochastic variations of defects and offer flexible control
over the locations and categories of the generated defects within the image
background. Extensive experiments show that Defect-GAN is capable of
synthesizing various defects with superior diversity and fidelity. In addition,
the synthesized defect samples demonstrate their effectiveness in training
better defect inspection networks.
</dc:description>
 <dc:description>Comment: Codes will not be released due to confidentiality agreement.
  Published on WACV 2021.
  (https://openaccess.thecvf.com/content/WACV2021/papers/Zhang_Defect-GAN_High-Fidelity_Defect_Synthesis_for_Automated_Defect_Inspection_WACV_2021_paper.pdf)</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15158</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15162</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Call Graph Constructor for Maven</dc:title>
 <dc:creator>Keshani, Mehdi</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  As a rich source of data, Call Graphs are used for various applications
including security vulnerability detection. Despite multiple studies showing
that Call Graphs can drastically improve the accuracy of analysis, existing
ecosystem-scale tools like Dependabot do not use Call Graphs and work at the
package-level. Using Call Graphs in ecosystem use cases is not practical
because of the scalability problems that Call Graph generators have. Call Graph
generation is usually considered to be a &quot;full program analysis&quot; resulting in
large Call Graphs and expensive computation. To make an analysis applicable to
ecosystem scale, this pragmatic approach does not work, because the number of
possible combinations of how a particular artifact can be combined in a full
program explodes. Therefore, it is necessary to make the analysis incremental.
There are existing studies on different types of incremental program analysis.
However, none of them focuses on Call Graph generation for an entire ecosystem.
In this paper, we propose an incremental implementation of the CHA algorithm
that can generate Call Graphs on-demand, by stitching together partial Call
Graphs that have been extracted for libraries before. Our preliminary
evaluation results show that the proposed approach scales well and outperforms
the most scalable existing framework called OPAL.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15162</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15164</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy-Assured Outsourcing of Compressed Sensing Reconstruction Service
  in Cloud</dc:title>
 <dc:creator>Wang, Ping</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  Compressed sensing (CS), breaking the constriction of Shannon-Nyquist
sampling theorem, is a very promising data acquisition technique in the era of
multimedia big data. However, the high complexity of CS reconstruction
algorithm is a big trouble for endusers who are hardly provided with great
computing power. The combination of CS and cloud has the potential of freeing
endusers from the resource constraint by cleverly transforming computational
workload from the local cilent to the cloud platform. As a result, the
low-complexity encoding virtue of CS is fully leveraged in the
resource-constrained sensing devices but its highcomplexity decoding problem is
effectively addressed in cloud. It seems to be perfect but privacy and security
concerns are ignored. In this paper, a secure outsourcing scheme for CS
reconstruction service is proposed. Experimental results and security analyses
demonstrate that the proposed scheme can restrict malicious access, verify the
integrity of the recovered data, and resist brute-force attack, ciphertext-only
attack, and plaintext attack.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15171</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bayesian Approach to Identifying Representational Errors</dc:title>
 <dc:creator>Ramakrishnan, Ramya</dc:creator>
 <dc:creator>Unhelkar, Vaibhav</dc:creator>
 <dc:creator>Kamar, Ece</dc:creator>
 <dc:creator>Shah, Julie</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Trained AI systems and expert decision makers can make errors that are often
difficult to identify and understand. Determining the root cause for these
errors can improve future decisions. This work presents Generative Error Model
(GEM), a generative model for inferring representational errors based on
observations of an actor's behavior (either simulated agent, robot, or human).
The model considers two sources of error: those that occur due to
representational limitations -- &quot;blind spots&quot; -- and non-representational
errors, such as those caused by noise in execution or systematic errors present
in the actor's policy. Disambiguating these two error types allows for targeted
refinement of the actor's policy (i.e., representational errors require
perceptual augmentation, while other errors can be reduced through methods such
as improved training or attention support). We present a Bayesian inference
algorithm for GEM and evaluate its utility in recovering representational
errors on multiple domains. Results show that our approach can recover blind
spots of both reinforcement learning agents as well as human users.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15171</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15179</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Arbitrary Lagrangian-Eulerian hybridizable discontinuous Galerkin
  methods for fluid-structure interaction</dc:title>
 <dc:creator>Fu, Guosheng</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We present a novel (high-order) hybridizable discontinuous Galerkin (HDG)
scheme for the fluid-structure interaction (FSI) problem. The (moving domain)
incompressible Navier-Stokes equations are discretized using a divergence-free
HDG scheme within the arbitrary Lagrangian-Euler (ALE) framework. The nonlinear
elasticity equations are discretized using a novel HDG scheme with an
H(curl)-conforming velocity/displacement approximation. We further use a
combination of the Nitsche's method (for the tangential component) and the
mortar method (for the normal component) to enforce the interface conditions on
the fluid/structure interface. A second-order backward difference formula
(BDF2) is use for the temporal discretization. Numerical results on the
classical benchmark problem by Turek and Hron show a good performance of our
proposed method.
</dc:description>
 <dc:description>Comment: 20 pages, 4 figures</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15180</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Watch out for Extrinsic Bugs! A Case Study of their Impact in
  Just-In-Time Bug Prediction Models on the OpenStack project</dc:title>
 <dc:creator>Rodriguez-Perez, Gema</dc:creator>
 <dc:creator>Nagappan, Meiyappan</dc:creator>
 <dc:creator>Robles, Gregorio</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Intrinsic bugs are bugs for which a bug introducing change can be identified
in the version control system of a software. In contrast, extrinsic bugs are
caused by external changes to a software, such as errors in external APIs;
thereby they do not have an explicit bug introducing change in the version
control system. Although most previous research literature has assumed that all
bugs are of intrinsic nature, in a previous study, we show that not all bugs
are intrinsic. This paper shows an example of how considering extrinsic bugs
can affect software engineering research. Specifically, we study the impact of
extrinsic bugs in Just In Time bug prediction by partially replicating a recent
study by McIntosh and Kamei on JIT models. These models are trained using
properties of earlier bug-introducing changes. Since extrinsic bugs do not have
bug introducing changes in the version control system, we manually curate
McIntosh and Kamei's dataset to distinguish between intrinsic and extrinsic
bugs. Then, we address their original research questions, this time removing
extrinsic bugs, to study whether bug-introducing changes are a moving target in
Just-In-Time bug prediction. Finally, we study whether characteristics of
intrinsic and extrinsic bugs are different. Our results show that intrinsic and
extrinsic bugs are of different nature. When removing extrinsic bugs the
performance is different up to 16 % Area Under the Curve points. This indicates
that our JIT models obtain a more accurate representation of the real world. We
conclude that extrinsic bugs negatively impact Just-In-Time models.
Furthermore, we offer evidence that extrinsic bugs should be further
investigated, as they can significantly impact how software engineers
understand bugs.
</dc:description>
 <dc:description>Comment: in IEEE Transactions on Software Engineering, 2020</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15180</dc:identifier>
 <dc:identifier>doi:10.1109/TSE.2020.3021380</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15186</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hidden Markov Model Based Approach for Diagnosing Cause of Alarm Signals</dc:title>
 <dc:creator>Venkidasalapathy, Joshiba Ariamuthu</dc:creator>
 <dc:creator>Kravaris, Costas</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  When a fault occurs in a process, it slowly propagates within the system and
affects the measurements triggering a sequence of alarms in the control room.
The operators are required to diagnose the cause of alarms and take necessary
corrective measures. The idea of representing the alarm sequence as the fault
propagation path and using the propagation path to diagnose the fault is
explored. A diagnoser based on hidden Markov model is built to identify the
cause of the alarm signals. The proposed approach is applied to an industrial
case study: Tennessee Eastman process. The results show that the proposed
approach is successful in determining the probable cause of alarms generated
with high accuracy. The model was able to identify the cause accurately, even
when tested with short alarm sub-sequences. This allows for early
identification of faults, providing more time to the operator to restore the
system to normal operation.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15193</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Subtyping on Nested Polymorphic Session Types</dc:title>
 <dc:creator>Das, Ankush</dc:creator>
 <dc:creator>DeYoung, Henry</dc:creator>
 <dc:creator>Mordido, Andreia</dc:creator>
 <dc:creator>Pfenning, Frank</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The importance of subtyping to enable a wider range of well-typed programs is
undeniable. However, the interaction between subtyping, recursion, and
polymorphism is not completely understood yet. In this work, we explore
subtyping in a system of nested, recursive, and polymorphic types with a
coinductive interpretation, and we prove that this problem is undecidable. Our
results will be broadly applicable, but to keep our study grounded in a
concrete setting, we work with an extension of session types with explicit
polymorphism, parametric type constructors, and nested types. We prove that
subtyping is undecidable even for the fragment with only internal choices and
nested unary recursive type constructors. Despite this negative result, we
present a subtyping algorithm for our system and prove its soundness. We
minimize the impact of the inescapable incompleteness by enabling the
programmer to seed the algorithm with subtyping declarations (that are
validated by the algorithm). We have implemented the proposed algorithm in Rast
and it showed to be efficient in various example programs.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15193</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15194</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data-Driven Threat Hunting Using Sysmon</dc:title>
 <dc:creator>Mavroeidis, Vasileios</dc:creator>
 <dc:creator>J&#xf8;sang, Audun</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Threat actors can be persistent, motivated and agile, and leverage a
diversified and extensive set of tactics and techniques to attain their goals.
In response to that, defenders establish threat intelligence programs to stay
threat-informed and lower risk. Actionable threat intelligence is integrated
into security information and event management systems (SIEM) or is accessed
via more dedicated tools like threat intelligence platforms. A threat
intelligence platform gives access to contextual threat information by
aggregating, processing, correlating, and analyzing real-time data and
information from multiple sources, and in many cases, it provides centralized
analysis and reporting of an organization's security events. Sysmon logs is a
data source that has received considerable attention for endpoint visibility.
Approaches for threat detection using Sysmon have been proposed, mainly
focusing on search engine technologies like NoSQL database systems. This paper
demonstrates one of the many use cases of Sysmon and cyber threat intelligence.
In particular, we present a threat assessment system that relies on a cyber
threat intelligence ontology to automatically classify executed software into
different threat levels by analyzing Sysmon log streams. The presented system
and approach augments cyber defensive capabilities through situational
awareness, prediction, and automated courses of action.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15194</dc:identifier>
 <dc:identifier>doi:10.1145/3199478.3199490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15195</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MergeComp: A Compression Scheduler for Scalable Communication-Efficient
  Distributed Training</dc:title>
 <dc:creator>Wang, Zhuang</dc:creator>
 <dc:creator>Wu, Xinyu</dc:creator>
 <dc:creator>Ng, T. S. Eugene</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Large-scale distributed training is increasingly becoming communication
bound. Many gradient compression algorithms have been proposed to reduce the
communication overhead and improve scalability. However, it has been observed
that in some cases gradient compression may even harm the performance of
distributed training.
  In this paper, we propose MergeComp, a compression scheduler to optimize the
scalability of communication-efficient distributed training. It automatically
schedules the compression operations to optimize the performance of compression
algorithms without the knowledge of model architectures or system parameters.
We have applied MergeComp to nine popular compression algorithms. Our
evaluations show that MergeComp can improve the performance of compression
algorithms by up to 3.83x without losing accuracy. It can even achieve a
scaling factor of distributed training up to 99% over high-speed networks.
</dc:description>
 <dc:description>Comment: 8 papes</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15195</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15196</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Application of Graphics Processing Units for self-consistent modelling
  of shallow water dynamics and sediment transport</dc:title>
 <dc:creator>Khrapov, Sergey</dc:creator>
 <dc:creator>Khoperskov, Alexander</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65M22, 76-04</dc:subject>
 <dc:description>  In this paper, we describe a numerical algorithm for the self-consistent
simulations of surface water and sediment dynamics. The method is based on the
original Lagrangian-Eulerian CSPH-TVD approach for solving the Saint-Venant and
Exner equations, taking into account the physical factors essential for the
understanding of the shallow water and surface soil layer motions, including
complex terrain structure and its evolution due to sediment transport.
Additional Exner equation for sediment transport has been used for the
numerical CSPH-TVD scheme stability criteria definition. By using OpenMP-CUDA
and GPUDirect technologies for hybrid computing systems (supercomputers) with
several graphic coprocessors (GPUs) interacting with each other via the PCI-E /
NVLINK interface we also develop a parallel numerical algorithm for the
CSPH-TVD method. The developed parallel version of the algorithm demonstrates
high efficiency for various configurations of Nvidia Tesla CPU + GPU computing
systems. In particular, maximal speed up is 1800 for a system with four C2070
GPUs compare to the serial version for the CPU. The calculation time on the GPU
V100~(Volta architecture) is reduced by 95 times compared to the GPU
C2070~(Fermi architecture).
</dc:description>
 <dc:description>Comment: 11 pages, 5 figures</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15196</dc:identifier>
 <dc:identifier>Lobachevskii Journal of Mathematics, 2020, Vol. 41, No. 8, pp.
  1475-1484</dc:identifier>
 <dc:identifier>doi:10.1134/S1995080220080089</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15209</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding the role of importance weighting for deep learning</dc:title>
 <dc:creator>Xu, Da</dc:creator>
 <dc:creator>Ye, Yuting</dc:creator>
 <dc:creator>Ruan, Chuanwei</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The recent paper by Byrd &amp; Lipton (2019), based on empirical observations,
raises a major concern on the impact of importance weighting for the
over-parameterized deep learning models. They observe that as long as the model
can separate the training data, the impact of importance weighting diminishes
as the training proceeds. Nevertheless, there lacks a rigorous characterization
of this phenomenon. In this paper, we provide formal characterizations and
theoretical justifications on the role of importance weighting with respect to
the implicit bias of gradient descent and margin-based learning theory. We
reveal both the optimization dynamics and generalization performance under deep
learning models. Our work not only explains the various novel phenomenons
observed for importance weighting in deep learning, but also extends to the
studies where the weights are being optimized as part of the model, which
applies to a number of topics under active research.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15209</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15212</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the limits of algorithmic prediction across the globe</dc:title>
 <dc:creator>Li, Xingyu</dc:creator>
 <dc:creator>Song, Difan</dc:creator>
 <dc:creator>Han, Miaozhe</dc:creator>
 <dc:creator>Zhang, Yu</dc:creator>
 <dc:creator>Kizilcec, Rene F.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The impact of predictive algorithms on people's lives and livelihoods has
been noted in medicine, criminal justice, finance, hiring and admissions. Most
of these algorithms are developed using data and human capital from highly
developed nations. We tested how well predictive models of human behavior
trained in a developed country generalize to people in less developed countries
by modeling global variation in 200 predictors of academic achievement on
nationally representative student data for 65 countries. Here we show that
state-of-the-art machine learning models trained on data from the United States
can predict achievement with high accuracy and generalize to other developed
countries with comparable accuracy. However, accuracy drops linearly with
national development due to global variation in the importance of different
achievement predictors, providing a useful heuristic for policymakers. Training
the same model on national data yields high accuracy in every country, which
highlights the value of local data collection.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15213</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Temporal Kernel Approach for Deep Learning with Continuous-time
  Information</dc:title>
 <dc:creator>Xu, Da</dc:creator>
 <dc:creator>Ruan, Chuanwei</dc:creator>
 <dc:creator>Korpeoglu, Evren</dc:creator>
 <dc:creator>Kumar, Sushant</dc:creator>
 <dc:creator>Achan, Kannan</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Sequential deep learning models such as RNN, causal CNN and attention
mechanism do not readily consume continuous-time information. Discretizing the
temporal data, as we show, causes inconsistency even for simple continuous-time
processes. Current approaches often handle time in a heuristic manner to be
consistent with the existing deep learning architectures and implementations.
In this paper, we provide a principled way to characterize continuous-time
systems using deep learning tools. Notably, the proposed approach applies to
all the major deep learning architectures and requires little modifications to
the implementation. The critical insight is to represent the continuous-time
system by composing neural networks with a temporal kernel, where we gain our
intuition from the recent advancements in understanding deep learning with
Gaussian process and neural tangent kernel. To represent the temporal kernel,
we introduce the random feature approach and convert the kernel learning
problem to spectral density estimation under reparameterization. We further
prove the convergence and consistency results even when the temporal kernel is
non-stationary, and the spectral density is misspecified. The simulations and
real-data experiments demonstrate the empirical effectiveness of our temporal
kernel approach in a broad range of settings.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15213</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15214</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Complexity of Covering Two-vertex Multigraphs with
  Semi-edges</dc:title>
 <dc:creator>Bok, Jan</dc:creator>
 <dc:creator>Fiala, Ji&#x159;&#xed;</dc:creator>
 <dc:creator>Hlin&#x11b;n&#xfd;, Petr</dc:creator>
 <dc:creator>Jedli&#x10d;kov&#xe1;, Nikola</dc:creator>
 <dc:creator>Kratochv&#xed;l, Jan</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We initiate the study of computational complexity of graph coverings, aka
locally bijective graph homomorphisms, for {\em graphs with semi-edges}. The
notion of graph covering is a discretization of coverings between surfaces or
topological spaces, a notion well known and deeply studied in classical
topology. Graph covers have found applications in discrete mathematics for
constructing highly symmetric graphs, and in computer science in the theory of
local computations. In 1991, Abello et al. asked for a classification of the
computational complexity of deciding if an input graph covers a fixed target
graph, in the ordinary setting (of graphs with only edges). Although many
general results are known, the full classification is still open. In spite of
that, we propose to study the more general case of covering graphs composed of
normal edges (including multiedges and loops) and so-called semi-edges.
Semi-edges are becoming increasingly popular in modern topological graph
theory, as well as in mathematical physics. They also naturally occur in the
local computation setting, since they are lifted to matchings in the covering
graph. We show that the presence of semi-edges makes the covering problem
considerably harder; e.g., it is no longer sufficient to specify the vertex
mapping induced by the covering, but one necessarily has to deal with the edge
mapping as well. We show some solvable cases, and completely characterize the
complexity of the already very nontrivial problem of covering one- and
two-vertex (multi)graphs with semi-edges. Our NP-hardness results are proven
for simple input graphs, and in the case of regular two-vertex target graphs,
even for bipartite ones. This provides a strengthening of previously known
results for covering graphs without semi-edges, and may contribute to better
understanding of this notion and its complexity.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15214</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15215</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Range-Visual-Inertial Odometry: Scale Observability Without Excitation</dc:title>
 <dc:creator>Delaune, Jeff</dc:creator>
 <dc:creator>Bayard, David S.</dc:creator>
 <dc:creator>Brockers, Roland</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Traveling at constant velocity is the most efficient trajectory for most
robotics applications. Unfortunately without accelerometer excitation,
monocular Visual-Inertial Odometry (VIO) cannot observe scale and suffers
severe error drift. This was the main motivation for incorporating a 1D laser
range finder in the navigation system for NASA's Ingenuity Mars Helicopter.
However, Ingenuity's simplified approach was limited to flat terrains. The
current paper introduces a novel range measurement update model based on using
facet constraints. The resulting range-VIO approach is no longer limited to
flat scenes, but extends to any arbitrary structure for generic robotic
applications. An important theoretical result shows that scale is no longer in
the right nullspace of the observability matrix for zero or constant
acceleration motion. In practical terms, this means that scale becomes
observable under constant-velocity motion, which enables simple and robust
autonomous operations over arbitrary terrain. Due to the small range finder
footprint, range-VIO retains the minimal size, weight, and power attributes of
VIO, with similar runtime. The benefits are evaluated on real flight data
representative of common aerial robotics scenarios. Robustness is demonstrated
using indoor stress data and fullstate ground truth. We release our software
framework, called xVIO, as open source.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15215</dc:identifier>
 <dc:identifier>IEEE Robotics and Automation Letters, with presentation at the
  IEEE International Conference on Robotics and Automation (ICRA), Xi'an,
  China, 2021</dc:identifier>
 <dc:identifier>doi:10.1109/LRA.2021.3058918</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15216</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bulk-Controlled Low-Voltage CMOS Quadrature Oscillator</dc:title>
 <dc:creator>Picos, R.</dc:creator>
 <dc:creator>Calafat, M. A.</dc:creator>
 <dc:creator>Suenaga, K.</dc:creator>
 <dc:creator>Bota, S.</dc:creator>
 <dc:creator>Roca, M.</dc:creator>
 <dc:creator>Isern, E.</dc:creator>
 <dc:creator>Garc&#xed;a-Moreno, E.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Physics - Instrumentation and Detectors</dc:subject>
 <dc:description>  In this paper, an schema for controlling the oscillation frequency of a
quadrature oscillator is proposed. The method involves controlling the
threshold voltage of the PMOS transistors in the inverter through control of
the bulk bias voltage. Results obtained using HSPICE simulation are presented
in a technology of 0.35{\mu}m, and experimental results using discrete elements
(HEF4007) are also shown. Both sets of experiments show the effectiveness of
the technique.
</dc:description>
 <dc:description>Comment: Conference DCIS'2007, paper 3B.1</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15217</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Euler Meets GPU: Practical Graph Algorithms with Theoretical Guarantees</dc:title>
 <dc:creator>Polak, Adam</dc:creator>
 <dc:creator>Siwiec, Adrian</dc:creator>
 <dc:creator>Stobierski, Micha&#x142;</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The Euler tour technique is a classical tool for designing parallel graph
algorithms, originally proposed for the PRAM model. We ask whether it can be
adapted to run efficiently on GPU. We focus on two established applications of
the technique: (1) the problem of finding lowest common ancestors (LCA) of
pairs of nodes in trees, and (2) the problem of finding bridges in undirected
graphs. In our experiments, we compare theoretically optimal algorithms using
the Euler tour technique against simpler heuristics supposed to perform
particularly well on typical instances. We show that the Euler tour-based
algorithms not only fulfill their theoretical promises and outperform practical
heuristics on hard instances, but also perform on par with them on easy
instances.
</dc:description>
 <dc:description>Comment: IPDPS 2021</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15217</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15222</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TULVCAN: Terahertz Ultra-broadband Learning Vehicular Channel-Aware
  Networking</dc:title>
 <dc:creator>Lin, Chia-Hung</dc:creator>
 <dc:creator>Lin, Shih-Chun</dc:creator>
 <dc:creator>Blasch, Erik</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Due to spectrum scarcity and increasing wireless capacity demands, terahertz
(THz) communications at 0.1-10THz and the corresponding spectrum
characterization have emerged to meet diverse service requirements in future 5G
and 6G wireless systems. However, conventional compressed sensing techniques to
reconstruct the original wideband spectrum with under-sampled measurements
become inefficient as local spectral correlation is deliberately omitted.
Recent works extend communication methods with deep learning-based algorithms
but lack strong ties to THz channel properties. This paper introduces novel THz
channel-aware spectrum learning solutions that fully disclose the uniqueness of
THz channels when performing such ultra-broadband sensing in vehicular
environments. Specifically, a joint design of spectrum compression and
reconstruction is proposed through a structured sensing matrix and two-phase
reconstruction based on high spreading loss and molecular absorption at THz
frequencies. An end-to-end learning framework, namely compression and
reconstruction network (CRNet), is further developed with the mean-square-error
loss function to improve sensing accuracy while significantly reducing
computational complexity. Numerical results show that the CRNet solutions
outperform the latest generative adversarial network (GAN) realization with a
much higher cosine and structure similarity measures, smaller learning errors,
and 56% less required training overheads. This THz Ultra-broadband Learning
Vehicular Channel-Aware Networking (TULVCAN) work successfully achieves
effective THz spectrum learning and hence allows frequency-agile access.
</dc:description>
 <dc:description>Comment: This paper was already accepted by the IEEE 2021 INFOCOM Workshop</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15223</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On symmetric higher-dimensional automata and bisimilarity</dc:title>
 <dc:creator>Kahl, Thomas</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  It is shown that a higher-dimensional automaton is hhp-bisimilar to the free
symmetric HDA generated by it. Consequently, up to hereditary
history-preserving bisimilarity, ordinary HDAs and symmetric HDAs are models of
concurrency with the same expressive power.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15223</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15226</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Local Geometry for Feature and Graph Construction for Better
  3D Point Cloud Processing with Graph Neural Networks</dc:title>
 <dc:creator>Srivastava, Siddharth</dc:creator>
 <dc:creator>Sharma, Gaurav</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We propose simple yet effective improvements in point representations and
local neighborhood graph construction within the general framework of graph
neural networks (GNNs) for 3D point cloud processing. As a first contribution,
we propose to augment the vertex representations with important local geometric
information of the points, followed by nonlinear projection using a MLP. As a
second contribution, we propose to improve the graph construction for GNNs for
3D point clouds. The existing methods work with a k-nn based approach for
constructing the local neighborhood graph. We argue that it might lead to
reduction in coverage in case of dense sampling by sensors in some regions of
the scene. The proposed methods aims to counter such problems and improve
coverage in such cases. As the traditional GNNs were designed to work with
general graphs, where vertices may have no geometric interpretations, we see
both our proposals as augmenting the general graphs to incorporate the
geometric nature of 3D point clouds. While being simple, we demonstrate with
multiple challenging benchmarks, with relatively clean CAD models, as well as
with real world noisy scans, that the proposed method achieves state of the art
results on benchmarks for 3D classification (ModelNet40) , part segmentation
(ShapeNet) and semantic segmentation (Stanford 3D Indoor Scenes Dataset). We
also show that the proposed network achieves faster training convergence, i.e.
~40% less epochs for classification. The project details are available at
https://siddharthsrivastava.github.io/publication/geomgcnn/
</dc:description>
 <dc:description>Comment: ICRA 2021</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15230</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synchronization and Control for Multi-Weighted and Directed Complex
  Networks</dc:title>
 <dc:creator>Liu, Xiwei</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  The study of complex networks with multi-weights has been a hot topic
recently. For a network with a single weight, previous studies have shown that
they can promote synchronization. But for complex networks with multi-weights,
there are no rigorous analysis to show that synchronization can be reached
faster. In this paper, the complex network is allowed to be directed, which
will make the synchronization analysis difficult for multiple couplings. In
virtue of the normalized left eigenvectors (NLEVec) corresponding to the zero
eigenvalue of coupling matrices, we prove that if the Chebyshev distance
between NLEVec is less than some value, which is defined as the allowable
deviation bound, then the synchronization and control will be realized with
sufficiently large coupling strengths, i.e., all coupling matrices do
accelerate synchronization. Moreover, adaptive rules are also designed for the
coupling strength.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15230</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15231</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ReAgent: Point Cloud Registration using Imitation and Reinforcement
  Learning</dc:title>
 <dc:creator>Bauer, Dominik</dc:creator>
 <dc:creator>Patten, Timothy</dc:creator>
 <dc:creator>Vincze, Markus</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Point cloud registration is a common step in many 3D computer vision tasks
such as object pose estimation, where a 3D model is aligned to an observation.
Classical registration methods generalize well to novel domains but fail when
given a noisy observation or a bad initialization. Learning-based methods, in
contrast, are more robust but lack in generalization capacity. We propose to
consider iterative point cloud registration as a reinforcement learning task
and, to this end, present a novel registration agent (ReAgent). We employ
imitation learning to initialize its discrete registration policy based on a
steady expert policy. Integration with policy optimization, based on our
proposed alignment reward, further improves the agent's registration
performance. We compare our approach to classical and learning-based
registration methods on both ModelNet40 (synthetic) and ScanObjectNN (real
data) and show that our ReAgent achieves state-of-the-art accuracy. The
lightweight architecture of the agent, moreover, enables reduced inference time
as compared to related approaches. In addition, we apply our method to the
object pose estimation task on real data (LINEMOD), outperforming
state-of-the-art pose refinement approaches.
</dc:description>
 <dc:description>Comment: Accepted at CVPR 2021</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15234</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Family Column Generation: A Principled Stabilized Column Generation
  Approach</dc:title>
 <dc:creator>Haghani, Naveen</dc:creator>
 <dc:creator>Yarkony, Julian</dc:creator>
 <dc:creator>Regan, Amelia</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We tackle the problem of accelerating column generation (CG) approaches to
set cover formulations in operations research. At each iteration of CG we
generate a dual solution that approximately solves the LP over all columns
consisting of a subset of columns in the nascent set. We refer to this linear
program (LP) as the Family Restricted Master Problem (FRMP), which provides a
tighter bound on the master problem at each iteration of CG, while preserving
efficient inference. For example, in the single source capacitated facility
location problem (SSCFLP) the family of a column $l$ associated with facility
$f$ and customer set $N_l$ contains the set of columns associated with $f$ and
the customer set that lies in the power set of $N_l$. The solution to FRMP
optimization is attacked with a coordinate ascent method in the dual. The
generation of direction of travel corresponds to solving the restricted master
problem over columns corresponding to the reduced lowest cost column in each
family given specific dual variables based on the incumbent dual, and is easily
generated without resolving complex pricing problems. We apply our algorithm to
the SSCFLP and demonstrate improved performance over two relevant baselines.
</dc:description>
 <dc:description>Comment: 30 pages, 3 figures</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15234</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15235</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>KNN, An Underestimated Model for Regional Rainfall Forecasting</dc:title>
 <dc:creator>Yu, Ning</dc:creator>
 <dc:creator>Haskins, Timothy</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Regional rainfall forecasting is an important issue in hydrology and
meteorology. This paper aims to design an integrated tool by applying various
machine learning algorithms, especially the state-of-the-art deep learning
algorithms including Deep Neural Network, Wide Neural Network, Deep and Wide
Neural Network, Reservoir Computing, Long Short Term Memory, Support Vector
Machine, K-Nearest Neighbor for forecasting regional precipitations over
different catchments in Upstate New York. Through the experimental results and
the comparison among machine learning models including classification and
regression, we find that KNN is an outstanding model over other models to
handle the uncertainty in the precipitation data. The data normalization
methods such as ZScore and MinMax are also evaluated and discussed.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15236</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lessons Learned Developing an Assembly System for WRS 2020 Assembly
  Challenge</dc:title>
 <dc:creator>Naik, Aayush</dc:creator>
 <dc:creator>Parashar, Priyam</dc:creator>
 <dc:creator>Hu, Jiaming</dc:creator>
 <dc:creator>Christensen, Henrik I.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The World Robot Summit (WRS) 2020 Assembly Challenge is designed to allow
teams to demonstrate how one can build flexible, robust systems for assembly of
machined objects. We present our approach to assembly based on integration of
machine vision, robust planning and execution using behavior trees and a
hierarchy of recovery strategies to ensure robust operation. Our system was
selected for the WRS 2020 Assembly Challenge finals based on robust performance
in the qualifying rounds. We present the systems approach adopted for the
challenge.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15236</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15246</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Arroyo-Figueroa's Proof that $\mathrm{P} \neq \mathrm{NP}$</dc:title>
 <dc:creator>Juvekar, Mandar</dc:creator>
 <dc:creator>Narv&#xe1;ez, David E.</dc:creator>
 <dc:creator>Welsh, Melissa</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We critique Javier Arroyo-Figueroa's paper titled ``The existence of the Tau
one-way functions class as a proof that $\mathrm{P} \neq \mathrm{NP}$,'' which
claims to prove $\mathrm{P} \neq \mathrm{NP}$ by showing the existence of a
class of one-way functions. We summarize our best interpretation of
Arroyo-Figueroa's argument, and show why it fails to prove the existence of
one-way functions. Hence, we show that Arroyo-Figueroa fails to prove
$\mathrm{P} \neq \mathrm{NP}$.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15246</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15249</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase transition in noisy high-dimensional random geometric graphs</dc:title>
 <dc:creator>Liu, Suqi</dc:creator>
 <dc:creator>Racz, Miklos Z.</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We study the problem of detecting latent geometric structure in random
graphs. To this end, we consider the soft high-dimensional random geometric
graph $\mathcal{G}(n,p,d,q)$, where each of the $n$ vertices corresponds to an
independent random point distributed uniformly on the sphere
$\mathbb{S}^{d-1}$, and the probability that two vertices are connected by an
edge is a decreasing function of the Euclidean distance between the points. The
probability of connection is parametrized by $q \in [0,1]$, with smaller $q$
corresponding to weaker dependence on the geometry; this can also be
interpreted as the level of noise in the geometric graph. In particular, the
model smoothly interpolates between the spherical hard random geometric graph
$\mathcal{G}(n,p,d)$ (corresponding to $q = 1$) and the Erd\H{o}s-R\'enyi model
$\mathcal{G}(n,p)$ (corresponding to $q = 0$). We focus on the dense regime
(i.e., $p$ is a constant).
  We show that if $nq \to 0$ or $d \gg n^{3} q^{2}$, then geometry is lost:
$\mathcal{G}(n,p,d,q)$ is asymptotically indistinguishable from
$\mathcal{G}(n,p)$. On the other hand, if $d \ll n^{3} q^{6}$, then the signed
triangle statistic provides an asymptotically powerful test for detecting
geometry. These results generalize those of Bubeck, Ding, Eldan, and R\'acz
(2016) for $\mathcal{G}(n,p,d)$, and give quantitative bounds on how the noise
level affects the dimension threshold for losing geometry. We also prove
analogous results under a related but different distributional assumption, and
we further explore generalizations of signed triangles in order to understand
the intermediate regime left open by our results.
</dc:description>
 <dc:description>Comment: 50 pages, 2 figures</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15250</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ABOME: A Multi-platform Data Repository of Artificially Boosted Online
  Media Entities</dc:title>
 <dc:creator>Dutta, Hridoy Sankar</dc:creator>
 <dc:creator>Arora, Udit</dc:creator>
 <dc:creator>Chakraborty, Tanmoy</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The rise of online media has incentivized users to adopt various unethical
and artificial ways of gaining social growth to boost their credibility within
a short time period. In this paper, we introduce ABOME, a novel multi-platform
data repository consisting of artificially boosted (also known as
blackmarket-driven collusive entities) online media entities such as Twitter
tweets/users and YouTube videos/channels, which are prevalent but often
unnoticed in online media. ABOME allows quick querying of collusive entities
across platforms. These include details of collusive entities involved in
blackmarket services to gain artificially boosted appraisals in the form of
likes, retweets, views, comments, follows and subscriptions. ABOME contains
data related to tweets and users on Twitter, YouTube videos and YouTube
channels. We believe that ABOME is a unique data repository that can be used as
a benchmark to identify and analyze blackmarket-driven fraudulent activities in
online media. We also develop SearchBM, an API and a web portal that offers a
free service to identify blackmarket entities.
</dc:description>
 <dc:description>Comment: Accepted for publication in ICWSM-2021</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15250</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15254</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Deep Basis Fitting for Depth Completion with Uncertainty</dc:title>
 <dc:creator>Qu, Chao</dc:creator>
 <dc:creator>Liu, Wenxin</dc:creator>
 <dc:creator>Taylor, Camillo J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this work we investigate the problem of uncertainty estimation for
image-guided depth completion. We extend Deep Basis Fitting (DBF) for depth
completion within a Bayesian evidence framework to provide calibrated per-pixel
variance. The DBF approach frames the depth completion problem in terms of a
network that produces a set of low-dimensional depth bases and a differentiable
least squares fitting module that computes the basis weights using the sparse
depths. By adopting a Bayesian treatment, our Bayesian Deep Basis Fitting
(BDBF) approach is able to 1) predict high-quality uncertainty estimates and 2)
enable depth completion with few or no sparse measurements. We conduct
controlled experiments to compare BDBF against commonly used techniques for
uncertainty estimation under various scenarios. Results show that our method
produces better uncertainty estimates with accurate depth prediction.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15254</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15256</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Personalized Affect-Aware Socially Assistive Robot Tutors Aimed at
  Fostering Social Grit in Children with Autism</dc:title>
 <dc:creator>Shi, Zhonghao</dc:creator>
 <dc:creator>Cao, Manwei</dc:creator>
 <dc:creator>Pei, Sophia</dc:creator>
 <dc:creator>Qiao, Xiaoyang</dc:creator>
 <dc:creator>Groechel, Thomas R</dc:creator>
 <dc:creator>Matari&#x107;, Maja J</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Affect-aware socially assistive robotics (SAR) tutors have great potential to
augment and democratize professional therapeutic interventions for children
with autism spectrum disorders (ASD) from different socioeconomic backgrounds.
However, the majority of research on SAR for ASD has been on teaching cognitive
and/or social skills, not on addressing users' emotional needs for real-world
social situations. To bridge that gap, this work aims to develop personalized
affect-aware SAR tutors to help alleviate social anxiety and foster social
grit-the growth mindset for social skill development-in children with ASD. We
propose a novel paradigm to incorporate clinically validated Acceptance and
Commitment Training (ACT) with personalized SAR interventions. This work paves
the way toward developing personalized affect-aware SAR interventions to
support the unique and diverse socio-emotional needs and challenges of children
with ASD.
</dc:description>
 <dc:description>Comment: Accepted to ACM/IEEE International Conference on Human-Robot
  Interaction Workshop on Child-Robot Interaction and Child's Fundamental
  Rights</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15256</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15260</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep reinforcement learning of event-triggered communication and control
  for multi-agent cooperative transport</dc:title>
 <dc:creator>Shibata, Kazuki</dc:creator>
 <dc:creator>Jimbo, Tomohiko</dc:creator>
 <dc:creator>Matsubara, Takamitsu</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper, we explore a multi-agent reinforcement learning approach to
address the design problem of communication and control strategies for
multi-agent cooperative transport. Typical end-to-end deep neural network
policies may be insufficient for covering communication and control; these
methods cannot decide the timing of communication and can only work with
fixed-rate communications. Therefore, our framework exploits event-triggered
architecture, namely, a feedback controller that computes the communication
input and a triggering mechanism that determines when the input has to be
updated again. Such event-triggered control policies are efficiently optimized
using a multi-agent deep deterministic policy gradient. We confirmed that our
approach could balance the transport performance and communication savings
through numerical simulations.
</dc:description>
 <dc:description>Comment: 7 pages, 7 figures, to be published in the 2021 International
  Conference on Robotics and Automation</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15261</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One Network Fits All? Modular versus Monolithic Task Formulations in
  Neural Networks</dc:title>
 <dc:creator>Agarwala, Atish</dc:creator>
 <dc:creator>Das, Abhimanyu</dc:creator>
 <dc:creator>Juba, Brendan</dc:creator>
 <dc:creator>Panigrahy, Rina</dc:creator>
 <dc:creator>Sharan, Vatsal</dc:creator>
 <dc:creator>Wang, Xin</dc:creator>
 <dc:creator>Zhang, Qiuyi</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Can deep learning solve multiple tasks simultaneously, even when they are
unrelated and very different? We investigate how the representations of the
underlying tasks affect the ability of a single neural network to learn them
jointly. We present theoretical and empirical findings that a single neural
network is capable of simultaneously learning multiple tasks from a combined
data set, for a variety of methods for representing tasks -- for example, when
the distinct tasks are encoded by well-separated clusters or decision trees
over certain task-code attributes. More concretely, we present a novel analysis
that shows that families of simple programming-like constructs for the codes
encoding the tasks are learnable by two-layer neural networks with standard
training. We study more generally how the complexity of learning such combined
tasks grows with the complexity of the task codes; we find that combining many
tasks may incur a sample complexity penalty, even though the individual tasks
are easy to learn. We provide empirical support for the usefulness of the
learning bounds by training networks on clusters, decision trees, and SQL-style
aggregation.
</dc:description>
 <dc:description>Comment: 30 pages, 6 figures</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15261</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15268</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real World Scrum A Grounded Theory of Variations in Practice</dc:title>
 <dc:creator>Masood, Zainab</dc:creator>
 <dc:creator>Hoda, Rashina</dc:creator>
 <dc:creator>Blincoe, Kelly</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Scrum, the most popular agile method and project management framework, is
widely reported to be used, adapted, misused, and abused in practice. However,
not much is known about how Scrum actually works in practice, and critically,
where, when, how and why it diverges from Scrum by the book. Through a Grounded
Theory study involving semi-structured interviews of 45 participants from 30
companies and observations of five teams, we present our findings on how Scrum
works in practice as compared to how it is presented in its formative books. We
identify significant variations in these practices such as work breakdown,
estimation, prioritization, assignment, the associated roles and artefacts, and
discuss the underlying rationales driving the variations. Critically, we claim
that not all variations are process misuse/abuse and propose a nuanced
classification approach to understanding variations as standard, necessary,
contextual, and clear deviations for successful Scrum use and adaptation
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15268</dc:identifier>
 <dc:identifier>doi:10.1109/TSE.2020.3025317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15275</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Anderson acceleration for partially observable Markov decision
  processes</dc:title>
 <dc:creator>Ermis, Melike</dc:creator>
 <dc:creator>Park, Mingyu</dc:creator>
 <dc:creator>Yang, Insoon</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper proposes an accelerated method for approximately solving partially
observable Markov decision process (POMDP) problems offline. Our method
carefully combines two existing tools: Anderson acceleration (AA) and the fast
informed bound (FIB) method. Adopting AA, our method rapidly solves an
approximate Bellman equation with an efficient combination of previous solution
estimates. Furthermore, the use of FIB alleviates the scalability issue
inherent in POMDPs. We show the convergence of the overall algorithm to the
suboptimal solution obtained by FIB. We further consider a simulation-based
method and prove that the approximation error is bounded explicitly. The
performance of our algorithm is evaluated on several benchmark problems. The
results of our experiments demonstrate that the proposed algorithm converges
significantly faster without degrading the quality of the solution compared to
its standard counterpart.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15275</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15279</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalizing to the Open World: Deep Visual Odometry with Online
  Adaptation</dc:title>
 <dc:creator>Li, Shunkai</dc:creator>
 <dc:creator>Wu, Xin</dc:creator>
 <dc:creator>Cao, Yingdian</dc:creator>
 <dc:creator>Zha, Hongbin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Despite learning-based visual odometry (VO) has shown impressive results in
recent years, the pretrained networks may easily collapse in unseen
environments. The large domain gap between training and testing data makes them
difficult to generalize to new scenes. In this paper, we propose an online
adaptation framework for deep VO with the assistance of scene-agnostic
geometric computations and Bayesian inference. In contrast to learning-based
pose estimation, our method solves pose from optical flow and depth while the
single-view depth estimation is continuously improved with new observations by
online learned uncertainties. Meanwhile, an online learned photometric
uncertainty is used for further depth and pose optimization by a differentiable
Gauss-Newton layer. Our method enables fast adaptation of deep VO networks to
unseen environments in a self-supervised manner. Extensive experiments
including Cityscapes to KITTI and outdoor KITTI to indoor TUM demonstrate that
our method achieves state-of-the-art generalization ability among
self-supervised VO methods.
</dc:description>
 <dc:description>Comment: Accepted by CVPR 2021</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15285</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A cooperative partial snapshot algorithm for checkpoint-rollback
  recovery of large-scale and dynamic distributed systems and experimental
  evaluations</dc:title>
 <dc:creator>Nakamura, Junya</dc:creator>
 <dc:creator>Kim, Yonghwan</dc:creator>
 <dc:creator>Katayama, Yoshiaki</dc:creator>
 <dc:creator>Masuzawa, Toshimitsu</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  A distributed system consisting of a huge number of computational entities is
prone to faults, because faults in a few nodes cause the entire system to fail.
Consequently, fault tolerance of distributed systems is a critical issue.
Checkpoint-rollback recovery is a universal and representative technique for
fault tolerance; it periodically records the entire system state
(configuration) to non-volatile storage, and the system restores itself using
the recorded configuration when the system fails. To record a configuration of
a distributed system, a specific algorithm known as a snapshot algorithm is
required. However, many snapshot algorithms require coordination among all
nodes in the system; thus, frequent executions of snapshot algorithms require
unacceptable communication cost, especially if the systems are large. As a
sophisticated snapshot algorithm, a partial snapshot algorithm has been
introduced that takes a partial snapshot (instead of a global snapshot).
However, if two or more partial snapshot algorithms are concurrently executed,
and their snapshot domains overlap, they should coordinate, so that the partial
snapshots (taken by the algorithms) are consistent. In this paper, we propose a
new efficient partial snapshot algorithm with the aim of reducing communication
for the coordination. In a simulation, we show that the proposed algorithm
drastically outperforms the existing partial snapshot algorithm, in terms of
message and time complexity.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15285</dc:identifier>
 <dc:identifier>Concurrency Computat Pract Exper. 2020;e5647</dc:identifier>
 <dc:identifier>doi:10.1002/cpe.5647</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15289</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Binary Translation for SGX Enclaves</dc:title>
 <dc:creator>Cui, Jinhua</dc:creator>
 <dc:creator>Shinde, Shweta</dc:creator>
 <dc:creator>Sen, Satyaki</dc:creator>
 <dc:creator>Saxena, Prateek</dc:creator>
 <dc:creator>Yuan, Pinghai</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Enclaves, such as those enabled by Intel SGX, offer a hardware primitive for
shielding user-level applications from the OS. While enclaves are a useful
starting point, code running in the enclave requires additional checks whenever
control or data is transferred to/from the untrusted OS. The enclave-OS
interface on SGX, however, can be extremely large if we wish to run existing
unmodified binaries inside enclaves. This paper presents Ratel, a dynamic
binary translation engine running inside SGX enclaves on Linux. Ratel offers
complete interposition, the ability to interpose on all executed instructions
in the enclave and monitor all interactions with the OS. Instruction-level
interposition offers a general foundation for implementing a large variety of
inline security monitors in the future.
  We take a principled approach in explaining why complete interposition on SGX
is challenging. We draw attention to 5 design decisions in SGX that create
fundamental trade-offs between performance and ensuring complete interposition,
and we explain how to resolve them in the favor of complete interposition. To
illustrate the utility of the Ratel framework, we present the first attempt to
offer binary compatibility with existing software on SGX. We report that Ratel
offers binary compatibility with over 200 programs we tested, including
micro-benchmarks and real applications such as Linux shell utilities. Runtimes
for two programming languages, namely Python and R, tested with standard
benchmarks work out-of-the-box on Ratel without any specialized handling.
</dc:description>
 <dc:description>Comment: 24 pages, 11 figures, 10 tables. arXiv admin note: substantial text
  overlap with arXiv:2009.01144</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15289</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15294</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>&quot;Weak AI&quot; is Likely to Never Become &quot;Strong AI&quot;, So What is its Greatest
  Value for us?</dc:title>
 <dc:creator>Liu, Bin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  AI has surpassed humans across a variety of tasks such as image
classification, playing games (e.g., go, &quot;Starcraft&quot; and poker), and protein
structure prediction. However, at the same time, AI is also bearing serious
controversies. Many researchers argue that little substantial progress has been
made for AI in recent decades. In this paper, the author (1) explains why
controversies about AI exist; (2) discriminates two paradigms of AI research,
termed &quot;weak AI&quot; and &quot;strong AI&quot; (a.k.a. artificial general intelligence); (3)
clarifies how to judge which paradigm a research work should be classified
into; (4) discusses what is the greatest value of &quot;weak AI&quot; if it has no chance
to develop into &quot;strong AI&quot;.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15297</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LiDAR R-CNN: An Efficient and Universal 3D Object Detector</dc:title>
 <dc:creator>Li, Zhichao</dc:creator>
 <dc:creator>Wang, Feng</dc:creator>
 <dc:creator>Wang, Naiyan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  LiDAR-based 3D detection in point cloud is essential in the perception system
of autonomous driving. In this paper, we present LiDAR R-CNN, a second stage
detector that can generally improve any existing 3D detector. To fulfill the
real-time and high precision requirement in practice, we resort to point-based
approach other than the popular voxel-based approach. However, we find an
overlooked issue in previous work: Naively applying point-based methods like
PointNet could make the learned features ignore the size of proposals. To this
end, we analyze this problem in detail and propose several methods to remedy
it, which bring significant performance improvement. Comprehensive experimental
results on real-world datasets like Waymo Open Dataset (WOD) and KITTI dataset
with various popular detectors demonstrate the universality and superiority of
our LiDAR R-CNN. In particular, based on one variant of PointPillars, our
method could achieve new state-of-the-art results with minor cost. Codes will
be released at https://github.com/tusimple/LiDAR_RCNN .
</dc:description>
 <dc:description>Comment: CVPR 2021 camera-ready</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15297</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15307</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Onfocus Detection: Identifying Individual-Camera Eye Contact from
  Unconstrained Images</dc:title>
 <dc:creator>Zhang, Dingwen</dc:creator>
 <dc:creator>Wang, Bo</dc:creator>
 <dc:creator>Wang, Gerong</dc:creator>
 <dc:creator>Zhang, Qiang</dc:creator>
 <dc:creator>Zhang, Jiajia</dc:creator>
 <dc:creator>Han, Jungong</dc:creator>
 <dc:creator>You, Zheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Onfocus detection aims at identifying whether the focus of the individual
captured by a camera is on the camera or not. Based on the behavioral research,
the focus of an individual during face-to-camera communication leads to a
special type of eye contact, i.e., the individual-camera eye contact, which is
a powerful signal in social communication and plays a crucial role in
recognizing irregular individual status (e.g., lying or suffering mental
disease) and special purposes (e.g., seeking help or attracting fans). Thus,
developing effective onfocus detection algorithms is of significance for
assisting the criminal investigation, disease discovery, and social behavior
analysis. However, the review of the literature shows that very few efforts
have been made toward the development of onfocus detector due to the lack of
large-scale public available datasets as well as the challenging nature of this
task. To this end, this paper engages in the onfocus detection research by
addressing the above two issues. Firstly, we build a large-scale onfocus
detection dataset, named as the OnFocus Detection In the Wild (OFDIW). It
consists of 20,623 images in unconstrained capture conditions (thus called ``in
the wild'') and contains individuals with diverse emotions, ages, facial
characteristics, and rich interactions with surrounding objects and background
scenes. On top of that, we propose a novel end-to-end deep model, i.e., the
eye-context interaction inferring network (ECIIN), for onfocus detection, which
explores eye-context interaction via dynamic capsule routing. Finally,
comprehensive experiments are conducted on the proposed OFDIW dataset to
benchmark the existing learning models and demonstrate the effectiveness of the
proposed ECIIN. The project (containing both datasets and codes) is at
https://github.com/wintercho/focus.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15307</dc:identifier>
 <dc:identifier>SCIENCE CHINA Information Sciences, 2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15308</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stability of Multi-Microgrids: New Certificates, Distributed Control,
  and Braess's Paradox</dc:title>
 <dc:creator>Gholami, Amin</dc:creator>
 <dc:creator>Sun, Xu Andy</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  This paper investigates the theory of resilience and stability in
multi-microgrid networks. We derive new sufficient conditions to guarantee
small-signal stability of multi-microgrids in both lossless and lossy networks.
The new stability certificate for lossy networks only requires local
information, thus leads to a fully distributed control scheme. Moreover, we
study the impact of network topology, interface parameters (virtual inertia and
damping), and local measurements (voltage magnitude and reactive power) on the
stability of the system. The proposed stability certificate suggests the
existence of Braess's Paradox in the stability of multi-microgrids, i.e. adding
more connections between microgrids could worsen the multi-microgrid system
stability as a whole. We also extend the presented analysis to
structure-preserving network models, and provide a stability certificate as a
function of original network parameters, instead of the Kron reduced network
parameters. We provide a detailed numerical study of the proposed certificate,
the distributed control scheme, and a coordinated control approach with line
switching. The simulation shows the effectiveness of the proposed stability
conditions and control schemes in a four-microgrid network, IEEE 33-bus system,
and several large-scale synthetic grids.
</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15309</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Feedback Motion Policy Design Using Reinforcement Learning on a
  3D Digit Bipedal Robot</dc:title>
 <dc:creator>Castillo, Guillermo A.</dc:creator>
 <dc:creator>Weng, Bowen</dc:creator>
 <dc:creator>Zhang, Wei</dc:creator>
 <dc:creator>Hereid, Ayonga</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper, a hierarchical and robust framework for learning bipedal
locomotion is presented and successfully implemented on the 3D biped robot
Digit built by Agility Robotics. We propose a cascade-structure controller that
combines the learning process with intuitive feedback regulations. This design
allows the framework to realize robust and stable walking with a
reduced-dimension state and action spaces of the policy, significantly
simplifying the design and reducing the sampling efficiency of the learning
method. The inclusion of feedback regulation into the framework improves the
robustness of the learned walking gait and ensures the success of the
sim-to-real transfer of the proposed controller with minimal tuning. We
specifically present a learning pipeline that considers hardware-feasible
initial poses of the robot within the learning process to ensure the initial
state of the learning is replicated as close as possible to the initial state
of the robot in hardware experiments. Finally, we demonstrate the feasibility
of our method by successfully transferring the learned policy in simulation to
the Digit robot hardware, realizing sustained walking gaits under external
force disturbances and challenging terrains not included during the training
process. To the best of our knowledge, this is the first time a learning-based
policy is transferred successfully to the Digit robot in hardware experiments
without using dynamic randomization or curriculum learning.
</dc:description>
 <dc:description>Comment: &quot;Supplemental video: https://www.youtube.com/watch?v=j8KbW-a9dbw&quot;</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15316</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Whitening Sentence Representations for Better Semantics and Faster
  Retrieval</dc:title>
 <dc:creator>Su, Jianlin</dc:creator>
 <dc:creator>Cao, Jiarun</dc:creator>
 <dc:creator>Liu, Weijie</dc:creator>
 <dc:creator>Ou, Yangyiwen</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Pre-training models such as BERT have achieved great success in many natural
language processing tasks. However, how to obtain better sentence
representation through these pre-training models is still worthy to exploit.
Previous work has shown that the anisotropy problem is an critical bottleneck
for BERT-based sentence representation which hinders the model to fully utilize
the underlying semantic features. Therefore, some attempts of boosting the
isotropy of sentence distribution, such as flow-based model, have been applied
to sentence representations and achieved some improvement. In this paper, we
find that the whitening operation in traditional machine learning can similarly
enhance the isotropy of sentence representations and achieve competitive
results. Furthermore, the whitening technique is also capable of reducing the
dimensionality of the sentence representation. Our experimental results show
that it can not only achieve promising performance but also significantly
reduce the storage cost and accelerate the model retrieval speed.
</dc:description>
 <dc:description>Comment: The source code of this paper is available at
  https://github.com/bojone/BERT-whitening</dc:description>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15317</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ground Encoding: Learned Factor Graph-based Models for Localizing Ground
  Penetrating Radar</dc:title>
 <dc:creator>Baikovitz, Alexander</dc:creator>
 <dc:creator>Sodhi, Paloma</dc:creator>
 <dc:creator>Dille, Michael</dc:creator>
 <dc:creator>Kaess, Michael</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We address the problem of robot localization using ground penetrating radar
(GPR) sensors. Current approaches for localization with GPR sensors require a
priori maps of the system's environment as well as access to approximate global
positioning (GPS) during operation. In this paper, we propose a novel,
real-time GPR-based localization system for unknown and GPS-denied
environments. We model the localization problem as an inference over a factor
graph. Our approach combines 1D single-channel GPR measurements to form 2D
image submaps. To use these GPR images in the graph, we need sensor models that
can map noisy, high-dimensional image measurements into the state space. These
are challenging to obtain a priori since image generation has a complex
dependency on subsurface composition and radar physics, which itself varies
with sensors and variations in subsurface electromagnetic properties. Our key
idea is to instead learn relative sensor models directly from GPR data that map
non-sequential GPR image pairs to relative robot motion. These models are
incorporated as factors within the factor graph with relative motion
predictions correcting for accumulated drift in the position estimates. We
demonstrate our approach over datasets collected across multiple locations
using a custom designed experimental rig. We show reliable, real-time
localization using only GPR and odometry measurements for varying trajectories
in three distinct GPS-denied environments. For our supplementary video, see
https://youtu.be/HXXgdTJzqyw.
</dc:description>
 <dc:description>Comment: Submitted to the International Conference on Intelligent Robots and
  Systems (IROS) 2021</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15319</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Attention Networks for Data Compression</dc:title>
 <dc:creator>Tetelman, Michael</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The lossless data compression algorithm based on Bayesian Attention Networks
is derived from first principles. Bayesian Attention Networks are defined by
introducing an attention factor per a training sample loss as a function of two
sample inputs, from training sample and prediction sample. By using a sharpened
Jensen's inequality we show that the attention factor is completely defined by
a correlation function of the two samples w.r.t. the model weights. Due to the
attention factor the solution for a prediction sample is mostly defined by a
few training samples that are correlated with the prediction sample. Finding a
specific solution per prediction sample couples together the training and the
prediction. To make the approach practical we introduce a latent space to map
each prediction sample to a latent space and learn all possible solutions as a
function of the latent space along with learning attention as a function of the
latent space and a training sample. The latent space plays a role of the
context representation with a prediction sample defining a context and a
learned context dependent solution used for the prediction.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15320</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TFPose: Direct Human Pose Estimation with Transformers</dc:title>
 <dc:creator>Mao, Weian</dc:creator>
 <dc:creator>Ge, Yongtao</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Tian, Zhi</dc:creator>
 <dc:creator>Wang, Xinlong</dc:creator>
 <dc:creator>Wang, Zhibin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a human pose estimation framework that solves the task in the
regression-based fashion. Unlike previous regression-based methods, which often
fall behind those state-of-the-art methods, we formulate the pose estimation
task into a sequence prediction problem that can effectively be solved by
transformers. Our framework is simple and direct, bypassing the drawbacks of
the heatmap-based pose estimation. Moreover, with the attention mechanism in
transformers, our proposed framework is able to adaptively attend to the
features most relevant to the target keypoints, which largely overcomes the
feature misalignment issue of previous regression-based methods and
considerably improves the performance. Importantly, our framework can
inherently take advantages of the structured relationship between keypoints.
Experiments on the MS-COCO and MPII datasets demonstrate that our method can
significantly improve the state-of-the-art of regression-based pose estimation
and perform comparably with the best heatmap-based pose estimation methods.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15320</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15323</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classifying Video based on Automatic Content Detection Overview</dc:title>
 <dc:creator>Wang, Yilin</dc:creator>
 <dc:creator>Ye, Jiayi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Video classification and analysis is always a popular and challenging field
in computer vision. It is more than just simple image classification due to the
correlation with respect to the semantic contents of subsequent frames brings
difficulties for video analysis. In this literature review, we summarized some
state-of-the-art methods for multi-label video classification. Our goal is
first to experimentally research the current widely used architectures, and
then to develop a method to deal with the sequential data of frames and perform
multi-label classification based on automatic content detection of video.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15323</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15329</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Fast and Small Subsampled R-index</dc:title>
 <dc:creator>Cobas, Dustin</dc:creator>
 <dc:creator>Gagie, Travis</dc:creator>
 <dc:creator>Navarro, Gonzalo</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The $r$-index (Gagie et al., JACM 2020) represented a breakthrough in
compressed indexing of repetitive text collections, outperforming its
alternatives by orders of magnitude. Its space usage, $\mathcal{O}(r)$ where
$r$ is the number of runs in the Burrows-Wheeler Transform of the text, is
however larger than Lempel-Ziv and grammar-based indexes, and makes it
uninteresting in various real-life scenarios of milder repetitiveness. In this
paper we introduce the $sr$-index, a variant that limits the space to
$\mathcal{O}(\min(r,n/s))$ for a text of length $n$ and a given parameter $s$,
at the expense of multiplying by $s$ the time per occurrence reported. The
$sr$-index is obtained by carefully subsampling the text positions indexed by
the $r$-index, in a way that we prove is still able to support pattern matching
with guaranteed performance. Our experiments demonstrate that the $sr$-index
sharply outperforms virtually every other compressed index on repetitive texts,
both in time and space, even matching the performance of the $r$-index while
using 1.5--3.0 times less space. Only some Lempel-Ziv-based indexes achieve
better compression than the $sr$-index, using about half the space, but they
are an order of magnitude slower.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15331</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>POSEFusion: Pose-guided Selective Fusion for Single-view Human
  Volumetric Capture</dc:title>
 <dc:creator>Li, Zhe</dc:creator>
 <dc:creator>Yu, Tao</dc:creator>
 <dc:creator>Zheng, Zerong</dc:creator>
 <dc:creator>Guo, Kaiwen</dc:creator>
 <dc:creator>Liu, Yebin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose POse-guided SElective Fusion (POSEFusion), a single-view human
volumetric capture method that leverages tracking-based methods and
tracking-free inference to achieve high-fidelity and dynamic 3D reconstruction.
By contributing a novel reconstruction framework which contains pose-guided
keyframe selection and robust implicit surface fusion, our method fully
utilizes the advantages of both tracking-based methods and tracking-free
inference methods, and finally enables the high-fidelity reconstruction of
dynamic surface details even in the invisible regions. We formulate the
keyframe selection as a dynamic programming problem to guarantee the temporal
continuity of the reconstructed sequence. Moreover, the novel robust implicit
surface fusion involves an adaptive blending weight to preserve high-fidelity
surface details and an automatic collision handling method to deal with the
potential self-collisions. Overall, our method enables high-fidelity and
dynamic capture in both visible and invisible regions from a single RGBD
camera, and the results and experiments show that our method outperforms
state-of-the-art methods.
</dc:description>
 <dc:description>Comment: CVPR 2021 (Oral presentation), for more information, please refer to
  the projectpage http://www.liuyebin.com/posefusion/posefusion.html</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15331</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15332</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring Sample Efficiency and Generalization in Reinforcement Learning
  Benchmarks: NeurIPS 2020 Procgen Benchmark</dc:title>
 <dc:creator>Mohanty, Sharada</dc:creator>
 <dc:creator>Poonganam, Jyotish</dc:creator>
 <dc:creator>Gaidon, Adrien</dc:creator>
 <dc:creator>Kolobov, Andrey</dc:creator>
 <dc:creator>Wulfe, Blake</dc:creator>
 <dc:creator>Chakraborty, Dipam</dc:creator>
 <dc:creator>&#x160;emetulskis, Gra&#x17e;vydas</dc:creator>
 <dc:creator>Schapke, Jo&#xe3;o</dc:creator>
 <dc:creator>Kubilius, Jonas</dc:creator>
 <dc:creator>Pa&#x161;ukonis, Jurgis</dc:creator>
 <dc:creator>Klimas, Linas</dc:creator>
 <dc:creator>Hausknecht, Matthew</dc:creator>
 <dc:creator>MacAlpine, Patrick</dc:creator>
 <dc:creator>Tran, Quang Nhat</dc:creator>
 <dc:creator>Tumiel, Thomas</dc:creator>
 <dc:creator>Tang, Xiaocheng</dc:creator>
 <dc:creator>Chen, Xinwei</dc:creator>
 <dc:creator>Hesse, Christopher</dc:creator>
 <dc:creator>Hilton, Jacob</dc:creator>
 <dc:creator>Guss, William Hebgen</dc:creator>
 <dc:creator>Genc, Sahika</dc:creator>
 <dc:creator>Schulman, John</dc:creator>
 <dc:creator>Cobbe, Karl</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The NeurIPS 2020 Procgen Competition was designed as a centralized benchmark
with clearly defined tasks for measuring Sample Efficiency and Generalization
in Reinforcement Learning. Generalization remains one of the most fundamental
challenges in deep reinforcement learning, and yet we do not have enough
benchmarks to measure the progress of the community on Generalization in
Reinforcement Learning. We present the design of a centralized benchmark for
Reinforcement Learning which can help measure Sample Efficiency and
Generalization in Reinforcement Learning by doing end to end evaluation of the
training and rollout phases of thousands of user submitted code bases in a
scalable way. We designed the benchmark on top of the already existing Procgen
Benchmark by defining clear tasks and standardizing the end to end evaluation
setups. The design aims to maximize the flexibility available for researchers
who wish to design future iterations of such benchmarks, and yet imposes
necessary practical constraints to allow for a system like this to scale. This
paper presents the competition setup and the details and analysis of the top
solutions identified through this setup in context of 2020 iteration of the
competition at NeurIPS.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15332</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15333</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Distributed Scheme for Stability Assessment in Large-Scale
  Structure-Preserving Models via Singular Perturbation</dc:title>
 <dc:creator>Gholami, Amin</dc:creator>
 <dc:creator>Sun, Xu Andy</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  Assessing small-signal stability of power systems composed of thousands of
interacting generators is a computationally challenging task. To reduce the
computational burden, this paper introduces a novel condition to assess and
certify small-signal stability. Using this certificate, we can see the impact
of network topology and system parameters (generators' damping and inertia) on
the eigenvalues of the system. The proposed certificate is derived from
rigorous analysis of the classical structure-preserving swing equation model
and has a physically insightful interpretation related to the generators'
parameters and reactive power. To develop the certificate, we use singular
perturbation techniques, and in the process, we establish the relationship
between the structure-preserving model and its singular perturbation
counterpart. As the proposed method is fully distributed and uses only local
measurements, its computational cost does not increase with the size of the
system. The effectiveness of the scheme is numerically illustrated on the WSCC
system.
</dc:description>
 <dc:description>Comment: https://hdl.handle.net/10125/71001</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15333</dc:identifier>
 <dc:identifier>Proceedings of the 54th Hawaii International Conference on System
  Sciences, 2021</dc:identifier>
 <dc:identifier>doi:10.24251/HICSS.2021.386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15335</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Changing the Mind of Transformers for Topically-Controllable Language
  Generation</dc:title>
 <dc:creator>Chang, Haw-Shiuan</dc:creator>
 <dc:creator>Yuan, Jiaming</dc:creator>
 <dc:creator>Iyyer, Mohit</dc:creator>
 <dc:creator>McCallum, Andrew</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Large Transformer-based language models can aid human authors by suggesting
plausible continuations of text written so far. However, current interactive
writing assistants do not allow authors to guide text generation in desired
topical directions. To address this limitation, we design a framework that
displays multiple candidate upcoming topics, of which a user can select a
subset to guide the generation. Our framework consists of two components: (1) a
method that produces a set of candidate topics by predicting the centers of
word clusters in the possible continuations, and (2) a text generation model
whose output adheres to the chosen topics. The training of both components is
self-supervised, using only unlabeled text. Our experiments demonstrate that
our topic options are better than those of standard clustering approaches, and
our framework often generates fluent sentences related to the chosen topics, as
judged by automated metrics and crowdsourced workers.
</dc:description>
 <dc:description>Comment: EACL 2021</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15335</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15337</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Inverse Problems of some Mathematical Programming Problems</dc:title>
 <dc:creator>Huang, Siming</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The non-convex quadratic orogramming problem and the non-monotone linear
complementarity problem are NP-complete problems. In this paper we first show
taht the inverse problem of determinning a KKT point of the non-convex
quadratic programming problem is polynomial. We then show that the inverse
problems of non-monotone linear complementarity problem are polynomial solvable
in some cases, and in another case is NP-hard. Therefore we solve an open
question raised by Heuberger on inverse NP-hard problems and prove that
CoNP=NP.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15337</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15339</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-facet Universal Schema</dc:title>
 <dc:creator>Paul, Rohan</dc:creator>
 <dc:creator>Chang, Haw-Shiuan</dc:creator>
 <dc:creator>McCallum, Andrew</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Universal schema (USchema) assumes that two sentence patterns that share the
same entity pairs are similar to each other. This assumption is widely adopted
for solving various types of relation extraction (RE) tasks. Nevertheless, each
sentence pattern could contain multiple facets, and not every facet is similar
to all the facets of another sentence pattern co-occurring with the same entity
pair. To address the violation of the USchema assumption, we propose
multi-facet universal schema that uses a neural model to represent each
sentence pattern as multiple facet embeddings and encourage one of these facet
embeddings to be close to that of another sentence pattern if they co-occur
with the same entity pair. In our experiments, we demonstrate that multi-facet
embeddings significantly outperform their single-facet embedding counterpart,
compositional universal schema (CUSchema) (Verga et al., 2016), in distantly
supervised relation extraction tasks. Moreover, we can also use multiple
embeddings to detect the entailment relation between two sentence patterns when
no manual label is available.
</dc:description>
 <dc:description>Comment: EACL 2021</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15343</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational Rejection Particle Filtering</dc:title>
 <dc:creator>Sharma, Rahul</dc:creator>
 <dc:creator>Banerjee, Soumya</dc:creator>
 <dc:creator>Vats, Dootika</dc:creator>
 <dc:creator>Rai, Piyush</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We present a variational inference (VI) framework that unifies and leverages
sequential Monte-Carlo (particle filtering) with \emph{approximate} rejection
sampling to construct a flexible family of variational distributions.
Furthermore, we augment this approach with a resampling step via Bernoulli
race, a generalization of a Bernoulli factory, to obtain a low-variance
estimator of the marginal likelihood. Our framework, Variational Rejection
Particle Filtering (VRPF), leads to novel variational bounds on the marginal
likelihood, which can be optimized efficiently with respect to the variational
parameters and generalizes several existing approaches in the VI literature. We
also present theoretical properties of the variational bound and demonstrate
experiments on various models of sequential data, such as the Gaussian
state-space model and variational recurrent neural net (VRNN), on which VRPF
outperforms various existing state-of-the-art VI methods.
</dc:description>
 <dc:description>Comment: 10 pages, 2 figures</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15343</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15345</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FixNorm: Dissecting Weight Decay for Training Deep Neural Networks</dc:title>
 <dc:creator>Zhou, Yucong</dc:creator>
 <dc:creator>Sun, Yunxiao</dc:creator>
 <dc:creator>Zhong, Zhao</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Weight decay is a widely used technique for training Deep Neural
Networks(DNN). It greatly affects generalization performance but the underlying
mechanisms are not fully understood. Recent works show that for layers followed
by normalizations, weight decay mainly affects the effective learning rate.
However, despite normalizations have been extensively adopted in modern DNNs,
layers such as the final fully-connected layer do not satisfy this
precondition. For these layers, the effects of weight decay are still unclear.
In this paper, we comprehensively investigate the mechanisms of weight decay
and find that except for influencing effective learning rate, weight decay has
another distinct mechanism that is equally important: affecting generalization
performance by controlling cross-boundary risk. These two mechanisms together
give a more comprehensive explanation for the effects of weight decay. Based on
this discovery, we propose a new training method called FixNorm, which discards
weight decay and directly controls the two mechanisms. We also propose a simple
yet effective method to tune hyperparameters of FixNorm, which can find
near-optimal solutions in a few trials. On ImageNet classification task,
training EfficientNet-B0 with FixNorm achieves 77.7%, which outperforms the
original baseline by a clear margin. Surprisingly, when scaling MobileNetV2 to
the same FLOPS and applying the same tricks with EfficientNet-B0, training with
FixNorm achieves 77.4%, which is only 0.3% lower. A series of SOTA results show
the importance of well-tuned training procedures, and further verify the
effectiveness of our approach. We set up more well-tuned baselines using
FixNorm, to facilitate fair comparisons in the community.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15350</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Specification Mining</dc:title>
 <dc:creator>Kang, Hong Jin</dc:creator>
 <dc:creator>Lo, David</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  There have been numerous studies on mining temporal specifications from
execution traces. These approaches learn finite-state automata (FSA) from
execution traces when running tests. To learn accurate specifications of a
software system, many tests are required. Existing approaches generalize from a
limited number of traces or use simple test generation strategies.
Unfortunately, these strategies may not exercise uncommon usage patterns of a
software system. To address this problem, we propose a new approach,
adversarial specification mining, and develop a prototype, DICE (Diversity
through Counter-Examples). DICE has two components: DICE-Tester and DICE-Miner.
After mining Linear Temporal Logic specifications from an input test suite,
DICE-Tester adversarially guides test generation, searching for counterexamples
to these specifications to invalidate spurious properties. These
counterexamples represent gaps in the diversity of the input test suite. This
process produces execution traces of usage patterns that were unrepresented in
the input test suite. Next, we propose a new specification inference algorithm,
DICE-Miner, to infer FSAs using the traces, guided by the temporal
specifications. We find that the inferred specifications are of higher quality
than those produced by existing state-of-the-art specification miners. Finally,
we use the FSAs in a fuzzer for servers of stateful protocols, increasing its
coverage.
</dc:description>
 <dc:description>Comment: Kang, Hong Jin, and David Lo. &quot;Adversarial Specification Mining.&quot; ACM
  Transactions on Software Engineering and Methodology (TOSEM) 30.2 (2021):
  1-40. The version that is on arxiv is the authors' version. The definitive
  version can be found at https://dl.acm.org/doi/10.1145/3424307</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15350</dc:identifier>
 <dc:identifier>ACM Transactions on Software Engineering and Methodology (TOSEM)
  30.2 (2021): 1-40</dc:identifier>
 <dc:identifier>doi:10.1145/3424307</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15354</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Robust State Estimation by Boosting the Maximum Correntropy
  Criterion Kalman Filter with Adaptive Behaviors</dc:title>
 <dc:creator>Fakoorian, Seyed</dc:creator>
 <dc:creator>Santamaria-Navarro, Angel</dc:creator>
 <dc:creator>Lopez, Brett T.</dc:creator>
 <dc:creator>Simon, Dan</dc:creator>
 <dc:creator>Agha-mohammadi, Ali-akbar</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This work proposes a resilient and adaptive state estimation framework for
robots operating in perceptually-degraded environments. The approach, called
Adaptive Maximum Correntropy Criterion Kalman Filtering (AMCCKF), is inherently
robust to corrupted measurements, such as those containing jumps or general
non-Gaussian noise, and is able to modify filter parameters online to improve
performance. Two separate methods are developed -- the Variational Bayesian
AMCCKF (VB-AMCCKF) and Residual AMCCKF (R-AMCCKF) -- that modify the process
and measurement noise models in addition to the bandwidth of the kernel
function used in MCCKF based on the quality of measurements received. The two
approaches differ in computational complexity and overall performance which is
experimentally analyzed. The method is demonstrated in real experiments on both
aerial and ground robots and is part of the solution used by the COSTAR team
participating at the DARPA Subterranean Challenge.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15363</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Infinite-horizon Risk-constrained Linear Quadratic Regulator with
  Average Cost</dc:title>
 <dc:creator>Zhao, Feiran</dc:creator>
 <dc:creator>You, Keyou</dc:creator>
 <dc:creator>Basar, Tamer</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  The behaviour of a stochastic dynamical system may be largely influenced by
those low-probability, yet extreme events. To address such occurrences, this
paper proposes an infinite-horizon risk-constrained Linear Quadratic Regulator
(LQR) framework with time-average cost. In addition to the standard LQR
objective, the average one-stage predictive variance of the state penalty is
constrained to lie within a user-specified level. By leveraging the duality,
its optimal solution is first shown to be stationary and affine in the state,
i.e., $u(x,\lambda^*) = -K(\lambda^*)x + l(\lambda^*)$, where $\lambda^*$ is an
optimal multiplier, used to address the risk constraint. Then, we establish the
stability of the resulting closed-loop system. Furthermore, we propose a
primal-dual method with sublinear convergence rate to find an optimal policy
$u(x,\lambda^*)$. Finally, a numerical example is provided to demonstrate the
effectiveness of the proposed framework and the primal-dual method.
</dc:description>
 <dc:description>Comment: Submitted to IEEE CDC 2021</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15363</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15367</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint User Association and Power Allocation in Heterogeneous Ultra Dense
  Network via Semi-Supervised Representation Learning</dc:title>
 <dc:creator>Zhang, Xiangyu</dc:creator>
 <dc:creator>Zhang, Zhengming</dc:creator>
 <dc:creator>Yang, Luxi</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Heterogeneous Ultra-Dense Network (HUDN) is one of the vital networking
architectures due to its ability to enable higher connectivity density and
ultra-high data rates. Rational user association and power control schedule in
HUDN can reduce wireless interference. This paper proposes a novel idea for
resolving the joint user association and power control problem: the optimal
user association and Base Station transmit power can be represented by channel
information. Then, we solve this problem by formulating an optimal
representation function. We model the HUDNs as a heterogeneous graph and train
a Graph Neural Network (GNN) to approach this representation function by using
semi-supervised learning, in which the loss function is composed of the
unsupervised part that helps the GNN approach the optimal representation
function and the supervised part that utilizes the previous experience to
reduce useless exploration. We separate the learning process into two parts,
the generalization-representation learning (GRL) part and the
specialization-representation learning (SRL) part, which train the GNN for
learning representation for generalized scenario quasi-static user distribution
scenario, respectively. Simulation results demonstrate that the proposed
GRL-based solution has higher computational efficiency than the traditional
optimization algorithm, and the performance of SRL outperforms the GRL.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15368</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attention-guided Image Compression by Deep Reconstruction of Compressive
  Sensed Saliency Skeleton</dc:title>
 <dc:creator>Zhang, Xi</dc:creator>
 <dc:creator>Wu, Xiaolin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  We propose a deep learning system for attention-guided dual-layer image
compression (AGDL). In the AGDL compression system, an image is encoded into
two layers, a base layer and an attention-guided refinement layer. Unlike the
existing ROI image compression methods that spend an extra bit budget equally
on all pixels in ROI, AGDL employs a CNN module to predict those pixels on and
near a saliency sketch within ROI that are critical to perceptual quality. Only
the critical pixels are further sampled by compressive sensing (CS) to form a
very compact refinement layer. Another novel CNN method is developed to jointly
decode the two compression layers for a much refined reconstruction, while
strictly satisfying the transmitted CS constraints on perceptually critical
pixels. Extensive experiments demonstrate that the proposed AGDL system
advances the state of the art in perception-aware image compression.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2021</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15369</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contextual Scene Augmentation and Synthesis via GSACNet</dc:title>
 <dc:creator>Keshavarzi, Mohammad</dc:creator>
 <dc:creator>Reyes, Flaviano Christian</dc:creator>
 <dc:creator>Shrivastava, Ritika</dc:creator>
 <dc:creator>Afolabi, Oladapo</dc:creator>
 <dc:creator>Caldas, Luisa</dc:creator>
 <dc:creator>Yang, Allen Y.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Indoor scene augmentation has become an emerging topic in the field of
computer vision and graphics with applications in augmented and virtual
reality. However, current state-of-the-art systems using deep neural networks
require large datasets for training. In this paper we introduce GSACNet, a
contextual scene augmentation system that can be trained with limited scene
priors. GSACNet utilizes a novel parametric data augmentation method combined
with a Graph Attention and Siamese network architecture followed by an
Autoencoder network to facilitate training with small datasets. We show the
effectiveness of our proposed system by conducting ablation and comparative
studies with alternative systems on the Matterport3D dataset. Our results
indicate that our scene augmentation outperforms prior art in scene synthesis
with limited scene priors available.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:2009.12395 by other authors</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15369</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15370</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Reinforcement Learning under model misspecification</dc:title>
 <dc:creator>Yu, Lebin</dc:creator>
 <dc:creator>Wang, Jian</dc:creator>
 <dc:creator>Zhang, Xudong</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Reinforcement learning has achieved remarkable performance in a wide range of
tasks these days. Nevertheless, some unsolved problems limit its applications
in real-world control. One of them is model misspecification, a situation where
an agent is trained and deployed in environments with different transition
dynamics. We propose an novel framework that utilize history trajectory and
Partial Observable Markov Decision Process Modeling to deal with this dilemma.
Additionally, we put forward an efficient adversarial attack method to assist
robust training. Our experiments in four gym domains validate the effectiveness
of our framework.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15370</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15371</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Resource Management for MC-NOMA: A Deep Reinforcement Learning
  Approach</dc:title>
 <dc:creator>Wang, Shaoyang</dc:creator>
 <dc:creator>Lv, Tiejun</dc:creator>
 <dc:creator>Ni, Wei</dc:creator>
 <dc:creator>Beaulieu, Norman C.</dc:creator>
 <dc:creator>Guo, Y. Jay</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  This paper presents a novel and effective deep reinforcement learning
(DRL)-based approach to addressing joint resource management (JRM) in a
practical multi-carrier non-orthogonal multiple access (MC-NOMA) system, where
hardware sensitivity and imperfect successive interference cancellation (SIC)
are considered. We first formulate the JRM problem to maximize the weighted-sum
system throughput. Then, the JRM problem is decoupled into two iterative
subtasks: subcarrier assignment (SA, including user grouping) and power
allocation (PA). Each subtask is a sequential decision process. Invoking a deep
deterministic policy gradient algorithm, our proposed DRL-based JRM (DRL-JRM)
approach jointly performs the two subtasks, where the optimization objective
and constraints of the subtasks are addressed by a new joint reward and
internal reward mechanism. A multi-agent structure and a convolutional neural
network are adopted to reduce the complexity of the PA subtask. We also tailor
the neural network structure for the stability and convergence of DRL-JRM.
Corroborated by extensive experiments, the proposed DRL-JRM scheme is superior
to existing alternatives in terms of system throughput and resistance to
interference, especially in the presence of many users and strong inter-cell
interference. DRL-JRM can flexibly meet individual service requirements of
users.
</dc:description>
 <dc:description>Comment: 14 pages, 10 figures, Accepted by IEEE Transactions on Wireless
  Communications</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15371</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2021.3069240</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15374</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lifelong Learning for Minimizing Age of Information in Internet of
  Things Networks</dc:title>
 <dc:creator>Gong, Zhenzhen</dc:creator>
 <dc:creator>Cui, Qimei</dc:creator>
 <dc:creator>Chaccour, Christina</dc:creator>
 <dc:creator>Zhou, Bo</dc:creator>
 <dc:creator>Chen, Mingzhe</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  In this paper, a lifelong learning problem is studied for an Internet of
Things (IoT) system. In the considered model, each IoT device aims to balance
its information freshness and energy consumption tradeoff by controlling its
computational resource allocation at each time slot under dynamic environments.
An unmanned aerial vehicle (UAV) is deployed as a flying base station so as to
enable the IoT devices to adapt to novel environments. To this end, a new
lifelong reinforcement learning algorithm, used by the UAV, is proposed in
order to adapt the operation of the devices at each visit by the UAV. By using
the experience from previously visited devices and environments, the UAV can
help devices adapt faster to future states of their environment. To do so, a
knowledge base shared by all devices is maintained at the UAV. Simulation
results show that the proposed algorithm can converge $25\%$ to $50\%$ faster
than a policy gradient baseline algorithm that optimizes each device's decision
making problem in isolation.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, conference</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15374</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15379</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Conversion Technique from Nodal to Edge Finite Element Data
  Structure for Electromagnetic Analysis</dc:title>
 <dc:creator>Kamireddy, Durgarao</dc:creator>
 <dc:creator>Nandy, Arup</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Standard nodal finite elements in electromagnetic analysis have well-known
limitation of occurrence of spurious solution. In order to circumvent the
problem, a penalty function method or a regularization method is used with
potential formulation. These methods solve the problem partially by pushing the
spurious mode to the higher end of the spectrum. But it fails to capture
singular eigenvalues in case of the problem domains with sharp edges and
corners. To circumvent this limitation, edge elements have been developed for
electromagnetic analysis where degree of freedoms are along the edges. But most
of the preprocessors develop complex meshes in nodal framework. In this work,
we have developed a novel technique to convert nodal data structure to edge
data structure for electromagnetic analysis. We have explained the conversion
algorithm in details, mentioning associated complexities with relevant
examples. The performance of the developed algorithm has been demonstrated
extensively with several examples.
</dc:description>
 <dc:description>Comment: 21 pages, 19 figures, 17 tables</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15381</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing Coordinated Motion Plans for Robot Swarms: The CG:SHOP
  Challenge 2021</dc:title>
 <dc:creator>Fekete, S&#xe1;ndor P.</dc:creator>
 <dc:creator>Keldenich, Phillip</dc:creator>
 <dc:creator>Krupke, Dominik</dc:creator>
 <dc:creator>Mitchell, Joseph S. B.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:description>  We give an overview of the 2021 Computational Geometry Challenge, which
targeted the problem of optimally coordinating a set of robots by computing a
family of collision-free trajectories for a set set S of n pixel-shaped objects
from a given start configuration into a desired target configuration.
</dc:description>
 <dc:description>Comment: 13 pages, 8 figures, 2 tables</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15385</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lagrangian Objective Function Leads to Improved Unforeseen Attack
  Generalization in Adversarial Training</dc:title>
 <dc:creator>Azizmalayeri, Mohammad</dc:creator>
 <dc:creator>Rohban, Mohammad Hossein</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent improvements in deep learning models and their practical applications
have raised concerns about the robustness of these models against adversarial
examples. Adversarial training (AT) has been shown effective to reach a robust
model against the attack that is used during training. However, it usually
fails against other attacks, i.e. the model overfits to the training attack
scheme. In this paper, we propose a simple modification to the AT that
mitigates the mentioned issue. More specifically, we minimize the perturbation
$\ell_p$ norm while maximizing the classification loss in the Lagrangian form.
We argue that crafting adversarial examples based on this scheme results in
enhanced attack generalization in the learned model. We compare our final model
robust accuracy against attacks that were not used during training to closely
related state-of-the-art AT methods. This comparison demonstrates that our
average robust accuracy against unseen attacks is 5.9% higher in the CIFAR-10
dataset and is 3.2% higher in the ImageNet-100 dataset than corresponding
state-of-the-art methods. We also demonstrate that our attack is faster than
other attack schemes that are designed for unseen attack generalization, and
conclude that it is feasible for large-scale datasets.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15386</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-Scale Approximate k-NN Graph Construction on GPU</dc:title>
 <dc:creator>Wang, Hui</dc:creator>
 <dc:creator>Zhao, Wan-Lei</dc:creator>
 <dc:creator>Zeng, Xiangxiang</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  k-nearest neighbor graph is a key data structure in many disciplines such as
manifold learning, machine learning and information retrieval, etc. NN-Descent
was proposed as an effective solution for the graph construction problem.
However, it cannot be directly transplanted to GPU due to the intensive memory
accesses required in the approach. In this paper, NN-Descent has been
redesigned to adapt to the GPU architecture. In particular, the number of
memory accesses has been reduced significantly. The redesign fully exploits the
parallelism of the GPU hardware. In the meantime, the genericness as well as
the simplicity of NN-Descent are well-preserved. In addition, a simple but
effective k-NN graph merge approach is presented. It allows two graphs to be
merged efficiently on GPUs. More importantly, it makes the construction of
high-quality k-NN graphs for out-of-GPU-memory datasets tractable. The results
show that our approach is 100-250x faster than single-thread NN-Descent and is
2.5-5x faster than existing GPU-based approaches.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15395</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>No frame left behind: Full Video Action Recognition</dc:title>
 <dc:creator>Liu, Xin</dc:creator>
 <dc:creator>Pintea, Silvia L.</dc:creator>
 <dc:creator>Nejadasl, Fatemeh Karimi</dc:creator>
 <dc:creator>Booij, Olaf</dc:creator>
 <dc:creator>van Gemert, Jan C.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Not all video frames are equally informative for recognizing an action. It is
computationally infeasible to train deep networks on all video frames when
actions develop over hundreds of frames. A common heuristic is uniformly
sampling a small number of video frames and using these to recognize the
action. Instead, here we propose full video action recognition and consider all
video frames. To make this computational tractable, we first cluster all frame
activations along the temporal dimension based on their similarity with respect
to the classification task, and then temporally aggregate the frames in the
clusters into a smaller number of representations. Our method is end-to-end
trainable and computationally efficient as it relies on temporally localized
clustering in combination with fast Hamming distances in feature space. We
evaluate on UCF101, HMDB51, Breakfast, and Something-Something V1 and V2, where
we compare favorably to existing heuristic frame sampling methods.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2021</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15395</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15399</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fatigue crack propagation in carbon steel using RVE based model</dc:title>
 <dc:creator>Cheng, Zhenxing</dc:creator>
 <dc:creator>Wang, Hu</dc:creator>
 <dc:creator>Liu, Gui-Rong</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  A representative volume element (RVE) based multi-scale method is proposed to
investigate the mechanism of fatigue crack propagation by the molecular
dynamics (MD) and the extended finite element methods(XFEM) in this study. An
atomic model of carbon steel plate is built to study the behavior of fatigue
crack at the micro scale by MD method. Then the RVE model for fatigue crack
propagation should be built by fitting the data which was obtained from the MD
result with the Paris law model. Moreover, the effect of micro-structural
defects including interstitial atoms, vacancies have also been considered in
this study. The results indicate that the micro-structural defects can deeply
influence the values of Paris law constants and the life of the specimen can be
evaluated by the proposed method.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15399</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15406</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fundamental Challenges in Deep Learning for Stiff Contact Dynamics</dc:title>
 <dc:creator>Parmar, Mihir</dc:creator>
 <dc:creator>Halm, Mathew</dc:creator>
 <dc:creator>Posa, Michael</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Frictional contact has been extensively studied as the core underlying
behavior of legged locomotion and manipulation, and its nearly-discontinuous
nature makes planning and control difficult even when an accurate model of the
robot is available. Here, we present empirical evidence that learning an
accurate model in the first place can be confounded by contact, as modern deep
learning approaches are not designed to capture this non-smoothness. We isolate
the effects of contact's non-smoothness by varying the mechanical stiffness of
a compliant contact simulator. Even for a simple system, we find that stiffness
alone dramatically degrades training processes, generalization, and
data-efficiency. Our results raise serious questions about simulated testing
environments which do not accurately reflect the stiffness of rigid robotic
hardware. Significant additional investigation will be necessary to fully
understand and mitigate these effects, and we suggest several avenues for
future study.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15406</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15409</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Dataset and Benchmark Towards Multi-Modal Face Anti-Spoofing Under
  Surveillance Scenarios</dc:title>
 <dc:creator>Chen, Xudong</dc:creator>
 <dc:creator>Xu, Shugong</dc:creator>
 <dc:creator>Ji, Qiaobin</dc:creator>
 <dc:creator>Cao, Shan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Face Anti-spoofing (FAS) is a challenging problem due to complex serving
scenarios and diverse face presentation attack patterns. Especially when
captured images are low-resolution, blurry, and coming from different domains,
the performance of FAS will degrade significantly. The existing multi-modal FAS
datasets rarely pay attention to the cross-domain problems under deployment
scenarios, which is not conducive to the study of model performance. To solve
these problems, we explore the fine-grained differences between multi-modal
cameras and construct a cross-domain multi-modal FAS dataset under surveillance
scenarios called GREAT-FASD-S. Besides, we propose an Attention based Face
Anti-spoofing network with Feature Augment (AFA) to solve the FAS towards
low-quality face images. It consists of the depthwise separable attention
module (DAM) and the multi-modal based feature augment module (MFAM). Our model
can achieve state-of-the-art performance on the CASIA-SURF dataset and our
proposed GREAT-FASD-S dataset.
</dc:description>
 <dc:description>Comment: Published in: IEEE Access</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15409</dc:identifier>
 <dc:identifier>IEEE Access, vol. 9, pp. 28140-28155, 2021</dc:identifier>
 <dc:identifier>doi:10.1109/ACCESS.2021.3052728</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15416</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance-based Trajectory Optimization for Path Following Control
  Using Bayesian Optimization</dc:title>
 <dc:creator>Rupenyan, Alisa</dc:creator>
 <dc:creator>Khosravi, Mohammad</dc:creator>
 <dc:creator>Lygeros, John</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Accurate positioning and fast traversal times determine the productivity in
machining applications. This paper demonstrates a hierarchical contour control
implementation for the increase of productivity in positioning systems. The
high-level controller pre-optimizes the input to a low-level cascade
controller, using a contouring predictive control approach. This control
structure requires tuning of multiple parameters. We propose a sample-efficient
joint tuning algorithm, where the performance metrics associated with the full
geometry traversal are modelled as Gaussian processes and used to form the
global cost and the constraints in a constrained Bayesian optimization
algorithm. This approach enables the trade-off between fast traversal, high
tracking accuracy, and suppression of vibrations in the system. The performance
improvement is evaluated numerically when tuning different combinations of
parameters. We demonstrate that jointly tuning the parameters of the contour-
and the low-level controller achieves the best performance in terms of time,
tracking accuracy, and minimization of the vibrations in the system.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15416</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15425</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FocusedDropout for Convolutional Neural Network</dc:title>
 <dc:creator>Xie, Tianshu</dc:creator>
 <dc:creator>Liu, Minghui</dc:creator>
 <dc:creator>Deng, Jiali</dc:creator>
 <dc:creator>Cheng, Xuan</dc:creator>
 <dc:creator>Wang, Xiaomin</dc:creator>
 <dc:creator>Liu, Ming</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In convolutional neural network (CNN), dropout cannot work well because
dropped information is not entirely obscured in convolutional layers where
features are correlated spatially. Except randomly discarding regions or
channels, many approaches try to overcome this defect by dropping influential
units. In this paper, we propose a non-random dropout method named
FocusedDropout, aiming to make the network focus more on the target. In
FocusedDropout, we use a simple but effective way to search for the
target-related features, retain these features and discard others, which is
contrary to the existing methods. We found that this novel method can improve
network performance by making the network more target-focused. Besides,
increasing the weight decay while using FocusedDropout can avoid the
overfitting and increase accuracy. Experimental results show that even a slight
cost, 10\% of batches employing FocusedDropout, can produce a nice performance
boost over the baselines on multiple datasets of classification, including
CIFAR10, CIFAR100, Tiny Imagenet, and has a good versatility for different CNN
models.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15428</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PlaneSegNet: Fast and Robust Plane Estimation Using a Single-stage
  Instance Segmentation CNN</dc:title>
 <dc:creator>Xie, Yaxu</dc:creator>
 <dc:creator>Rambach, Jason</dc:creator>
 <dc:creator>Shu, Fangwen</dc:creator>
 <dc:creator>Stricker, Didier</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Instance segmentation of planar regions in indoor scenes benefits visual SLAM
and other applications such as augmented reality (AR) where scene understanding
is required. Existing methods built upon two-stage frameworks show satisfactory
accuracy but are limited by low frame rates. In this work, we propose a
real-time deep neural architecture that estimates piece-wise planar regions
from a single RGB image. Our model employs a variant of a fast single-stage CNN
architecture to segment plane instances. Considering the particularity of the
target detected, we propose Fast Feature Non-maximum Suppression (FF-NMS) to
reduce the suppression errors resulted from overlapping bounding boxes of
planes. We also utilize a Residual Feature Augmentation module in the Feature
Pyramid Network (FPN). Our method achieves significantly higher frame-rates and
comparable segmentation accuracy against two-stage methods. We automatically
label over 70,000 images as ground truth from the Stanford 2D-3D-Semantics
dataset. Moreover, we incorporate our method with a state-of-the-art planar
SLAM and validate its benefits.
</dc:description>
 <dc:description>Comment: accepted to ICRA 2021</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15428</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15436</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transformer Tracking</dc:title>
 <dc:creator>Chen, Xin</dc:creator>
 <dc:creator>Yan, Bin</dc:creator>
 <dc:creator>Zhu, Jiawen</dc:creator>
 <dc:creator>Wang, Dong</dc:creator>
 <dc:creator>Yang, Xiaoyun</dc:creator>
 <dc:creator>Lu, Huchuan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Correlation acts as a critical role in the tracking field, especially in
recent popular Siamese-based trackers. The correlation operation is a simple
fusion manner to consider the similarity between the template and the search
region. However, the correlation operation itself is a local linear matching
process, leading to lose semantic information and fall into local optimum
easily, which may be the bottleneck of designing high-accuracy tracking
algorithms. Is there any better feature fusion method than correlation? To
address this issue, inspired by Transformer, this work presents a novel
attention-based feature fusion network, which effectively combines the template
and search region features solely using attention. Specifically, the proposed
method includes an ego-context augment module based on self-attention and a
cross-feature augment module based on cross-attention. Finally, we present a
Transformer tracking (named TransT) method based on the Siamese-like feature
extraction backbone, the designed attention-based fusion mechanism, and the
classification and regression head. Experiments show that our TransT achieves
very promising results on six challenging datasets, especially on large-scale
LaSOT, TrackingNet, and GOT-10k benchmarks. Our tracker runs at approximatively
50 fps on GPU. Code and models are available at
https://github.com/chenxin-dlut/TransT.
</dc:description>
 <dc:description>Comment: Accepted by CVPR2021</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15438</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Predict Salient Faces: A Novel Visual-Audio Saliency Model</dc:title>
 <dc:creator>Liu, Yufan</dc:creator>
 <dc:creator>Qiao, Minglang</dc:creator>
 <dc:creator>Xu, Mai</dc:creator>
 <dc:creator>Li, Bing</dc:creator>
 <dc:creator>Hu, Weiming</dc:creator>
 <dc:creator>Borji, Ali</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, video streams have occupied a large proportion of Internet traffic,
most of which contain human faces. Hence, it is necessary to predict saliency
on multiple-face videos, which can provide attention cues for many content
based applications. However, most of multiple-face saliency prediction works
only consider visual information and ignore audio, which is not consistent with
the naturalistic scenarios. Several behavioral studies have established that
sound influences human attention, especially during the speech turn-taking in
multiple-face videos. In this paper, we thoroughly investigate such influences
by establishing a large-scale eye-tracking database of Multiple-face Video in
Visual-Audio condition (MVVA). Inspired by the findings of our investigation,
we propose a novel multi-modal video saliency model consisting of three
branches: visual, audio and face. The visual branch takes the RGB frames as the
input and encodes them into visual feature maps. The audio and face branches
encode the audio signal and multiple cropped faces, respectively. A fusion
module is introduced to integrate the information from three modalities, and to
generate the final saliency map. Experimental results show that the proposed
method outperforms 11 state-of-the-art saliency prediction works. It performs
closer to human multi-modal attention.
</dc:description>
 <dc:description>Comment: Published as an ECCV2020 paper</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15438</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-030-58565-5_25</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15446</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Image Compositing</dc:title>
 <dc:creator>Aneja, Shivangi</dc:creator>
 <dc:creator>Mazumder, Soham</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In image editing, the most common task is pasting objects from one image to
the other and then eventually adjusting the manifestation of the foreground
object with the background object. This task is called image compositing. But
image compositing is a challenging problem that requires professional editing
skills and a considerable amount of time. Not only these professionals are
expensive to hire, but the tools (like Adobe Photoshop) used for doing such
tasks are also expensive to purchase making the overall task of image
compositing difficult for people without this skillset. In this work, we aim to
cater to this problem by making composite images look realistic. To achieve
this, we are using Generative Adversarial Networks (GANS). By training the
network with a diverse range of filters applied to the images and special loss
functions, the model is able to decode the color histogram of the foreground
and background part of the image and also learns to blend the foreground object
with the background. The hue and saturation values of the image play an
important role as discussed in this paper. To the best of our knowledge, this
is the first work that uses GANs for the task of image compositing. Currently,
there is no benchmark dataset available for image compositing. So we created
the dataset and will also make the dataset publicly available for benchmarking.
Experimental results on this dataset show that our method outperforms all
current state-of-the-art methods.
</dc:description>
 <dc:description>Comment: ESSE 2020: Proceedings of the 2020 European Symposium on Software
  Engineering</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15446</dc:identifier>
 <dc:identifier>In Proceedings of the 2020 European Symposium on Software
  Engineering (pp. 101-104) 2020</dc:identifier>
 <dc:identifier>doi:10.1145/3393822.3432314</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15447</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Network Embedding Survey</dc:title>
 <dc:creator>Xue, Guotong</dc:creator>
 <dc:creator>Zhong, Ming</dc:creator>
 <dc:creator>Li, Jianxin</dc:creator>
 <dc:creator>Chen, Jia</dc:creator>
 <dc:creator>Zhai, Chengshuai</dc:creator>
 <dc:creator>Kong, Ruochen</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Since many real world networks are evolving over time, such as social
networks and user-item networks, there are increasing research efforts on
dynamic network embedding in recent years. They learn node representations from
a sequence of evolving graphs but not only the latest network, for preserving
both structural and temporal information from the dynamic networks. Due to the
lack of comprehensive investigation of them, we give a survey of dynamic
network embedding in this paper. Our survey inspects the data model,
representation learning technique, evaluation and application of current
related works and derives common patterns from them. Specifically, we present
two basic data models, namely, discrete model and continuous model for dynamic
networks. Correspondingly, we summarize two major categories of dynamic network
embedding techniques, namely, structural-first and temporal-first that are
adopted by most related works. Then we build a taxonomy that refines the
category hierarchy by typical learning models. The popular experimental data
sets and applications are also summarized. Lastly, we have a discussion of
several distinct research topics in dynamic network embedding.
</dc:description>
 <dc:description>Comment: Neurocomputing accepted</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15447</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15448</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring, browsing and interacting with multi-scale structures of
  knowledge</dc:title>
 <dc:creator>Lobb&#xe9;, Quentin</dc:creator>
 <dc:creator>Delano&#xeb;, Alexandre</dc:creator>
 <dc:creator>Chavalarias, David</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The ICT revolution has given birth to a world of digital traces. A wide
number of knowledgedriven domains like science are daily fueled by unlimited
flows of textual contents. In order to navigate across these growing
constellations of words, interdisciplinary innovations are emerging at the
crossroad between social and computational sciences. In particular, complex
systems approaches make it now possible to reconstruct multi-level and
multi-scale structures of knowledge by means of phylomemies: inheritance
networks of elements of knowledge. In this article, we will introduce an
endogenous way to visualize the outcomes of the phylomemy reconstruction
process by combining both synchronic and diachronic approaches. Our aim is to
translate high-dimensional phylomemetic networks into graphical projections and
interactive visualizations. To that end, we will use seabed and kinship views
to translate the multilevel and multi-scale properties of complex branches of
knowledge. We will then define a generic macro-to-micro methodology of
exploration implemented within an open source software called Memiescape and
validate our approach by browsing through the reconstructed histories of
thousands of scientific publications and clinical trials.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15448</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15451</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pairing Character Classes in a Deathmatch Shooter Game via a
  Deep-Learning Surrogate Model</dc:title>
 <dc:creator>Karavolos, Daniel</dc:creator>
 <dc:creator>Liapis, Antonios</dc:creator>
 <dc:creator>Yannakakis, Georgios N.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  This paper introduces a surrogate model of gameplay that learns the mapping
between different game facets, and applies it to a generative system which
designs new content in one of these facets. Focusing on the shooter game genre,
the paper explores how deep learning can help build a model which combines the
game level structure and the game's character class parameters as input and the
gameplay outcomes as output. The model is trained on a large corpus of game
data from simulations with artificial agents in random sets of levels and class
parameters. The model is then used to generate classes for specific levels and
for a desired game outcome, such as balanced matches of short duration.
Findings in this paper show that the system can be expressive and can generate
classes for both computer generated and human authored levels.
</dc:description>
 <dc:description>Comment: Proceedings of the FDG Workshop on Procedural Content Generation,
  2018, 10 pages</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15451</dc:identifier>
 <dc:identifier>doi:10.1145/3235765.3235816</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15452</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boosting the Speed of Entity Alignment 10*: Dual Attention Matching
  Network with Normalized Hard Sample Mining</dc:title>
 <dc:creator>Mao, Xin</dc:creator>
 <dc:creator>Wang, Wenting</dc:creator>
 <dc:creator>Wu, Yuanbin</dc:creator>
 <dc:creator>Lan, Man</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Seeking the equivalent entities among multi-source Knowledge Graphs (KGs) is
the pivotal step to KGs integration, also known as \emph{entity alignment}
(EA). However, most existing EA methods are inefficient and poor in
scalability. A recent summary points out that some of them even require several
days to deal with a dataset containing 200,000 nodes (DWY100K). We believe
over-complex graph encoder and inefficient negative sampling strategy are the
two main reasons. In this paper, we propose a novel KG encoder -- Dual
Attention Matching Network (Dual-AMN), which not only models both intra-graph
and cross-graph information smartly, but also greatly reduces computational
complexity. Furthermore, we propose the Normalized Hard Sample Mining Loss to
smoothly select hard negative samples with reduced loss shift. The experimental
results on widely used public datasets indicate that our method achieves both
high accuracy and high efficiency. On DWY100K, the whole running process of our
method could be finished in 1,100 seconds, at least 10* faster than previous
work. The performances of our method also outperform previous works across all
datasets, where Hits@1 and MRR have been improved from 6% to 13%.
</dc:description>
 <dc:description>Comment: 12 pages; Accepted by TheWebConf(WWW) 2021</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15452</dc:identifier>
 <dc:identifier>doi:10.1145/3442381.3449897</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15453</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Disentangling Parallelism and Interference in Game Semantics</dc:title>
 <dc:creator>Castellan, Simon</dc:creator>
 <dc:creator>Clairambault, Pierre</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Game semantics is a denotational semantics presenting compositionally the
computational behaviour of various kinds of effectful programs. One of its
celebrated achievement is to have obtained full abstraction results for
programming languages with a variety of computational effects, in a single
framework. This is known as the semantic cube or Abramsky's cube, which for
sequential deterministic programs establishes a correspondence between certain
conditions on strategies (''innocence'', ''well-bracketing'', ''visibility'')
and the absence of matching computational effects. Outside of the sequential
deterministic realm, there are still a wealth of game semantics-based full
abstraction results; but they no longer fit in a unified canvas. In particular,
Ghica and Murawski's fully abstract model for shared state concurrency (IA)
does not have a matching notion of pure parallel program-we say that
parallelism and interference (i.e. state plus semaphores) are entangled. In
this paper we construct a causal version of Ghica and Murawski's model, also
fully abstract for IA. We provide compositional conditions parallel innocence
and sequentiality, respectively banning interference and parallelism, and
leading to four full abstraction results. To our knowledge, this is the first
extension of Abramsky's semantic cube programme beyond the sequential
deterministic world.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15453</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15454</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proxy Synthesis: Learning with Synthetic Classes for Deep Metric
  Learning</dc:title>
 <dc:creator>Gu, Geonmo</dc:creator>
 <dc:creator>Ko, Byungsoo</dc:creator>
 <dc:creator>Kim, Han-Gyu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  One of the main purposes of deep metric learning is to construct an embedding
space that has well-generalized embeddings on both seen (training) classes and
unseen (test) classes. Most existing works have tried to achieve this using
different types of metric objectives and hard sample mining strategies with
given training data. However, learning with only the training data can be
overfitted to the seen classes, leading to the lack of generalization
capability on unseen classes. To address this problem, we propose a simple
regularizer called Proxy Synthesis that exploits synthetic classes for stronger
generalization in deep metric learning. The proposed method generates synthetic
embeddings and proxies that work as synthetic classes, and they mimic unseen
classes when computing proxy-based losses. Proxy Synthesis derives an embedding
space considering class relations and smooth decision boundaries for robustness
on unseen classes. Our method is applicable to any proxy-based losses,
including softmax and its variants. Extensive experiments on four famous
benchmarks in image retrieval tasks demonstrate that Proxy Synthesis
significantly boosts the performance of proxy-based losses and achieves
state-of-the-art performance.
</dc:description>
 <dc:description>Comment: Accepted by AAAI2021</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15454</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15456</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monitoring Object Detection Abnormalities via Data-Label and
  Post-Algorithm Abstractions</dc:title>
 <dc:creator>Chen, Yuhang</dc:creator>
 <dc:creator>Cheng, Chih-Hong</dc:creator>
 <dc:creator>Yan, Jun</dc:creator>
 <dc:creator>Yan, Rongjie</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  While object detection modules are essential functionalities for any
autonomous vehicle, the performance of such modules that are implemented using
deep neural networks can be, in many cases, unreliable. In this paper, we
develop abstraction-based monitoring as a logical framework for filtering
potentially erroneous detection results. Concretely, we consider two types of
abstraction, namely data-label abstraction and post-algorithm abstraction.
Operated on the training dataset, the construction of data-label abstraction
iterates each input, aggregates region-wise information over its associated
labels, and stores the vector under a finite history length. Post-algorithm
abstraction builds an abstract transformer for the tracking algorithm. Elements
being associated together by the abstract transformer can be checked against
consistency over their original values. We have implemented the overall
framework to a research prototype and validated it using publicly available
object detection datasets.
</dc:description>
 <dc:description>Comment: Work in progress report</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15456</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15459</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capsule Network is Not More Robust than Convolutional Network</dc:title>
 <dc:creator>Gu, Jindong</dc:creator>
 <dc:creator>Tresp, Volker</dc:creator>
 <dc:creator>Hu, Han</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The Capsule Network is widely believed to be more robust than Convolutional
Networks. However, there are no comprehensive comparisons between these two
networks, and it is also unknown which components in the CapsNet affect its
robustness. In this paper, we first carefully examine the special designs in
CapsNet that differ from that of a ConvNet commonly used for image
classification. The examination reveals five major new/different components in
CapsNet: a transformation process, a dynamic routing layer, a squashing
function, a marginal loss other than cross-entropy loss, and an additional
class-conditional reconstruction loss for regularization. Along with these
major differences, we conduct comprehensive ablation studies on three kinds of
robustness, including affine transformation, overlapping digits, and semantic
representation. The study reveals that some designs, which are thought critical
to CapsNet, actually can harm its robustness, i.e., the dynamic routing layer
and the transformation process, while others are beneficial for the robustness.
Based on these findings, we propose enhanced ConvNets simply by introducing the
essential components behind the CapsNet's success. The proposed simple ConvNets
can achieve better robustness than the CapsNet.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15459</dc:identifier>
 <dc:identifier>IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
  2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15462</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Situated Case Studies for a Human-Centered Design of Explanation User
  Interfaces</dc:title>
 <dc:creator>M&#xfc;ller-Birn, Claudia</dc:creator>
 <dc:creator>Glinka, Katrin</dc:creator>
 <dc:creator>S&#xf6;rries, Peter</dc:creator>
 <dc:creator>Tebbe, Michael</dc:creator>
 <dc:creator>Michl, Susanne</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Researchers and practitioners increasingly consider a human-centered
perspective in the design of machine learning-based applications, especially in
the context of Explainable Artificial Intelligence (XAI). However, clear
methodological guidance in this context is still missing because each new
situation seems to require a new setup, which also creates different
methodological challenges. Existing case study collections in XAI inspired us;
therefore, we propose a similar collection of case studies for human-centered
XAI that can provide methodological guidance or inspiration for others. We want
to showcase our idea in this workshop by describing three case studies from our
research. These case studies are selected to highlight how apparently small
differences require a different set of methods and considerations. With this
workshop contribution, we would like to engage in a discussion on how such a
collection of case studies can provide a methodological guidance and critical
reflection.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15462</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15471</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Explicit Construction of Minimum Storage Rack-Aware Regenerating Codes
  for All Parameters</dc:title>
 <dc:creator>Zhou, Liyang</dc:creator>
 <dc:creator>Zhang, Zhifang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the rack-aware storage system where $n=\bar{n}u$ nodes are
organized in $\bar{n}$ racks each containing $u$ nodes, and any
$k=\bar{k}u+u_0~(0\leq u_0&lt;u)$ nodes can retrieve the original data file. More
importantly, the cross-rack communication cost is much more expensive than the
intra-rack communication cost, so that the latter is usually neglected in the
system bandwidth. The MSRR (minimum storage rack-aware regenerating) code is an
important variation of regenerating codes that achieves the optimal repair
bandwidth for single node failures in the rack-aware model. However, explicit
construction of MSRR codes for all parameters were not developed until
Chen\&amp;Barg's work. In this paper we present another explicit construction of
MSRR codes for all parameters that improve Chen\&amp;Barg's construction in two
aspects: (1) The sub-packetization is reduced from
$(\bar{d}-\bar{k}+1)^{\bar{n}}$ to
$(\bar{d}-\bar{k}+1)^{\lceil\frac{\bar{n}}{u-u_{0}}\rceil}$ where $\bar{d}$ is
the number of helper racks that participate in the repair process; (2) The
field size is reduced to $|F|&gt;n$ which is almost half of the field used in
Chen\&amp;Barg's construction. Besides, our code keeps the same access level as
Chen\&amp;Barg's low-access construction.
</dc:description>
 <dc:description>Comment: 5 pages, To appear in ITW 2020</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15471</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15472</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>View-Dependent Formulation of 2.5D Cartoon Models</dc:title>
 <dc:creator>Fukusato, Tsukasa</dc:creator>
 <dc:creator>Maejima, Akinobu</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  2.5D cartoon models are methods to simulate three-dimensional (3D)-like
movements, such as out-of-plane rotation, from two-dimensional (2D) shapes in
different views. However, cartoon objects and characters have several distorted
parts which do not correspond to any real 3D positions (e.g., Mickey Mouse's
ears), that implies that existing systems are not suitable for designing such
representations. Hence, we formulate it as a view-dependent deformation (VDD)
problem, which has been proposed in the field of 3D character animation. The
distortions in an arbitrary viewpoint are automatically obtained by blending
the user-specified 2D shapes of key views. This model is simple enough to
easily implement in an existing animation system. Several examples demonstrate
the robustness of our method over previous methods. In addition, we conduct a
user study and confirm that the proposed system is effective for animating
classic cartoon characters.
</dc:description>
 <dc:description>Comment: 11 pages, 13 figures</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15472</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15476</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ZeroGrad : Mitigating and Explaining Catastrophic Overfitting in FGSM
  Adversarial Training</dc:title>
 <dc:creator>Golgooni, Zeinab</dc:creator>
 <dc:creator>Saberi, Mehrdad</dc:creator>
 <dc:creator>Eskandar, Masih</dc:creator>
 <dc:creator>Rohban, Mohammad Hossein</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Making deep neural networks robust to small adversarial noises has recently
been sought in many applications. Adversarial training through iterative
projected gradient descent (PGD) has been established as one of the mainstream
ideas to achieve this goal. However, PGD is computationally demanding and often
prohibitive in case of large datasets and models. For this reason, single-step
PGD, also known as FGSM, has recently gained interest in the field.
Unfortunately, FGSM-training leads to a phenomenon called ``catastrophic
overfitting,&quot; which is a sudden drop in the adversarial accuracy under the PGD
attack. In this paper, we support the idea that small input gradients play a
key role in this phenomenon, and hence propose to zero the input gradient
elements that are small for crafting FGSM attacks. Our proposed idea, while
being simple and efficient, achieves competitive adversarial accuracy on
various datasets.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15484</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A hybrid controller for safe and efficient collision avoidance control</dc:title>
 <dc:creator>Wang, Qiang</dc:creator>
 <dc:creator>Zheng, Xinlei</dc:creator>
 <dc:creator>Zhang, Jiyong</dc:creator>
 <dc:creator>Sifakis, Joseph</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  We design and experimentally evaluate a hybrid safe-by-construction collision
avoidance controller for autonomous vehicles. The controller combines into a
single architecture the respective advantages of an adaptive controller and a
discrete safe controller. The adaptive controller relies on model predictive
control to achieve optimal efficiency in nominal conditions. The safe
controller avoids collision by applying two different policies, for nominal and
out-of-nominal conditions, respectively. We present design principles for both
the adaptive and the safe controller and show how each one can contribute in
the hybrid architecture to improve performance, road occupancy and passenger
comfort while preserving safety. The experimental results confirm the
feasibility of the approach and the practical relevance of hybrid controllers
for safe and efficient driving.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15484</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15486</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ClaRe: Practical Class Incremental Learning By Remembering Previous
  Class Representations</dc:title>
 <dc:creator>Mohammadi, Bahram</dc:creator>
 <dc:creator>Sabokrou, Mohammad</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a practical and simple yet efficient method to
effectively deal with the catastrophic forgetting for Class Incremental
Learning (CIL) tasks. CIL tends to learn new concepts perfectly, but not at the
expense of performance and accuracy for old data. Learning new knowledge in the
absence of data instances from previous classes or even imbalance samples of
both old and new classes makes CIL an ongoing challenging problem. These issues
can be tackled by storing exemplars belonging to the previous tasks or by
utilizing the rehearsal strategy. Inspired by the rehearsal strategy with the
approach of using generative models, we propose ClaRe, an efficient solution
for CIL by remembering the representations of learned classes in each
increment. Taking this approach leads to generating instances with the same
distribution of the learned classes. Hence, our model is somehow retrained from
the scratch using a new training set including both new and the generated
samples. Subsequently, the imbalance data problem is also solved. ClaRe has a
better generalization than prior methods thanks to producing diverse instances
from the distribution of previously learned classes. We comprehensively
evaluate ClaRe on the MNIST benchmark. Results show a very low degradation on
accuracy against facing new knowledge over time. Furthermore, contrary to the
most proposed solutions, the memory limitation is not problematic any longer
which is considered as a consequential issue in this research area.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15486</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15488</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracking Based Semi-Automatic Annotation for Scene Text Videos</dc:title>
 <dc:creator>Zhu, Jiajun</dc:creator>
 <dc:creator>Jiang, Xiufeng</dc:creator>
 <dc:creator>Jia, Zhiwei</dc:creator>
 <dc:creator>Xu, Shugong</dc:creator>
 <dc:creator>Cao, Shan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, video scene text detection has received increasing attention due to
its comprehensive applications. However, the lack of annotated scene text video
datasets has become one of the most important problems, which hinders the
development of video scene text detection. The existing scene text video
datasets are not large-scale due to the expensive cost caused by manual
labeling. In addition, the text instances in these datasets are too clear to be
a challenge. To address the above issues, we propose a tracking based
semi-automatic labeling strategy for scene text videos in this paper. We get
semi-automatic scene text annotation by labeling manually for the first frame
and tracking automatically for the subsequent frames, which avoid the huge cost
of manual labeling. Moreover, a paired low-quality scene text video dataset
named Text-RBL is proposed, consisting of raw videos, blurry videos, and
low-resolution videos, labeled by the proposed convenient semi-automatic
labeling strategy. Through an averaging operation and bicubic down-sampling
operation over the raw videos, we can efficiently obtain blurry videos and
low-resolution videos paired with raw videos separately. To verify the
effectiveness of Text-RBL, we propose a baseline model combined with the text
detector and tracker for video scene text detection. Moreover, a failure
detection scheme is designed to alleviate the baseline model drift issue caused
by complex scenes. Extensive experiments demonstrate that Text-RBL with paired
low-quality videos labeled by the semi-automatic method can significantly
improve the performance of the text detector in low-quality scenes.
</dc:description>
 <dc:description>Comment: Published in: IEEE Access ( Early Access )</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15488</dc:identifier>
 <dc:identifier>doi:10.1109/ACCESS.2021.3066601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15500</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Retrieving Event-related Human Brain Dynamics from Natural Sentence
  Reading</dc:title>
 <dc:creator>Liu, Xinping</dc:creator>
 <dc:creator>Cao, Zehong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Electroencephalography (EEG) signals recordings when people reading natural
languages are commonly used as a cognitive method to interpret human language
understanding in neuroscience and psycholinguistics. Previous studies have
demonstrated that the human fixation and activation in word reading associated
with some brain regions, but it is not clear when and how to measure the brain
dynamics across time and frequency domains. In this study, we propose the first
analysis of event-related brain potentials (ERPs), and event-related spectral
perturbations (ERSPs) on benchmark datasets which consist of sentence-level
simultaneous EEG and related eye-tracking recorded from human natural reading
experiment tasks. Our results showed peaks evoked at around 162 ms after the
stimulus (starting to read each sentence) in the occipital area, indicating the
brain retriving lexical and semantic visual information processing approaching
200 ms from the sentence onset. Furthermore, the occipital ERP around 200ms
presents negative power and positive power in short and long reaction times. In
addition, the occipital ERSP around 200ms demonstrated increased high gamma and
decreased low beta and low gamma power, relative to the baseline. Our results
implied that most of the semantic-perception responses occurred around the
200ms in alpha, beta and gamma bands of EEG signals. Our findings also provide
potential impacts on promoting cognitive natural language processing models
evaluation from EEG dynamics.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15500</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15501</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structure of Multiple Mirror System from Kaleidoscopic Projections of
  Single 3D Point</dc:title>
 <dc:creator>Takahashi, Kosuke</dc:creator>
 <dc:creator>Nobuhara, Shohei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a novel algorithm of discovering the structure of a
kaleidoscopic imaging system that consists of multiple planar mirrors and a
camera. The kaleidoscopic imaging system can be recognized as the virtual
multi-camera system and has strong advantages in that the virtual cameras are
strictly synchronized and have the same intrinsic parameters. In this paper, we
focus on the extrinsic calibration of the virtual multi-camera system. The
problems to be solved in this paper are two-fold. The first problem is to
identify to which mirror chamber each of the 2D projections of mirrored 3D
points belongs. The second problem is to estimate all mirror parameters, i.e.,
normals, and distances of the mirrors. The key contribution of this paper is to
propose novel algorithms for these problems using a single 3D point of unknown
geometry by utilizing a kaleidoscopic projection constraint, which is an
epipolar constraint on mirror reflections. We demonstrate the performance of
the proposed algorithm of chamber assignment and estimation of mirror
parameters with qualitative and quantitative evaluations using synthesized and
real data.
</dc:description>
 <dc:description>Comment: Accepted to IEEE Transactions on Pattern Analysis and Machine
  Intelligence (TPAMI)</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15509</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Clustering in Hyrise</dc:title>
 <dc:creator>L&#xf6;ser, Alexander</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Physical data layout is an important performance factor for modern databases.
Clustering, i.e., storing similar values in proximity, can lead to performance
gains in several ways. We present an automated model to determine beneficial
clustering columns and a clustering algorithm for the column-oriented,
memory-resident database Hyrise. To automatically select clustering columns,
the model analyzes the database's workload and provides estimates by how much
certain clustering columns would impact the workload's latency. We evaluate the
precision of the model's estimates, as well as the overall quality of its
clustering suggestions. To apply a determined clustering configuration, we
developed an online clustering algorithm. The clustering algorithm supports an
arbitrary number of clustering dimensions. We show that the algorithm is robust
against concurrently running data modifying queries. We obtain a 5% latency
reduction for the TPC-H benchmark when clustering the lineitem table and a 4%
latency reduction for the TPC-DS benchmark when clustering the store_sales
table.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15509</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15511</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis of I/Q Imbalance with Hardware Impairments over
  Fox's H-Fading Channels</dc:title>
 <dc:creator>Mouchtak, Yassine</dc:creator>
 <dc:creator>Bouanani, Faissal El</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94A40, 68M10, 94-10</dc:subject>
 <dc:description>  Impairments baseband model in-phase and quadrature-phase Imbalance (IQI) and
Residual hardware impairments (RHI) are two key factors degrading the
performance of wireless communication systems (WCSs), particularly when
high-frequency bands are employed, as in 5G systems and beyond. The impact of
either IQI or RHI on the performance of various WCSs has been investigated
exclusively in a separate way. To fill this gap, in this paper, the joint
effect of both IQI and RHI on the performance of a WCS subject to the sum of
Fox's H-function fading model (SFHF) is investigated. Such a fading model
generalizes most, if not all, of well-known fading and turbulence models. To
this end, closed-form and asymptotic expressions for the outage probability
(OP), channel capacity (CC) under constant power with optimum rate adaptation
(ORA) policy, and average symbol error probability (ASEP) for both coherent and
non-coherent modulation schemes. Specifically, all the analytical expressions
are derived for three different scenarios: (i) ideal Tx and Rx impaired, (ii)
Tx impaired and ideal Rx, and (iii) both Tx and Rx are impaired. Further,
asymptotic expressions for OP, CC under ORA policy, and ASEP are obtained,
based on which, insightful discussions on the IQI and RHI impacts are made.
Alpha-mu and Malaga M turbulence with pointing error distribution models have
been considered particular SFHF distribution cases. The analytical derivations,
revealed by simulation results, demonstrate that the RF impairments' effects
should be seriously taken into account in the design of next-generation
wireless technologies.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15511</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15514</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Context-aware short-term interest first model for session-based
  recommendation</dc:title>
 <dc:creator>Duan, Haomei</dc:creator>
 <dc:creator>Zhu, Jinghua</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In the case that user profiles are not available, the recommendation based on
anonymous session is particularly important, which aims to predict the items
that the user may click at the next moment based on the user's access sequence
over a while. In recent years, with the development of recurrent neural
network, attention mechanism, and graph neural network, the performance of
session-based recommendation has been greatly improved. However, the previous
methods did not comprehensively consider the context dependencies and
short-term interest first of the session. Therefore, we propose a context-aware
short-term interest first model (CASIF).The aim of this paper is improve the
accuracy of recommendations by combining context and short-term interest. In
CASIF, we dynamically construct a graph structure for session sequences and
capture rich context dependencies via graph neural network (GNN), latent
feature vectors are captured as inputs of the next step. Then we build the
short-term interest first module, which can to capture the user's general
interest from the session in the context of long-term memory, at the same time
get the user's current interest from the item of the last click. In the end,
the short-term and long-term interest are combined as the final interest and
multiplied by the candidate vector to obtain the recommendation probability.
Finally, a large number of experiments on two real-world datasets demonstrate
the effectiveness of our proposed method.
</dc:description>
 <dc:description>Comment: 15 pages,5 figures,8th International Conference on Computer Science
  and Information Technology (CoSIT 2021), March 27 ~ 28, 2021, Sydney,
  Australia</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15514</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15521</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Web Interface for Petri Nets with Transits and Petri Games</dc:title>
 <dc:creator>Gieseking, Manuel</dc:creator>
 <dc:creator>Hecking-Harbusch, Jesko</dc:creator>
 <dc:creator>Yanich, Ann</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Developing algorithms for distributed systems is an error-prone task. Formal
models like Petri nets with transits and Petri games can prevent errors when
developing such algorithms. Petri nets with transits allow us to follow the
data flow between components in a distributed system. They can be model checked
against specifications in LTL on both the local data flow and the global
behavior. Petri games allow the synthesis of local controllers for distributed
systems from safety specifications. Modeling problems in these formalisms
requires defining extended Petri nets which can be cumbersome when performed
textually.
  In this paper, we present a web interface that allows an intuitive, visual
definition of Petri nets with transits and Petri games. The corresponding model
checking and synthesis problems are solved directly on a server. In the
interface, implementations, counterexamples, and all intermediate steps can be
analyzed and simulated. Stepwise simulations and interactive state space
generation support the user in detecting modeling errors.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures, version corresponding to the TACAS'21 paper</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15522</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Score-oriented loss (SOL) functions</dc:title>
 <dc:creator>Marchetti, Francesco</dc:creator>
 <dc:creator>Guastavino, Sabrina</dc:creator>
 <dc:creator>Piana, Michele</dc:creator>
 <dc:creator>Campi, Cristina</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Loss functions engineering and the assessment of forecasting performances are
two crucial and intertwined aspects of supervised machine learning. This paper
focuses on binary classification to introduce a class of loss functions that
are defined on probabilistic confusion matrices and that allow an automatic and
a priori maximization of the skill scores. The performances of these loss
functions are validated during the training phase of two experimental
forecasting problems, thus showing that the probability distribution function
associated with the confusion matrices significantly impacts the outcome of the
score maximization process.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15522</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15536</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cloud2Curve: Generation and Vectorization of Parametric Sketches</dc:title>
 <dc:creator>Das, Ayan</dc:creator>
 <dc:creator>Yang, Yongxin</dc:creator>
 <dc:creator>Hospedales, Timothy</dc:creator>
 <dc:creator>Xiang, Tao</dc:creator>
 <dc:creator>Song, Yi-Zhe</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Analysis of human sketches in deep learning has advanced immensely through
the use of waypoint-sequences rather than raster-graphic representations. We
further aim to model sketches as a sequence of low-dimensional parametric
curves. To this end, we propose an inverse graphics framework capable of
approximating a raster or waypoint based stroke encoded as a point-cloud with a
variable-degree B\'ezier curve. Building on this module, we present
Cloud2Curve, a generative model for scalable high-resolution vector sketches
that can be trained end-to-end using point-cloud data alone. As a consequence,
our model is also capable of deterministic vectorization which can map novel
raster or waypoint based sketches to their corresponding high-resolution
scalable B\'ezier equivalent. We evaluate the generation and vectorization
capabilities of our model on Quick, Draw! and K-MNIST datasets.
</dc:description>
 <dc:description>Comment: Accepted at CVPR 2021 (Poster)</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15543</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Be Careful about Poisoned Word Embeddings: Exploring the Vulnerability
  of the Embedding Layers in NLP Models</dc:title>
 <dc:creator>Yang, Wenkai</dc:creator>
 <dc:creator>Li, Lei</dc:creator>
 <dc:creator>Zhang, Zhiyuan</dc:creator>
 <dc:creator>Ren, Xuancheng</dc:creator>
 <dc:creator>Sun, Xu</dc:creator>
 <dc:creator>He, Bin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recent studies have revealed a security threat to natural language processing
(NLP) models, called the Backdoor Attack. Victim models can maintain
competitive performance on clean samples while behaving abnormally on samples
with a specific trigger word inserted. Previous backdoor attacking methods
usually assume that attackers have a certain degree of data knowledge, either
the dataset which users would use or proxy datasets for a similar task, for
implementing the data poisoning procedure. However, in this paper, we find that
it is possible to hack the model in a data-free way by modifying one single
word embedding vector, with almost no accuracy sacrificed on clean samples.
Experimental results on sentiment analysis and sentence-pair classification
tasks show that our method is more efficient and stealthier. We hope this work
can raise the awareness of such a critical security risk hidden in the
embedding layers of NLP models. Our code is available at
https://github.com/lancopku/Embedding-Poisoning.
</dc:description>
 <dc:description>Comment: NAACL-HLT 2021, Long Paper</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15543</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15546</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Heterogeneous Objectives: State-of-the-Art and Future Research</dc:title>
 <dc:creator>Allmendinger, Richard</dc:creator>
 <dc:creator>Knowles, Joshua</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Multiobjective optimization problems with heterogeneous objectives are
defined as those that possess significantly different types of objective
function components (not just incommensurable in units or scale). For example,
in a heterogeneous problem the objective function components may differ in
formal computational complexity, practical evaluation effort (time, costs, or
resources), determinism (stochastic vs deterministic), or some combination of
all three. A particularly challenging variety of heterogeneity may occur by the
combination of a time-consuming laboratory-based objective with other
objectives that are evaluated using faster computer-based calculations. Perhaps
more commonly, all objectives may be evaluated computationally, but some may
require a lengthy simulation process while others are computed from a
relatively simple closed-form calculation. In this chapter, we motivate the
need for more work on the topic of heterogeneous objectives (with reference to
real-world examples), expand on a basic taxonomy of heterogeneity types, and
review the state of the art in tackling these problems. We give special
attention to heterogeneity in evaluation time (latency) as this requires
sophisticated approaches. We also present original experimental work on
estimating the amount of heterogeneity in evaluation time expected in
many-objective problems, given reasonable assumptions, and survey related
research threads that could contribute to this area in future.
</dc:description>
 <dc:description>Comment: 20 pages, submitted for consideration to the MACODA book project</dc:description>
 <dc:date>2021-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15546</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15547</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analyzing Uniaxial Compressive Strength of Concrete Using a Novel Satin
  Bowerbird Optimizer</dc:title>
 <dc:creator>Moayedi, Hossein</dc:creator>
 <dc:creator>Mosavi, Amir</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>68T05</dc:subject>
 <dc:description>  Surmounting the complexities in analyzing the mechanical parameters of
concrete entails selecting an appropriate methodology. This study integrates an
artificial neural network (ANN) with a novel metaheuristic technique, namely
satin bowerbird optimizer (SBO) for predicting uniaxial compressive strength
(UCS) of concrete. For this purpose, the created hybrid is trained and tested
using a relatively large dataset collected from the published literature. Three
other new algorithms, namely Henry gas solubility optimization (HGSO),
sunflower optimization (SFO), and vortex search algorithm (VSA) are also used
as benchmarks. After attaining a proper population size for all algorithms,
Utilizing various accuracy indicators, it was shown that the proposed ANN-SBO
not only can excellently analyze the UCS behavior, but also outperforms all
three benchmark hybrids (i.e., ANN-HGSO, ANN-SFO, and ANN-VSA). In the
prediction phase, the correlation indices of 0.87394, 0.87936, 0.95329, and
0.95663, as well as mean absolute percentage errors of 15.9719, 15.3845,
9.4970, and 8.0629%, calculated for the ANN-HGSO, ANN-SFO, ANN-VSA, and
ANN-SBO, respectively, manifested the best prediction performance for the
proposed model. Also, the ANN-VSA achieved reliable results as well. In short,
the ANN-SBO can be used by engineers as an efficient non-destructive method for
predicting the UCS of concrete.
</dc:description>
 <dc:description>Comment: 16 pages, 4 figures</dc:description>
 <dc:date>2021-03-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15547</dc:identifier>
 <dc:identifier>doi:10.31219/osf.io/5qmt7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15550</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SCNN: Swarm Characteristic Neural Network</dc:title>
 <dc:creator>Nguyen, Ha-Thanh</dc:creator>
 <dc:creator>Nguyen, Le-Minh</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Deep learning is a powerful approach with good performance on many different
tasks. However, these models often require massive computational resources. It
is a worrying trend that we increasingly need models that work well on more
complex problems. In this paper, we propose and verify the effectiveness and
efficiency of SCNN, an innovative neural network inspired by the swarm concept.
In addition to introducing the relevant theories, our detailed experiments
suggest that fewer parameters may perform better than models with more
parameters. Besides, our experiments show that SCNN needs less data than
traditional models. That could be an essential hint for problems where there is
not much data.
</dc:description>
 <dc:date>2021-03-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15550</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15553</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Connectionism, Complexity, and Living Systems: a comparison of
  Artificial and Biological Neural Networks</dc:title>
 <dc:creator>Katyal, Krishna</dc:creator>
 <dc:creator>Parent, Jesse</dc:creator>
 <dc:creator>Alicea, Bradly</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  While Artificial Neural Networks (ANNs) have yielded impressive results in
the realm of simulated intelligent behavior, it is important to remember that
they are but sparse approximations of Biological Neural Networks (BNNs). We go
beyond comparison of ANNs and BNNs to introduce principles from BNNs that might
guide the further development of ANNs as embodied neural models. These
principles include representational complexity, complex network
structure/energetics, and robust function. We then consider these principles in
ways that might be implemented in the future development of ANNs. In
conclusion, we consider the utility of this comparison, particularly in terms
of building more robust and dynamic ANNs. This even includes constructing a
morphology and sensory apparatus to create an embodied ANN, which when
complemented with the organizational and functional advantages of BNNs unlocks
the adaptive potential of lifelike networks.
</dc:description>
 <dc:description>Comment: 14 pages, 3 figures</dc:description>
 <dc:date>2021-03-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15553</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15559</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gamified and Self-Adaptive Applications for the Common Good: Research
  Challenges Ahead</dc:title>
 <dc:creator>Bucchiarone, Antonio</dc:creator>
 <dc:creator>Cicchetti, Antonio</dc:creator>
 <dc:creator>Bencomo, Nelly</dc:creator>
 <dc:creator>Loria, Enrica</dc:creator>
 <dc:creator>Marconi, Annapaola</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Motivational digital systems offer capabilities to engage and motivate
end-users to foster behavioral changes towards a common goal. In general these
systems use gamification principles in non-games contexts. Over the years,
gamification has gained consensus among researchers and practitioners as a tool
to motivate people to perform activities with the ultimate goal of promoting
behavioural change, or engaging the users to perform activities that can offer
relevant benefits but which can be seen as unrewarding and even tedious.
  There exists a plethora of heterogeneous application scenarios towards
reaching the common good that can benefit from gamification. However, an open
problem is how to effectively combine multiple motivational campaigns to
maximise the degree of participation without exposing the system to
counterproductive behaviours.
  We conceive motivational digital systems as multi-agent systems:
self-adaptation is a feature of the overall system, while individual agents may
self-adapt in order to leverage other agents' resources, functionalities and
capabilities to perform tasks more efficiently and effectively. Consequently,
multiple campaigns can be run and adapted to reach common good. At the same
time, agents are grouped into micro-communities in which agents contribute with
their own social capital and leverage others' capabilities to balance their
weaknesses.
  In this paper we propose our vision on how the principles at the base of the
autonomous and multi-agent systems can be exploited to design multi-challenge
motivational systems to engage smart communities towards common goals. We
present an initial version of a general framework based on the MAPE-K loop and
a set of research challenges that characterise our research roadmap for the
implementation of our vision.
</dc:description>
 <dc:description>Comment: 7 pages, 1 figure</dc:description>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15564</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prototype-based Personalized Pruning</dc:title>
 <dc:creator>Kim, Jangho</dc:creator>
 <dc:creator>Chang, Simyung</dc:creator>
 <dc:creator>Yun, Sungrack</dc:creator>
 <dc:creator>Kwak, Nojun</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Nowadays, as edge devices such as smartphones become prevalent, there are
increasing demands for personalized services. However, traditional
personalization methods are not suitable for edge devices because retraining or
finetuning is needed with limited personal data. Also, a full model might be
too heavy for edge devices with limited resources. Unfortunately, model
compression methods which can handle the model complexity issue also require
the retraining phase. These multiple training phases generally need huge
computational cost during on-device learning which can be a burden to edge
devices. In this work, we propose a dynamic personalization method called
prototype-based personalized pruning (PPP). PPP considers both ends of
personalization and model efficiency. After training a network, PPP can easily
prune the network with a prototype representing the characteristics of personal
data and it performs well without retraining or finetuning. We verify the
usefulness of PPP on a couple of tasks in computer vision and Keyword spotting.
</dc:description>
 <dc:description>Comment: 4 pages, ICASSP '21 accepted</dc:description>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15565</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RAN-GNNs: breaking the capacity limits of graph neural networks</dc:title>
 <dc:creator>Valsesia, Diego</dc:creator>
 <dc:creator>Fracastoro, Giulia</dc:creator>
 <dc:creator>Magli, Enrico</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Graph neural networks have become a staple in problems addressing learning
and analysis of data defined over graphs. However, several results suggest an
inherent difficulty in extracting better performance by increasing the number
of layers. Recent works attribute this to a phenomenon peculiar to the
extraction of node features in graph-based tasks, i.e., the need to consider
multiple neighborhood sizes at the same time and adaptively tune them. In this
paper, we investigate the recently proposed randomly wired architectures in the
context of graph neural networks. Instead of building deeper networks by
stacking many layers, we prove that employing a randomly-wired architecture can
be a more effective way to increase the capacity of the network and obtain
richer representations. We show that such architectures behave like an ensemble
of paths, which are able to merge contributions from receptive fields of varied
size. Moreover, these receptive fields can also be modulated to be wider or
narrower through the trainable weights over the paths. We also provide
extensive experimental evidence of the superior performance of randomly wired
architectures over multiple tasks and four graph convolution definitions, using
recent benchmarking frameworks that addresses the reliability of previous
testing methodologies.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15565</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15569</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Risk Bounds for Learning via Hilbert Coresets</dc:title>
 <dc:creator>Douglas, Spencer</dc:creator>
 <dc:creator>Kumar, Piyush</dc:creator>
 <dc:creator>Prasanth, R. K.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:subject>F.2.3</dc:subject>
 <dc:description>  We develop a formalism for constructing stochastic upper bounds on the
expected full sample risk for supervised classification tasks via the Hilbert
coresets approach within a transductive framework. We explicitly compute tight
and meaningful bounds for complex datasets and complex hypothesis classes such
as state-of-the-art deep neural network architectures. The bounds we develop
exhibit nice properties: i) the bounds are non-uniform in the hypothesis space,
ii) in many practical examples, the bounds become effectively deterministic by
appropriate choice of prior and training data-dependent posterior distributions
on the hypothesis space, and iii) the bounds become significantly better with
increase in the size of the training set. We also lay out some ideas to explore
for future research.
</dc:description>
 <dc:description>Comment: 16 pages, 2 figures</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15569</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15573</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HumanGPS: Geodesic PreServing Feature for Dense Human Correspondences</dc:title>
 <dc:creator>Tan, Feitong</dc:creator>
 <dc:creator>Tang, Danhang</dc:creator>
 <dc:creator>Dou, Mingsong</dc:creator>
 <dc:creator>Guo, Kaiwen</dc:creator>
 <dc:creator>Pandey, Rohit</dc:creator>
 <dc:creator>Keskin, Cem</dc:creator>
 <dc:creator>Du, Ruofei</dc:creator>
 <dc:creator>Sun, Deqing</dc:creator>
 <dc:creator>Bouaziz, Sofien</dc:creator>
 <dc:creator>Fanello, Sean</dc:creator>
 <dc:creator>Tan, Ping</dc:creator>
 <dc:creator>Zhang, Yinda</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we address the problem of building dense correspondences
between human images under arbitrary camera viewpoints and body poses. Prior
art either assumes small motion between frames or relies on local descriptors,
which cannot handle large motion or visually ambiguous body parts, e.g., left
vs. right hand. In contrast, we propose a deep learning framework that maps
each pixel to a feature space, where the feature distances reflect the geodesic
distances among pixels as if they were projected onto the surface of a 3D human
scan. To this end, we introduce novel loss functions to push features apart
according to their geodesic distances on the surface. Without any semantic
annotation, the proposed embeddings automatically learn to differentiate
visually similar parts and align different subjects into an unified feature
space. Extensive experiments show that the learned embeddings can produce
accurate correspondences between images with remarkable generalization
capabilities on both intra and inter subjects.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15573</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15575</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contrastive Explanations of Plans Through Model Restrictions</dc:title>
 <dc:creator>Krarup, Benjamin</dc:creator>
 <dc:creator>Krivic, Senka</dc:creator>
 <dc:creator>Magazzeni, Daniele</dc:creator>
 <dc:creator>Long, Derek</dc:creator>
 <dc:creator>Cashmore, Michael</dc:creator>
 <dc:creator>Smith, David E.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In automated planning, the need for explanations arises when there is a
mismatch between a proposed plan and the user's expectation. We frame
Explainable AI Planning in the context of the plan negotiation problem, in
which a succession of hypothetical planning problems are generated and solved.
The object of the negotiation is for the user to understand and ultimately
arrive at a satisfactory plan. We present the results of a user study that
demonstrates that when users ask questions about plans, those questions are
contrastive, i.e. &quot;why A rather than B?&quot;. We use the data from this study to
construct a taxonomy of user questions that often arise during plan
negotiation. We formally define our approach to plan negotiation through model
restriction as an iterative process. This approach generates hypothetical
problems and contrastive plans by restricting the model through constraints
implied by user questions. We formally define model-based compilations in
PDDL2.1 of each constraint derived from a user question in the taxonomy, and
empirically evaluate the compilations in terms of computational complexity. The
compilations were implemented as part of an explanation framework that employs
iterative model restriction. We demonstrate its benefits in a second user
study.
</dc:description>
 <dc:description>Comment: 80 pages, 32 figures, 7 tables</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15575</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15578</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classification of Seeds using Domain Randomization on Self-Supervised
  Learning Frameworks</dc:title>
 <dc:creator>Margapuri, Venkat</dc:creator>
 <dc:creator>Neilsen, Mitchell</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The first step toward Seed Phenotyping i.e. the comprehensive assessment of
complex seed traits such as growth, development, tolerance, resistance,
ecology, yield, and the measurement of pa-rameters that form more complex
traits is the identification of seed type. Generally, a plant re-searcher
inspects the visual attributes of a seed such as size, shape, area, color and
texture to identify the seed type, a process that is tedious and
labor-intensive. Advances in the areas of computer vision and deep learning
have led to the development of convolutional neural networks (CNN) that aid in
classification using images. While they classify efficiently, a key bottleneck
is the need for an extensive amount of labelled data to train the CNN before it
can be put to the task of classification. The work leverages the concepts of
Contrastive Learning and Domain Randomi-zation in order to achieve the same.
Briefly, domain randomization is the technique of applying models trained on
images containing simulated objects to real-world objects. The use of synthetic
images generated from a representational sample crop of real-world images
alleviates the need for a large volume of test subjects. As part of the work,
synthetic image datasets of five different types of seed images namely, canola,
rough rice, sorghum, soy and wheat are applied to three different
self-supervised learning frameworks namely, SimCLR, Momentum Contrast (MoCo)
and Build Your Own Latent (BYOL) where ResNet-50 is used as the backbone in
each of the networks. When the self-supervised models are fine-tuned with only
5% of the labels from the synthetic dataset, results show that MoCo, the model
that yields the best performance of the self-supervised learning frameworks in
question, achieves an accuracy of 77% on the test dataset which is only ~13%
less than the accuracy of 90% achieved by ResNet-50 trained on 100% of the
labels.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15578</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15580</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis of Out-of-Distribution Detection on Various Trained
  Neural Networks</dc:title>
 <dc:creator>Henriksson, Jens</dc:creator>
 <dc:creator>Berger, Christian</dc:creator>
 <dc:creator>Borg, Markus</dc:creator>
 <dc:creator>Tornberg, Lars</dc:creator>
 <dc:creator>Sathyamoorthy, Sankar Raman</dc:creator>
 <dc:creator>Englund, Cristofer</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  Several areas have been improved with Deep Learning during the past years.
For non-safety related products adoption of AI and ML is not an issue, whereas
in safety critical applications, robustness of such approaches is still an
issue. A common challenge for Deep Neural Networks (DNN) occur when exposed to
out-of-distribution samples that are previously unseen, where DNNs can yield
high confidence predictions despite no prior knowledge of the input.
  In this paper we analyse two supervisors on two well-known DNNs with varied
setups of training and find that the outlier detection performance improves
with the quality of the training procedure. We analyse the performance of the
supervisor after each epoch during the training cycle, to investigate
supervisor performance as the accuracy converges. Understanding the
relationship between training results and supervisor performance is valuable to
improve robustness of the model and indicates where more work has to be done to
create generalized models for safety critical applications.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures, presented at SEAA 2019</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15580</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15581</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Supporting verification of news articles with automated search for
  semantically similar articles</dc:title>
 <dc:creator>Gupta, Vishwani</dc:creator>
 <dc:creator>Beckh, Katharina</dc:creator>
 <dc:creator>Giesselbach, Sven</dc:creator>
 <dc:creator>Wegener, Dennis</dc:creator>
 <dc:creator>Wirtz, Tim</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Fake information poses one of the major threats for society in the 21st
century. Identifying misinformation has become a key challenge due to the
amount of fake news that is published daily. Yet, no approach is established
that addresses the dynamics and versatility of fake news editorials. Instead of
classifying content, we propose an evidence retrieval approach to handle fake
news. The learning task is formulated as an unsupervised machine learning
problem. For validation purpose, we provide the user with a set of news
articles from reliable news sources supporting the hypothesis of the news
article in query and the final decision is left to the user. Technically we
propose a two-step process: (i) Aggregation-step: With information extracted
from the given text we query for similar content from reliable news sources.
(ii) Refining-step: We narrow the supporting evidence down by measuring the
semantic distance of the text with the collection from step (i). The distance
is calculated based on Word2Vec and the Word Mover's Distance. In our
experiments, only content that is below a certain distance threshold is
considered as supporting evidence. We find that our approach is agnostic to
concept drifts, i.e. the machine learning task is independent of the hypotheses
in a text. This makes it highly adaptable in times where fake news is as
diverse as classical news is. Our pipeline offers the possibility for further
analysis in the future, such as investigating bias and differences in news
reporting.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15581</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15587</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IA-GCN: Interpretable Attention based Graph Convolutional Network for
  Disease prediction</dc:title>
 <dc:creator>Kazi, Anees</dc:creator>
 <dc:creator>Farghadani, Soroush</dc:creator>
 <dc:creator>Navab, Nassir</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Interpretability in Graph Convolutional Networks (GCNs) has been explored to
some extent in computer vision in general, yet, in the medical domain, it
requires further examination. Moreover, most of the interpretability approaches
for GCNs, especially in the medical domain, focus on interpreting the model in
a post hoc fashion. In this paper, we propose an interpretable graph
learning-based model which 1) interprets the clinical relevance of the input
features towards the task, 2) uses the explanation to improve the model
performance and, 3) learns a population level latent graph that may be used to
interpret the cohort's behavior. In a clinical scenario, such a model can
assist the clinical experts in better decision-making for diagnosis and
treatment planning. The main novelty lies in the interpretable attention module
(IAM), which directly operates on multi-modal features. Our IAM learns the
attention for each feature based on the unique interpretability-specific
losses. We show the application on two publicly available datasets, Tadpole and
UKBB, for three tasks of disease, age, and gender prediction. Our proposed
model shows superior performance with respect to compared methods with an
increase in an average accuracy of 3.2% for Tadpole, 1.6% for UKBB Gender, and
2% for the UKBB Age prediction task. Further, we show exhaustive validation and
clinical interpretation of our results.
</dc:description>
 <dc:description>Comment: 10 pages, 1 figure</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15587</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15592</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Current Trends and Applications of Dempster-Shafer Theory (Review)</dc:title>
 <dc:creator>Ivanov, V. K.</dc:creator>
 <dc:creator>Vinogradova, N . V.</dc:creator>
 <dc:creator>Palyukh, B. V.</dc:creator>
 <dc:creator>Sotnikov, A. N.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The article provides a review of the publications on the current trends and
developments in Dempster-Shafer theory and its different applications in
science, engineering, and technologies. The review took account of the
following provisions with a focus on some specific aspects of the theory.
Firstly, the article considers the research directions whose results are known
not only in scientific and academic community but understood by a wide circle
of potential designers and developers of advanced engineering solutions and
technologies. Secondly, the article shows the theory applications in some
important areas of human activity such as manufacturing systems, diagnostics of
technological processes, materials and products, building and construction,
product quality control, economic and social systems. The particular attention
is paid to the current state of research in the domains under consideration
and, thus, the papers published, as a rule, in recent years and presenting the
achievements of modern research on Dempster-Shafer theory and its application
are selected and analyzed.
</dc:description>
 <dc:description>Comment: 11 pages, in Russian. Artificial intelligence and decision making.
  2018. N 4</dc:description>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15592</dc:identifier>
 <dc:identifier>doi:10.14357/20718594180403</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15602</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Product semantics translation from brain activity via adversarial
  learning</dc:title>
 <dc:creator>Wang, Pan</dc:creator>
 <dc:creator>Gong, Zhifeng</dc:creator>
 <dc:creator>Wang, Shuo</dc:creator>
 <dc:creator>Dong, Hao</dc:creator>
 <dc:creator>Fan, Jialu</dc:creator>
 <dc:creator>Li, Ling</dc:creator>
 <dc:creator>Childs, Peter</dc:creator>
 <dc:creator>Guo, Yike</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  A small change of design semantics may affect a user's satisfaction with a
product. To modify a design semantic of a given product from personalised brain
activity via adversarial learning, in this work, we propose a deep generative
transformation model to modify product semantics from the brain signal. We
attempt to accomplish such synthesis: 1) synthesising the product image with
new features corresponding to EEG signal; 2) maintaining the other image
features that irrelevant to EEG signal. We leverage the idea of StarGAN and the
model is designed to synthesise products with preferred design semantics
(colour &amp; shape) via adversarial learning from brain activity, and is applied
with a case study to generate shoes with different design semantics from
recorded EEG signals. To verify our proposed cognitive transformation model, a
case study has been presented. The results work as a proof-of-concept that our
framework has the potential to synthesis product semantic from brain activity.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15602</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15608</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid Evolutionary Optimization Approach for Oilfield Well Control
  Optimization</dc:title>
 <dc:creator>Kumar, Ajitabh</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Oilfield production optimization is challenging due to subsurface model
complexity and associated non-linearity, large number of control parameters,
large number of production scenarios, and subsurface uncertainties.
Optimization involves time-consuming reservoir simulation studies to compare
different production scenarios and settings. This paper presents efficacy of
two hybrid evolutionary optimization approaches for well control optimization
of a waterflooding operation, and demonstrates their application using Olympus
benchmark. A simpler, weighted sum of cumulative fluid (WCF) is used as
objective function first, which is then replaced by net present value (NPV) of
discounted cash-flow for comparison. Two popular evolutionary optimization
algorithms, genetic algorithm (GA) and particle swarm optimization (PSO), are
first used in standalone mode to solve well control optimization problem. Next,
both GA and PSO methods are used with another popular optimization algorithm,
covariance matrix adaptation-evolution strategy (CMA-ES), in hybrid mode.
Hybrid optimization run is made by transferring the resulting population from
one algorithm to the next as its starting population for further improvement.
Approximately four thousand simulation runs are needed for standalone GA and
PSO methods to converge, while six thousand runs are needed in case of two
hybrid optimization modes (GA-CMA-ES and PSO-CMA-ES). To reduce turn-around
time, commercial cloud computing is used and simulation workload is distributed
using parallel programming. GA and PSO algorithms have a good balance between
exploratory and exploitative properties, thus are able identify regions of
interest. CMA-ES algorithm is able to further refine the solution using its
excellent exploitative properties. Thus, GA or PSO with CMA-ES in hybrid mode
yields better optimization result as compared to standalone GA or PSO
algorithms.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15608</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15618</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Empirical Bayesian Inference using Joint Sparsity</dc:title>
 <dc:creator>Zhang, Jiahui</dc:creator>
 <dc:creator>Gelb, Anne</dc:creator>
 <dc:creator>Scarnati, Theresa</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>62C12, 65C40, 68U10</dc:subject>
 <dc:description>  This paper develops a new empirical Bayesian inference algorithm for solving
a linear inverse problem given multiple measurement vectors (MMV) of
under-sampled and noisy observable data. Specifically, by exploiting the joint
sparsity across the multiple measurements in the sparse domain of the
underlying signal or image, we construct a new support informed sparsity
promoting prior. Several applications can be modeled using this framework, and
as a prototypical example we consider reconstructing an image from synthetic
aperture radar (SAR) observations using nearby azimuth angles. Our numerical
experiments demonstrate that using this new prior not only improves accuracy of
the recovery, but also reduces the uncertainty in the posterior when compared
to standard sparsity producing priors.
</dc:description>
 <dc:description>Comment: Submitted for publication to SIAM Journal on Uncertainty
  Quantification 26 March 2021</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15618</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15619</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SetVAE: Learning Hierarchical Composition for Generative Modeling of
  Set-Structured Data</dc:title>
 <dc:creator>Kim, Jinwoo</dc:creator>
 <dc:creator>Yoo, Jaehoon</dc:creator>
 <dc:creator>Lee, Juho</dc:creator>
 <dc:creator>Hong, Seunghoon</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Generative modeling of set-structured data, such as point clouds, requires
reasoning over local and global structures at various scales. However, adopting
multi-scale frameworks for ordinary sequential data to a set-structured data is
nontrivial as it should be invariant to the permutation of its elements. In
this paper, we propose SetVAE, a hierarchical variational autoencoder for sets.
Motivated by recent progress in set encoding, we build SetVAE upon attentive
modules that first partition the set and project the partition back to the
original cardinality. Exploiting this module, our hierarchical VAE learns
latent variables at multiple scales, capturing coarse-to-fine dependency of the
set elements while achieving permutation invariance. We evaluate our model on
point cloud generation task and achieve competitive performance to the prior
arts with substantially smaller model capacity. We qualitatively demonstrate
that our model generalizes to unseen set sizes and learns interesting subset
relations without supervision. Our implementation is available at
https://github.com/jw9730/setvae.
</dc:description>
 <dc:description>Comment: 19 pages, 20 figures</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15620</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotically Optimal Massey-Like Inequality on Guessing Entropy With
  Application to Side-Channel Attack Evaluations</dc:title>
 <dc:creator>T&#x103;n&#x103;sescu, Andrei</dc:creator>
 <dc:creator>Choudary, Marios O.</dc:creator>
 <dc:creator>Rioul, Olivier</dc:creator>
 <dc:creator>Popescu, Pantelimon George</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  A Massey-like inequality is any useful lower bound on guessing entropy in
terms of the computationally scalable Shannon entropy. The asymptotically
optimal Massey-like inequality is determined and further refined for
finite-support distributions. The impact of these results are highlighted for
side-channel attack evaluation where guessing entropy is a key metric. In this
context, the obtained bounds are compared to the state of the art.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15620</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15622</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph Classification by Mixture of Diverse Experts</dc:title>
 <dc:creator>Hu, Fenyu</dc:creator>
 <dc:creator>Wang, Liping</dc:creator>
 <dc:creator>Wu, Shu</dc:creator>
 <dc:creator>Wang, Liang</dc:creator>
 <dc:creator>Tan, Tieniu</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Graph classification is a challenging research problem in many applications
across a broad range of domains. In these applications, it is very common that
class distribution is imbalanced. Recently, Graph Neural Network (GNN) models
have achieved superior performance on various real-world datasets. Despite
their success, most of current GNN models largely overlook the important
setting of imbalanced class distribution, which typically results in prediction
bias towards majority classes. To alleviate the prediction bias, we propose to
leverage semantic structure of dataset based on the distribution of node
embedding. Specifically, we present GraphDIVE, a general framework leveraging
mixture of diverse experts (i.e., graph classifiers) for imbalanced graph
classification. With a divide-and-conquer principle, GraphDIVE employs a gating
network to partition an imbalanced graph dataset into several subsets. Then
each expert network is trained based on its corresponding subset. Experiments
on real-world imbalanced graph datasets demonstrate the effectiveness of
GraphDIVE.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15622</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15623</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enabling Replications and Contexts in Reversible Concurrent Calculus</dc:title>
 <dc:creator>Aubert, Cl&#xe9;ment</dc:creator>
 <dc:creator>Medi&#x107;, Doriana</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  Existing formalisms for the algebraic specification and representation of
networks of reversible agents suffer some shortcomings. Despite multiple
attempts, reversible declensions of the Calculus of Communicating Systems (CCS)
do not offer satisfactory adaptation of notions that are usual in
''forward-only'' process algebras, such as replication or context. They also
seem to fail to leverage possible new features stemming from reversibility,
such as the capacity of distinguishing between multiple replications, based on
how they replicate the memory mechanism allowing to reverse the computation.
Existing formalisms disallow the ''hot-plugging'' of processes during their
execution in contexts that also have a past. Finally, they assume the existence
of ''eternally fresh'' keys or identifiers that, if implemented poorly, could
result in unnecessary bottlenecks and look-ups involving all the threads. In
this paper, we begin investigating those issues, by first designing a process
algebra endowed with a mechanism to generate identifiers without the need to
consult with the other threads. We use this calculus to recast the possible
representations of non-determinism in CCS, and as a by-product establish a
simple and straightforward definition of concurrency. Our reversible calculus
is then proven to satisfy expected properties, and allows to lay out precisely
different representations of the replication of a process with a memory. We
also observe that none of the reversible bisimulations defined thus far are
congruences under our notion of ''reversible'' contexts.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15623</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15631</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On data-driven stabilization of systems with quadratic nonlinearities</dc:title>
 <dc:creator>Luppi, Alessandro</dc:creator>
 <dc:creator>De Persis, Claudio</dc:creator>
 <dc:creator>Tesi, Pietro</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  In this paper, we directly design a state feedback controller that stabilizes
a class of uncertain nonlinear systems solely based on input-state data
collected from a finite-length experiment. Necessary and sufficient conditions
are derived to guarantee that the system is absolutely stabilizable and a
controller is designed. Results derived under some relaxed prior information
about the system and strengthened data assumptions are also discussed.
Numerical examples illustrate the method with different levels of prior
information.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15631</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15632</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regular Polytope Networks</dc:title>
 <dc:creator>Pernici, Federico</dc:creator>
 <dc:creator>Bruni, Matteo</dc:creator>
 <dc:creator>Baecchi, Claudio</dc:creator>
 <dc:creator>Del Bimbo, Alberto</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Neural networks are widely used as a model for classification in a large
variety of tasks. Typically, a learnable transformation (i.e. the classifier)
is placed at the end of such models returning a value for each class used for
classification. This transformation plays an important role in determining how
the generated features change during the learning process. In this work, we
argue that this transformation not only can be fixed (i.e. set as
non-trainable) with no loss of accuracy and with a reduction in memory usage,
but it can also be used to learn stationary and maximally separated embeddings.
We show that the stationarity of the embedding and its maximal separated
representation can be theoretically justified by setting the weights of the
fixed classifier to values taken from the coordinate vertices of the three
regular polytopes available in $\mathbb{R}^d$, namely: the $d$-Simplex, the
$d$-Cube and the $d$-Orthoplex. These regular polytopes have the maximal amount
of symmetry that can be exploited to generate stationary features angularly
centered around their corresponding fixed weights. Our approach improves and
broadens the concept of a fixed classifier, recently proposed in
\cite{hoffer2018fix}, to a larger class of fixed classifier models.
Experimental results confirm the theoretical analysis, the generalization
capability, the faster convergence and the improved performance of the proposed
method. Code will be publicly available.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1902.10441</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15632</dc:identifier>
 <dc:identifier>IEEE Transactions on Neural Networks and Learning Systems, 2021</dc:identifier>
 <dc:identifier>doi:10.1109/TNNLS.2021.3056762</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15636</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine learning based digital twin for stochastic nonlinear
  multi-degree of freedom dynamical system</dc:title>
 <dc:creator>Garg, Shailesh</dc:creator>
 <dc:creator>Gogoi, Ankush</dc:creator>
 <dc:creator>Chakraborty, Souvik</dc:creator>
 <dc:creator>Hazra, Budhaditya</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The potential of digital twin technology is immense, specifically in the
infrastructure, aerospace, and automotive sector. However, practical
implementation of this technology is not at an expected speed, specifically
because of lack of application-specific details. In this paper, we propose a
novel digital twin framework for stochastic nonlinear multi-degree of freedom
(MDOF) dynamical systems. The approach proposed in this paper strategically
decouples the problem into two time-scales -- (a) a fast time-scale governing
the system dynamics and (b) a slow time-scale governing the degradation in the
system. The proposed digital twin has four components - (a) a physics-based
nominal model (low-fidelity), (b) a Bayesian filtering algorithm a (c) a
supervised machine learning algorithm and (d) a high-fidelity model for
predicting future responses. The physics-based nominal model combined with
Bayesian filtering is used combined parameter state estimation and the
supervised machine learning algorithm is used for learning the temporal
evolution of the parameters. While the proposed framework can be used with any
choice of Bayesian filtering and machine learning algorithm, we propose to use
unscented Kalman filter and Gaussian process. Performance of the proposed
approach is illustrated using two examples. Results obtained indicate the
applicability and excellent performance of the proposed digital twin framework.
</dc:description>
 <dc:description>Comment: 21 pages</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15636</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15651</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aperiodic two-way transducers and FO-transductions</dc:title>
 <dc:creator>Carton, Olivier</dc:creator>
 <dc:creator>Dartois, Luc</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>F.4.3</dc:subject>
 <dc:description>  Deterministic two-way transducers on finite words have been shown by
Engelfriet and Hoogeboom to have the same expressive power as
MSO-transductions. We introduce a notion of aperiodicity for these transducers
and we show that aperiodic transducers correspond exactly to FO-transductions.
This lifts to transducers the classical equivalence for languages between
FO-definability, recognition by aperiodic monoids and acceptance by
counter-free automata.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15651</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15653</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The EM Algorithm is Adaptively-Optimal for Unbalanced Symmetric Gaussian
  Mixtures</dc:title>
 <dc:creator>Weinberger, Nir</dc:creator>
 <dc:creator>Bresler, Guy</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  This paper studies the problem of estimating the means
$\pm\theta_{*}\in\mathbb{R}^{d}$ of a symmetric two-component Gaussian mixture
$\delta_{*}\cdot N(\theta_{*},I)+(1-\delta_{*})\cdot N(-\theta_{*},I)$ where
the weights $\delta_{*}$ and $1-\delta_{*}$ are unequal. Assuming that
$\delta_{*}$ is known, we show that the population version of the EM algorithm
globally converges if the initial estimate has non-negative inner product with
the mean of the larger weight component. This can be achieved by the trivial
initialization $\theta_{0}=0$. For the empirical iteration based on $n$
samples, we show that when initialized at $\theta_{0}=0$, the EM algorithm
adaptively achieves the minimax error rate
$\tilde{O}\Big(\min\Big\{\frac{1}{(1-2\delta_{*})}\sqrt{\frac{d}{n}},\frac{1}{\|\theta_{*}\|}\sqrt{\frac{d}{n}},\left(\frac{d}{n}\right)^{1/4}\Big\}\Big)$
in no more than $O\Big(\frac{1}{\|\theta_{*}\|(1-2\delta_{*})}\Big)$ iterations
(with high probability). We also consider the EM iteration for estimating the
weight $\delta_{*}$, assuming a fixed mean $\theta$ (which is possibly
mismatched to $\theta_{*}$). For the empirical iteration of $n$ samples, we
show that the minimax error rate
$\tilde{O}\Big(\frac{1}{\|\theta_{*}\|}\sqrt{\frac{d}{n}}\Big)$ is achieved in
no more than $O\Big(\frac{1}{\|\theta_{*}\|^{2}}\Big)$ iterations. These
results robustify and complement recent results of Wu and Zhou obtained for the
equal weights case $\delta_{*}=1/2$.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15653</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15654</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analyzing the Effects of COVID-19 Pandemic on the Energy Demand: the
  Case of Northern Italy</dc:title>
 <dc:creator>Scarabaggio, Paolo</dc:creator>
 <dc:creator>La Scala, Massimo</dc:creator>
 <dc:creator>Carli, Raffaele</dc:creator>
 <dc:creator>Dotoli, Mariagrazia</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  The COVID-19 crisis is profoundly influencing the global economic framework
due to restrictive measures adopted by governments worldwide. Finding real-time
data to correctly quantify this impact is very significant but not as
straightforward. Nevertheless, an analysis of the power demand profiles
provides insight into the overall economic trends. To accurately assess the
change in energy consumption patterns, in this work we employ a multi-layer
feed-forward neural network that calculates an estimation of the aggregated
power demand in the north of Italy, (i.e, in one of the European areas that
were most affected by the pandemics) in the absence of the COVID-19 emergency.
After assessing the forecasting model reliability, we compare the estimation
with the ground truth data to quantify the variation in power consumption.
Moreover, we correlate this variation with the change in mobility behaviors
during the lockdown period by employing the Google mobility report data. From
this unexpected and unprecedented situation, we obtain some intuition regarding
the power system macro-structure and its relation with the overall people's
mobility.
</dc:description>
 <dc:date>2020-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15654</dc:identifier>
 <dc:identifier>Published in: 2020 AEIT International Annual Conference (AEIT)</dc:identifier>
 <dc:identifier>doi:10.23919/AEIT50178.2020.9241136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15660</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pursuer Assignment and Control Strategies in Multi-agent Pursuit-Evasion
  Under Uncertainties</dc:title>
 <dc:creator>Zhang, Leiming</dc:creator>
 <dc:creator>Prorok, Amanda</dc:creator>
 <dc:creator>Bhattacharya, Subhrajit</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We consider a pursuit-evasion problem with a heterogeneous team of multiple
pursuers and multiple evaders. Although both the pursuers (robots) and the
evaders are aware of each others' control and assignment strategies, they do
not have exact information about the other type of agents' location or action.
Using only noisy on-board sensors the pursuers (or evaders) make probabilistic
estimation of positions of the evaders (or pursuers). Each type of agent use
Markov localization to update the probability distribution of the other type. A
search-based control strategy is developed for the pursuers that intrinsically
takes the probability distribution of the evaders into account. Pursuers are
assigned using an assignment algorithm that takes redundancy (i.e., an excess
in the number of pursuers than the number of evaders) into account, such that
the total or maximum estimated time to capture the evaders is minimized. In
this respect we assume the pursuers to have clear advantage over the evaders.
However, the objective of this work is to use assignment strategies that
minimize the capture time. This assignment strategy is based on a modified
Hungarian algorithm as well as a novel algorithm for determining assignment of
redundant pursuers. The evaders, in order to effectively avoid the pursuers,
predict the assignment based on their probabilistic knowledge of the pursuers
and use a control strategy to actively move away from those pursues. Our
experimental evaluation shows that the redundant assignment algorithm performs
better than an alternative nearest-neighbor based assignment algorithm.
</dc:description>
 <dc:description>Comment: 14 pages, 6 figures</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15662</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unified Graph Structured Models for Video Understanding</dc:title>
 <dc:creator>Arnab, Anurag</dc:creator>
 <dc:creator>Sun, Chen</dc:creator>
 <dc:creator>Schmid, Cordelia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Accurate video understanding involves reasoning about the relationships
between actors, objects and their environment, often over long temporal
intervals. In this paper, we propose a message passing graph neural network
that explicitly models these spatio-temporal relations and can use explicit
representations of objects, when supervision is available, and implicit
representations otherwise. Our formulation generalises previous structured
models for video understanding, and allows us to study how different design
choices in graph structure and representation affect the model's performance.
We demonstrate our method on two different tasks requiring relational reasoning
in videos -- spatio-temporal action detection on AVA and UCF101-24, and video
scene graph classification on the recent Action Genome dataset -- and achieve
state-of-the-art results on all three datasets. Furthermore, we show
quantitatively and qualitatively how our method is able to more effectively
model relationships between relevant entities in the scene.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15662</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15664</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Competing Adaptive Networks</dc:title>
 <dc:creator>Vlaski, Stefan</dc:creator>
 <dc:creator>Sayed, Ali H.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Adaptive networks have the capability to pursue solutions of global
stochastic optimization problems by relying only on local interactions within
neighborhoods. The diffusion of information through repeated interactions
allows for globally optimal behavior, without the need for central
coordination. Most existing strategies are developed for cooperative learning
settings, where the objective of the network is common to all agents. We
consider in this work a team setting, where a subset of the agents form a team
with a common goal while competing with the remainder of the network. We
develop an algorithm for decentralized competition among teams of adaptive
agents, analyze its dynamics and present an application in the decentralized
training of generative adversarial neural networks.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15677</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Transmission Topology for Facilitating the Growth of Renewable
  Power Generation</dc:title>
 <dc:creator>Little, Emily</dc:creator>
 <dc:creator>Bortolotti, Sandrine</dc:creator>
 <dc:creator>Bourmaud, Jean-Yves</dc:creator>
 <dc:creator>Karangelos, Efthymios</dc:creator>
 <dc:creator>Perez, Yannick</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Transmission topology control is a tool used by system operators in the role
of a control action taken into account as a preventive or corrective action
relative to a specific outage or set of outages. However, their inclusion in
most electricity market frameworks is limited. With the increasing penetration
of intermittent energy sources, optimal topology can be used as a lever of
flexibility to decrease the total system cost. This paper demonstrates the
evolution of optimal topology control on systems with increasing quantities of
intermittent renewable energy along two axes. First, the effects of the
increased variable sources on the variations of optimal topology are explored.
Second, we elaborate on the growing advantages of exploiting transmission level
grid flexibility in terms of total system cost. Case studies are performed on a
modified RTS-96 network.
</dc:description>
 <dc:description>Comment: Accepted at IEEE Powertech 2021 Madrid (virtual)</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15677</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15679</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generic Attention-model Explainability for Interpreting Bi-Modal and
  Encoder-Decoder Transformers</dc:title>
 <dc:creator>Chefer, Hila</dc:creator>
 <dc:creator>Gur, Shir</dc:creator>
 <dc:creator>Wolf, Lior</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Transformers are increasingly dominating multi-modal reasoning tasks, such as
visual question answering, achieving state-of-the-art results thanks to their
ability to contextualize information using the self-attention and co-attention
mechanisms. These attention modules also play a role in other computer vision
tasks including object detection and image segmentation. Unlike Transformers
that only use self-attention, Transformers with co-attention require to
consider multiple attention maps in parallel in order to highlight the
information that is relevant to the prediction in the model's input. In this
work, we propose the first method to explain prediction by any
Transformer-based architecture, including bi-modal Transformers and
Transformers with co-attentions. We provide generic solutions and apply these
to the three most commonly used of these architectures: (i) pure
self-attention, (ii) self-attention combined with co-attention, and (iii)
encoder-decoder attention. We show that our method is superior to all existing
methods which are adapted from single modality explainability.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15679</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15680</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wall Detection Via IMU Data Classification In Autonomous Quadcopters</dc:title>
 <dc:creator>Hughes, Jason</dc:creator>
 <dc:creator>Lyons, Damian</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  An autonomous drone flying near obstacles needs to be able to detect and
avoid the obstacles or it will collide with them. In prior work, drones can
detect and avoid walls using data from camera, ultrasonic or laser sensors
mounted either on the drone or in the environment. It is not always possible to
instrument the environment, and sensors added to the drone consume payload and
power - both of which are constrained for drones.
  This paper studies how data mining classification techniques can be used to
predict where an obstacle is in relation to the drone based only on monitoring
air-disturbance. We modeled the airflow of the rotors physically to deduce
higher level features for classification. Data was collected from the drone's
IMU while it was flying with a wall to its direct left, front and right, as
well as with no walls present. In total 18 higher level features were produced
from the raw data. We used an 80%, 20% train-test scheme with the RandomForest
(RF), K-Nearest Neighbor (KNN) and GradientBoosting (GB) classifiers. Our
results show that with the RF classifier and with 90% accuracy it can predict
which direction a wall is in relation to the drone.
</dc:description>
 <dc:description>Comment: Appears In ICCAR 2021</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15680</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15683</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Omniscient Video Super-Resolution</dc:title>
 <dc:creator>Yi, Peng</dc:creator>
 <dc:creator>Wang, Zhongyuan</dc:creator>
 <dc:creator>Jiang, Kui</dc:creator>
 <dc:creator>Jiang, Junjun</dc:creator>
 <dc:creator>Lu, Tao</dc:creator>
 <dc:creator>Tian, Xin</dc:creator>
 <dc:creator>Ma, Jiayi</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Most recent video super-resolution (SR) methods either adopt an iterative
manner to deal with low-resolution (LR) frames from a temporally sliding
window, or leverage the previously estimated SR output to help reconstruct the
current frame recurrently. A few studies try to combine these two structures to
form a hybrid framework but have failed to give full play to it. In this paper,
we propose an omniscient framework to not only utilize the preceding SR output,
but also leverage the SR outputs from the present and future. The omniscient
framework is more generic because the iterative, recurrent and hybrid
frameworks can be regarded as its special cases. The proposed omniscient
framework enables a generator to behave better than its counterparts under
other frameworks. Abundant experiments on public datasets show that our method
is superior to the state-of-the-art methods in objective metrics, subjective
visual effects and complexity. Our code will be made public.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15683</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15686</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Memory Enhanced Embedding Learning for Cross-Modal Video-Text Retrieval</dc:title>
 <dc:creator>Zhao, Rui</dc:creator>
 <dc:creator>Zheng, Kecheng</dc:creator>
 <dc:creator>Zha, Zheng-Jun</dc:creator>
 <dc:creator>Xie, Hongtao</dc:creator>
 <dc:creator>Luo, Jiebo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Cross-modal video-text retrieval, a challenging task in the field of vision
and language, aims at retrieving corresponding instance giving sample from
either modality. Existing approaches for this task all focus on how to design
encoding model through a hard negative ranking loss, leaving two key problems
unaddressed during this procedure. First, in the training stage, only a
mini-batch of instance pairs is available in each iteration. Therefore, this
kind of hard negatives is locally mined inside a mini-batch while ignoring the
global negative samples among the dataset. Second, there are many text
descriptions for one video and each text only describes certain local features
of a video. Previous works for this task did not consider to fuse the multiply
texts corresponding to a video during the training. In this paper, to solve the
above two problems, we propose a novel memory enhanced embedding learning
(MEEL) method for videotext retrieval. To be specific, we construct two kinds
of memory banks respectively: cross-modal memory module and text center memory
module. The cross-modal memory module is employed to record the instance
embeddings of all the datasets for global negative mining. To avoid the fast
evolving of the embedding in the memory bank during training, we utilize a
momentum encoder to update the features by a moving-averaging strategy. The
text center memory module is designed to record the center information of the
multiple textual instances corresponding to a video, and aims at bridging these
textual instances together. Extensive experimental results on two challenging
benchmarks, i.e., MSR-VTT and VATEX, demonstrate the effectiveness of the
proposed method.
</dc:description>
 <dc:description>Comment: Technical Report</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15690</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Sample Complexity of Distribution-Free Parity Learning in the Robust
  Shuffle Model</dc:title>
 <dc:creator>Nissim, Kobbi</dc:creator>
 <dc:creator>Yan, Chao</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We provide a lowerbound on the sample complexity of distribution-free parity
learning in the realizable case in the shuffle model of differential privacy.
Namely, we show that the sample complexity of learning $d$-bit parity functions
is $\Omega(2^{d/2})$. Our result extends a recent similar lowerbound on the
sample complexity of private agnostic learning of parity functions in the
shuffle model by Cheu and Ullman. We also sketch a simple shuffle model
protocol demonstrating that our results are tight up to $poly(d)$ factors.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15690</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15692</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Constructing Neural Networks Through Random Mutation</dc:title>
 <dc:creator>Schmidgall, Samuel</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The search for neural architecture is producing many of the most exciting
results in artificial intelligence. It has increasingly become apparent that
task-specific neural architecture plays a crucial role for effectively solving
problems. This paper presents a simple method for learning neural architecture
through random mutation. This method demonstrates 1) neural architecture may be
learned during the agent's lifetime, 2) neural architecture may be constructed
over a single lifetime without any initial connections or neurons, and 3)
architectural modifications enable rapid adaptation to dynamic and novel task
scenarios. Starting without any neurons or connections, this method constructs
a neural architecture capable of high-performance on several tasks. The
lifelong learning capabilities of this method are demonstrated in an
environment without episodic resets, even learning with constantly changing
morphology, limb disablement, and changing task goals all without losing
locomotion capabilities.
</dc:description>
 <dc:description>Comment: Accepted to ICLR 'A Roadmap to Never-Ending RL' (NERL) 2021 Workshop</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15692</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15694</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MIMO-OFDM Joint Radar-Communications: Is ICI Friend or Foe?</dc:title>
 <dc:creator>Keskin, Musa Furkan</dc:creator>
 <dc:creator>Wymeersch, Henk</dc:creator>
 <dc:creator>Koivunen, Visa</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Inter-carrier interference (ICI) poses a significant challenge for OFDM joint
radar-communications (JRC) systems in high-mobility scenarios. In this paper,
we propose a novel ICI-aware sensing algorithm for MIMO-OFDM JRC systems to
detect the presence of multiple targets and estimate their delay-Doppler-angle
parameters. First, leveraging the observation that spatial covariance matrix is
independent of target delays and Dopplers, we perform angle estimation via the
MUSIC algorithm. For each estimated angle, we next formulate the radar
delay-Doppler estimation as a joint carrier frequency offset (CFO) and channel
estimation problem via an APES (amplitude and phase estimation) spatial
filtering approach by transforming the delay-Doppler parameterized radar
channel into an unstructured form. To account for the presence of multiple
targets at a given angle, we devise an iterative interference cancellation
based orthogonal matching pursuit (OMP) procedure, where at each iteration the
generalized likelihood ratio test (GLRT) detector is employed to form decision
statistics, providing as by-products the maximum likelihood estimates (MLEs) of
radar channels and CFOs. In the final step, target detection is performed in
delay-Doppler domain using target-specific, ICI-decontaminated channel
estimates over time and frequency, where CFO estimates are utilized to resolve
Doppler ambiguities, thereby turning ICI from foe to friend. The proposed
algorithm can further exploit the ICI effect to introduce an additional
dimension (namely, CFO) for target resolvability, which enables resolving
targets located at the same delay-Doppler-angle cell. Simulation results
illustrate the ICI exploitation capability of the proposed approach and
showcase its superior detection and estimation performance in high-mobility
scenarios over conventional methods.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:2102.06756</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15694</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15703</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Engineering Nearly Linear-Time Algorithms for Small Vertex Connectivity</dc:title>
 <dc:creator>Franck, Max</dc:creator>
 <dc:creator>Yingchareonthawornchai, Sorrachai</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Vertex connectivity is a well-studied concept in graph theory with numerous
applications. A graph is $k$-connected if it remains connected after removing
any $k-1$ vertices. The vertex connectivity of a graph is the maximum $k$ such
that the graph is $k$-connected. There is a long history of algorithmic
development for efficiently computing vertex connectivity. Recently, two near
linear-time algorithms for small k were introduced by [Forster et al. SODA
2020]. Prior to that, the best known algorithm was one by [Henzinger et al.
FOCS'96] with quadratic running time when k is small.
  In this paper, we study the practical performance of the algorithms by
Forster et al. In addition, we introduce a new heuristic on a key subroutine
called local cut detection, which we call degree counting. We prove that the
new heuristic improves space-efficiency (which can be good for caching
purposes) and allows the subroutine to terminate earlier. According to
experimental results on random graphs with planted vertex cuts, random
hyperbolic graphs, and real world graphs with vertex connectivity between 4 and
15, the degree counting heuristic offers a factor of 2-4 speedup over the
original non-degree counting version for most of our data. It also outperforms
the previous state-of-the-art algorithm by Henzinger et al. even on relatively
small graphs.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15710</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Representation of a vehicular traffic model using hybrid systems</dc:title>
 <dc:creator>Velasquez, Miguel Andres</dc:creator>
 <dc:creator>Ramirez, Carlos Ernesto</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  There is a great diversity of formal models to understand the dynamics of
transport and vehicular flow on a road. Many of these models are inspired by
the dynamics of flows governed by partial differential equations. However, it
is possible to simplify these models to ordinary equations by considering
constant variations in some of the input variables in this type of models.
However, given that these types of systems present discrete changes when the
vehicle density is altered in some sections of the lane, it seems reasonable to
make use of hybrid systems to better understand the evolution of these
dynamics. In this work we are interested in making use of dynamic differential
logic to formally verify one of these models proposed in ordinary equations.
This verification will be done through a proof assistant specially designed for
hybrid systems called KeYmaera. Once we adapt the model to a hybrid system
representation we proceed to use KeYmaera to verify that the proposed model is
formally correct.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15710</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15724</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Note on Isolating Cut Lemma for Submodular Function Minimization</dc:title>
 <dc:creator>Mukhopadhyay, Sagnik</dc:creator>
 <dc:creator>Nanongkai, Danupon</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  It has been observed independently by many researchers that the isolating cut
lemma of Li and Panigrahi [FOCS 2020] can be easily extended to obtain new
algorithms for finding the non-trivial minimizer of a symmetric submodular
function and solving the hypergraph minimum cut problem. This note contains
these observations.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15724</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15737</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Retraining DistilBERT for a Voice Shopping Assistant by Using Universal
  Dependencies</dc:title>
 <dc:creator>Jayarao, Pratik</dc:creator>
 <dc:creator>Sharma, Arpit</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this work, we retrained the distilled BERT language model for Walmart's
voice shopping assistant on retail domain-specific data. We also injected
universal syntactic dependencies to improve the performance of the model
further. The Natural Language Understanding (NLU) components of the voice
assistants available today are heavily dependent on language models for various
tasks. The generic language models such as BERT and RoBERTa are useful for
domain-independent assistants but have limitations when they cater to a
specific domain. For example, in the shopping domain, the token 'horizon' means
a brand instead of its literal meaning. Generic models are not able to capture
such subtleties. So, in this work, we retrained a distilled version of the BERT
language model on retail domain-specific data for Walmart's voice shopping
assistant. We also included universal dependency-based features in the
retraining process further to improve the performance of the model on
downstream tasks. We evaluated the performance of the retrained language model
on four downstream tasks, including intent-entity detection, sentiment
analysis, voice title shortening and proactive intent suggestion. We observed
an increase in the performance of all the downstream tasks of up to 1.31% on
average.
</dc:description>
 <dc:description>Comment: Published in the Proceedings of The Fourth Workshop on Reasoning and
  Learning for Human-Machine Dialogues at the Thirty-Fifth AAAI Conference on
  Artificial Intelligence (AAAI-21)</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15737</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15739</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automation: An Essential Component Of Ethical AI?</dc:title>
 <dc:creator>Nallur, Vivek</dc:creator>
 <dc:creator>Lloyd, Martin</dc:creator>
 <dc:creator>Pearson, Siani</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>68T01</dc:subject>
 <dc:subject>I.2.0</dc:subject>
 <dc:description>  Ethics is sometimes considered to be too abstract to be meaningfully
implemented in artificial intelligence (AI). In this paper, we reflect on other
aspects of computing that were previously considered to be very abstract. Yet,
these are now accepted as being done very well by computers. These tasks have
ranged from multiple aspects of software engineering to mathematics to
conversation in natural language with humans. This was done by automating the
simplest possible step and then building on it to perform more complex tasks.
We wonder if ethical AI might be similarly achieved and advocate the process of
automation as key step in making AI take ethical decisions. The key
contribution of this paper is to reflect on how automation was introduced into
domains previously considered too abstract for computers.
</dc:description>
 <dc:description>Comment: 4 pages, 15th Multi Conference on Computer Science and Information
  Systems, 20-23 July 2021</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15739</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15746</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards An Ethics-Audit Bot</dc:title>
 <dc:creator>Pearson, Siani</dc:creator>
 <dc:creator>Lloyd, Martin</dc:creator>
 <dc:creator>Nallur, Vivek</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>68T37</dc:subject>
 <dc:subject>I.2.0</dc:subject>
 <dc:description>  In this paper we focus on artificial intelligence (AI) for governance, not
governance for AI, and on just one aspect of governance, namely ethics audit.
Different kinds of ethical audit bots are possible, but who makes the choices
and what are the implications? In this paper, we do not provide
ethical/philosophical solutions, but rather focus on the technical aspects of
what an AI-based solution for validating the ethical soundness of a target
system would be like. We propose a system that is able to conduct an ethical
audit of a target system, given certain socio-technical conditions. To be more
specific, we propose the creation of a bot that is able to support
organisations in ensuring that their software development lifecycles contain
processes that meet certain ethical standards.
</dc:description>
 <dc:description>Comment: 5 pages, short paper, 15th Multi Conference on Computer Science and
  Information Systems, 20-23 July 2021</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15746</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15756</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GnetDet: Object Detection Optimized on a 224mW CNN Accelerator Chip at
  the Speed of 106FPS</dc:title>
 <dc:creator>Sun, Baohua</dc:creator>
 <dc:creator>Zhang, Tao</dc:creator>
 <dc:creator>Su, Jiapeng</dc:creator>
 <dc:creator>Sha, Hao</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Object detection is widely used on embedded devices. With the wide
availability of CNN (Convolutional Neural Networks) accelerator chips, the
object detection applications are expected to run with low power consumption,
and high inference speed. In addition, the CPU load is expected to be as low as
possible for a CNN accelerator chip working as a co-processor with a host CPU.
In this paper, we optimize the object detection model on the CNN accelerator
chip by minimizing the CPU load. The resulting model is called GnetDet. The
experimental result shows that the GnetDet model running on a 224mW chip
achieves the speed of 106FPS with excellent accuracy.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures, and 1 table. arXiv admin note: text overlap with
  arXiv:2101.10444</dc:description>
 <dc:date>2021-02-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15756</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15757</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Residential smart plug with bluetooth communication</dc:title>
 <dc:creator>de Souza, Thales Ruano Barros</dc:creator>
 <dc:creator>Rodrigues, Gabriel Goes</dc:creator>
 <dc:creator>Serrao, Luan da Silva</dc:creator>
 <dc:creator>Macambira, Renata do Nascimento Mota</dc:creator>
 <dc:creator>Carvalho, Celso Barbosa</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Electricity forms the backbone of the modern world but increasing energy
demand with the growth of urban areas in recent decades has overwhelmed the
current power grid ecosystem. So, there is a need to move towards a more
efficient and interconnected smart grid infrastructure. The growing popularity
of the Internet of Things(IoT) has increased the demand for smart and connected
devices. In this work we developed a hardware device based on the ATmega2560
microcontroller that can estimate the power consumption and control the state
of electro-electronic devices interconnected to it through Bluetooth wireless
technology. The developed hardware is a smart plug focusing on smart home
applications. As a result, by using a smartphone device with Bluetooth
communication, one can control and measure electrical parameters of the
interconnected electro-electronic hardware such as the RMS (Root Mean Square)
current and RMS power been consumed. The obtained results showed the technical
viability in the construction of energy consumption measuring device using
modules and components available in the Brazilian market.
</dc:description>
 <dc:date>2021-01-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15757</dc:identifier>
 <dc:identifier>ITEGAM-JETIA, 6(21), p. 20-30 (2020)</dc:identifier>
 <dc:identifier>doi:10.5935/2447-0228.20200003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15764</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>eDarkTrends: Harnessing Social Media Trends in Substance use disorders
  for Opioid Listings on Cryptomarket</dc:title>
 <dc:creator>Lokala, Usha</dc:creator>
 <dc:creator>Lamy, Francois</dc:creator>
 <dc:creator>Dastidar, Triyasha Ghosh</dc:creator>
 <dc:creator>Roy, Kaushik</dc:creator>
 <dc:creator>Daniulaityte, Raminta</dc:creator>
 <dc:creator>Parthasarathy, Srinivasan</dc:creator>
 <dc:creator>Sheth, Amit</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Opioid and substance misuse is rampant in the United States today, with the
phenomenon known as the opioid crisis. The relationship between substance use
and mental health has been extensively studied, with one possible relationship
being substance misuse causes poor mental health. However, the lack of evidence
on the relationship has resulted in opioids being largely inaccessible through
legal means. This study analyzes the substance misuse posts on social media
with the opioids being sold through crypto market listings. We use the Drug
Abuse Ontology, state-of-the-art deep learning, and BERT-based models to
generate sentiment and emotion for the social media posts to understand user
perception on social media by investigating questions such as, which synthetic
opioids people are optimistic, neutral, or negative about or what kind of drugs
induced fear and sorrow or what kind of drugs people love or thankful about or
which drug people think negatively about or which opioids cause little to no
sentimental reaction. We also perform topic analysis associated with the
generated sentiments and emotions to understand which topics correlate with
people's responses to various drugs. Our findings can help shape policy to help
isolate opioid use cases where timely intervention may be required to prevent
adverse consequences, prevent overdose-related deaths, and worsen the epidemic.
</dc:description>
 <dc:description>Comment: 6 pages, ICLR AI for Public Health Workshop 2021</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15764</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15787</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Meeting in the notebook: a notebook-based environment for
  micro-submissions in data science collaborations</dc:title>
 <dc:creator>Smith, Micah J.</dc:creator>
 <dc:creator>Cito, J&#xfc;rgen</dc:creator>
 <dc:creator>Veeramachaneni, Kalyan</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Developers in data science and other domains frequently use computational
notebooks to create exploratory analyses and prototype models. However, they
often struggle to incorporate existing software engineering tooling into these
notebook-based workflows, leading to fragile development processes. We
introduce Assembl\'{e}, a new development environment for collaborative data
science projects, in which promising code fragments of data science pipelines
can be contributed as pull requests to an upstream repository entirely from
within JupyterLab, abstracting away low-level version control tool usage. We
describe the design and implementation of Assembl\'{e} and report on a user
study of 23 data scientists.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15792</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Affect Analysis in-the-wild: Valence-Arousal, Expressions, Action Units
  and a Unified Framework</dc:title>
 <dc:creator>Kollias, Dimitrios</dc:creator>
 <dc:creator>Zafeiriou, Stefanos</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Affect recognition based on subjects' facial expressions has been a topic of
major research in the attempt to generate machines that can understand the way
subjects feel, act and react. In the past, due to the unavailability of large
amounts of data captured in real-life situations, research has mainly focused
on controlled environments. However, recently, social media and platforms have
been widely used. Moreover, deep learning has emerged as a means to solve
visual analysis and recognition problems. This paper exploits these advances
and presents significant contributions for affect analysis and recognition
in-the-wild. Affect analysis and recognition can be seen as a dual knowledge
generation problem, involving: i) creation of new, large and rich in-the-wild
databases and ii) design and training of novel deep neural architectures that
are able to analyse affect over these databases and to successfully generalise
their performance on other datasets. The paper focuses on large in-the-wild
databases, i.e., Aff-Wild and Aff-Wild2 and presents the design of two classes
of deep neural networks trained with these databases. The first class refers to
uni-task affect recognition, focusing on prediction of the valence and arousal
dimensional variables. The second class refers to estimation of all main
behavior tasks, i.e. valence-arousal prediction; categorical emotion
classification in seven basic facial expressions; facial Action Unit detection.
A novel multi-task and holistic framework is presented which is able to jointly
learn and effectively generalize and perform affect recognition over all
existing in-the-wild databases. Large experimental studies illustrate the
achieved performance improvement over the existing state-of-the-art in affect
recognition.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15794</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Higher dimensional generalization of the Benjamin-Ono equation: 2D case</dc:title>
 <dc:creator>Ria&#xf1;o, Oscar</dc:creator>
 <dc:creator>Roudenko, Svetlana</dc:creator>
 <dc:creator>Yang, Kai</dc:creator>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We consider a higher-dimensional version of the Benjamin-Ono (HBO) equation
in the 2D setting: $u_t- \mathcal{R}_1 \Delta u + \frac{1}{2}(u^2)_x=0, (x,y)
\in \mathbb{R}^2$, which is $L^2$-critical, and investigate properties of
solutions both analytically and numerically. For a generalized equation
(fractional 2D gKdV) after deriving the Pohozaev identities, we obtain
non-existence conditions for solitary wave solutions, then prove uniform bounds
in the energy space or conditional global existence, and investigate the
radiation region, a specific wedge in the negative $x$-direction. We then
introduce our numerical approach in a general context, and apply it to obtain
the ground state solution in the 2D critical HBO equation, then show that its
mass is a threshold for global vs. finite time existing solutions, which is
typical in the focusing (mass-)critical dispersive equations. We also observe
that globally existing solutions tend to disperse completely into the radiation
in this nonlocal equation. The blow-up solutions travel in the positive
$x$-direction with the rescaled ground state profile while also radiating
dispersive oscillations into the radiative wedge. We conclude with examples of
different interactions of two solitary wave solutions, including weak and
strong interactions.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15795</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Physical model simulator-trained neural network for computational 3D
  phase imaging of multiple-scattering samples</dc:title>
 <dc:creator>Matlock, Alex</dc:creator>
 <dc:creator>Tian, Lei</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  Recovering 3D phase features of complex, multiple-scattering biological
samples traditionally sacrifices computational efficiency and processing time
for physical model accuracy and reconstruction quality. This trade-off hinders
the rapid analysis of living, dynamic biological samples that are often of
greatest interest to biological research. Here, we overcome this bottleneck by
combining annular intensity diffraction tomography (aIDT) with an
approximant-guided deep learning framework. Using a novel physics model
simulator-based learning strategy trained entirely on natural image datasets,
we show our network can robustly reconstruct complex 3D biological samples of
arbitrary size and structure. This approach highlights that large-scale
multiple-scattering models can be leveraged in place of acquiring experimental
datasets for achieving highly generalizable deep learning models. We devise a
new model-based data normalization pre-processing procedure for homogenizing
the sample contrast and achieving uniform prediction quality regardless of
scattering strength. To achieve highly efficient training and prediction, we
implement a lightweight 2D network structure that utilizes a multi-channel
input for encoding the axial information. We demonstrate this framework's
capabilities on experimental measurements of epithelial buccal cells and
Caenorhabditis elegans worms. We highlight the robustness of this approach by
evaluating dynamic samples on a living worm video, and we emphasize our
approach's generalizability by recovering algae samples evaluated with
different experimental setups. To assess the prediction quality, we develop a
novel quantitative evaluation metric and show that our predictions are
consistent with our experimental measurements and multiple-scattering physics.
</dc:description>
 <dc:description>Comment: 16 Pages, 6 Figures</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15795</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15797</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Putting Things into Context: Rich Explanations for Query Answers using
  Join Graphs (extended version)</dc:title>
 <dc:creator>Li, Chenjie</dc:creator>
 <dc:creator>Miao, Zhengjie</dc:creator>
 <dc:creator>Zeng, Qitian</dc:creator>
 <dc:creator>Glavic, Boris</dc:creator>
 <dc:creator>Roy, Sudeepa</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  In many data analysis applications, there is a need to explain why a
surprising or interesting result was produced by a query. Previous approaches
to explaining results have directly or indirectly used data provenance (input
tuples contributing to the result(s) of interest), which is limited by the fact
that relevant information for explaining an answer may not be fully contained
in the provenance. We propose a new approach for explaining query results by
augmenting provenance with information from other related tables in the
database. We develop a suite of optimization techniques, and demonstrate
experimentally using real datasets and through a user study that our approach
produces meaningful results by efficiently navigating the large search space of
possible explanations.
</dc:description>
 <dc:description>Comment: technical report(32 pages), main paper to appear in SIGMOD 2021</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15797</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15808</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CvT: Introducing Convolutions to Vision Transformers</dc:title>
 <dc:creator>Wu, Haiping</dc:creator>
 <dc:creator>Xiao, Bin</dc:creator>
 <dc:creator>Codella, Noel</dc:creator>
 <dc:creator>Liu, Mengchen</dc:creator>
 <dc:creator>Dai, Xiyang</dc:creator>
 <dc:creator>Yuan, Lu</dc:creator>
 <dc:creator>Zhang, Lei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present in this paper a new architecture, named Convolutional vision
Transformer (CvT), that improves Vision Transformer (ViT) in performance and
efficiency by introducing convolutions into ViT to yield the best of both
designs. This is accomplished through two primary modifications: a hierarchy of
Transformers containing a new convolutional token embedding, and a
convolutional Transformer block leveraging a convolutional projection. These
changes introduce desirable properties of convolutional neural networks (CNNs)
to the ViT architecture (\ie shift, scale, and distortion invariance) while
maintaining the merits of Transformers (\ie dynamic attention, global context,
and better generalization). We validate CvT by conducting extensive
experiments, showing that this approach achieves state-of-the-art performance
over other Vision Transformers and ResNets on ImageNet-1k, with fewer
parameters and lower FLOPs. In addition, performance gains are maintained when
pretrained on larger datasets (\eg ImageNet-22k) and fine-tuned to downstream
tasks. Pre-trained on ImageNet-22k, our CvT-W24 obtains a top-1 accuracy of
87.7\% on the ImageNet-1k val set. Finally, our results show that the
positional encoding, a crucial component in existing Vision Transformers, can
be safely removed in our model, simplifying the design for higher resolution
vision tasks. Code will be released at \url{https://github.com/leoxiaobin/CvT}.
</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15808</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15813</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PixelTransformer: Sample Conditioned Signal Generation</dc:title>
 <dc:creator>Tulsiani, Shubham</dc:creator>
 <dc:creator>Gupta, Abhinav</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We propose a generative model that can infer a distribution for the
underlying spatial signal conditioned on sparse samples e.g. plausible images
given a few observed pixels. In contrast to sequential autoregressive
generative models, our model allows conditioning on arbitrary samples and can
answer distributional queries for any location. We empirically validate our
approach across three image datasets and show that we learn to generate diverse
and meaningful samples, with the distribution variance reducing given more
observed pixels. We also show that our approach is applicable beyond images and
can allow generating other types of spatial outputs e.g. polynomials, 3D
shapes, and videos.
</dc:description>
 <dc:description>Comment: Project page: https://shubhtuls.github.io/PixelTransformer/</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.15814</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Fidelity and Arbitrary Face Editing</dc:title>
 <dc:creator>Gao, Yue</dc:creator>
 <dc:creator>Wei, Fangyun</dc:creator>
 <dc:creator>Bao, Jianmin</dc:creator>
 <dc:creator>Gu, Shuyang</dc:creator>
 <dc:creator>Chen, Dong</dc:creator>
 <dc:creator>Wen, Fang</dc:creator>
 <dc:creator>Lian, Zhouhui</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Cycle consistency is widely used for face editing. However, we observe that
the generator tends to find a tricky way to hide information from the original
image to satisfy the constraint of cycle consistency, making it impossible to
maintain the rich details (e.g., wrinkles and moles) of non-editing areas. In
this work, we propose a simple yet effective method named HifaFace to address
the above-mentioned problem from two perspectives. First, we relieve the
pressure of the generator to synthesize rich details by directly feeding the
high-frequency information of the input image into the end of the generator.
Second, we adopt an additional discriminator to encourage the generator to
synthesize rich details. Specifically, we apply wavelet transformation to
transform the image into multi-frequency domains, among which the
high-frequency parts can be used to recover the rich details. We also notice
that a fine-grained and wider-range control for the attribute is of great
importance for face editing. To achieve this goal, we propose a novel attribute
regression loss. Powered by the proposed framework, we achieve high-fidelity
and arbitrary face editing, outperforming other state-of-the-art approaches.
</dc:description>
 <dc:description>Comment: CVPR 2021</dc:description>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.15814</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<resumptionToken cursor="2000" completeListSize="2358"></resumptionToken>
</ListRecords>
</OAI-PMH>
