<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2024-01-30T08:19:16Z</responseDate>
<request verb="ListRecords" until="2021-03-30" from="2021-03-20" metadataPrefix="oai_dc" set="cs">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:0912.0228</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Answering Hilbert's 1st Problem</dc:title>
 <dc:creator>Sauerbier, Charles</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03E17</dc:subject>
 <dc:description>  Hilbert's first problem is of importance in relation to work being done in
computational systems. It is the question of equipollence of natural and real
numbers. By construction equipollence is established for real numbers in open
interval (0, 1) and natural numbers and, from such to all real numbers.
Construction stands in contradiction of the generally accepted diagonal
argument of Cantor. Mathematics being irrefutable, in absence rejection of all
theory of mathematics and logic, the problem exists in acceptance; that itself
arises of more fundamental a problem in science generally. The problem within
Hilbert's problem is of Schopenhauer's, et al, &quot;will and representation&quot; born.
</dc:description>
 <dc:description>Comment: 7 pages, 0 figures; full revision of content to address critiques;
  along with numerous complaints as to &quot;style&quot;, &quot;quality&quot;, and other nonsense
  arising of opinion</dc:description>
 <dc:date>2009-12-01</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/0912.0228</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3608</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The complexity of multiple-precision arithmetic</dc:title>
 <dc:creator>Brent, Richard P.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>03D15 (Primary) 68Q17, 68Q25 (Secondary)</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:subject>G.1.0</dc:subject>
 <dc:description>  In studying the complexity of iterative processes it is usually assumed that
the arithmetic operations of addition, multiplication, and division can be
performed in certain constant times. This assumption is invalid if the
precision required increases as the computation proceeds. We give upper and
lower bounds on the number of single-precision operations required to perform
various multiple-precision operations, and deduce some interesting consequences
concerning the relative efficiencies of methods for solving nonlinear equations
using variable-length multiple-precision arithmetic. A postscript describes
more recent developments.
</dc:description>
 <dc:description>Comment: An old (1976) paper with a postscript (1999) describing more recent
  developments. 30 pages. For further details, see
  http://wwwmaths.anu.edu.au/~brent/pub/pub032.html. Typos corrected in v2</dc:description>
 <dc:date>2010-04-20</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1004.3608</dc:identifier>
 <dc:identifier>The Complexity of Computational Problem Solving (edited by R. S.
  Anderssen and R. P. Brent), University of Queensland Press, Brisbane, 1976,
  126-165</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1006.2403</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Queueing Behavior of Random Codes over a Gilbert-Elliot Erasure
  Channel</dc:title>
 <dc:creator>Parag, Parimal</dc:creator>
 <dc:creator>Chamberland, Jean-Francois</dc:creator>
 <dc:creator>Pfister, Henry D.</dc:creator>
 <dc:creator>Narayanan, Krishna R.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers the queueing performance of a system that transmits
coded data over a time-varying erasure channel. In our model, the queue length
and channel state together form a Markov chain that depends on the system
parameters. This gives a framework that allows a rigorous analysis of the queue
as a function of the code rate. Most prior work in this area either ignores
block-length (e.g., fluid models) or assumes error-free communication using
finite codes. This work enables one to determine when such assumptions provide
good, or bad, approximations of true behavior. Moreover, it offers a new
approach to optimize parameters and evaluate performance. This can be valuable
for delay-sensitive systems that employ short block lengths.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures, conference</dc:description>
 <dc:date>2010-06-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1006.2403</dc:identifier>
 <dc:identifier>IEEE International Symposium on Information Theory (ISIT),
  1798--1802, Austin, TX, Jun 13-18, 2010</dc:identifier>
 <dc:identifier>doi:10.1109/ISIT.2010.5513296</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4428</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Untangling Typechecking of Intersections and Unions</dc:title>
 <dc:creator>Dunfield, Jana</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Intersection and union types denote conjunctions and disjunctions of
properties. Using bidirectional typechecking, intersection types are relatively
straightforward, but union types present challenges. For union types, we can
case-analyze a subterm of union type when it appears in evaluation position
(replacing the subterm with a variable, and checking that term twice under
appropriate assumptions). This technique preserves soundness in a call-by-value
semantics.
  Sadly, there are so many choices of subterms that a direct implementation is
not practical. But carefully transforming programs into let-normal form
drastically reduces the number of choices. The key results are soundness and
completeness: a typing derivation (in the system with too many subterm choices)
exists for a program if and only if a derivation exists for the let-normalized
program.
</dc:description>
 <dc:description>Comment: In Proceedings ITRS 2010, arXiv:1101.4104</dc:description>
 <dc:date>2011-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1101.4428</dc:identifier>
 <dc:identifier>EPTCS 45, 2011, pp. 59-70</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.45.5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.5495</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Formalization of Polytime Functions</dc:title>
 <dc:creator>Heraud, Sylvain</dc:creator>
 <dc:creator>Nowak, David</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We present a deep embedding of Bellantoni and Cook's syntactic
characterization of polytime functions. We prove formally that it is correct
and complete with respect to the original characterization by Cobham that
required a bound to be proved manually. Compared to the paper proof by
Bellantoni and Cook, we have been careful in making our proof fully contructive
so that we obtain more precise bounding polynomials and more efficient
translations between the two characterizations. Another difference is that we
consider functions on bitstrings instead of functions on positive integers.
This latter change is motivated by the application of our formalization in the
context of formal security proofs in cryptography. Based on our core
formalization, we have started developing a library of polytime functions that
can be reused to build more complex ones.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2011-02-27</dc:date>
 <dc:date>2011-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1102.5495</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-642-22863-6_11</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1110.0811</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A general model of regression using iterative series</dc:title>
 <dc:creator>Sinha, Nilotpal Kanti</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>93E24, 62J05</dc:subject>
 <dc:description>  We present a new and general method of weighted least square univariate
regression where the dependent variable is expanded as a series of suitably
chosen functions of the independent variables. Each term of the series is
obtained by an iterative process which reduces the sum of the square of the
residuals. Thus by evaluating the regression series to a sufficiently large
number of terms we can, in principle, reduce the sum of the square of residuals
and improve the accuracy of the fit.
</dc:description>
 <dc:description>Comment: Need major changes and corrections</dc:description>
 <dc:date>2011-10-04</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1110.0811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1210.1841</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Arab Spring: A Simple Compartmental Model for the Dynamics of a
  Revolution</dc:title>
 <dc:creator>Lang, John</dc:creator>
 <dc:creator>De Sterck, Hans</dc:creator>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The self-immolation of Mohamed Bouazizi on December 17, 2011 in the small
Tunisian city of Sidi Bouzid, set off a sequence of events culminating in the
revolutions of the Arab Spring. It is widely believed that the Internet and
social media played a critical role in the growth and success of protests that
led to the downfall of the regimes in Egypt and Tunisia. However, the precise
mechanisms by which these new media affected the course of events remain
unclear. We introduce a simple compartmental model for the dynamics of a
revolution in a dictatorial regime such as Tunisia or Egypt which takes into
account the role of the Internet and social media. An elementary mathematical
analysis of the model identifies four main parameter regions: stable police
state, meta-stable police state, unstable police state, and failed state. We
illustrate how these regions capture, at least qualitatively, a wide range of
scenarios observed in the context of revolutionary movements by considering the
revolutions in Tunisia and Egypt, as well as the situation in Iran, China, and
Somalia, as case studies. We pose four questions about the dynamics of the Arab
Spring revolutions and formulate answers informed by the model. We conclude
with some possible directions for future work.
</dc:description>
 <dc:date>2012-10-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1210.1841</dc:identifier>
 <dc:identifier>doi:10.1016/j.mathsocsci.2014.01.004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1307.8204</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Annotations for Intersection Typechecking</dc:title>
 <dc:creator>Dunfield, Jana</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  In functional programming languages, the classic form of annotation is a
single type constraint on a term. Intersection types add complications: a
single term may have to be checked several times against different types, in
different contexts, requiring annotation with several types. Moreover, it is
useful (in some systems, necessary) to indicate the context in which each such
type is to be used.
  This paper explores the technical design space of annotations in systems with
intersection types. Earlier work (Dunfield and Pfenning 2004) introduced
contextual typing annotations, which we now tease apart into more elementary
mechanisms: a &quot;right hand&quot; annotation (the standard form), a &quot;left hand&quot;
annotation (the context in which a right-hand annotation is to be used), a
merge that allows for multiple annotations, and an existential binder for index
variables. The most novel element is the left-hand annotation, which guards
terms (and right-hand annotations) with a judgment that must follow from the
current context.
</dc:description>
 <dc:description>Comment: In Proceedings ITRS 2012, arXiv:1307.7849</dc:description>
 <dc:date>2013-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1307.8204</dc:identifier>
 <dc:identifier>EPTCS 121, 2013, pp. 35-47</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.121.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1311.0804</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Innovation \'educative en sciences de l'information</dc:title>
 <dc:creator>Wulff, Enrique</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Concerning its development in the virtual classroom, the web 2.0 educational
innovation means the use and the production of textbooks and the
personalisation of the classnotes. The controversy, that is a precondition of
awareness, organized around the assignment of knowledge to a central authority
vs its grant to individuals who need it to share their plans with others, would
meet the present dynamism of e-learning. To introduce these training strategies
with scientific information in marine sciences, an online course was
transformed into an opportunity for evaluating and living open access.
</dc:description>
 <dc:description>Comment: 35 pages, in French</dc:description>
 <dc:date>2013-11-04</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1311.0804</dc:identifier>
 <dc:language>fr</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1410.1233</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EnKF-C user guide</dc:title>
 <dc:creator>Sakov, Pavel</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>90-04</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  EnKF-C provides a compact generic framework for off-line data assimilation
into large-scale layered geophysical models with the ensemble Kalman filter
(EnKF). It is coded in C for GNU/Linux platform and can work either in EnKF,
ensemble optimal interpolation (EnOI), or hybrid (EnKF/EnOI) modes.
</dc:description>
 <dc:date>2014-10-05</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1410.1233</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1501.04091</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Hierarchy of Linear Threshold Models for the Spread of Political
  Revolutions on Social Networks</dc:title>
 <dc:creator>Lang, John C.</dc:creator>
 <dc:creator>De Sterck, Hans</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>91D10, 91D30, 70G60, 37M99</dc:subject>
 <dc:description>  We study a linear threshold agent-based model (ABM) for the spread of
political revolutions on social networks using empirical network data. We
propose new techniques for building a hierarchy of simplified ordinary
differential equation (ODE) based models that aim to capture essential features
of the ABM, including effects of the actual networks, and give insight in the
parameter regime transitions of the ABM. We relate the ABM and the hierarchy of
models to a population-level compartmental ODE model that we proposed
previously for the spread of political revolutions [1], which is shown to be
mathematically consistent with the proposed ABM and provides a way to analyze
the global behaviour of the ABM. This consistency with the linear threshold ABM
also provides further justification a posteriori for the compartmental model of
[1]. Extending concepts from epidemiological modelling, we define a basic
reproduction number $R_0$ for the linear threshold ABM and apply it to predict
ABM behaviour on empirical networks. In small-scale numerical tests we
investigate experimentally the differences in spreading behaviour that occur
under the linear threshold ABM model when applied to some empirical online and
offline social networks, searching for quantitative evidence that political
revolutions may be facilitated by the modern online social networks of social
media.
</dc:description>
 <dc:date>2015-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1501.04091</dc:identifier>
 <dc:identifier>doi:10.1093/comnet/cnv030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07792</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incremental Computation with Names</dc:title>
 <dc:creator>Hammer, Matthew A.</dc:creator>
 <dc:creator>Dunfield, Jana</dc:creator>
 <dc:creator>Headley, Kyle</dc:creator>
 <dc:creator>Labich, Nicholas</dc:creator>
 <dc:creator>Foster, Jeffrey S.</dc:creator>
 <dc:creator>Hicks, Michael</dc:creator>
 <dc:creator>Van Horn, David</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  Over the past thirty years, there has been significant progress in developing
general-purpose, language-based approaches to incremental computation, which
aims to efficiently update the result of a computation when an input is
changed. A key design challenge in such approaches is how to provide efficient
incremental support for a broad range of programs. In this paper, we argue that
first-class names are a critical linguistic feature for efficient incremental
computation. Names identify computations to be reused across differing runs of
a program, and making them first class gives programmers a high level of
control over reuse. We demonstrate the benefits of names by presenting NOMINAL
ADAPTON, an ML-like language for incremental computation with names. We
describe how to use NOMINAL ADAPTON to efficiently incrementalize several
standard programming patterns -- including maps, folds, and unfolds -- and show
how to build efficient, incremental probabilistic trees and tries. Since
NOMINAL ADAPTON's implementation is subtle, we formalize it as a core calculus
and prove it is from-scratch consistent, meaning it always produces the same
answer as simply re-running the computation. Finally, we demonstrate that
NOMINAL ADAPTON can provide large speedups over both from-scratch computation
and ADAPTON, a previous state-of-the-art incremental computation system.
</dc:description>
 <dc:description>Comment: OOPSLA '15, October 25-30, 2015, Pittsburgh, PA, USA</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07792</dc:identifier>
 <dc:identifier>doi:10.1145/2814270.2814305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1509.03389</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Attribute Proportional Representation</dc:title>
 <dc:creator>Lang, Jerome</dc:creator>
 <dc:creator>Skowron, Piotr</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We consider the following problem in which a given number of items has to be
chosen from a predefined set. Each item is described by a vector of attributes
and for each attribute there is a desired distribution that the selected set
should have. We look for a set that fits as much as possible the desired
distributions on all attributes. Examples of applications include choosing
members of a representative committee, where candidates are described by
attributes such as sex, age and profession, and where we look for a committee
that for each attribute offers a certain representation, i.e., a single
committee that contains a certain number of young and old people, certain
number of men and women, certain number of people with different professions,
etc. With a single attribute the problem collapses to the apportionment problem
for party-list proportional representation systems (in such case the value of
the single attribute would be a political affiliation of a candidate). We study
the properties of the associated subset selection rules, as well as their
computation complexity.
</dc:description>
 <dc:date>2015-09-11</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1509.03389</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1510.08498</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Coinductive Approach to Computing with Compact Sets</dc:title>
 <dc:creator>Berger, Ulrich</dc:creator>
 <dc:creator>Spreen, Dieter</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03B70, 03F60, 68T15</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.2</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:description>  Exact representations of real numbers such as the signed digit representation
or more generally linear fractional representations or the infinite Gray code
represent real numbers as infinite streams of digits. In earlier work by the
first author it was shown how to extract certified algorithms working with the
signed digit representations from constructive proofs. In this paper we lay the
foundation for doing a similar thing with nonempty compact sets. It turns out
that a representation by streams of finitely many digits is impossible and
instead trees are needed.
</dc:description>
 <dc:description>Comment: 34 pages</dc:description>
 <dc:date>2015-10-28</dc:date>
 <dc:date>2016-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1510.08498</dc:identifier>
 <dc:identifier>doi:10.4115/jla.2016.8.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.04549</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incremental Semiparametric Inverse Dynamics Learning</dc:title>
 <dc:creator>Camoriano, Raffaello</dc:creator>
 <dc:creator>Traversaro, Silvio</dc:creator>
 <dc:creator>Rosasco, Lorenzo</dc:creator>
 <dc:creator>Metta, Giorgio</dc:creator>
 <dc:creator>Nori, Francesco</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents a novel approach for incremental semiparametric inverse
dynamics learning. In particular, we consider the mixture of two approaches:
Parametric modeling based on rigid body dynamics equations and nonparametric
modeling based on incremental kernel methods, with no prior information on the
mechanical properties of the system. This yields to an incremental
semiparametric approach, leveraging the advantages of both the parametric and
nonparametric models. We validate the proposed technique learning the dynamics
of one arm of the iCub humanoid robot.
</dc:description>
 <dc:date>2016-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.04549</dc:identifier>
 <dc:identifier>doi:10.1109/ICRA.2016.7487177</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.08510</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Patch-Ordering as a Regularization for Inverse Problems in Image
  Processing</dc:title>
 <dc:creator>Vaksman, Gregory</dc:creator>
 <dc:creator>Zibulevsky, Michael</dc:creator>
 <dc:creator>Elad, Michael</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>62H35, 68U10, 94A08</dc:subject>
 <dc:description>  Recent work in image processing suggests that operating on (overlapping)
patches in an image may lead to state-of-the-art results. This has been
demonstrated for a variety of problems including denoising, inpainting,
deblurring, and super-resolution. The work reported in [1,2] takes an extra
step forward by showing that ordering these patches to form an approximate
shortest path can be leveraged for better processing. The core idea is to apply
a simple filter on the resulting 1D smoothed signal obtained after the
patch-permutation. This idea has been also explored in combination with a
wavelet pyramid, leading eventually to a sophisticated and highly effective
regularizer for inverse problems in imaging. In this work we further study the
patch-permutation concept, and harness it to propose a new simple yet effective
regularization for image restoration problems. Our approach builds on the
classic Maximum A'posteriori probability (MAP), with a penalty function
consisting of a regular log-likelihood term and a novel permutation-based
regularization term. Using a plain 1D Laplacian, the proposed regularization
forces robust smoothness (L1) on the permuted pixels. Since the permutation
originates from patch-ordering, we propose to accumulate the smoothness terms
over all the patches' pixels. Furthermore, we take into account the found
distances between adjacent patches in the ordering, by weighting the Laplacian
outcome. We demonstrate the proposed scheme on a diverse set of problems: (i)
severe Poisson image denoising, (ii) Gaussian image denoising, (iii) image
deblurring, and (iv) single image super-resolution. In all these cases, we use
recent methods that handle these problems as initialization to our scheme. This
is followed by an L-BFGS optimization of the above-described penalty function,
leading to state-of-the-art results, and especially so for highly ill-posed
cases.
</dc:description>
 <dc:date>2016-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.08510</dc:identifier>
 <dc:identifier>doi:10.1137/15M1038074</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1605.02160</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Belief Merging by Source Reliability Assessment</dc:title>
 <dc:creator>Liberatore, Paolo</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Merging beliefs requires the plausibility of the sources of the information
to be merged. They are typically assumed equally reliable in lack of hints
indicating otherwise; yet, a recent line of research spun from the idea of
deriving this information from the revision process itself. In particular, the
history of previous revisions and previous merging examples provide information
for performing subsequent mergings.
  Yet, no examples or previous revisions may be available. In spite of the
apparent lack of information, something can still be inferred by a
try-and-check approach: a relative reliability ordering is assumed, the merging
process is performed based on it, and the result is compared with the original
information. The outcome of this check may be incoherent with the initial
assumption, like when a completely reliable source is rejected some of the
information it provided. In such cases, the reliability ordering assumed in the
first place can be excluded from consideration. The first theorem of this
article proves that such a scenario is indeed possible. Other results are
obtained under various definition of reliability and merging.
</dc:description>
 <dc:date>2016-05-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1605.02160</dc:identifier>
 <dc:identifier>doi:10.1613/jair.1.11238</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.01006</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Fully Convolutional and Recurrent Neural Networks for 3D
  Biomedical Image Segmentation</dc:title>
 <dc:creator>Chen, Jianxu</dc:creator>
 <dc:creator>Yang, Lin</dc:creator>
 <dc:creator>Zhang, Yizhe</dc:creator>
 <dc:creator>Alber, Mark</dc:creator>
 <dc:creator>Chen, Danny Z.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Segmentation of 3D images is a fundamental problem in biomedical image
analysis. Deep learning (DL) approaches have achieved state-of-the-art
segmentation perfor- mance. To exploit the 3D contexts using neural networks,
known DL segmentation methods, including 3D convolution, 2D convolution on
planes orthogonal to 2D image slices, and LSTM in multiple directions, all
suffer incompatibility with the highly anisotropic dimensions in common 3D
biomedical images. In this paper, we propose a new DL framework for 3D image
segmentation, based on a com- bination of a fully convolutional network (FCN)
and a recurrent neural network (RNN), which are responsible for exploiting the
intra-slice and inter-slice contexts, respectively. To our best knowledge, this
is the first DL framework for 3D image segmentation that explicitly leverages
3D image anisotropism. Evaluating using a dataset from the ISBI Neuronal
Structure Segmentation Challenge and in-house image stacks for 3D fungus
segmentation, our approach achieves promising results comparing to the known
DL-based 3D segmentation approaches.
</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:date>2016-09-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.01006</dc:identifier>
 <dc:identifier>https://papers.nips.cc/paper/2016/hash/4dcf435435894a4d0972046fc566af76-Abstract.html</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1610.00097</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Refinement types for precisely named cache locations</dc:title>
 <dc:creator>Hammer, Matthew A.</dc:creator>
 <dc:creator>Dunfield, Jana</dc:creator>
 <dc:creator>Economou, Dimitrios J.</dc:creator>
 <dc:creator>Narasimhamurthy, Monal</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Many programming language techniques for incremental computation employ
programmer-specified names for cached information. At runtime, each name
identifies a &quot;cache location&quot; for a dynamic data value or a sub-computation; in
sum, these cache location choices guide change propagation and incremental
(re)execution.
  We call a cache location name precise when it identifies at most one value or
subcomputation; we call all other names imprecise, or ambiguous. At a minimum,
cache location names must be precise to ensure that change propagation works
correctly; yet, reasoning statically about names in incremental programs
remains an open problem.
  As a first step, this paper defines and solves the precise name problem,
where we verify that incremental programs with explicit names use them
precisely. To do so, we give a refinement type and effect system, and prove it
sound (every well-typed program uses names precisely). We also demonstrate that
this type system is expressive by verifying example programs that compute over
efficient representations of incremental sequences and sets. Beyond verifying
these programs, our type system also describes their dynamic naming strategies,
e.g., for library documentation purposes.
</dc:description>
 <dc:date>2016-10-01</dc:date>
 <dc:date>2017-10-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1610.00097</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1610.00386</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rain Removal via Shrinkage-Based Sparse Coding and Learned Rain
  Dictionary</dc:title>
 <dc:creator>Son, Chang-Hwan</dc:creator>
 <dc:creator>Zhang, Xiao-Ping</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper introduces a new rain removal model based on the shrinkage of the
sparse codes for a single image. Recently, dictionary learning and sparse
coding have been widely used for image restoration problems. These methods can
also be applied to the rain removal by learning two types of rain and non-rain
dictionaries and forcing the sparse codes of the rain dictionary to be zero
vectors. However, this approach can generate unwanted edge artifacts and detail
loss in the non-rain regions. Based on this observation, a new approach for
shrinking the sparse codes is presented in this paper. To effectively shrink
the sparse codes in the rain and non-rain regions, an error map between the
input rain image and the reconstructed rain image is generated by using the
learned rain dictionary. Based on this error map, both the sparse codes of rain
and non-rain dictionaries are used jointly to represent the image structures of
objects and avoid the edge artifacts in the non-rain regions. In the rain
regions, the correlation matrix between the rain and non-rain dictionaries is
calculated. Then, the sparse codes corresponding to the highly correlated
signal-atoms in the rain and non-rain dictionaries are shrunk jointly to
improve the removal of the rain structures. The experimental results show that
the proposed shrinkage-based sparse coding can preserve image structures and
avoid the edge artifacts in the non-rain regions, and it can remove the rain
structures in the rain regions. Also, visual quality evaluation confirms that
the proposed method outperforms the conventional texture and rain removal
methods.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2016-10-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1610.00386</dc:identifier>
 <dc:identifier>Journal of Imaging Science and Technology, vol. 64, no. 3, pp.
  30501-1-30501-17(17), May 2020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1610.02260</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalised Information Systems Capture L-Domains</dc:title>
 <dc:creator>Spreen, Dieter</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>68Q55, 03B70, 06B35, 03B22</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  A generalisation of Scott's information systems \cite{sco82} is presented
that captures exactly all L-domains. The global consistency predicate in
Scott's definition is relativised in such a way that there is a consistency
predicate for each atomic proposition (token) saying which finite sets of such
statements express information that is consistent with the given statement.
  It is shown that the states of such generalised information systems form an
L-domain, and that each L-domain can be generated in this way, up to
isomorphism. Moreover, the equivalence of the category of generalised
information systems with the category of L-domains is derived. In addition, it
will be seen that from every generalised information system capturing an
algebraic bounded-complete domain a corresponding Scott information system can
be obtained in an easy and natural way, and vice versa; similarly for Hoofman's
continuous information systems \cite{ho93} and the continuous bounded-complete
domains captured by them; for Chen and Jung's disjunctive propositional logic
\cite{cj06} and algebraic L-domains (as well as for Wang and Li's \cite{wll20}
finitary version and Lawson-compact algebraic L-domains); and for Wang and Li's
conjunctive sequent calculi \cite{wlbc20} and proper continuous
bounded-complete domains. The proofs always contain syntactic translations
between the logical calculi involved.
</dc:description>
 <dc:description>Comment: Typo removed</dc:description>
 <dc:date>2016-10-07</dc:date>
 <dc:date>2021-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1610.02260</dc:identifier>
 <dc:identifier>doi:10.1016/j.tcs.2020.12.044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1610.02518</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Advantage of Truncated Permutations</dc:title>
 <dc:creator>Gilboa, Shoni</dc:creator>
 <dc:creator>Gueron, Shay</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Constructing a Pseudo Random Function (PRF) is a fundamental problem in
cryptology. Such a construction, implemented by truncating the last $m$ bits of
permutations of $\{0, 1\}^{n}$ was suggested by Hall et al. (1998). They
conjectured that the distinguishing advantage of an adversary with $q$ queries,
${\bf Adv}_{n, m} (q)$, is small if $q = o (2^{(n+m)/2})$, established an upper
bound on ${\bf Adv}_{n, m} (q)$ that confirms the conjecture for $m &lt; n/7$, and
also declared a general lower bound ${\bf Adv}_{n,m}(q)=\Omega(q^2/2^{n+m})$.
The conjecture was essentially confirmed by Bellare and Impagliazzo (1999).
Nevertheless, the problem of {\em estimating} ${\bf Adv}_{n, m} (q)$ remained
open. Combining the trivial bound $1$, the birthday bound, and a result of Stam
(1978) leads to the upper bound \begin{equation*} {\bf Adv}_{n,m}(q) =
O\left(\min\left\{\frac{q(q-1)}{2^n},\,\frac{q}{2^{\frac{n+m}{2}}},\,1\right\}\right).
\end{equation*} In this paper we show that this upper bound is tight for every
$0\leq m&lt;n$ and any $q$. This, in turn, verifies that the converse to the
conjecture of Hall et al. is also correct, i.e., that ${\bf Adv}_{n, m} (q)$ is
negligible only for $q = o (2^{(n+m)/2})$.
</dc:description>
 <dc:date>2016-10-08</dc:date>
 <dc:date>2021-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1610.02518</dc:identifier>
 <dc:identifier>Discrete Applied Mathematics 294 (2021), 214-223</dc:identifier>
 <dc:identifier>doi:10.1016/j.dam.2021.01.029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06423</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incorporating Pass-Phrase Dependent Background Models for Text-Dependent
  Speaker Verification</dc:title>
 <dc:creator>Sarkar, A. K.</dc:creator>
 <dc:creator>Tan, Zheng-Hua</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we propose pass-phrase dependent background models (PBMs) for
text-dependent (TD) speaker verification (SV) to integrate the pass-phrase
identification process into the conventional TD-SV system, where a PBM is
derived from a text-independent background model through adaptation using the
utterances of a particular pass-phrase. During training, pass-phrase specific
target speaker models are derived from the particular PBM using the training
data for the respective target model. While testing, the best PBM is first
selected for the test utterance in the maximum likelihood (ML) sense and the
selected PBM is then used for the log likelihood ratio (LLR) calculation with
respect to the claimant model. The proposed method incorporates the pass-phrase
identification step in the LLR calculation, which is not considered in
conventional standalone TD-SV systems. The performance of the proposed method
is compared to conventional text-independent background model based TD-SV
systems using either Gaussian mixture model (GMM)-universal background model
(UBM) or Hidden Markov model (HMM)-UBM or i-vector paradigms. In addition, we
consider two approaches to build PBMs: speaker-independent and
speaker-dependent. We show that the proposed method significantly reduces the
error rates of text-dependent speaker verification for the non-target types:
target-wrong and imposter-wrong while it maintains comparable TD-SV performance
when imposters speak a correct utterance with respect to the conventional
system. Experiments are conducted on the RedDots challenge and the RSR2015
databases that consist of short utterances.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:date>2017-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06423</dc:identifier>
 <dc:identifier>Computer speech Language: Volume 47,January 2018, pp. 259-271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06729</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Convergence Time of a Natural Dynamics for Linear Programming</dc:title>
 <dc:creator>Bonifaci, Vincenzo</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68Q05, 90C05</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>G.1.7</dc:subject>
 <dc:description>  We consider a system of nonlinear ordinary differential equations for the
solution of linear programming (LP) problems that was first proposed in the
mathematical biology literature as a model for the foraging behavior of
acellular slime mold Physarum polycephalum, and more recently considered as a
method to solve LPs. We study the convergence time of the continuous Physarum
dynamics in the context of the linear programming problem, and derive a new
time bound to approximate optimality that depends on the relative entropy
between projected versions of the optimal point and of the initial point. The
bound scales logarithmically with the LP cost coefficients and linearly with
the inverse of the relative accuracy, establishing the efficiency of the
dynamics for arbitrary LP instances with positive costs.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06729</dc:identifier>
 <dc:identifier>Algorithmica, 82(2):300-315, 2020</dc:identifier>
 <dc:identifier>doi:10.1007/s00453-019-00615-3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1612.03382</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Motion Detection Method Resistant to Severe Illumination Changes</dc:title>
 <dc:creator>Yousefi, Sahar</dc:creator>
 <dc:creator>Shalmani, M. T. Manzuri</dc:creator>
 <dc:creator>Lin, Jeremy</dc:creator>
 <dc:creator>Staring, Marius</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, there has been a considerable attention given to the motion
detection problem due to the explosive growth of its applications in video
analysis and surveillance systems. While the previous approaches can produce
good results, an accurate detection of motion remains a challenging task due to
the difficulties raised by illumination variations, occlusion, camouflage,
burst physical motion, dynamic texture, and environmental changes such as those
on climate changes, sunlight changes during a day, etc. In this paper, we
propose a novel per-pixel motion descriptor for both motion detection and
dynamic texture segmentation which outperforms the current methods in the
literature particularly in severe scenarios. The proposed descriptor is based
on two complementary three-dimensional-discrete wavelet transform (3D-DWT) and
three-dimensional wavelet leader. In this approach, a feature vector is
extracted for each pixel by applying a novel three dimensional wavelet-based
motion descriptor. Then, the extracted features are clustered by a clustering
method such as well-known k-means algorithm or Gaussian Mixture Model (GMM).
The experimental results demonstrate the effectiveness of our proposed method
compared to the other motion detection approaches from the literature. The
application of the proposed method and additional experimental results for the
different datasets are available at
(http://dspl.ce.sharif.edu/motiondetector.html).
</dc:description>
 <dc:date>2016-12-11</dc:date>
 <dc:date>2018-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1612.03382</dc:identifier>
 <dc:identifier>doi:10.1109/TCSVT.2018.2885211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.04407</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Sparse Representations with Gradient Penalties</dc:title>
 <dc:creator>Wohlberg, Brendt</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  While convolutional sparse representations enjoy a number of useful
properties, they have received limited attention for image reconstruction
problems. The present paper compares the performance of block-based and
convolutional sparse representations in the removal of Gaussian white noise.
While the usual formulation of the convolutional sparse coding problem is
slightly inferior to the block-based representations in this problem, the
performance of the convolutional form can be boosted beyond that of the
block-based form by the inclusion of suitable penalties on the gradients of the
coefficient maps.
</dc:description>
 <dc:date>2017-05-11</dc:date>
 <dc:date>2018-02-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.04407</dc:identifier>
 <dc:identifier>doi:10.1109/ICASSP.2018.8462151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.06145</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-paced Convolutional Neural Network for Computer Aided Detection in
  Medical Imaging Analysis</dc:title>
 <dc:creator>Li, Xiang</dc:creator>
 <dc:creator>Zhong, Aoxiao</dc:creator>
 <dc:creator>Lin, Ming</dc:creator>
 <dc:creator>Guo, Ning</dc:creator>
 <dc:creator>Sun, Mu</dc:creator>
 <dc:creator>Sitek, Arkadiusz</dc:creator>
 <dc:creator>Ye, Jieping</dc:creator>
 <dc:creator>Thrall, James</dc:creator>
 <dc:creator>Li, Quanzheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Tissue characterization has long been an important component of Computer
Aided Diagnosis (CAD) systems for automatic lesion detection and further
clinical planning. Motivated by the superior performance of deep learning
methods on various computer vision problems, there has been increasing work
applying deep learning to medical image analysis. However, the development of a
robust and reliable deep learning model for computer-aided diagnosis is still
highly challenging due to the combination of the high heterogeneity in the
medical images and the relative lack of training samples. Specifically,
annotation and labeling of the medical images is much more expensive and
time-consuming than other applications and often involves manual labor from
multiple domain experts. In this work, we propose a multi-stage, self-paced
learning framework utilizing a convolutional neural network (CNN) to classify
Computed Tomography (CT) image patches. The key contribution of this approach
is that we augment the size of training samples by refining the unlabeled
instances with a self-paced learning CNN. By implementing the framework on high
performance computing servers including the NVIDIA DGX1 machine, we obtained
the experimental result, showing that the self-pace boosted network
consistently outperformed the original network even with very scarce manual
labels. The performance gain indicates that applications with limited training
samples such as medical image analysis can benefit from using the proposed
framework.
</dc:description>
 <dc:description>Comment: accepted by 8th International Workshop on Machine Learning in Medical
  Imaging (MLMI 2017)</dc:description>
 <dc:date>2017-07-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.06145</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-67389-9_25</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08114</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Multi-Task Learning</dc:title>
 <dc:creator>Zhang, Yu</dc:creator>
 <dc:creator>Yang, Qiang</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Multi-Task Learning (MTL) is a learning paradigm in machine learning and its
aim is to leverage useful information contained in multiple related tasks to
help improve the generalization performance of all the tasks. In this paper, we
give a survey for MTL from the perspective of algorithmic modeling,
applications and theoretical analyses. For algorithmic modeling, we give a
definition of MTL and then classify different MTL algorithms into five
categories, including feature learning approach, low-rank approach, task
clustering approach, task relation learning approach and decomposition approach
as well as discussing the characteristics of each approach. In order to improve
the performance of learning tasks further, MTL can be combined with other
learning paradigms including semi-supervised learning, active learning,
unsupervised learning, reinforcement learning, multi-view learning and
graphical models. When the number of tasks is large or the data dimensionality
is high, we review online, parallel and distributed MTL models as well as
dimensionality reduction and feature hashing to reveal their computational and
storage advantages. Many real-world applications use MTL to boost their
performance and we review representative works in this paper. Finally, we
present theoretical analyses and discuss several future directions for MTL.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Transactions on Knowledge and Data Engineering</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08192</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rook theory of the finite general linear group</dc:title>
 <dc:creator>Lewis, Joel Brewster</dc:creator>
 <dc:creator>Morales, Alejandro H.</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:description>  Matrices over a finite field having fixed rank and restricted support are a
natural $q$-analogue of rook placements on a board. We develop this $q$-rook
theory by defining a corresponding analogue of the hit numbers. Using tools
from coding theory, we show that these $q$-hit and $q$-rook numbers obey a
variety of identities analogous to the classical case. We also explore
connections to earlier $q$-analogues of rook theory, as well as settling a
polynomiality conjecture and finding a counterexample of a positivity
conjecture of the authors and Klein.
</dc:description>
 <dc:description>Comment: 25 pages, 10 figure files. Minor change in definition of q-hit
  numbers changes notation but doesn't substantively affect results</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08192</dc:identifier>
 <dc:identifier>Experimental Mathematics 29:3 (2020), 328-346</dc:identifier>
 <dc:identifier>doi:10.1080/10586458.2018.1470045</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08834</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Arithmetic Circuits for Multilevel Qudits Based on Quantum Fourier
  Transform</dc:title>
 <dc:creator>Pavlidis, Archimedes</dc:creator>
 <dc:creator>Floratos, Emmanuel</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  We present some basic integer arithmetic quantum circuits, such as adders and
multipliers-accumulators of various forms, as well as diagonal operators, which
operate on multilevel qudits. The integers to be processed are represented in
an alternative basis after they have been Fourier transformed. Several
arithmetic circuits operating on Fourier transformed integers have appeared in
the literature for two level qubits. Here we extend these techniques on
multilevel qudits, as they may offer some advantages relative to qubits
implementations. The arithmetic circuits presented can be used as basic
building blocks for higher level algorithms such as quantum phase estimation,
quantum simulation, quantum optimization etc., but they can also be used in the
implementation of a quantum fractional Fourier transform as it is shown in a
companion work presented separately.
</dc:description>
 <dc:description>Comment: 34 pages, 18 figures</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08834</dc:identifier>
 <dc:identifier>Phys. Rev. A 103, 032417 (2021)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevA.103.032417</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09775</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity limitations of visual search in deep convolutional neural
  networks</dc:title>
 <dc:creator>Poder, Endel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Deep convolutional neural networks follow roughly the architecture of
biological visual systems and have shown a performance comparable to human
observers in object recognition tasks. In this study, I tested three pretrained
deep neural networks in visual search for simple visual features, and for
feature configurations. The results reveal a qualitative difference from human
performance. It appears that there is no clear difference between searches for
simple features that pop out in experiments with humans, and for feature
configurations that exhibit strict capacity limitations in human vision. Both
types of stimuli reveal comparable capacity limitations in the neural networks
tested here.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09775</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.02415</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Power System Simulation Using the Adomian Decomposition
  Method</dc:title>
 <dc:creator>Duan, Nan</dc:creator>
 <dc:creator>Sun, Kai</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Considering increasing distributed energy resources and responsive loads in
smart grid, this paper proposes a stochastic simulation approach for stability
analysis of a power system having stochastic loads. The proposed approach
solves a stochastic, nonlinear differential equation model of the system in an
analytical way by the Adomian decomposition method and generates
semi-analytical solutions that express both deterministic and stochastic state
variables explicitly as symbolic variables so as to embed stochastic processes
directly into the solutions for efficient stability analysis with
uncertainties. The proposed approach is tested on the New England 10-machine
39-bus system with different penetration levels of stochastic loads. The
approach is also benchmarked with a traditional stochastic simulation approach
based on the Euler-Maruyama method. The results show that the new approach has
better time performance and a comparable accuracy.
</dc:description>
 <dc:date>2017-10-06</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.02415</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1710.04726</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RAWSim-O: A Simulation Framework for Robotic Mobile Fulfillment Systems</dc:title>
 <dc:creator>Merschformann, Marius</dc:creator>
 <dc:creator>Xie, Lin</dc:creator>
 <dc:creator>Li, Hanyi</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper deals with a new type of warehousing system, Robotic Mobile
Fulfillment Systems (RMFS). In such systems, robots are sent to carry storage
units, so-called &quot;pods&quot;, from the inventory and bring them to human operators
working at stations. At the stations, the items are picked according to
customers' orders. There exist new decision problems in such systems, for
example, the reallocation of pods after their visits at work stations or the
selection of pods to fulfill orders. In order to analyze decision strategies
for these decision problems and relations between them, we develop a simulation
framework called &quot;RAWSim-O&quot; in this paper. Moreover, we show a real-world
application of our simulation framework by integrating simple robot prototypes
based on vacuum cleaning robots.
</dc:description>
 <dc:date>2017-10-12</dc:date>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1710.04726</dc:identifier>
 <dc:identifier>doi:10.23773/2018_8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1712.03586</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fairness in Machine Learning: Lessons from Political Philosophy</dc:title>
 <dc:creator>Binns, Reuben</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  What does it mean for a machine learning model to be `fair', in terms which
can be operationalised? Should fairness consist of ensuring everyone has an
equal probability of obtaining some benefit, or should we aim instead to
minimise the harms to the least advantaged? Can the relevant ideal be
determined by reference to some alternative state of affairs in which a
particular social pattern of discrimination does not exist? Various definitions
proposed in recent literature make different assumptions about what terms like
discrimination and fairness mean and how they can be defined in mathematical
terms. Questions of discrimination, egalitarianism and justice are of
significant interest to moral and political philosophers, who have expended
significant efforts in formalising and defending these central concepts. It is
therefore unsurprising that attempts to formalise `fairness' in machine
learning contain echoes of these old philosophical debates. This paper draws on
existing work in moral and political philosophy in order to elucidate emerging
debates about fair machine learning.
</dc:description>
 <dc:date>2017-12-10</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1712.03586</dc:identifier>
 <dc:identifier>Proceedings of Machine Learning Research 81:149-159, 2018
  Conference on Fairness, Accountability, and Transparency</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.04105</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active repositioning of storage units in Robotic Mobile Fulfillment
  Systems</dc:title>
 <dc:creator>Merschformann, Marius</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  In our work we focus on Robotic Mobile Fulfillment Systems in e-commerce
distribution centers. These systems were designed to increase pick rates by
employing mobile robots bringing movable storage units (so-called pods) to pick
and replenishment stations as needed, and back to the storage area afterwards.
One advantage of this approach is that repositioning of inventory can be done
continuously, even during pick and replenishment operations. This is primarily
accomplished by bringing a pod to a storage location different than the one it
was fetched from, a process we call passive pod repositioning. Additionally,
this can be done by explicitly bringing a pod from one storage location to
another, a process we call active pod repositioning. In this work we introduce
first mechanisms for the latter technique and conduct a simulation-based
experiment to give first insights of their effect.
</dc:description>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.04105</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-89920-6_51</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1801.06703</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decision Rules for Robotic Mobile Fulfillment Systems</dc:title>
 <dc:creator>Merschformann, Marius</dc:creator>
 <dc:creator>Lamballais, Tim</dc:creator>
 <dc:creator>de Koster, Ren&#xe9;</dc:creator>
 <dc:creator>Suhl, Leena</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  The Robotic Mobile Fulfillment Systems (RMFS) is a new type of robotized,
parts-to-picker material handling system, designed especially for e-commerce
warehouses. Robots bring movable shelves, called pods, to workstations where
inventory is put on or removed from the pods. This paper simulates both the
pick and replenishment process and studies the order assignment, pod selection
and pod storage assignment problems by evaluating multiple decision rules per
problem. The discrete event simulation uses realistic robot movements and keeps
track of every unit of inventory on every pod. We analyze seven performance
measures, e.g. throughput capacity and order due time, and find that the unit
throughput is strongly correlated with the other performance measures. We vary
the number of robots, the number of pick stations, the number of SKUs (stock
keeping units), the order size and whether returns need processing or not. The
decision rules for pick order assignment have a strong impact on the unit
throughput rate. This is not the case for replenishment order assignment, pod
selection and pod storage. Furthermore, for warehouses with a large number of
SKUs, more robots are needed for a high unit throughput rate, even if the
number of pods and the dimensions of the storage area remain the same. Lastly,
processing return orders only affects the unit throughput rate for warehouse
with a large number of SKUs and large pick orders.
</dc:description>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1801.06703</dc:identifier>
 <dc:identifier>doi:10.1016/j.orp.2019.100128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.03713</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>$\mathcal{G}$-SGD: Optimizing ReLU Neural Networks in its Positively
  Scale-Invariant Space</dc:title>
 <dc:creator>Meng, Qi</dc:creator>
 <dc:creator>Zheng, Shuxin</dc:creator>
 <dc:creator>Zhang, Huishuai</dc:creator>
 <dc:creator>Chen, Wei</dc:creator>
 <dc:creator>Ma, Zhi-Ming</dc:creator>
 <dc:creator>Liu, Tie-Yan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  It is well known that neural networks with rectified linear units (ReLU)
activation functions are positively scale-invariant. Conventional algorithms
like stochastic gradient descent optimize the neural networks in the vector
space of weights, which is, however, not positively scale-invariant. This
mismatch may lead to problems during the optimization process. Then, a natural
question is: \emph{can we construct a new vector space that is positively
scale-invariant and sufficient to represent ReLU neural networks so as to
better facilitate the optimization process }? In this paper, we provide our
positive answer to this question. First, we conduct a formal study on the
positive scaling operators which forms a transformation group, denoted as
$\mathcal{G}$. We show that the value of a path (i.e. the product of the
weights along the path) in the neural network is invariant to positive scaling
and prove that the value vector of all the paths is sufficient to represent the
neural networks under mild conditions. Second, we show that one can identify
some basis paths out of all the paths and prove that the linear span of their
value vectors (denoted as $\mathcal{G}$-space) is an invariant space with lower
dimension under the positive scaling group. Finally, we design stochastic
gradient descent algorithm in $\mathcal{G}$-space (abbreviated as
$\mathcal{G}$-SGD) to optimize the value vector of the basis paths of neural
networks with little extra cost by leveraging back-propagation. Our experiments
show that $\mathcal{G}$-SGD significantly outperforms the conventional SGD
algorithm in optimizing ReLU networks on benchmark datasets.
</dc:description>
 <dc:date>2018-02-11</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1802.03713</dc:identifier>
 <dc:identifier>ICLR2019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1802.05995</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing generalized kernels of polygons</dc:title>
 <dc:creator>Martinez-Moraian, Alejandra</dc:creator>
 <dc:creator>Orden, David</dc:creator>
 <dc:creator>Palios, Leonidas</dc:creator>
 <dc:creator>Seara, Carlos</dc:creator>
 <dc:creator>&#x17b;yli&#x144;ski, Pawe&#x142;</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Let $\mathcal{O}$ be a set of $k$ orientations in the plane, and let $P$ be a
simple polygon in the plane. Given two points $p,q$ inside $P$, we say that $p$
$\mathcal{O}$-\emph{sees} $q$ if there is an $\mathcal{O}$-\emph{staircase}
contained in $P$ that connects $p$ and $q$. The $\mathcal{O}$-${\rm Kernel }$
of the polygon $P$, denoted by $\mathcal{O}$-${\rm Kernel }(P)$, is the subset
of points which $\mathcal{O}$-see all the other points in $P$. This work
initiates the study of the computation and maintenance of $\mathcal{O}$-${\rm
Kernel }(P)$ as we rotate the set $\mathcal{O}$ by an angle $\theta$, denoted
$\mathcal{O}$-${\rm Kernel }_{\theta}(P)$. In particular, we consider the case
when the set $\mathcal{O}$ is formed by either one or two orthogonal
orientations, $\mathcal{O}=\{0^\circ\}$ or $\mathcal{O}=\{0^\circ,90^\circ\}$.
For these cases and $P$ being a simple polygon, we design efficient algorithms
for computing and maintaining the $\mathcal{O}$-${\rm Kernel }_{\theta}(P)$
while $\theta$ varies in $[-\frac{\pi}{2},\frac{\pi}{2})$, obtaining the
angular intervals where: (i) $\mathcal{O}$-${\rm Kernel }_{\theta}(P)$ is not
empty, (ii) $\mathcal{O}$-${\rm Kernel }_{\theta}(P)$ optimizes area or
perimeter. Further, we show how the algorithms can be improved when $P$ is a
simple orthogonal polygon.
</dc:description>
 <dc:description>Comment: 26 pages, 18 figures, version submitted to Journal of Global
  Optimization (the accepted version including minor changes)</dc:description>
 <dc:date>2018-02-16</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1802.05995</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1804.10969</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>UNIQ: Uniform Noise Injection for Non-Uniform Quantization of Neural
  Networks</dc:title>
 <dc:creator>Baskin, Chaim</dc:creator>
 <dc:creator>Schwartz, Eli</dc:creator>
 <dc:creator>Zheltonozhskii, Evgenii</dc:creator>
 <dc:creator>Liss, Natan</dc:creator>
 <dc:creator>Giryes, Raja</dc:creator>
 <dc:creator>Bronstein, Alex M.</dc:creator>
 <dc:creator>Mendelson, Avi</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present a novel method for neural network quantization that emulates a
non-uniform $k$-quantile quantizer, which adapts to the distribution of the
quantized parameters. Our approach provides a novel alternative to the existing
uniform quantization techniques for neural networks. We suggest to compare the
results as a function of the bit-operations (BOPS) performed, assuming a
look-up table availability for the non-uniform case. In this setup, we show the
advantages of our strategy in the low computational budget regime. While the
proposed solution is harder to implement in hardware, we believe it sets a
basis for new alternatives to neural networks quantization.
</dc:description>
 <dc:date>2018-04-29</dc:date>
 <dc:date>2018-10-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1804.10969</dc:identifier>
 <dc:identifier>doi:10.1145/3444943</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.01041</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Updated Experimental Evaluation of Graph Bipartization Methods</dc:title>
 <dc:creator>Goodrich, Timothy D.</dc:creator>
 <dc:creator>Horton, Eric</dc:creator>
 <dc:creator>Sullivan, Blair D.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>G.2.3</dc:subject>
 <dc:description>  We experimentally evaluate the practical state-of-the-art in graph
bipartization (Odd Cycle Transversal), motivated by recent advances in
near-term quantum computing hardware and the related embedding problems. We
assemble a preprocessing suite of fast input reduction routines from the Odd
Cycle Transversal (OCT) and Vertex Cover (VC) literature, and compare algorithm
implementations using Quadratic Unconstrained Binary Optimization problems from
the quantum literature. We also generate a corpus of frustrated cluster loop
graphs, which have previously been used to benchmark quantum annealing
hardware. The diversity of these graphs leads to harder OCT instances than in
existing benchmarks.
  In addition to combinatorial branching algorithms for solving OCT directly,
we study various reformulations into other NP-hard problems such as VC and
Integer Linear Programming (ILP), enabling the use of solvers such as CPLEX. We
find that for heuristic solutions with time constraints under a second,
iterative compression routines jump-started with a heuristic solution perform
best, after which point using a highly tuned solver like CPLEX is worthwhile.
Results on exact solvers are split between using ILP formulations on CPLEX and
solving VC formulations with a branch-and-reduce solver. We extend our results
with a large corpus of synthetic graphs, establishing robustness and potential
to generalize to other domain data. In total, over 8000 graph instances are
evaluated, compared to the previous canonical corpus of 100 graphs.
  Finally, we provide all code and data in an open source suite, including a
Python API for accessing reduction routines and branching algorithms, along
with scripts for fully replicating our results.
</dc:description>
 <dc:description>Comment: Revised paper with with frustrated cluster loops</dc:description>
 <dc:date>2018-05-02</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1805.01041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.03235</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Systematic Approach to Incremental Redundancy over Erasure Channels</dc:title>
 <dc:creator>Heidarzadeh, Anoosheh</dc:creator>
 <dc:creator>Chamberland, Jean-Francois</dc:creator>
 <dc:creator>Parag, Parimal</dc:creator>
 <dc:creator>Wesel, Richard D.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  As sensing and instrumentation play an increasingly important role in systems
controlled over wired and wireless networks, the need to better understand
delay-sensitive communication becomes a prime issue. Along these lines, this
article studies the operation of data links that employ incremental redundancy
as a practical means to protect information from the effects of unreliable
channels. Specifically, this work extends a powerful methodology termed
sequential differential optimization to choose near-optimal block sizes for
hybrid ARQ over erasure channels. In doing so, an interesting connection
between random coding and well-known constants in number theory is established.
Furthermore, results show that the impact of the coding strategy adopted and
the propensity of the channel to erase symbols naturally decouple when
analyzing throughput. Overall, block size selection is motivated by normal
approximations on the probability of decoding success at every stage of the
incremental transmission process. This novel perspective, which rigorously
bridges hybrid ARQ and coding, offers a pragmatic means to select code rates
and blocklengths for incremental redundancy.
</dc:description>
 <dc:description>Comment: 7 pages, 2 figures; A shorter version of this article will appear in
  the proceedings of ISIT 2018</dc:description>
 <dc:date>2018-05-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1805.03235</dc:identifier>
 <dc:identifier>IEEE International Symposium on Information Theory (ISIT), Vail,
  CO, USA, 2018, pp. 1176-1180</dc:identifier>
 <dc:identifier>doi:10.1109/ISIT.2018.8437808</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.04488</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Standard Triples for Algebraic Linearizations of Matrix
  Polynomials</dc:title>
 <dc:creator>Chan, Eunice Y. S.</dc:creator>
 <dc:creator>Corless, Robert M.</dc:creator>
 <dc:creator>Sevyeri, Leili Rafiee</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65F15, 15A22, 65D05</dc:subject>
 <dc:description>  We define \emph{generalized standard triples} $\mathbf{X}$, $\mathbf{Y}$, and
$L(z) = z\mathbf{C}_{1} - \mathbf{C}_{0}$, where $L(z)$ is a linearization of a
regular matrix polynomial $\mathbf{P}(z) \in \mathbb{C}^{n \times n}[z]$, in
order to use the representation $\mathbf{X}(z
\mathbf{C}_{1}~-~\mathbf{C}_{0})^{-1}\mathbf{Y}~=~\mathbf{P}^{-1}(z)$ which
holds except when $z$ is an eigenvalue of $\mathbf{P}$. This representation can
be used in constructing so-called \emph{algebraic linearizations} for matrix
polynomials of the form $\mathbf{H}(z) = z \mathbf{A}(z)\mathbf{B}(z) +
\mathbf{C} \in \mathbb{C}^{n \times n}[z]$ from generalized standard triples of
$\mathbf{A}(z)$ and $\mathbf{B}(z)$. This can be done even if $\mathbf{A}(z)$
and $\mathbf{B}(z)$ are expressed in differing polynomial bases. Our main
theorem is that $\mathbf{X}$ can be expressed using the coefficients of the
expression $1 = \sum_{k=0}^\ell e_k \phi_k(z)$ in terms of the relevant
polynomial basis. For convenience, we tabulate generalized standard triples for
orthogonal polynomial bases, the monomial basis, and Newton interpolational
bases; for the Bernstein basis; for Lagrange interpolational bases; and for
Hermite interpolational bases. We account for the possibility of common
similarity transformations.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2018-05-11</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1805.04488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.05750</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Private Are Commonly-Used Voting Rules?</dc:title>
 <dc:creator>Liu, Ao</dc:creator>
 <dc:creator>Lu, Yun</dc:creator>
 <dc:creator>Xia, Lirong</dc:creator>
 <dc:creator>Zikas, Vassilis</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Differential privacy has been widely applied to provide privacy guarantees by
adding random noise to the function output. However, it inevitably fails in
many high-stakes voting scenarios, where voting rules are required to be
deterministic. In this work, we present the first framework for answering the
question: &quot;How private are commonly-used voting rules?&quot; Our answers are
two-fold. First, we show that deterministic voting rules provide sufficient
privacy in the sense of distributional differential privacy (DDP). We show that
assuming the adversarial observer has uncertainty about individual votes, even
publishing the histogram of votes achieves good DDP. Second, we introduce the
notion of exact privacy to compare the privacy preserved in various
commonly-studied voting rules, and obtain dichotomy theorems of exact DDP
within a large subset of voting rules called generalized scoring rules.
</dc:description>
 <dc:date>2018-05-15</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1805.05750</dc:identifier>
 <dc:identifier>Proceedings of the 36th Conference on Uncertainty in Artificial
  Intelligence (UAI), in Proceedings of Machine Learning Research 124:629-638
  (2020)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.08154</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Numeracy for Language Models: Evaluating and Improving their Ability to
  Predict Numbers</dc:title>
 <dc:creator>Spithourakis, Georgios P.</dc:creator>
 <dc:creator>Riedel, Sebastian</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Numeracy is the ability to understand and work with numbers. It is a
necessary skill for composing and understanding documents in clinical,
scientific, and other technical domains. In this paper, we explore different
strategies for modelling numerals with language models, such as memorisation
and digit-by-digit composition, and propose a novel neural architecture that
uses a continuous probability density function to model numerals from an open
vocabulary. Our evaluation on clinical and scientific datasets shows that using
hierarchical models to distinguish numerals from words improves a perplexity
metric on the subset of numerals by 2 and 4 orders of magnitude, respectively,
over non-hierarchical models. A combination of strategies can further improve
perplexity. Our continuous probability density function model reduces mean
absolute percentage errors by 18% and 54% in comparison to the second best
strategy for each dataset, respectively.
</dc:description>
 <dc:description>Comment: accepted at ACL 2018</dc:description>
 <dc:date>2018-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1805.08154</dc:identifier>
 <dc:identifier>doi:10.18653/v1/P18-1196</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1805.12564</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling 4D fMRI Data via Spatio-Temporal Convolutional Neural Networks
  (ST-CNN)</dc:title>
 <dc:creator>Zhao, Yu</dc:creator>
 <dc:creator>Li, Xiang</dc:creator>
 <dc:creator>Zhang, Wei</dc:creator>
 <dc:creator>Zhao, Shijie</dc:creator>
 <dc:creator>Makkie, Milad</dc:creator>
 <dc:creator>Zhang, Mo</dc:creator>
 <dc:creator>Li, Quanzheng</dc:creator>
 <dc:creator>Liu, Tianming</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Simultaneous modeling of the spatio-temporal variation patterns of brain
functional network from 4D fMRI data has been an important yet challenging
problem for the field of cognitive neuroscience and medical image analysis.
Inspired by the recent success in applying deep learning for functional brain
decoding and encoding, in this work we propose a spatio-temporal convolutional
neural network (ST-CNN)to jointly learn the spatial and temporal patterns of
targeted network from the training data and perform automatic, pin-pointing
functional network identification. The proposed ST-CNN is evaluated by the task
of identifying the Default Mode Network (DMN) from fMRI data. Results show that
while the framework is only trained on one fMRI dataset,it has the sufficient
generalizability to identify the DMN from different populations of data as well
as different cognitive tasks. Further investigation into the results show that
the superior performance of ST-CNN is driven by the jointly-learning scheme,
which capture the intrinsic relationship between the spatial and temporal
characteristic of DMN and ensures the accurate identification.
</dc:description>
 <dc:description>Comment: Yu Zhao and Xiang Li contribute equally to this work</dc:description>
 <dc:date>2018-05-31</dc:date>
 <dc:date>2018-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1805.12564</dc:identifier>
 <dc:identifier>doi:10.1109/TCDS.2019.2916916</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1806.01483</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>JTAV: Jointly Learning Social Media Content Representation by Fusing
  Textual, Acoustic, and Visual Features</dc:title>
 <dc:creator>Liang, Hongru</dc:creator>
 <dc:creator>Wang, Haozheng</dc:creator>
 <dc:creator>Wang, Jun</dc:creator>
 <dc:creator>You, Shaodi</dc:creator>
 <dc:creator>Sun, Zhe</dc:creator>
 <dc:creator>Wei, Jin-Mao</dc:creator>
 <dc:creator>Yang, Zhenglu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Learning social media content is the basis of many real-world applications,
including information retrieval and recommendation systems, among others. In
contrast with previous works that focus mainly on single modal or bi-modal
learning, we propose to learn social media content by fusing jointly textual,
acoustic, and visual information (JTAV). Effective strategies are proposed to
extract fine-grained features of each modality, that is, attBiGRU and DCRNN. We
also introduce cross-modal fusion and attentive pooling techniques to integrate
multi-modal information comprehensively. Extensive experimental evaluation
conducted on real-world datasets demonstrates our proposed model outperforms
the state-of-the-art approaches by a large margin.
</dc:description>
 <dc:date>2018-06-04</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1806.01483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.06649</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Remote Sampling with Applications to General Entanglement Simulation</dc:title>
 <dc:creator>Brassard, Gilles</dc:creator>
 <dc:creator>Devroye, Luc</dc:creator>
 <dc:creator>Gravel, Claude</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We show how to sample exactly discrete probability distributions whose
defining parameters are distributed among remote parties. For this purpose, von
Neumann's rejection algorithm is turned into a distributed sampling
communication protocol. We study the expected number of bits communicated among
the parties and also exhibit a trade-off between the number of rounds of the
rejection algorithm and the number of bits transmitted in the initial phase.
Finally, we apply remote sampling to the simulation of quantum entanglement in
its most general form possible, when an arbitrary number of parties share
systems of arbitrary dimensions on which they apply arbitrary measurements (not
restricted to being projective measurements). In case the dimension of the
systems and the number of possible outcomes per party is bounded by a constant,
it suffices to communicate an expected O(m^2) bits in order to simulate exactly
the outcomes that these measurements would have produced on those systems,
where m is the number of participants.
</dc:description>
 <dc:description>Comment: 17 pages, 1 figure, 4 algorithms (protocols); Complete generalization
  of previous paper arXiv:1303.5942 [cs.IT] -- Exact simulation of the GHZ
  distribution -- by the same authors</dc:description>
 <dc:date>2018-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1807.06649</dc:identifier>
 <dc:identifier>Entropy 21(1):92, 2019</dc:identifier>
 <dc:identifier>doi:10.3390/e21010092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1807.09077</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optional Stopping with Bayes Factors: a categorization and extension of
  folklore results, with an application to invariant situations</dc:title>
 <dc:creator>Hendriksen, Allard</dc:creator>
 <dc:creator>de Heide, Rianne</dc:creator>
 <dc:creator>Gr&#xfc;nwald, Peter</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  It is often claimed that Bayesian methods, in particular Bayes factor methods
for hypothesis testing, can deal with optional stopping. We first give an
overview, using elementary probability theory, of three different mathematical
meanings that various authors give to this claim: (1) stopping rule
independence, (2) posterior calibration and (3) (semi-) frequentist robustness
to optional stopping. We then prove theorems to the effect that these claims do
indeed hold in a general measure-theoretic setting. For claims of type (2) and
(3), such results are new. By allowing for non-integrable measures based on
improper priors, we obtain particularly strong results for the practically
important case of models with nuisance parameters satisfying a group invariance
(such as location or scale). We also discuss the practical relevance of
(1)--(3), and conclude that whether Bayes factor methods actually perform well
under optional stopping crucially depends on details of models, priors and the
goal of the analysis.
</dc:description>
 <dc:description>Comment: 29 pages</dc:description>
 <dc:date>2018-07-24</dc:date>
 <dc:date>2020-04-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1807.09077</dc:identifier>
 <dc:identifier>doi:10.1214/20-BA1234</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.00079</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Gradient Checkpoint Search for Arbitrary Computation Graphs</dc:title>
 <dc:creator>Feng, Jianwei</dc:creator>
 <dc:creator>Huang, Dong</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep Neural Networks(DNNs) require huge GPU memory when training on modern
image/video databases. Unfortunately, the GPU memory is physically finite,
which limits the image resolutions and batch sizes that could be used in
training for better DNN performance. Unlike solutions that require physically
upgrade GPUs, the Gradient CheckPointing(GCP) training trades computation for
more memory beyond existing GPU hardware. GCP only stores a subset of
intermediate tensors, called Gradient Checkpoints (GCs), during forward. Then
during backward, extra local forwards are conducted to compute the missing
tensors. The total training memory cost becomes the sum of (1) the memory cost
of the gradient checkpoints and (2) the maximum memory cost of local forwards.
To achieve maximal memory cut-offs, one needs optimal algorithms to select GCs.
Existing GCP approaches rely on either manual input of GCs or heuristics-based
GC search on Linear Computation Graphs (LCGs), and cannot apply to Arbitrary
Computation Graphs(ACGs). In this paper, we present theories and optimal
algorithms on GC selection that, for the first time, are applicable to ACGs and
achieve the maximal memory cut-offs. Extensive experiments show that our
approach not only outperforms existing approaches (only applicable on LCGs),
and is applicable to a vast family of LCG and ACG networks, such as Alexnet,
VGG, ResNet, Densenet, Inception Net and highly complicated DNNs by Network
Architecture Search. Our work enables GCP training on ACGs, and cuts off up-to
80% of training memory with a moderate time overhead (~30%-50%). Codes are
available
</dc:description>
 <dc:date>2018-07-31</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1808.00079</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02056</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Estimator Full Left Ventricle Quantification through Ensemble
  Learning</dc:title>
 <dc:creator>Liu, Jiasha</dc:creator>
 <dc:creator>Li, Xiang</dc:creator>
 <dc:creator>Ren, Hui</dc:creator>
 <dc:creator>Li, Quanzheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Cardiovascular disease accounts for 1 in every 4 deaths in United States.
Accurate estimation of structural and functional cardiac parameters is crucial
for both diagnosis and disease management. In this work, we develop an ensemble
learning framework for more accurate and robust left ventricle (LV)
quantification. The framework combines two 1st-level modules: direct estimation
module and a segmentation module. The direct estimation module utilizes
Convolutional Neural Network (CNN) to achieve end-to-end quantification. The
CNN is trained by taking 2D cardiac images as input and cardiac parameters as
output. The segmentation module utilizes a U-Net architecture for obtaining
pixel-wise prediction of the epicardium and endocardium of LV from the
background. The binary U-Net output is then analyzed by a separate CNN for
estimating the cardiac parameters. We then employ linear regression between the
1st-level predictor and ground truth to learn a 2nd-level predictor that
ensembles the results from 1st-level modules for the final estimation.
Preliminary results by testing the proposed framework on the LVQuan18 dataset
show superior performance of the ensemble learning model over the two base
modules.
</dc:description>
 <dc:description>Comment: Jiasha Liu, Xiang Li and Hui Ren contribute equally to this work</dc:description>
 <dc:date>2018-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1808.02056</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-030-12029-0_49</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.02346</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the integrality gap of the maximum-cut semidefinite programming
  relaxation in fixed dimension</dc:title>
 <dc:creator>Filho, Fernando M&#xe1;rio de Oliveira</dc:creator>
 <dc:creator>Vallentin, Frank</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>46N10, 68W25, 90C22</dc:subject>
 <dc:description>  We describe a factor-revealing convex optimization problem for the
integrality gap of the maximum-cut semidefinite programming relaxation: for
each $n \geq 2$ we present a convex optimization problem whose optimal value is
the largest possible ratio between the value of an optimal rank-$n$ solution to
the relaxation and the value of an optimal cut. This problem is then used to
compute lower bounds for the integrality gap.
</dc:description>
 <dc:description>Comment: 17 pages, 2 figures</dc:description>
 <dc:date>2018-08-07</dc:date>
 <dc:date>2020-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1808.02346</dc:identifier>
 <dc:identifier>Discrete Analysis, 2020:10</dc:identifier>
 <dc:identifier>doi:10.19086/da.14164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1808.07826</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fungi: Typed incremental computation with names</dc:title>
 <dc:creator>Hammer, Matthew A.</dc:creator>
 <dc:creator>Dunfield, Jana</dc:creator>
 <dc:creator>Headley, Kyle</dc:creator>
 <dc:creator>Narasimhamurthy, Monal</dc:creator>
 <dc:creator>Economou, Dimitrios J.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Incremental computations attempt to exploit input similarities over time,
reusing work that is unaffected by input changes. To maximize this reuse in a
general-purpose programming setting, programmers need a mechanism to identify
dynamic allocations (of data and subcomputations) that correspond over time. We
present Fungi, a typed functional language for incremental computation with
names. Unlike prior general-purpose languages for incremental computing,
Fungi's notion of names is formal, general, and statically verifiable. Fungi's
type-and-effect system permits the programmer to encode (program-specific)
local invariants about names, and to use these invariants to establish global
uniqueness for their composed programs, the property of using names correctly.
We prove that well-typed Fungi programs respect global uniqueness. We derive a
bidirectional version of the type and effect system, and we have implemented a
prototype of Fungi in Rust. We apply Fungi to a library of incremental
collections, showing that it is expressive in practice.
</dc:description>
 <dc:date>2018-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1808.07826</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1809.01701</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pack and Detect: Fast Object Detection in Videos Using
  Region-of-Interest Packing</dc:title>
 <dc:creator>Kumar, Athindran Ramesh</dc:creator>
 <dc:creator>Ravindran, Balaraman</dc:creator>
 <dc:creator>Raghunathan, Anand</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Object detection in videos is an important task in computer vision for
various applications such as object tracking, video summarization and video
search. Although great progress has been made in improving the accuracy of
object detection in recent years due to the rise of deep neural networks, the
state-of-the-art algorithms are highly computationally intensive. In order to
address this challenge, we make two important observations in the context of
videos: (i) Objects often occupy only a small fraction of the area in each
video frame, and (ii) There is a high likelihood of strong temporal correlation
between consecutive frames. Based on these observations, we propose Pack and
Detect (PaD), an approach to reduce the computational requirements of object
detection in videos. In PaD, only selected video frames called anchor frames
are processed at full size. In the frames that lie between anchor frames
(inter-anchor frames), regions of interest (ROIs) are identified based on the
detections in the previous frame. We propose an algorithm to pack the ROIs of
each inter-anchor frame together into a reduced-size frame. The computational
requirements of the detector are reduced due to the lower size of the input. In
order to maintain the accuracy of object detection, the proposed algorithm
expands the ROIs greedily to provide additional background around each object
to the detector. PaD can use any underlying neural network architecture to
process the full-size and reduced-size frames. Experiments using the ImageNet
video object detection dataset indicate that PaD can potentially reduce the
number of FLOPS required for a frame by $4\times$. This leads to an overall
increase in throughput of $1.25\times$ on a 2.1 GHz Intel Xeon server with a
NVIDIA Titan X GPU at the cost of $1.1\%$ drop in accuracy.
</dc:description>
 <dc:description>Comment: Proceedings of the ACM India Joint International Conference on Data
  Science and Management of Data. 2019</dc:description>
 <dc:date>2018-09-05</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1809.01701</dc:identifier>
 <dc:identifier>doi:10.1145/3297001.3297020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1809.04693</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Online Plug-and-Play Algorithm for Regularized Image Reconstruction</dc:title>
 <dc:creator>Sun, Yu</dc:creator>
 <dc:creator>Wohlberg, Brendt</dc:creator>
 <dc:creator>Kamilov, Ulugbek S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Plug-and-play priors (PnP) is a powerful framework for regularizing imaging
inverse problems by using advanced denoisers within an iterative algorithm.
Recent experimental evidence suggests that PnP algorithms achieve
state-of-the-art performance in a range of imaging applications. In this paper,
we introduce a new online PnP algorithm based on the iterative
shrinkage/thresholding algorithm (ISTA). The proposed algorithm uses only a
subset of measurements at every iteration, which makes it scalable to very
large datasets. We present a new theoretical convergence analysis, for both
batch and online variants of PnP-ISTA, for denoisers that do not necessarily
correspond to proximal operators. We also present simulations illustrating the
applicability of the algorithm to image reconstruction in diffraction
tomography. The results in this paper have the potential to expand the
applicability of the PnP framework to very large and redundant datasets.
</dc:description>
 <dc:date>2018-09-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1809.04693</dc:identifier>
 <dc:identifier>doi:10.1109/TCI.2019.2893568</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1809.07221</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring the Impact of Password Dataset Distribution on Guessing</dc:title>
 <dc:creator>Murray, Hazel</dc:creator>
 <dc:creator>Malone, David</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Leaks from password datasets are a regular occurrence. An organization may
defend a leak with reassurances that just a small subset of passwords were
taken. In this paper we show that the leak of a relatively small number of
text-based passwords from an organizations' stored dataset can lead to a
further large collection of users being compromised. Taking a sample of
passwords from a given dataset of passwords we exploit the knowledge we gain of
the distribution to guess other samples from the same dataset. We show
theoretically and empirically that the distribution of passwords in the sample
follows the same distribution as the passwords in the whole dataset. We propose
a function that measures the ability of one distribution to estimate another.
Leveraging this we show that a sample of passwords leaked from a given dataset,
will compromise the remaining passwords in that dataset better than a sample
leaked from another source.
</dc:description>
 <dc:date>2018-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1809.07221</dc:identifier>
 <dc:identifier>2018 16th Annual Conference on Privacy, Security and Trust (PST)</dc:identifier>
 <dc:identifier>doi:10.1109/PST.2018.8514194</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1810.02363</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Transition Networks for Character Locomotion</dc:title>
 <dc:creator>Harvey, F&#xe9;lix G.</dc:creator>
 <dc:creator>Pal, Christopher</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Manually authoring transition animations for a complete locomotion system can
be a tedious and time-consuming task, especially for large games that allow
complex and constrained locomotion movements, where the number of transitions
grows exponentially with the number of states. In this paper, we present a
novel approach, based on deep recurrent neural networks, to automatically
generate such transitions given a past context of a few frames and a target
character state to reach. We present the Recurrent Transition Network (RTN),
based on a modified version of the Long-Short-Term-Memory (LSTM) network,
designed specifically for transition generation and trained without any gait,
phase, contact or action labels. We further propose a simple yet principled way
to initialize the hidden states of the LSTM layer for a given sequence which
improves the performance and generalization to new motions. We both
quantitatively and qualitatively evaluate our system and show that making the
network terrain-aware by adding a local terrain representation to the input
yields better performance for rough-terrain navigation on long transitions. Our
system produces realistic and fluid transitions that rival the quality of
Motion Capture-based ground-truth motions, even before applying any
inverse-kinematics postprocess. Direct benefits of our approach could be to
accelerate the creation of transition variations for large coverage, or even to
entirely replace transition nodes in an animation graph. We further explore
applications of this model in a animation super-resolution setting where we
temporally decompress animations saved at 1 frame per second and show that the
network is able to reconstruct motions that are hard to distinguish from
un-compressed locomotion sequences.
</dc:description>
 <dc:description>Comment: revision fixes: clarity issues in Section 4.4 (text and equations)</dc:description>
 <dc:date>2018-10-04</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1810.02363</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1810.05561</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Source Codes for Timely Updates</dc:title>
 <dc:creator>Mayekar, Prathamesh</dc:creator>
 <dc:creator>Parag, Parimal</dc:creator>
 <dc:creator>Tyagi, Himanshu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A transmitter observing a sequence of independent and identically distributed
random variables seeks to keep a receiver updated about its latest
observations. The receiver need not be apprised about each symbol seen by the
transmitter, but needs to output a symbol at each time instant $t$. If at time
$t$ the receiver outputs the symbol seen by the transmitter at time $U(t)\leq
t$, the age of information at the receiver at time $t$ is $t-U(t)$. We study
the design of lossless source codes that enable transmission with minimum
average age at the receiver. We show that the asymptotic minimum average age
can be attained up to a constant gap by the Shannon codes for a tilted version
of the original pmf generating the symbols, which can be computed easily by
solving an optimization problem. Furthermore, we exhibit an example with
alphabet $\X$ where Shannon codes for the original pmf incur an asymptotic
average age of a factor $O(\sqrt{\log |\X|})$ more than that achieved by our
codes. Underlying our prescription for optimal codes is a new variational
formula for integer moments of random variables, which may be of independent
interest. Also, we discuss possible extensions of our formulation to randomized
schemes and to the erasure channel, and include a treatment of the related
problem of source coding for minimum average queuing delay.
</dc:description>
 <dc:description>Comment: Added a missing reference, in IEEE Transactions on Information
  Theory, 2020</dc:description>
 <dc:date>2018-10-12</dc:date>
 <dc:date>2020-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1810.05561</dc:identifier>
 <dc:identifier>IEEE Transactions on Information Theory, vol. 66, no. 6, pp.
  3714--3731, June 2020</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2020.2983151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.00120</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regularized Fourier Ptychography using an Online Plug-and-Play Algorithm</dc:title>
 <dc:creator>Sun, Yu</dc:creator>
 <dc:creator>Xu, Shiqi</dc:creator>
 <dc:creator>Li, Yunzhe</dc:creator>
 <dc:creator>Tian, Lei</dc:creator>
 <dc:creator>Wohlberg, Brendt</dc:creator>
 <dc:creator>Kamilov, Ulugbek S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The plug-and-play priors (PnP) framework has been recently shown to achieve
state-of-the-art results in regularized image reconstruction by leveraging a
sophisticated denoiser within an iterative algorithm. In this paper, we propose
a new online PnP algorithm for Fourier ptychographic microscopy (FPM) based on
the fast iterative shrinkage/threshold algorithm (FISTA). Specifically, the
proposed algorithm uses only a subset of measurements, which makes it scalable
to a large set of measurements. We validate the algorithm by showing that it
can lead to significant performance gains on both simulated and experimental
data.
</dc:description>
 <dc:date>2018-10-31</dc:date>
 <dc:date>2018-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1811.00120</dc:identifier>
 <dc:identifier>doi:10.1109/ICASSP.2019.8683057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.00684</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SDCNet: Video Prediction Using Spatially-Displaced Convolution</dc:title>
 <dc:creator>Reda, Fitsum A.</dc:creator>
 <dc:creator>Liu, Guilin</dc:creator>
 <dc:creator>Shih, Kevin J.</dc:creator>
 <dc:creator>Kirby, Robert</dc:creator>
 <dc:creator>Barker, Jon</dc:creator>
 <dc:creator>Tarjan, David</dc:creator>
 <dc:creator>Tao, Andrew</dc:creator>
 <dc:creator>Catanzaro, Bryan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present an approach for high-resolution video frame prediction by
conditioning on both past frames and past optical flows. Previous approaches
rely on resampling past frames, guided by a learned future optical flow, or on
direct generation of pixels. Resampling based on flow is insufficient because
it cannot deal with disocclusions. Generative models currently lead to blurry
results. Recent approaches synthesis a pixel by convolving input patches with a
predicted kernel. However, their memory requirement increases with kernel size.
Here, we spatially-displaced convolution (SDC) module for video frame
prediction. We learn a motion vector and a kernel for each pixel and synthesize
a pixel by applying the kernel at a displaced location in the source image,
defined by the predicted motion vector. Our approach inherits the merits of
both vector-based and kernel-based approaches, while ameliorating their
respective disadvantages. We train our model on 428K unlabelled 1080p video
game frames. Our approach produces state-of-the-art results, achieving an SSIM
score of 0.904 on high-definition YouTube-8M videos, 0.918 on Caltech
Pedestrian videos. Our model handles large motion effectively and synthesizes
crisp frames with consistent motion.
</dc:description>
 <dc:description>Comment: Published in ECCV 2018. Codes available at
  https://github.com/NVIDIA/semantic-segmentation/tree/sdcnet/sdcnet. Project
  page available at https://nv-adlr.github.io/publication/2018-SDCNet</dc:description>
 <dc:date>2018-11-01</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1811.00684</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1811.11454</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Invariant Sets Computation for Switched Discrete-Time Polynomial
  Systems</dc:title>
 <dc:creator>Xue, Bai</dc:creator>
 <dc:creator>Zhan, Naijun</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper we study the robust invariant sets generation problem for
discrete-time switched polynomial systems subject to disturbance inputs within
the optimal control framework. A robust invariant set of interest is a set of
states such that every possible trajectory starting from it never leaves a
specified safe set, regardless of actual disturbances. The maximal robust
invariant set is shown to be the zero level set of the unique bounded solution
to a Bellman type equation, which is a functional equation being widely used in
discrete-time optimal control. This is the main contribution of this work. The
uniqueness of bounded solutions enables us to solve the derived Bellman type
equation using numerical methods such as the value iteration, which provides an
approximation of the maximal robust invariant set. In order to increase the
scalability of the Bellman equation based method, a semi-definite program,
which is constructed based on the derived Bellman type equation, is also
implemented to synthesize robust invariant sets. Finally, three examples
demonstrate the performance of our methods.
</dc:description>
 <dc:description>Comment: This paper is accepted by IEEE TAC. The title is changed to 'Robust
  Invariant Sets Computation for Discrete-Time Perturbed Nonlinear Systems'</dc:description>
 <dc:date>2018-11-28</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1811.11454</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.01339</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Guided Belief Propagation -- A Homotopy Continuation Method</dc:title>
 <dc:creator>Knoll, Christian</dc:creator>
 <dc:creator>Weller, Adrian</dc:creator>
 <dc:creator>Pernkopf, Franz</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Belief propagation (BP) is a popular method for performing probabilistic
inference on graphical models. In this work, we enhance BP and propose
self-guided belief propagation (SBP) that incorporates the pairwise potentials
only gradually. This homotopy continuation method converges to a unique
solution and increases the accuracy without increasing the computational
burden. We provide a formal analysis to demonstrate that SBP finds the global
optimum of the Bethe approximation for attractive models where all variables
favor the same state. Moreover, we apply SBP to various graphs with random
potentials and empirically show that: (i) SBP is superior in terms of accuracy
whenever BP converges, and (ii) SBP obtains a unique, stable, and accurate
solution whenever BP does not converge.
</dc:description>
 <dc:description>Comment: This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</dc:description>
 <dc:date>2018-12-04</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1812.01339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.04894</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A3: Assisting Android API Migrations Using Code Examples</dc:title>
 <dc:creator>Lamothe, Maxime</dc:creator>
 <dc:creator>Shang, Weiyi</dc:creator>
 <dc:creator>Chen, Tse-Hsun</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The fast-paced evolution of Android APIs has posed a challenging task for
Android app developers. To leverage Android's frequently released APIs,
developers must often spend considerable effort on API migrations. Prior
research and Android official documentation typically provide enough
information to guide developers in identifying the API calls that must be
migrated and the corresponding API calls in an updated version of Android (what
to migrate). However, API migration remains a challenging task since developers
lack the knowledge of how to migrate the API calls. There exist code examples,
such as Google Samples, that illustrate the usage of APIs. We posit that by
analyzing the changes of API usage in code examples, we can learn API migration
patterns to assist developers with API Migrations.
  In this paper, we propose an approach that learns API migration patterns from
code examples, applies these patterns to the source code of Android apps for
API migration, and presents the results to users as potential migration
solutions. To evaluate our approach, we migrate API calls in open source
Android apps by learning API migration patterns from code examples. We find
that our approach can successfully learn API migration patterns and provide API
migration assistance in 71 out of 80 cases. Our approach can either migrate API
calls with little to no extra modifications needed or provide guidance to
assist with the migrations. Through a user study, we find that adopting our
approach can reduce the time spent on migrating APIs, on average, by 29%.
Moreover, our interviews with app developers highlight the benefits of our
approach when seeking API migrations. Our approach demonstrates the value of
leveraging the knowledge contained in software repositories to facilitate API
migrations.
</dc:description>
 <dc:description>Comment: Published in IEEE TSE</dc:description>
 <dc:date>2018-12-12</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1812.04894</dc:identifier>
 <dc:identifier>doi:10.1109/TSE.2020.2988396</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1812.11257</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate Nearest Neighbors in the Space of Persistence Diagrams</dc:title>
 <dc:creator>Fasy, Brittany Terese</dc:creator>
 <dc:creator>He, Xiaozhou</dc:creator>
 <dc:creator>Liu, Zhihui</dc:creator>
 <dc:creator>Micka, Samuel</dc:creator>
 <dc:creator>Millman, David L.</dc:creator>
 <dc:creator>Zhu, Binhai</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Persistence diagrams are important tools in the field of topological data
analysis that describe the presence and magnitude of features in a filtered
topological space. However, current approaches for comparing a persistence
diagram to a set of other persistence diagrams is linear in the number of
diagrams or do not offer performance guarantees. In this paper, we apply
concepts from locality-sensitive hashing to support approximate nearest
neighbor search in the space of persistence diagrams. Given a set $\Gamma$ of
$n$ $(M,m)$-bounded persistence diagrams, each with at most $m$ points, we
snap-round the points of each diagram to points on a cubical lattice and
produce a key for each possible snap-rounding. Specifically, we fix a grid over
each diagram at several resolutions and consider the snap-roundings of each
diagram to the four nearest lattice points. Then, we propose a data structure
with $\tau$ levels $\mathbb{D}_{\tau}$ that stores all snap-roundings of each
persistence diagram in $\Gamma$ at each resolution. This data structure has
size $O(n5^m\tau)$ to account for varying lattice resolutions as well as
snap-roundings and the deletion of points with low persistence. To search for a
persistence diagram, we compute a key for a query diagram by snapping each
point to a lattice and deleting points of low persistence. Furthermore, as the
lattice parameter decreases, searching our data structure yields a
six-approximation of the nearest diagram in $\Gamma$ in
$O((m\log{n}+m^2)\log\tau)$ time and a constant factor approximation of the
$k$th nearest diagram in $O((m\log{n}+m^2+k)\log\tau)$ time.
</dc:description>
 <dc:date>2018-12-28</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1812.11257</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.02928</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond the EM Algorithm: Constrained Optimization Methods for Latent
  Class Model</dc:title>
 <dc:creator>Chen, Hao</dc:creator>
 <dc:creator>Han, Lanshan</dc:creator>
 <dc:creator>Lim, Alvin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Latent class model (LCM), which is a finite mixture of different categorical
distributions, is one of the most widely used models in statistics and machine
learning fields. Because of its non-continuous nature and the flexibility in
shape, researchers in practice areas such as marketing and social sciences also
frequently use LCM to gain insights from their data. One likelihood-based
method, the Expectation-Maximization (EM) algorithm, is often used to obtain
the model estimators. However, the EM algorithm is well-known for its
notoriously slow convergence. In this research, we explore alternative
likelihood-based methods that can potential remedy the slow convergence of the
EM algorithm. More specifically, we regard likelihood-based approach as a
constrained nonlinear optimization problem, and apply quasi-Newton type methods
to solve them. We examine two different constrained optimization methods to
maximize the log likelihood function. We present simulation study results to
show that the proposed methods not only converge in less iterations than the EM
algorithm but also produce more accurate model estimators.
</dc:description>
 <dc:date>2019-01-09</dc:date>
 <dc:date>2020-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1901.02928</dc:identifier>
 <dc:identifier>doi:10.1080/03610918.2020.1764034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1901.10657</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature Concatenation Multi-view Subspace Clustering</dc:title>
 <dc:creator>Zheng, Qinghai</dc:creator>
 <dc:creator>Zhu, Jihua</dc:creator>
 <dc:creator>Li, Zhongyu</dc:creator>
 <dc:creator>Pang, Shanmin</dc:creator>
 <dc:creator>Wang, Jun</dc:creator>
 <dc:creator>Li, Yaochen</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Multi-view clustering is a learning paradigm based on multi-view data. Since
statistic properties of different views are diverse, even incompatible, few
approaches implement multi-view clustering based on the concatenated features
straightforward. However, feature concatenation is a natural way to combine
multi-view data. To this end, this paper proposes a novel multi-view subspace
clustering approach dubbed Feature Concatenation Multi-view Subspace Clustering
(FCMSC), which boosts the clustering performance by exploring the consensus
information of multi-view data. Specifically, multi-view data are concatenated
into a joint representation firstly, then, $l_{2,1}$-norm is integrated into
the objective function to deal with the sample-specific and cluster-specific
corruptions of multiple views. Moreover, a graph regularized FCMSC is also
proposed in this paper to explore both the consensus information and
complementary information of multi-view data for clustering. It is noteworthy
that the obtained coefficient matrix is not derived by simply applying the
Low-Rank Representation (LRR) to concatenated features directly. Finally, an
effective algorithm based on the Augmented Lagrangian Multiplier (ALM) is
designed to optimize the objective functions. Comprehensive experiments on six
real-world datasets illustrate the superiority of the proposed methods over
several state-of-the-art approaches for multi-view clustering.
</dc:description>
 <dc:date>2019-01-29</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1901.10657</dc:identifier>
 <dc:identifier>doi:10.1016/j.neucom.2019.10.074</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.03101</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Dissertation on Bearing Rigidity Theory</dc:title>
 <dc:creator>Michieletto, Giulia</dc:creator>
 <dc:creator>Cenedese, Angelo</dc:creator>
 <dc:creator>Zelazo, Daniel</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  This work focuses on the bearing rigidity theory, namely the branch of
knowledge investigating the structural properties necessary for multi-element
systems to preserve the inter-units bearings when exposed to deformations. The
original contributions are twofold. The first one consists in the definition of
a general framework for the statement of the principal definitions and results
that are then particularized by evaluating the most studied metric spaces,
providing a complete overview of the existing literature about the bearing
rigidity theory. The second one rests on the determination of a necessary and
sufficient condition guaranteeing the rigidity properties of a given
multi-element system, independently of its metric space.
</dc:description>
 <dc:date>2019-02-07</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1902.03101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.05247</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D Graph Embedding Learning with a Structure-aware Loss Function for
  Point Cloud Semantic Instance Segmentation</dc:title>
 <dc:creator>Liang, Zhidong</dc:creator>
 <dc:creator>Yang, Ming</dc:creator>
 <dc:creator>Wang, Chunxiang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper introduces a novel approach for 3D semantic instance segmentation
on point clouds. A 3D convolutional neural network called submanifold sparse
convolutional network is used to generate semantic predictions and instance
embeddings simultaneously. To obtain discriminative embeddings for each 3D
instance, a structure-aware loss function is proposed which considers both the
structure information and the embedding information. To get more consistent
embeddings for each 3D instance, attention-based k nearest neighbour (KNN) is
proposed to assign different weights for different neighbours. Based on the
attention-based KNN, we add a graph convolutional network after the sparse
convolutional network to get refined embeddings. Our network can be trained
end-to-end. A simple mean-shift algorithm is utilized to cluster refined
embeddings to get final instance predictions. As a result, our framework can
output both the semantic prediction and the instance prediction. Experiments
show that our approach outperforms all state-of-art methods on ScanNet
benchmark and NYUv2 dataset.
</dc:description>
 <dc:date>2019-02-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1902.05247</dc:identifier>
 <dc:identifier>Title: 3D Instance Embedding Learning With a Structure-Aware Loss
  Function for Point Cloud Segmentation; Published in: IEEE Robotics and
  Automation Letters ( Volume: 5, Issue: 3, July 2020)</dc:identifier>
 <dc:identifier>doi:10.1109/LRA.2020.3004802</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.07669</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ScispaCy: Fast and Robust Models for Biomedical Natural Language
  Processing</dc:title>
 <dc:creator>Neumann, Mark</dc:creator>
 <dc:creator>King, Daniel</dc:creator>
 <dc:creator>Beltagy, Iz</dc:creator>
 <dc:creator>Ammar, Waleed</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Despite recent advances in natural language processing, many statistical
models for processing text perform extremely poorly under domain shift.
Processing biomedical and clinical text is a critically important application
area of natural language processing, for which there are few robust, practical,
publicly available models. This paper describes scispaCy, a new tool for
practical biomedical/scientific text processing, which heavily leverages the
spaCy library. We detail the performance of two packages of models released in
scispaCy and demonstrate their robustness on several tasks and datasets. Models
and code are available at https://allenai.github.io/scispacy/
</dc:description>
 <dc:description>Comment: BioNLP@ACL2019 final version</dc:description>
 <dc:date>2019-02-20</dc:date>
 <dc:date>2019-10-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1902.07669</dc:identifier>
 <dc:identifier>Proceedings of the 18th BioNLP Workshop and Shared Task (2019)
  319-327</dc:identifier>
 <dc:identifier>doi:10.18653/v1/W19-5034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1902.08437</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random finite-difference discretizations of the Ambrosio-Tortorelli
  functional with optimal mesh size</dc:title>
 <dc:creator>Bach, Annika</dc:creator>
 <dc:creator>Cicalese, Marco</dc:creator>
 <dc:creator>Ruf, Matthias</dc:creator>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>49M25, 68U10, 49J55, 49J45</dc:subject>
 <dc:description>  We propose and analyze a finite-difference discretization of the
Ambrosio-Tortorelli functional. It is known that if the discretization is made
with respect to an underlying periodic lattice of spacing $\delta$, the
discretized functionals $\Gamma$-converge to the Mumford-Shah functional only
if $\delta\ll\varepsilon$, $\varepsilon$ being the elliptic approximation
parameter of the Ambrosio-Tortorelli functional. Discretizing with respect to
stationary, ergodic and isotropic random lattices we prove this
$\Gamma$-convergence result also for $\delta\sim\varepsilon$, a regime at which
the discretization with respect to a periodic lattice converges instead to an
anisotropic version of the Mumford-Shah functional.
</dc:description>
 <dc:description>Comment: 36 pages, 6 figures. Added some numerical examples</dc:description>
 <dc:date>2019-02-22</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1902.08437</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1903.03091</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear quadratic regulation of polytopic time-inhomogeneous Markov jump
  linear systems (extended version)</dc:title>
 <dc:creator>Lun, Y. Zacchia</dc:creator>
 <dc:creator>Abate, A.</dc:creator>
 <dc:creator>D'Innocenzo, A.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  In most real cases transition probabilities between operational modes of
Markov jump linear systems cannot be computed exactly and are time-varying. We
take into account this aspect by considering Markov jump linear systems where
the underlying Markov chain is polytopic and time-inhomogeneous, i.e. its
transition probability matrix is varying over time, with variations that are
arbitrary within a polytopic set of stochastic matrices. We address and solve
for this class of systems the infinite-horizon optimal control problem. In
particular, we show that the optimal controller can be obtained from a set of
coupled algebraic Riccati equations, and that for mean square stabilizable
systems the optimal finite-horizon cost corresponding to the solution to a
parsimonious set of coupled difference Riccati equations converges
exponentially fast to the optimal infinite-horizon cost related to the set of
coupled algebraic Riccati equations. All the presented concepts are illustrated
on a numerical example showing the efficiency of the provided solution.
</dc:description>
 <dc:description>Comment: Extended version of the paper accepted for the presentation at the
  European Control Conference (ECC 2019)</dc:description>
 <dc:date>2019-03-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1903.03091</dc:identifier>
 <dc:identifier>doi:10.23919/ECC.2019.8796279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1903.03238</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ranked List Loss for Deep Metric Learning</dc:title>
 <dc:creator>Wang, Xinshao</dc:creator>
 <dc:creator>Hua, Yang</dc:creator>
 <dc:creator>Kodirov, Elyor</dc:creator>
 <dc:creator>Robertson, Neil M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The objective of deep metric learning (DML) is to learn embeddings that can
capture semantic similarity and dissimilarity information among data points.
Existing pairwise or tripletwise loss functions used in DML are known to suffer
from slow convergence due to a large proportion of trivial pairs or triplets as
the model improves. To improve this, ranking-motivated structured losses are
proposed recently to incorporate multiple examples and exploit the structured
information among them. They converge faster and achieve state-of-the-art
performance. In this work, we unveil two limitations of existing
ranking-motivated structured losses and propose a novel ranked list loss to
solve both of them. First, given a query, only a fraction of data points is
incorporated to build the similarity structure. Consequently, some useful
examples are ignored and the structure is less informative. To address this, we
propose to build a set-based similarity structure by exploiting all instances
in the gallery. The learning setting can be interpreted as few-shot retrieval:
given a mini-batch, every example is iteratively used as a query, and the rest
ones compose the gallery to search, i.e., the support set in few-shot setting.
The rest examples are split into a positive set and a negative set. For every
mini-batch, the learning objective of ranked list loss is to make the query
closer to the positive set than to the negative set by a margin. Second,
previous methods aim to pull positive pairs as close as possible in the
embedding space. As a result, the intraclass data distribution tends to be
extremely compressed. In contrast, we propose to learn a hypersphere for each
class in order to preserve useful similarity structure inside it, which
functions as regularisation. Extensive experiments demonstrate the superiority
of our proposal by comparing with the state-of-the-art methods.
</dc:description>
 <dc:description>Comment: Accepted to T-PAMI. Therefore, to read the offical version, please go
  to IEEE Xplore. Fine-grained image retrieval task. Our source code is
  available online: https://github.com/XinshaoAmosWang/Ranked-List-Loss-for-DML</dc:description>
 <dc:date>2019-03-07</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1903.03238</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1903.05303</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analytic Semi-device-independent Entanglement Quantification for
  Bipartite Quantum States</dc:title>
 <dc:creator>Wei, Zhaohui</dc:creator>
 <dc:creator>Lin, Lijinzhi</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We define a property called nondegeneracy for Bell inequalities, which
describes the situation that in a Bell setting, if a Bell inequality and
involved local measurements are chosen and fixed, any quantum state with a
given dimension and its orthogonal quantum state cannot violate the inequality
remarkably at the same time. By choosing a proper nondegenerate Bell
inequality, we prove that for a unknown bipartite quantum state of a given
dimension, based on the measurement statistics only, we can provide an analytic
lower bound for the entanglement of formation or even for the distillable
entanglement, making the whole process semi-device-independent. We characterize
the mathematical structure of nondegenerate Bell inequalities, and prove that
quite a lot of well-known Bell inequalities are nondegenerate. We demonstrate
our approach by quantifying entanglement for qutrit-qutrit states based on
their violation to the CGLMP inequality.
</dc:description>
 <dc:description>Comment: A mathematical characterization for nondegeneracy Bell inequalities
  that proves quite a lot of well-known Bell inequalities are nondegenerate was
  added; A demonstration of our approach that quantifies the entanglement of
  qutrit-qutrit states based on their violation to the CGLMP inequality was
  also provided; Comments are welcome</dc:description>
 <dc:date>2019-03-13</dc:date>
 <dc:date>2019-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1903.05303</dc:identifier>
 <dc:identifier>Phys. Rev. A 103, 032215 (2021)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevA.103.032215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1903.08358</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounded Synthesis of Resilient Supervisors</dc:title>
 <dc:creator>Lin, Liyong</dc:creator>
 <dc:creator>Su, Rong</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we investigate the problem of synthesizing resilient
supervisors against combined actuator and sensor attacks, for the subclass of
cyber-physical systems that can be modelled as discrete-event systems. We
assume that the attackers can carry out actuator enablement and disablement
attacks as well as sensor replacement attacks. We consider both risky attackers
and covert attackers in the setup where the (partial-observation) attackers may
or may not eavesdrop the control commands (issued by the supervisor). A
constraint-based approach for the bounded synthesis of resilient supervisors is
developed, by reducing the problem to the Quantified Boolean Formulas (QBF)
problem. The bounded synthesis problem can then be solved either with a QBF
solver or with repeated calls to a propositional satisfiability (SAT) solver,
by employing maximally permissive attackers, which can be synthesized with the
existing partial-observation supervisor synthesis procedures, as counter
examples in the counter example guided inductive synthesis loop.
</dc:description>
 <dc:description>Comment: This paper has been submitted to IEEE Transactions on Automatic
  Control for review</dc:description>
 <dc:date>2019-03-20</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1903.08358</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1903.09837</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Curve Text with Local Segmentation Network and Curve
  Connection</dc:title>
 <dc:creator>Zhou, Zhao</dc:creator>
 <dc:creator>Ye, Hao</dc:creator>
 <dc:creator>Chen, Luhui</dc:creator>
 <dc:creator>Zheng, Yingbin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Curve text or arbitrary shape text is very common in real-world scenarios. In
this paper, we propose a novel framework with the local segmentation network
(LSN) followed by the curve connection to detect text in horizontal, oriented
and curved forms. The LSN is composed of two elements, i.e., proposal
generation to get the horizontal rectangle proposals with high overlap with
text and text segmentation to find the arbitrary shape text region within
proposals. The curve connection is then designed to connect the local mask to
the detection results. We conduct experiments using the proposed framework on
two real-world curve text detection datasets and demonstrate the effectiveness
over previous approaches.
</dc:description>
 <dc:date>2019-03-23</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1903.09837</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1903.10525</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inverse Optimal Planning for Air Traffic Control</dc:title>
 <dc:creator>Tolstaya, Ekaterina</dc:creator>
 <dc:creator>Ribeiro, Alejandro</dc:creator>
 <dc:creator>Kumar, Vijay</dc:creator>
 <dc:creator>Kapoor, Ashish</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We envision a system that concisely describes the rules of air traffic
control, assists human operators and supports dense autonomous air traffic
around commercial airports. We develop a method to learn the rules of air
traffic control from real data as a cost function via maximum entropy inverse
reinforcement learning. This cost function is used as a penalty for a
search-based motion planning method that discretizes both the control and the
state space. We illustrate the methodology by showing that our approach can
learn to imitate the airport arrival routes and separation rules of dense
commercial air traffic. The resulting trajectories are shown to be safe,
feasible, and efficient.
</dc:description>
 <dc:date>2019-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1903.10525</dc:identifier>
 <dc:identifier>doi:10.1109/IROS40897.2019.8968460</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1903.10527</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Decentralized Controllers for Robot Swarms with Graph Neural
  Networks</dc:title>
 <dc:creator>Tolstaya, Ekaterina</dc:creator>
 <dc:creator>Gama, Fernando</dc:creator>
 <dc:creator>Paulos, James</dc:creator>
 <dc:creator>Pappas, George</dc:creator>
 <dc:creator>Kumar, Vijay</dc:creator>
 <dc:creator>Ribeiro, Alejandro</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We consider the problem of finding distributed controllers for large networks
of mobile robots with interacting dynamics and sparsely available
communications. Our approach is to learn local controllers that require only
local information and communications at test time by imitating the policy of
centralized controllers using global information at training time. By extending
aggregation graph neural networks to time varying signals and time varying
network support, we learn a single common local controller which exploits
information from distant teammates using only local communication interchanges.
We apply this approach to the problem of flocking to demonstrate performance on
communication graphs that change as the robots move. We examine how a
decreasing communication radius and faster velocities increase the value of
multi-hop information.
</dc:description>
 <dc:date>2019-03-25</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1903.10527</dc:identifier>
 <dc:identifier>doi:10.1561/2200000060</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1904.00402</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pebble Exchange Group of Graphs</dc:title>
 <dc:creator>Kato, Tatsuoki</dc:creator>
 <dc:creator>Nakamigawa, Tomoki</dc:creator>
 <dc:creator>Sakuma, Tadashi</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A graph puzzle ${\rm Puz}(G)$ of a graph $G$ is defined as follows. A
configuration of ${\rm Puz}(G)$ is a bijection from the set of vertices of a
board graph to the set of vertices of a pebble graph, both graphs being
isomorphic to some input graph $G$. A move of pebbles is defined as exchanging
two pebbles which are adjacent on both a board graph and a pebble graph. For a
pair of configurations $f$ and $g$, we say that $f$ is equivalent to $g$ if $f$
can be transformed into $g$ by a finite sequence of moves.
  Let ${\rm Aut}(G)$ be the automorphism group of $G$, and let ${\rm 1}_G$ be
the unit element of ${\rm Aut}(G)$. The pebble exchange group of $G$, denoted
by ${\rm Peb}(G)$, is defined as the set of all automorphisms $f$ of $G$ such
that ${\rm 1}_G$ and $f$ are equivalent to each other.
  In this paper, some basic properties of ${\rm Peb}(G)$ are studied. Among
other results, it is shown that for any connected graph $G$, all automorphisms
of $G$ are contained in ${\rm Peb}(G^2)$, where $G^2$ is a square graph of $G$.
</dc:description>
 <dc:description>Comment: Accepted in European Journal of Combinatorics</dc:description>
 <dc:date>2019-03-31</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1904.00402</dc:identifier>
 <dc:identifier>European Journal of Combinatorics (2021)</dc:identifier>
 <dc:identifier>doi:10.1016/j.ejc.2021.103325</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1904.04072</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Complexity of the Ideal Membership Problem for Constrained Problems
  Over the Boolean Domain</dc:title>
 <dc:creator>Mastrolilli, Monaldo</dc:creator>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Given an ideal $I$ and a polynomial $f$ the Ideal Membership Problem is to
test if $f\in I$. This problem is a fundamental algorithmic problem with
important applications and notoriously intractable. We study the complexity of
the Ideal Membership Problem for combinatorial ideals that arise from
constrained problems over the Boolean domain. As our main result, we identify
the borderline of tractability. By using Gr\&quot;{o}bner bases techniques, we
extend Schaefer's dichotomy theorem [STOC, 1978] which classifies all
Constraint Satisfaction Problems over the Boolean domain to be either in P or
NP-hard. Moreover, our result implies necessary and sufficient conditions for
the efficient computation of Theta Body SDP relaxations, identifying therefore
the borderline of tractability for constraint language problems. This paper is
motivated by the pursuit of understanding the recently raised issue of bit
complexity of Sum-of-Squares proofs [O'Donnell, ITCS, 2017]. Raghavendra and
Weitz [ICALP, 2017] show how the Ideal Membership Problem tractability for
combinatorial ideals implies bounded coefficients in Sum-of-Squares proofs.
</dc:description>
 <dc:description>Comment: Preliminary version appeared in ACM-SIAM Symposium on Discrete
  Algorithms (SODA19)</dc:description>
 <dc:date>2019-04-05</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1904.04072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1904.09090</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SCANN: Synthesis of Compact and Accurate Neural Networks</dc:title>
 <dc:creator>Hassantabar, Shayan</dc:creator>
 <dc:creator>Wang, Zeyu</dc:creator>
 <dc:creator>Jha, Niraj K.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Deep neural networks (DNNs) have become the driving force behind recent
artificial intelligence (AI) research. An important problem with implementing a
neural network is the design of its architecture. Typically, such an
architecture is obtained manually by exploring its hyperparameter space and
kept fixed during training. This approach is time-consuming and inefficient.
Another issue is that modern neural networks often contain millions of
parameters, whereas many applications and devices require small inference
models. However, efforts to migrate DNNs to such devices typically entail a
significant loss of classification accuracy. To address these challenges, we
propose a two-step neural network synthesis methodology, called DR+SCANN, that
combines two complementary approaches to design compact and accurate DNNs. At
the core of our framework is the SCANN methodology that uses three basic
architecture-changing operations, namely connection growth, neuron growth, and
connection pruning, to synthesize feed-forward architectures with arbitrary
structure. SCANN encapsulates three synthesis methodologies that apply a
repeated grow-and-prune paradigm to three architectural starting points.
DR+SCANN combines the SCANN methodology with dataset dimensionality reduction
to alleviate the curse of dimensionality. We demonstrate the efficacy of SCANN
and DR+SCANN on various image and non-image datasets. We evaluate SCANN on
MNIST and ImageNet benchmarks. In addition, we also evaluate the efficacy of
using dimensionality reduction alongside SCANN (DR+SCANN) on nine small to
medium-size datasets. We also show that our synthesis methodology yields neural
networks that are much better at navigating the accuracy vs. energy efficiency
space. This would enable neural network-based inference even on
Internet-of-Things sensors.
</dc:description>
 <dc:description>Comment: 13 pages, 8 figures</dc:description>
 <dc:date>2019-04-19</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1904.09090</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1904.10159</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synthesis of Covert Actuator Attackers for Free</dc:title>
 <dc:creator>Lin, Liyong</dc:creator>
 <dc:creator>Zhu, Yuting</dc:creator>
 <dc:creator>Su, Rong</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we shall formulate and address a problem of covert actuator
attacker synthesis for cyber-physical systems that are modelled by
discrete-event systems. We assume the actuator attacker partially observes the
execution of the closed-loop system and is able to modify each control command
issued by the supervisor on a specified attackable subset of controllable
events. We provide straightforward but in general exponential-time reductions,
due to the use of subset construction procedure, from the covert actuator
attacker synthesis problems to the Ramadge-Wonham supervisor synthesis
problems. It then follows that it is possible to use the many techniques and
tools already developed for solving the supervisor synthesis problem to solve
the covert actuator attacker synthesis problem for free. In particular, we show
that, if the attacker cannot attack unobservable events to the supervisor, then
the reductions can be carried out in polynomial time. We also provide a brief
discussion on some other conditions under which the exponential blowup in state
size can be avoided. Finally, we show how the reduction based synthesis
procedure can be extended for the synthesis of successful covert actuator
attackers that also eavesdrop the control commands issued by the supervisor.
</dc:description>
 <dc:description>Comment: The paper has been accepted for the journal Discrete Event Dynamic
  Systems</dc:description>
 <dc:date>2019-04-23</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1904.10159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1904.12025</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polyhedral Properties of the Induced Cluster Subgraphs</dc:title>
 <dc:creator>Hosseinian, Seyedmohammadhossein</dc:creator>
 <dc:creator>Butenko, Sergiy</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>90C57 (Primary) 90C35, 90C10, 90C27, 05C (Secondary)</dc:subject>
 <dc:description>  A cluster graph is a graph whose every connected component is a complete
graph. Given a simple undirected graph $G$, a subset of vertices inducing a
cluster graph is called an independent union of cliques (IUC), and the IUC
polytope associated with $G$ is defined as the convex hull of the incidence
vectors of all IUCs in the graph. The {\sc Maximum IUC} problem, which is to
find a maximum-cardinality IUC in a graph, finds applications in network-based
data analysis. In this paper, we derive several families of facet-defining
valid inequalities for the IUC polytope. We also give a complete description of
this polytope for some special classes of graphs. We establish computational
complexity of the separation problem for most of the considered families of
valid inequalities and explore the effectiveness of employing the corresponding
cutting planes in an integer (linear) programming framework for the {\sc
Maximum IUC} problem through computational experiments.
</dc:description>
 <dc:description>Comment: 40 pages, 3 figures, 5 tables</dc:description>
 <dc:date>2019-04-26</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1904.12025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1904.13198</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Models for Commercial Advertisements in Social Networks</dc:title>
 <dc:creator>Atdag, Samet</dc:creator>
 <dc:creator>Bingol, Haluk O.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Identifying noteworthy spreaders in a network is essential for understanding
the spreading process and controlling the reach of the spread in the network.
The nodes that are holding more intrinsic power to extend the reach of the
spread are important due to demand for various applications such as viral
marketing, controlling rumor spreading or get a better understanding of
spreading of the diseases. As an application of the viral marketing,
maximization of the reach with a fixed budget is a fundamental requirement in
the advertising business. Distributing a fixed number of promotional items for
maximizing the viral reach can leverage influencer detection methods. For
detecting such &quot;influencer&quot; nodes, there are local metrics such as degree
centrality (mostly used as in-degree centrality) or global metrics such as
k-shell decomposition or eigenvector centrality. All the methods can rank
graphs but they all have limitations and there is still no de-facto method for
influencer detection in the domain.
  In this paper, we propose an extended k-shell algorithm which better utilizes
the k-shell decomposition for identifying viral spreader nodes using the
topological features of the network. We use Susceptible-Infected-Recovered
model for the simulations of the spreading process in real-life networks and
the simulations demonstrates that our approach can reach to up to 36% larger
crowds within the same network, with the same number of initial spreaders.
</dc:description>
 <dc:date>2019-04-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1904.13198</dc:identifier>
 <dc:identifier>Physica A, 572, 125916, 2021</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2021.125916</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.00502</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Task Planning with a Weighted Functional Object-Oriented Network</dc:title>
 <dc:creator>Paulius, David</dc:creator>
 <dc:creator>Dong, Kelvin Sheng Pei</dc:creator>
 <dc:creator>Sun, Yu</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In reality, there is still much to be done for robots to be able to perform
manipulation actions with full autonomy. Complicated manipulation tasks, such
as cooking, may still require a person to perform some actions that are very
risky for a robot to perform. On the other hand, some other actions may be very
risky for a human with physical disabilities to perform. Therefore, it is
necessary to balance the workload of a robot and a human based on their
limitations while minimizing the effort needed from a human in a collaborative
robot (cobot) set-up. This paper proposes a new version of our functional
object-oriented network (FOON) that integrates weights in its functional units
to reflect a robot's chance of successfully executing an action of that
functional unit. The paper also presents a task planning algorithm for the
weighted FOON to allocate manipulation action load to the robot and human to
achieve optimal performance while minimizing human effort. Through a number of
experiments, this paper shows several successful cases in which using the
proposed weighted FOON and the task planning algorithm allow a robot and a
human to successfully complete complicated tasks together with higher success
rates than a robot doing them alone.
</dc:description>
 <dc:description>Comment: ICRA 2021 Submission -- 7 Pages, Accepted to Conference</dc:description>
 <dc:date>2019-05-01</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1905.00502</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.02847</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Atomic Commitment Across Blockchains</dc:title>
 <dc:creator>Zakhary, Victor</dc:creator>
 <dc:creator>Agrawal, Divyakant</dc:creator>
 <dc:creator>Abbadi, Amr El</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The recent adoption of blockchain technologies and open permissionless
networks suggest the importance of peer-to-peer atomic cross-chain transaction
protocols. Users should be able to atomically exchange tokens and assets
without depending on centralized intermediaries such as exchanges. Recent
peer-to-peer atomic cross-chain swap protocols use hashlocks and timelocks to
ensure that participants comply to the protocol. However, an expired timelock
could lead to a violation of the all-or-nothing atomicity property. An honest
participant who fails to execute a smart contract on time due to a crash
failure or network delays at her site might end up losing her assets. Although
a crashed participant is the only participant who ends up worse off, current
proposals are unsuitable for atomic cross-chain transactions in asynchronous
environments where crash failures and network delays are the norm. In this
paper, we present AC3WN, the first decentralized all-or-nothing atomic
cross-chain commitment protocol. The redeem and refund events of the smart
contracts that exchange assets are modeled as conflicting events. An open
permissionless network of witnesses is used to guarantee that conflicting
events could never simultaneously occur and either all smart contracts in an
atomic cross-chain transaction are redeemed or all of them are refunded.
</dc:description>
 <dc:date>2019-05-07</dc:date>
 <dc:date>2019-06-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1905.02847</dc:identifier>
 <dc:identifier>doi:10.14778/3397230.3397231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.03908</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DEMC: A Deep Dual-Encoder Network for Denoising Monte Carlo Rendering</dc:title>
 <dc:creator>Yang, Xin</dc:creator>
 <dc:creator>Hu, Wenbo</dc:creator>
 <dc:creator>Wang, Dawei</dc:creator>
 <dc:creator>Zhao, Lijing</dc:creator>
 <dc:creator>Yin, Baocai</dc:creator>
 <dc:creator>Zhang, Qiang</dc:creator>
 <dc:creator>Wei, Xiaopeng</dc:creator>
 <dc:creator>Fu, Hongbo</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  In this paper, we present DEMC, a deep Dual-Encoder network to remove Monte
Carlo noise efficiently while preserving details. Denoising Monte Carlo
rendering is different from natural image denoising since inexpensive
by-products (feature buffers) can be extracted in the rendering stage. Most of
them are noise-free and can provide sufficient details for image
reconstruction. However, these feature buffers also contain redundant
information, which makes Monte Carlo denoising different from natural image
denoising. Hence, the main challenge of this topic is how to extract useful
information and reconstruct clean images. To address this problem, we propose a
novel network structure, Dual-Encoder network with a feature fusion
sub-network, to fuse feature buffers firstly, then encode the fused feature
buffers and a noisy image simultaneously, and finally reconstruct a clean image
by a decoder network. Compared with the state-of-the-art methods, our model is
more robust on a wide range of scenes and is able to generate satisfactory
results in a significantly faster way.
</dc:description>
 <dc:description>Comment: Published in Journal of Computer Science and Technology. The final
  publication is available at springerlink.com</dc:description>
 <dc:date>2019-05-09</dc:date>
 <dc:date>2020-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1905.03908</dc:identifier>
 <dc:identifier>Journal of Computer Science and Technology, 2019, 34.5: 1123-1135</dc:identifier>
 <dc:identifier>doi:10.1007/s11390-019-1964-2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.04166</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Open Source and Open Hardware Deep Learning-powered Visual Navigation
  Engine for Autonomous Nano-UAVs</dc:title>
 <dc:creator>Palossi, Daniele</dc:creator>
 <dc:creator>Conti, Francesco</dc:creator>
 <dc:creator>Benini, Luca</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  Nano-size unmanned aerial vehicles (UAVs), with few centimeters of diameter
and sub-10 Watts of total power budget, have so far been considered incapable
of running sophisticated visual-based autonomous navigation software without
external aid from base-stations, ad-hoc local positioning infrastructure, and
powerful external computation servers. In this work, we present what is, to the
best of our knowledge, the first 27g nano-UAV system able to run aboard an
end-to-end, closed-loop visual pipeline for autonomous navigation based on a
state-of-the-art deep-learning algorithm, built upon the open-source CrazyFlie
2.0 nano-quadrotor. Our visual navigation engine is enabled by the combination
of an ultra-low power computing device (the GAP8 system-on-chip) with a novel
methodology for the deployment of deep convolutional neural networks (CNNs). We
enable onboard real-time execution of a state-of-the-art deep CNN at up to
18Hz. Field experiments demonstrate that the system's high responsiveness
prevents collisions with unexpected dynamic obstacles up to a flight speed of
1.5m/s. In addition, we also demonstrate the capability of our visual
navigation engine of fully autonomous indoor navigation on a 113m previously
unseen path. To share our key findings with the embedded and robotics
communities and foster further developments in autonomous nano-UAVs, we
publicly release all our code, datasets, and trained networks.
</dc:description>
 <dc:description>Comment: Accepted for publication in Proceeding of International Conference on
  Distributed Computing in Sensor Systems (DCOSS 2019). arXiv admin note: text
  overlap with arXiv:1805.01831</dc:description>
 <dc:date>2019-05-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1905.04166</dc:identifier>
 <dc:identifier>doi:10.1109/DCOSS.2019.00111</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.05490</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-malleability for quantum public-key encryption</dc:title>
 <dc:creator>Majenz, Christian</dc:creator>
 <dc:creator>Schaffner, Christian</dc:creator>
 <dc:creator>van Wier, Jeroen</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Non-malleability is an important security property for public-key encryption
(PKE). Its significance is due to the fundamental unachievability of integrity
and authenticity guarantees in this setting, rendering it the strongest
integrity-like property achievable using only PKE, without digital signatures.
In this work, we generalize this notion to the setting of quantum public-key
encryption. Overcoming the notorious &quot;recording barrier&quot; known from
generalizing other integrity-like security notions to quantum encryption, we
generalize one of the equivalent classical definitions, comparison-based
non-malleability, and show how it can be fulfilled. In addition, we explore
one-time non-malleability notions for symmetric-key encryption from the
literature by defining plaintext and ciphertext variants and by characterizing
their relation.
</dc:description>
 <dc:description>Comment: 29 pages</dc:description>
 <dc:date>2019-05-14</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1905.05490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.09916</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative Grading: Near Human-level Accuracy for Automated Feedback on
  Richly Structured Problems</dc:title>
 <dc:creator>Malik, Ali</dc:creator>
 <dc:creator>Wu, Mike</dc:creator>
 <dc:creator>Vasavada, Vrinda</dc:creator>
 <dc:creator>Song, Jinpeng</dc:creator>
 <dc:creator>Coots, Madison</dc:creator>
 <dc:creator>Mitchell, John</dc:creator>
 <dc:creator>Goodman, Noah</dc:creator>
 <dc:creator>Piech, Chris</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Access to high-quality education at scale is limited by the difficulty of
providing student feedback on open-ended assignments in structured domains like
computer programming, graphics, and short response questions. This problem has
proven to be exceptionally difficult: for humans, it requires large amounts of
manual work, and for computers, until recently, achieving anything near
human-level accuracy has been unattainable. In this paper, we present
generative grading: a novel computational approach for providing feedback at
scale that is capable of accurately grading student work and providing nuanced,
interpretable feedback. Our approach uses generative descriptions of student
cognition, written as probabilistic programs, to synthesise millions of
labelled example solutions to a problem; we then learn to infer feedback for
real student solutions based on this cognitive model.
  We apply our methods to three settings. In block-based coding, we achieve a
50% improvement upon the previous best results for feedback, achieving
super-human accuracy. In two other widely different domains -- graphical tasks
and short text answers -- we achieve major improvement over the previous state
of the art by about 4x and 1.5x respectively, approaching human accuracy. In a
real classroom, we ran an experiment where we used our system to augment human
graders, yielding doubled grading accuracy while halving grading time.
</dc:description>
 <dc:description>Comment: 10 pages of content</dc:description>
 <dc:date>2019-05-23</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1905.09916</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10661</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Locality-Promoting Representation Learning</dc:title>
 <dc:creator>Schneider, Johannes</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This work investigates fundamental questions related to learning features in
convolutional neural networks (CNN). Empirical findings across multiple
architectures such as VGG, ResNet, Inception, DenseNet and MobileNet indicate
that weights near the center of a filter are larger than weights on the
outside. Current regularization schemes violate this principle. Thus, we
introduce Locality-promoting Regularization (LOCO-Reg), which yields accuracy
gains across multiple architectures and datasets. We also show theoretically
that the empirical finding is a consequence of maximizing feature cohesion
under the assumption of spatial locality.
</dc:description>
 <dc:date>2019-05-25</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1905.10661</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1905.10825</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase Transitions in Bandits with Switching Constraints</dc:title>
 <dc:creator>Simchi-Levi, David</dc:creator>
 <dc:creator>Xu, Yunzong</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the classical stochastic multi-armed bandit problem with a
constraint that limits the total cost incurred by switching between actions to
be no larger than a given switching budget. For this problem, we prove matching
upper and lower bounds on the optimal (i.e., minimax) regret, and provide
efficient rate-optimal algorithms. Surprisingly, the optimal regret of this
problem exhibits a non-conventional growth rate in terms of the time horizon
and the number of arms. Consequently, we discover surprising &quot;phase
transitions&quot; regarding how the optimal regret rate changes with respect to the
switching budget: when the number of arms is fixed, there are equal-length
phases, where the optimal regret rate remains (almost) the same within each
phase and exhibits abrupt changes between phases; when the number of arms grows
with the time horizon, such abrupt changes become subtler and may disappear,
but a generalized notion of phase transitions involving certain new
measurements still exists. The results enable us to fully characterize the
trade-off between the regret rate and the incurred switching cost in the
stochastic multi-armed bandit problem, contributing new insights to this
fundamental problem. Under the general switching cost structure, the results
reveal interesting connections between bandit problems and graph traversal
problems, such as the shortest Hamiltonian path problem.
</dc:description>
 <dc:description>Comment: An enhanced version. Many new results are obtained. The presentation
  is improved</dc:description>
 <dc:date>2019-05-26</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1905.10825</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04072</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bayesian Model of Dose-Response for Cancer Drug Studies</dc:title>
 <dc:creator>Tansey, Wesley</dc:creator>
 <dc:creator>Tosh, Christopher</dc:creator>
 <dc:creator>Blei, David M.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  Exploratory cancer drug studies test multiple tumor cell lines against
multiple candidate drugs. The goal in each paired (cell line, drug) experiment
is to map out the dose-response curve of the cell line as the dose level of the
drug increases. We propose Bayesian Tensor Filtering (BTF), a hierarchical
Bayesian model for dose-response modeling in multi-sample, multi-treatment
cancer drug studies. BTF uses low-dimensional embeddings to share statistical
strength between similar drugs and similar cell lines. Structured shrinkage
priors in BTF encourage smoothness in the dose-response curves while remaining
adaptive to sharp jumps when the data call for it. We focus on a pair of cancer
drug studies exhibiting a particular pathology in their experimental design,
leading us to a non-conjugate monotone mixture-of-Gammas likelihood. To perform
posterior inference, we develop a variant of the elliptical slice sampling
algorithm for sampling from linearly-constrained multivariate normal priors
with non-conjugate likelihoods. In benchmarks, BTF outperforms state-of-the-art
methods for covariance regression and dynamic Poisson matrix factorization. On
the two cancer drug studies, BTF outperforms the current standard approach in
biology and reveals potential new biomarkers of drug sensitivity in cancer.
Code is available at https://github.com/tansey/functionalmf.
</dc:description>
 <dc:description>Comment: Extended to handle covariates; additional benchmarks comparing to
  related work</dc:description>
 <dc:date>2019-06-10</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1906.04072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.04410</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Random Numbers generated by the Cloud Superconducting Quantum
  Computer</dc:title>
 <dc:creator>Tamura, Kentaro</dc:creator>
 <dc:creator>Shikano, Yutaka</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>K.6.5</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>K.6.m</dc:subject>
 <dc:description>  A cloud quantum computer is similar to a random number generator in that its
physical mechanism is inaccessible to its users. In this respect, a cloud
quantum computer is a black box. In both devices, its users decide the device
condition from the output. A framework to achieve this exists in the field of
random number generation in the form of statistical tests for random number
generators. In the present study, we generated random numbers on a 20-qubit
cloud quantum computer and evaluated the condition and stability of its qubits
using statistical tests for random number generators. As a result, we observed
that some qubits were more biased than others. Statistical tests for random
number generators may provide a simple indicator of qubit condition and
stability, enabling users to decide for themselves which qubits inside a cloud
quantum computer to use.
</dc:description>
 <dc:description>Comment: 21 pages, 5 figures, submitted to the paper in Book &quot;Mathematics,
  Quantum Theory, and Cryptography&quot; Mathematics for Industry, Springer. In the
  revised manuscript, the results of the simulator with the noise parameters
  were added</dc:description>
 <dc:date>2019-06-11</dc:date>
 <dc:date>2019-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1906.04410</dc:identifier>
 <dc:identifier>International Symposium on Mathematics, Quantum Theory, and
  Cryptography, Mathematics for Industry, vol 33 (Springer, Singapore, 2021) 17
  -- 37</dc:identifier>
 <dc:identifier>doi:10.1007/978-981-15-5191-8_6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05675</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy-Preserving Deep Action Recognition: An Adversarial Learning
  Framework and A New Dataset</dc:title>
 <dc:creator>Wu, Zhenyu</dc:creator>
 <dc:creator>Wang, Haotao</dc:creator>
 <dc:creator>Wang, Zhaowen</dc:creator>
 <dc:creator>Jin, Hailin</dc:creator>
 <dc:creator>Wang, Zhangyang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We investigate privacy-preserving, video-based action recognition in deep
learning, a problem with growing importance in smart camera applications. A
novel adversarial training framework is formulated to learn an anonymization
transform for input videos such that the trade-off between target utility task
performance and the associated privacy budgets is explicitly optimized on the
anonymized videos. Notably, the privacy budget, often defined and measured in
task-driven contexts, cannot be reliably indicated using any single model
performance because strong protection of privacy should sustain against any
malicious model that tries to steal private information. To tackle this
problem, we propose two new optimization strategies of model restarting and
model ensemble to achieve stronger universal privacy protection against any
attacker models. Extensive experiments have been carried out and analyzed. On
the other hand, given few public datasets available with both utility and
privacy labels, the data-driven (supervised) learning cannot exert its full
power on this task. We first discuss an innovative heuristic of cross-dataset
training and evaluation, enabling the use of multiple single-task datasets (one
with target task labels and the other with privacy labels) in our problem. To
further address this dataset challenge, we have constructed a new dataset,
termed PA-HMDB51, with both target task labels (action) and selected privacy
attributes (skin color, face, gender, nudity, and relationship) annotated on a
per-frame basis. This first-of-its-kind video dataset and evaluation protocol
can greatly facilitate visual privacy research and open up other opportunities.
Our codes, models, and the PA-HMDB51 dataset are available at
https://github.com/VITA-Group/PA-HMDB51.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Transactions on Pattern Analysis and Machine
  Intelligence (TPAMI). arXiv admin note: text overlap with arXiv:1807.08379</dc:description>
 <dc:date>2019-06-11</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1906.05675</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.05928</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Video Interpolation Using Cycle Consistency</dc:title>
 <dc:creator>Reda, Fitsum A.</dc:creator>
 <dc:creator>Sun, Deqing</dc:creator>
 <dc:creator>Dundar, Aysegul</dc:creator>
 <dc:creator>Shoeybi, Mohammad</dc:creator>
 <dc:creator>Liu, Guilin</dc:creator>
 <dc:creator>Shih, Kevin J.</dc:creator>
 <dc:creator>Tao, Andrew</dc:creator>
 <dc:creator>Kautz, Jan</dc:creator>
 <dc:creator>Catanzaro, Bryan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Learning to synthesize high frame rate videos via interpolation requires
large quantities of high frame rate training videos, which, however, are
scarce, especially at high resolutions. Here, we propose unsupervised
techniques to synthesize high frame rate videos directly from low frame rate
videos using cycle consistency. For a triplet of consecutive frames, we
optimize models to minimize the discrepancy between the center frame and its
cycle reconstruction, obtained by interpolating back from interpolated
intermediate frames. This simple unsupervised constraint alone achieves results
comparable with supervision using the ground truth intermediate frames. We
further introduce a pseudo supervised loss term that enforces the interpolated
frames to be consistent with predictions of a pre-trained interpolation model.
The pseudo supervised loss term, used together with cycle consistency, can
effectively adapt a pre-trained model to a new target domain. With no
additional data and in a completely unsupervised fashion, our techniques
significantly improve pre-trained models on new target domains, increasing PSNR
values from 32.84dB to 33.05dB on the Slowflow and from 31.82dB to 32.53dB on
the Sintel evaluation datasets.
</dc:description>
 <dc:description>Comment: Published in ICCV 2019. Codes are available at
  https://github.com/NVIDIA/unsupervised-video-interpolation. Project website
  https://nv-adlr.github.io/publication/2019-UnsupervisedVideoInterpolation</dc:description>
 <dc:date>2019-06-13</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1906.05928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.06393</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Framework of Constrained Robust Submodular Optimization with
  Applications</dc:title>
 <dc:creator>Iyer, Rishabh</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Robust optimization is becoming increasingly important in machine learning
applications. In this paper, we study a unified framework of robust submodular
optimization. We study this problem both from a minimization and maximization
perspective (previous work has only focused on variants of robust submodular
maximization). We do this under a broad range of combinatorial constraints
including cardinality, knapsack, matroid as well as graph-based constraints
such as cuts, paths, matchings and trees. Furthermore, we also study robust
submodular minimization and maximization under multiple submodular upper and
lower bound constraints. We show that all these problems are motivated by
important machine learning applications including robust data subset selection,
robust co-operative cuts and robust co-operative matchings. In each case, we
provide scalable approximation algorithms and also study hardness bounds.
Finally, we empirically demonstrate the utility of our algorithms on synthetic
data, and real-world applications of robust cooperative matchings for image
correspondence, robust data subset selection for speech recognition, and image
collection summarization with multiple queries.
</dc:description>
 <dc:description>Comment: V2, Match 2021</dc:description>
 <dc:date>2019-06-14</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1906.06393</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08039</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Barron Space and the Flow-induced Function Spaces for Neural Network
  Models</dc:title>
 <dc:creator>E, Weinan</dc:creator>
 <dc:creator>Ma, Chao</dc:creator>
 <dc:creator>Wu, Lei</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  One of the key issues in the analysis of machine learning models is to
identify the appropriate function space and norm for the model. This is the set
of functions endowed with a quantity which can control the approximation and
estimation errors by a particular machine learning model. In this paper, we
address this issue for two representative neural network models: the two-layer
networks and the residual neural networks. We define the Barron space and show
that it is the right space for two-layer neural network models in the sense
that optimal direct and inverse approximation theorems hold for functions in
the Barron space. For residual neural network models, we construct the
so-called flow-induced function space, and prove direct and inverse
approximation theorems for this space. In addition, we show that the Rademacher
complexity for bounded sets under these norms has the optimal upper bounds.
</dc:description>
 <dc:date>2019-06-18</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1906.08039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.08107</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constrained Bilinear Factorization Multi-view Subspace Clustering</dc:title>
 <dc:creator>Zheng, Qinghai</dc:creator>
 <dc:creator>Zhu, Jihua</dc:creator>
 <dc:creator>Tian, Zhiqiang</dc:creator>
 <dc:creator>Li, Zhongyu</dc:creator>
 <dc:creator>Pang, Shanmin</dc:creator>
 <dc:creator>Jia, Xiuyi</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Multi-view clustering is an important and fundamental problem. Many
multi-view subspace clustering methods have been proposed, and most of them
assume that all views share a same coefficient matrix. However, the underlying
information of multi-view data are not fully exploited under this assumption,
since the coefficient matrices of different views should have the same
clustering properties rather than be uniform among multiple views. To this end,
this paper proposes a novel Constrained Bilinear Factorization Multi-view
Subspace Clustering (CBF-MSC) method. Specifically, the bilinear factorization
with an orthonormality constraint and a low-rank constraint is imposed for all
coefficient matrices to make them have the same trace-norm instead of being
equivalent, so as to explore the consensus information of multi-view data more
fully. Finally, an Augmented Lagrangian Multiplier (ALM) based algorithm is
designed to optimize the objective function. Comprehensive experiments tested
on nine benchmark datasets validate the effectiveness and competitiveness of
the proposed approach compared with several state-of-the-arts.
</dc:description>
 <dc:date>2019-06-19</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1906.08107</dc:identifier>
 <dc:identifier>doi:10.1016/j.knosys.2020.105514</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09222</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Versatile linkage: a family of space-conserving strategies for
  agglomerative hierarchical clustering</dc:title>
 <dc:creator>Fern&#xe1;ndez, Alberto</dc:creator>
 <dc:creator>G&#xf3;mez, Sergio</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Agglomerative hierarchical clustering can be implemented with several
strategies that differ in the way elements of a collection are grouped together
to build a hierarchy of clusters. Here we introduce versatile linkage, a new
infinite system of agglomerative hierarchical clustering strategies based on
generalized means, which go from single linkage to complete linkage, passing
through arithmetic average linkage and other clustering methods yet unexplored
such as geometric linkage and harmonic linkage. We compare the different
clustering strategies in terms of cophenetic correlation, mean absolute error,
and also tree balance and space distortion, two new measures proposed to
describe hierarchical trees. Unlike the $\beta$-flexible clustering system, we
show that the versatile linkage family is space-conserving.
</dc:description>
 <dc:description>Comment: To appear in Journal of Classification. Software for Versatile
  linkage available at http://deim.urv.cat/~sergio.gomez/multidendrograms.php</dc:description>
 <dc:date>2019-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1906.09222</dc:identifier>
 <dc:identifier>Journal of Classification 37 (2020) 584-597</dc:identifier>
 <dc:identifier>doi:10.1007/s00357-019-09339-z</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.09864</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When is the best time to learn? -- Evidence from an introductory
  statistics course</dc:title>
 <dc:creator>Massing, Till</dc:creator>
 <dc:creator>Reckmann, Natalie</dc:creator>
 <dc:creator>Blasberg, Alexander</dc:creator>
 <dc:creator>Otto, Benjamin</dc:creator>
 <dc:creator>Hanck, Christoph</dc:creator>
 <dc:creator>Goedicke, Michael</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  We analyze learning data of an e-assessment platform for an introductory
mathematical statistics course, more specifically the time of the day when
students learn. We propose statistical models to predict students' success and
to describe their behavior with a special focus on the following aspects.
First, we find that learning during daytime and not at nighttime is a relevant
variable for predicting success in final exams. Second, we observe that good
and very good students tend to learn in the afternoon, while some students who
failed our course were more likely to study at night but not successfully so.
Third, we discuss the average time spent on exercises. Regarding this, students
who participated in an exam spent more time doing exercises than students who
dropped the course before.
</dc:description>
 <dc:date>2019-06-24</dc:date>
 <dc:date>2021-02-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1906.09864</dc:identifier>
 <dc:identifier>doi:10.1515/edu-2020-0144</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1906.11828</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integration of adversarial autoencoders with residual dense
  convolutional networks for estimation of non-Gaussian hydraulic
  conductivities</dc:title>
 <dc:creator>Mo, Shaoxing</dc:creator>
 <dc:creator>Zabaras, Nicholas</dc:creator>
 <dc:creator>Shi, Xiaoqing</dc:creator>
 <dc:creator>Wu, Jichun</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Inverse modeling for the estimation of non-Gaussian hydraulic conductivity
fields in subsurface flow and solute transport models remains a challenging
problem. This is mainly due to the non-Gaussian property, the non-linear
physics, and the fact that many repeated evaluations of the forward model are
often required. In this study, we develop a convolutional adversarial
autoencoder (CAAE) to parameterize non-Gaussian conductivity fields with
heterogeneous conductivity within each facies using a low-dimensional latent
representation. In addition, a deep residual dense convolutional network
(DRDCN) is proposed for surrogate modeling of forward models with
high-dimensional and highly-complex mappings. The two networks are both based
on a multilevel residual learning architecture called residual-in-residual
dense block. The multilevel residual learning strategy and the dense connection
structure ease the training of deep networks, enabling us to efficiently build
deeper networks that have an essentially increased capacity for approximating
mappings of very high-complexity. The CCAE and DRDCN networks are incorporated
into an iterative ensemble smoother to formulate an inversion framework. The
numerical experiments performed using 2-D and 3-D solute transport models
illustrate the performance of the integrated method. The obtained results
indicate that the CAAE is a robust parameterization method for non-Gaussian
conductivity fields with different heterogeneity patterns. The DRDCN is able to
obtain accurate approximations of the forward models with high-dimensional and
highly-complex mappings using relatively limited training data. The CAAE and
DRDCN methods together significantly reduce the computation time required to
achieve accurate inversion results.
</dc:description>
 <dc:date>2019-06-26</dc:date>
 <dc:date>2020-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1906.11828</dc:identifier>
 <dc:identifier>doi:10.1029/2019WR026082</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.00304</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonstationary Gauss-Markov Processes: Parameter Estimation and
  Dispersion</dc:title>
 <dc:creator>Tian, Peida</dc:creator>
 <dc:creator>Kostina, Victoria</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  This paper provides a precise error analysis for the maximum likelihood
estimate $\hat{a}_{\text{ML}}(u_1^n)$ of the parameter $a$ given samples $u_1^n
= (u_1, \ldots, u_n)'$ drawn from a nonstationary Gauss-Markov process $U_i = a
U_{i-1} + Z_i,~i\geq 1$, where $U_0 = 0$, $a&gt; 1$, and $Z_i$'s are independent
Gaussian random variables with zero mean and variance $\sigma^2$. We show a
tight nonasymptotic exponentially decaying bound on the tail probability of the
estimation error. Unlike previous works, our bound is tight already for a
sample size of the order of hundreds. We apply the new estimation bound to find
the dispersion for lossy compression of nonstationary Gauss-Markov sources. We
show that the dispersion is given by the same integral formula that we derived
previously for the asymptotically stationary Gauss-Markov sources, i.e., $|a| &lt;
1$. New ideas in the nonstationary case include separately bounding the maximum
eigenvalue (which scales exponentially) and the other eigenvalues (which are
bounded by constants that depend only on $a$) of the covariance matrix of the
source sequence, and new techniques in the derivation of our estimation error
bound.
</dc:description>
 <dc:description>Comment: 25 pages, 5 figures</dc:description>
 <dc:date>2019-06-29</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1907.00304</dc:identifier>
 <dc:identifier>in IEEE Transactions on Information Theory, vol. 67, no. 4, pp.
  2426-2449, April 2021</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2021.3050342</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.02206</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Mixed-Integer Optimization in Milliseconds</dc:title>
 <dc:creator>Bertsimas, Dimitris</dc:creator>
 <dc:creator>Stellato, Bartolomeo</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We propose a method to solve online mixed-integer optimization (MIO) problems
at very high speed using machine learning. By exploiting the repetitive nature
of online optimization, we are able to greatly speedup the solution time. Our
approach encodes the optimal solution into a small amount of information
denoted as strategy using the Voice of Optimization framework proposed in
[BS21]. In this way the core part of the optimization algorithm becomes a
multiclass classification problem which can be solved very quickly. In this
work, we extend that framework to real-time and high-speed applications
focusing on parametric mixed-integer quadratic optimization (MIQO). We propose
an extremely fast online optimization algorithm consisting of a feedforward
neural network (NN) evaluation and a linear system solution where the matrix
has already been factorized. Therefore, this online approach does not require
any solver nor iterative algorithm. We show the speed of the proposed method
both in terms of total computations required and measured execution time. We
estimate the number of floating point operations (flops) required to completely
recover the optimal solution as a function of the problem dimensions. Compared
to state-of-the-art MIO routines, the online running time of our method is very
predictable and can be lower than a single matrix factorization time. We
benchmark our method against the state-of-the-art solver Gurobi obtaining from
two to three orders of magnitude speedups on examples from fuel cell energy
management, sparse portfolio optimization and motion planning with obstacle
avoidance.
</dc:description>
 <dc:date>2019-07-03</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1907.02206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.05980</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence Analysis of Machine Learning Algorithms for the Numerical
  Solution of Mean Field Control and Games: I -- The Ergodic Case</dc:title>
 <dc:creator>Carmona, Ren&#xe9;</dc:creator>
 <dc:creator>Lauri&#xe8;re, Mathieu</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We propose two algorithms for the solution of the optimal control of ergodic
McKean-Vlasov dynamics. Both algorithms are based on approximations of the
theoretical solutions by neural networks, the latter being characterized by
their architecture and a set of parameters. This allows the use of modern
machine learning tools, and efficient implementations of stochastic gradient
descent.The first algorithm is based on the idiosyncrasies of the ergodic
optimal control problem. We provide a mathematical proof of the convergence of
the approximation scheme, and we analyze rigorously the approximation by
controlling the different sources of error. The second method is an adaptation
of the deep Galerkin method to the system of partial differential equations
issued from the optimality condition. We demonstrate the efficiency of these
algorithms on several numerical examples, some of them being chosen to show
that our algorithms succeed where existing ones failed. We also argue that both
methods can easily be applied to problems in dimensions larger than what can be
found in the existing literature. Finally, we illustrate the fact that,
although the first algorithm is specifically designed for mean field control
problems, the second one is more general and can also be applied to the partial
differential equation systems arising in the theory of mean field games.
</dc:description>
 <dc:date>2019-07-12</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1907.05980</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.06157</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Software Development with Feature Toggles: Practices used by
  Practitioners</dc:title>
 <dc:creator>Mahdavi-Hezaveh, Rezvan</dc:creator>
 <dc:creator>Dremann, Jacob</dc:creator>
 <dc:creator>Williams, Laurie</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Background: Using feature toggles is a technique that allows developers to
either turn a feature on or off with a variable in a conditional statement.
Feature toggles are increasingly used by software companies to facilitate
continuous integration and continuous delivery. However, using feature toggles
inappropriately may cause problems which can have a severe impact, such as code
complexity, dead code, and system failure. For example, the erroneous
repurposing of an old feature toggle caused Knight Capital Group, an American
global financial services firm, to go bankrupt due to the implications of the
resultant incorrect system behavior. Aim: The goal of this research project is
to aid software practitioners in the use of practices to support software
development with feature toggles through an empirical study of feature toggle
practice usage by practitioners. Method: We conducted a qualitative analysis of
99 artifacts from the grey literature and 10 peer-reviewed papers about feature
toggles. We conducted a survey of practitioners from 38 companies. Results: We
identified 17 practices in 4 categories: Management practices, Initialization
practices, Implementation practices, and Clean-up practices. We observed that
all of the survey respondents use a dedicated tool to create and manage feature
toggles in their code. Documenting feature toggle's metadata, setting up the
default value for feature toggles, and logging the changes made on feature
toggles are also frequently-observed practices. Conclusions: The feature toggle
development practices discovered and enumerated in this work can help
practitioners more effectively use feature toggles. This work can enable future
mining of code repositories to automatically identify feature toggle practices.
</dc:description>
 <dc:description>Comment: Paper submitted to Empirical Software Engineering Journal</dc:description>
 <dc:date>2019-07-13</dc:date>
 <dc:date>2020-03-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1907.06157</dc:identifier>
 <dc:identifier>doi:10.1007/s10664-020-09901-z</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.07020</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quasipolynomial Computation of Nested Fixpoints</dc:title>
 <dc:creator>Hausmann, Daniel</dc:creator>
 <dc:creator>Schr&#xf6;der, Lutz</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  It is well-known that the winning region of a parity game with $n$ nodes and
$k$ priorities can be computed as a $k$-nested fixpoint of a suitable function;
straightforward computation of this nested fixpoint requires
$\mathcal{O}(n^{\frac{k}{2}})$ iterations of the function. Calude et al.'s
recent quasipolynomial-time parity game solving algorithm essentially shows how
to compute the same fixpoint in only quasipolynomially many iterations by
reducing parity games to quasipolynomially sized safety games. Universal graphs
have been used to modularize this transformation of parity games to equivalent
safety games that are obtained by combining the original game with a universal
graph. We show that this approach naturally generalizes to the computation of
solutions of systems of \emph{any} fixpoint equations over finite lattices;
hence, the solution of fixpoint equation systems can be computed by
quasipolynomially many iterations of the equations. We present applications to
modal fixpoint logics and games beyond relational semantics. For instance, the
model checking problems for the energy $\mu$-calculus, finite latticed
$\mu$-calculi, and the graded and the (two-valued) probabilistic $\mu$-calculus
-- with numbers coded in binary -- can be solved via nested fixpoints of
functions that differ substantially from the function for parity games but
still can be computed in quasipolynomial time; our result hence implies that
model checking for these $\mu$-calculi is in QP. Moreover, we improve the
exponent in known exponential bounds on satisfiability checking.
</dc:description>
 <dc:description>Comment: extended version of conference paper</dc:description>
 <dc:date>2019-07-16</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1907.07020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.08697</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast approximation of orthogonal matrices and application to PCA</dc:title>
 <dc:creator>Rusu, Cristian</dc:creator>
 <dc:creator>Rosasco, Lorenzo</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the problem of approximating orthogonal matrices so that their
application is numerically fast and yet accurate. We find an approximation by
solving an optimization problem over a set of structured matrices, that we call
extended orthogonal Givens transformations, including Givens rotations as a
special case. We propose an efficient greedy algorithm to solve such a problem
and show that it strikes a balance between approximation accuracy and speed of
computation. The approach is relevant to spectral methods and we illustrate its
application to PCA.
</dc:description>
 <dc:date>2019-07-18</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1907.08697</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.09439</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model-Driven Deep Learning for MIMO Detection</dc:title>
 <dc:creator>He, Hengtao</dc:creator>
 <dc:creator>Wen, Chao-Kai</dc:creator>
 <dc:creator>Jin, Shi</dc:creator>
 <dc:creator>Li, Geoffrey Ye</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  In this paper, we investigate the model-driven deep learning (DL) for MIMO
detection. In particular, the MIMO detector is specially designed by unfolding
an iterative algorithm and adding some trainable parameters. Since the number
of trainable parameters is much fewer than the data-driven DL based signal
detector, the model-driven DL based MIMO detector can be rapidly trained with a
much smaller data set. The proposed MIMO detector can be extended to soft-input
soft-output detection easily. Furthermore, we investigate joint MIMO channel
estimation and signal detection (JCESD), where the detector takes channel
estimation error and channel statistics into consideration while channel
estimation is refined by detected data and considers the detection error. Based
on numerical results, the model-driven DL based MIMO detector significantly
improves the performance of corresponding traditional iterative detector,
outperforms other DL-based MIMO detectors and exhibits superior robustness to
various mismatches.
</dc:description>
 <dc:description>Comment: This paper has been published on the IEEE Trans. Signal Process. The
  code is available at https://github.com/hehengtao/OAMP-Net</dc:description>
 <dc:date>2019-07-22</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1907.09439</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2020.2976585</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1907.12403</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stabilizability of Markov jump linear systems modeling wireless
  networked control scenarios (extended version)</dc:title>
 <dc:creator>Lun, Yuriy Zacchia</dc:creator>
 <dc:creator>D'Innocenzo, Alessandro</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  The communication channels used to convey information between the components
of wireless networked control systems (WNCSs) are subject to packet losses due
to time-varying fading and interference. The WNCSs with missing packets can be
modeled as Markov jump linear systems with one time-step delayed mode
observations. While the problem of the optimal linear quadratic regulation for
such systems has been already solved, we derive the necessary and sufficient
conditions for stabilizability. We also show, with an example considering a
communication channel model based on WirelessHART (a on-the-market wireless
communication standard specifically designed for process automation), that such
conditions are essential to the analysis of WNCSs where packet losses are
modeled with Bernoulli random variables representing the expected value of the
real random process governing the channel.
</dc:description>
 <dc:description>Comment: Extended version of the paper accepted for the presentation at the
  58th IEEE Conference on Decision and Control (CDC 2019)</dc:description>
 <dc:date>2019-07-29</dc:date>
 <dc:date>2019-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1907.12403</dc:identifier>
 <dc:identifier>doi:10.1109/CDC40024.2019.9029202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00041</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FaVeST: Fast Vector Spherical Harmonic Transforms</dc:title>
 <dc:creator>Gia, Quoc T. Le</dc:creator>
 <dc:creator>Li, Ming</dc:creator>
 <dc:creator>Wang, Yu Guang</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>65T50, 37C10, 33C55, 65D30</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:subject>G.1.4</dc:subject>
 <dc:subject>G.1.2</dc:subject>
 <dc:description>  Vector spherical harmonics on the unit sphere of $\mathbb{R}^3$ have broad
applications in geophysics, quantum mechanics and astrophysics. In the
representation of a tangent vector field, one needs to evaluate the expansion
and the Fourier coefficients of vector spherical harmonics. In this paper, we
develop fast algorithms (FaVeST) for vector spherical harmonic transforms on
these evaluations. The forward FaVeST evaluates the Fourier coefficients and
has a computational cost proportional to $N\log \sqrt{N}$ for $N$ number of
evaluation points. The adjoint FaVeST which evaluates a linear combination of
vector spherical harmonics with a degree up to $\sqrt{M}$ for $M$ evaluation
points has cost proportional to $M\log\sqrt{M}$. Numerical examples of
simulated tangent fields illustrate the accuracy, efficiency and stability of
FaVeST.
</dc:description>
 <dc:description>Comment: 23 pages, 6 figures, 3 tables</dc:description>
 <dc:date>2019-07-31</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1908.00041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.00209</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A computational EXFOR database</dc:title>
 <dc:creator>Schnabel, Georg</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Nuclear Experiment</dc:subject>
 <dc:subject>Nuclear Theory</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  The EXFOR library is a useful resource for many people in the field of
nuclear physics. In particular, the experimental data in the EXFOR library
serves as a starting point for nuclear data evaluations. There is an ongoing
discussion about how to make evaluations more transparent and reproducible. One
important ingredient may be convenient programmatic access to the data in the
EXFOR library from high-level languages. To this end, the complete EXFOR
library can be converted to a MongoDB database. This database can be
conveniently searched and accessed from a wide variety of programming
languages, such as C++, Python, Java, Matlab, and R. This contribution provides
some details about the successful conversion of the EXFOR library to a MongoDB
database and shows simple usage examples to underline its merits. All codes
required for the conversion have been made available online and are
open-source. In addition, a Dockerfile has been created to facilitate the
installation process.
</dc:description>
 <dc:description>Comment: 4 pages, ND2019 conference</dc:description>
 <dc:date>2019-08-01</dc:date>
 <dc:date>2020-05-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1908.00209</dc:identifier>
 <dc:identifier>EPJ Web of Conferences 239, 16001 (2020)</dc:identifier>
 <dc:identifier>doi:10.1051/epjconf/202023916001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01259</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attentive Normalization</dc:title>
 <dc:creator>Li, Xilai</dc:creator>
 <dc:creator>Sun, Wei</dc:creator>
 <dc:creator>Wu, Tianfu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In state-of-the-art deep neural networks, both feature normalization and
feature attention have become ubiquitous. % with significant performance
improvement shown in a vast amount of tasks. They are usually studied as
separate modules, however. In this paper, we propose a light-weight integration
between the two schema and present Attentive Normalization (AN). Instead of
learning a single affine transformation, AN learns a mixture of affine
transformations and utilizes their weighted-sum as the final affine
transformation applied to re-calibrate features in an instance-specific way.
The weights are learned by leveraging channel-wise feature attention. In
experiments, we test the proposed AN using four representative neural
architectures in the ImageNet-1000 classification benchmark and the MS-COCO
2017 object detection and instance segmentation benchmark. AN obtains
consistent performance improvement for different neural architectures in both
benchmarks with absolute increase of top-1 accuracy in ImageNet-1000 between
0.5\% and 2.7\%, and absolute increase up to 1.8\% and 2.2\% for bounding box
and mask AP in MS-COCO respectively. We observe that the proposed AN provides a
strong alternative to the widely used Squeeze-and-Excitation (SE) module. The
source codes are publicly available at https://github.com/iVMCL/AOGNet-v2 (the
ImageNet Classification Repo) and
https://github.com/iVMCL/AttentiveNorm\_Detection (the MS-COCO Detection and
Segmentation Repo).
</dc:description>
 <dc:description>Comment: ECCV2020</dc:description>
 <dc:date>2019-08-03</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1908.01259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.01293</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>To Learn or Not to Learn: Visual Localization from Essential Matrices</dc:title>
 <dc:creator>Zhou, Qunjie</dc:creator>
 <dc:creator>Sattler, Torsten</dc:creator>
 <dc:creator>Pollefeys, Marc</dc:creator>
 <dc:creator>Leal-Taixe, Laura</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Visual localization is the problem of estimating a camera within a scene and
a key component in computer vision applications such as self-driving cars and
Mixed Reality. State-of-the-art approaches for accurate visual localization use
scene-specific representations, resulting in the overhead of constructing these
models when applying the techniques to new scenes. Recently, deep
learning-based approaches based on relative pose estimation have been proposed,
carrying the promise of easily adapting to new scenes. However, it has been
shown such approaches are currently significantly less accurate than
state-of-the-art approaches. In this paper, we are interested in analyzing this
behavior. To this end, we propose a novel framework for visual localization
from relative poses. Using a classical feature-based approach within this
framework, we show state-of-the-art performance. Replacing the classical
approach with learned alternatives at various levels, we then identify the
reasons for why deep learned approaches do not perform well. Based on our
analysis, we make recommendations for future work.
</dc:description>
 <dc:description>Comment: Accepted to ICRA 2020</dc:description>
 <dc:date>2019-08-04</dc:date>
 <dc:date>2020-03-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1908.01293</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04653</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multilayer Modularity Belief Propagation To Assess Detectability Of
  Community Structure</dc:title>
 <dc:creator>Weir, William H.</dc:creator>
 <dc:creator>Walker, Benjamin</dc:creator>
 <dc:creator>Zdeborov&#xe1;, Lenka</dc:creator>
 <dc:creator>Mucha, Peter J.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Modularity based community detection encompasses a number of widely used,
efficient heuristics for identification of structure in networks. Recently, a
belief propagation approach to modularity optimization provided a useful guide
for identifying non-trivial structure in single-layer networks in a way that
other optimization heuristics have not. In this paper, we extend modularity
belief propagation to multilayer networks. As part of this development, we also
directly incorporate a resolution parameter. We show that adjusting the
resolution parameter affects the convergence properties of the algorithm and
yields different community structures than the baseline. We compare our
approach with a widely used community detection tool, GenLouvain, across a
range of synthetic, multilayer benchmark networks, demonstrating that our
method performs comparably to the state of the art. Finally, we demonstrate the
practical advantages of the additional information provided by our tool by way
of two real-world network examples. We show how the convergence properties of
the algorithm can be used in selecting the appropriate resolution and coupling
parameters and how the node-level marginals provide an interpretation for the
strength of attachment to the identified communities. We have released our tool
as a Python package for convenient use.
</dc:description>
 <dc:date>2019-08-13</dc:date>
 <dc:date>2020-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1908.04653</dc:identifier>
 <dc:identifier>SIAM Journal on Mathematics of Data Science 2 (3), 872-900 (2020)</dc:identifier>
 <dc:identifier>doi:10.1137/19M1279812</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.04734</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reward Tampering Problems and Solutions in Reinforcement Learning: A
  Causal Influence Diagram Perspective</dc:title>
 <dc:creator>Everitt, Tom</dc:creator>
 <dc:creator>Hutter, Marcus</dc:creator>
 <dc:creator>Kumar, Ramana</dc:creator>
 <dc:creator>Krakovna, Victoria</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Can humans get arbitrarily capable reinforcement learning (RL) agents to do
their bidding? Or will sufficiently capable RL agents always find ways to
bypass their intended objectives by shortcutting their reward signal? This
question impacts how far RL can be scaled, and whether alternative paradigms
must be developed in order to build safe artificial general intelligence. In
this paper, we study when an RL agent has an instrumental goal to tamper with
its reward process, and describe design principles that prevent instrumental
goals for two different types of reward tampering (reward function tampering
and RF-input tampering). Combined, the design principles can prevent both types
of reward tampering from being instrumental goals. The analysis benefits from
causal influence diagrams to provide intuitive yet precise formalizations.
</dc:description>
 <dc:description>Comment: Accepted to Synthese, March 2021</dc:description>
 <dc:date>2019-08-13</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1908.04734</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.05425</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PS^2-Net: A Locally and Globally Aware Network for Point-Based Semantic
  Segmentation</dc:title>
 <dc:creator>Zhao, Na</dc:creator>
 <dc:creator>Chua, Tat-Seng</dc:creator>
 <dc:creator>Lee, Gim Hee</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we present the PS^2-Net -- a locally and globally aware deep
learning framework for semantic segmentation on 3D scene-level point clouds. In
order to deeply incorporate local structures and global context to support 3D
scene segmentation, our network is built on four repeatedly stacked encoders,
where each encoder has two basic components: EdgeConv that captures local
structures and NetVLAD that models global context. Different from existing
start-of-the-art methods for point-based scene semantic segmentation that
either violate or do not achieve permutation invariance, our PS^2-Net is
designed to be permutation invariant which is an essential property of any deep
network used to process unordered point clouds. We further provide theoretical
proof to guarantee the permutation invariance property of our network. We
perform extensive experiments on two large-scale 3D indoor scene datasets and
demonstrate that our PS2-Net is able to achieve state-of-the-art performances
as compared to existing approaches.
</dc:description>
 <dc:date>2019-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1908.05425</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-030-68787-8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07247</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An efficient bounded-variable nonlinear least-squares algorithm for
  embedded MPC</dc:title>
 <dc:creator>Saraf, Nilay</dc:creator>
 <dc:creator>Bemporad, Alberto</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents a new approach to solve linear and nonlinear model
predictive control (MPC) problems that requires small memory footprint and
throughput and is particularly suitable when the model and/or controller
parameters change at runtime. Typically MPC requires two phases: 1) construct
an optimization problem based on the given MPC parameters (prediction model,
tuning weights, prediction horizon, and constraints), which results in a
quadratic or nonlinear programming problem, and then 2) call an optimization
algorithm to solve the resulting problem. In the proposed approach the problem
construction step is systematically eliminated, as in the optimization
algorithm problem matrices are expressed in terms of abstract functions of the
MPC parameters. We present a unifying algorithmic framework based on active-set
methods with bounded variables that can cope with linear, nonlinear, and
adaptive MPC variants based on a broad class of prediction models and a
sum-of-squares cost function. The theoretical and numerical results demonstrate
the potential, applicability, and efficiency of the proposed framework for
practical real-time embedded MPC.
</dc:description>
 <dc:date>2019-08-20</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1908.07247</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.07753</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GeoBlocks: A Query-Cache Accelerated Data Structure for Spatial
  Aggregation over Polygons</dc:title>
 <dc:creator>Winter, Christian</dc:creator>
 <dc:creator>Kipf, Andreas</dc:creator>
 <dc:creator>Anneser, Christoph</dc:creator>
 <dc:creator>Zacharatou, Eleni Tzirita</dc:creator>
 <dc:creator>Neumann, Thomas</dc:creator>
 <dc:creator>Kemper, Alfons</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  As individual traffic and public transport in cities are changing, city
authorities need to analyze urban geospatial data to improve transportation and
infrastructure. To that end, they highly rely on spatial aggregation queries
that extract summarized information from point data (e.g., Uber rides)
contained in a given polygonal region (e.g., a city neighborhood). To support
such queries, current analysis tools either allow only predefined aggregates on
predefined regions and are thus unsuitable for exploratory analyses, or access
the raw data to compute aggregate results on-the-fly, which severely limits the
interactivity. At the same time, existing pre-aggregation techniques are
inadequate since they maintain aggregates over rectangular regions. As a
result, when applied over arbitrary polygonal regions, they induce an
approximation error that cannot be bounded. In this paper, we introduce
GeoBlocks, a novel pre-aggregating data structure that supports spatial
aggregation over arbitrary polygons. GeoBlocks closely approximate polygons
using a set of fine-grained grid cells and, in contrast to prior work, allow to
bound the approximation error by adjusting the cell size. Furthermore,
GeoBlocks employ a trie-like cache that caches aggregate results of frequently
queried regions, thereby dynamically adapting to the skew inherently present in
query workloads and improving performance over time. In summary, GeoBlocks
outperform on-the-fly aggregation by up to three orders of magnitude, achieving
the sub-second query latencies required for interactive exploratory analytics.
</dc:description>
 <dc:description>Comment: Accepted at EDBT 2021, please cite the EDBT version</dc:description>
 <dc:date>2019-08-21</dc:date>
 <dc:date>2021-03-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1908.07753</dc:identifier>
 <dc:identifier>doi:10.5441/002/edbt.2021.16</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.08616</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quadratic Surface Support Vector Machine with L1 Norm Regularization</dc:title>
 <dc:creator>Mousavi, Ahmad</dc:creator>
 <dc:creator>Gao, Zheming</dc:creator>
 <dc:creator>Han, Lanshan</dc:creator>
 <dc:creator>Lim, Alvin</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose $\ell_1$ norm regularized quadratic surface support vector machine
models for binary classification in supervised learning. We establish their
desired theoretical properties, including the existence and uniqueness of the
optimal solution, reduction to the standard SVMs over (almost) linearly
separable data sets, and detection of true sparsity pattern over (almost)
quadratically separable data sets if the penalty parameter of $\ell_1$ norm is
large enough. We also demonstrate their promising practical efficiency by
conducting various numerical experiments on both synthetic and publicly
available benchmark data sets.
</dc:description>
 <dc:date>2019-08-22</dc:date>
 <dc:date>2021-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1908.08616</dc:identifier>
 <dc:identifier>doi:10.3934/jimo.2021046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.09961</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Theory and Evaluation Metrics for Learning Disentangled Representations</dc:title>
 <dc:creator>Do, Kien</dc:creator>
 <dc:creator>Tran, Truyen</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We make two theoretical contributions to disentanglement learning by (a)
defining precise semantics of disentangled representations, and (b)
establishing robust metrics for evaluation. First, we characterize the concept
&quot;disentangled representations&quot; used in supervised and unsupervised methods
along three dimensions-informativeness, separability and interpretability -
which can be expressed and quantified explicitly using information-theoretic
constructs. This helps explain the behaviors of several well-known
disentanglement learning models. We then propose robust metrics for measuring
informativeness, separability and interpretability. Through a comprehensive
suite of experiments, we show that our metrics correctly characterize the
representations learned by different methods and are consistent with
qualitative (visual) results. Thus, the metrics allow disentanglement learning
methods to be compared on a fair ground. We also empirically uncovered new
interesting properties of VAE-based methods and interpreted them with our
formulation. These findings are promising and hopefully will encourage the
design of more theoretically driven models for learning disentangled
representations.
</dc:description>
 <dc:date>2019-08-26</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1908.09961</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10481</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>K-CONFIG: Using Failing Test Cases to Generate Test Cases in GCC
  Compilers</dc:title>
 <dc:creator>Rabin, Md Rafiqul Islam</dc:creator>
 <dc:creator>Alipour, Mohammad Amin</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  The correctness of compilers is instrumental in the safety and reliability of
other software systems, as bugs in compilers can produce programs that do not
reflect the intents of programmers. Compilers are complex software systems due
to the complexity of optimization. GCC is an optimizing C compiler that has
been used in building operating systems and many other system software. In this
paper, we describe K-CONFIG, an approach that uses the bugs reported in the GCC
repository to generate new test inputs. Our main insight is that the features
appearing in the bug reports are likely to reappear in the future bugs, as the
bugfixes can be incomplete or those features may be inherently challenging to
implement hence more prone to errors. Our approach first clusters the failing
test input extracted from the bug reports into clusters of similar test inputs.
It then uses these clusters to create configurations for Csmith, the most
popular test generator for C compilers. In our experiments on two versions of
GCC, our approach could trigger up to 36 miscompilation failures, and 179
crashes, while Csmith with the default configuration did not trigger any
failures. This work signifies the benefits of analyzing and using the reported
bugs in the generation of new test inputs.
</dc:description>
 <dc:description>Comment: ASE 2019 Late Breaking Results</dc:description>
 <dc:date>2019-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1908.10481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1908.10711</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Testing Neural Program Analyzers</dc:title>
 <dc:creator>Rabin, Md Rafiqul Islam</dc:creator>
 <dc:creator>Wang, Ke</dc:creator>
 <dc:creator>Alipour, Mohammad Amin</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep neural networks have been increasingly used in software engineering and
program analysis tasks. They usually take a program and make some predictions
about it, e.g., bug prediction. We call these models neural program analyzers.
The reliability of neural programs can impact the reliability of the
encompassing analyses. In this paper, we describe our ongoing efforts to
develop effective techniques for testing neural programs. We discuss the
challenges involved in developing such tools and our future plans. In our
preliminary experiment on a neural model recently proposed in the literature,
we found that the model is very brittle, and simple perturbations in the input
can cause the model to make mistakes in its prediction.
</dc:description>
 <dc:description>Comment: ASE 2019 Late Breaking Results</dc:description>
 <dc:date>2019-08-25</dc:date>
 <dc:date>2019-09-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1908.10711</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.00526</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Abstraction-Free Method for Multi-Robot Temporal Logic Optimal
  Control Synthesis</dc:title>
 <dc:creator>Luo, Xusheng</dc:creator>
 <dc:creator>Kantaros, Yiannis</dc:creator>
 <dc:creator>Zavlanos, Michael M.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The majority of existing Linear Temporal Logic (LTL) planning methods rely on
the construction of a discrete product automaton, that combines a discrete
abstraction of robot mobility and a B$\ddot{\text{u}}$chi automaton that
captures the LTL specification. Representing this product automaton as a graph
and using graph search techniques, optimal plans that satisfy the LTL task can
be synthesized. However, constructing expressive discrete abstractions makes
the synthesis problem computationally intractable. In this paper, we propose a
new sampling-based LTL planning algorithm that does not require any discrete
abstraction of robot mobility. Instead, it incrementally builds trees that
explore the product state-space, until a maximum number of iterations is
reached or a feasible plan is found. The use of trees makes data storage and
graph search tractable, which significantly increases the scalability of our
algorithm. To accelerate the construction of feasible plans, we introduce bias
in the sampling process which is guided by transitions in the
B$\ddot{\text{u}}$chi automaton that belong to the shortest path to the
accepting states. We show that our planning algorithm, with and without bias,
is probabilistically complete and asymptotically optimal. Finally, we present
numerical experiments showing that our method outperforms relevant temporal
logic planning methods.
</dc:description>
 <dc:description>Comment: 21 pages, 10 figures</dc:description>
 <dc:date>2019-09-01</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1909.00526</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02487</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ab-Initio Solution of the Many-Electron Schr\&quot;odinger Equation with Deep
  Neural Networks</dc:title>
 <dc:creator>Pfau, David</dc:creator>
 <dc:creator>Spencer, James S.</dc:creator>
 <dc:creator>Matthews, Alexander G. de G.</dc:creator>
 <dc:creator>Foulkes, W. M. C.</dc:creator>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  Given access to accurate solutions of the many-electron Schr\&quot;odinger
equation, nearly all chemistry could be derived from first principles. Exact
wavefunctions of interesting chemical systems are out of reach because they are
NP-hard to compute in general, but approximations can be found using
polynomially-scaling algorithms. The key challenge for many of these algorithms
is the choice of wavefunction approximation, or Ansatz, which must trade off
between efficiency and accuracy. Neural networks have shown impressive power as
accurate practical function approximators and promise as a compact wavefunction
Ansatz for spin systems, but problems in electronic structure require
wavefunctions that obey Fermi-Dirac statistics. Here we introduce a novel deep
learning architecture, the Fermionic Neural Network, as a powerful wavefunction
Ansatz for many-electron systems. The Fermionic Neural Network is able to
achieve accuracy beyond other variational quantum Monte Carlo Ans\&quot;atze on a
variety of atoms and small molecules. Using no data other than atomic positions
and charges, we predict the dissociation curves of the nitrogen molecule and
hydrogen chain, two challenging strongly-correlated systems, to significantly
higher accuracy than the coupled cluster method, widely considered the most
accurate scalable method for quantum chemistry at equilibrium geometry. This
demonstrates that deep neural networks can improve the accuracy of variational
quantum Monte Carlo to the point where it outperforms other ab-initio quantum
chemistry methods, opening the possibility of accurate direct optimization of
wavefunctions for previously intractable many-electron systems.
</dc:description>
 <dc:description>Comment: Final proof for Physical Review Research</dc:description>
 <dc:date>2019-09-05</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1909.02487</dc:identifier>
 <dc:identifier>Phys. Rev. Research 2, 033429 (2020)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevResearch.2.033429</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.02551</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quasi-optimal adaptive hybridized mixed finite element methods for
  linear elasticity</dc:title>
 <dc:creator>Li, Yuwen</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65N12, 65N15, 65N30, 65N50</dc:subject>
 <dc:description>  For the planar Navier--Lam\'e equation in mixed form with symmetric stress
tensors, we prove the uniform quasi-optimal convergence of an adaptive method
based on the hybridized mixed finite element proposed in [Gong, Wu, and Xu:
Numer.~Math., 141 (2019), pp.~569--604]. The main ingredients in the analysis
consist of a discrete a posteriori upper bound and a quasi-orthogonality result
for the stress field under the mixed boundary condition. Compared with existing
adaptive methods, the proposed adaptive algorithm could be directly applied to
the traction boundary condition and be easily implemented.
</dc:description>
 <dc:date>2019-09-05</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1909.02551</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04054</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pretrained Language Models for Sequential Sentence Classification</dc:title>
 <dc:creator>Cohan, Arman</dc:creator>
 <dc:creator>Beltagy, Iz</dc:creator>
 <dc:creator>King, Daniel</dc:creator>
 <dc:creator>Dalvi, Bhavana</dc:creator>
 <dc:creator>Weld, Daniel S.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  As a step toward better document-level understanding, we explore
classification of a sequence of sentences into their corresponding categories,
a task that requires understanding sentences in context of the document. Recent
successful models for this task have used hierarchical models to contextualize
sentence representations, and Conditional Random Fields (CRFs) to incorporate
dependencies between subsequent labels. In this work, we show that pretrained
language models, BERT (Devlin et al., 2018) in particular, can be used for this
task to capture contextual dependencies without the need for hierarchical
encoding nor a CRF. Specifically, we construct a joint sentence representation
that allows BERT Transformer layers to directly utilize contextual information
from all words in all sentences. Our approach achieves state-of-the-art results
on four datasets, including a new dataset of structured scientific abstracts.
</dc:description>
 <dc:description>Comment: EMNLP 2019</dc:description>
 <dc:date>2019-09-09</dc:date>
 <dc:date>2019-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1909.04054</dc:identifier>
 <dc:identifier>Proceedings of the 2019 Conference on Empirical Methods in Natural
  Language Processing and the 9th International Joint Conference on Natural
  Language Processing (EMNLP-IJCNLP) (2019) 3693-3699</dc:identifier>
 <dc:identifier>doi:10.18653/v1/D19-1383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04063</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploratory Combinatorial Optimization with Reinforcement Learning</dc:title>
 <dc:creator>Barrett, Thomas D.</dc:creator>
 <dc:creator>Clements, William R.</dc:creator>
 <dc:creator>Foerster, Jakob N.</dc:creator>
 <dc:creator>Lvovsky, A. I.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Many real-world problems can be reduced to combinatorial optimization on a
graph, where the subset or ordering of vertices that maximize some objective
function must be found. With such tasks often NP-hard and analytically
intractable, reinforcement learning (RL) has shown promise as a framework with
which efficient heuristic methods to tackle these problems can be learned.
Previous works construct the solution subset incrementally, adding one element
at a time, however, the irreversible nature of this approach prevents the agent
from revising its earlier decisions, which may be necessary given the
complexity of the optimization task. We instead propose that the agent should
seek to continuously improve the solution by learning to explore at test time.
Our approach of exploratory combinatorial optimization (ECO-DQN) is, in
principle, applicable to any combinatorial problem that can be defined on a
graph. Experimentally, we show our method to produce state-of-the-art RL
performance on the Maximum Cut problem. Moreover, because ECO-DQN can start
from any arbitrary configuration, it can be combined with other search methods
to further improve performance, which we demonstrate using a simple random
search.
</dc:description>
 <dc:description>Comment: In Proceedings of the 34th National Conference on Artificial
  Intelligence, AAAI 2020</dc:description>
 <dc:date>2019-09-09</dc:date>
 <dc:date>2020-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1909.04063</dc:identifier>
 <dc:identifier>Proceedings of Thirty-fourth AAAI conference on artificial
  intelligence, 3243-3250 (2020)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.04131</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Super ensemble learning for daily streamflow forecasting: Large-scale
  demonstration and comparison with multiple machine learning algorithms</dc:title>
 <dc:creator>Tyralis, Hristos</dc:creator>
 <dc:creator>Papacharalampous, Georgia</dc:creator>
 <dc:creator>Langousis, Andreas</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Daily streamflow forecasting through data-driven approaches is traditionally
performed using a single machine learning algorithm. Existing applications are
mostly restricted to examination of few case studies, not allowing accurate
assessment of the predictive performance of the algorithms involved. Here we
propose super learning (a type of ensemble learning) by combining 10 machine
learning algorithms. We apply the proposed algorithm in one-step ahead
forecasting mode. For the application, we exploit a big dataset consisting of
10-year long time series of daily streamflow, precipitation and temperature
from 511 basins. The super learner improves over the performance of the linear
regression algorithm by 20.06%, outperforming the &quot;hard to beat in practice&quot;
equal weight combiner. The latter improves over the performance of the linear
regression algorithm by 19.21%. The best performing individual machine learning
algorithm is neural networks, which improves over the performance of the linear
regression algorithm by 16.73%, followed by extremely randomized trees
(16.40%), XGBoost (15.92%), loess (15.36%), random forests (12.75%), polyMARS
(12.36%), MARS (4.74%), lasso (0.11%) and support vector regression (-0.45%).
Based on the obtained large-scale results, we propose super learning for daily
streamflow forecasting.
</dc:description>
 <dc:date>2019-09-09</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1909.04131</dc:identifier>
 <dc:identifier>Neural Computing and Applications 33 (2021) 3053-3068</dc:identifier>
 <dc:identifier>doi:10.1007/s00521-020-05172-3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06099</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A relaxed interior point method for low-rank semidefinite programming
  problems with applications to matrix completion</dc:title>
 <dc:creator>Bellavia, Stefania</dc:creator>
 <dc:creator>Gondzio, Jacek</dc:creator>
 <dc:creator>Porcelli, Margherita</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>90C22, 90C51, 65F10, 65F50</dc:subject>
 <dc:description>  A new relaxed variant of interior point method for low-rank semidefinite
programming problems is proposed in this paper. The method is a step outside of
the usual interior point framework. In anticipation to converging to a low-rank
primal solution, a special nearly low-rank form of all primal iterates is
imposed. To accommodate such a (restrictive) structure, the first order
optimality conditions have to be relaxed and are therefore approximated by
solving an auxiliary least-squares problem. The relaxed interior point
framework opens numerous possibilities how primal and dual approximated Newton
directions can be computed. In particular, it admits the application of both
the first- and the second-order methods in this context. The convergence of the
method is established. A prototype implementation is discussed and encouraging
preliminary computational results are reported for solving the
SDP-reformulation of matrix-completion problems.
</dc:description>
 <dc:date>2019-09-13</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1909.06099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.06885</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>6DLS: Modeling Nonplanar Frictional Surface Contacts for Grasping using
  6D Limit Surfaces</dc:title>
 <dc:creator>Xu, Jingyi</dc:creator>
 <dc:creator>Aykut, Tamay</dc:creator>
 <dc:creator>Ma, Daolin</dc:creator>
 <dc:creator>Steinbach, Eckehard</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Robot grasping with deformable gripper jaws results in nonplanar surface
contacts if the jaws deform to the nonplanar local geometry of an object. The
frictional force and torque that can be transmitted through a nonplanar surface
contact are both three-dimensional, resulting in a six-dimensional frictional
wrench (6DFW). Applying traditional planar contact models to such contacts
leads to over-conservative results as the models do not consider the nonplanar
surface geometry and only compute a three-dimensional subset of the 6DFW. To
address this issue, we derive the 6DFW for nonplanar surfaces by combining
concepts of differential geometry and Coulomb friction. We also propose two 6D
limit surface (6DLS) models, generalized from well-known three-dimensional LS
(3DLS) models, which describe the friction-motion constraints for a contact. We
evaluate the 6DLS models by fitting them to the 6DFW samples obtained from six
parametric surfaces and 2,932 meshed contacts from finite element method
simulations of 24 rigid objects. We further present an algorithm to predict
multicontact grasp success by building a grasp wrench space with the 6DLS model
of each contact. To evaluate the algorithm, we collected 1,035 physical grasps
of ten 3D-printed objects with a KUKA robot and a deformable parallel-jaw
gripper. In our experiments, the algorithm achieves 66.8% precision, a metric
inversely related to false positive predictions, and 76.9% recall, a metric
inversely related to false negative predictions. The 6DLS models increase
recall by up to 26.1% over 3DLS models with similar precision.
</dc:description>
 <dc:date>2019-09-15</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1909.06885</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.08483</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Environmental Hotspot Identification in Limited Time with a UAV Equipped
  with a Downward-Facing Camera</dc:title>
 <dc:creator>Sung, Yoonchang</dc:creator>
 <dc:creator>Dixit, Deeksha</dc:creator>
 <dc:creator>Tokekar, Pratap</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  Our work is motivated by environmental monitoring tasks, where finding the
global maxima (i.e., hotspot) of a spatially varying field is crucial. We
investigate the problem of identifying the hotspot for fields that can be
sensed using an Unmanned Aerial Vehicle (UAV) equipped with a downward-facing
camera. The UAV has a limited time budget which it can use for learning the
unknown field and identifying the hotspot. Our contribution is to show how this
problem can be formulated as a novel multi-fidelity variant of the Gaussian
Process (GP) multi-armed bandit problem. The novelty is two-fold: (i) unlike
standard multi-armed bandit settings, the rewards of the arms are correlated
with each other; and (ii) unlike standard GP regression, the measurements in
our problem are images (i.e., vector measurements) whose quality depends on the
altitude of the UAV. We present a strategy for finding the sequence of UAV
sensing locations and empirically compare it with several baselines.
Experimental results using images gathered onboard a UAV are also presented and
the scalability of the proposed methodology is assessed in a large-scale
simulated environment in Gazebo.
</dc:description>
 <dc:description>Comment: 9 pages, 7 figures, Published in IEEE International Conference on
  Robotics and Automation (ICRA), 2021</dc:description>
 <dc:date>2019-09-18</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1909.08483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09526</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hypermap Mapping Framework and its Application to Autonomous Semantic
  Exploration</dc:title>
 <dc:creator>Zaenker, Tobias</dc:creator>
 <dc:creator>Verdoja, Francesco</dc:creator>
 <dc:creator>Kyrki, Ville</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Modern intelligent and autonomous robotic applications often require robots
to have more information about their environment than that provided by
traditional occupancy grid maps. For example, a robot tasked to perform
autonomous semantic exploration has to label objects in the environment it is
traversing while autonomously navigating. To solve this task the robot needs to
at least maintain an occupancy map of the environment for navigation, an
exploration map keeping track of which areas have already been visited, and a
semantic map where locations and labels of objects in the environment are
recorded. As the number of maps required grows, an application has to know and
handle different map representations, which can be a burden.
  We present the Hypermap framework, which can manage multiple maps of
different types. In this work, we explore the capabilities of the framework to
handle occupancy grid layers and semantic polygonal layers, but the framework
can be extended with new layer types in the future. Additionally, we present an
algorithm to automatically generate semantic layers from RGB-D images. We
demonstrate the utility of the framework using the example of autonomous
exploration for semantic mapping.
</dc:description>
 <dc:description>Comment: In 2020 IEEE International Conference on Multisensor Fusion and
  Integration (MFI)</dc:description>
 <dc:date>2019-09-20</dc:date>
 <dc:date>2020-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1909.09526</dc:identifier>
 <dc:identifier>2020 IEEE International Conference on Multisensor Fusion and
  Integration for Intelligent Systems (MFI), Karlsruhe, Germany, 2020, pp.
  133-139</dc:identifier>
 <dc:identifier>doi:10.1109/MFI49285.2020.9235231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.09923</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Backpressure Flow Control</dc:title>
 <dc:creator>Goyal, Prateesh</dc:creator>
 <dc:creator>Shah, Preey</dc:creator>
 <dc:creator>Zhao, Kevin</dc:creator>
 <dc:creator>Nikolaidis, Georgios</dc:creator>
 <dc:creator>Alizadeh, Mohammad</dc:creator>
 <dc:creator>Anderson, Thomas E.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Effective congestion control for data center networks is becoming
increasingly challenging with a growing amount of latency sensitive traffic,
much fatter links, and extremely bursty traffic. Widely deployed algorithms,
such as DCTCP and DCQCN, are still far from optimal in many plausible
scenarios, particularly for tail latency. Many operators compensate by running
their networks at low average utilization, dramatically increasing costs.
  In this paper, we argue that we have reached the practical limits of
end-to-end congestion control. Instead, we propose, implement, and evaluate a
new congestion control architecture called Backpressure Flow Control (BFC). BFC
provides per-hop per-flow flow control, but with bounded state, constant-time
switch operations, and careful use of buffers. We demonstrate BFC's feasibility
by implementing it on Tofino2, a state-of-the-art P4-based programmable
hardware switch. In simulation, we show that BFC achieves near optimal
throughput and tail latency behavior even under challenging conditions such as
high network load and incast cross traffic. Compared to existing end-to-end
schemes, BFC achieves 2.3 - 60 X lower tail latency for short flows and 1.6 - 5
X better average completion time for long flows.
</dc:description>
 <dc:date>2019-09-21</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1909.09923</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.12057</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>B-Spline CNNs on Lie Groups</dc:title>
 <dc:creator>Bekkers, Erik J</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Group convolutional neural networks (G-CNNs) can be used to improve classical
CNNs by equipping them with the geometric structure of groups. Central in the
success of G-CNNs is the lifting of feature maps to higher dimensional
disentangled representations, in which data characteristics are effectively
learned, geometric data-augmentations are made obsolete, and predictable
behavior under geometric transformations (equivariance) is guaranteed via group
theory. Currently, however, the practical implementations of G-CNNs are limited
to either discrete groups (that leave the grid intact) or continuous compact
groups such as rotations (that enable the use of Fourier theory). In this paper
we lift these limitations and propose a modular framework for the design and
implementation of G-CNNs for arbitrary Lie groups. In our approach the
differential structure of Lie groups is used to expand convolution kernels in a
generic basis of B-splines that is defined on the Lie algebra. This leads to a
flexible framework that enables localized, atrous, and deformable convolutions
in G-CNNs by means of respectively localized, sparse and non-uniform B-spline
expansions. The impact and potential of our approach is studied on two
benchmark datasets: cancer detection in histopathology slides in which rotation
equivariance plays a key role and facial landmark localization in which scale
equivariance is important. In both cases, G-CNN architectures outperform their
classical 2D counterparts and the added value of atrous and localized group
convolutions is studied in detail.
</dc:description>
 <dc:description>Comment: Accepted for publication at ICLR 2020, code available at
  https://github.com/ebekkers/gsplinets</dc:description>
 <dc:date>2019-09-26</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1909.12057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13021</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-scale Attributed Node Embedding</dc:title>
 <dc:creator>Rozemberczki, Benedek</dc:creator>
 <dc:creator>Allen, Carl</dc:creator>
 <dc:creator>Sarkar, Rik</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present network embedding algorithms that capture information about a node
from the local distribution over node attributes around it, as observed over
random walks following an approach similar to Skip-gram. Observations from
neighborhoods of different sizes are either pooled (AE) or encoded distinctly
in a multi-scale approach (MUSAE). Capturing attribute-neighborhood
relationships over multiple scales is useful for a diverse range of
applications, including latent feature identification across disconnected
networks with similar attributes. We prove theoretically that matrices of
node-feature pointwise mutual information are implicitly factorized by the
embeddings. Experiments show that our algorithms are robust, computationally
efficient and outperform comparable models on social networks and web graphs.
</dc:description>
 <dc:description>Comment: Published in the Journal of Complex Networks</dc:description>
 <dc:date>2019-09-28</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1909.13021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1909.13304</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identifying supportive student factors for mindset interventions: A
  two-model machine learning approach</dc:title>
 <dc:creator>Bosch, Nigel</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Growth mindset interventions foster students' beliefs that their abilities
can grow through effort and appropriate strategies. However, not every student
benefits from such interventions - yet research identifying which student
factors support growth mindset interventions is sparse. In this study, we
utilized machine learning methods to predict growth mindset effectiveness in a
nationwide experiment in the U.S. with over 10,000 students. These methods
enable analysis of arbitrarily-complex interactions between combinations of
student-level predictor variables and intervention outcome, defined as the
improvement in grade point average (GPA) during the transition to high school.
We utilized two separate machine learning models: one to control for complex
relationships between 51 student-level predictors and GPA, and one to predict
the change in GPA due to the intervention. We analyzed the trained models to
discover which features influenced model predictions most, finding that prior
academic achievement, blocked navigations (attempting to navigate through the
intervention software too quickly), self-reported reasons for learning, and
race/ethnicity were the most important predictors in the model for predicting
intervention effectiveness. As in previous research, we found that the
intervention was most effective for students with prior low academic
achievement. Unique to this study, we found that blocked navigations predicted
an intervention effect as low as 0.185 GPA points (on a 0-4 scale) less than
the mean. This was a notable negative prediction given that the mean
intervention effect in our sample was just 0.026 GPA points, though few
students (4.4%) experienced a substantial number of blocked navigation events.
We also found that some minoritized students were predicted to benefit less (or
even not at all) from the intervention.
</dc:description>
 <dc:description>Comment: 28 pages, 4 figures, 3 tables</dc:description>
 <dc:date>2019-09-29</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1909.13304</dc:identifier>
 <dc:identifier>doi:10.1016/j.compedu.2021.104190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00185</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Alzheimer's Disease by Hierarchical Graph Convolution from
  Positron Emission Tomography Imaging</dc:title>
 <dc:creator>Guo, Jiaming</dc:creator>
 <dc:creator>Qiu, Wei</dc:creator>
 <dc:creator>Li, Xiang</dc:creator>
 <dc:creator>Zhao, Xuandong</dc:creator>
 <dc:creator>Guo, Ning</dc:creator>
 <dc:creator>Li, Quanzheng</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Imaging-based early diagnosis of Alzheimer Disease (AD) has become an
effective approach, especially by using nuclear medicine imaging techniques
such as Positron Emission Topography (PET). In various literature it has been
found that PET images can be better modeled as signals (e.g. uptake of
florbetapir) defined on a network (non-Euclidean) structure which is governed
by its underlying graph patterns of pathological progression and metabolic
connectivity. In order to effectively apply deep learning framework for PET
image analysis to overcome its limitation on Euclidean grid, we develop a
solution for 3D PET image representation and analysis under a generalized,
graph-based CNN architecture (PETNet), which analyzes PET signals defined on a
group-wise inferred graph structure. Computations in PETNet are defined in
non-Euclidean, graph (network) domain, as it performs feature extraction by
convolution operations on spectral-filtered signals on the graph and pooling
operations based on hierarchical graph clustering. Effectiveness of the PETNet
is evaluated on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset,
which shows improved performance over both deep learning and other machine
learning-based methods.
</dc:description>
 <dc:description>Comment: Jiaming Guo, Wei Qiu and Xiang Li contribute equally to this work</dc:description>
 <dc:date>2019-09-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.00185</dc:identifier>
 <dc:identifier>doi:10.1109/BigData47090.2019.9005971</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.00285</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Blind calibration for compressed sensing: State evolution and an online
  algorithm</dc:title>
 <dc:creator>Gabri&#xe9;, Marylou</dc:creator>
 <dc:creator>Barbier, Jean</dc:creator>
 <dc:creator>Krzakala, Florent</dc:creator>
 <dc:creator>Zdeborov&#xe1;, Lenka</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Compressed sensing, allows to acquire compressible signals with a small
number of measurements. In applications, a hardware implementation often
requires a calibration as the sensing process is not perfectly known. Blind
calibration, that is performing at the same time calibration and compressed
sensing is thus particularly appealing. A potential approach was suggested by
Sch\&quot;ulke and collaborators in Sch\&quot;ulke et al. 2013 and 2015, using
approximate message passing (AMP) for blind calibration (cal-AMP). Here, the
algorithm is extended from the already proposed offline case to the online
case, where the calibration is refined step by step as new measured samples are
received. Furthermore, we show that the performance of both the offline and the
online algorithms can be theoretically studied via the State Evolution (SE)
formalism. Through numerical simulations, the efficiency of cal-AMP and the
consistency of the theoretical predictions are confirmed.
</dc:description>
 <dc:date>2019-10-01</dc:date>
 <dc:date>2020-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.00285</dc:identifier>
 <dc:identifier>J. Phys. A: Math. Theor. 53 334004 (2020)</dc:identifier>
 <dc:identifier>doi:10.1088/1751-8121/ab8416</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.01547</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A deep surrogate approach to efficient Bayesian inversion in PDE and
  integral equation models</dc:title>
 <dc:creator>Deveney, Teo</dc:creator>
 <dc:creator>Mueller, Eike</dc:creator>
 <dc:creator>Shardlow, Tony</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  We investigate a deep learning approach to efficiently perform Bayesian
inference in partial differential equation (PDE) and integral equation models
over potentially high-dimensional parameter spaces. The contributions of this
paper are two-fold; the first is the introduction of a neural network approach
to approximating the solutions of Fredholm and Volterra integral equations of
the first and second kind. The second is the development of a new, efficient
deep learning-based method for Bayesian inversion applied to problems that can
be described by PDEs or integral equations. To achieve this we introduce a
surrogate model, and demonstrate how this allows efficient sampling from a
Bayesian posterior distribution in which the likelihood depends on the
solutions of PDEs or integral equations. Our method relies on the direct
approximation of parametric solutions by neural networks, without need of
traditional numerical solves. This deep learning approach allows the accurate
and efficient approximation of parametric solutions in significantly higher
dimensions than is possible using classical discretisation schemes. Since the
approximated solutions can be cheaply evaluated, the solutions of Bayesian
inverse problems over large parameter spaces are efficient using Markov chain
Monte Carlo. We demonstrate the performance of our method using two real-world
examples; these include Bayesian inference in the PDE and integral equation
case for an example from electrochemistry, and Bayesian inference of a
function-valued heat-transfer parameter with applications in aviation.
</dc:description>
 <dc:date>2019-10-03</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.01547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.03970</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A systematic review of smartphone-based human activity recognition for
  health research</dc:title>
 <dc:creator>Straczkiewicz, Marcin</dc:creator>
 <dc:creator>James, Peter</dc:creator>
 <dc:creator>Onnela, Jukka-Pekka</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  Background: Smartphones are now nearly ubiquitous; their numerous built-in
sensors enable continuous measurement of activities of daily living, making
them especially well-suited for health research. Researchers have proposed
various human activity recognition (HAR) systems aimed at translating
measurements from smartphones into various types of physical activity. In this
review, we summarize the existing approaches to smartphone-based HAR. Methods:
We systematically searched Scopus, PubMed, and Web of Science for peer-reviewed
articles published up to December 2020 on the use of smartphones for HAR. We
extracted information on smartphone body location, sensors, and physical
activity types studied and the data transformation techniques and
classification schemes used for activity recognition. Results: We identified
108 articles and described the various approaches used for data acquisition,
data preprocessing, feature extraction, and activity classification,
identifying the most common practices and their alternatives. Conclusions:
Smartphones are well-suited for HAR research in the health sciences. For
population-level impact, future studies should focus on improving quality of
collected data, address missing data, incorporate more diverse participants and
activities, relax requirements about phone placement, provide more complete
documentation on study participants, and share the source code of the
implemented methods and algorithms.
</dc:description>
 <dc:description>Comment: 47 pages, 8 figures, 2 tables</dc:description>
 <dc:date>2019-10-07</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.03970</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04209</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the adequacy of untuned warmup for adaptive optimization</dc:title>
 <dc:creator>Ma, Jerry</dc:creator>
 <dc:creator>Yarats, Denis</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Adaptive optimization algorithms such as Adam are widely used in deep
learning. The stability of such algorithms is often improved with a warmup
schedule for the learning rate. Motivated by the difficulty of choosing and
tuning warmup schedules, recent work proposes automatic variance rectification
of Adam's adaptive learning rate, claiming that this rectified approach
(&quot;RAdam&quot;) surpasses the vanilla Adam algorithm and reduces the need for
expensive tuning of Adam with warmup. In this work, we refute this analysis and
provide an alternative explanation for the necessity of warmup based on the
magnitude of the update term, which is of greater relevance to training
stability. We then provide some &quot;rule-of-thumb&quot; warmup schedules, and we
demonstrate that simple untuned warmup of Adam performs more-or-less
identically to RAdam in typical practical settings. We conclude by suggesting
that practitioners stick to linear warmup with Adam, with a sensible default
being linear warmup over $2 / (1 - \beta_2)$ training iterations.
</dc:description>
 <dc:description>Comment: AAAI 2021</dc:description>
 <dc:date>2019-10-09</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.04209</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04543</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning protein conformational space by enforcing physics with
  convolutions and latent interpolations</dc:title>
 <dc:creator>Ramaswamy, Venkata K.</dc:creator>
 <dc:creator>Willcocks, Chris G.</dc:creator>
 <dc:creator>Degiacomi, Matteo T.</dc:creator>
 <dc:subject>Physics - Biological Physics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>68T05, 92C05</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  Determining the different conformational states of a protein and the
transition paths between them is key to fully understanding the relationship
between biomolecular structure and function. This can be accomplished by
sampling protein conformational space with molecular simulation methodologies.
Despite advances in computing hardware and sampling techniques, simulations
always yield a discretized representation of this space, with transition states
undersampled proportionally to their associated energy barrier. We present a
convolutional neural network that learns a continuous conformational space
representation from example structures, and loss functions that ensure
intermediates between examples are physically plausible. We show that this
network, trained with simulations of distinct protein states, can correctly
predict a biologically relevant non-linear transition path, without any example
on the path provided. We also show we can transfer features learnt from one
protein to others, which results in superior performances, and requires a
surprisingly small number of training examples.
</dc:description>
 <dc:date>2019-10-10</dc:date>
 <dc:date>2020-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.04543</dc:identifier>
 <dc:identifier>Phys. Rev. X 11, 011052 (2021)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevX.11.011052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.04732</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structured Pruning of Large Language Models</dc:title>
 <dc:creator>Wang, Ziheng</dc:creator>
 <dc:creator>Wohlwend, Jeremy</dc:creator>
 <dc:creator>Lei, Tao</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Large language models have recently achieved state of the art performance
across a wide variety of natural language tasks. Meanwhile, the size of these
models and their latency have significantly increased, which makes their usage
costly, and raises an interesting question: do language models need to be
large? We study this question through the lens of model compression. We present
a generic, structured pruning approach by parameterizing each weight matrix
using its low-rank factorization, and adaptively removing rank-1 components
during training. On language modeling tasks, our structured approach
outperforms other unstructured and block-structured pruning baselines at
various compression levels, while achieving significant speedups during both
training and inference. We also demonstrate that our method can be applied to
pruning adaptive word embeddings in large language models, and to pruning the
BERT model on several downstream fine-tuning classification benchmarks.
</dc:description>
 <dc:date>2019-10-10</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.04732</dc:identifier>
 <dc:identifier>doi:10.18653/v1/2020.emnlp-main.496</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05192</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>L-Platooning: A Protocol for Managing a Long Platoon with DSRC</dc:title>
 <dc:creator>Won, Myounggyu</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Vehicle platooning is an automated driving technology that enables a group of
vehicles to travel very closely together as a single unit to improve fuel
efficiency and driver safety and reduces CO2 emission. The significant benefits
of platooning attracted huge interests from academia and industry, especially
from logistics companies for utilizing platoons of &quot;long-body&quot; trailer trucks
because of the huge cost savings. In this paper, we demonstrate that existing
DSRC-based platooning solutions, however, fail to support formation of such
&quot;long&quot; platoons consisting of typical trailer trucks because of the limited
communication range of DSRC. To address this problem, we propose L-Platooning,
the first platooning protocol that enables seamless, reliable, and rapid
formation of a long platoon. We introduce a novel concept called Virtual Leader
that refers to a vehicle that acts like a platoon leader to extend the coverage
of the original platoon leader. A virtual leader election algorithm is
developed to effectively designate a virtual leader based on the novel metric
called the Virtual Leader Quality Index (VLQI) which quantifies the
effectiveness of a vehicle serving as a platoon leader. We also develop
mechanisms for L-Platooning to support the vehicle join and leave maneuvers
specifically for a long platoon. Through extensive simulations using the
combination of Veins (Plexe) and SUMO, we demonstrate that L-Platooning enables
long-body trailer trucks to form a long platoon effectively and maintain the
desired inter-vehicle distance precisely. We also show that L-Platooning
handles seamlessly the vehicle join and leave maneuvers for a long platoon.
</dc:description>
 <dc:description>Comment: Published in IEEE Transactions on Intelligent Transportation Systems</dc:description>
 <dc:date>2019-10-11</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.05192</dc:identifier>
 <dc:identifier>doi:10.1109/TITS.2021.3057956</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05313</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building HVAC Scheduling Using Reinforcement Learning via Neural Network
  Based Model Approximation</dc:title>
 <dc:creator>Zhang, Chi</dc:creator>
 <dc:creator>Kuppannagari, Sanmukh R.</dc:creator>
 <dc:creator>Kannan, Rajgopal</dc:creator>
 <dc:creator>Prasanna, Viktor K.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Buildings sector is one of the major consumers of energy in the United
States. The buildings HVAC (Heating, Ventilation, and Air Conditioning)
systems, whose functionality is to maintain thermal comfort and indoor air
quality (IAQ), account for almost half of the energy consumed by the buildings.
Thus, intelligent scheduling of the building HVAC system has the potential for
tremendous energy and cost savings while ensuring that the control objectives
(thermal comfort, air quality) are satisfied. Recently, several works have
focused on model-free deep reinforcement learning based techniques such as Deep
Q-Network (DQN). Such methods require extensive interactions with the
environment. Thus, they are impractical to implement in real systems due to low
sample efficiency. Safety-aware exploration is another challenge in real
systems since certain actions at particular states may result in catastrophic
outcomes. To address these issues and challenges, we propose a model-based
reinforcement learning approach that learns the system dynamics using a neural
network. Then, we adopt Model Predictive Control (MPC) using the learned system
dynamics to perform control with random-sampling shooting method. To ensure
safe exploration, we limit the actions within safe range and the maximum
absolute change of actions according to prior knowledge. We evaluate our ideas
through simulation using widely adopted EnergyPlus tool on a case study
consisting of a two zone data-center. Experiments show that the average
deviation of the trajectories sampled from the learned dynamics and the ground
truth is below $20\%$. Compared with baseline approaches, we reduce the total
energy consumption by $17.1\% \sim 21.8\%$. Compared with model-free
reinforcement learning approach, we reduce the required number of training
steps to converge by 10x.
</dc:description>
 <dc:description>Comment: 10 pages, 13 figures, to be appear in ACM BuildSys '19, November
  13-14, 2019, New York, NY, USA</dc:description>
 <dc:date>2019-10-11</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.05313</dc:identifier>
 <dc:identifier>doi:10.1145/3360322.3360861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05361</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relevant Region Exploration On General Cost-maps For Sampling-Based
  Motion Planning</dc:title>
 <dc:creator>Joshi, Sagar Suhas</dc:creator>
 <dc:creator>Tsiotras, Panagiotis</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Asymptotically optimal sampling-based planners require an intelligent
exploration strategy to accelerate convergence. After an initial solution is
found, a necessary condition for improvement is to generate new samples in the
so-called &quot;Informed Set&quot;. However, Informed Sampling can be ineffective in
focusing search if the chosen heuristic fails to provide a good estimate of the
solution cost. This work proposes an algorithm to sample the &quot;Relevant Region&quot;
instead, which is a subset of the Informed Set. The Relevant Region utilizes
cost-to-come information from the planner's tree structure, reduces dependence
on the heuristic, and further focuses the search. Benchmarking tests in uniform
and general cost-space settings demonstrate the efficacy of Relevant Region
sampling.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures</dc:description>
 <dc:date>2019-10-11</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.05361</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.05587</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to Not Measure Disentanglement</dc:title>
 <dc:creator>Sepliarskaia, Anna</dc:creator>
 <dc:creator>Kiseleva, Julia</dc:creator>
 <dc:creator>de Rijke, Maarten</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  To evaluate disentangled representations several metrics have been proposed.
However, theoretical guarantees for conventional metrics of disentanglement are
missing. Moreover, conventional metrics do not have a consistent correlation
with the outcomes of qualitative studies. In this paper we analyze metrics of
disentanglement and their properties. We conclude that existing metrics of
disentanglement were created to reflect different characteristics of
disentanglement and do not satisfy two basic desirable properties: (1) assign a
high score to representations that are disentangled according to the
definition; and (2) assign a low score to representations that are entangled
according to the definition. In addition, we propose a new metric of
disentanglement and prove that it satisfies both of the properties.
</dc:description>
 <dc:date>2019-10-12</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.05587</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06089</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>UBAT: On Jointly Optimizing UAV Trajectories and Placement of Battery
  Swap Stations</dc:title>
 <dc:creator>Won, Myounggyu</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Unmanned aerial vehicles (UAVs) have been widely used in many applications.
The limited flight time of UAVs, however, still remains as a major challenge.
Although numerous approaches have been developed to recharge the battery of
UAVs effectively, little is known about optimal methodologies to deploy
charging stations. In this paper, we address the charging station deployment
problem with an aim to find the optimal number and locations of charging
stations such that the system performance is maximized. We show that the
problem is NP-Hard and propose UBAT, a heuristic framework based on the ant
colony optimization (ACO) to solve the problem. Additionally, a suite of
algorithms are designed to enhance the execution time and the quality of the
solutions for UBAT. Through extensive simulations, we demonstrate that UBAT
effectively performs multi-objective optimization of generation of UAV
trajectories and placement of charging stations that are within 8.3% and 7.3%
of the true optimal solutions, respectively.
</dc:description>
 <dc:description>Comment: Accepted for publication in ICRA, 2020</dc:description>
 <dc:date>2019-10-10</dc:date>
 <dc:date>2020-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.06089</dc:identifier>
 <dc:identifier>doi:10.1109/ICRA40945.2020.9197227</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.06316</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NeurVPS: Neural Vanishing Point Scanning via Conic Convolution</dc:title>
 <dc:creator>Zhou, Yichao</dc:creator>
 <dc:creator>Qi, Haozhi</dc:creator>
 <dc:creator>Huang, Jingwei</dc:creator>
 <dc:creator>Ma, Yi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a simple yet effective end-to-end trainable deep network with
geometry-inspired convolutional operators for detecting vanishing points in
images. Traditional convolutional neural networks rely on aggregating edge
features and do not have mechanisms to directly exploit the geometric
properties of vanishing points as the intersections of parallel lines. In this
work, we identify a canonical conic space in which the neural network can
effectively compute the global geometric information of vanishing points
locally, and we propose a novel operator named conic convolution that can be
implemented as regular convolutions in this space. This new operator explicitly
enforces feature extractions and aggregations along the structural lines and
yet has the same number of parameters as the regular 2D convolution. Our
extensive experiments on both synthetic and real-world datasets show that the
proposed operator significantly improves the performance of vanishing point
detection over traditional methods. The code and dataset have been made
publicly available at https://github.com/zhou13/neurvps.
</dc:description>
 <dc:description>Comment: NeurIPS 2019</dc:description>
 <dc:date>2019-10-14</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.06316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.08546</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic sequences are also non-uniformly morphic</dc:title>
 <dc:creator>Allouche, Jean-Paul</dc:creator>
 <dc:creator>Shallit, Jeffrey</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>11B85, 68R15, 68Q45</dc:subject>
 <dc:description>  It is well-known that there exist infinite sequences that are the fixed point
of non-uniform morphisms, but not $k$-automatic for any $k$. In this note we
show that every $k$-automatic sequence is the image of a fixed point of a {\it
non-uniform\/} morphism.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:0905.0015</dc:description>
 <dc:date>2019-10-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.08546</dc:identifier>
 <dc:identifier>in &quot;Discrete Mathematics and Applications'', A. M. Raigorodskii
  and M. Th. Rassias eds., Springer Optimization and Its Applications, Springer
  Nature 165 (2020), 1-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.09080</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Error estimate of a bi-fidelity method for kinetic equations with random
  parameters and multiple scales</dc:title>
 <dc:creator>Gamba, Irene M.</dc:creator>
 <dc:creator>Jin, Shi</dc:creator>
 <dc:creator>Liu, Liu</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>35Q20, 65M70</dc:subject>
 <dc:description>  In this paper, we conduct uniform error estimates of the bi-fidelity method
for multi-scale kinetic equations. We take the Boltzmann and the linear
transport equations as important examples. The main analytic tool is the
hypocoercivity analysis for kinetic equations, considering solutions in a
perturbative setting close to the global equilibrium. This allows us to obtain
the error estimates in both kinetic and hydrodynamic regimes.
</dc:description>
 <dc:date>2019-10-20</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.09080</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.11002</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting LTE LAA: Channel Access, QoS, and Coexistence with WiFi</dc:title>
 <dc:creator>Wszo&#x142;ek, Jacek</dc:creator>
 <dc:creator>Ludyga, Szymon</dc:creator>
 <dc:creator>Anzel, Wojciech</dc:creator>
 <dc:creator>Szott, Szymon</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>91A06, 91A10, 91A80</dc:subject>
 <dc:subject>C.2.0</dc:subject>
 <dc:subject>C.2.5</dc:subject>
 <dc:description>  Network operators are looking towards LTE License Assisted Access (LAA) as a
means of extending capacity by offloading traffic to unlicensed bands. However,
operation in these bands requires abiding to certain coexistence rules in terms
of channel access. The description of these rules in existing literature is not
always in line with the latest standards. Therefore, in this paper, we clarify
the operation of LAA, focusing on channel access and methods of providing
Quality of Service (QoS) support. In terms of coexistence, we evaluate the
impact of LAA under its various QoS settings on Wi-Fi performance in an
experimental testbed. Finally, we describe the upcoming research challenges for
LTE-based technologies in unlicensed bands considering the latest developments.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures, 2 tables</dc:description>
 <dc:date>2019-10-24</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.11002</dc:identifier>
 <dc:identifier>IEEE Communications Magazine, vol. 59, no. 2, pp. 91-97, February
  2021</dc:identifier>
 <dc:identifier>doi:10.1109/MCOM.001.2000595</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.11217</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Katyusha Acceleration for Convex Finite-Sum Compositional Optimization</dc:title>
 <dc:creator>Xu, Yibo</dc:creator>
 <dc:creator>Xu, Yangyang</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>90C06, 90C15, 90C25, 62L20, 65C60, 65Y20</dc:subject>
 <dc:description>  Structured problems arise in many applications. To solve these problems, it
is important to leverage the structure information. This paper focuses on
convex problems with a finite-sum compositional structure. Finite-sum problems
appear as the sample average approximation of a stochastic optimization problem
and also arise in machine learning with a huge amount of training data. One
popularly used numerical approach for finite-sum problems is the stochastic
gradient method (SGM). However, the additional compositional structure
prohibits easy access to unbiased stochastic approximation of the gradient, so
directly applying the SGM to a finite-sum compositional optimization problem
(COP) is often inefficient.
  We design new algorithms for solving strongly-convex and also convex
two-level finite-sum COPs. Our design incorporates the Katyusha acceleration
technique and adopts the mini-batch sampling from both outer-level and
inner-level finite-sum. We first analyze the algorithm for strongly-convex
finite-sum COPs. Similar to a few existing works, we obtain linear convergence
rate in terms of the expected objective error, and from the convergence rate
result, we then establish complexity results of the algorithm to produce an
$\varepsilon$-solution. Our complexity results have the same dependence on the
number of component functions as existing works. However, due to the use of
Katyusha acceleration, our results have better dependence on the condition
number $\kappa$ and improve to $\kappa^{2.5}$ from the best-known $\kappa^3$.
Finally, we analyze the algorithm for convex finite-sum COPs, which uses as a
subroutine the algorithm for strongly-convex finite-sum COPs. Again, we obtain
better complexity results than existing works in terms of the dependence on
$\varepsilon$, improving to $\varepsilon^{-2.5}$ from the best-known
$\varepsilon^{-3}$.
</dc:description>
 <dc:description>Comment: Accepted in INFORMS J. on Optimization</dc:description>
 <dc:date>2019-10-24</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.11217</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.12142</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized SAT-Attack-Resistant Logic Locking</dc:title>
 <dc:creator>Zhou, Jingbo</dc:creator>
 <dc:creator>Zhang, Xinmiao</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Logic locking is used to protect integrated circuits (ICs) from piracy and
counterfeiting. An encrypted IC implements the correct function only when the
right key is input. Many existing logic-locking methods are subject to the
powerful satisfiability (SAT)-based attack. Recently, an Anti-SAT scheme has
been developed. By adopting two complementary logic blocks that consist of
AND/NAND trees, it makes the number of iterations needed by the SAT attack
exponential to the number of input bits. Nevertheless, the Anti-SAT scheme is
vulnerable to the later AppSAT and removal attacks. This paper proposes a
generalized (G-)Anti-SAT scheme. Different from the Anti-SAT scheme, a variety
of complementary or non-complementary functions can be adopted for the two
blocks in our G-Anti-SAT scheme. The Anti-SAT scheme is just a special case of
our proposed design. Our design can achieve higher output corruptibility, which
is also tunable, so that better resistance to the AppSAT and removal attacks is
achieved. Meanwhile, unlike existing AppSAT-resilient designs, our design does
not sacrifice the resistance to the SAT attack.
</dc:description>
 <dc:date>2019-10-26</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.12142</dc:identifier>
 <dc:identifier>in IEEE Transactions on Information Forensics and Security, vol.
  16, pp. 2581-2592, 2021</dc:identifier>
 <dc:identifier>doi:10.1109/TIFS.2021.3059271.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.12327</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A simple measure of conditional dependence</dc:title>
 <dc:creator>Azadkia, Mona</dc:creator>
 <dc:creator>Chatterjee, Sourav</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>62G05, 62H20</dc:subject>
 <dc:description>  We propose a coefficient of conditional dependence between two random
variables $Y$ and $Z$ given a set of other variables $X_1,\ldots,X_p$, based on
an i.i.d. sample. The coefficient has a long list of desirable properties, the
most important of which is that under absolutely no distributional assumptions,
it converges to a limit in $[0,1]$, where the limit is $0$ if and only if $Y$
and $Z$ are conditionally independent given $X_1,\ldots,X_p$, and is $1$ if and
only if $Y$ is equal to a measurable function of $Z$ given $X_1,\ldots,X_p$.
Moreover, it has a natural interpretation as a nonlinear generalization of the
familiar partial $R^2$ statistic for measuring conditional dependence by
regression. Using this statistic, we devise a new variable selection algorithm,
called Feature Ordering by Conditional Independence (FOCI), which is
model-free, has no tuning parameters, and is provably consistent under sparsity
assumptions. A number of applications to synthetic and real datasets are worked
out.
</dc:description>
 <dc:description>Comment: 41 pages, 2 tables. Final version. To appear in Ann. Statist. An R
  package is available at https://CRAN.R-project.org/package=FOCI</dc:description>
 <dc:date>2019-10-27</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.12327</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.12526</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Fast and Tight Heuristic for A* in Road Networks</dc:title>
 <dc:creator>Strasser, Ben</dc:creator>
 <dc:creator>Zeitz, Tim</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study exact, efficient and practical algorithms for route planning in
large road networks. Routing applications often require integrating the current
traffic situation, planning ahead with traffic predictions for the future,
respecting forbidden turns, and many other features depending on the exact
application. While Dijkstra's algorithm can be used to solve these problems, it
is too slow for many applications. A* is a classical approach to accelerate
Dijkstra's algorithm. A* can support many extended scenarios without much
additional implementation complexity. However, A*'s performance depends on the
availability of a good heuristic that estimates distances. Computing tight
distance estimates is a challenge on its own. On road networks, shortest paths
can also be quickly computed using hierarchical speedup techniques. They
achieve speed and exactness but sacrifice A*'s flexibility. Extending them to
certain practical applications can be hard. In this paper, we present an
algorithm to efficiently extract distance estimates for A* from Contraction
Hierarchies (CH), a hierarchical technique. We call our heuristic
CH-Potentials. Our approach allows decoupling the supported extensions from the
hierarchical speed-up technique. Additionally, we describe A* optimizations to
accelerate the processing of low degree nodes, which often occur in road
networks.
</dc:description>
 <dc:description>Comment: 16 pages, 3 figures; v2: Camera ready for SEA 2021</dc:description>
 <dc:date>2019-10-28</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.12526</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.12726</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Space-Efficient, Fast and Exact Routing in Time-Dependent Road Networks</dc:title>
 <dc:creator>Strasser, Ben</dc:creator>
 <dc:creator>Wagner, Dorothea</dc:creator>
 <dc:creator>Zeitz, Tim</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the problem of quickly computing point-to-point shortest paths in
massive road networks with traffic predictions. Incorporating traffic
predictions into routing allows, for example, to avoid commuter traffic
congestions. Existing techniques follow a two-phase approach: In a
preprocessing step, an index is built. The index depends on the road network
and the traffic patterns but not on the path start and end. The latter are the
input of the query phase, in which shortest paths are computed. All existing
techniques have large index size, slow query running times or may compute
suboptimal paths. In this work, we introduce CATCHUp (Customizable Approximated
Time-dependent Contraction Hierarchies through Unpacking), the first algorithm
that simultaneously achieves all three objectives.The core idea of CATCHUp is
to store paths instead of travel times at shortcuts. Shortcut travel times are
derived lazily from the stored paths. We perform an experimental study on a set
of real world instances and compare our approach with state-of-the-art
techniques. Our approach achieves the fastest preprocessing, competitive query
running times and up to 38 times smaller indexes than competing approaches.
</dc:description>
 <dc:description>Comment: 32 pages, 11 figures, published in MDPI Algorithms and a short
  version at ESA 2020</dc:description>
 <dc:date>2019-10-28</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.12726</dc:identifier>
 <dc:identifier>doi:10.3390/a14030090</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1910.13041</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterizing Power Consumption of Dual-Frequency GNSS of a Smartphone</dc:title>
 <dc:creator>Karki, Bikram</dc:creator>
 <dc:creator>Won, Myounggyu</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Location service is one of the most widely used features on a smartphone.
More and more apps are built based on location services. As such, demand for
accurate positioning is ever higher. Mobile brand Xiaomi has introduced Mi 8,
the world's first smartphone equipped with a dual-frequency GNSS chipset which
is claimed to provide up to decimeter-level positioning accuracy. Such
unprecedentedly high location accuracy brought excitement to industry and
academia for navigation research and development of emerging apps. On the other
hand, there is a significant knowledge gap on the energy efficiency of
smartphones equipped with a dual-frequency GNSS chipset. In this paper, we
bridge this knowledge gap by performing an empirical study on power consumption
of a dual-frequency GNSS phone. To the best our knowledge, this is the first
experimental study that characterizes the power consumption of a smartphone
equipped with a dual-frequency GNSS chipset and compares the energy efficiency
with a single-frequency GNSS phone. We demonstrate that a smartphone with a
dual-frequency GNSS chipset consumes 37% more power on average outdoors, and
28% more power indoors, in comparison with a singe-frequency GNSS phone.
</dc:description>
 <dc:description>Comment: Published in IEEE Global Communications Conference (GLOBECOM)</dc:description>
 <dc:date>2019-10-28</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1910.13041</dc:identifier>
 <dc:identifier>doi:10.1109/GLOBECOM42002.2020.9322317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1911.00593</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entropy-stable positivity-preserving DG schemes for Boltzmann-Poisson
  models of collisional electronic transport along energy bands</dc:title>
 <dc:creator>Escalante, Jose A. Morales</dc:creator>
 <dc:creator>Gamba, Irene M.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  This work develops entropy-stable positivity-preserving DG methods as a
computational scheme for Boltzmann-Poisson systems modeling the pdf of
electronic transport along energy bands in semiconductor crystal lattices. We
pose, using spherical or energy-angular variables as momentum coordinates, the
corresponding Vlasov Boltzmann eq. with a linear collision operator with a
singular measure modeling the scattering as functions of the energy band. We
show stability results of semi-discrete DG schemes under an entropy norm for
1D-position 2D-momentum, and 2D-position 3D-momentum, using the dissipative
properties of the collisional operator given its entropy inequality, which
depends on the whole Hamiltonian rather than only the kinetic energy. For the
1D problem, knowledge of the analytic solution to Poisson and of the
convergence to a constant current is crucial to obtain full stability. For the
2D problem, specular reflection BC are considered in addition to periodicity in
the estimate for stability under an entropy norm. Regarding positivity
preservation (1D position), we treat the collision operator as a source term
and find convex combinations of the transport and collision terms which
guarantee the positivity of the cell average of our numerical pdf at the next
time step. The positivity of the numerical pdf in the whole domain is
guaranteed by applying the natural limiters that preserve the cell average but
modify the slope of the piecewise linear solutions in order to make the
function non-negative. The use of a spherical coordinate system
$\vec{p}(|\vec{p}|,\mu=cos\theta,\varphi)$ is slightly different to the choice
in previous DG solvers for BP, since the proposed DG formulation gives simpler
integrals involving just piecewise polynomial functions for both transport and
collision terms, which is more adequate for Gaussian quadrature than previous
approaches.
</dc:description>
 <dc:description>Comment: Preprint. The first author acknowledges discussions with Eirik Endeve
  and Cory Hauck during the time he spent visiting them at ORNL (restricted to
  positivity preservation, appearing on arXiv:1711.03949) on a trip paid by the
  kinet grant NSF-RNMS DMS-1107465. V2 is a replacement for V1. V2 has added
  some references and corrected typos (not affecting any of the calculations)</dc:description>
 <dc:date>2019-11-01</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1911.00593</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1911.02947</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Second order splitting of a class of fourth order PDEs with point
  constraints</dc:title>
 <dc:creator>Elliott, Charles M.</dc:creator>
 <dc:creator>Herbert, Philip J.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We formulate a well-posedness and approximation theory for a class of
generalised saddle point problems with a specific form of constraints. In this
way we develop an approach to a class of fourth order elliptic partial
differential equations with point constraints using the idea of splitting into
coupled second order equations. An approach is formulated using a penalty
method to impose the constraints. Our main motivation is to treat certain
fourth order equations involving the biharmonic operator and point Dirichlet
constraints for example arising in the modelling of biomembranes on curved and
flat surfaces but the approach may be applied more generally. The theory for
well-posedness and approximation is presented in an abstract setting. Several
examples are described together with some numerical experiments.
</dc:description>
 <dc:date>2019-11-07</dc:date>
 <dc:date>2020-04-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1911.02947</dc:identifier>
 <dc:identifier>doi:10.1090/mcom/3556</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1911.03561</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph-to-Graph Transformer for Transition-based Dependency Parsing</dc:title>
 <dc:creator>Mohammadshahi, Alireza</dc:creator>
 <dc:creator>Henderson, James</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We propose the Graph2Graph Transformer architecture for conditioning on and
predicting arbitrary graphs, and apply it to the challenging task of
transition-based dependency parsing. After proposing two novel Transformer
models of transition-based dependency parsing as strong baselines, we show that
adding the proposed mechanisms for conditioning on and predicting graphs of
Graph2Graph Transformer results in significant improvements, both with and
without BERT pre-training. The novel baselines and their integration with
Graph2Graph Transformer significantly outperform the state-of-the-art in
traditional transition-based dependency parsing on both English Penn Treebank,
and 13 languages of Universal Dependencies Treebanks. Graph2Graph Transformer
can be integrated with many previous structured prediction methods, making it
easy to apply to a wide range of NLP tasks.
</dc:description>
 <dc:description>Comment: Accepted to Findings of EMNLP 2020</dc:description>
 <dc:date>2019-11-08</dc:date>
 <dc:date>2020-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1911.03561</dc:identifier>
 <dc:identifier>doi:10.18653/v1/2020.findings-emnlp.294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1911.03679</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decision Procedures for Guarded Logics</dc:title>
 <dc:creator>Kappelmann, Kevin</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  An important class of decidable first-order logic fragments are those
satisfying a guardedness condition, such as the guarded fragment (GF). Usually,
decidability for these logics is closely linked to the tree-like model property
- the fact that satisfying models can be taken to have tree-like form. Decision
procedures for the guarded fragment based on the tree-like model property are
difficult to implement. An alternative approach, based on restricting
first-order resolution, has been proposed, and this shows more promise from the
point of view of implementation. In this work, we connect the tree-like model
property of the guarded fragment with the resolution-based approach. We derive
efficient resolution-based rewriting algorithms that solve the Quantifier-Free
Query Answering Problem under Guarded Tuple Generating Dependencies (GTGDs) and
Disjunctive Guarded Tuple Generating Dependencies (DisGTGDs). The Query
Answering Problem for these classes subsumes many cases of GF satisfiability.
Our algorithms, in addition to making the connection to the tree-like model
property clear, give a natural account of the selection and ordering strategies
used by resolution procedures for the guarded fragment. We also believe that
our rewriting algorithm for the special case of GTGDs may prove itself valuable
in practice as it does not require any Skolemisation step and its theoretical
runtime outperforms those of known GF resolution procedures in case of fixed
dependencies. Moreover, we show a novel normalisation procedure for the widely
used chase procedure in case of (disjunctive) GTGDs, which could be useful for
future studies.
</dc:description>
 <dc:description>Comment: A thesis submitted in partial fulfilment for the degree of MSc in
  Mathematics and Foundations of Computer Science at the University of Oxford.
  Update 25.03.2021: added missing constraint in definition of simple
  saturation algorithm</dc:description>
 <dc:date>2019-11-09</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1911.03679</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1911.04536</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Approach: Cognitive Multi-Level Authentication (CMLA) in Nuclear
  Command and Control</dc:title>
 <dc:creator>Shabbir, Aysha</dc:creator>
 <dc:creator>Shabbir, Maryam</dc:creator>
 <dc:creator>Ahmad, Fahad</dc:creator>
 <dc:creator>Rizwan, Muhammad</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Nuclear monitoring must considered as high precedence against national
security. Now with the increasing nuclear threats it is crucial to ensure that
malicious entity never procure nuclear warheads. Which comprises the prevention
of illegal or terrorist access to nuclear weapons. The disastrous damage that
could be the consequence of unauthorized unapproved utilization of nuclear
weapon and from the expansion of nuclear technologies to unacceptable states
has driven the nuclear forces to spend epic measures of securing nuclear
warheads as well as the supporting materials infrastructure and industries. The
procedure of ratifying users credentials is known as authentication. Cognitive
based authentication is a type of authentication that is actually the
amalgamation of neuron biological and psychological techniques. This research
is intended to provide human inspired Cognitive Multi-level Authentication
utilizing the extensive quantum processing capabilities. Simulation is being
done on online Q U V I S quantum simulator using quantum cryptography B B 8 4
algorithm where the intended person is successfully authenticated while
considering different scenarios. So the proposed scheme will come up with self
learning intellect based secure speedy and reliable authentication systems
against nuclear command and control.
</dc:description>
 <dc:description>Comment: We want to improve this version of research</dc:description>
 <dc:date>2019-11-11</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1911.04536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1911.04594</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rate-Regularization and Generalization in VAEs</dc:title>
 <dc:creator>Bozkurt, Alican</dc:creator>
 <dc:creator>Esmaeili, Babak</dc:creator>
 <dc:creator>Tristan, Jean-Baptiste</dc:creator>
 <dc:creator>Brooks, Dana H.</dc:creator>
 <dc:creator>Dy, Jennifer G.</dc:creator>
 <dc:creator>van de Meent, Jan-Willem</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Variational autoencoders optimize an objective that combines a reconstruction
loss (the distortion) and a KL term (the rate). The rate is an upper bound on
the mutual information, which is often interpreted as a regularizer that
controls the degree of compression. We here examine whether inclusion of the
rate also acts as an inductive bias that improves generalization. We perform
rate-distortion analyses that control the strength of the rate term, the
network capacity, and the difficulty of the generalization problem. Decreasing
the strength of the rate paradoxically improves generalization in most
settings, and reducing the mutual information typically leads to underfitting.
Moreover, we show that generalization continues to improve even after the
mutual information saturates, indicating that the gap on the bound (i.e. the KL
divergence relative to the inference marginal) affects generalization. This
suggests that the standard Gaussian prior is not an inductive bias that
typically aids generalization, prompting work to understand what choices of
priors improve generalization in VAEs.
</dc:description>
 <dc:date>2019-11-11</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1911.04594</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1911.05047</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weakly Convex Optimization over Stiefel Manifold Using Riemannian
  Subgradient-Type Methods</dc:title>
 <dc:creator>Li, Xiao</dc:creator>
 <dc:creator>Chen, Shixiang</dc:creator>
 <dc:creator>Deng, Zengde</dc:creator>
 <dc:creator>Qu, Qing</dc:creator>
 <dc:creator>Zhu, Zhihui</dc:creator>
 <dc:creator>So, Anthony Man Cho</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>68Q25, 65K10, 90C90, 90C26, 90C06</dc:subject>
 <dc:description>  We consider a class of nonsmooth optimization problems over the Stiefel
manifold, in which the objective function is weakly convex in the ambient
Euclidean space. Such problems are ubiquitous in engineering applications but
still largely unexplored. We present a family of Riemannian subgradient-type
methods -- namely Riemannain subgradient, incremental subgradient, and
stochastic subgradient methods -- to solve these problems and show that they
all have an iteration complexity of ${\cal O}(\varepsilon^{-4})$ for driving a
natural stationarity measure below $\varepsilon$. In addition, we establish the
local linear convergence of the Riemannian subgradient and incremental
subgradient methods when the problem at hand further satisfies a sharpness
property and the algorithms are properly initialized and use geometrically
diminishing stepsizes. To the best of our knowledge, these are the first
convergence guarantees for using Riemannian subgradient-type methods to
optimize a class of nonconvex nonsmooth functions over the Stiefel manifold.
The fundamental ingredient in the proof of the aforementioned convergence
results is a new Riemannian subgradient inequality for restrictions of weakly
convex functions on the Stiefel manifold, which could be of independent
interest. We also show that our convergence results can be extended to handle a
class of compact embedded submanifolds of the Euclidean space. Finally, we
discuss the sharpness properties of various formulations of the robust subspace
recovery and orthogonal dictionary learning problems and demonstrate the
convergence performance of the algorithms on both problems via numerical
simulations.
</dc:description>
 <dc:description>Comment: 30 pages. Accepted to SIAM Journal on Optimization</dc:description>
 <dc:date>2019-11-12</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1911.05047</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1911.05889</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generating Persona Consistent Dialogues by Exploiting Natural Language
  Inference</dc:title>
 <dc:creator>Song, Haoyu</dc:creator>
 <dc:creator>Zhang, Wei-Nan</dc:creator>
 <dc:creator>Hu, Jingwen</dc:creator>
 <dc:creator>Liu, Ting</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Consistency is one of the major challenges faced by dialogue agents. A
human-like dialogue agent should not only respond naturally, but also maintain
a consistent persona. In this paper, we exploit the advantages of natural
language inference (NLI) technique to address the issue of generating persona
consistent dialogues. Different from existing work that re-ranks the retrieved
responses through an NLI model, we cast the task as a reinforcement learning
problem and propose to exploit the NLI signals from response-persona pairs as
rewards for the process of dialogue generation. Specifically, our generator
employs an attention-based encoder-decoder to generate persona-based responses.
Our evaluator consists of two components: an adversarially trained naturalness
module and an NLI based consistency module. Moreover, we use another
well-performed NLI model in the evaluation of persona-consistency. Experimental
results on both human and automatic metrics, including the model-based
consistency evaluation, demonstrate that the proposed approach outperforms
strong generative baselines, especially in the persona-consistency of generated
responses.
</dc:description>
 <dc:description>Comment: AAAI20. Update code links</dc:description>
 <dc:date>2019-11-13</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1911.05889</dc:identifier>
 <dc:identifier>doi:10.1609/aaai.v34i05.6417</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1911.07167</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LIDIA: Lightweight Learned Image Denoising with Instance Adaptation</dc:title>
 <dc:creator>Vaksman, Gregory</dc:creator>
 <dc:creator>Elad, Michael</dc:creator>
 <dc:creator>Milanfar, Peyman</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image denoising is a well studied problem with an extensive activity that has
spread over several decades. Despite the many available denoising algorithms,
the quest for simple, powerful and fast denoisers is still an active and
vibrant topic of research. Leading classical denoising methods are typically
designed to exploit the inner structure in images by modeling local overlapping
patches, while operating in an unsupervised fashion. In contrast, recent
newcomers to this arena are supervised and universal neural-network-based
methods that bypass this modeling altogether, targeting the inference goal
directly and globally, while tending to be very deep and parameter heavy.
  This work proposes a novel lightweight learnable architecture for image
denoising, and presents a combination of supervised and unsupervised training
of it, the first aiming for a universal denoiser and the second for adapting it
to the incoming image. Our architecture embeds in it several of the main
concepts taken from classical methods, relying on patch processing, leveraging
non-local self-similarity, exploiting representation sparsity and providing a
multiscale treatment. Our proposed universal denoiser achieves near
state-of-the-art results, while using a small fraction of the typical number of
parameters. In addition, we introduce and demonstrate two highly effective ways
for further boosting the denoising performance, by adapting this universal
network to the input image.
</dc:description>
 <dc:date>2019-11-17</dc:date>
 <dc:date>2020-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1911.07167</dc:identifier>
 <dc:identifier>doi:10.1109/CVPRW50498.2020.00270</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1911.07205</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>REFIT: A Unified Watermark Removal Framework For Deep Learning Systems
  With Limited Data</dc:title>
 <dc:creator>Chen, Xinyun</dc:creator>
 <dc:creator>Wang, Wenxiao</dc:creator>
 <dc:creator>Bender, Chris</dc:creator>
 <dc:creator>Ding, Yiming</dc:creator>
 <dc:creator>Jia, Ruoxi</dc:creator>
 <dc:creator>Li, Bo</dc:creator>
 <dc:creator>Song, Dawn</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Training deep neural networks from scratch could be computationally expensive
and requires a lot of training data. Recent work has explored different
watermarking techniques to protect the pre-trained deep neural networks from
potential copyright infringements. However, these techniques could be
vulnerable to watermark removal attacks. In this work, we propose REFIT, a
unified watermark removal framework based on fine-tuning, which does not rely
on the knowledge of the watermarks, and is effective against a wide range of
watermarking schemes. In particular, we conduct a comprehensive study of a
realistic attack scenario where the adversary has limited training data, which
has not been emphasized in prior work on attacks against watermarking schemes.
To effectively remove the watermarks without compromising the model
functionality under this weak threat model, we propose two techniques that are
incorporated into our fine-tuning framework: (1) an adaption of the elastic
weight consolidation (EWC) algorithm, which is originally proposed for
mitigating the catastrophic forgetting phenomenon; and (2) unlabeled data
augmentation (AU), where we leverage auxiliary unlabeled data from other
sources. Our extensive evaluation shows the effectiveness of REFIT against
diverse watermark embedding schemes. In particular, both EWC and AU
significantly decrease the amount of labeled training data needed for effective
watermark removal, and the unlabeled data samples used for AU do not
necessarily need to be drawn from the same distribution as the benign data for
model evaluation. The experimental results demonstrate that our fine-tuning
based watermark removal attacks could pose real threats to the copyright of
pre-trained models, and thus highlight the importance of further investigating
the watermarking problem and proposing more robust watermark embedding schemes
against the attacks.
</dc:description>
 <dc:description>Comment: ACM Asia Conference on Computer and Communications Security
  (AsiaCCS), 2021. Early version in ICML 2019 Workshop on Security and Privacy
  of Machine Learning. The first two authors contribute equally</dc:description>
 <dc:date>2019-11-17</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1911.07205</dc:identifier>
 <dc:identifier>doi:10.1145/3433210.3453079</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1911.07816</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantized Compressed Sensing by Rectified Linear Units</dc:title>
 <dc:creator>Jung, Hans Christian</dc:creator>
 <dc:creator>Maly, Johannes</dc:creator>
 <dc:creator>Palzer, Lars</dc:creator>
 <dc:creator>Stollenwerk, Alexander</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>62B10</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  This work is concerned with the problem of recovering high-dimensional
signals $\mathbf{x} \in \mathbb{R}^n$ which belong to a convex set of
low-complexity from a small number of quantized measurements. We propose to
estimate the signals via a convex program based on rectified linear units
(ReLUs) for two different quantization schemes, namely one-bit and uniform
multi-bit quantization. Assuming that the linear measurement process can be
modelled by a sensing matrix with i.i.d. subgaussian rows, we obtain for both
schemes near-optimal uniform reconstruction guarantees by adding well-designed
noise to the linear measurements prior to the quantization step. In the one-bit
case, we show that the program is robust against adversarial bit corruptions as
well as additive noise on the linear measurements. Further, our analysis
quantifies precisely how the rate-distortion relationship of the program
changes depending on whether we seek reconstruction accuracies above or below
the noise floor. The proofs rely on recent results by Dirksen and Mendelson on
non-Gaussian hyperplane tessellations. Finally, we complement our theoretical
analysis with numerical experiments which compare our method to other
state-of-the-art methodologies.
</dc:description>
 <dc:description>Comment: 40 pages, 5 figures</dc:description>
 <dc:date>2019-11-18</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1911.07816</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1911.08044</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decision Making for Autonomous Driving via Augmented Adversarial Inverse
  Reinforcement Learning</dc:title>
 <dc:creator>Wang, Pin</dc:creator>
 <dc:creator>Liu, Dapeng</dc:creator>
 <dc:creator>Chen, Jiayu</dc:creator>
 <dc:creator>Li, Hanhan</dc:creator>
 <dc:creator>Chan, Ching-Yao</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Making decisions in complex driving environments is a challenging task for
autonomous agents. Imitation learning methods have great potentials for
achieving such a goal. Adversarial Inverse Reinforcement Learning (AIRL) is one
of the state-of-art imitation learning methods that can learn both a behavioral
policy and a reward function simultaneously, yet it is only demonstrated in
simple and static environments where no interactions are introduced. In this
paper, we improve and stabilize AIRL's performance by augmenting it with
semantic rewards in the learning framework. Additionally, we adapt the
augmented AIRL to a more practical and challenging decision-making task in a
highly interactive environment in autonomous driving. The proposed method is
compared with four baselines and evaluated by four performance metrics.
Simulation results show that the augmented AIRL outperforms all the baseline
methods, and its performance is comparable with that of the experts on all of
the four metrics.
</dc:description>
 <dc:description>Comment: The 2021 International Conference on Robotics and Automation (ICRA
  2021)</dc:description>
 <dc:date>2019-11-18</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1911.08044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1911.09804</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring Uncertainty through Bayesian Learning of Deep Neural Network
  Structure</dc:title>
 <dc:creator>Deng, Zhijie</dc:creator>
 <dc:creator>Luo, Yucen</dc:creator>
 <dc:creator>Zhu, Jun</dc:creator>
 <dc:creator>Zhang, Bo</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Bayesian neural networks (BNNs) augment deep networks with uncertainty
quantification by Bayesian treatment of the network weights. However, such
models face the challenge of Bayesian inference in a high-dimensional and
usually over-parameterized space. This paper investigates a new line of
Bayesian deep learning by performing Bayesian inference on network structure.
Instead of building structure from scratch inefficiently, we draw inspirations
from neural architecture search to represent the network structure. We then
develop an efficient stochastic variational inference approach which unifies
the learning of both network structure and weights. Empirically, our method
exhibits competitive predictive performance while preserving the benefits of
Bayesian principles across challenging scenarios. We also provide convincing
experimental justification for our modeling choice.
</dc:description>
 <dc:description>Comment: 2nd Workshop on Neural Architecture Search at ICLR 2021</dc:description>
 <dc:date>2019-11-21</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1911.09804</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1911.11250</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Visual Fault Detection and Classification System for
  Semiconductor Manufacturing Using Stacked Hybrid Convolutional Neural
  Networks</dc:title>
 <dc:creator>Schlosser, Tobias</dc:creator>
 <dc:creator>Beuth, Frederik</dc:creator>
 <dc:creator>Friedrich, Michael</dc:creator>
 <dc:creator>Kowerko, Danny</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Automated visual inspection in the semiconductor industry aims to detect and
classify manufacturing defects utilizing modern image processing techniques.
While an earliest possible detection of defect patterns allows quality control
and automation of manufacturing chains, manufacturers benefit from an increased
yield and reduced manufacturing costs. Since classical image processing systems
are limited in their ability to detect novel defect patterns, and machine
learning approaches often involve a tremendous amount of computational effort,
this contribution introduces a novel deep neural network based hybrid approach.
Unlike classical deep neural networks, a multi-stage system allows the
detection and classification of the finest structures in pixel size within
high-resolution imagery. Consisting of stacked hybrid convolutional neural
networks (SH-CNN) and inspired by current approaches of visual attention, the
realized system draws the focus over the level of detail from its structures to
more task-relevant areas of interest. The results of our test environment show
that the SH-CNN outperforms current approaches of learning-based automated
visual inspection, whereas a distinction depending on the level of detail
enables the elimination of defect patterns in earlier stages of the
manufacturing process.
</dc:description>
 <dc:description>Comment: Accepted for: 2019 IEEE 24th International Conference on Emerging
  Technologies and Factory Automation (ETFA); the latest versions of this
  contribution cover minor typo corrections</dc:description>
 <dc:date>2019-11-25</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1911.11250</dc:identifier>
 <dc:identifier>doi:10.1109/ETFA.2019.8869311</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1911.11251</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hexagonal Image Processing in the Context of Machine Learning:
  Conception of a Biologically Inspired Hexagonal Deep Learning Framework</dc:title>
 <dc:creator>Schlosser, Tobias</dc:creator>
 <dc:creator>Friedrich, Michael</dc:creator>
 <dc:creator>Kowerko, Danny</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Inspired by the human visual perception system, hexagonal image processing in
the context of machine learning deals with the development of image processing
systems that combine the advantages of evolutionary motivated structures based
on biological models. While conventional state-of-the-art image processing
systems of recording and output devices almost exclusively utilize square
arranged methods, their hexagonal counterparts offer a number of key advantages
that can benefit both researchers and users. This contribution serves as a
general application-oriented approach the synthesis of the therefore designed
hexagonal image processing framework, called Hexnet, the processing steps of
hexagonal image transformation, and dependent methods. The results of our
created test environment show that the realized framework surpasses current
approaches of hexagonal image processing systems, while hexagonal artificial
neural networks can benefit from the implemented hexagonal architecture. As
hexagonal lattice format based deep neural networks, also called H-DNN, can be
compared to their square counterparts by transforming classical square lattice
based data sets into their hexagonal representation, they can also result in a
reduction of trainable parameters as well as result in increased training and
test rates.
</dc:description>
 <dc:description>Comment: Accepted for: 2019 18th IEEE International Conference on Machine
  Learning and Applications (ICMLA); the latest versions of this contribution
  cover minor typo corrections</dc:description>
 <dc:date>2019-11-25</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1911.11251</dc:identifier>
 <dc:identifier>doi:10.1109/ICMLA.2019.00300</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1911.11263</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deeply Shape-guided Cascade for Instance Segmentation</dc:title>
 <dc:creator>Ding, Hao</dc:creator>
 <dc:creator>Qiao, Siyuan</dc:creator>
 <dc:creator>Yuille, Alan</dc:creator>
 <dc:creator>Shen, Wei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The key to a successful cascade architecture for precise instance
segmentation is to fully leverage the relationship between bounding box
detection and mask segmentation across multiple stages. Although modern
instance segmentation cascades achieve leading performance, they mainly make
use of a unidirectional relationship, i.e., mask segmentation can benefit from
iteratively refined bounding box detection. In this paper, we investigate an
alternative direction, i.e., how to take the advantage of precise mask
segmentation for bounding box detection in a cascade architecture. We propose a
Deeply Shape-guided Cascade (DSC) for instance segmentation, which iteratively
imposes the shape guidances extracted from mask prediction at the previous
stage on bounding box detection at current stage. It forms a bi-directional
relationship between the two tasks by introducing three key components: (1)
Initial shape guidance: A mask-supervised Region Proposal Network (mPRN) with
the ability to generate class-agnostic masks; (2) Explicit shape guidance: A
mask-guided region-of-interest (RoI) feature extractor, which employs mask
segmentation at previous stage to focus feature extraction at current stage
within a region aligned well with the shape of the instance-of-interest rather
than a rectangular RoI; (3) Implicit shape guidance: A feature fusion operation
which feeds intermediate mask features at previous stage to the bounding box
head at current stage. Experimental results show that DSC outperforms the
state-of-the-art instance segmentation cascade, Hybrid Task Cascade (HTC), by a
large margin and achieves 51.8 box AP and 45.5 mask AP on COCO test-dev. The
code is released at: https://github.com/hding2455/DSC.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2021</dc:description>
 <dc:date>2019-11-25</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1911.11263</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1911.12018</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Autoregressive Coarse-to-Fine Video Captioning</dc:title>
 <dc:creator>Yang, Bang</dc:creator>
 <dc:creator>Zou, Yuexian</dc:creator>
 <dc:creator>Liu, Fenglin</dc:creator>
 <dc:creator>Zhang, Can</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  It is encouraged to see that progress has been made to bridge videos and
natural language. However, mainstream video captioning methods suffer from slow
inference speed due to the sequential manner of autoregressive decoding, and
prefer generating generic descriptions due to the insufficient training of
visual words (e.g., nouns and verbs) and inadequate decoding paradigm. In this
paper, we propose a non-autoregressive decoding based model with a
coarse-to-fine captioning procedure to alleviate these defects. In
implementations, we employ a bi-directional self-attention based network as our
language model for achieving inference speedup, based on which we decompose the
captioning procedure into two stages, where the model has different focuses.
Specifically, given that visual words determine the semantic correctness of
captions, we design a mechanism of generating visual words to not only promote
the training of scene-related words but also capture relevant details from
videos to construct a coarse-grained sentence &quot;template&quot;. Thereafter, we devise
dedicated decoding algorithms that fill in the &quot;template&quot; with suitable words
and modify inappropriate phrasing via iterative refinement to obtain a
fine-grained description. Extensive experiments on two mainstream video
captioning benchmarks, i.e., MSVD and MSR-VTT, demonstrate that our approach
achieves state-of-the-art performance, generates diverse descriptions, and
obtains high inference efficiency. Our code is available at
https://github.com/yangbang18/Non-Autoregressive-Video-Captioning.
</dc:description>
 <dc:description>Comment: 9 pages, 6 figures, to be published in AAAI2021. Our code is
  available at
  https://github.com/yangbang18/Non-Autoregressive-Video-Captioning</dc:description>
 <dc:date>2019-11-27</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1911.12018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1911.12179</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extended Formulations for Stable Set Polytopes of Graphs Without Two
  Disjoint Odd Cycles</dc:title>
 <dc:creator>Conforti, Michele</dc:creator>
 <dc:creator>Fiorini, Samuel</dc:creator>
 <dc:creator>Huynh, Tony</dc:creator>
 <dc:creator>Weltge, Stefan</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>90C27, 90C10, 05C85</dc:subject>
 <dc:description>  Let $G$ be an $n$-node graph without two disjoint odd cycles. The algorithm
of Artmann, Weismantel and Zenklusen (STOC'17) for bimodular integer programs
can be used to find a maximum weight stable set in $G$ in strongly polynomial
time. Building on structural results characterizing sufficiently connected
graphs without two disjoint odd cycles, we construct a size-$O(n^2)$ extended
formulation for the stable set polytope of $G$.
</dc:description>
 <dc:description>Comment: 19 pages, 3 figures</dc:description>
 <dc:date>2019-11-27</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1911.12179</dc:identifier>
 <dc:identifier>doi:10.1007/s10107-021-01635-0</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.00969</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IENet: Interacting Embranchment One Stage Anchor Free Detector for
  Orientation Aerial Object Detection</dc:title>
 <dc:creator>Lin, Youtian</dc:creator>
 <dc:creator>Feng, Pengming</dc:creator>
 <dc:creator>Guan, Jian</dc:creator>
 <dc:creator>Wang, Wenwu</dc:creator>
 <dc:creator>Chambers, Jonathon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Object detection in aerial images is a challenging task due to the lack of
visible features and variant orientation of objects. Significant progress has
been made recently for predicting targets from aerial images with horizontal
bounding boxes (HBBs) and oriented bounding boxes (OBBs) using two-stage
detectors with region based convolutional neural networks (R-CNN), involving
object localization in one stage and object classification in the other.
However, the computational complexity in two-stage detectors is often high,
especially for orientational object detection, due to anchor matching and using
regions of interest (RoI) pooling for feature extraction. In this paper, we
propose a one-stage anchor free detector for orientational object detection,
namely, an interactive embranchment network (IENet), which is built upon a
detector with prediction in per-pixel fashion. First, a novel geometric
transformation is employed to better represent the oriented object in angle
prediction, then a branch interactive module with a self-attention mechanism is
developed to fuse features from classification and box regression branches.
Finally, we introduce an enhanced intersection over union (IoU) loss for OBB
detection, which is computationally more efficient than regular polygon IoU.
Experiments conducted demonstrate the effectiveness and the superiority of our
proposed method, as compared with state-of-the-art detectors.
</dc:description>
 <dc:date>2019-12-02</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.00969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.01499</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards blind user's indoor navigation: a comparative study of beacons
  and decawave for indoor accurate location</dc:title>
 <dc:creator>Sharma, Prabin</dc:creator>
 <dc:creator>Bidari, Sambad</dc:creator>
 <dc:creator>Thapa, Kisan</dc:creator>
 <dc:creator>Valente, Antonio</dc:creator>
 <dc:creator>Paredes, Hugo</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  There are many systems for indoor navigation specially built for visually
impaired people but only some has good accuracy for navigation. While there are
solutions like global navigation satellite systems for the localization
outdoors, problems arise in urban scenarios and indoors due to insufficient or
failed signal reception. To build a support system for navigation for visually
impaired people, in this paper we present a comparison of indoor localization
and navigation system, which performs continuous and real-time processing using
commercially available systems (Beacons and Decawave) under the same
experimental condition for the performance analysis. Error is calculated and
analyzed using Euclidean distance and standard deviation for both the cases. We
used Navigine Platform for this navigation system which allows both
Tri-lateration as well as Fingerprinting algorithms. For calculating location
we have used the concept of Time of Arrival and time of difference of arrivals.
Taking into concern about the blind people, location is important as well as
accuracy is necessity because small measurement in the walk is important to
them. With this concern, in this paper, we are showing the comparative study of
beacons and Decawave. The study and the accuracy tests of those systems for the
blind people/user's in navigating indoor are presented in this paper.
</dc:description>
 <dc:description>Comment: 5 Pages, 8 Figures</dc:description>
 <dc:date>2019-12-02</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.01499</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.02028</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Maximin Optimal Online Power Control Policy for Energy Harvesting
  Communications</dc:title>
 <dc:creator>Yang, Shengtian</dc:creator>
 <dc:creator>Chen, Jun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A general theory of online power control for discrete-time battery limited
energy harvesting communications is developed, which leads to, among other
things, an explicit characterization of a maximin optimal policy. This policy
only requires the knowledge of the (effective) mean of the energy arrival
process and maximizes the minimum asymptotic expected average reward (with the
minimization taken over all energy arrival distributions of a given (effective)
mean). Moreover, it is universally near optimal and has a strictly better
worst-case performance as well as a strictly improved lower multiplicative
factor in comparison with the fixed fraction policy proposed by Shaviv and
\&quot;{O}zg\&quot;{u}r when the objective is to maximize the throughput over an additive
white Gaussian noise channel. The competitiveness of this maximin optimal
policy is also demonstrated via numerical examples.
</dc:description>
 <dc:description>Comment: 13 pages, 5 figures</dc:description>
 <dc:date>2019-12-04</dc:date>
 <dc:date>2020-04-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.02028</dc:identifier>
 <dc:identifier>IEEE Trans. Wireless Commun. 19 (2020) 6708 - 6720</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2020.3004693</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.03264</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PU-GCN: Point Cloud Upsampling using Graph Convolutional Networks</dc:title>
 <dc:creator>Qian, Guocheng</dc:creator>
 <dc:creator>Abualshour, Abdulellah</dc:creator>
 <dc:creator>Li, Guohao</dc:creator>
 <dc:creator>Thabet, Ali</dc:creator>
 <dc:creator>Ghanem, Bernard</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The effectiveness of learning-based point cloud upsampling pipelines heavily
relies on the upsampling modules and feature extractors used therein. For the
point upsampling module, we propose a novel model called NodeShuffle, which
uses a Graph Convolutional Network (GCN) to better encode local point
information from point neighborhoods. NodeShuffle is versatile and can be
incorporated into any point cloud upsampling pipeline. Extensive experiments
show how NodeShuffle consistently improves state-of-the-art upsampling methods.
For feature extraction, we also propose a new multi-scale point feature
extractor, called Inception DenseGCN. By aggregating features at multiple
scales, this feature extractor enables further performance gain in the final
upsampled point clouds. We combine Inception DenseGCN with NodeShuffle into a
new point upsampling pipeline called PU-GCN. PU-GCN sets new state-of-art
performance with much fewer parameters and more efficient inference.
</dc:description>
 <dc:description>Comment: Get accepted to CVPR 2021. The source code of this work is available
  at https://github.com/guochengqian/PU-GCN</dc:description>
 <dc:date>2019-11-30</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.03264</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.03761</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variationally Regularized Graph-based Representation Learning for
  Electronic Health Records</dc:title>
 <dc:creator>Zhu, Weicheng</dc:creator>
 <dc:creator>Razavian, Narges</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Electronic Health Records (EHR) are high-dimensional data with implicit
connections among thousands of medical concepts. These connections, for
instance, the co-occurrence of diseases and lab-disease correlations can be
informative when only a subset of these variables is documented by the
clinician. A feasible approach to improving the representation learning of EHR
data is to associate relevant medical concepts and utilize these connections.
Existing medical ontologies can be the reference for EHR structures, but they
place numerous constraints on the data source. Recent progress on graph neural
networks (GNN) enables end-to-end learning of topological structures for
non-grid or non-sequential data. However, there are problems to be addressed on
how to learn the medical graph adaptively and how to understand the effect of
the medical graph on representation learning. In this paper, we propose a
variationally regularized encoder-decoder graph network that achieves more
robustness in graph structure learning by regularizing node representations.
Our model outperforms the existing graph and non-graph based methods in various
EHR predictive tasks based on both public data and real-world clinical data.
Besides the improvements in empirical experiment performances, we provide an
interpretation of the effect of variational regularization compared to standard
graph neural network, using singular value analysis.
</dc:description>
 <dc:date>2019-12-08</dc:date>
 <dc:date>2021-02-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.03761</dc:identifier>
 <dc:identifier>doi:10.1145/3450439.3451855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.04496</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuous Domains in Formal Concept Analysis</dc:title>
 <dc:creator>Guo, Longchun Wang Lankun</dc:creator>
 <dc:creator>Li, Qingguo</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  Formal Concept Analysis has proven to be an effective method of restructuring
complete lattices and various algebraic domains. In this paper, the notions of
attribute continuous formal context and continuous formal concept are
introduced by considering a selection F of fnite subsets of attributes. Our
decision of a selection F relies on a kind of generalized interior operators.
It is shown that the set of continuous formal concepts forms a continuous
domain, and every continuous domain can be obtained in this way. Moreover, an
notion of F-morphism is also identified to produce a category equivalent to
that of continuous domains with Scott-continuous functions. This paper also
consider the representations of various subclasses of continuous domains such
as algebraic domains, bounded complete domains and stably continuous
semilattices. These results explore the fundamental idea of domain theory in
Formal Concept Analysis from a categorical viewpoint.
</dc:description>
 <dc:date>2019-12-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.04496</dc:identifier>
 <dc:identifier>Fundamenta Informaticae 179 (2021)</dc:identifier>
 <dc:identifier>doi:10.3233/FI-2021-2025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.04536</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Analysis System of Calcaneus Radiograph: Rotation-Invariant
  Landmark Detection for Calcaneal Angle Measurement, Fracture Identification
  and Fracture Region Segmentation</dc:title>
 <dc:creator>Guo, Jia</dc:creator>
 <dc:creator>Mu, Yuxuan</dc:creator>
 <dc:creator>Xue, Dong</dc:creator>
 <dc:creator>Li, Huiqi</dc:creator>
 <dc:creator>Chen, Junxian</dc:creator>
 <dc:creator>Yan, Huanxin</dc:creator>
 <dc:creator>Xu, Hailin</dc:creator>
 <dc:creator>Wang, Wei</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Calcaneus is the largest tarsal bone to withstand the daily stresses of
weight-bearing. The calcaneal fracture is the most common type in the tarsal
bone fractures. After a fracture is suspected, plain radiographs should be
taken first. Bohler's Angle (BA) and Critical Angle of Gissane (CAG), measured
by four anatomic landmarks in lateral foot radiograph, can guide fracture
diagnosis and facilitate operative recovery of the fractured calcaneus. This
study aims to develop an analysis system that can automatically locate four
anatomic landmarks, measure BA and CAG for fracture assessment, identify
fractured calcaneus, and segment fractured regions. For landmark detection, we
proposed a coarse-to-fine Rotation-Invariant Regression-Voting (RIRV) landmark
detection method based on regressive Multi-Layer Perceptron (MLP) and Scale
Invariant Feature Transform (SIFT) patch descriptor, which solves the problem
of fickle rotation of calcaneus. By implementing a novel normalization
approach, the RIRV method is explicitly rotation-invariance comparing with
traditional regressive methods. For fracture identification and segmentation, a
convolution neural network (CNN) based on U-Net with auxiliary classification
head (U-Net-CH) is designed. The input ROIs of the CNN are normalized by
detected landmarks to uniform view, orientation, and scale. The advantage of
this approach is the multi-task learning that combines classification and
segmentation. Our system can accurately measure BA and CAG with a mean angle
error of 3.8 and 6.2 respectively. For fracture identification and fracture
region segmentation, our system presents good performance with an F1-score of
96.55%, recall of 94.99%, and segmentation IoU-score of 0.586.
</dc:description>
 <dc:date>2019-12-10</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.04536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.05067</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wide-Area Land Cover Mapping with Sentinel-1 Imagery using Deep Learning
  Semantic Segmentation Models</dc:title>
 <dc:creator>&#x160;&#x107;epanovi&#x107;, Sanja</dc:creator>
 <dc:creator>Antropov, Oleg</dc:creator>
 <dc:creator>Laurila, Pekka</dc:creator>
 <dc:creator>Rauste, Yrj&#xf6;</dc:creator>
 <dc:creator>Ignatenko, Vladimir</dc:creator>
 <dc:creator>Praks, Jaan</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Land cover mapping is essential to monitoring the environment and
understanding the effects of human activities on it. The automatic approaches
to land cover mapping (i.e., image segmentation) mostly used traditional
machine learning that requires heuristic feature design. On natural images,
deep learning has outperformed traditional machine learning approaches for
image segmentation. On remote sensing images, recent studies demonstrate
successful applications of specific deep learning models to small-scale land
cover mapping tasks (e.g., to classify wetland complexes). However, it is not
readily clear which of the existing models are the best candidates for which
remote sensing task. In this study, we answer that question for mapping the
fundamental land cover classes using satellite radar data. We took Sentinel-1
C-band SAR images available at no cost to users as representative data. CORINE
land cover map was used as a reference, and the models were trained to
distinguish between the 5 major CORINE classes. We selected seven among the
state-of-the-art semantic segmentation models so that they cover a diverse set
of approaches: U-Net, DeepLabV3+, PSPNet, BiSeNet, SegNet, FC-DenseNet, and
FRRN-B. The models were pre-trained on the ImageNet dataset and further
fine-tuned in this study. All the models demonstrated solid performance with
overall accuracy between 87.9% and 93.1%, and with good to a very good
agreement (kappa statistic between 0.75 and 0.86). The two best models were
FC-DenseNet and SegNet, with the latter having a much smaller inference time.
Overall, our results indicate that the semantic segmentation models are
suitable for efficient wide-area mapping using satellite SAR imagery and also
provide baseline accuracy against which the newly proposed models should be
evaluated.
</dc:description>
 <dc:date>2019-12-10</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.05067</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.05191</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Iterative Heuristic Method to Determine Radial Topology for
  Distribution System Restoration</dc:title>
 <dc:creator>Liu, Jiayu</dc:creator>
 <dc:creator>Zhang, Qiqi</dc:creator>
 <dc:creator>Li, Jiaxu</dc:creator>
 <dc:creator>Wang, Ying</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Coordinating multiple local power sources can restore critical loads after
the major outages caused by extreme events. A radial topology is needed for
distribution system restoration, while determining a good topology in real-time
for online use is a challenge. In this paper, a graph theory-based heuristic
considering power flow state is proposed to fast determine the radial topology.
The loops of distribution network are eliminated by iteration. The proposed
method is validated by one snapshot and multi-period critical load restoration
models on different cases. The case studies indicate that the proposed method
can determine radial topology in a few seconds and ensure the restoration
capacity.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure, IEEE conference-- CIEEC 2021</dc:description>
 <dc:date>2019-12-11</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.05191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.05652</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Human Objectives by Evaluating Hypothetical Behavior</dc:title>
 <dc:creator>Reddy, Siddharth</dc:creator>
 <dc:creator>Dragan, Anca D.</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:creator>Legg, Shane</dc:creator>
 <dc:creator>Leike, Jan</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We seek to align agent behavior with a user's objectives in a reinforcement
learning setting with unknown dynamics, an unknown reward function, and unknown
unsafe states. The user knows the rewards and unsafe states, but querying the
user is expensive. To address this challenge, we propose an algorithm that
safely and interactively learns a model of the user's reward function. We start
with a generative model of initial states and a forward dynamics model trained
on off-policy data. Our method uses these models to synthesize hypothetical
behaviors, asks the user to label the behaviors with rewards, and trains a
neural network to predict the rewards. The key idea is to actively synthesize
the hypothetical behaviors from scratch by maximizing tractable proxies for the
value of information, without interacting with the environment. We call this
method reward query synthesis via trajectory optimization (ReQueST). We
evaluate ReQueST with simulated users on a state-based 2D navigation task and
the image-based Car Racing video game. The results show that ReQueST
significantly outperforms prior methods in learning reward models that transfer
to new environments with different initial state distributions. Moreover,
ReQueST safely trains the reward model to detect unsafe states, and corrects
reward hacking before deploying the agent.
</dc:description>
 <dc:description>Comment: Published at International Conference on Machine Learning (ICML) 2020</dc:description>
 <dc:date>2019-12-05</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.05652</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.06311</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Short-duration Speaker Verification (SdSV) Challenge 2021: the Challenge
  Evaluation Plan</dc:title>
 <dc:creator>Zeinali, Hossein</dc:creator>
 <dc:creator>Lee, Kong Aik</dc:creator>
 <dc:creator>Alam, Jahangir</dc:creator>
 <dc:creator>Burget, Lukas</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  This document describes the Short-duration Speaker Verification (SdSV)
Challenge 2021. The main goal of the challenge is to evaluate new technologies
for text-dependent (TD) and text-independent (TI) speaker verification (SV) in
a short duration scenario. The proposed challenge evaluates SdSV with varying
degree of phonetic overlap between the enrollment and test utterances
(cross-lingual). It is the first challenge with a broad focus on systematic
benchmark and analysis on varying degrees of phonetic variability on
short-duration speaker recognition. We expect that modern methods (deep neural
networks in particular) will play a key role.
</dc:description>
 <dc:date>2019-12-12</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.06311</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.07746</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Freeway network design with exclusive lanes for automated vehicles under
  endogenous mobility demand</dc:title>
 <dc:creator>Chakraborty, Shantanu</dc:creator>
 <dc:creator>Rey, David</dc:creator>
 <dc:creator>Levin, Michael W.</dc:creator>
 <dc:creator>Waller, S. Travis</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Automated vehicles (AV) have the potential to provide cost-effective mobility
options along with overall system-level benefits in terms of congestion and
vehicular emissions. Additional resource allocation at the network level, such
as AV-exclusive lanes, can further foster the usage of AVs rendering this mode
of travel more attractive than legacy vehicles (LV). However, it is necessary
to find the crucial locations in the network where providing these dedicated
lanes would reap the maximum benefits. In this study, we propose an integrated
mixed-integer programming framework for optimal AV-exclusive lane design on
freeway networks which accounts for commuters' demand split among AVs and LVs
via a logit model incorporating class-based utilities. We incorporate the link
transmission model (LTM) as the underlying traffic flow model due to its
computational efficiency for system optimum dynamic traffic assignment. The LTM
is modified to integrate two vehicle classes namely, LVs and AVs with a
lane-based approach. The presence of binary variables to represent lane design
and the logit model for endogenous demand estimation results in a nonconvex
mixed-integer nonlinear program (MINLP) formulation. We propose a Benders'
decomposition approach to tackle this challenging optimization problem. Our
approach iteratively explores possible lane designs in the Benders' master
problem and, at each iteration, solves a sequence of system-optimum dynamic
traffic assignment (SODTA) problems which is shown to converge to fixed-points
representative of logit-compatible demand splits. Further, we prove that the
proposed solution method converges to a local optima of the nonconvex problem
and identify under which conditions this local optima is a global solution. The
proposed approach is implemented on three hypothetical freeway networks with
single and multiple origins and destinations.
</dc:description>
 <dc:date>2019-12-16</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.07746</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.08648</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inferring the causal effect of journals on citations</dc:title>
 <dc:creator>Traag, V. A.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Articles in high-impact journals are, on average, more frequently cited. But
are they cited more often because those articles are somehow more &quot;citable&quot;? Or
are they cited more often simply because they are published in a high-impact
journal? Although some evidence suggests the latter, the causal relationship is
not clear. We here compare citations of preprints to citations of the published
version to uncover the causal mechanism. We build on an earlier model of
citation dynamics to infer the causal effect of journals on citations. We find
that high-impact journals select articles that tend to attract more citations.
At the same time, we find that high-impact journals augment the citation rate
of published articles. Our results yield a deeper understanding of the role of
journals in the research system. The use of journal metrics in research
evaluation has been increasingly criticized in recent years and article-level
citations are sometimes suggested as an alternative. Our results show that
removing impact factors from evaluation does not negate the influence of
journals. This insight has important implications for changing practices of
research evaluation.
</dc:description>
 <dc:date>2019-12-18</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.08648</dc:identifier>
 <dc:identifier>doi:10.1162/qss_a_00128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.09570</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometric Considerations of a Good Dictionary for Koopman Analysis of
  Dynamical Systems: Cardinality, 'Primary Eigenfunction,' and Efficient
  Representation</dc:title>
 <dc:creator>Bollt, Erik</dc:creator>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Representation of a dynamical system in terms of simplifying modes is a
central premise of reduced order modelling and a primary concern of the
increasingly popular DMD (dynamic mode decomposition) empirical interpretation
of Koopman operator analysis of complex systems. In the spirit of optimal
approximation and reduced order modelling the goal of DMD methods and variants
are to describe the dynamical evolution as a linear evolution in an
appropriately transformed lower rank space, as best as possible.
  That Koopman eigenfunctions follow a linear PDE that is solvable by the
method of characteristics yields several interesting relationships between
geometric and algebraic properties.
  Corresponding to freedom to arbitrarily define functions on a data surface,
for each eigenvalue, there are infinitely many eigenfunctions emanating along
characteristics. We focus on contrasting cardinality and equivalence. In
particular, we introduce an equivalence class, &quot;primary eigenfunctions,&quot;
consisting of those eigenfunctions with identical sets of level sets, that
helps contrast algebraic multiplicity from other geometric aspects.
  Popularly, Koopman methods and notably dynamic mode decomposition (DMD) and
variants, allow data-driven study of how measurable functions evolve along
orbits. As far as we know, there has not been an in depth study regarding the
underlying geometry as related to an efficient representation. We present a
construction that leads to functions on the data surface whose corresponding
eigenfunctions are efficient in a least squares sense. We call this
construction optimal Koopman eigenfunction DMD, (oKEEDMD), and we highlight
with examples.
</dc:description>
 <dc:description>Comment: 27 pages, 8 figures</dc:description>
 <dc:date>2019-12-18</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.09570</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.09623</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Heterogeneity-aware and communication-efficient distributed statistical
  inference</dc:title>
 <dc:creator>Duan, Rui</dc:creator>
 <dc:creator>Ning, Yang</dc:creator>
 <dc:creator>Chen, Yong</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  In multicenter research, individual-level data are often protected against
sharing across sites. To overcome the barrier of data sharing, many distributed
algorithms, which only require sharing aggregated information, have been
developed. The existing distributed algorithms usually assume the data are
homogeneously distributed across sites. This assumption ignores the important
fact that the data collected at different sites may come from various
sub-populations and environments, which can lead to heterogeneity in the
distribution of the data. Ignoring the heterogeneity may lead to erroneous
statistical inference. In this paper, we propose distributed algorithms which
account for the heterogeneous distributions by allowing site-specific nuisance
parameters. The proposed methods extend the surrogate likelihood approach to
the heterogeneous setting by applying a novel density ratio tilting method to
the efficient score function. The proposed algorithms maintain the same
communication cost as the existing communication-efficient algorithms. We
establish a non-asymptotic risk bound for the proposed distributed estimator
and its limiting distribution in the two-index asymptotic setting which allows
both sample size per site and the number of sites to go to infinity. In
addition, we show that the asymptotic variance of the estimator attains the
Cram\'er-Rao lower bound when the number of sites is in rate smaller than the
sample size at each site. Finally, we use simulation studies and a real data
application to demonstrate the validity and feasibility of the proposed
methods.
</dc:description>
 <dc:date>2019-12-19</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.09623</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.09678</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IRS: A Large Naturalistic Indoor Robotics Stereo Dataset to Train Deep
  Models for Disparity and Surface Normal Estimation</dc:title>
 <dc:creator>Wang, Qiang</dc:creator>
 <dc:creator>Zheng, Shizhen</dc:creator>
 <dc:creator>Yan, Qingsong</dc:creator>
 <dc:creator>Deng, Fei</dc:creator>
 <dc:creator>Zhao, Kaiyong</dc:creator>
 <dc:creator>Chu, Xiaowen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Indoor robotics localization, navigation, and interaction heavily rely on
scene understanding and reconstruction. Compared to the monocular vision which
usually does not explicitly introduce any geometrical constraint, stereo
vision-based schemes are more promising and robust to produce accurate
geometrical information, such as surface normal and depth/disparity. Besides,
deep learning models trained with large-scale datasets have shown their
superior performance in many stereo vision tasks. However, existing stereo
datasets rarely contain the high-quality surface normal and disparity ground
truth, which hardly satisfies the demand of training a prospective deep model
for indoor scenes. To this end, we introduce a large-scale synthetic but
naturalistic indoor robotics stereo (IRS) dataset with over 100K stereo RGB
images and high-quality surface normal and disparity maps. Leveraging the
advanced rendering techniques of our customized rendering engine, the dataset
is considerably close to the real-world captured images and covers several
visual effects, such as brightness changes, light reflection/transmission, lens
flare, vivid shadow, etc. We compare the data distribution of IRS with existing
stereo datasets to illustrate the typical visual attributes of indoor scenes.
Besides, we present DTN-Net, a two-stage deep model for surface normal
estimation. Extensive experiments show the advantages and effectiveness of IRS
in training deep models for disparity estimation, and DTN-Net provides
state-of-the-art results for normal estimation compared to existing methods.
</dc:description>
 <dc:date>2019-12-20</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.09678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.10269</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>UWGAN: Underwater GAN for Real-world Underwater Color Restoration and
  Dehazing</dc:title>
 <dc:creator>Wang, Nan</dc:creator>
 <dc:creator>Zhou, Yabin</dc:creator>
 <dc:creator>Han, Fenglei</dc:creator>
 <dc:creator>Zhu, Haitao</dc:creator>
 <dc:creator>Yao, Jingzheng</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In real-world underwater environment, exploration of seabed resources,
underwater archaeology, and underwater fishing rely on a variety of sensors,
vision sensor is the most important one due to its high information content,
non-intrusive, and passive nature. However, wavelength-dependent light
attenuation and back-scattering result in color distortion and haze effect,
which degrade the visibility of images. To address this problem, firstly, we
proposed an unsupervised generative adversarial network (GAN) for generating
realistic underwater images (color distortion and haze effect) from in-air
image and depth map pairs based on improved underwater imaging model. Secondly,
U-Net, which is trained efficiently using synthetic underwater dataset, is
adopted for color restoration and dehazing. Our model directly reconstructs
underwater clear images using end-to-end autoencoder networks, while
maintaining scene content structural similarity. The results obtained by our
method were compared with existing methods qualitatively and quantitatively.
Experimental results obtained by the proposed model demonstrate well
performance on open real-world underwater datasets, and the processing speed
can reach up to 125FPS running on one NVIDIA 1060 GPU. Source code, sample
datasets are made publicly available at
https://github.com/infrontofme/UWGAN_UIE.
</dc:description>
 <dc:description>Comment: 10 pages, 8 figures</dc:description>
 <dc:date>2019-12-21</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.10269</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.10347</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-Complexity Random Rotation-based Schemes for Intelligent Reflecting
  Surfaces</dc:title>
 <dc:creator>Psomas, Constantinos</dc:creator>
 <dc:creator>Krikidis, Ioannis</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  The employment of intelligent reflecting surfaces (IRSs) is a potential and
promising solution to increase the spectral and energy efficiency of wireless
communication networks. Despite their many advantages, IRS-aided communications
have limitations as they are subject to high propagation losses. To overcome
this, the phase rotation (shift) at each element needs to be designed in such a
way as to increase the channel gain at the destination. However, this increases
the system's complexity as well as its power consumption. In this paper, we
present an analytical framework for the performance of random rotation-based
IRS-aided communications. Under this framework, we propose four low-complexity
and energy efficient schemes, based on a coding or a selection approach. Both
of these approaches employ random phase rotations and require limited knowledge
of channel state information. Specifically, the coding-based schemes use
time-varying random phase rotations to produce an equivalent time-varying
channel. On the other hand, the selection-based schemes select a partition of
the IRS elements based on the received signal power at the destination.
Analytical expressions for the achieved outage probability and energy
efficiency of each scheme are derived. It is demonstrated that all schemes can
provide significant performance gains as well as full diversity order.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2019-12-21</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.10347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.11258</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Graph Transformer for Free-Hand Sketch Recognition</dc:title>
 <dc:creator>Xu, Peng</dc:creator>
 <dc:creator>Joshi, Chaitanya K.</dc:creator>
 <dc:creator>Bresson, Xavier</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Learning meaningful representations of free-hand sketches remains a
challenging task given the signal sparsity and the high-level abstraction of
sketches. Existing techniques have focused on exploiting either the static
nature of sketches with Convolutional Neural Networks (CNNs) or the temporal
sequential property with Recurrent Neural Networks (RNNs). In this work, we
propose a new representation of sketches as multiple sparsely connected graphs.
We design a novel Graph Neural Network (GNN), the Multi-Graph Transformer
(MGT), for learning representations of sketches from multiple graphs which
simultaneously capture global and local geometric stroke structures, as well as
temporal information. We report extensive numerical experiments on a sketch
recognition task to demonstrate the performance of the proposed approach.
Particularly, MGT applied on 414k sketches from Google QuickDraw: (i) achieves
small recognition gap to the CNN-based performance upper bound (72.80% vs.
74.22%), and (ii) outperforms all RNN-based models by a significant margin. To
the best of our knowledge, this is the first work proposing to represent
sketches as graphs and apply GNNs for sketch recognition. Code and trained
models are available at
https://github.com/PengBoXiangShang/multigraph_transformer.
</dc:description>
 <dc:description>Comment: This paper has been accepted by IEEE TNNLS</dc:description>
 <dc:date>2019-12-24</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.11258</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.11264</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Manifold Embedding for Hyperspectral Image Classification</dc:title>
 <dc:creator>Gong, Zhiqiang</dc:creator>
 <dc:creator>Hu, Weidong</dc:creator>
 <dc:creator>Du, Xiaoyong</dc:creator>
 <dc:creator>Zhong, Ping</dc:creator>
 <dc:creator>Hu, Panhe</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Deep learning methods have played a more and more important role in
hyperspectral image classification. However, the general deep learning methods
mainly take advantage of the information of sample itself or the pairwise
information between samples while ignore the intrinsic data structure within
the whole data. To tackle this problem, this work develops a novel deep
manifold embedding method(DMEM) for hyperspectral image classification. First,
each class in the image is modelled as a specific nonlinear manifold and the
geodesic distance is used to measure the correlation between the samples. Then,
based on the hierarchical clustering, the manifold structure of the data can be
captured and each nonlinear data manifold can be divided into several
sub-classes. Finally, considering the distribution of each sub-class and the
correlation between different subclasses, the DMEM is constructed to preserve
the estimated geodesic distances on the data manifold between the learned low
dimensional features of different samples. Experiments over three real-world
hyperspectral image datasets have demonstrated the effectiveness of the
proposed method.
</dc:description>
 <dc:description>Comment: Accepted by IEEE TCYB</dc:description>
 <dc:date>2019-12-24</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.11264</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.11292</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational framework for monolithic coupling for thin fluid flow in
  contact interfaces</dc:title>
 <dc:creator>Shvarts, Andrei G.</dc:creator>
 <dc:creator>Vignollet, Julien</dc:creator>
 <dc:creator>Yastrebov, Vladislav A.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:description>  We developed a computational framework for simulating thin fluid flow in
narrow interfaces between contacting solids, which is relevant for a range of
engineering, biological and geophysical applications. The treatment of this
problem requires coupling between fluid and solid mechanics equations, further
complicated by contact constraints and potentially complex geometrical features
of contacting surfaces. We developed a monolithic finite-element framework for
handling mechanical contact, thin incompressible viscous flow and fluid-induced
tractions on the surface of the solid, suitable for both one- and two-way
coupling approaches. Additionally, we consider the possibility of fluid
entrapment in &quot;pools&quot; delimited by contact patches and its pressurisation
following a non-linear compressibility constitutive law. Furthermore, image
analysis algorithms were adapted to identify the local status of each interface
element within the Newton-Raphson loop. First, an application of the proposed
framework for a problem with a model geometry is given, and the robustness is
demonstrated by the residual-wise and status-wise convergence. The full
capability of the developed two-way coupling framework is demonstrated on a
problem of a fluid flow in contact interface between a solid with
representative rough surface and a rigid flat. The evolution of the contact
pressure, fluid flow pattern and the morphology of trapped fluid zones until
the complete sealing of the interface is displayed. Additionally, we
demonstrated an almost mesh-independent result of a refined post-processing
approach to the real contact-area computation. The developed framework permits
not only to study the evolution of effective properties of contact interfaces,
but also to highlight the difference between one- and two-way coupling
approaches and to quantify the effect of multiple trapped fluid &quot;pools&quot; on the
coupled problem.
</dc:description>
 <dc:description>Comment: 38 pages, 15 figures</dc:description>
 <dc:date>2019-12-24</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.11292</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.11316</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TRADI: Tracking deep neural network weight distributions for uncertainty
  estimation</dc:title>
 <dc:creator>Franchi, Gianni</dc:creator>
 <dc:creator>Bursuc, Andrei</dc:creator>
 <dc:creator>Aldea, Emanuel</dc:creator>
 <dc:creator>Dubuisson, Severine</dc:creator>
 <dc:creator>Bloch, Isabelle</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  During training, the weights of a Deep Neural Network (DNN) are optimized
from a random initialization towards a nearly optimum value minimizing a loss
function. Only this final state of the weights is typically kept for testing,
while the wealth of information on the geometry of the weight space,
accumulated over the descent towards the minimum is discarded. In this work we
propose to make use of this knowledge and leverage it for computing the
distributions of the weights of the DNN. This can be further used for
estimating the epistemic uncertainty of the DNN by sampling an ensemble of
networks from these distributions. To this end we introduce a method for
tracking the trajectory of the weights during optimization, that does not
require any changes in the architecture nor on the training procedure. We
evaluate our method on standard classification and regression benchmarks, and
on out-of-distribution detection for classification and semantic segmentation.
We achieve competitive results, while preserving computational efficiency in
comparison to other popular approaches.
</dc:description>
 <dc:description>Comment: Accepted to ECCV2020</dc:description>
 <dc:date>2019-12-24</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.11316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.12256</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Backpropagation through nonlinear units for all-optical training of
  neural networks</dc:title>
 <dc:creator>Guo, Xianxin</dc:creator>
 <dc:creator>Barrett, Thomas D.</dc:creator>
 <dc:creator>Wang, Zhiming M.</dc:creator>
 <dc:creator>Lvovsky, A. I.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:description>  Backpropagation through nonlinear neurons is an outstanding challenge to the
field of optical neural networks and the major conceptual barrier to
all-optical training schemes. Each neuron is required to exhibit a
directionally dependent response to propagating optical signals, with the
backwards response conditioned on the forward signal, which is highly
non-trivial to implement optically. We propose a practical and surprisingly
simple solution that uses saturable absorption to provide the network
nonlinearity. We find that the backward propagating gradients required to train
the network can be approximated in a pump-probe scheme that requires only
passive optical elements. Simulations show that, with readily obtainable
optical depths, our approach can achieve equivalent performance to
state-of-the-art computational networks on image classification benchmarks,
even in deep networks with multiple sequential gradient approximations. This
scheme is compatible with leading optical neural network proposals and
therefore provides a feasible path towards end-to-end optical training.
</dc:description>
 <dc:description>Comment: Error fixed in Fig.1</dc:description>
 <dc:date>2019-12-23</dc:date>
 <dc:date>2020-10-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.12256</dc:identifier>
 <dc:identifier>Photonics Research 9, B71-B80 (2021)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.12936</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovering Latent Classes for Semi-Supervised Semantic Segmentation</dc:title>
 <dc:creator>Zatsarynna, Olga</dc:creator>
 <dc:creator>Sawatzky, Johann</dc:creator>
 <dc:creator>Gall, Juergen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  High annotation costs are a major bottleneck for the training of semantic
segmentation systems. Therefore, methods working with less annotation effort
are of special interest. This paper studies the problem of semi-supervised
semantic segmentation. This means that only a small subset of the training
images is annotated while the other training images do not contain any
annotation. In order to leverage the information present in the unlabeled
images, we propose to learn a second task that is related to semantic
segmentation but easier. On labeled images, we learn latent classes consistent
with semantic classes so that the variety of semantic classes assigned to a
latent class is as low as possible. On unlabeled images, we predict a
probability map for latent classes and use it as a supervision signal to learn
semantic segmentation. The latent classes, as well as the semantic classes, are
simultaneously predicted by a two-branch network. In our experiments on Pascal
VOC and Cityscapes, we show that the latent classes learned this way have an
intuitive meaning and that the proposed method achieves state of the art
results for semi-supervised semantic segmentation.
</dc:description>
 <dc:description>Comment: In DAGM German Conference on Pattern Recognition (GCPR'20)</dc:description>
 <dc:date>2019-12-30</dc:date>
 <dc:date>2021-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.12936</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-030-71278-5_15</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1912.13248</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Numerical approximation of the value of a stochastic differential game
  with asymmetric information</dc:title>
 <dc:creator>Ba&#x148;as, &#x13d;ubom&#xed;r</dc:creator>
 <dc:creator>Ferrari, Giorgio</dc:creator>
 <dc:creator>Randrianasolo, Tsiry A.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65K15, 65C20, 49N70, 49L25, 35F21, 52A27, 52B55</dc:subject>
 <dc:description>  We consider a convexity constrained Hamilton-Jacobi-Bellman-type obstacle
problem for the value function of a zero-sum differential game with asymmetric
information. We propose a convexity-preserving probabilistic numerical scheme
for the approximation of the value function which is discrete w.r.t. the time
and convexity variables, and show that the scheme converges to the unique
viscosity solution of the considered problem. Furthermore, we generalize the
semi-discrete scheme to obtain an implementable fully discrete numerical
approximation of the value function and present numerical experiments to
demonstrate the properties of the proposed numerical scheme.
</dc:description>
 <dc:description>Comment: 23 pages, 8 figures</dc:description>
 <dc:date>2019-12-31</dc:date>
 <dc:date>2020-10-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1912.13248</dc:identifier>
 <dc:identifier>SIAM Journal on Control and Optimization, 2021, Vol. 59, No. 2 :
  pp. 1109-1135</dc:identifier>
 <dc:identifier>doi:10.1137/19M1309997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2001.00111</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpretable Conservation Law Estimation by Deriving the Symmetries of
  Dynamics from Trained Deep Neural Networks</dc:title>
 <dc:creator>Mototake, Yoh-ichi</dc:creator>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Nonlinear Sciences - Pattern Formation and Solitons</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Understanding complex systems with their reduced model is one of the central
roles in scientific activities. Although physics has greatly been developed
with the physical insights of physicists, it is sometimes challenging to build
a reduced model of such complex systems on the basis of insights alone. We
propose a novel framework that can infer the hidden conservation laws of a
complex system from deep neural networks (DNNs) that have been trained with
physical data of the system. The purpose of the proposed framework is not to
analyze physical data with deep learning, but to extract interpretable physical
information from trained DNNs. With Noether's theorem and by an efficient
sampling method, the proposed framework infers conservation laws by extracting
symmetries of dynamics from trained DNNs. The proposed framework is developed
by deriving the relationship between a manifold structure of time-series
dataset and the necessary conditions for Noether's theorem. The feasibility of
the proposed framework has been verified in some primitive cases for which the
conservation law is well known. We also apply the proposed framework to
conservation law estimation for a more practical case that is a large-scale
collective motion system in the metastable state, and we obtain a result
consistent with that of a previous study.
</dc:description>
 <dc:description>Comment: 38 pages, 8 figures</dc:description>
 <dc:date>2019-12-31</dc:date>
 <dc:date>2020-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2001.00111</dc:identifier>
 <dc:identifier>Phys. Rev. E 103, 033303 (2021)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.103.033303</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2001.00550</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cost Function Dependent Barren Plateaus in Shallow Parametrized Quantum
  Circuits</dc:title>
 <dc:creator>Cerezo, M.</dc:creator>
 <dc:creator>Sone, Akira</dc:creator>
 <dc:creator>Volkoff, Tyler</dc:creator>
 <dc:creator>Cincio, Lukasz</dc:creator>
 <dc:creator>Coles, Patrick J.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Variational quantum algorithms (VQAs) optimize the parameters $\vec{\theta}$
of a parametrized quantum circuit $V(\vec{\theta})$ to minimize a cost function
$C$. While VQAs may enable practical applications of noisy quantum computers,
they are nevertheless heuristic methods with unproven scaling. Here, we
rigorously prove two results, assuming $V(\vec{\theta})$ is an alternating
layered ansatz composed of blocks forming local 2-designs. Our first result
states that defining $C$ in terms of global observables leads to exponentially
vanishing gradients (i.e., barren plateaus) even when $V(\vec{\theta})$ is
shallow. Hence, several VQAs in the literature must revise their proposed
costs. On the other hand, our second result states that defining $C$ with local
observables leads to at worst a polynomially vanishing gradient, so long as the
depth of $V(\vec{\theta})$ is $\mathcal{O}(\log n)$. Our results establish a
connection between locality and trainability. We illustrate these ideas with
large-scale simulations, up to 100 qubits, of a quantum autoencoder
implementation.
</dc:description>
 <dc:description>Comment: 14 + 25 pages, 8 + 2 figures. Updated to published version. Changed
  title</dc:description>
 <dc:date>2020-01-02</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2001.00550</dc:identifier>
 <dc:identifier>Nature Communications 12, 1791 (2021)</dc:identifier>
 <dc:identifier>doi:10.1038/s41467-021-21728-w</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2001.01050</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discrimination-aware Network Pruning for Deep Model Compression</dc:title>
 <dc:creator>Liu, Jing</dc:creator>
 <dc:creator>Zhuang, Bohan</dc:creator>
 <dc:creator>Zhuang, Zhuangwei</dc:creator>
 <dc:creator>Guo, Yong</dc:creator>
 <dc:creator>Huang, Junzhou</dc:creator>
 <dc:creator>Zhu, Jinhui</dc:creator>
 <dc:creator>Tan, Mingkui</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We study network pruning which aims to remove redundant channels/kernels and
hence speed up the inference of deep networks. Existing pruning methods either
train from scratch with sparsity constraints or minimize the reconstruction
error between the feature maps of the pre-trained models and the compressed
ones. Both strategies suffer from some limitations: the former kind is
computationally expensive and difficult to converge, while the latter kind
optimizes the reconstruction error but ignores the discriminative power of
channels. In this paper, we propose a simple-yet-effective method called
discrimination-aware channel pruning (DCP) to choose the channels that actually
contribute to the discriminative power. Note that a channel often consists of a
set of kernels. Besides the redundancy in channels, some kernels in a channel
may also be redundant and fail to contribute to the discriminative power of the
network, resulting in kernel level redundancy. To solve this, we propose a
discrimination-aware kernel pruning (DKP) method to further compress deep
networks by removing redundant kernels. To prevent DCP/DKP from selecting
redundant channels/kernels, we propose a new adaptive stopping condition, which
helps to automatically determine the number of selected channels/kernels and
often results in more compact models with better performance. Extensive
experiments on both image classification and face recognition demonstrate the
effectiveness of our methods. For example, on ILSVRC-12, the resultant
ResNet-50 model with 30% reduction of channels even outperforms the baseline
model by 0.36% in terms of Top-1 accuracy. The pruned MobileNetV1 and
MobileNetV2 achieve 1.93x and 1.42x inference acceleration on a mobile device,
respectively, with negligible performance degradation. The source code and the
pre-trained models are available at https://github.com/SCUT-AILab/DCP.
</dc:description>
 <dc:description>Comment: 14 pages. Extended version of the NeurIPS paper arXiv:1810.11809</dc:description>
 <dc:date>2020-01-04</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2001.01050</dc:identifier>
 <dc:identifier>doi:10.1109/TPAMI.2021.3066410</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2001.01167</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computationally Efficient NER Taggers with Combined Embeddings and
  Constrained Decoding</dc:title>
 <dc:creator>Lester, Brian</dc:creator>
 <dc:creator>Pressel, Daniel</dc:creator>
 <dc:creator>Hemmeter, Amy</dc:creator>
 <dc:creator>Choudhury, Sagnik Ray</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Current State-of-the-Art models in Named Entity Recognition (NER) are neural
models with a Conditional Random Field (CRF) as the final network layer, and
pre-trained &quot;contextual embeddings&quot;. The CRF layer is used to facilitate global
coherence between labels, and the contextual embeddings provide a better
representation of words in context. However, both of these improvements come at
a high computational cost. In this work, we explore two simple techniques that
substantially improve NER performance over a strong baseline with negligible
cost. First, we use multiple pre-trained embeddings as word representations via
concatenation. Second, we constrain the tagger, trained using a cross-entropy
loss, during decoding to eliminate illegal transitions. While training a tagger
on CoNLL 2003 we find a $786$\% speed-up over a contextual embeddings-based
tagger without sacrificing strong performance. We also show that the
concatenation technique works across multiple tasks and datasets. We analyze
aspects of similarity and coverage between pre-trained embeddings and the
dynamics of tag co-occurrence to explain why these techniques work. We provide
an open source implementation of our tagger using these techniques in three
popular deep learning frameworks --- TensorFlow, Pytorch, and DyNet.
</dc:description>
 <dc:description>Comment: This paper has since been split into two. See arXiv:2009.14394 for
  the paper on Combined Embeddings and arXiv:2010.04362 for the paper on
  Constrained Decoding</dc:description>
 <dc:date>2020-01-04</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2001.01167</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2001.01848</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Practical Encrypted Network Traffic Pattern Matching for Secure
  Middleboxes</dc:title>
 <dc:creator>Lai, Shangqi</dc:creator>
 <dc:creator>Yuan, Xingliang</dc:creator>
 <dc:creator>Sun, Shi-Feng</dc:creator>
 <dc:creator>Liu, Joseph K.</dc:creator>
 <dc:creator>Steinfeld, Ron</dc:creator>
 <dc:creator>Sakzad, Amin</dc:creator>
 <dc:creator>Liu, Dongxi</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Network Function Virtualisation (NFV) advances the adoption of composable
software middleboxes. Accordingly, cloud data centres become major NFV vendors
for enterprise traffic processing. Due to the privacy concern of traffic
redirection to the cloud, secure middlebox systems (e.g., BlindBox) draw much
attention; they can process encrypted packets against encrypted rules directly.
However, most of the existing systems supporting pattern matching based network
functions require the enterprise gateway to tokenise packet payloads via
sliding windows. Such tokenisation induces a considerable communication
overhead, which can be over 100$\times$ to the packet size. To overcome this
bottleneck, in this paper, we propose the first bandwidth-efficient encrypted
pattern matching protocol for secure middleboxes. We resort to a primitive
called symmetric hidden vector encryption (SHVE), and propose a variant of it,
aka SHVE+, to achieve constant and moderate communication cost. To speed up, we
devise encrypted filters to reduce the number of accesses to SHVE+ during
matching highly. We formalise the security of our proposed protocol and conduct
comprehensive evaluations over real-world rulesets and traffic dumps. The
results show that our design can inspect a packet over 20k rules within 100
$\mu$s. Compared to prior work, it brings a saving of $94\%$ in bandwidth
consumption.
</dc:description>
 <dc:description>Comment: Accepted version of our work published in IEEE Transactions on
  Dependable and Secure Computing (TDSC, 2021)</dc:description>
 <dc:date>2020-01-06</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2001.01848</dc:identifier>
 <dc:identifier>doi:10.1109/TDSC.2021.3065652</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2001.02908</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial-Temporal Transformer Networks for Traffic Flow Forecasting</dc:title>
 <dc:creator>Xu, Mingxing</dc:creator>
 <dc:creator>Dai, Wenrui</dc:creator>
 <dc:creator>Liu, Chunmiao</dc:creator>
 <dc:creator>Gao, Xing</dc:creator>
 <dc:creator>Lin, Weiyao</dc:creator>
 <dc:creator>Qi, Guo-Jun</dc:creator>
 <dc:creator>Xiong, Hongkai</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Traffic forecasting has emerged as a core component of intelligent
transportation systems. However, timely accurate traffic forecasting,
especially long-term forecasting, still remains an open challenge due to the
highly nonlinear and dynamic spatial-temporal dependencies of traffic flows. In
this paper, we propose a novel paradigm of Spatial-Temporal Transformer
Networks (STTNs) that leverages dynamical directed spatial dependencies and
long-range temporal dependencies to improve the accuracy of long-term traffic
forecasting. Specifically, we present a new variant of graph neural networks,
named spatial transformer, by dynamically modeling directed spatial
dependencies with self-attention mechanism to capture realtime traffic
conditions as well as the directionality of traffic flows. Furthermore,
different spatial dependency patterns can be jointly modeled with multi-heads
attention mechanism to consider diverse relationships related to different
factors (e.g. similarity, connectivity and covariance). On the other hand, the
temporal transformer is utilized to model long-range bidirectional temporal
dependencies across multiple time steps. Finally, they are composed as a block
to jointly model the spatial-temporal dependencies for accurate traffic
prediction. Compared to existing works, the proposed model enables fast and
scalable training over a long range spatial-temporal dependencies. Experiment
results demonstrate that the proposed model achieves competitive results
compared with the state-of-the-arts, especially forecasting long-term traffic
flows on real-world PeMS-Bay and PeMSD7(M) datasets.
</dc:description>
 <dc:date>2020-01-09</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2001.02908</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2001.03507</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A storage expansion planning framework using reinforcement learning and
  simulation-based optimization</dc:title>
 <dc:creator>Tsianikas, S.</dc:creator>
 <dc:creator>Yousefi, N.</dc:creator>
 <dc:creator>Zhou, J.</dc:creator>
 <dc:creator>Rodgers, M.</dc:creator>
 <dc:creator>Coit, D. W.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In the wake of the highly electrified future ahead of us, the role of energy
storage is crucial wherever distributed generation is abundant, such as in
microgrid settings. Given the variety of storage options that are becoming more
and more economical, determining which type of storage technology to invest in,
along with the appropriate timing and capacity becomes a critical research
question. It is inevitable that these problems will continue to become
increasingly relevant in the future and require strategic planning and holistic
and modern frameworks in order to be solved. Reinforcement Learning algorithms
have already proven to be successful in problems where sequential
decision-making is inherent. In the operations planning area, these algorithms
are already used but mostly in short-term problems with well-defined
constraints. On the contrary, we expand and tailor these techniques to
long-term planning by utilizing model-free algorithms combined with
simulation-based models. A model and expansion plan have been developed to
optimally determine microgrid designs as they evolve to dynamically react to
changing conditions and to exploit energy storage capabilities. We show that it
is possible to derive better engineering solutions that would point to the
types of energy storage units which could be at the core of future microgrid
applications. Another key finding is that the optimal storage capacity
threshold for a system depends heavily on the price movements of the available
storage units. By utilizing the proposed approaches, it is possible to model
inherent problem uncertainties and optimize the whole streamline of sequential
investment decision-making.
</dc:description>
 <dc:date>2020-01-10</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2001.03507</dc:identifier>
 <dc:identifier>Applied Energy; Volume 290; 2021; Pages 116778;</dc:identifier>
 <dc:identifier>doi:10.1016/j.apenergy.2021.116778</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2001.04694</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hydra: Preserving Ensemble Diversity for Model Distillation</dc:title>
 <dc:creator>Tran, Linh</dc:creator>
 <dc:creator>Veeling, Bastiaan S.</dc:creator>
 <dc:creator>Roth, Kevin</dc:creator>
 <dc:creator>Swiatkowski, Jakub</dc:creator>
 <dc:creator>Dillon, Joshua V.</dc:creator>
 <dc:creator>Snoek, Jasper</dc:creator>
 <dc:creator>Mandt, Stephan</dc:creator>
 <dc:creator>Salimans, Tim</dc:creator>
 <dc:creator>Nowozin, Sebastian</dc:creator>
 <dc:creator>Jenatton, Rodolphe</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Ensembles of models have been empirically shown to improve predictive
performance and to yield robust measures of uncertainty. However, they are
expensive in computation and memory. Therefore, recent research has focused on
distilling ensembles into a single compact model, reducing the computational
and memory burden of the ensemble while trying to preserve its predictive
behavior. Most existing distillation formulations summarize the ensemble by
capturing its average predictions. As a result, the diversity of the ensemble
predictions, stemming from each member, is lost. Thus, the distilled model
cannot provide a measure of uncertainty comparable to that of the original
ensemble. To retain more faithfully the diversity of the ensemble, we propose a
distillation method based on a single multi-headed neural network, which we
refer to as Hydra. The shared body network learns a joint feature
representation that enables each head to capture the predictive behavior of
each ensemble member. We demonstrate that with a slight increase in parameter
count, Hydra improves distillation performance on classification and regression
settings while capturing the uncertainty behavior of the original ensemble over
both in-domain and out-of-distribution tasks.
</dc:description>
 <dc:description>Comment: Accepted to ICML 2020 Workshop on Uncertainty and Robustness in Deep
  Learning</dc:description>
 <dc:date>2020-01-14</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2001.04694</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2001.05411</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lipschitz Lifelong Reinforcement Learning</dc:title>
 <dc:creator>Lecarpentier, Erwan</dc:creator>
 <dc:creator>Abel, David</dc:creator>
 <dc:creator>Asadi, Kavosh</dc:creator>
 <dc:creator>Jinnai, Yuu</dc:creator>
 <dc:creator>Rachelson, Emmanuel</dc:creator>
 <dc:creator>Littman, Michael L.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of knowledge transfer when an agent is facing a
series of Reinforcement Learning (RL) tasks. We introduce a novel metric
between Markov Decision Processes (MDPs) and establish that close MDPs have
close optimal value functions. Formally, the optimal value functions are
Lipschitz continuous with respect to the tasks space. These theoretical results
lead us to a value-transfer method for Lifelong RL, which we use to build a
PAC-MDP algorithm with improved convergence rate. Further, we show the method
to experience no negative transfer with high probability. We illustrate the
benefits of the method in Lifelong RL experiments.
</dc:description>
 <dc:description>Comment: In proceedings of the 35th AAAI Conference on Artificial Intelligence
  (AAAI 2021), 21 pages, 11 figures</dc:description>
 <dc:date>2020-01-15</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2001.05411</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2001.06315</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An elliptic local problem with exponential decay of the resonance error
  for numerical homogenization</dc:title>
 <dc:creator>Abdulle, Assyr</dc:creator>
 <dc:creator>Arjmand, Doghonay</dc:creator>
 <dc:creator>Paganoni, Edoardo</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Numerical multiscale methods usually rely on some coupling between a
macroscopic and a microscopic model. The macroscopic model is incomplete as
effective quantities, such as the homogenized material coefficients or fluxes,
are missing in the model. These effective data need to be computed by running
local microscale simulations followed by a local averaging of the microscopic
information. Motivated by the classical homogenization theory, it is a common
practice to use local elliptic cell problems for computing the missing
homogenized coefficients in the macro model. Such a consideration results in a
first order error $O(\varepsilon/\delta)$, where $\varepsilon$ represents the
wavelength of the microscale variations and $\delta$ is the size of the
microscopic simulation boxes. This error, called &quot;resonance error&quot;, originates
from the boundary conditions used in the micro-problem and typically dominates
all other errors in a multiscale numerical method. Optimal decay of the
resonance error remains an open problem, although several interesting
approaches reducing the effect of the boundary have been proposed over the last
two decades. In this paper, as an attempt to resolve this problem, we propose a
computationally efficient, fully elliptic approach with exponential decay of
the resonance error.
</dc:description>
 <dc:date>2020-01-17</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2001.06315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2001.06968</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FD-GAN: Generative Adversarial Networks with Fusion-discriminator for
  Single Image Dehazing</dc:title>
 <dc:creator>Dong, Yu</dc:creator>
 <dc:creator>Liu, Yihao</dc:creator>
 <dc:creator>Zhang, He</dc:creator>
 <dc:creator>Chen, Shifeng</dc:creator>
 <dc:creator>Qiao, Yu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, convolutional neural networks (CNNs) have achieved great
improvements in single image dehazing and attained much attention in research.
Most existing learning-based dehazing methods are not fully end-to-end, which
still follow the traditional dehazing procedure: first estimate the medium
transmission and the atmospheric light, then recover the haze-free image based
on the atmospheric scattering model. However, in practice, due to lack of
priors and constraints, it is hard to precisely estimate these intermediate
parameters. Inaccurate estimation further degrades the performance of dehazing,
resulting in artifacts, color distortion and insufficient haze removal. To
address this, we propose a fully end-to-end Generative Adversarial Networks
with Fusion-discriminator (FD-GAN) for image dehazing. With the proposed
Fusion-discriminator which takes frequency information as additional priors,
our model can generator more natural and realistic dehazed images with less
color distortion and fewer artifacts. Moreover, we synthesize a large-scale
training dataset including various indoor and outdoor hazy images to boost the
performance and we reveal that for learning-based dehazing methods, the
performance is strictly influenced by the training data. Experiments have shown
that our method reaches state-of-the-art performance on both public synthetic
datasets and real-world images with more visually pleasing dehazed results.
</dc:description>
 <dc:description>Comment: Accepted by AAAI2020 (with supplementary files)</dc:description>
 <dc:date>2020-01-19</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2001.06968</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2001.07038</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring Diversity of Artificial Intelligence Conferences</dc:title>
 <dc:creator>Freire, Ana</dc:creator>
 <dc:creator>Porcaro, Lorenzo</dc:creator>
 <dc:creator>G&#xf3;mez, Emilia</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The lack of diversity of the Artificial Intelligence (AI) field is nowadays a
concern, and several initiatives such as funding schemes and mentoring programs
have been designed to overcome it. However, there is no indication on how these
initiatives actually impact AI diversity in the short and long term. This work
studies the concept of diversity in this particular context and proposes a
small set of diversity indicators (i.e. indexes) of AI scientific events. These
indicators are designed to quantify the diversity of the AI field and monitor
its evolution. We consider diversity in terms of gender, geographical location
and business (understood as the presence of academia versus industry). We
compute these indicators for the different communities of a conference:
authors, keynote speakers and organizing committee. From these components we
compute a summarized diversity indicator for each AI event. We evaluate the
proposed indexes for a set of recent major AI conferences and we discuss their
values and limitations.
</dc:description>
 <dc:date>2020-01-20</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2001.07038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2001.07845</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence Time Optimization for Federated Learning over Wireless
  Networks</dc:title>
 <dc:creator>Chen, Mingzhe</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:creator>Cui, Shuguang</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, the convergence time of federated learning (FL), when deployed
over a realistic wireless network, is studied. In particular, a wireless
network is considered in which wireless users transmit their local FL models
(trained using their locally collected data) to a base station (BS). The BS,
acting as a central controller, generates a global FL model using the received
local FL models and broadcasts it back to all users. Due to the limited number
of resource blocks (RBs) in a wireless network, only a subset of users can be
selected to transmit their local FL model parameters to the BS at each learning
step. Moreover, since each user has unique training data samples, the BS
prefers to include all local user FL models to generate a converged global FL
model. Hence, the FL performance and convergence time will be significantly
affected by the user selection scheme. Therefore, it is necessary to design an
appropriate user selection scheme that enables users of higher importance to be
selected more frequently. This joint learning, wireless resource allocation,
and user selection problem is formulated as an optimization problem whose goal
is to minimize the FL convergence time while optimizing the FL performance. To
solve this problem, a probabilistic user selection scheme is proposed such that
the BS is connected to the users whose local FL models have significant effects
on its global FL model with high probabilities. Given the user selection
policy, the uplink RB allocation can be determined. To further reduce the FL
convergence time, artificial neural networks (ANNs) are used to estimate the
local FL models of the users that are not allocated any RBs for local FL model
transmission at each given learning step, which enables the BS to enhance its
global FL model and improve the FL convergence speed and performance.
</dc:description>
 <dc:description>Comment: This paper has been accepted in the IEEE Transactions on Wireless
  Communications</dc:description>
 <dc:date>2020-01-21</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2001.07845</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2001.09043</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal terminal sliding-mode control for second-order motion systems</dc:title>
 <dc:creator>Ruderman, Michael</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Terminal sliding mode (TSM) control algorithm and its non-singular refinement
have been elaborated for two decades and belong, since then, to a broader class
of the finite-time controllers, which are known to be robust against the
matched perturbations. While TSM manifold allows for different forms of the
sliding variable, which are satisfying the $q/p$ power ratio of the measurable
output state, we demonstrate that $q/p=0.5$ is the optimal one for the
second-order Newton's motion dynamics with a bounded control action. The paper
analyzes the time-optimal sliding surface and, based thereupon, claims the
optimal TSM control for the second-order motion systems. It is stressed that
the optimal TSM control is fully inline with the Fuller's problem of optimal
switching which minimizes the settling time, i.e. with time-optimal control of
an unperturbed double-integrator. Is is also shown that for the given plant
characteristics, i.e. the overall inertia and control bound, there is no need
for additional control parameters. The single surface design parameter might
(but not necessarily need to) be used for driving system on the boundary layer
of the twisting mode, or for forcing it to the robust terminal sliding mode.
Additional insight is given into the finite-time convergence of TSM and
robustness against the bounded perturbations. Numerical examples with different
upper-bounded perturbations are demonstrated.
</dc:description>
 <dc:description>Comment: 5 figures</dc:description>
 <dc:date>2020-01-24</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2001.09043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2001.11334</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Why Should Anyone use Colours? or, Syntax Highlighting Beyond Code
  Snippets</dc:title>
 <dc:creator>Patrignani, Marco</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Syntax highlighting in the form of colours and font diversification, is an
excellent tool to provide clarity, concision and correctness to writings.
Unfortunately, this practice is not widely adopted, which results in often
hard-to-parse papers. The reasons for this lack of adoption is that researchers
often struggle to embrace new technologies, piling up unconvincing motivations.
This paper argues against such motivations and justifies the usage of syntax
highlighting so that it can become a new standard for dissemination of clearer
and more understandable research. Moreover, this paper reports on the criticism
grounded on the shortcomings of using syntax highlighting in LATEX and suggests
remedies to that. We believe this paper can be used as a guide to using syntax
highlighting as well as a reference to counter unconvincing motivations against
it.
</dc:description>
 <dc:date>2020-01-28</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2001.11334</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2002.02525</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpolating Predictors in High-Dimensional Factor Regression</dc:title>
 <dc:creator>Bunea, Florentina</dc:creator>
 <dc:creator>Strimas-Mackey, Seth</dc:creator>
 <dc:creator>Wegkamp, Marten</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  This work studies finite-sample properties of the risk of the minimum-norm
interpolating predictor in high-dimensional regression models. If the effective
rank of the covariance matrix $\Sigma$ of the $p$ regression features is much
larger than the sample size $n$, we show that the min-norm interpolating
predictor is not desirable, as its risk approaches the risk of trivially
predicting the response by 0. However, our detailed finite-sample analysis
reveals, surprisingly, that this behavior is not present when the regression
response and the features are {\it jointly} low-dimensional, following a widely
used factor regression model. Within this popular model class, and when the
effective rank of $\Sigma$ is smaller than $n$, while still allowing for $p \gg
n$, both the bias and the variance terms of the excess risk can be controlled,
and the risk of the minimum-norm interpolating predictor approaches optimal
benchmarks. Moreover, through a detailed analysis of the bias term, we exhibit
model classes under which our upper bound on the excess risk approaches zero,
while the corresponding upper bound in the recent work arXiv:1906.11300
diverges. Furthermore, we show that the minimum-norm interpolating predictor
analyzed under the factor regression model, despite being model-agnostic and
devoid of tuning parameters, can have similar risk to predictors based on
principal components regression and ridge regression, and can improve over
LASSO based predictors, in the high-dimensional regime.
</dc:description>
 <dc:description>Comment: 47 pages, 1 figure</dc:description>
 <dc:date>2020-02-06</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2002.02525</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2002.03711</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning End-to-End Lossy Image Compression: A Benchmark</dc:title>
 <dc:creator>Hu, Yueyu</dc:creator>
 <dc:creator>Yang, Wenhan</dc:creator>
 <dc:creator>Ma, Zhan</dc:creator>
 <dc:creator>Liu, Jiaying</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image compression is one of the most fundamental techniques and commonly used
applications in the image and video processing field. Earlier methods built a
well-designed pipeline, and efforts were made to improve all modules of the
pipeline by handcrafted tuning. Later, tremendous contributions were made,
especially when data-driven methods revitalized the domain with their excellent
modeling capacities and flexibility in incorporating newly designed modules and
constraints. Despite great progress, a systematic benchmark and comprehensive
analysis of end-to-end learned image compression methods are lacking. In this
paper, we first conduct a comprehensive literature survey of learned image
compression methods. The literature is organized based on several aspects to
jointly optimize the rate-distortion performance with a neural network, i.e.,
network architecture, entropy model and rate control. We describe milestones in
cutting-edge learned image-compression methods, review a broad range of
existing works, and provide insights into their historical development routes.
With this survey, the main challenges of image compression methods are
revealed, along with opportunities to address the related issues with recent
advanced learning methods. This analysis provides an opportunity to take a
further step towards higher-efficiency image compression. By introducing a
coarse-to-fine hyperprior model for entropy estimation and signal
reconstruction, we achieve improved rate-distortion performance, especially on
high-resolution images. Extensive benchmark experiments demonstrate the
superiority of our model in rate-distortion performance and time complexity on
multi-core CPUs and GPUs. Our project website is available at
https://huzi96.github.io/compression-bench.html.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE Transactions on Pattern Analysis and
  Machine Intelligence. Website available at
  https://huzi96.github.io/compression-bench.html</dc:description>
 <dc:date>2020-02-10</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2002.03711</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2002.04676</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement Learning Enhanced Quantum-inspired Algorithm for
  Combinatorial Optimization</dc:title>
 <dc:creator>Beloborodov, Dmitrii</dc:creator>
 <dc:creator>Ulanov, A. E.</dc:creator>
 <dc:creator>Foerster, Jakob N.</dc:creator>
 <dc:creator>Whiteson, Shimon</dc:creator>
 <dc:creator>Lvovsky, A. I.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Quantum hardware and quantum-inspired algorithms are becoming increasingly
popular for combinatorial optimization. However, these algorithms may require
careful hyperparameter tuning for each problem instance. We use a reinforcement
learning agent in conjunction with a quantum-inspired algorithm to solve the
Ising energy minimization problem, which is equivalent to the Maximum Cut
problem. The agent controls the algorithm by tuning one of its parameters with
the goal of improving recently seen solutions. We propose a new Rescaled Ranked
Reward (R3) method that enables stable single-player version of self-play
training that helps the agent to escape local optima. The training on any
problem instance can be accelerated by applying transfer learning from an agent
trained on randomly generated problems. Our approach allows sampling
high-quality solutions to the Ising problem with high probability and
outperforms both baseline heuristics and a black-box hyperparameter
optimization approach.
</dc:description>
 <dc:description>Comment: Submitted to ICML 2020. 9 pages, 3 pdf figures. V2: fixed
  acknowledgements</dc:description>
 <dc:date>2020-02-11</dc:date>
 <dc:date>2020-02-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2002.04676</dc:identifier>
 <dc:identifier>Machine Learning: Science and Technology, 2, 025009 (2021)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2002.05646</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Machine Learning -- Industry Perspectives</dc:title>
 <dc:creator>Kumar, Ram Shankar Siva</dc:creator>
 <dc:creator>Nystr&#xf6;m, Magnus</dc:creator>
 <dc:creator>Lambert, John</dc:creator>
 <dc:creator>Marshall, Andrew</dc:creator>
 <dc:creator>Goertzel, Mario</dc:creator>
 <dc:creator>Comissoneru, Andi</dc:creator>
 <dc:creator>Swann, Matt</dc:creator>
 <dc:creator>Xia, Sharon</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Based on interviews with 28 organizations, we found that industry
practitioners are not equipped with tactical and strategic tools to protect,
detect and respond to attacks on their Machine Learning (ML) systems. We
leverage the insights from the interviews and we enumerate the gaps in
perspective in securing machine learning systems when viewed in the context of
traditional software security development. We write this paper from the
perspective of two personas: developers/ML engineers and security incident
responders who are tasked with securing ML systems as they are designed,
developed and deployed ML systems. The goal of this paper is to engage
researchers to revise and amend the Security Development Lifecycle for
industrial-grade software in the adversarial ML era.
</dc:description>
 <dc:description>Comment: Minor Typos corrected 7 pages, 1 figure</dc:description>
 <dc:date>2020-02-03</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2002.05646</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2002.05712</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-Iteration Batch Normalization</dc:title>
 <dc:creator>Yao, Zhuliang</dc:creator>
 <dc:creator>Cao, Yue</dc:creator>
 <dc:creator>Zheng, Shuxin</dc:creator>
 <dc:creator>Huang, Gao</dc:creator>
 <dc:creator>Lin, Stephen</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A well-known issue of Batch Normalization is its significantly reduced
effectiveness in the case of small mini-batch sizes. When a mini-batch contains
few examples, the statistics upon which the normalization is defined cannot be
reliably estimated from it during a training iteration. To address this
problem, we present Cross-Iteration Batch Normalization (CBN), in which
examples from multiple recent iterations are jointly utilized to enhance
estimation quality. A challenge of computing statistics over multiple
iterations is that the network activations from different iterations are not
comparable to each other due to changes in network weights. We thus compensate
for the network weight changes via a proposed technique based on Taylor
polynomials, so that the statistics can be accurately estimated and batch
normalization can be effectively applied. On object detection and image
classification with small mini-batch sizes, CBN is found to outperform the
original batch normalization and a direct calculation of statistics over
previous iterations without the proposed compensation technique. Code is
available at https://github.com/Howal/Cross-iterationBatchNorm .
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2021</dc:description>
 <dc:date>2020-02-13</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2002.05712</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2002.06269</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimally weighted loss functions for solving PDEs with Neural Networks</dc:title>
 <dc:creator>van der Meer, Remco</dc:creator>
 <dc:creator>Oosterlee, Cornelis</dc:creator>
 <dc:creator>Borovykh, Anastasia</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Recent works have shown that deep neural networks can be employed to solve
partial differential equations, giving rise to the framework of physics
informed neural networks. We introduce a generalization for these methods that
manifests as a scaling parameter which balances the relative importance of the
different constraints imposed by partial differential equations. A mathematical
motivation of these generalized methods is provided, which shows that for
linear and well-posed partial differential equations, the functional form is
convex. We then derive a choice for the scaling parameter that is optimal with
respect to a measure of relative error. Because this optimal choice relies on
having full knowledge of analytical solutions, we also propose a heuristic
method to approximate this optimal choice. The proposed methods are compared
numerically to the original methods on a variety of model partial differential
equations, with the number of data points being updated adaptively. For several
problems, including high-dimensional PDEs the proposed methods are shown to
significantly enhance accuracy.
</dc:description>
 <dc:date>2020-02-14</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2002.06269</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2002.06448</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring Abuse in Web Push Advertising</dc:title>
 <dc:creator>Subramani, Karthika</dc:creator>
 <dc:creator>Yuan, Xingzi</dc:creator>
 <dc:creator>Setayeshfar, Omid</dc:creator>
 <dc:creator>Vadrevu, Phani</dc:creator>
 <dc:creator>Lee, Kyu Hyung</dc:creator>
 <dc:creator>Perdisci, Roberto</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The rapid growth of online advertising has fueled the growth of ad-blocking
software, such as new ad-blocking and privacy-oriented browsers or browser
extensions. In response, both ad publishers and ad networks are constantly
trying to pursue new strategies to keep up their revenues. To this end, ad
networks have started to leverage the Web Push technology enabled by modern web
browsers.
  As web push notifications (WPNs) are relatively new, their role in ad
delivery has not been yet studied in depth. Furthermore, it is unclear to what
extent WPN ads are being abused for malvertising (i.e., to deliver malicious
ads). In this paper, we aim to fill this gap. Specifically, we propose a system
called PushAdMiner that is dedicated to (1) automatically registering for and
collecting a large number of web-based push notifications from publisher
websites, (2) finding WPN-based ads among these notifications, and (3)
discovering malicious WPN-based ad campaigns.
  Using PushAdMiner, we collected and analyzed 21,541 WPN messages by visiting
thousands of different websites. Among these, our system identified 572 WPN ad
campaigns, for a total of 5,143 WPN-based ads that were pushed by a variety of
ad networks. Furthermore, we found that 51% of all WPN ads we collected are
malicious, and that traditional ad-blockers and malicious URL filters are
remarkably ineffective against WPN-based malicious ads, leaving a significant
abuse vector unchecked.
</dc:description>
 <dc:date>2020-02-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2002.06448</dc:identifier>
 <dc:identifier>IMC '20: ACM Internet Measurement Conference October, 2020</dc:identifier>
 <dc:identifier>doi:10.1145/3419394.3423631</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2002.06864</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Quantitative Verification For Deep Neural Networks</dc:title>
 <dc:creator>Baluta, Teodora</dc:creator>
 <dc:creator>Chua, Zheng Leong</dc:creator>
 <dc:creator>Meel, Kuldeep S.</dc:creator>
 <dc:creator>Saxena, Prateek</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Despite the functional success of deep neural networks (DNNs), their
trustworthiness remains a crucial open challenge. To address this challenge,
both testing and verification techniques have been proposed. But these existing
techniques provide either scalability to large networks or formal guarantees,
not both. In this paper, we propose a scalable quantitative verification
framework for deep neural networks, i.e., a test-driven approach that comes
with formal guarantees that a desired probabilistic property is satisfied. Our
technique performs enough tests until soundness of a formal probabilistic
property can be proven. It can be used to certify properties of both
deterministic and randomized DNNs. We implement our approach in a tool called
PROVERO and apply it in the context of certifying adversarial robustness of
DNNs. In this context, we first show a new attack-agnostic measure of
robustness which offers an alternative to purely attack-based methodology of
evaluating robustness being reported today. Second, PROVERO provides
certificates of robustness for large DNNs, where existing state-of-the-art
verification tools fail to produce conclusive results. Our work paves the way
forward for verifying properties of distributions captured by real-world deep
neural networks, with provable guarantees, even where testers only have
black-box access to the neural network.
</dc:description>
 <dc:date>2020-02-17</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2002.06864</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2002.07621</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resource-Frugal Classification and Analysis of Pathology Slides Using
  Image Entropy</dc:title>
 <dc:creator>Frank, Steven J.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Pathology slides of lung malignancies are classified using resource-frugal
convolution neural networks (CNNs) that may be deployed on mobile devices. In
particular, the challenging task of distinguishing adenocarcinoma (LUAD) and
squamous-cell carcinoma (LUSC) lung cancer subtypes is approached in two
stages. First, whole-slide histopathology images are downsampled to a size too
large for CNN analysis but large enough to retain key anatomic detail. The
downsampled images are decomposed into smaller square tiles, which are sifted
based on their image entropies. A lightweight CNN produces tile-level
classifications that are aggregated to classify the slide. The resulting
accuracies are comparable to those obtained with much more complex CNNs and
larger training sets. To allow clinicians to visually assess the basis for the
classification -- that is, to see the image regions that underlie it --
color-coded probability maps are created by overlapping tiles and averaging the
tile-level probabilities at a pixel level.
</dc:description>
 <dc:date>2020-02-16</dc:date>
 <dc:date>2020-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2002.07621</dc:identifier>
 <dc:identifier>Biomedical Signal Processing and Control, vol. 66, April 2021,
  102388</dc:identifier>
 <dc:identifier>doi:10.1016/j.bspc.2020.102388</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2002.08423</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PrivacyFL: A simulator for privacy-preserving and secure federated
  learning</dc:title>
 <dc:creator>Mugunthan, Vaikkunth</dc:creator>
 <dc:creator>Peraire-Bueno, Anton</dc:creator>
 <dc:creator>Kagal, Lalana</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Federated learning is a technique that enables distributed clients to
collaboratively learn a shared machine learning model while keeping their
training data localized. This reduces data privacy risks, however, privacy
concerns still exist since it is possible to leak information about the
training dataset from the trained model's weights or parameters. Setting up a
federated learning environment, especially with security and privacy
guarantees, is a time-consuming process with numerous configurations and
parameters that can be manipulated. In order to help clients ensure that
collaboration is feasible and to check that it improves their model accuracy, a
real-world simulator for privacy-preserving and secure federated learning is
required. In this paper, we introduce PrivacyFL, which is an extensible, easily
configurable and scalable simulator for federated learning environments. Its
key features include latency simulation, robustness to client departure,
support for both centralized and decentralized learning, and configurable
privacy and security mechanisms based on differential privacy and secure
multiparty computation. In this paper, we motivate our research, describe the
architecture of the simulator and associated protocols, and discuss its
evaluation in numerous scenarios that highlight its wide range of functionality
and its advantages. Our paper addresses a significant real-world problem:
checking the feasibility of participating in a federated learning environment
under a variety of circumstances. It also has a strong practical impact because
organizations such as hospitals, banks, and research institutes, which have
large amounts of sensitive data and would like to collaborate, would greatly
benefit from having a system that enables them to do so in a privacy-preserving
and secure manner.
</dc:description>
 <dc:date>2020-02-19</dc:date>
 <dc:date>2020-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2002.08423</dc:identifier>
 <dc:identifier>doi:10.1145/3340531.3412771</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2002.09594</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One-Class Graph Neural Networks for Anomaly Detection in Attributed
  Networks</dc:title>
 <dc:creator>Wang, Xuhong</dc:creator>
 <dc:creator>Jin, Baihong</dc:creator>
 <dc:creator>Du, Ying</dc:creator>
 <dc:creator>Cui, Ping</dc:creator>
 <dc:creator>Yang, Yupu</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Nowadays, graph-structured data are increasingly used to model complex
systems. Meanwhile, detecting anomalies from graph has become a vital research
problem of pressing societal concerns. Anomaly detection is an unsupervised
learning task of identifying rare data that differ from the majority. As one of
the dominant anomaly detection algorithms, One Class Support Vector Machine has
been widely used to detect outliers. However, those traditional anomaly
detection methods lost their effectiveness in graph data. Since traditional
anomaly detection methods are stable, robust and easy to use, it is vitally
important to generalize them to graph data. In this work, we propose One Class
Graph Neural Network (OCGNN), a one-class classification framework for graph
anomaly detection. OCGNN is designed to combine the powerful representation
ability of Graph Neural Networks along with the classical one-class objective.
Compared with other baselines, OCGNN achieves significant improvements in
extensive experiments.
</dc:description>
 <dc:description>Comment: 16 pages, 4 figures. Neural Comput &amp; Applic (2021)</dc:description>
 <dc:date>2020-02-21</dc:date>
 <dc:date>2020-06-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2002.09594</dc:identifier>
 <dc:identifier>doi:10.1007/s00521-021-05924-9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2002.10120</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Flow for Fast and Accurate Scene Parsing</dc:title>
 <dc:creator>Li, Xiangtai</dc:creator>
 <dc:creator>You, Ansheng</dc:creator>
 <dc:creator>Zhu, Zhen</dc:creator>
 <dc:creator>Zhao, Houlong</dc:creator>
 <dc:creator>Yang, Maoke</dc:creator>
 <dc:creator>Yang, Kuiyuan</dc:creator>
 <dc:creator>Tong, Yunhai</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper, we focus on designing effective method for fast and accurate
scene parsing. A common practice to improve the performance is to attain high
resolution feature maps with strong semantic representation. Two strategies are
widely used -- atrous convolutions and feature pyramid fusion, are either
computation intensive or ineffective. Inspired by the Optical Flow for motion
alignment between adjacent video frames, we propose a Flow Alignment Module
(FAM) to learn Semantic Flow between feature maps of adjacent levels, and
broadcast high-level features to high resolution features effectively and
efficiently. Furthermore, integrating our module to a common feature pyramid
structure exhibits superior performance over other real-time methods even on
light-weight backbone networks, such as ResNet-18. Extensive experiments are
conducted on several challenging datasets, including Cityscapes, PASCAL
Context, ADE20K and CamVid. Especially, our network is the first to achieve
80.4\% mIoU on Cityscapes with a frame rate of 26 FPS. The code is available at
\url{https://github.com/lxtGH/SFSegNets}.
</dc:description>
 <dc:description>Comment: accepted by ECCV 2020(oral)</dc:description>
 <dc:date>2020-02-24</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2002.10120</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2002.10542</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Polyak Step-size for SGD: An Adaptive Learning Rate for Fast
  Convergence</dc:title>
 <dc:creator>Loizou, Nicolas</dc:creator>
 <dc:creator>Vaswani, Sharan</dc:creator>
 <dc:creator>Laradji, Issam</dc:creator>
 <dc:creator>Lacoste-Julien, Simon</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a stochastic variant of the classical Polyak step-size (Polyak,
1987) commonly used in the subgradient method. Although computing the Polyak
step-size requires knowledge of the optimal function values, this information
is readily available for typical modern machine learning applications.
Consequently, the proposed stochastic Polyak step-size (SPS) is an attractive
choice for setting the learning rate for stochastic gradient descent (SGD). We
provide theoretical convergence guarantees for SGD equipped with SPS in
different settings, including strongly convex, convex and non-convex functions.
Furthermore, our analysis results in novel convergence guarantees for SGD with
a constant step-size. We show that SPS is particularly effective when training
over-parameterized models capable of interpolating the training data. In this
setting, we prove that SPS enables SGD to converge to the true solution at a
fast rate without requiring the knowledge of any problem-dependent constants or
additional computational overhead. We experimentally validate our theoretical
results via extensive experiments on synthetic and real datasets. We
demonstrate the strong performance of SGD with SPS compared to state-of-the-art
optimization methods when training over-parameterized models.
</dc:description>
 <dc:description>Comment: Proceedings of the 24th International Conference on Artificial
  Intelligence and Statistics (AISTATS) 2021</dc:description>
 <dc:date>2020-02-24</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2002.10542</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2002.10586</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Is The Leader Robot an Adequate Sensor for Posture Estimation and
  Ergonomic Assessment of A Human Teleoperator?</dc:title>
 <dc:creator>Yazdani, Amir</dc:creator>
 <dc:creator>Novin, Roya Sabbagh</dc:creator>
 <dc:creator>Merryweather, Andrew</dc:creator>
 <dc:creator>Hermans, Tucker</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  Ergonomic assessment of human posture plays a vital role in understanding
work-related safety and health. Current posture estimation approaches face
occlusion challenges in teleoperation and physical human-robot interaction. We
investigate if the leader robot is an adequate sensor for posture estimation in
teleoperation and we introduce a new probabilistic approach that relies solely
on the trajectory of the leader robot for generating observations. We model the
human using a redundant, partially-observable dynamical system and we infer the
posture using a standard particle filter. We compare our approach with postures
from a commercial motion capture system and also two least-squares optimization
approaches for human inverse kinematics. The results reveal that the proposed
approach successfully estimates human postures and ergonomic risk scores
comparable to those estimates from gold-standard motion capture.
</dc:description>
 <dc:description>Comment: Submitted to IEEE CASE 2021</dc:description>
 <dc:date>2020-02-24</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2002.10586</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2002.10878</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gaussian Process Regression for Probabilistic Short-term Solar Output
  Forecast</dc:title>
 <dc:creator>Najibi, Fatemeh</dc:creator>
 <dc:creator>Apostolopoulou, Dimitra</dc:creator>
 <dc:creator>Alonso, Eduardo</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  With increasing concerns of climate change, renewable resources such as
photovoltaic (PV) have gained popularity as a means of energy generation. The
smooth integration of such resources in power system operations is enabled by
accurate forecasting mechanisms that address their inherent intermittency and
variability. This paper proposes a probabilistic framework to predict
short-term PV output taking into account the uncertainty of weather. To this
end, we make use of datasets that comprise of power output and meteorological
data such as irradiance, temperature, zenith, and azimuth. First, we categorise
the data into four groups based on solar output and time by using k-means
clustering. Next, a correlation study is performed to choose the weather
features which affect solar output to a greater extent. Finally, we determine a
function that relates the aforementioned selected features with solar output by
using Gaussian Process Regression and Matern 5/2 as a kernel function. We
validate our method with five solar generation plants in different locations
and compare the results with existing methodologies. More specifically, in
order to test the proposed model, two different methods are used: (i) 5-fold
cross-validation; and (ii) holding out 30 random days as test data. To confirm
the model accuracy, we apply our framework 30 independent times on each of the
four clusters. The average error follows a normal distribution, and with 95%
confidence level, it takes values between -1.6% to 1.4%.
</dc:description>
 <dc:date>2020-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2002.10878</dc:identifier>
 <dc:identifier>doi:10.1016/j.ijepes.2021.106916</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2002.11044</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regression with Deep Learning for Sensor Performance Optimization</dc:title>
 <dc:creator>Vaila, Ruthvik</dc:creator>
 <dc:creator>Lloyd, Denver</dc:creator>
 <dc:creator>Tetz, Kevin</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Neural networks with at least two hidden layers are called deep networks.
Recent developments in AI and computer programming in general has led to
development of tools such as Tensorflow, Keras, NumPy etc. making it easier to
model and draw conclusions from data. In this work we re-approach non-linear
regression with deep learning enabled by Keras and Tensorflow. In particular,
we use deep learning to parametrize a non-linear multivariate relationship
between inputs and outputs of an industrial sensor with an intent to optimize
the sensor performance based on selected key metrics.
</dc:description>
 <dc:description>Comment: Accepted in Workshop on Microelectronics and Electron Devices March
  30th, 2020</dc:description>
 <dc:date>2020-02-22</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2002.11044</dc:identifier>
 <dc:identifier>Workshop on Microelectronics and Electron Devices. March 30th,
  2020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2002.11245</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear-Time Variational Integrators in Maximal Coordinates</dc:title>
 <dc:creator>Br&#xfc;digam, Jan</dc:creator>
 <dc:creator>Manchester, Zachary</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  Most dynamic simulation tools parameterize the configuration of multi-body
robotic systems using minimal coordinates, also called generalized or joint
coordinates. However, maximal-coordinate approaches have several advantages
over minimal-coordinate parameterizations, including native handling of closed
kinematic loops and nonholonomic constraints. This paper describes a
linear-time variational integrator that is formulated in maximal coordinates.
Due to its variational formulation, the algorithm does not suffer from
constraint drift and has favorable energy and momentum conservation properties.
A sparse matrix factorization technique allows the dynamics of a loop-free
articulated mechanism with $n$ links to be computed in $O(n)$ (linear) time.
Additional constraints that introduce loops can also be handled by the
algorithm without incurring much computational overhead. Experimental results
show that our approach offers speed competitive with state-of-the-art
minimal-coordinate algorithms while outperforming them in several scenarios,
especially when dealing with closed loops and configuration singularities.
</dc:description>
 <dc:date>2020-02-25</dc:date>
 <dc:date>2020-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2002.11245</dc:identifier>
 <dc:identifier>Workshop on the Algorithmic Foundations of Robotics (WAFR) 2020</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-030-66723-8_12</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2002.11544</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The role of regularization in classification of high-dimensional noisy
  Gaussian mixture</dc:title>
 <dc:creator>Mignacco, Francesca</dc:creator>
 <dc:creator>Krzakala, Florent</dc:creator>
 <dc:creator>Lu, Yue M.</dc:creator>
 <dc:creator>Zdeborov&#xe1;, Lenka</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We consider a high-dimensional mixture of two Gaussians in the noisy regime
where even an oracle knowing the centers of the clusters misclassifies a small
but finite fraction of the points. We provide a rigorous analysis of the
generalization error of regularized convex classifiers, including ridge, hinge
and logistic regression, in the high-dimensional limit where the number $n$ of
samples and their dimension $d$ go to infinity while their ratio is fixed to
$\alpha= n/d$. We discuss surprising effects of the regularization that in some
cases allows to reach the Bayes-optimal performances. We also illustrate the
interpolation peak at low regularization, and analyze the role of the
respective sizes of the two clusters.
</dc:description>
 <dc:description>Comment: 8 pages + appendix, 6 figures</dc:description>
 <dc:date>2020-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2002.11544</dc:identifier>
 <dc:identifier>International Conference on Machine Learning, ICML 2020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2002.12647</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>REGNet: REgion-based Grasp Network for End-to-end Grasp Detection in
  Point Clouds</dc:title>
 <dc:creator>Zhao, Binglei</dc:creator>
 <dc:creator>Zhang, Hanbo</dc:creator>
 <dc:creator>Lan, Xuguang</dc:creator>
 <dc:creator>Wang, Haoyu</dc:creator>
 <dc:creator>Tian, Zhiqiang</dc:creator>
 <dc:creator>Zheng, Nanning</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Reliable robotic grasping in unstructured environments is a crucial but
challenging task. The main problem is to generate the optimal grasp of novel
objects from partial noisy observations. This paper presents an end-to-end
grasp detection network taking one single-view point cloud as input to tackle
the problem. Our network includes three stages: Score Network (SN), Grasp
Region Network (GRN), and Refine Network (RN). Specifically, SN regresses point
grasp confidence and selects positive points with high confidence. Then GRN
conducts grasp proposal prediction on the selected positive points. RN
generates more accurate grasps by refining proposals predicted by GRN. To
further improve the performance, we propose a grasp anchor mechanism, in which
grasp anchors with assigned gripper orientations are introduced to generate
grasp proposals. Experiments demonstrate that REGNet achieves a success rate of
79.34% and a completion rate of 96% in real-world clutter, which significantly
outperforms several state-of-the-art point-cloud based methods, including GPD,
PointNetGPD, and S4G. The code is available at
https://github.com/zhaobinglei/REGNet_for_3D_Grasping.
</dc:description>
 <dc:description>Comment: Accepted to ICRA 2021</dc:description>
 <dc:date>2020-02-28</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2002.12647</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2002.12655</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A U-Net Based Discriminator for Generative Adversarial Networks</dc:title>
 <dc:creator>Sch&#xf6;nfeld, Edgar</dc:creator>
 <dc:creator>Schiele, Bernt</dc:creator>
 <dc:creator>Khoreva, Anna</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Among the major remaining challenges for generative adversarial networks
(GANs) is the capacity to synthesize globally and locally coherent images with
object shapes and textures indistinguishable from real images. To target this
issue we propose an alternative U-Net based discriminator architecture,
borrowing the insights from the segmentation literature. The proposed U-Net
based architecture allows to provide detailed per-pixel feedback to the
generator while maintaining the global coherence of synthesized images, by
providing the global image feedback as well. Empowered by the per-pixel
response of the discriminator, we further propose a per-pixel consistency
regularization technique based on the CutMix data augmentation, encouraging the
U-Net discriminator to focus more on semantic and structural changes between
real and fake images. This improves the U-Net discriminator training, further
enhancing the quality of generated samples. The novel discriminator improves
over the state of the art in terms of the standard distribution and image
quality metrics, enabling the generator to synthesize images with varying
structure, appearance and levels of detail, maintaining global and local
realism. Compared to the BigGAN baseline, we achieve an average improvement of
2.7 FID points across FFHQ, CelebA, and the newly introduced COCO-Animals
dataset. The code is available at https://github.com/boschresearch/unetgan.
</dc:description>
 <dc:description>Comment: CVPR 2020 (Main Conference). Code repository:
  https://github.com/boschresearch/unetgan</dc:description>
 <dc:date>2020-02-28</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2002.12655</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.00075</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learned Threshold Pruning</dc:title>
 <dc:creator>Azarian, Kambiz</dc:creator>
 <dc:creator>Bhalgat, Yash</dc:creator>
 <dc:creator>Lee, Jinwon</dc:creator>
 <dc:creator>Blankevoort, Tijmen</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper presents a novel differentiable method for unstructured weight
pruning of deep neural networks. Our learned-threshold pruning (LTP) method
learns per-layer thresholds via gradient descent, unlike conventional methods
where they are set as input. Making thresholds trainable also makes LTP
computationally efficient, hence scalable to deeper networks. For example, it
takes $30$ epochs for LTP to prune ResNet50 on ImageNet by a factor of $9.1$.
This is in contrast to other methods that search for per-layer thresholds via a
computationally intensive iterative pruning and fine-tuning process.
Additionally, with a novel differentiable $L_0$ regularization, LTP is able to
operate effectively on architectures with batch-normalization. This is
important since $L_1$ and $L_2$ penalties lose their regularizing effect in
networks with batch-normalization. Finally, LTP generates a trail of
progressively sparser networks from which the desired pruned network can be
picked based on sparsity and performance requirements. These features allow LTP
to achieve competitive compression rates on ImageNet networks such as AlexNet
($26.4\times$ compression with $79.1\%$ Top-5 accuracy) and ResNet50
($9.1\times$ compression with $92.0\%$ Top-5 accuracy). We also show that LTP
effectively prunes modern \textit{compact} architectures, such as EfficientNet,
MobileNetV2 and MixNet.
</dc:description>
 <dc:date>2020-02-28</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.00075</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.00152</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training BatchNorm and Only BatchNorm: On the Expressive Power of Random
  Features in CNNs</dc:title>
 <dc:creator>Frankle, Jonathan</dc:creator>
 <dc:creator>Schwab, David J.</dc:creator>
 <dc:creator>Morcos, Ari S.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A wide variety of deep learning techniques from style transfer to multitask
learning rely on training affine transformations of features. Most prominent
among these is the popular feature normalization technique BatchNorm, which
normalizes activations and then subsequently applies a learned affine
transform. In this paper, we aim to understand the role and expressive power of
affine parameters used to transform features in this way. To isolate the
contribution of these parameters from that of the learned features they
transform, we investigate the performance achieved when training only these
parameters in BatchNorm and freezing all weights at their random
initializations. Doing so leads to surprisingly high performance considering
the significant limitations that this style of training imposes. For example,
sufficiently deep ResNets reach 82% (CIFAR-10) and 32% (ImageNet, top-5)
accuracy in this configuration, far higher than when training an equivalent
number of randomly chosen parameters elsewhere in the network. BatchNorm
achieves this performance in part by naturally learning to disable around a
third of the random features. Not only do these results highlight the
expressive power of affine parameters in deep learning, but - in a broader
sense - they characterize the expressive power of neural networks constructed
simply by shifting and rescaling random features.
</dc:description>
 <dc:description>Comment: Published in ICLR 2021</dc:description>
 <dc:date>2020-02-28</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.00152</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.00613</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Do We Move: Modeling Human Movement with System Dynamics</dc:title>
 <dc:creator>Wei, Hua</dc:creator>
 <dc:creator>Xu, Dongkuan</dc:creator>
 <dc:creator>Liang, Junjie</dc:creator>
 <dc:creator>Li, Zhenhui</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Modeling how human moves in the space is useful for policy-making in
transportation, public safety, and public health. Human movements can be viewed
as a dynamic process that human transits between states (\eg, locations) over
time. In the human world where intelligent agents like humans or vehicles with
human drivers play an important role, the states of agents mostly describe
human activities, and the state transition is influenced by both the human
decisions and physical constraints from the real-world system (\eg, agents need
to spend time to move over a certain distance). Therefore, the modeling of
state transition should include the modeling of the agent's decision process
and the physical system dynamics. In this paper, we propose \ours to model
state transition in human movement from a novel perspective, by learning the
decision model and integrating the system dynamics. \ours learns the human
movement with Generative Adversarial Imitation Learning and integrates the
stochastic constraints from system dynamics in the learning process. To the
best of our knowledge, we are the first to learn to model the state transition
of moving agents with system dynamics. In extensive experiments on real-world
datasets, we demonstrate that the proposed method can generate trajectories
similar to real-world ones, and outperform the state-of-the-art methods in
predicting the next location and generating long-term future trajectories.
</dc:description>
 <dc:description>Comment: Accepted by AAAI 2021, Appendices included. 12 pages, 8 figures. in
  Proceedings of the Thirty-Fifth AAAI Conference on Artificial Intelligence
  (AAAI'21), Feb 2021</dc:description>
 <dc:date>2020-03-01</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.00613</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.00678</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SketchGNN: Semantic Sketch Segmentation with Graph Neural Networks</dc:title>
 <dc:creator>Yang, Lumin</dc:creator>
 <dc:creator>Zhuang, Jiajie</dc:creator>
 <dc:creator>Fu, Hongbo</dc:creator>
 <dc:creator>Wei, Xiangzhi</dc:creator>
 <dc:creator>Zhou, Kun</dc:creator>
 <dc:creator>Zheng, Youyi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce SketchGNN, a convolutional graph neural network for semantic
segmentation and labeling of freehand vector sketches. We treat an input
stroke-based sketch as a graph, with nodes representing the sampled points
along input strokes and edges encoding the stroke structure information. To
predict the per-node labels, our SketchGNN uses graph convolution and a
static-dynamic branching network architecture to extract the features at three
levels, i.e., point-level, stroke-level, and sketch-level. SketchGNN
significantly improves the accuracy of the state-of-the-art methods for
semantic sketch segmentation (by 11.2% in the pixel-based metric and 18.2% in
the component-based metric over a large-scale challenging SPG dataset) and has
magnitudes fewer parameters than both image-based and sequence-based methods.
</dc:description>
 <dc:date>2020-03-02</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.00678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.00773</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Top-K Deep Video Analytics: A Probabilistic Approach</dc:title>
 <dc:creator>Lai, Ziliang</dc:creator>
 <dc:creator>Han, Chenxia</dc:creator>
 <dc:creator>Liu, Chris</dc:creator>
 <dc:creator>Zhang, Pengfei</dc:creator>
 <dc:creator>Lo, Eric</dc:creator>
 <dc:creator>Kao, Ben</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The impressive accuracy of deep neural networks (DNNs) has created great
demands on practical analytics over video data. Although efficient and
accurate, the latest video analytic systems have not supported analytics beyond
selection and aggregation queries. In data analytics, Top-K is a very important
analytical operation that enables analysts to focus on the most important
entities. In this paper, we present Everest, the first system that supports
efficient and accurate Top-K video analytics. Everest ranks and identifies the
most interesting frames/moments from videos with probabilistic guarantees.
Everest is a system built with a careful synthesis of deep computer vision
models, uncertain data management, and Top-K query processing. Evaluations on
real-world videos and the latest Visual Road benchmark show that Everest
achieves between 14.3x to 20.6x higher efficiency than baseline approaches with
high result accuracy
</dc:description>
 <dc:description>Comment: 14 pages, 9 figures, 8 tables</dc:description>
 <dc:date>2020-03-02</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.00773</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.01017</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A priori error estimates for finite element approximations of
  regularized level set flows in higher norms</dc:title>
 <dc:creator>Kr&#xf6;ner, Axel</dc:creator>
 <dc:creator>Kr&#xf6;ner, Heiko</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>35J66, 35J93, 65N15, 65N30</dc:subject>
 <dc:description>  This paper proves error estimates for $H^2$ conforming finite elements for
equations which model the flow of surfaces by different powers of the mean
curvature (this includes mean curvature flow). for an adapted scheme originally
proposed in [17] for the inverse mean curvature flow. The scheme is based on a
known regularization procedure and produces different kinds of errors, a
regularization error, a finite element discretization error for the regularized
problems and a full error. While in the literature and own previous work
different aspects of the aforementioned error types are treated, here, we
solely and for the first time focus on the finite element discretization error
in the $W^{2,\mu}$ norm for the regularized equation analyzing also the
dependencies from the regularization parameter.
</dc:description>
 <dc:date>2020-03-02</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.01017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.03472</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SuPer Deep: A Surgical Perception Framework for Robotic Tissue
  Manipulation using Deep Learning for Feature Extraction</dc:title>
 <dc:creator>Lu, Jingpei</dc:creator>
 <dc:creator>Jayakumari, Ambareesh</dc:creator>
 <dc:creator>Richter, Florian</dc:creator>
 <dc:creator>Li, Yang</dc:creator>
 <dc:creator>Yip, Michael C.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Robotic automation in surgery requires precise tracking of surgical tools and
mapping of deformable tissue. Previous works on surgical perception frameworks
require significant effort in developing features for surgical tool and tissue
tracking. In this work, we overcome the challenge by exploiting deep learning
methods for surgical perception. We integrated deep neural networks, capable of
efficient feature extraction, into the tissue reconstruction and instrument
pose estimation processes. By leveraging transfer learning, the deep learning
based approach requires minimal training data and reduced feature engineering
efforts to fully perceive a surgical scene. The framework was tested on three
publicly available datasets, which use the da Vinci Surgical System, for
comprehensive analysis. Experimental results show that our framework achieves
state-of-the-art tracking performance in a surgical environment by utilizing
deep learning for feature extraction.
</dc:description>
 <dc:description>Comment: 7 pages, 7 figures, ICRA 2021 camera-ready version</dc:description>
 <dc:date>2020-03-06</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.03472</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.03533</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synaptic Metaplasticity in Binarized Neural Networks</dc:title>
 <dc:creator>Laborieux, Axel</dc:creator>
 <dc:creator>Ernoult, Maxence</dc:creator>
 <dc:creator>Hirtzlin, Tifenn</dc:creator>
 <dc:creator>Querlioz, Damien</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  While deep neural networks have surpassed human performance in multiple
situations, they are prone to catastrophic forgetting: upon training a new
task, they rapidly forget previously learned ones. Neuroscience studies, based
on idealized tasks, suggest that in the brain, synapses overcome this issue by
adjusting their plasticity depending on their past history. However, such
&quot;metaplastic&quot; behaviours do not transfer directly to mitigate catastrophic
forgetting in deep neural networks. In this work, we interpret the hidden
weights used by binarized neural networks, a low-precision version of deep
neural networks, as metaplastic variables, and modify their training technique
to alleviate forgetting. Building on this idea, we propose and demonstrate
experimentally, in situations of multitask and stream learning, a training
technique that reduces catastrophic forgetting without needing previously
presented data, nor formal boundaries between datasets and with performance
approaching more mainstream techniques with task boundaries. We support our
approach with a theoretical analysis on a tractable task. This work bridges
computational neuroscience and deep learning, and presents significant assets
for future embedded and neuromorphic systems, especially when using novel
nanodevices featuring physics analogous to metaplasticity.
</dc:description>
 <dc:date>2020-03-07</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.03533</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.03810</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attacking the DeFi Ecosystem with Flash Loans for Fun and Profit</dc:title>
 <dc:creator>Qin, Kaihua</dc:creator>
 <dc:creator>Zhou, Liyi</dc:creator>
 <dc:creator>Livshits, Benjamin</dc:creator>
 <dc:creator>Gervais, Arthur</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Credit allows a lender to loan out surplus capital to a borrower. In the
traditional economy, credit bears the risk that the borrower may default on its
debt, the lender hence requires upfront collateral from the borrower, plus
interest fee payments. Due to the atomicity of blockchain transactions, lenders
can offer flash loans, i.e., loans that are only valid within one transaction
and must be repaid by the end of that transaction. This concept has lead to a
number of interesting attack possibilities, some of which were exploited in
February 2020.
  This paper is the first to explore the implication of transaction atomicity
and flash loans for the nascent decentralized finance (DeFi) ecosystem. We show
quantitatively how transaction atomicity increases the arbitrage revenue. We
moreover analyze two existing attacks with ROIs beyond 500k%. We formulate
finding the attack parameters as an optimization problem over the state of the
underlying Ethereum blockchain and the state of the DeFi ecosystem. We show how
malicious adversaries can efficiently maximize an attack profit and hence
damage the DeFi ecosystem further. Specifically, we present how two previously
executed attacks can be &quot;boosted&quot; to result in a profit of 829.5k USD and 1.1M
USD, respectively, which is a boost of 2.37x and 1.73x, respectively.
</dc:description>
 <dc:date>2020-03-08</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.03810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.04508</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Graph Embedding via Adaptive Graph Learning</dc:title>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:creator>Zhang, Yunxing</dc:creator>
 <dc:creator>Li, Xuelong</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Graph autoencoders (GAEs) are powerful tools in representation learning for
graph embedding. However, the performance of GAEs is very dependent on the
quality of the graph structure, i.e., of the adjacency matrix. In other words,
GAEs would perform poorly when the adjacency matrix is incomplete or be
disturbed. In this paper, two novel unsupervised graph embedding methods,
unsupervised graph embedding via adaptive graph learning (BAGE) and
unsupervised graph embedding via variational adaptive graph learning (VBAGE)
are proposed. The proposed methods expand the application range of GAEs on
graph embedding, i.e, on the general datasets without graph structure.
Meanwhile, the adaptive learning mechanism can initialize the adjacency matrix
without be affected by the parameter. Besides that, the latent representations
are embedded in the laplacian graph structure to preserve the topology
structure of the graph in the vector space. Moreover, the adjacency matrix can
be self-learned for better embedding performance when the original graph
structure is incomplete. With adaptive learning, the proposed method is much
more robust to the graph structure. Experimental studies on several datasets
validate our design and demonstrate that our methods outperform baselines by a
wide margin in node clustering, node classification, and graph visualization
tasks.
</dc:description>
 <dc:date>2020-03-09</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.04508</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.05016</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Reward Learning for Co-Robotic Vision Based Exploration in
  Bandwidth Limited Environments</dc:title>
 <dc:creator>Jamieson, Stewart</dc:creator>
 <dc:creator>How, Jonathan P.</dc:creator>
 <dc:creator>Girdhar, Yogesh</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We present a novel POMDP problem formulation for a robot that must
autonomously decide where to go to collect new and scientifically relevant
images given a limited ability to communicate with its human operator. From
this formulation we derive constraints and design principles for the
observation model, reward model, and communication strategy of such a robot,
exploring techniques to deal with the very high-dimensional observation space
and scarcity of relevant training data. We introduce a novel active reward
learning strategy based on making queries to help the robot minimize path
&quot;regret&quot; online, and evaluate it for suitability in autonomous visual
exploration through simulations. We demonstrate that, in some bandwidth-limited
environments, this novel regret-based criterion enables the robotic explorer to
collect up to 17% more reward per mission than the next-best criterion.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures; accepted for presentation in IEEE Int. Conf. on
  Robotics and Automation, ICRA '20, Paris, France, June 2020</dc:description>
 <dc:date>2020-03-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.05016</dc:identifier>
 <dc:identifier>2020 IEEE International Conference on Robotics and Automation
  (ICRA), Paris, France, 2020, pp. 1806-1812</dc:identifier>
 <dc:identifier>doi:10.1109/ICRA40945.2020.9196922</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.06808</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Constraint Satisfaction in Data-Driven MPC</dc:title>
 <dc:creator>Berberich, Julian</dc:creator>
 <dc:creator>K&#xf6;hler, Johannes</dc:creator>
 <dc:creator>M&#xfc;ller, Matthias A.</dc:creator>
 <dc:creator>Allg&#xf6;wer, Frank</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We propose a purely data-driven model predictive control (MPC) scheme to
control unknown linear time-invariant systems with guarantees on stability and
constraint satisfaction in the presence of noisy data. The scheme predicts
future trajectories based on data-dependent Hankel matrices, which span the
full system behavior if the input is persistently exciting. This paper extends
previous work on data-driven MPC by including a suitable constraint tightening
which ensures that the closed-loop trajectory satisfies desired
pointwise-in-time output constraints. Furthermore, we provide estimation
procedures to compute system constants related to controllability and
observability, which are required to implement the constraint tightening. The
practicality of the proposed approach is illustrated via a numerical example.
</dc:description>
 <dc:description>Comment: This version fixes a minor typo in the published version (definition
  of equilibrium on page 2, change marked in blue color)</dc:description>
 <dc:date>2020-03-15</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.06808</dc:identifier>
 <dc:identifier>in Proc. Conference on Decision and Control, 2020, pp. 1260-1267</dc:identifier>
 <dc:identifier>doi:10.1109/CDC42340.2020.9303965</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.07069</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Supervised Discovering of Interpretable Features for Reinforcement
  Learning</dc:title>
 <dc:creator>Shi, Wenjie</dc:creator>
 <dc:creator>Huang, Gao</dc:creator>
 <dc:creator>Song, Shiji</dc:creator>
 <dc:creator>Wang, Zhuoyuan</dc:creator>
 <dc:creator>Lin, Tingyu</dc:creator>
 <dc:creator>Wu, Cheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep reinforcement learning (RL) has recently led to many breakthroughs on a
range of complex control tasks. However, the agent's decision-making process is
generally not transparent. The lack of interpretability hinders the
applicability of RL in safety-critical scenarios. While several methods have
attempted to interpret vision-based RL, most come without detailed explanation
for the agent's behavior. In this paper, we propose a self-supervised
interpretable framework, which can discover interpretable features to enable
easy understanding of RL agents even for non-experts. Specifically, a
self-supervised interpretable network (SSINet) is employed to produce
fine-grained attention masks for highlighting task-relevant information, which
constitutes most evidence for the agent's decisions. We verify and evaluate our
method on several Atari 2600 games as well as Duckietown, which is a
challenging self-driving car simulator environment. The results show that our
method renders empirical evidences about how the agent makes decisions and why
the agent performs well or badly, especially when transferred to novel scenes.
Overall, our method provides valuable insight into the internal decision-making
process of vision-based RL. In addition, our method does not use any external
labelled data, and thus demonstrates the possibility to learn high-quality mask
through a self-supervised manner, which may shed light on new paradigms for
label-free vision learning such as self-supervised segmentation and detection.
</dc:description>
 <dc:description>Comment: Accepted as a Regular Paper in IEEE Transactions on Pattern Analysis
  and Machine Intelligence (TPAMI)</dc:description>
 <dc:date>2020-03-16</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.07069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.07131</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Blockchain based Decentralized Applications: Technology Review and
  Development Guidelines</dc:title>
 <dc:creator>Pop, Claudia</dc:creator>
 <dc:creator>Cioara, Tudor</dc:creator>
 <dc:creator>Anghel, Ionut</dc:creator>
 <dc:creator>Antal, Marcel</dc:creator>
 <dc:creator>Salomie, Ioan</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:description>  Blockchain or Distributed Ledger Technology is a disruptive technology that
provides the infrastructure for developing decentralized applications enabling
the implementation of novel business models even in traditionally centralized
domains. In the last years it has drawn high interest from the academic
community, technology developers and startups thus lots of solutions have been
developed to address blockchain technology limitations and the requirements of
applications software engineering. In this paper, we provide a comprehensive
overview of DLT solutions analyzing the addressed challenges, provided
solutions and their usage for developing decentralized applications. Our study
reviews over 100 blockchain papers and startup initiatives from which we
construct a 3-tier based architecture for decentralized applications and we use
it to systematically classify the technology solutions. Protocol and Network
Tier solutions address the digital assets registration, transactions, data
structure, and privacy and business rules implementation and the creation of
peer-to-peer networks, ledger replication, and consensus-based state
validation. Scaling Tier solutions address the scalability problems in terms of
storage size, transaction throughput, and computational capability. Finally,
Federated Tier aggregates integrative solutions across multiple blockchain
applications deployments. The paper closes with a discussion on challenges and
opportunities for developing decentralized applications by providing a
multi-step guideline for decentralizing the design of traditional systems and
implementing decentralized applications.
</dc:description>
 <dc:description>Comment: 30 pages, 8 figures, 9 tables, 121 references</dc:description>
 <dc:date>2020-03-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.07131</dc:identifier>
 <dc:identifier>Future Internet 2021, 13(3), 62</dc:identifier>
 <dc:identifier>doi:10.3390/fi13030062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.08780</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-End Delay Approximation in Packet-Switched Networks</dc:title>
 <dc:creator>Chen, Yu</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  In this paper, I develop a generalized method to approximate end-to-end delay
(average delay, jitter and density functions) in packet-switched networks
(PSNs) of any size under 1) Kleinrock's independence assumption (KIA) and 2)
when packet lengths are kept unchanged when they traverse from node to node in
a network, which is an Alternative to Kleinrock's independence assumption
(AKIA). I introduce a new phase-type distribution $C(\mathbf{p},\boldsymbol
\theta)$; and then use results from the network flow theory and queueing theory
to show that the end-to-end delay in PSNs under KIA and AKIA are two different
random variables approximately described by $C(\mathbf{p},\boldsymbol \theta)$.
When PSNs have AKIA, I show from simulation that the method under AKIA
significantly reduces end-to-end delay approximation errors and provides close
approximation compared with the method under KIA.
</dc:description>
 <dc:description>Comment: Submitted to the IEEE Transactions on Networking</dc:description>
 <dc:date>2020-03-19</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.08780</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.08841</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximately Supermodular Scheduling Subject to Matroid Constraints</dc:title>
 <dc:creator>Chamon, Luiz F. O.</dc:creator>
 <dc:creator>Amice, Alexandre</dc:creator>
 <dc:creator>Ribeiro, Alejandro</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Control scheduling refers to the problem of assigning agents or actuators to
act upon a dynamical system at specific times so as to minimize a quadratic
control cost, such as the objective of the Linear-quadratic-Gaussian (LQG) or
the Linear Quadratic Regulator (LQR). When budget or operational constraints
are imposed on the schedule, this problem is in general NP-hard and its
solution can therefore only be approximated even for moderately sized systems.
The quality of this approximation depends on the structure of both the
constraints and the objective. This work shows that greedy scheduling is
near-optimal when the constraints can be represented as an intersection of
matroids, algebraic structures that encode requirements such as limits on the
number of agents deployed per time slot, total number of actuator uses, and
duty cycle restrictions. To do so, it proves that the LQG cost function is
alpha-supermodular and provides a new alpha/(alpha + P)-optimality certificates
for the greedy minimization of such functions over an intersections of P
matroids. These certificates are shown to approach the 1/(1+P) guarantee of
supermodular functions in relevant settings. These results support the use of
greedy algorithms in non-supermodular quadratic control problems as opposed to
typical heuristics such as convex relaxations and surrogate figures of merit,
e.g., the logdet of the controllability Gramian.
</dc:description>
 <dc:description>Comment: Accepted for publication in the IEEE Transactions of Automatic
  Control</dc:description>
 <dc:date>2020-03-19</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.08841</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.10072</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Lower Bounds for Permutation Arrays Using Permutation Rational
  Functions</dc:title>
 <dc:creator>Bereg, Sergey</dc:creator>
 <dc:creator>Malouf, Brian</dc:creator>
 <dc:creator>Morales, Linda</dc:creator>
 <dc:creator>Stanley, Thomas</dc:creator>
 <dc:creator>Sudborough, I. Hal</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider rational functions of the form $V(x)/U(x)$, where both $V(x)$ and
$U(x)$ are polynomials over the finite field $\mathbb{F}_q$. Polynomials that
permute the elements of a field, called {\it permutation polynomials ($PPs$)},
have been the subject of research for decades. Let ${\mathcal
P}^1(\mathbb{F}_q)$ denote $\mathbb{Z}_q \cup \{\infty\}$. If the rational
function, $V(x)/U(x)$, permutes the elements of ${\mathcal P}^1(\mathbb{F}_q)$,
it is called a {\em permutation rational function (PRf)}. Let $N_d(q)$ denote
the number of PPs of degree $d$ over $\mathbb{F}_q$, and let $N_{v,u}(q)$
denote the number of PRfs with a numerator of degree $v$ and a denominator of
degree $u$. It follows that $N_{d,0}(q) = N_d(q)$, so PRFs are a generalization
of PPs. The number of monic degree 3 PRfs is known [11]. We develop efficient
computational techniques for $N_{v,u}(q)$, and use them to show $N_{4,3}(q) =
(q+1)q^2(q-1)^2/3$, for all prime powers $q \le 307$, $N_{5,4}(q) &gt;
(q+1)q^3(q-1)^2/2$, for all prime powers $q \le 97$, and $N_{4,4}(p) =
(p+1)p^2(p-1)^3/3$, for all primes $p \le 47$. We conjecture that these
formulas are, in fact, true for all prime powers $q$. Let $M(n,D)$ denote the
maximum number of permutations on $n$ symbols with pairwise Hamming distance
$D$. Computing improved lower bounds for $M(n,D)$ is the subject of much
current research with applications in error correcting codes. Using PRfs, we
obtain significantly improved lower bounds on $M(q,q-d)$ and $M(q+1,q-d)$, for
$d \in \{5,7,9\}$.
</dc:description>
 <dc:date>2020-03-23</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.10072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.10261</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed projected-reflected-gradient algorithms for stochastic
  generalized Nash equilibrium problems</dc:title>
 <dc:creator>Franci, Barbara</dc:creator>
 <dc:creator>Grammatico, Sergio</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  We consider the stochastic generalized Nash equilibrium problem (SGNEP) with
joint feasibility constraints and expected-value cost functions. We propose a
distributed stochastic projected reflected gradient algorithm and show its
almost sure convergence when the pseudogradient mapping is monotone and the
solution is unique. The algorithm is based on monotone operator splitting
methods tailored for SGNEPs when the expected-value pseudogradient mapping is
approximated at each iteration via an increasing number of samples of the
random variable. Finally, we show that a preconditioned variant of our proposed
algorithm has convergence guarantees when the pseudogradient mapping is
cocoercive.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1910.11776</dc:description>
 <dc:date>2020-03-20</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.10261</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.11059</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integrating Physiological Time Series and Clinical Notes with Deep
  Learning for Improved ICU Mortality Prediction</dc:title>
 <dc:creator>Shukla, Satya Narayan</dc:creator>
 <dc:creator>Marlin, Benjamin M.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Intensive Care Unit Electronic Health Records (ICU EHRs) store multimodal
data about patients including clinical notes, sparse and irregularly sampled
physiological time series, lab results, and more. To date, most methods
designed to learn predictive models from ICU EHR data have focused on a single
modality. In this paper, we leverage the recently proposed
interpolation-prediction deep learning architecture(Shukla and Marlin 2019) as
a basis for exploring how physiological time series data and clinical notes can
be integrated into a unified mortality prediction model. We study both early
and late fusion approaches and demonstrate how the relative predictive value of
clinical text and physiological data change over time. Our results show that a
late fusion approach can provide a statistically significant improvement in
mortality prediction performance over using individual modalities in isolation.
</dc:description>
 <dc:description>Comment: Presented at ACM Conference on Health, Inference and Learning
  (Workshop Track), 2020</dc:description>
 <dc:date>2020-03-24</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.11059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.11571</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Layout and Style Reconfigurable GANs for Controllable Image
  Synthesis</dc:title>
 <dc:creator>Sun, Wei</dc:creator>
 <dc:creator>Wu, Tianfu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  With the remarkable recent progress on learning deep generative models, it
becomes increasingly interesting to develop models for controllable image
synthesis from reconfigurable inputs. This paper focuses on a recent emerged
task, layout-to-image, to learn generative models that are capable of
synthesizing photo-realistic images from spatial layout (i.e., object bounding
boxes configured in an image lattice) and style (i.e., structural and
appearance variations encoded by latent vectors). This paper first proposes an
intuitive paradigm for the task, layout-to-mask-to-image, to learn to unfold
object masks of given bounding boxes in an input layout to bridge the gap
between the input layout and synthesized images. Then, this paper presents a
method built on Generative Adversarial Networks for the proposed
layout-to-mask-to-image with style control at both image and mask levels.
Object masks are learned from the input layout and iteratively refined along
stages in the generator network. Style control at the image level is the same
as in vanilla GANs, while style control at the object mask level is realized by
a proposed novel feature normalization scheme, Instance-Sensitive and
Layout-Aware Normalization. In experiments, the proposed method is tested in
the COCO-Stuff dataset and the Visual Genome dataset with state-of-the-art
performance obtained.
</dc:description>
 <dc:description>Comment: 16 pages (w/o ref), 15 figures)</dc:description>
 <dc:date>2020-03-25</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.11571</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.11593</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Heavy-tailed Representations, Text Polarity Classification &amp; Data
  Augmentation</dc:title>
 <dc:creator>Jalalzai, Hamid</dc:creator>
 <dc:creator>Colombo, Pierre</dc:creator>
 <dc:creator>Clavel, Chlo&#xe9;</dc:creator>
 <dc:creator>Gaussier, Eric</dc:creator>
 <dc:creator>Varni, Giovanna</dc:creator>
 <dc:creator>Vignon, Emmanuel</dc:creator>
 <dc:creator>Sabourin, Anne</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The dominant approaches to text representation in natural language rely on
learning embeddings on massive corpora which have convenient properties such as
compositionality and distance preservation. In this paper, we develop a novel
method to learn a heavy-tailed embedding with desirable regularity properties
regarding the distributional tails, which allows to analyze the points far away
from the distribution bulk using the framework of multivariate extreme value
theory. In particular, a classifier dedicated to the tails of the proposed
embedding is obtained which performance outperforms the baseline. This
classifier exhibits a scale invariance property which we leverage by
introducing a novel text generation method for label preserving dataset
augmentation. Numerical experiments on synthetic and real text data demonstrate
the relevance of the proposed framework and confirm that this method generates
meaningful sentences with controllable attribute, e.g. positive or negative
sentiment.
</dc:description>
 <dc:date>2020-03-25</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.11593</dc:identifier>
 <dc:identifier>Advances in Neural Information Processing Systems (NeurIPS), Dec
  2020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.11883</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DCNAS: Densely Connected Neural Architecture Search for Semantic Image
  Segmentation</dc:title>
 <dc:creator>Zhang, Xiong</dc:creator>
 <dc:creator>Xu, Hongmin</dc:creator>
 <dc:creator>Mo, Hong</dc:creator>
 <dc:creator>Tan, Jianchao</dc:creator>
 <dc:creator>Yang, Cheng</dc:creator>
 <dc:creator>Wang, Lei</dc:creator>
 <dc:creator>Ren, Wenqi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Neural Architecture Search (NAS) has shown great potentials in automatically
designing scalable network architectures for dense image predictions. However,
existing NAS algorithms usually compromise on restricted search space and
search on proxy task to meet the achievable computational demands. To allow as
wide as possible network architectures and avoid the gap between target and
proxy dataset, we propose a Densely Connected NAS (DCNAS) framework, which
directly searches the optimal network structures for the multi-scale
representations of visual information, over a large-scale target dataset.
Specifically, by connecting cells with each other using learnable weights, we
introduce a densely connected search space to cover an abundance of mainstream
network designs. Moreover, by combining both path-level and channel-level
sampling strategies, we design a fusion module to reduce the memory consumption
of ample search space. We demonstrate that the architecture obtained from our
DCNAS algorithm achieves state-of-the-art performances on public semantic image
segmentation benchmarks, including 84.3% on Cityscapes, and 86.9% on PASCAL VOC
2012. We also retain leading performances when evaluating the architecture on
the more challenging ADE20K and Pascal Context dataset.
</dc:description>
 <dc:description>Comment: accepted by CVPR 2021</dc:description>
 <dc:date>2020-03-26</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.11883</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.12091</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online and Real-time Object Tracking Algorithm with Extremely Small
  Matrices</dc:title>
 <dc:creator>Tithi, Jesmin Jahan</dc:creator>
 <dc:creator>Aananthakrishnan, Sriram</dc:creator>
 <dc:creator>Petrini, Fabrizio</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Online and Real-time Object Tracking is an interesting workload that can be
used to track objects (e.g., car, human, animal) in a series of video sequences
in real-time. For simple object tracking on edge devices, the output of object
tracking could be as simple as drawing a bounding box around a detected object
and in some cases, the input matrices used in such computation are quite small
(e.g., 4x7, 3x3, 5x5, etc). As a result, the amount of actual work is low.
Therefore, a typical multi-threading based parallelization technique can not
accelerate the tracking application; instead, a throughput based
parallelization technique where each thread operates on independent video
sequences is more rewarding. In this paper, we share our experience in
parallelizing a Simple Online and Real-time Tracking (SORT) application on
shared-memory multicores.
</dc:description>
 <dc:description>Comment: 5 Pages (4 Pages main paper, 5th page for reference), Accepted for
  presentation in WHPC 2020 Summit which got canceled for Corona. But it will
  not be published in Digital Library</dc:description>
 <dc:date>2020-03-26</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.12091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.13118</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recursive Non-Autoregressive Graph-to-Graph Transformer for Dependency
  Parsing with Iterative Refinement</dc:title>
 <dc:creator>Mohammadshahi, Alireza</dc:creator>
 <dc:creator>Henderson, James</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We propose the Recursive Non-autoregressive Graph-to-Graph Transformer
architecture (RNGTr) for the iterative refinement of arbitrary graphs through
the recursive application of a non-autoregressive Graph-to-Graph Transformer
and apply it to syntactic dependency parsing. We demonstrate the power and
effectiveness of RNGTr on several dependency corpora, using a refinement model
pre-trained with BERT. We also introduce Syntactic Transformer (SynTr), a
non-recursive parser similar to our refinement model. RNGTr can improve the
accuracy of a variety of initial parsers on 13 languages from the Universal
Dependencies Treebanks, English and Chinese Penn Treebanks, and the German
CoNLL2009 corpus, even improving over the new state-of-the-art results achieved
by SynTr, significantly improving the state-of-the-art for all corpora tested.
</dc:description>
 <dc:description>Comment: Accepted to Transactions of the Association for Computational
  Linguistics (TACL) journal</dc:description>
 <dc:date>2020-03-29</dc:date>
 <dc:date>2020-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.13118</dc:identifier>
 <dc:identifier>doi:10.1162/tacl_a_00358</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.13268</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Architecture Disentanglement for Deep Neural Networks</dc:title>
 <dc:creator>Hu, Jie</dc:creator>
 <dc:creator>Cao, Liujuan</dc:creator>
 <dc:creator>Ye, Qixiang</dc:creator>
 <dc:creator>Tong, Tong</dc:creator>
 <dc:creator>Zhang, ShengChuan</dc:creator>
 <dc:creator>Li, Ke</dc:creator>
 <dc:creator>Huang, Feiyue</dc:creator>
 <dc:creator>Ji, Rongrong</dc:creator>
 <dc:creator>Shao, Ling</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Understanding the inner workings of deep neural networks (DNNs) is essential
to provide trustworthy artificial intelligence techniques for practical
applications. Existing studies typically involve linking semantic concepts to
units or layers of DNNs, but fail to explain the inference process. In this
paper, we introduce neural architecture disentanglement (NAD) to fill the gap.
Specifically, NAD learns to disentangle a pre-trained DNN into
sub-architectures according to independent tasks, forming information flows
that describe the inference processes. We investigate whether, where, and how
the disentanglement occurs through experiments conducted with handcrafted and
automatically-searched network architectures, on both object-based and
scene-based datasets. Based on the experimental results, we present three new
findings that provide fresh insights into the inner logic of DNNs. First, DNNs
can be divided into sub-architectures for independent tasks. Second, deeper
layers do not always correspond to higher semantics. Third, the connection type
in a DNN affects how the information flows across layers, leading to different
disentanglement behaviors. With NAD, we further explain why DNNs sometimes give
wrong predictions. Experimental results show that misclassified images have a
high probability of being assigned to task sub-architectures similar to the
correct ones. Code will be available at: https://github.com/hujiecpp/NAD.
</dc:description>
 <dc:date>2020-03-30</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.13268</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.13479</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RPM-Net: Robust Point Matching using Learned Features</dc:title>
 <dc:creator>Yew, Zi Jian</dc:creator>
 <dc:creator>Lee, Gim Hee</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Iterative Closest Point (ICP) solves the rigid point cloud registration
problem iteratively in two steps: (1) make hard assignments of spatially
closest point correspondences, and then (2) find the least-squares rigid
transformation. The hard assignments of closest point correspondences based on
spatial distances are sensitive to the initial rigid transformation and
noisy/outlier points, which often cause ICP to converge to wrong local minima.
In this paper, we propose the RPM-Net -- a less sensitive to initialization and
more robust deep learning-based approach for rigid point cloud registration. To
this end, our network uses the differentiable Sinkhorn layer and annealing to
get soft assignments of point correspondences from hybrid features learned from
both spatial coordinates and local geometry. To further improve registration
performance, we introduce a secondary network to predict optimal annealing
parameters. Unlike some existing methods, our RPM-Net handles missing
correspondences and point clouds with partial visibility. Experimental results
show that our RPM-Net achieves state-of-the-art performance compared to
existing non-deep learning and recent deep learning methods. Our source code is
available at the project website https://github.com/yewzijian/RPMNet .
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures. To appear in CVPR2020</dc:description>
 <dc:date>2020-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.13479</dc:identifier>
 <dc:identifier>doi:10.1109/CVPR42600.2020.01184</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.13874</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Low-cost Fault Corrector for Deep Neural Networks through Range
  Restriction</dc:title>
 <dc:creator>Chen, Zitao</dc:creator>
 <dc:creator>Li, Guanpeng</dc:creator>
 <dc:creator>Pattabiraman, Karthik</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The adoption of deep neural networks (DNNs) in safety-critical domains has
engendered serious reliability concerns. A prominent example is hardware
transient faults that are growing in frequency due to the progressive
technology scaling, and can lead to failures in DNNs.
  This work proposes Ranger, a low-cost fault corrector, which directly
rectifies the faulty output due to transient faults without re-computation.
DNNs are inherently resilient to benign faults (which will not cause output
corruption), but not to critical faults (which can result in erroneous output).
Ranger is an automated transformation to selectively restrict the value ranges
in DNNs, which reduces the large deviations caused by critical faults and
transforms them to benign faults that can be tolerated by the inherent
resilience of the DNNs. Our evaluation on 8 DNNs demonstrates Ranger
significantly increases the error resilience of the DNNs (by 3x to 50x), with
no loss in accuracy, and with negligible overheads.
</dc:description>
 <dc:description>Comment: 13 pages, 12 figures</dc:description>
 <dc:date>2020-03-30</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.13874</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.13919</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Numerical schemes for reconstructing profiles of moving sources in
  (time-fractional) evolution equations</dc:title>
 <dc:creator>Liu, Yikan</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:description>  This article is concerned with the derivation of numerical reconstruction
schemes for the inverse moving source problem on determining source profiles in
(time-fractional) evolution equations. As a continuation of the theoretical
result on the uniqueness, we adopt a minimization procedure with regularization
to construct iterative thresholding schemes for the reduced backward problems
on recovering one or two unknown initial value(s). Moreover, an elliptic
approach is proposed to solve a convection equation in the case of two
profiles.
</dc:description>
 <dc:description>Comment: 15 pages, 2 figures, submitted to RIMS K\^oky\^uroku</dc:description>
 <dc:date>2020-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.13919</dc:identifier>
 <dc:identifier>RIMS K\^oky\^uroku, 2174 (2021) 73--87</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.14240</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data-driven Stabilization of SISO Feedback Linearizable Systems</dc:title>
 <dc:creator>Fraile, Lucas</dc:creator>
 <dc:creator>Marchi, Matteo</dc:creator>
 <dc:creator>Tabuada, Paulo</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper we propose a methodology for stabilizing single-input
single-output feedback linearizable systems when no system model is known and
no prior data is available to identify a model. Conceptually, we have been
greatly inspired by the work of Fliess and Join on intelligent PID controllers
and the results in this paper provide sufficient conditions under which a
modified version of their approach is guaranteed to result in asymptotically
stable behavior. One of the key advantages of the proposed results is that,
contrary to other approaches to controlling systems without a model (or with a
partial model), such as reinforcement learning, there is no need for extensive
training nor large amounts of data. Technically, our results draw heavily from
the work of Nesic and co-workers on observer and controller design based on
approximate models. Along the way we also make connections with other well
established results such as high-gain observers and adaptive control. Although
we focus on the simple setting of single-input single-output feedback
linearizable systems we believe the presented results are already theoretically
insightful and practically useful, the last point being substantiated by
experimental evidence.
</dc:description>
 <dc:description>Comment: 30 pages, 4 figures. This paper is an extension of the work presented
  in arXiv:1909.01959. arXiv admin note: text overlap with arXiv:1909.01959</dc:description>
 <dc:date>2020-03-29</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.14240</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2003.14257</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Is it feasible to detect FLOSS version release events from textual
  messages? A case study on Stack Overflow</dc:title>
 <dc:creator>Sokolovsky, A.</dc:creator>
 <dc:creator>Gross, T.</dc:creator>
 <dc:creator>Bacardit, J.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Topic Detection and Tracking (TDT) is a very active research question within
the area of text mining, generally applied to news feeds and Twitter datasets,
where topics and events are detected. The notion of &quot;event&quot; is broad, but
typically it applies to occurrences that can be detected from a single post or
a message. Little attention has been drawn to what we call &quot;micro-events&quot;,
which, due to their nature, cannot be detected from a single piece of textual
information. The study investigates the feasibility of micro-event detection on
textual data using a sample of messages from the Stack Overflow Q&amp;A platform
and Free/Libre Open Source Software (FLOSS) version releases from Libraries.io
dataset. We build pipelines for detection of micro-events using three different
estimators whose parameters are optimized using a grid search approach. We
consider two feature spaces: LDA topic modeling with sentiment analysis, and
hSBM topics with sentiment analysis. The feature spaces are optimized using the
recursive feature elimination with cross validation (RFECV) strategy.
  In our experiments we investigate whether there is a characteristic change in
the topics distribution or sentiment features before or after micro-events take
place and we thoroughly evaluate the capacity of each variant of our analysis
pipeline to detect micro-events. Additionally, we perform a detailed
statistical analysis of the models, including influential cases, variance
inflation factors, validation of the linearity assumption, pseudo R squared
measures and no-information rate. Finally, in order to study limits of
micro-event detection, we design a method for generating micro-event synthetic
datasets with similar properties to the real-world data, and use them to
identify the micro-event detectability threshold for each of the evaluated
classifiers.
</dc:description>
 <dc:date>2020-03-30</dc:date>
 <dc:date>2020-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2003.14257</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0246464</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.00348</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OptTyper: Probabilistic Type Inference by Optimising Logical and Natural
  Constraints</dc:title>
 <dc:creator>Pandi, Irene Vlassi</dc:creator>
 <dc:creator>Barr, Earl T.</dc:creator>
 <dc:creator>Gordon, Andrew D.</dc:creator>
 <dc:creator>Sutton, Charles</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We present a new approach to the type inference problem for dynamic
languages. Our goal is to combine \emph{logical} constraints, that is,
deterministic information from a type system, with \emph{natural} constraints,
that is, uncertain statistical information about types learnt from sources like
identifier names. To this end, we introduce a framework for probabilistic type
inference that combines logic and learning: logical constraints on the types
are extracted from the program, and deep learning is applied to predict types
from surface-level code properties that are statistically associated. The
foremost insight of our method is to constrain the predictions from the
learning procedure to respect the logical constraints, which we achieve by
relaxing the logical inference problem of type prediction into a continuous
optimisation problem. We build a tool called OptTyper to predict missing types
for TypeScript files. OptTyper combines a continuous interpretation of logical
constraints derived by classical static analysis of TypeScript code, with
natural constraints obtained from a deep learning model, which learns naming
conventions for types from a large codebase. By evaluating OptTyper, we show
that the combination of logical and natural constraints yields a large
improvement in performance over either kind of information individually and
achieves a 4% improvement over the state-of-the-art.
</dc:description>
 <dc:description>Comment: 29 pages, 5 figures, 2 tables</dc:description>
 <dc:date>2020-04-01</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.00348</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.01744</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Universality and Training in Binary Hypothesis Testing</dc:title>
 <dc:creator>Bell, Michael</dc:creator>
 <dc:creator>Kochman, Yuval</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The classical binary hypothesis testing problem is revisited. We notice that
when one of the hypotheses is composite, there is an inherent difficulty in
defining an optimality criterion that is both informative and well-justified.
For testing in the simple normal location problem (that is, testing for the
mean of multivariate Gaussians), we overcome the difficulty as follows. In this
problem there exists a natural hardness order between parameters as for
different parameters the error-probailities curves (when the parameter is
known) are either identical, or one dominates the other. We can thus define
minimax performance as the worst-case among parameters which are below some
hardness level. Fortunately, there exists a universal minimax test, in the
sense that it is minimax for all hardness levels simultaneously. Under this
criterion we also find the optimal test for composite hypothesis testing with
training data. This criterion extends to the wide class of local asymptotic
normal models, in an asymptotic sense where the approximation of the error
probabilities is additive. Since we have the asymptotically optimal tests for
composite hypothesis testing with and without training data, we quantify the
loss of universality and gain of training data for these models.
</dc:description>
 <dc:date>2020-04-03</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.01744</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.02288</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continual Domain-Tuning for Pretrained Language Models</dc:title>
 <dc:creator>Rongali, Subendhu</dc:creator>
 <dc:creator>Jagannatha, Abhyuday</dc:creator>
 <dc:creator>Rawat, Bhanu Pratap Singh</dc:creator>
 <dc:creator>Yu, Hong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Pre-trained language models (LM) such as BERT, DistilBERT, and RoBERTa can be
tuned for different domains (domain-tuning) by continuing the pre-training
phase on a new target domain corpus. This simple domain tuning (SDT) technique
has been widely used to create domain-tuned models such as BioBERT, SciBERT and
ClinicalBERT. However, during the pretraining phase on the target domain, the
LM models may catastrophically forget the patterns learned from their source
domain. In this work, we study the effects of catastrophic forgetting on
domain-tuned LM models and investigate methods that mitigate its negative
effects. We propose continual learning (CL) based alternatives for SDT, that
aim to reduce catastrophic forgetting. We show that these methods may increase
the performance of LM models on downstream target domain tasks. Additionally,
we also show that constraining the LM model from forgetting the source domain
leads to downstream task models that are more robust to domain shifts. We
analyze the computational cost of using our proposed CL methods and provide
recommendations for computationally lightweight and effective CL domain-tuning
procedures.
</dc:description>
 <dc:description>Comment: Updated from a previous shorter version</dc:description>
 <dc:date>2020-04-05</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.02288</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.03212</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Text-Guided Neural Image Inpainting</dc:title>
 <dc:creator>Zhang, Lisai</dc:creator>
 <dc:creator>Chen, Qingcai</dc:creator>
 <dc:creator>Hu, Baotian</dc:creator>
 <dc:creator>Jiang, Shuoran</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Image inpainting task requires filling the corrupted image with contents
coherent with the context. This research field has achieved promising progress
by using neural image inpainting methods. Nevertheless, there is still a
critical challenge in guessing the missed content with only the context pixels.
The goal of this paper is to fill the semantic information in corrupted images
according to the provided descriptive text. Unique from existing text-guided
image generation works, the inpainting models are required to compare the
semantic content of the given text and the remaining part of the image, then
find out the semantic content that should be filled for missing part. To
fulfill such a task, we propose a novel inpainting model named Text-Guided Dual
Attention Inpainting Network (TDANet). Firstly, a dual multimodal attention
mechanism is designed to extract the explicit semantic information about the
corrupted regions, which is done by comparing the descriptive text and
complementary image areas through reciprocal attention. Secondly, an image-text
matching loss is applied to maximize the semantic similarity of the generated
image and the text. Experiments are conducted on two open datasets. Results
show that the proposed TDANet model reaches new state-of-the-art on both
quantitative and qualitative measures. Result analysis suggests that the
generated images are consistent with the guidance text, enabling the generation
of various results by providing different descriptions. Codes are available at
https://github.com/idealwhite/TDANet
</dc:description>
 <dc:description>Comment: ACM MM'2020 (Oral). 9 pages, 4 tables, 7 figures</dc:description>
 <dc:date>2020-04-07</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.03212</dc:identifier>
 <dc:identifier>doi:10.1145/3394171.3414017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.03259</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What and Where: Modeling Skeletons from Semantic and Spatial
  Perspectives for Action Recognition</dc:title>
 <dc:creator>Shi, Lei</dc:creator>
 <dc:creator>Zhang, Yifan</dc:creator>
 <dc:creator>Cheng, Jian</dc:creator>
 <dc:creator>Lu, Hanqing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Skeleton data, which consists of only the 2D/3D coordinates of the human
joints, has been widely studied for human action recognition. Existing methods
take the semantics as prior knowledge to group human joints and draw
correlations according to their spatial locations, which we call the semantic
perspective for skeleton modeling. In this paper, in contrast to previous
approaches, we propose to model skeletons from a novel spatial perspective,
from which the model takes the spatial location as prior knowledge to group
human joints and mines the discriminative patterns of local areas in a
hierarchical manner. The two perspectives are orthogonal and complementary to
each other; and by fusing them in a unified framework, our method achieves a
more comprehensive understanding of the skeleton data. Besides, we customized
two networks for the two perspectives. From the semantic perspective, we
propose a Transformer-like network that is expert in modeling joint
correlations, and present three effective techniques to adapt it for skeleton
data. From the spatial perspective, we transform the skeleton data into the
sparse format for efficient feature extraction and present two types of sparse
convolutional networks for sparse skeleton modeling. Extensive experiments are
conducted on three challenging datasets for skeleton-based human action/gesture
recognition, namely, NTU-60, NTU-120 and SHREC, where our method achieves
state-of-the-art performance.
</dc:description>
 <dc:date>2020-04-07</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.03259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.04077</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continual Learning with Gated Incremental Memories for sequential data
  processing</dc:title>
 <dc:creator>Cossu, Andrea</dc:creator>
 <dc:creator>Carta, Antonio</dc:creator>
 <dc:creator>Bacciu, Davide</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The ability to learn in dynamic, nonstationary environments without
forgetting previous knowledge, also known as Continual Learning (CL), is a key
enabler for scalable and trustworthy deployments of adaptive solutions. While
the importance of continual learning is largely acknowledged in machine vision
and reinforcement learning problems, this is mostly under-documented for
sequence processing tasks. This work proposes a Recurrent Neural Network (RNN)
model for CL that is able to deal with concept drift in input distribution
without forgetting previously acquired knowledge. We also implement and test a
popular CL approach, Elastic Weight Consolidation (EWC), on top of two
different types of RNNs. Finally, we compare the performances of our enhanced
architecture against EWC and RNNs on a set of standard CL benchmarks, adapted
to the sequential data processing scenario. Results show the superior
performance of our architecture and highlight the need for special solutions
designed to address CL in RNNs.
</dc:description>
 <dc:description>Comment: Accepted as a conference paper at 2020 International Joint Conference
  on Neural Networks (IJCNN 2020). Part of 2020 IEEE World Congress on
  Computational Intelligence (IEEE WCCI 2020)</dc:description>
 <dc:date>2020-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.04077</dc:identifier>
 <dc:identifier>doi:10.1109/IJCNN48605.2020.9207550</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.04323</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Robust Dispatch of Combined Heat and Power Systems</dc:title>
 <dc:creator>Jiang, Yibao</dc:creator>
 <dc:creator>Wan, Can</dc:creator>
 <dc:creator>Botterud, Audun</dc:creator>
 <dc:creator>Song, Yonghua</dc:creator>
 <dc:creator>Dong, Zhao Yang</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Combined heat and power systems facilitate efficient interactions between
individual energy sectors for higher renewable energy accommodation. However,
the feasibility of operational strategies is difficult to guarantee due to the
presence of substantial uncertainties pertinent to renewable energy and
multi-energy loads. This paper proposes a novel efficient robust dispatch model
of combined heat and power systems based on extensions of disturbance invariant
sets. The approach has high computational efficiency and provides flexible and
robust strategies with an adjustable level of conservativeness. In particular,
the proposed robust dispatch method obtains operational strategies by solving a
nominal uncertainty-free dispatch problem, whose complexity is identical to a
deterministic problem. The robustness against uncertainties is enhanced by
endowing the nominal dispatch model with properly tightened constraints
considering time-variant uncertainty sets. Towards this end, a novel direct
constraint tightening algorithm is developed based on the dual norm to
calculate multi-period tightened constraints efficiently without linear
programming iterations. Furthermore, the budget uncertainty set is newly
combined with constraint tightening to flexibly adjust the conservativeness
level of robust solutions. The effectiveness of the proposed robust method is
demonstrated in simulation studies of a test system in terms of computational
efficiency, decision robustness and cost optimality.
</dc:description>
 <dc:description>Comment: 8 pages, 12 figures</dc:description>
 <dc:date>2020-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.04323</dc:identifier>
 <dc:identifier>doi:10.1109/TSG.2021.3066449</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.04627</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AdaStereo: A Simple and Efficient Approach for Adaptive Stereo Matching</dc:title>
 <dc:creator>Song, Xiao</dc:creator>
 <dc:creator>Yang, Guorun</dc:creator>
 <dc:creator>Zhu, Xinge</dc:creator>
 <dc:creator>Zhou, Hui</dc:creator>
 <dc:creator>Wang, Zhe</dc:creator>
 <dc:creator>Shi, Jianping</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, records on stereo matching benchmarks are constantly broken by
end-to-end disparity networks. However, the domain adaptation ability of these
deep models is quite poor. Addressing such problem, we present a novel
domain-adaptive pipeline called AdaStereo that aims to align multi-level
representations for deep stereo matching networks. Compared to previous methods
for adaptive stereo matching, our AdaStereo realizes a more standard, complete
and effective domain adaptation pipeline. Firstly, we propose a non-adversarial
progressive color transfer algorithm for input image-level alignment. Secondly,
we design an efficient parameter-free cost normalization layer for internal
feature-level alignment. Lastly, a highly related auxiliary task,
self-supervised occlusion-aware reconstruction is presented to narrow down the
gaps in output space. Our AdaStereo models achieve state-of-the-art
cross-domain performance on multiple stereo benchmarks, including KITTI,
Middlebury, ETH3D, and DrivingStereo, even outperforming disparity networks
finetuned with target-domain ground-truths.
</dc:description>
 <dc:description>Comment: Accepted by CVPR 2021</dc:description>
 <dc:date>2020-04-09</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.04627</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.05693</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SFE-GACN: A Novel Unknown Attack Detection Method Using Intra Categories
  Generation in Embedding Space</dc:title>
 <dc:creator>Liu, Ao</dc:creator>
 <dc:creator>Wang, Yunpeng</dc:creator>
 <dc:creator>Li, Tao</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In the encrypted network traffic intrusion detection, deep learning based
schemes have attracted lots of attention. However, in real-world scenarios,
data is often insufficient (few-shot), which leads to various deviations
between the models prediction and the ground truth. Consequently, downstream
tasks such as unknown attack detection based on few-shot will be limited by
insufficient data. In this paper, we propose a novel unknown attack detection
method based on Intra Categories Generation in Embedding Space, namely
SFE-GACN, which might be the solution of few-shot problem. Concretely, we first
proposed Session Feature Embedding (SFE) to summarize the context of sessions
(session is the basic granularity of network traffic), bring the insufficient
data to the pre-trained embedding space. In this way, we achieve the goal of
preliminary information extension in the few-shot case. Second, we further
propose the Generative Adversarial Cooperative Network (GACN), which improves
the conventional Generative Adversarial Network by supervising the generated
sample to avoid falling into similar categories, and thus enables samples to
generate intra categories. Our proposed SFE-GACN can accurately generate
session samples in the case of few-shot, and ensure the difference between
categories during data augmentation. The detection results show that, compared
to the state-of-the-art method, the average TPR is 8.38% higher, and the
average FPR is 12.77% lower. In addition, we evaluated the graphics generation
capabilities of GACN on the graphics dataset, the result shows our proposed
GACN can be popularized for generating easy-confused multi-categories graphics.
</dc:description>
 <dc:description>Comment: 19 pages, 9 figures, submitted to Computers &amp; Security, accepted</dc:description>
 <dc:date>2020-04-12</dc:date>
 <dc:date>2021-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.05693</dc:identifier>
 <dc:identifier>doi:10.1016/j.cose.2021.102262</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.06337</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differentially Private AirComp Federated Learning with Power Adaptation
  Harnessing Receiver Noise</dc:title>
 <dc:creator>Koda, Yusuke</dc:creator>
 <dc:creator>Yamamoto, Koji</dc:creator>
 <dc:creator>Nishio, Takayuki</dc:creator>
 <dc:creator>Morikura, Masahiro</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  Over-the-air computation (AirComp)-based federated learning (FL) enables
low-latency uploads and the aggregation of machine learning models by
exploiting simultaneous co-channel transmission and the resultant waveform
superposition. This study aims at realizing secure AirComp-based FL against
various privacy attacks where malicious central servers infer clients' private
data from aggregated global models. To this end, a differentially private
AirComp-based FL is designed in this study, where the key idea is to harness
receiver noise perturbation injected to aggregated global models inherently,
thereby preventing the inference of clients' private data. However, the
variance of the inherent receiver noise is often uncontrollable, which renders
the process of injecting an appropriate noise perturbation to achieve a desired
privacy level quite challenging. Hence, this study designs transmit power
control across clients, wherein the received signal level is adjusted
intentionally to control the noise perturbation levels effectively, thereby
achieving the desired privacy level. It is observed that a higher privacy level
requires lower transmit power, which indicates the tradeoff between the privacy
level and signal-to-noise ratio (SNR). To understand this tradeoff more fully,
the closed-form expressions of SNR (with respect to the privacy level) are
derived, and the tradeoff is analytically demonstrated. The analytical results
also demonstrate that among the configurable parameters, the number of
participating clients is a key parameter that enhances the received SNR under
the aforementioned tradeoff. The analytical results are validated through
numerical evaluations.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures</dc:description>
 <dc:date>2020-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.06337</dc:identifier>
 <dc:identifier>doi:10.1109/GLOBECOM42002.2020.9322199</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.06711</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deformable Siamese Attention Networks for Visual Object Tracking</dc:title>
 <dc:creator>Yu, Yuechen</dc:creator>
 <dc:creator>Xiong, Yilei</dc:creator>
 <dc:creator>Huang, Weilin</dc:creator>
 <dc:creator>Scott, Matthew R.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Siamese-based trackers have achieved excellent performance on visual object
tracking. However, the target template is not updated online, and the features
of the target template and search image are computed independently in a Siamese
architecture. In this paper, we propose Deformable Siamese Attention Networks,
referred to as SiamAttn, by introducing a new Siamese attention mechanism that
computes deformable self-attention and cross-attention. The self attention
learns strong context information via spatial attention, and selectively
emphasizes interdependent channel-wise features with channel attention. The
cross-attention is capable of aggregating rich contextual inter-dependencies
between the target template and the search image, providing an implicit manner
to adaptively update the target template. In addition, we design a region
refinement module that computes depth-wise cross correlations between the
attentional features for more accurate tracking. We conduct experiments on six
benchmarks, where our method achieves new state of-the-art results,
outperforming the strong baseline, SiamRPN++ [24], by 0.464-&gt;0.537 and
0.415-&gt;0.470 EAO on VOT 2016 and 2018. Our code is available at:
https://github.com/msight-tech/research-siamattn.
</dc:description>
 <dc:description>Comment: CVPR 2020, with code available at:
  https://github.com/msight-tech/research-siamattn</dc:description>
 <dc:date>2020-04-14</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.06711</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.07683</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Do sequence-to-sequence VAEs learn global features of sentences?</dc:title>
 <dc:creator>Bosc, Tom</dc:creator>
 <dc:creator>Vincent, Pascal</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Autoregressive language models are powerful and relatively easy to train.
However, these models are usually trained without explicit conditioning labels
and do not offer easy ways to control global aspects such as sentiment or topic
during generation. Bowman &amp; al. (2016) adapted the Variational Autoencoder
(VAE) for natural language with the sequence-to-sequence architecture and
claimed that the latent vector was able to capture such global features in an
unsupervised manner. We question this claim. We measure which words benefit
most from the latent information by decomposing the reconstruction loss per
position in the sentence. Using this method, we find that VAEs are prone to
memorizing the first words and the sentence length, producing local features of
limited usefulness. To alleviate this, we investigate alternative architectures
based on bag-of-words assumptions and language model pretraining. These
variants learn latent variables that are more global, i.e., more predictive of
topic or sentiment labels. Moreover, using reconstructions, we observe that
they decrease memorization: the first word and the sentence length are not
recovered as accurately than with the baselines, consequently yielding more
diverse reconstructions.
</dc:description>
 <dc:description>Comment: Camera-ready version, EMNLP2020</dc:description>
 <dc:date>2020-04-16</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.07683</dc:identifier>
 <dc:identifier>doi:10.18653/v1/2020.emnlp-main.350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.08555</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning on Traffic Prediction: Methods, Analysis and Future
  Directions</dc:title>
 <dc:creator>Yin, Xueyan</dc:creator>
 <dc:creator>Wu, Genze</dc:creator>
 <dc:creator>Wei, Jinze</dc:creator>
 <dc:creator>Shen, Yanming</dc:creator>
 <dc:creator>Qi, Heng</dc:creator>
 <dc:creator>Yin, Baocai</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Traffic prediction plays an essential role in intelligent transportation
system. Accurate traffic prediction can assist route planing, guide vehicle
dispatching, and mitigate traffic congestion. This problem is challenging due
to the complicated and dynamic spatio-temporal dependencies between different
regions in the road network. Recently, a significant amount of research efforts
have been devoted to this area, especially deep learning method, greatly
advancing traffic prediction abilities. The purpose of this paper is to provide
a comprehensive survey on deep learning-based approaches in traffic prediction
from multiple perspectives. Specifically, we first summarize the existing
traffic prediction methods, and give a taxonomy. Second, we list the
state-of-the-art approaches in different traffic prediction applications.
Third, we comprehensively collect and organize widely used public datasets in
the existing literature to facilitate other researchers. Furthermore, we give
an evaluation and analysis by conducting extensive experiments to compare the
performance of different methods on a real-world public dataset. Finally, we
discuss open challenges in this field.
</dc:description>
 <dc:description>Comment: to be published in IEEE Transactions on Intelligent Transportation
  Systems</dc:description>
 <dc:date>2020-04-18</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.08555</dc:identifier>
 <dc:identifier>doi:10.1109/TITS.2021.3054840</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.08714</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Almost intersecting families</dc:title>
 <dc:creator>Frankl, Peter</dc:creator>
 <dc:creator>Kupavskii, Andrey</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Let $n &gt; k &gt; 1$ be integers, $[n] = \{1, \ldots, n\}$. Let $\mathcal F$ be a
family of $k$-subsets of~$[n]$. The family $\mathcal F$ is called intersecting
if $F \cap F' \neq \emptyset$ for all $F, F' \in \mathcal F$. It is called
almost intersecting if it is not intersecting but to every $F \in \mathcal F$
there is at most one $F'\in \mathcal F$ satisfying $F \cap F' = \emptyset$.
Gerbner et al. proved that if $n \geq 2k + 2$ then $|\mathcal F| \leq {n -
1\choose k - 1}$ holds for almost intersecting families. The main result
implies the considerably stronger and best possible bound $|\mathcal F| \leq {n
- 1\choose k - 1} - {n - k - 1\choose k - 1} + 2$ for $n &gt; (2 + o(1))k$.
</dc:description>
 <dc:date>2020-04-18</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.08714</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.09341</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uniform H\&quot;older-norm bounds for finite element approximations of
  second-order elliptic equations</dc:title>
 <dc:creator>Diening, Lars</dc:creator>
 <dc:creator>Scharle, Toni</dc:creator>
 <dc:creator>S&#xfc;li, Endre</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65N30, 65N50, 35J25</dc:subject>
 <dc:description>  We develop a discrete counterpart of the De Giorgi-Nash-Moser theory, which
provides uniform H\&quot;older-norm bounds on continuous piecewise affine finite
element approximations of second-order linear elliptic problems of the form
$-\nabla \cdot(A\nabla u)=f-\nabla\cdot F$ with $A\in
L^\infty(\Omega;\mathbb{R}^{n\times n})$ a uniformly elliptic matrix-valued
function, $f\in L^{q}(\Omega)$, $F\in L^p(\Omega;\mathbb{R}^n)$, with $p &gt; n$
and $q &gt; n/2$, on $A$-nonobtuse shape-regular triangulations, which are not
required to be quasi-uniform, of a bounded polyhedral Lipschitz domain $\Omega
\subset \mathbb{R}^n$.
</dc:description>
 <dc:description>Comment: The paper has been accepted for publication in the IMAJNA on 24th
  March 2021</dc:description>
 <dc:date>2020-04-20</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.09341</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.09750</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MiniSeg: An Extremely Minimum Network for Efficient COVID-19
  Segmentation</dc:title>
 <dc:creator>Qiu, Yu</dc:creator>
 <dc:creator>Liu, Yun</dc:creator>
 <dc:creator>Li, Shijie</dc:creator>
 <dc:creator>Xu, Jing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The rapid spread of the new pandemic, i.e., COVID-19, has severely threatened
global health. Deep-learning-based computer-aided screening, e.g., COVID-19
infected CT area segmentation, has attracted much attention. However, the
publicly available COVID-19 training data are limited, easily causing
overfitting for traditional deep learning methods that are usually data-hungry
with millions of parameters. On the other hand, fast training/testing and low
computational cost are also necessary for quick deployment and development of
COVID-19 screening systems, but traditional deep learning methods are usually
computationally intensive. To address the above problems, we propose MiniSeg, a
lightweight deep learning model for efficient COVID-19 segmentation. Compared
with traditional segmentation methods, MiniSeg has several significant
strengths: i) it only has 83K parameters and is thus not easy to overfit; ii)
it has high computational efficiency and is thus convenient for practical
deployment; iii) it can be fast retrained by other users using their private
COVID-19 data for further improving performance. In addition, we build a
comprehensive COVID-19 segmentation benchmark for comparing MiniSeg to
traditional methods.
</dc:description>
 <dc:date>2020-04-21</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.09750</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.09819</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Forecasting the Price-Response of a Pool of Buildings via Homothetic
  Inverse Optimization</dc:title>
 <dc:creator>Fern&#xe1;ndez-Blanco, Ricardo</dc:creator>
 <dc:creator>Morales, Juan Miguel</dc:creator>
 <dc:creator>Pineda, Salvador</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper focuses on the day-ahead forecasting of the aggregate power of a
pool of smart buildings equipped with thermostatically-controlled loads. We
first propose the modeling of the aggregate behavior of its power trajectory by
using a geometric approach. Specifically, we assume that the aggregate power is
a homothet of a prototype building, whose physical and technical parameters are
chosen to be the mean of those in the pool. This allows us to preserve the
building thermal dynamics of the pool. We then apply inverse optimization to
estimate the homothetic parameters with bilevel programming. The lower level
characterizes the price-response of the ensemble by a set of marginal utility
curves and a homothet of the prototype building, which, in turn, are inferred
in the upper-level problem. The upper level minimizes the mean absolute error
over a training sample. This bilevel program is transformed into a regularized
nonlinear problem that is initialized with the solution given by an efficient
heuristic procedure. This heuristic consists in solving two linear programs and
its solution is deemed a suitable proxy for the original bilevel problem. The
results have been compared to state-of-the-art methodologies.
</dc:description>
 <dc:date>2020-04-21</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.09819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.10128</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An effective construction for cut-and-project rhombus tilings with
  global n-fold rotational symmetry</dc:title>
 <dc:creator>Lutfalla, Victor H.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:description>  We give an explicit and effective construction for rhombus cut-and-project
tilings with global n-fold rotational symmetry for any n. This construction is
based on the dualization of regular n-fold multigrids. The main point is to
prove the regularity of these multigrids, for this we use a result on
trigonometric diophantine equations.
</dc:description>
 <dc:date>2020-04-21</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.10128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.10497</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Learning and Inference with Compressed Images</dc:title>
 <dc:creator>Katakol, Sudeep</dc:creator>
 <dc:creator>Elbarashy, Basem</dc:creator>
 <dc:creator>Herranz, Luis</dc:creator>
 <dc:creator>van de Weijer, Joost</dc:creator>
 <dc:creator>Lopez, Antonio M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>I.4.2</dc:subject>
 <dc:description>  Modern computer vision requires processing large amounts of data, both while
training the model and/or during inference, once the model is deployed.
Scenarios where images are captured and processed in physically separated
locations are increasingly common (e.g. autonomous vehicles, cloud computing).
In addition, many devices suffer from limited resources to store or transmit
data (e.g. storage space, channel capacity). In these scenarios, lossy image
compression plays a crucial role to effectively increase the number of images
collected under such constraints. However, lossy compression entails some
undesired degradation of the data that may harm the performance of the
downstream analysis task at hand, since important semantic information may be
lost in the process. Moreover, we may only have compressed images at training
time but are able to use original images at inference time, or vice versa, and
in such a case, the downstream model suffers from covariate shift. In this
paper, we analyze this phenomenon, with a special focus on vision-based
perception for autonomous driving as a paradigmatic scenario. We see that loss
of semantic information and covariate shift do indeed exist, resulting in a
drop in performance that depends on the compression rate. In order to address
the problem, we propose dataset restoration, based on image restoration with
generative adversarial networks (GANs). Our method is agnostic to both the
particular image compression method and the downstream task; and has the
advantage of not adding additional cost to the deployed models, which is
particularly important in resource-limited devices. The presented experiments
focus on semantic segmentation as a challenging use case, cover a broad range
of compression rates and diverse datasets, and show how our method is able to
significantly alleviate the negative effects of compression on the downstream
visual task.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE Transactions on Image Processing; 15
  pages, 15 figures</dc:description>
 <dc:date>2020-04-22</dc:date>
 <dc:date>2021-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.10497</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2021.3058545</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.10734</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Red-GAN: Attacking class imbalance via conditioned generation. Yet
  another perspective on medical image synthesis for skin lesion dermoscopy and
  brain tumor MRI</dc:title>
 <dc:creator>Qasim, Ahmad B</dc:creator>
 <dc:creator>Ezhov, Ivan</dc:creator>
 <dc:creator>Shit, Suprosanna</dc:creator>
 <dc:creator>Schoppe, Oliver</dc:creator>
 <dc:creator>Paetzold, Johannes C</dc:creator>
 <dc:creator>Sekuboyina, Anjany</dc:creator>
 <dc:creator>Kofler, Florian</dc:creator>
 <dc:creator>Lipkova, Jana</dc:creator>
 <dc:creator>Li, Hongwei</dc:creator>
 <dc:creator>Menze, Bjoern</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Exploiting learning algorithms under scarce data regimes is a limitation and
a reality of the medical imaging field. In an attempt to mitigate the problem,
we propose a data augmentation protocol based on generative adversarial
networks. We condition the networks at a pixel-level (segmentation mask) and at
a global-level information (acquisition environment or lesion type). Such
conditioning provides immediate access to the image-label pairs while
controlling global class specific appearance of the synthesized images. To
stimulate synthesis of the features relevant for the segmentation task, an
additional passive player in a form of segmentor is introduced into the
adversarial game. We validate the approach on two medical datasets: BraTS,
ISIC. By controlling the class distribution through injection of synthetic
images into the training set we achieve control over the accuracy levels of the
datasets' classes.
</dc:description>
 <dc:date>2020-04-22</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.10734</dc:identifier>
 <dc:identifier>Published in Proceedings of the 3rd edition of Medical Imaging
  with Deep Learning, Montr\'eal, Canada, PMLR 121, 2020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.11612</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vision based hardware-software real-time control system for autonomous
  landing of an UAV</dc:title>
 <dc:creator>Blachut, Krzysztof</dc:creator>
 <dc:creator>Szolc, Hubert</dc:creator>
 <dc:creator>Wasala, Mateusz</dc:creator>
 <dc:creator>Kryjak, Tomasz</dc:creator>
 <dc:creator>Gorgon, Marek</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  In this paper we present a vision based hardware-software control system
enabling autonomous landing of a multirotor unmanned aerial vehicle (UAV). It
allows the detection of a marked landing pad in real-time for a 1280 x 720 @ 60
fps video stream. In addition, a LiDAR sensor is used to measure the altitude
above ground. A heterogeneous Zynq SoC device is used as the computing
platform. The solution was tested on a number of sequences and the landing pad
was detected with 96% accuracy. This research shows that a reprogrammable
heterogeneous computing system is a good solution for UAVs because it enables
real-time data stream processing with relatively low energy consumption.
</dc:description>
 <dc:description>Comment: 7 pages, 9 figures, submitted to MMAR 2020 conference</dc:description>
 <dc:date>2020-04-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.11612</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-030-59006-2_2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.13225</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Petrov-Galerkin flux upwinding for mixed mimetic spectral elements, and
  its application to geophysical flow problems</dc:title>
 <dc:creator>Lee, David</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Upwinded mass fluxes are described and analysed for advection operators
discretised using mixed mimetic spectral elements. This involves a
Petrov-Galerkin formulation by which the mass flux test functions are evaluated
at downstream locations along velocity characteristics. As for the original
mixed mimetic spectral element advection operator, the upwinded mass flux
advection operator is conservative, however unlike the original advection
operator, which is purely hyperbolic, the upwinded advection operator adds
dissipation which is biased towards high wave numbers. The upwinded advection
operator also removes the spectral gaps present in the dispersion relation for
the original advection operator. As for the original advection operator, a
material form advection operator may be constructed by similarly downwinding
the trial functions of the tracer gradients. Both methods allow for the
recovery of exact energy conservation for an incompressible flow field via
skew-symmetric formulations. However these skew-symmetric formulations are once
again purely hyperbolic operators which do not suppress oscillations. The
scheme is implemented within a shallow water code on the sphere in order to
diagnose and interpolate the potential vorticity. In the absence of other
dissipation terms, it is shown to yield more coherent results for a standard
test case of barotropic instability.
</dc:description>
 <dc:date>2020-04-27</dc:date>
 <dc:date>2020-09-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.13225</dc:identifier>
 <dc:identifier>doi:10.1016/j.camwa.2021.02.017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.13335</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Doubly Regularized Linear Discriminant Analysis Classifier with
  Automatic Parameter Selection</dc:title>
 <dc:creator>Zaib, Alam</dc:creator>
 <dc:creator>Ballal, Tarig</dc:creator>
 <dc:creator>Khattak, Shahid</dc:creator>
 <dc:creator>Al-Naffouri, Tareq Y.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Linear discriminant analysis (LDA) based classifiers tend to falter in many
practical settings where the training data size is smaller than, or comparable
to, the number of features. As a remedy, different regularized LDA (RLDA)
methods have been proposed. These methods may still perform poorly depending on
the size and quality of the available training data. In particular, the test
data deviation from the training data model, for example, due to noise
contamination, can cause severe performance degradation. Moreover, these
methods commit further to the Gaussian assumption (upon which LDA is
established) to tune their regularization parameters, which may compromise
accuracy when dealing with real data. To address these issues, we propose a
doubly regularized LDA classifier that we denote as R2LDA. In the proposed
R2LDA approach, the RLDA score function is converted into an inner product of
two vectors. By substituting the expressions of the regularized estimators of
these vectors, we obtain the R2LDA score function that involves two
regularization parameters. To set the values of these parameters, we adopt
three existing regularization techniques; the constrained perturbation
regularization approach (COPRA), the bounded perturbation regularization (BPR)
algorithm, and the generalized cross-validation (GCV) method. These methods are
used to tune the regularization parameters based on linear estimation models,
with the sample covariance matrix's square root being the linear operator.
Results obtained from both synthetic and real data demonstrate the consistency
and effectiveness of the proposed R2LDA approach, especially in scenarios
involving test data contaminated with noise that is not observed during the
training phase.
</dc:description>
 <dc:description>Comment: 11 pages, 40 figures</dc:description>
 <dc:date>2020-04-28</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.13335</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.13969</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complementing Lexical Retrieval with Semantic Residual Embedding</dc:title>
 <dc:creator>Gao, Luyu</dc:creator>
 <dc:creator>Dai, Zhuyun</dc:creator>
 <dc:creator>Chen, Tongfei</dc:creator>
 <dc:creator>Fan, Zhen</dc:creator>
 <dc:creator>Van Durme, Benjamin</dc:creator>
 <dc:creator>Callan, Jamie</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  This paper presents CLEAR, a retrieval model that seeks to complement
classical lexical exact-match models such as BM25 with semantic matching
signals from a neural embedding matching model. CLEAR explicitly trains the
neural embedding to encode language structures and semantics that lexical
retrieval fails to capture with a novel residual-based embedding learning
method. Empirical evaluations demonstrate the advantages of CLEAR over
state-of-the-art retrieval models, and that it can substantially improve the
end-to-end accuracy and efficiency of reranking pipelines.
</dc:description>
 <dc:description>Comment: ECIR 2021</dc:description>
 <dc:date>2020-04-29</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.13969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2004.15020</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Crisscrossed Captions: Extended Intramodal and Intermodal Semantic
  Similarity Judgments for MS-COCO</dc:title>
 <dc:creator>Parekh, Zarana</dc:creator>
 <dc:creator>Baldridge, Jason</dc:creator>
 <dc:creator>Cer, Daniel</dc:creator>
 <dc:creator>Waters, Austin</dc:creator>
 <dc:creator>Yang, Yinfei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  By supporting multi-modal retrieval training and evaluation, image captioning
datasets have spurred remarkable progress on representation learning.
Unfortunately, datasets have limited cross-modal associations: images are not
paired with other images, captions are only paired with other captions of the
same image, there are no negative associations and there are missing positive
cross-modal associations. This undermines research into how inter-modality
learning impacts intra-modality tasks. We address this gap with Crisscrossed
Captions (CxC), an extension of the MS-COCO dataset with human semantic
similarity judgments for 267,095 intra- and inter-modality pairs. We report
baseline results on CxC for strong existing unimodal and multimodal models. We
also evaluate a multitask dual encoder trained on both image-caption and
caption-caption pairs that crucially demonstrates CxC's value for measuring the
influence of intra- and inter-modality learning.
</dc:description>
 <dc:description>Comment: To be presented at EACL2021</dc:description>
 <dc:date>2020-04-30</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2004.15020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.00402</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Workgroup Mapping: Visual Analysis of Collaboration Culture</dc:title>
 <dc:creator>Edge, Darren</dc:creator>
 <dc:creator>Larson, Jonathan</dc:creator>
 <dc:creator>Trandev, Nikolay</dc:creator>
 <dc:creator>Shah, Neha Parikh</dc:creator>
 <dc:creator>Buractaon, Carolyn</dc:creator>
 <dc:creator>Caurvina, Nicholas</dc:creator>
 <dc:creator>Evans, Nathan</dc:creator>
 <dc:creator>White, Christopher M.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The digital transformation of work presents new opportunities to understand
how informal workgroups organize around the dynamic needs of organizations,
potentially in contrast to the formal, static, and idealized hierarchies
depicted by org charts. We present a design study that spans multiple enabling
capabilities for the visual mapping and analysis of organizational workgroups,
including metrics for quantifying two dimensions of collaboration culture: the
fluidity of collaborative relationships (measured using network machine
learning) and the freedom with which workgroups form across organizational
boundaries. These capabilities come together to create a turnkey pipeline that
combines the analysis of a target organization, the generation of data graphics
and statistics, and their integration in a template-based presentation that
enables narrative visualization of results. Our metrics and visuals have
supported hundreds of presentations to executives of major US-based and
multinational organizations, while our engineering practices have created an
ensemble of standalone tools with broad relevance to visualization and visual
analytics. We present our work as an example of applied visual analytics
research, describing the design iterations that allowed us to move from
experimentation to production, as well as the perspectives of the research team
and the customer-facing team at each stage in this process.
</dc:description>
 <dc:date>2020-05-01</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.00402</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.00536</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can Terahertz Provide High-Rate Reliable Low Latency Communications for
  Wireless VR?</dc:title>
 <dc:creator>Chaccour, Christina</dc:creator>
 <dc:creator>Soorki, Mehdi Naderi</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:creator>Bennis, Mehdi</dc:creator>
 <dc:creator>Popovski, Petar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Wireless virtual reality (VR) imposes new visual and haptic requirements that
are directly linked to the quality-of-experience (QoE) of VR users. These QoE
requirements can only be met by wireless connectivity that offers high-rate and
high-reliability low latency communications (HRLLC), unlike the low rates
usually considered in vanilla ultra-reliable low latency communication
scenarios. The high rates for VR over short distances can only be supported by
an enormous bandwidth, which is available in terahertz (THz) frequency bands.
Guaranteeing HRLLC requires dealing with the uncertainty that is specific to
the THz channel. To explore the potential of THz for meeting HRLLC
requirements, a quantification of the risk for an unreliable VR performance is
conducted through a novel and rigorous characterization of the tail of the
end-to-end (E2E) delay. Then, a thorough analysis of the tail-value-atrisk
(TVaR) is performed to concretely characterize the behavior of extreme wireless
events crucial to the real-time VR experience. System reliability for scenarios
with guaranteed line-of-sight (LoS) is then derived as a function of THz
network parameters after deriving a novel expression for the probability
distribution function of the THz transmission delay. Numerical results show
that abundant bandwidth and low molecular absorption are necessary to improve
the reliability. However, their effect remains secondary compared to the
availability of LoS, which significantly affects the THz HRLLC performance. In
particular, for scenarios with guaranteed LoS, a reliability of 99.999% (with
an E2E delay threshold of 20 ms) for a bandwidth of 15 GHz along with data
rates of 18.3 Gbps can be achieved by the THz network (operating at a frequency
of 1 THz), compared to a reliability of 96% for twice the bandwidth, when
blockages are considered.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1905.07656</dc:description>
 <dc:date>2020-04-30</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.00536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.01460</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reducing graph transversals via edge contractions</dc:title>
 <dc:creator>Lima, Paloma T.</dc:creator>
 <dc:creator>Santos, Vinicius F. dos</dc:creator>
 <dc:creator>Sau, Ignasi</dc:creator>
 <dc:creator>Souza, U&#xe9;verton S.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05C15</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  For a graph invariant $\pi$, the Contraction($\pi$) problem consists in,
given a graph $G$ and two positive integers $k,d$, deciding whether one can
contract at most $k$ edges of $G$ to obtain a graph in which $\pi$ has dropped
by at least $d$. Galby et al. [ISAAC 2019, MFCS 2019] recently studied the case
where $\pi$ is the size of a minimum dominating set. We focus on graph
invariants defined as the minimum size of a vertex set that hits all the
occurrences of graphs in a collection ${\cal H}$ according to a fixed
containment relation. We prove co-NP-hardness results under some assumptions on
the graphs in ${\cal H}$, which in particular imply that Contraction($\pi$) is
co-NP-hard even for fixed $k=d=1$ when $\pi$ is the size of a minimum feedback
vertex set or an odd cycle transversal. In sharp contrast, we show that when
$\pi$ is the size of a minimum vertex cover, the problem is in XP parameterized
by $d$.
</dc:description>
 <dc:description>Comment: 19 pages, 2 figures</dc:description>
 <dc:date>2020-05-04</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.01460</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.01861</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sampling Arbitrary Subgraphs Exactly Uniformly in Sublinear Time</dc:title>
 <dc:creator>Fichtenberger, Hendrik</dc:creator>
 <dc:creator>Gao, Mingze</dc:creator>
 <dc:creator>Peng, Pan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present a simple sublinear-time algorithm for sampling an arbitrary
subgraph $H$ \emph{exactly uniformly} from a graph $G$ with $m$ edges, to which
the algorithm has access by performing the following types of queries: (1)
degree queries, (2) neighbor queries, (3) pair queries and (4) edge sampling
queries. The query complexity and running time of our algorithm are
$\tilde{O}(\min\{m, \frac{m^{\rho(H)}}{\# H}\})$ and
$\tilde{O}(\frac{m^{\rho(H)}}{\# H})$, respectively, where $\rho(H)$ is the
fractional edge-cover of $H$ and $\# H$ is the number of copies of $H$ in $G$.
For any clique on $r$ vertices, i.e., $H=K_r$, our algorithm is almost optimal
as any algorithm that samples an $H$ from any distribution that has $\Omega(1)$
total probability mass on the set of all copies of $H$ must perform
$\Omega(\min\{m, \frac{m^{\rho(H)}}{\# H\cdot (cr)^r}\})$ queries.
  Together with the query and time complexities of the $(1\pm
\varepsilon)$-approximation algorithm for the number of subgraphs $H$ by
Assadi, Kapralov and Khanna [ITCS 2018] and the lower bound by Eden and
Rosenbaum [APPROX 2018] for approximately counting cliques, our results suggest
that in our query model, approximately counting cliques is &quot;equivalent to&quot;
exactly uniformly sampling cliques, in the sense that the query and time
complexities of exactly uniform sampling and randomized approximate counting
are within a polylogarithmic factor of each other. This stands in interesting
contrast to an analogous relation between approximate counting and almost
uniformly sampling for self-reducible problems in the polynomial-time regime by
Jerrum, Valiant and Vazirani [TCS 1986].
</dc:description>
 <dc:description>Comment: ICALP 2020</dc:description>
 <dc:date>2020-05-04</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.01861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.02287</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence analysis of the scaled boundary finite element method for
  the Laplace equation</dc:title>
 <dc:creator>Bertrand, Fleurianne</dc:creator>
 <dc:creator>Boffi, Daniele</dc:creator>
 <dc:creator>de Diego, Gonzalo G.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65N12, 65N15 (Primary) 65N38 (Secondary)</dc:subject>
 <dc:subject>G.1.2</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:description>  The scaled boundary finite element method (SBFEM) is a relatively recent
boundary element method that allows the approximation of solutions to PDEs
without the need of a fundamental solution. A theoretical framework for the
convergence analysis of SBFEM is proposed here. This is achieved by defining a
space of semi-discrete functions and constructing an interpolation operator
onto this space. We prove error estimates for this interpolation operator and
show that optimal convergence to the solution can be obtained in SBFEM. These
theoretical results are backed by a numerical example.
</dc:description>
 <dc:description>Comment: 15 pages, 3 figures</dc:description>
 <dc:date>2020-05-05</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.02287</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.03343</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating the phase dynamics of coupled oscillators via time-variant
  topological features</dc:title>
 <dc:creator>Itabashi, Kazuha</dc:creator>
 <dc:creator>Tran, Quoc Hoan</dc:creator>
 <dc:creator>Hasegawa, Yoshihiko</dc:creator>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:description>  By characterizing the phase dynamics in coupled oscillators, we gain insights
into the fundamental phenomena of complex systems. The collective dynamics in
oscillatory systems are often described by order parameters, which are
insufficient for identifying more specific behaviors. To improve this
situation, we propose a topological approach that constructs the quantitative
features describing the phase evolution of oscillators. Here, the phase data
are mapped into a high-dimensional space at each time, and the topological
features describing the shape of the data are subsequently extracted from the
mapped points. These features are extended to time-variant topological features
by adding the evolution time as an extra dimension in the topological feature
space. The time-variant features provide crucial insights into the evolution of
phase dynamics. Combining these features with the kernel method, we
characterize the multi-clustered synchronized dynamics during the early
evolution stages. Finally, we demonstrate that our method can qualitatively
explain chimera states. The experimental results confirmed the superiority of
our method over those based on order parameters, especially when the available
data are limited to the early-stage dynamics.
</dc:description>
 <dc:description>Comment: 13 pages, 8 figures</dc:description>
 <dc:date>2020-05-07</dc:date>
 <dc:date>2021-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.03343</dc:identifier>
 <dc:identifier>Phys. Rev. E 103, 032207 (2021)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.103.032207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.03768</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Two-Stage Adaptive Robust Optimization for Power Flexibility
  Aggregation</dc:title>
 <dc:creator>Chen, Xin</dc:creator>
 <dc:creator>Li, Na</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Adaptive robust optimization (ARO) is a well-known technique to deal with the
parameter uncertainty in optimization problems. While the ARO framework can
actually be borrowed to solve some special problems without uncertain
parameters, such as the power flexibility aggregation problem studied in this
paper. To effectively harness the significant flexibility from massive
distributed energy resources (DERs), power flexibility aggregation is performed
for a distribution system to compute the feasible region of the exchanged power
at the substation over time. Based on two-stage ARO, this paper proposes a
novel method to aggregate system-level multi-period power flexibility,
considering heterogeneous DER facilities, network operational constraints, and
an unbalanced power flow model. This method is applicable to aggregate only the
active (or reactive) power, and the joint active-reactive power domain.
Accordingly, two power aggregation models with two-stage optimization are
developed: one focuses on aggregating active power and computes its optimal
feasible intervals over multiple periods, and the other solves the optimal
elliptical feasible regions for the aggregate active-reactive power. By
leveraging the ARO technique, the disaggregation feasibility of the obtained
feasible regions is guaranteed with optimality. Numerical simulations on a
real-world distribution feeder with 126 multi-phase nodes demonstrate the
effectiveness of the proposed method.
</dc:description>
 <dc:description>Comment: 12 Pages</dc:description>
 <dc:date>2020-05-07</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.03768</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.05859</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Architecture Transfer</dc:title>
 <dc:creator>Lu, Zhichao</dc:creator>
 <dc:creator>Sreekumar, Gautam</dc:creator>
 <dc:creator>Goodman, Erik</dc:creator>
 <dc:creator>Banzhaf, Wolfgang</dc:creator>
 <dc:creator>Deb, Kalyanmoy</dc:creator>
 <dc:creator>Boddeti, Vishnu Naresh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Neural architecture search (NAS) has emerged as a promising avenue for
automatically designing task-specific neural networks. Existing NAS approaches
require one complete search for each deployment specification of hardware or
objective. This is a computationally impractical endeavor given the potentially
large number of application scenarios. In this paper, we propose Neural
Architecture Transfer (NAT) to overcome this limitation. NAT is designed to
efficiently generate task-specific custom models that are competitive under
multiple conflicting objectives. To realize this goal we learn task-specific
supernets from which specialized subnets can be sampled without any additional
training. The key to our approach is an integrated online transfer learning and
many-objective evolutionary search procedure. A pre-trained supernet is
iteratively adapted while simultaneously searching for task-specific subnets.
We demonstrate the efficacy of NAT on 11 benchmark image classification tasks
ranging from large-scale multi-class to small-scale fine-grained datasets. In
all cases, including ImageNet, NATNets improve upon the state-of-the-art under
mobile settings ($\leq$ 600M Multiply-Adds). Surprisingly, small-scale
fine-grained datasets benefit the most from NAT. At the same time, the
architecture search and transfer is orders of magnitude more efficient than
existing NAS methods. Overall, the experimental evaluation indicates that,
across diverse image classification tasks and computational objectives, NAT is
an appreciably more effective alternative to conventional transfer learning of
fine-tuning weights of an existing network architecture learned on standard
datasets. Code is available at
https://github.com/human-analysis/neural-architecture-transfer
</dc:description>
 <dc:description>Comment: Code is available at
  https://github.com/human-analysis/neural-architecture-transfer</dc:description>
 <dc:date>2020-05-12</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.05859</dc:identifier>
 <dc:identifier>IEEE Transactions on Pattern Analysis and Machine Intelligence,
  2021</dc:identifier>
 <dc:identifier>doi:10.1109/TPAMI.2021.3052758</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.06065</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Estimation of Intelligibility Measure for Consonants in Speech</dc:title>
 <dc:creator>Abavisani, Ali</dc:creator>
 <dc:creator>Hasegawa-Johnson, Mark</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  In this article, we provide a model to estimate a real-valued measure of the
intelligibility of individual speech segments. We trained regression models
based on Convolutional Neural Networks (CNN) for stop consonants
\textipa{/p,t,k,b,d,g/} associated with vowel \textipa{/A/}, to estimate the
corresponding Signal to Noise Ratio (SNR) at which the Consonant-Vowel (CV)
sound becomes intelligible for Normal Hearing (NH) ears. The intelligibility
measure for each sound is called SNR$_{90}$, and is defined to be the SNR level
at which human participants are able to recognize the consonant at least 90\%
correctly, on average, as determined in prior experiments with NH subjects.
Performance of the CNN is compared to a baseline prediction based on automatic
speech recognition (ASR), specifically, a constant offset subtracted from the
SNR at which the ASR becomes capable of correctly labeling the consonant.
Compared to baseline, our models were able to accurately estimate the
SNR$_{90}$~intelligibility measure with less than 2 [dB$^2$] Mean Squared Error
(MSE) on average, while the baseline ASR-defined measure computes
SNR$_{90}$~with a variance of 5.2 to 26.6 [dB$^2$], depending on the consonant.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure, 7 tables, submitted to Inter Speech 2020
  Conference</dc:description>
 <dc:date>2020-05-12</dc:date>
 <dc:date>2020-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.06065</dc:identifier>
 <dc:identifier>doi:10.21437/Interspeech.2020-2121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.06138</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel Learning of Koopman Eigenfunctions and Invariant Subspaces For
  Accurate Long-Term Prediction</dc:title>
 <dc:creator>Haseli, Masih</dc:creator>
 <dc:creator>Cort&#xe9;s, Jorge</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  We present a parallel data-driven strategy to identify finite-dimensional
functional spaces invariant under the Koopman operator associated to an unknown
dynamical system. We build on the Symmetric Subspace Decomposition (SSD)
algorithm, a centralized method that under mild conditions on data sampling
provably finds the maximal Koopman-invariant subspace and all Koopman
eigenfunctions in an arbitrary finite-dimensional functional space. A network
of processors, each aware of a common dictionary of functions and equipped with
a local set of data snapshots, repeatedly interact over a directed
communication graph. Each processor receives its neighbors' estimates of the
invariant dictionary and refines its estimate by applying SSD with its local
data on the intersection of the subspaces spanned by its own dictionary and the
neighbors' dictionaries. We identify conditions on the network topology to
ensure the algorithm identifies the maximal Koopman-invariant subspace in the
span of the original dictionary, characterize its time, computational, and
communication complexity, and establish its robustness against communication
failures.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2020-05-12</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.06138</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.06718</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distance and Steering Heuristics for Streamline-Based Flow Field
  Planning</dc:title>
 <dc:creator>To, K. Y. Cadmus</dc:creator>
 <dc:creator>Yoo, Chanyeol</dc:creator>
 <dc:creator>Anstee, Stuart</dc:creator>
 <dc:creator>Fitch, Robert</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Motion planning for vehicles under the influence of flow fields can benefit
from the idea of streamline-based planning, which exploits ideas from fluid
dynamics to achieve computational efficiency. Important to such planners is an
efficient means of computing the travel distance and direction between two
points in free space, but this is difficult to achieve in strong incompressible
flows such as ocean currents. We propose two useful distance functions in
analytical form that combine Euclidean distance with values of the stream
function associated with a flow field, and with an estimation of the strength
of the opposing flow between two points. Further, we propose steering
heuristics that are useful for steering towards a sampled point. We evaluate
these ideas by integrating them with RRT* and comparing the algorithm's
performance with state-of-the-art methods in an artificial flow field and in
actual ocean prediction data in the region of the dominant East Australian
Current between Sydney and Brisbane. Results demonstrate the method's
computational efficiency and ability to find high-quality paths outperforming
state-of-the-art methods, and show promise for practical use with autonomous
marine robots.
</dc:description>
 <dc:description>Comment: 7 pages, 7 figures, accepted to IEEE ICRA 2020. Copyright 2020 IEEE</dc:description>
 <dc:date>2020-05-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.06718</dc:identifier>
 <dc:identifier>doi:10.1109/ICRA40945.2020.9196555</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.06727</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Shared-memory Parallel Sinkhorn-Knopp Algorithm to Compute
  the Word Mover's Distance</dc:title>
 <dc:creator>Tithi, Jesmin Jahan</dc:creator>
 <dc:creator>Petrini, Fabrizio</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The Word Mover's Distance (WMD) is a metric that measures the semantic
dissimilarity between two text documents by computing the cost of moving all
words of a source/query document to the most similar words of a target document
optimally. Computing WMD between two documents is costly because it requires
solving an optimization problem that costs \(O(V^3log(V))\) where \(V\) is the
number of unique words in the document. Fortunately, the WMD can be framed as
the Earth Mover's Distance (EMD) (also known as the Optimal Transportation
Distance) for which it has been shown that the algorithmic complexity can be
reduced to \(O(V^2)\) by adding an entropy penalty to the optimization problem
and a similar idea can be adapted to compute WMD efficiently. Additionally, the
computation can be made highly parallel by computing WMD of a single query
document against multiple target documents at once (e.g., finding whether a
given tweet is similar to any other tweets happened in a day). In this paper,
we present a shared-memory parallel Sinkhorn-Knopp Algorithm to compute the WMD
of one document against many other documents by adopting the \(O(V^2)\) EMD
algorithm. We used algorithmic transformations to change the original dense
compute-heavy kernel to a sparse compute kernel and obtained \(67\times\)
speedup using \(96\) cores on the state-of-the-art of Intel\textregistered{}
4-sockets Cascade Lake machine w.r.t. its sequential run. Our parallel
algorithm is over \(700\times\) faster than the naive parallel python code that
internally uses optimized matrix library calls.
</dc:description>
 <dc:description>Comment: 10 pages, 1 page for reference, total 11 pages</dc:description>
 <dc:date>2020-05-14</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.06727</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.07456</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-lingual Transfer of Sentiment Classifiers</dc:title>
 <dc:creator>Robnik-Sikonja, Marko</dc:creator>
 <dc:creator>Reba, Kristjan</dc:creator>
 <dc:creator>Mozetic, Igor</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>68T50 (Primary)</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:subject>K.4.2</dc:subject>
 <dc:description>  Word embeddings represent words in a numeric space so that semantic relations
between words are represented as distances and directions in the vector space.
Cross-lingual word embeddings transform vector spaces of different languages so
that similar words are aligned. This is done by constructing a mapping between
vector spaces of two languages or learning a joint vector space for multiple
languages. Cross-lingual embeddings can be used to transfer machine learning
models between languages, thereby compensating for insufficient data in
less-resourced languages. We use cross-lingual word embeddings to transfer
machine learning prediction models for Twitter sentiment between 13 languages.
We focus on two transfer mechanisms that recently show superior transfer
performance. The first mechanism uses the trained models whose input is the
joint numerical space for many languages as implemented in the LASER library.
The second mechanism uses large pretrained multilingual BERT language models.
Our experiments show that the transfer of models between similar languages is
sensible, even with no target language data. The performance of cross-lingual
models obtained with the multilingual BERT and LASER library is comparable, and
the differences are language-dependent. The transfer with CroSloEngual BERT,
pretrained on only three languages, is superior on these and some closely
related languages.
</dc:description>
 <dc:description>Comment: 18 pages, 8 tables</dc:description>
 <dc:date>2020-05-15</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.07456</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.08606</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-End Lip Synchronisation Based on Pattern Classification</dc:title>
 <dc:creator>Kim, You Jin</dc:creator>
 <dc:creator>Heo, Hee Soo</dc:creator>
 <dc:creator>Chung, Soo-Whan</dc:creator>
 <dc:creator>Lee, Bong-Jin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  The goal of this work is to synchronise audio and video of a talking face
using deep neural network models. Existing works have trained networks on proxy
tasks such as cross-modal similarity learning, and then computed similarities
between audio and video frames using a sliding window approach. While these
methods demonstrate satisfactory performance, the networks are not trained
directly on the task. To this end, we propose an end-to-end trained network
that can directly predict the offset between an audio stream and the
corresponding video stream. The similarity matrix between the two modalities is
first computed from the features, then the inference of the offset can be
considered to be a pattern recognition problem where the matrix is considered
equivalent to an image. The feature extractor and the classifier are trained
jointly. We demonstrate that the proposed approach outperforms the previous
work by a large margin on LRS2 and LRS3 datasets.
</dc:description>
 <dc:description>Comment: slt 2021 accepted</dc:description>
 <dc:date>2020-05-18</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.08606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.09945</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Early Classification of Time Series. Cost-based Optimization Criterion
  and Algorithms</dc:title>
 <dc:creator>Achenchabe, Youssef</dc:creator>
 <dc:creator>Bondu, Alexis</dc:creator>
 <dc:creator>Cornu&#xe9;jols, Antoine</dc:creator>
 <dc:creator>Dachraoui, Asma</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  An increasing number of applications require to recognize the class of an
incoming time series as quickly as possible without unduly compromising the
accuracy of the prediction. In this paper, we put forward a new optimization
criterion which takes into account both the cost of misclassification and the
cost of delaying the decision. Based on this optimization criterion, we derived
a family of non-myopic algorithms which try to anticipate the expected future
gain in information in balance with the cost of waiting. In one class of
algorithms, unsupervised-based, the expectations use the clustering of time
series, while in a second class, supervised-based, time series are grouped
according to the confidence level of the classifier used to label them.
Extensive experiments carried out on real data sets using a large range of
delay cost functions show that the presented algorithms are able to
satisfactorily solving the earliness vs. accuracy trade-off, with the
supervised-based approaches faring better than the unsupervised-based ones. In
addition, all these methods perform better in a wide variety of conditions than
a state of the art method based on a myopic strategy which is recognized as
very competitive.
</dc:description>
 <dc:description>Comment: Accepted for publication in Machine learning journal (MACH)</dc:description>
 <dc:date>2020-05-20</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.09945</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.10817</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computationally efficient sparse clustering</dc:title>
 <dc:creator>L&#xf6;ffler, Matthias</dc:creator>
 <dc:creator>Wein, Alexander S.</dc:creator>
 <dc:creator>Bandeira, Afonso S.</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>62H30</dc:subject>
 <dc:description>  We study statistical and computational limits of clustering when the means of
the centres are sparse and their dimension is possibly much larger than the
sample size. Our theoretical analysis focuses on the model $X_i = z_i \theta +
\varepsilon_i, ~z_i \in \{-1,1\}, ~\varepsilon_i \thicksim \mathcal{N}(0,I)$,
which has two clusters with centres $\theta$ and $-\theta$. We provide a finite
sample analysis of a new sparse clustering algorithm based on sparse PCA and
show that it achieves the minimax optimal misclustering rate in the regime
$\|\theta\| \rightarrow \infty$.
  Our results require the sparsity to grow slower than the square root of the
sample size. Using a recent framework for computational lower bounds -- the
low-degree likelihood ratio -- we give evidence that this condition is
necessary for any polynomial-time clustering algorithm to succeed below the BBP
threshold. This complements existing evidence based on reductions and
statistical query lower bounds. Compared to these existing results, we cover a
wider set of parameter regimes and give a more precise understanding of the
runtime required and the misclustering error achievable. Our results imply that
a large class of tests based on low-degree polynomials fail to solve even the
weak testing task.
</dc:description>
 <dc:description>Comment: 33 pages</dc:description>
 <dc:date>2020-05-21</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.10817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.10863</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RV-FuseNet: Range View Based Fusion of Time-Series LiDAR Data for Joint
  3D Object Detection and Motion Forecasting</dc:title>
 <dc:creator>Laddha, Ankit</dc:creator>
 <dc:creator>Gautam, Shivam</dc:creator>
 <dc:creator>Meyer, Gregory P.</dc:creator>
 <dc:creator>Vallespi-Gonzalez, Carlos</dc:creator>
 <dc:creator>Wellington, Carl K.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Robust real-time detection and motion forecasting of traffic participants is
necessary for autonomous vehicles to safely navigate urban environments. In
this paper, we present RV-FuseNet, a novel end-to-end approach for joint
detection and trajectory estimation directly from time-series LiDAR data.
Instead of the widely used bird's eye view (BEV) representation, we utilize the
native range view (RV) representation of LiDAR data. The RV preserves the full
resolution of the sensor by avoiding the voxelization used in the BEV.
Furthermore, RV can be processed efficiently due to its compactness. Previous
approaches project time-series data to a common viewpoint for temporal fusion,
and often this viewpoint is different from where it was captured. This is
sufficient for BEV methods, but for RV methods, this can lead to loss of
information and data distortion which has an adverse impact on performance. To
address this challenge we propose a simple yet effective novel architecture,
\textit{Incremental Fusion}, that minimizes the information loss by
sequentially projecting each RV sweep into the viewpoint of the next sweep in
time. We show that our approach significantly improves motion forecasting
performance over the existing state-of-the-art. Furthermore, we demonstrate
that our sequential fusion approach is superior to alternative RV based fusion
methods on multiple datasets.
</dc:description>
 <dc:description>Comment: Submitted to IROS 2021</dc:description>
 <dc:date>2020-05-21</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.10863</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.11041</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of Information Cascade Analysis: Models, Predictions, and
  Recent Advances</dc:title>
 <dc:creator>Zhou, Fan</dc:creator>
 <dc:creator>Xu, Xovee</dc:creator>
 <dc:creator>Trajcevski, Goce</dc:creator>
 <dc:creator>Zhang, Kunpeng</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The deluge of digital information in our daily life -- from user-generated
content, such as microblogs and scientific papers, to online business, such as
viral marketing and advertising -- offers unprecedented opportunities to
explore and exploit the trajectories and structures of the evolution of
information cascades. Abundant research efforts, both academic and industrial,
have aimed to reach a better understanding of the mechanisms driving the spread
of information and quantifying the outcome of information diffusion. This
article presents a comprehensive review and categorization of information
popularity prediction methods, from feature engineering and stochastic
processes, through graph representation, to deep learning-based approaches.
Specifically, we first formally define different types of information cascades
and summarize the perspectives of existing studies. We then present a taxonomy
that categorizes existing works into the aforementioned three main groups as
well as the main subclasses in each group, and we systematically review
cutting-edge research work. Finally, we summarize the pros and cons of existing
research efforts and outline the open challenges and opportunities in this
field.
</dc:description>
 <dc:description>Comment: Author version, with 43 pages, 9 figures, and 11 tables</dc:description>
 <dc:date>2020-05-22</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.11041</dc:identifier>
 <dc:identifier>ACM Computing Surveys (CSUR), 54(2), Article 27, Mar 2021, 36
  pages</dc:identifier>
 <dc:identifier>doi:10.1145/3433000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.11387</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectrally-Encoded Single-Pixel Machine Vision Using Diffractive
  Networks</dc:title>
 <dc:creator>Li, Jingxi</dc:creator>
 <dc:creator>Mengu, Deniz</dc:creator>
 <dc:creator>Yardimci, Nezih T.</dc:creator>
 <dc:creator>Luo, Yi</dc:creator>
 <dc:creator>Li, Xurong</dc:creator>
 <dc:creator>Veli, Muhammed</dc:creator>
 <dc:creator>Rivenson, Yair</dc:creator>
 <dc:creator>Jarrahi, Mona</dc:creator>
 <dc:creator>Ozcan, Aydogan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:description>  3D engineering of matter has opened up new avenues for designing systems that
can perform various computational tasks through light-matter interaction. Here,
we demonstrate the design of optical networks in the form of multiple
diffractive layers that are trained using deep learning to transform and encode
the spatial information of objects into the power spectrum of the diffracted
light, which are used to perform optical classification of objects with a
single-pixel spectroscopic detector. Using a time-domain spectroscopy setup
with a plasmonic nanoantenna-based detector, we experimentally validated this
machine vision framework at terahertz spectrum to optically classify the images
of handwritten digits by detecting the spectral power of the diffracted light
at ten distinct wavelengths, each representing one class/digit. We also report
the coupling of this spectral encoding achieved through a diffractive optical
network with a shallow electronic neural network, separately trained to
reconstruct the images of handwritten digits based on solely the spectral
information encoded in these ten distinct wavelengths within the diffracted
light. These reconstructed images demonstrate task-specific image decompression
and can also be cycled back as new inputs to the same diffractive network to
improve its optical object classification. This unique machine vision framework
merges the power of deep learning with the spatial and spectral processing
capabilities of diffractive networks, and can also be extended to other
spectral-domain measurement systems to enable new 3D imaging and sensing
modalities integrated with spectrally encoded classification tasks performed
through diffractive optical networks.
</dc:description>
 <dc:description>Comment: 21 pages, 5 figures, 1 table</dc:description>
 <dc:date>2020-05-15</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.11387</dc:identifier>
 <dc:identifier>Science Advances (2021)</dc:identifier>
 <dc:identifier>doi:10.1126/sciadv.abd7690</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.12244</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Controllability of Hypergraphs</dc:title>
 <dc:creator>Chen, Can</dc:creator>
 <dc:creator>Surana, Amit</dc:creator>
 <dc:creator>Bloch, Anthony</dc:creator>
 <dc:creator>Rajapakse, Indika</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we develop a notion of controllability for hypergraphs via
tensor algebra and polynomial control theory. Inspired by uniform hypergraphs,
we propose a new tensor-based multilinear dynamical system representation, and
derive a Kalman-rank-like condition to determine the minimum number of control
nodes (MCN) needed to achieve controllability of even uniform hypergraphs. We
present an efficient heuristic to obtain the MCN. MCN can be used as a measure
of robustness, and we show that it is related to the hypergraph degree
distribution in simulated examples. Finally, we use MCN to examine robustness
in real biological networks.
</dc:description>
 <dc:description>Comment: 12 pages, 9 figures, 1 table, IEEE Transactions on Network Science
  and Engineering, accepted to appear</dc:description>
 <dc:date>2020-05-25</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.12244</dc:identifier>
 <dc:identifier>doi:10.1109/TNSE.2021.3068203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.12955</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Notes on a high order fully discrete scheme for the Korteweg-de vries
  equation with a time-stepping procedure of Runge-Kutta-composition type</dc:title>
 <dc:creator>Dougalis, Vassilios A.</dc:creator>
 <dc:creator>Dur&#xe1;n, Angel</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We consider the periodic initial-value problem for the Korteweg-de Vries
equation that we discretize in space by a spectral Fourier-Galerkin method and
in time by an implicit, high order, Runge-Kutta scheme of composition type
based on the implicit midpoint rule. We prove $L^{2}$ error estimates for the
resulting semidiscrete and the fully discrete approximations.
</dc:description>
 <dc:date>2020-05-26</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.12955</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.13167</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How does Working from Home Affect Developer Productivity? -- A Case
  Study of Baidu During COVID-19 Pandemic</dc:title>
 <dc:creator>Bao, Lingfeng</dc:creator>
 <dc:creator>Li, Tao</dc:creator>
 <dc:creator>Xia, Xin</dc:creator>
 <dc:creator>Zhu, Kaiyu</dc:creator>
 <dc:creator>Li, Hui</dc:creator>
 <dc:creator>Yang, Xiaohu</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Nowadays, working from home (WFH) has become a popular work arrangement due
to its many potential benefits for both companies and employees (e.g.,
increasing job satisfaction and retention of employees). Many previous studies
have investigated the impact of working from home on the productivity of
employees. However, most of these studies usually use a qualitative analysis
method such as survey and interview, and the studied participants do not work
from home for a long continuing time. Due to the outbreak of coronavirus
disease 2019 (COVID-19), a large number of companies asked their employees to
work from home, which provides us an opportunity to investigate whether working
from home affects their productivity.
  In this study, to investigate the difference of developer productivity
between working from home and working onsite, we conduct a quantitative
analysis based on a dataset of developers' daily activities from Baidu Inc, one
of the largest IT companies in China. In total, we collected approximately four
thousand records of 139 developers' activities of 138 working days. Out of
these records, 1,103 records are submitted when developers work from home due
to COVID-19 pandemic. We find that WFH has both positive and negative impacts
on developer productivity in terms of different metrics, e.g., the number of
builds/commits/code reviews. We also notice that working from home has
different impacts on projects with different characteristics including
programming language, project type/age/size. For example, working from home has
a negative impact on developer productivity for large projects. Additionally,
we find that productivity varies for different developers. Based on these
findings, we get some feedbacks from developers of Baidu and understand some
reasons why WFH has different impacts on developer productivity.
</dc:description>
 <dc:date>2020-05-27</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.13167</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.13525</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Security: Adversarial Defense Using Long-Run Dynamics of
  Energy-Based Models</dc:title>
 <dc:creator>Hill, Mitch</dc:creator>
 <dc:creator>Mitchell, Jonathan</dc:creator>
 <dc:creator>Zhu, Song-Chun</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The vulnerability of deep networks to adversarial attacks is a central
problem for deep learning from the perspective of both cognition and security.
The current most successful defense method is to train a classifier using
adversarial images created during learning. Another defense approach involves
transformation or purification of the original input to remove adversarial
signals before the image is classified. We focus on defending naturally-trained
classifiers using Markov Chain Monte Carlo (MCMC) sampling with an Energy-Based
Model (EBM) for adversarial purification. In contrast to adversarial training,
our approach is intended to secure pre-existing and highly vulnerable
classifiers.
  The memoryless behavior of long-run MCMC sampling will eventually remove
adversarial signals, while metastable behavior preserves consistent appearance
of MCMC samples after many steps to allow accurate long-run prediction.
Balancing these factors can lead to effective purification and robust
classification. We evaluate adversarial defense with an EBM using the strongest
known attacks against purification. Our contributions are 1) an improved method
for training EBM's with realistic long-run MCMC samples, 2) an
Expectation-Over-Transformation (EOT) defense that resolves theoretical
ambiguities for stochastic defenses and from which the EOT attack naturally
follows, and 3) state-of-the-art adversarial defense for naturally-trained
classifiers and competitive defense compared to adversarially-trained
classifiers on Cifar-10, SVHN, and Cifar-100. Code and pre-trained models are
available at https://github.com/point0bar1/ebm-defense.
</dc:description>
 <dc:description>Comment: ICLR 2021</dc:description>
 <dc:date>2020-05-27</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.13525</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.13527</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Potential Games</dc:title>
 <dc:creator>Mguni, David</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Computing the Nash equilibrium (NE) for N-player non-zerosum stochastic games
is a formidable challenge. Currently, algorithmic methods in stochastic game
theory are unable to compute NE for stochastic games (SGs) for settings in all
but extreme cases in which the players either play as a team or have
diametrically opposed objectives in a two-player setting. This greatly impedes
the application of the SG framework to numerous problems within economics and
practical systems of interest. In this paper, we provide a method of computing
Nash equilibria in nonzero-sum settings and for populations of players more
than two. In particular, we identify a subset of SGs known as stochastic
potential games (SPGs) for which the (Markov perfect) Nash equilibrium can be
computed tractably and in polynomial time. Unlike SGs for which, in general,
computing the NE is PSPACE-hard, we show that SGs with the potential property
are P-Complete. We further demonstrate that for each SPG there is a dual Markov
decision process whose solution coincides with the MP-NE of the SPG. We lastly
provide algorithms that tractably compute the MP-NE for SGs with more than two
players.
</dc:description>
 <dc:description>Comment: The submission contains an overlap with and has been superseded by
  arXiv:2103.09284</dc:description>
 <dc:date>2020-05-27</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.13527</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.13563</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An arbitrary high-order Spectral Difference method for the induction
  equation</dc:title>
 <dc:creator>Veiga, Maria Han</dc:creator>
 <dc:creator>Velasco-Romero, David A</dc:creator>
 <dc:creator>Wenger, Quentin</dc:creator>
 <dc:creator>Teyssier, Romain</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>65Mxx</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:description>  We study in this paper three variants of the high-order Discontinuous
Galerkin (DG) method with Runge-Kutta (RK) time integration for the induction
equation, analysing their ability to preserve the divergence free constraint of
the magnetic field. To quantify divergence errors, we use a norm based on both
a surface term, measuring global divergence errors, and a volume term,
measuring local divergence errors. This leads us to design a new, arbitrary
high-order numerical scheme for the induction equation in multiple space
dimensions, based on a modification of the Spectral Difference (SD) method [1]
with ADER time integration [2]. It appears as a natural extension of the
Constrained Transport (CT) method. We show that it preserves
$\nabla\cdot\vec{B}=0$ exactly by construction, both in a local and a global
sense. We compare our new method to the 3 RKDG variants and show that the
magnetic energy evolution and the solution maps of our new SD-ADER scheme are
qualitatively similar to the RKDG variant with divergence cleaning, but without
the need for an additional equation and an extra variable to control the
divergence errors.
  [1] Liu Y., Vinokur M., Wang Z.J. (2006) Discontinuous Spectral Difference
Method for Conservation Laws on Unstructured Grids. In: Groth C., Zingg D.W.
(eds) Computational Fluid Dynamics 2004. Springer, Berlin, Heidelberg
  [2] Dumbser M., Castro M., Par\'es C., Toro E.F (2009) ADER schemes on
unstructured meshes for nonconservative hyperbolic systems: Applications to
geophysical flows. In: Computers &amp; Fluids, Volume 38, Issue 9
</dc:description>
 <dc:description>Comment: 33 pages</dc:description>
 <dc:date>2020-05-27</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.13563</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.13702</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Difficulty of Membership Inference Attacks</dc:title>
 <dc:creator>Rezaei, Shahbaz</dc:creator>
 <dc:creator>Liu, Xin</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recent studies propose membership inference (MI) attacks on deep models,
where the goal is to infer if a sample has been used in the training process.
Despite their apparent success, these studies only report accuracy, precision,
and recall of the positive class (member class). Hence, the performance of
these attacks have not been clearly reported on negative class (non-member
class). In this paper, we show that the way the MI attack performance has been
reported is often misleading because they suffer from high false positive rate
or false alarm rate (FAR) that has not been reported. FAR shows how often the
attack model mislabel non-training samples (non-member) as training (member)
ones. The high FAR makes MI attacks fundamentally impractical, which is
particularly more significant for tasks such as membership inference where the
majority of samples in reality belong to the negative (non-training) class.
Moreover, we show that the current MI attack models can only identify the
membership of misclassified samples with mediocre accuracy at best, which only
constitute a very small portion of training samples.
  We analyze several new features that have not been comprehensively explored
for membership inference before, including distance to the decision boundary
and gradient norms, and conclude that deep models' responses are mostly similar
among train and non-train samples. We conduct several experiments on image
classification tasks, including MNIST, CIFAR-10, CIFAR-100, and ImageNet, using
various model architecture, including LeNet, AlexNet, ResNet, etc. We show that
the current state-of-the-art MI attacks cannot achieve high accuracy and low
FAR at the same time, even when the attacker is given several advantages.
  The source code is available at https://github.com/shrezaei/MI-Attack.
</dc:description>
 <dc:date>2020-05-27</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.13702</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.14025</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>copent: Estimating Copula Entropy and Transfer Entropy in R</dc:title>
 <dc:creator>Ma, Jian</dc:creator>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  Statistical independence and conditional independence are two fundamental
concepts in statistics and machine learning. Copula Entropy is a mathematical
concept defined by Ma and Sun for multivariate statistical independence
measuring and testing, and also proved to be closely related to conditional
independence (or transfer entropy). As the unified framework for measuring both
independence and causality, CE has been applied to solve several related
statistical or machine learning problems, including association discovery,
structure learning, variable selection, and causal discovery. The nonparametric
methods for estimating copula entropy and transfer entropy were also proposed
previously. This paper introduces copent, the R package which implements these
proposed methods for estimating copula entropy and transfer entropy. The
implementation detail of the package is introduced. Three examples with
simulated data and real-world data on variable selection and causal discovery
are also presented to demonstrate the usage of this package. The examples on
variable selection and causal discovery show the strong ability of copent on
testing (conditional) independence compared with the related packages. The
copent package is available on the Comprehensive R Archive Network (CRAN) and
also on GitHub at https://github.com/majianthu/copent.
</dc:description>
 <dc:description>Comment: 18 pages, 3 figures</dc:description>
 <dc:date>2020-05-27</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.14025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.14282</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Blockchain Interoperability: Past, Present, and Future
  Trends</dc:title>
 <dc:creator>Belchior, Rafael</dc:creator>
 <dc:creator>Vasconcelos, Andr&#xe9;</dc:creator>
 <dc:creator>Guerreiro, S&#xe9;rgio</dc:creator>
 <dc:creator>Correia, Miguel</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:description>  Blockchain interoperability is emerging as one of the crucial features of
blockchain technology, but the knowledge necessary for achieving it is
fragmented. This fact makes it challenging for academics and the industry to
seamlessly achieve interoperability among blockchains.
  Given the novelty and potential of this new domain, we conduct a literature
review on blockchain interoperability, by collecting 262 papers, and 70 grey
literature documents, constituting a corpus of 332 documents. From those 332
documents, we systematically analyzed and discussed 80 documents, including
both peer-reviewed papers and grey literature.
  Our review classifies studies in three categories: Cryptocurrency-directed
interoperability approaches, Blockchain Engines, and Blockchain Connectors.
Each category is further divided into sub-categories based on defined criteria.
We discuss not only studies within each category and subcategory but also
across categories, providing a holistic overview of blockchain
interoperability, paving the way for systematic research in this domain. Our
findings show that blockchain interoperability has a much broader spectrum than
cryptocurrencies.
  The present survey leverages an interesting approach: we systematically
contacted the authors of grey literature papers and industry solutions to
obtain an updated view of their work. Finally, this paper discusses supporting
technologies, standards, use cases, open challenges, and provides several
future research directions.
</dc:description>
 <dc:description>Comment: For any comments or suggestions, contact rafael.belchior AT
  t\'ecnico.ulisboa.pt</dc:description>
 <dc:date>2020-05-28</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.14282</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.14344</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Chook -- A comprehensive suite for generating binary optimization
  problems with planted solutions</dc:title>
 <dc:creator>Perera, Dilina</dc:creator>
 <dc:creator>Akpabio, Inimfon</dc:creator>
 <dc:creator>Hamze, Firas</dc:creator>
 <dc:creator>Mandra, Salvatore</dc:creator>
 <dc:creator>Rose, Nathan</dc:creator>
 <dc:creator>Aramon, Maliheh</dc:creator>
 <dc:creator>Katzgraber, Helmut G.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  We present Chook, an open-source Python-based tool to generate discrete
optimization problems of tunable complexity with a priori known solutions.
Chook provides a cross-platform unified environment for solution planting using
a number of techniques, such as tile planting, Wishart planting, equation
planting, and deceptive cluster loop planting. Chook also incorporates planted
solutions for higher-order (beyond quadratic) binary optimization problems. The
support for various planting schemes and the tunable hardness allows the user
to generate problems with a wide range of complexity on different graph
topologies ranging from hypercubic lattices to fully-connected graphs.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures, 3 tables. Python source code under ancillary
  files (v 0.2 uses an updated k-local scheme)</dc:description>
 <dc:date>2020-05-28</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.14344</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.14405</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Not made for each other- Audio-Visual Dissonance-based Deepfake
  Detection and Localization</dc:title>
 <dc:creator>Chugh, Komal</dc:creator>
 <dc:creator>Gupta, Parul</dc:creator>
 <dc:creator>Dhall, Abhinav</dc:creator>
 <dc:creator>Subramanian, Ramanathan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  We propose detection of deepfake videos based on the dissimilarity between
the audio and visual modalities, termed as the Modality Dissonance Score (MDS).
We hypothesize that manipulation of either modality will lead to dis-harmony
between the two modalities, eg, loss of lip-sync, unnatural facial and lip
movements, etc. MDS is computed as an aggregate of dissimilarity scores between
audio and visual segments in a video. Discriminative features are learnt for
the audio and visual channels in a chunk-wise manner, employing the
cross-entropy loss for individual modalities, and a contrastive loss that
models inter-modality similarity. Extensive experiments on the DFDC and
DeepFake-TIMIT Datasets show that our approach outperforms the state-of-the-art
by up to 7%. We also demonstrate temporal forgery localization, and show how
our technique identifies the manipulated video segments.
</dc:description>
 <dc:date>2020-05-29</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.14405</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2005.14431</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fairness-Aware PageRank</dc:title>
 <dc:creator>Tsioutsiouliklis, Sotiris</dc:creator>
 <dc:creator>Pitoura, Evaggelia</dc:creator>
 <dc:creator>Tsaparas, Panayiotis</dc:creator>
 <dc:creator>Kleftakis, Ilias</dc:creator>
 <dc:creator>Mamoulis, Nikos</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>H.3.5</dc:subject>
 <dc:subject>I.6.4</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:description>  Algorithmic fairness has attracted significant attention in the past years.
Surprisingly, there is little work on fairness in networks. In this work, we
consider fairness for link analysis algorithms and in particular for the
celebrated PageRank algorithm. We provide definitions for fairness, and propose
two approaches for achieving fairness. The first modifies the jump vector of
the Pagerank algorithm to enfonce fairness, and the second imposes a fair
behavior per node. We also consider the problem of achieving fairness while
minimizing the utility loss with respect to the original algorithm. We present
experiments with real and synthetic graphs that examine the fairness of
Pagerank and demonstrate qualitatively and quantitatively the properties of our
algorithms.
</dc:description>
 <dc:date>2020-05-29</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2005.14431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.00089</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph-based calibration transfer</dc:title>
 <dc:creator>Nikzad-Langerodi, Ramin</dc:creator>
 <dc:creator>Sobieczky, Florian</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  The problem of transferring calibrations from a primary to a secondary
instrument, i.e. calibration transfer (CT), has been a matter of considerable
research in chemometrics over the past decades. Current state-of-the-art (SoA)
methods like (piecewise) direct standardization perform well when suitable
transfer standards are available. However, stable calibration standards that
share similar (spectral) features with the calibration samples are not always
available. Towards enabling CT with arbitrary calibration standards, we propose
a novel CT technique that employs manifold regularization of the partial least
squares (PLS) objective. In particular, our method enforces that calibration
standards, measured on primary and secondary instruments, have (nearly)
invariant projections in the latent variable space of the primary calibration
model. Thereby, our approach implicitly removes inter-device variation in the
predictive directions of X which is in contrast to most state-of-the-art
techniques that employ explicit pre-processing of the input data. We test our
approach on the well-known corn benchmark data set employing the NBS glass
standard spectra for instrument standardization and compare the results with
current SoA methods.
</dc:description>
 <dc:description>Comment: Preprint submitted to Journal of Chemometrics</dc:description>
 <dc:date>2020-05-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.00089</dc:identifier>
 <dc:identifier>doi:10.1002/cem.3319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.00661</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Submodular Bandit Problem Under Multiple Constraints</dc:title>
 <dc:creator>Takemori, Sho</dc:creator>
 <dc:creator>Sato, Masahiro</dc:creator>
 <dc:creator>Sonoda, Takashi</dc:creator>
 <dc:creator>Singh, Janmajay</dc:creator>
 <dc:creator>Ohkuma, Tomoko</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The linear submodular bandit problem was proposed to simultaneously address
diversified retrieval and online learning in a recommender system. If there is
no uncertainty, this problem is equivalent to a submodular maximization problem
under a cardinality constraint. However, in some situations, recommendation
lists should satisfy additional constraints such as budget constraints, other
than a cardinality constraint. Thus, motivated by diversified retrieval
considering budget constraints, we introduce a submodular bandit problem under
the intersection of $l$ knapsacks and a $k$-system constraint. Here $k$-system
constraints form a very general class of constraints including cardinality
constraints and the intersection of $k$ matroid constraints. To solve this
problem, we propose a non-greedy algorithm that adaptively focuses on a
standard or modified upper-confidence bound. We provide a high-probability
upper bound of an approximation regret, where the approximation ratio matches
that of a fast offline algorithm. Moreover, we perform experiments under
various combinations of constraints using a synthetic and two real-world
datasets and demonstrate that our proposed methods outperform the existing
baselines.
</dc:description>
 <dc:description>Comment: accepted at UAI 2020, minor mistakes fixed</dc:description>
 <dc:date>2020-05-31</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.00661</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.01411</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>D-ACC: Dynamic Adaptive Cruise Control for Highways with Ramps Based on
  Deep Q-Learning</dc:title>
 <dc:creator>Das, Lokesh</dc:creator>
 <dc:creator>Won, Myounggyu</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  An Adaptive Cruise Control (ACC) system allows vehicles to maintain a desired
headway distance to a preceding vehicle automatically. It is increasingly
adopted by commercial vehicles. Recent research demonstrates that the effective
use of ACC can improve the traffic flow through the adaptation of the headway
distance in response to the current traffic conditions. In this paper, we
demonstrate that a state-of-the-art intelligent ACC system performs poorly on
highways with ramps due to the limitation of the model-based approaches that do
not take into account appropriately the traffic dynamics on ramps in
determining the optimal headway distance. We then propose a dynamic adaptive
cruise control system (D-ACC) based on deep reinforcement learning that adapts
the headway distance effectively according to dynamically changing traffic
conditions for both the main road and ramp to optimize the traffic flow.
Extensive simulations are performed with a combination of a traffic simulator
(SUMO) and vehicle-to-everything communication (V2X) network simulator (Veins)
under numerous traffic scenarios. We demonstrate that D-ACC improves the
traffic flow by up to 70% compared with a state-of-the-art intelligent ACC
system in a highway segment with a ramp.
</dc:description>
 <dc:description>Comment: Accepted for Publication in IEEE International Conference on Robotics
  and Automation (ICRA) 2021</dc:description>
 <dc:date>2020-06-02</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.01411</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.02252</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interferobot: aligning an optical interferometer by a reinforcement
  learning agent</dc:title>
 <dc:creator>Sorokin, Dmitry</dc:creator>
 <dc:creator>Ulanov, Alexander</dc:creator>
 <dc:creator>Sazhina, Ekaterina</dc:creator>
 <dc:creator>Lvovsky, Alexander</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:description>  Limitations in acquiring training data restrict potential applications of
deep reinforcement learning (RL) methods to the training of real-world robots.
Here we train an RL agent to align a Mach-Zehnder interferometer, which is an
essential part of many optical experiments, based on images of interference
fringes acquired by a monocular camera. The agent is trained in a simulated
environment, without any hand-coded features or a priori information about the
physics, and subsequently transferred to a physical interferometer. Thanks to a
set of domain randomizations simulating uncertainties in physical measurements,
the agent successfully aligns this interferometer without any fine tuning,
achieving a performance level of a human expert.
</dc:description>
 <dc:description>Comment: Accepted at NeurIPS 2020 (spotlight presentation)</dc:description>
 <dc:date>2020-06-03</dc:date>
 <dc:date>2021-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.02252</dc:identifier>
 <dc:identifier>Advances in Neural Information Processing Systems 33, 13238-13248
  (2020)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.02634</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuation Newton methods with the residual trust-region time-stepping
  scheme for nonlinear equations</dc:title>
 <dc:creator>Luo, Xin-long</dc:creator>
 <dc:creator>Xiao, Hang</dc:creator>
 <dc:creator>Lv, Jia-hui</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  For nonlinear equations, the homotopy methods (continuation methods) are
popular in engineering fields since their convergence regions are large and
they are quite reliable to find a solution. The disadvantage of the classical
homotopy methods is that their computational time is heavy since they need to
solve many auxiliary nonlinear systems during the intermediate continuation
processes. In order to overcome this shortcoming, we consider the special
explicit continuation Newton method with the residual trust-region
time-stepping scheme for this problem. According to our numerical experiments,
the new method is more robust and faster to find the required solution of the
real-world problem than the traditional optimization method (the built-in
subroutine fsolve.m of the MATLAB environment) and the homotopy continuation
methods(HOMPACK90 and NAClab). Furthermore, we analyze the global convergence
and the local superlinear convergence of the new method.
</dc:description>
 <dc:date>2020-06-03</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.02634</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.03355</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prediction and Generalisation over Directed Actions by Grid Cells</dc:title>
 <dc:creator>Yu, Changmin</dc:creator>
 <dc:creator>Behrens, Timothy E. J.</dc:creator>
 <dc:creator>Burgess, Neil</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Knowing how the effects of directed actions generalise to new situations
(e.g. moving North, South, East and West, or turning left, right, etc.) is key
to rapid generalisation across new situations. Markovian tasks can be
characterised by a state space and a transition matrix and recent work has
proposed that neural grid codes provide an efficient representation of the
state space, as eigenvectors of a transition matrix reflecting diffusion across
states, that allows efficient prediction of future state distributions. Here we
extend the eigenbasis prediction model, utilising tools from Fourier analysis,
to prediction over arbitrary translation-invariant directed transition
structures (i.e. displacement and diffusion), showing that a single set of
eigenvectors can support predictions over arbitrary directed actions via
action-specific eigenvalues. We show how to define a &quot;sense of direction&quot; to
combine actions to reach a target state (ignoring task-specific deviations from
translation-invariance), and demonstrate that adding the Fourier
representations to a deep Q network aids policy learning in continuous control
tasks. We show the equivalence between the generalised prediction framework and
traditional models of grid cell firing driven by self-motion to perform path
integration, either using oscillatory interference (via Fourier components as
velocity-controlled oscillators) or continuous attractor networks (via analysis
of the update dynamics). We thus provide a unifying framework for the role of
the grid system in predictive planning, sense of direction and path
integration: supporting generalisable inference over directed actions across
different tasks.
</dc:description>
 <dc:description>Comment: In Proceedings of ICLR 2021</dc:description>
 <dc:date>2020-06-05</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.03355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.03514</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tertiary Regulation of Cascaded Run-of-the-River Hydropower in the
  Islanded Renewable Power System Considering Multi-Timescale Dynamics</dc:title>
 <dc:creator>Qiu, Yiwei</dc:creator>
 <dc:creator>Lin, Jin</dc:creator>
 <dc:creator>Liu, Feng</dc:creator>
 <dc:creator>Dai, Ningyi</dc:creator>
 <dc:creator>Song, Yonghua</dc:creator>
 <dc:creator>Chen, Gang</dc:creator>
 <dc:creator>Ding, Lijie</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  To enable power supply in rural areas and to exploit clean energy, fully
renewable power systems consisting of cascaded run-of-the-river hydropower and
volatile energies such as pv and wind are built around the world. In islanded
operation mode, the primary and secondary frequency control, i.e., hydro
governors and automatic generation control (AGC), are responsible for the
frequency stability. However, due to limited water storage capacity of
run-of-the-river hydropower and river dynamics constraints, without
coordination between the cascaded plants, the traditional AGC with fixed
participation factors cannot fully exploit the adjustability of cascaded
hydropower. When imbalances between the volatile energy and load occur, load
shedding can be inevitable. To address this issue, this paper proposes a
coordinated tertiary control approach by jointly considering power system
dynamics and the river dynamics that couples the cascaded hydropower plants.
The timescales of the power system and river dynamics are very different. To
unify the multi-timescale dynamics to establish a model predictive controller
that coordinates the cascaded plants, the relation between AGC parameters and
turbine discharge over a time interval is approximated by a data-based
second-order polynomial surrogate model. The cascaded plants are coordinated by
optimising AGC participation factors in a receding-horizon manner, and load
shedding is minimised. Simulation of a real-life system with real-time pv data
collected on site shows the proposed method significantly reduces load loss
under pv volatility.
</dc:description>
 <dc:description>Comment: Accepted by IET Renewable Power Generation; 13 pages</dc:description>
 <dc:date>2020-06-05</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.03514</dc:identifier>
 <dc:identifier>doi:10.1049/rpg2.12146</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.03652</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Filtered Inner Product Projection for Crosslingual Embedding Alignment</dc:title>
 <dc:creator>Sachidananda, Vin</dc:creator>
 <dc:creator>Yang, Ziyi</dc:creator>
 <dc:creator>Zhu, Chenguang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Due to widespread interest in machine translation and transfer learning,
there are numerous algorithms for mapping multiple embeddings to a shared
representation space. Recently, these algorithms have been studied in the
setting of bilingual dictionary induction where one seeks to align the
embeddings of a source and a target language such that translated word pairs
lie close to one another in a common representation space. In this paper, we
propose a method, Filtered Inner Product Projection (FIPP), for mapping
embeddings to a common representation space and evaluate FIPP in the context of
bilingual dictionary induction. As semantic shifts are pervasive across
languages and domains, FIPP first identifies the common geometric structure in
both embeddings and then, only on the common structure, aligns the Gram
matrices of these embeddings. Unlike previous approaches, FIPP is applicable
even when the source and target embeddings are of differing dimensionalities.
We show that our approach outperforms existing methods on the MUSE dataset for
various language pairs. Furthermore, FIPP provides computational benefits both
in ease of implementation and scalability.
</dc:description>
 <dc:description>Comment: ICLR 2021</dc:description>
 <dc:date>2020-06-05</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.03652</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.03820</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attention-Based Deep Learning Framework for Human Activity Recognition
  with User Adaptation</dc:title>
 <dc:creator>Buffelli, Davide</dc:creator>
 <dc:creator>Vandin, Fabio</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Sensor-based human activity recognition (HAR) requires to predict the action
of a person based on sensor-generated time series data. HAR has attracted major
interest in the past few years, thanks to the large number of applications
enabled by modern ubiquitous computing devices. While several techniques based
on hand-crafted feature engineering have been proposed, the current
state-of-the-art is represented by deep learning architectures that
automatically obtain high level representations and that use recurrent neural
networks (RNNs) to extract temporal dependencies in the input. RNNs have
several limitations, in particular in dealing with long-term dependencies. We
propose a novel deep learning framework, \algname, based on a purely
attention-based mechanism, that overcomes the limitations of the
state-of-the-art. We show that our proposed attention-based architecture is
considerably more powerful than previous approaches, with an average increment,
of more than $7\%$ on the F1 score over the previous best performing model.
Furthermore, we consider the problem of personalizing HAR deep learning models,
which is of great importance in several applications. We propose a simple and
effective transfer-learning based strategy to adapt a model to a specific user,
providing an average increment of $6\%$ on the F1 score on the predictions for
that user. Our extensive experimental evaluation proves the significantly
superior capabilities of our proposed framework over the current
state-of-the-art and the effectiveness of our user adaptation technique.
</dc:description>
 <dc:description>Comment: Accepted for publication on the IEEE Sensors Journal</dc:description>
 <dc:date>2020-06-06</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.03820</dc:identifier>
 <dc:identifier>doi:10.1109/JSEN.2021.3067690</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.04260</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formal synthesis of closed-form sampled-data controllers for nonlinear
  continuous-time systems under STL specifications</dc:title>
 <dc:creator>Verdier, Cees F.</dc:creator>
 <dc:creator>Kochdumper, Niklas</dc:creator>
 <dc:creator>Althoff, Matthias</dc:creator>
 <dc:creator>Mazo Jr, Manuel</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  We propose a counterexample-guided inductive synthesis framework for the
formal synthesis of closed-form sampled-data controllers for nonlinear systems
to meet STL specifications over finite-time trajectories. Rather than stating
the STL specification for a single initial condition, we consider an (infinite
and bounded) set of initial conditions. Candidate solutions are proposed using
genetic programming, which evolves controllers based on a finite number of
simulations. Subsequently, the best candidate is verified using reachability
analysis; if the candidate solution does not satisfy the specification, an
initial condition violating the specification is extracted as a counterexample.
Based on this counterexample, candidate solutions are refined until eventually
a solution is found (or a user-specified number of iterations is met). The
resulting sampled-data controller is expressed as a closed-form expression,
enabling both interpretability and the implementation in embedded hardware with
limited memory and computation power. The effectiveness of our approach is
demonstrated for multiple systems.
</dc:description>
 <dc:description>Comment: submitted to Automatica</dc:description>
 <dc:date>2020-06-07</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.04260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.04342</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Sensor Node Selection and State Estimation for Nonlinear Networks
  and Systems</dc:title>
 <dc:creator>Haber, Aleksandar</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  State estimation and sensor selection problems for nonlinear networks and
systems are ubiquitous problems that are important for the control, monitoring,
analysis, and prediction of a large number of engineered and physical systems.
Sensor selection problems are extensively studied for linear networks. However,
less attention has been dedicated to networks with nonlinear dynamics.
Furthermore, widely used sensor selection methods relying on structural
(graph-based) observability approaches might produce far from optimal results
when applied to nonlinear network dynamics. In addition, state estimation and
sensor selection problems are often treated separately, and this might decrease
the overall estimation performance. To address these challenges, we develop a
novel methodology for selecting sensor nodes for networks with nonlinear
dynamics. Our main idea is to incorporate the sensor selection problem into an
initial state estimation problem. The resulting mixed-integer nonlinear
optimization problem is approximately solved using three methods. The good
numerical performance of our approach is demonstrated by testing the algorithms
on prototypical Duffing oscillator, associative memory, and chemical reaction
networks. The developed codes are available online.
</dc:description>
 <dc:description>Comment: Paper accepted to IEEE Transactions on Network Science and
  Engineering, 19 pages, 7 figures</dc:description>
 <dc:date>2020-06-07</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.04342</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.04528</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation of Similarity-based Explanations</dc:title>
 <dc:creator>Hanawa, Kazuaki</dc:creator>
 <dc:creator>Yokoi, Sho</dc:creator>
 <dc:creator>Hara, Satoshi</dc:creator>
 <dc:creator>Inui, Kentaro</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Explaining the predictions made by complex machine learning models helps
users to understand and accept the predicted outputs with confidence. One
promising way is to use similarity-based explanation that provides similar
instances as evidence to support model predictions. Several relevance metrics
are used for this purpose. In this study, we investigated relevance metrics
that can provide reasonable explanations to users. Specifically, we adopted
three tests to evaluate whether the relevance metrics satisfy the minimal
requirements for similarity-based explanation. Our experiments revealed that
the cosine similarity of the gradients of the loss performs best, which would
be a recommended choice in practice. In addition, we showed that some metrics
perform poorly in our tests and analyzed the reasons of their failure. We
expect our insights to help practitioners in selecting appropriate relevance
metrics and also aid further researches for designing better relevance metrics
for explanations.
</dc:description>
 <dc:description>Comment: ICLR 2021</dc:description>
 <dc:date>2020-06-08</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.04528</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.04806</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SoK: Attacks on Industrial Control Logic and Formal Verification-Based
  Defenses</dc:title>
 <dc:creator>Sun, Ruimin</dc:creator>
 <dc:creator>Mera, Alejandro</dc:creator>
 <dc:creator>Lu, Long</dc:creator>
 <dc:creator>Choffnes, David</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>A.1</dc:subject>
 <dc:subject>C.3</dc:subject>
 <dc:description>  Programmable Logic Controllers (PLCs) play a critical role in the industrial
control systems. Vulnerabilities in PLC programs might lead to attacks causing
devastating consequences to the critical infrastructure, as shown in Stuxnet
and similar attacks. In recent years, we have seen an exponential increase in
vulnerabilities reported for PLC control logic. Looking back on past research,
we found extensive studies explored control logic modification attacks, as well
as formal verification-based security solutions. We performed systematization
on these studies, and found attacks that can compromise a full chain of control
and evade detection. However, the majority of the formal verification research
investigated ad-hoc techniques targeting PLC programs. We discovered challenges
in every aspect of formal verification, rising from (1) the ever-expanding
attack surface from evolved system design, (2) the real-time constraint during
the program execution, and (3) the barrier in security evaluation given
proprietary and vendor-specific dependencies on different techniques. Based on
the knowledge systematization, we provide a set of recommendations for future
research directions, and we highlight the need of defending security issues
besides safety issues.
</dc:description>
 <dc:description>Comment: 18 pages w/ ref, Sok, PLC, ICS, CPS, attack, formal verification</dc:description>
 <dc:date>2020-06-09</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.04806</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.04884</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Stability of Fine-tuning BERT: Misconceptions, Explanations, and
  Strong Baselines</dc:title>
 <dc:creator>Mosbach, Marius</dc:creator>
 <dc:creator>Andriushchenko, Maksym</dc:creator>
 <dc:creator>Klakow, Dietrich</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Fine-tuning pre-trained transformer-based language models such as BERT has
become a common practice dominating leaderboards across various NLP benchmarks.
Despite the strong empirical performance of fine-tuned models, fine-tuning is
an unstable process: training the same model with multiple random seeds can
result in a large variance of the task performance. Previous literature (Devlin
et al., 2019; Lee et al., 2020; Dodge et al., 2020) identified two potential
reasons for the observed instability: catastrophic forgetting and small size of
the fine-tuning datasets. In this paper, we show that both hypotheses fail to
explain the fine-tuning instability. We analyze BERT, RoBERTa, and ALBERT,
fine-tuned on commonly used datasets from the GLUE benchmark, and show that the
observed instability is caused by optimization difficulties that lead to
vanishing gradients. Additionally, we show that the remaining variance of the
downstream task performance can be attributed to differences in generalization
where fine-tuned models with the same training loss exhibit noticeably
different test performance. Based on our analysis, we present a simple but
strong baseline that makes fine-tuning BERT-based models significantly more
stable than the previously proposed approaches. Code to reproduce our results
is available online: https://github.com/uds-lsv/bert-stable-fine-tuning.
</dc:description>
 <dc:description>Comment: ICLR 2021</dc:description>
 <dc:date>2020-06-08</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.04884</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.05187</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stereo RGB and Deeper LIDAR Based Network for 3D Object Detection</dc:title>
 <dc:creator>He, Qingdong</dc:creator>
 <dc:creator>Wang, Zhengning</dc:creator>
 <dc:creator>Zeng, Hao</dc:creator>
 <dc:creator>Liu, Yijun</dc:creator>
 <dc:creator>Liu, Shuaicheng</dc:creator>
 <dc:creator>Zeng, Bing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  3D object detection has become an emerging task in autonomous driving
scenarios. Previous works process 3D point clouds using either projection-based
or voxel-based models. However, both approaches contain some drawbacks. The
voxel-based methods lack semantic information, while the projection-based
methods suffer from numerous spatial information loss when projected to
different views. In this paper, we propose the Stereo RGB and Deeper LIDAR
(SRDL) framework which can utilize semantic and spatial information
simultaneously such that the performance of network for 3D object detection can
be improved naturally. Specifically, the network generates candidate boxes from
stereo pairs and combines different region-wise features using a deep fusion
scheme. The stereo strategy offers more information for prediction compared
with prior works. Then, several local and global feature extractors are stacked
in the segmentation module to capture richer deep semantic geometric features
from point clouds. After aligning the interior points with fused features, the
proposed network refines the prediction in a more accurate manner and encodes
the whole box in a novel compact method. The decent experimental results on the
challenging KITTI detection benchmark demonstrate the effectiveness of
utilizing both stereo images and point clouds for 3D object detection.
</dc:description>
 <dc:date>2020-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.05187</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.05301</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>VAEs in the Presence of Missing Data</dc:title>
 <dc:creator>Collier, Mark</dc:creator>
 <dc:creator>Nazabal, Alfredo</dc:creator>
 <dc:creator>Williams, Christopher K. I.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Real world datasets often contain entries with missing elements e.g. in a
medical dataset, a patient is unlikely to have taken all possible diagnostic
tests. Variational Autoencoders (VAEs) are popular generative models often used
for unsupervised learning. Despite their widespread use it is unclear how best
to apply VAEs to datasets with missing data. We develop a novel latent variable
model of a corruption process which generates missing data, and derive a
corresponding tractable evidence lower bound (ELBO). Our model is
straightforward to implement, can handle both missing completely at random
(MCAR) and missing not at random (MNAR) data, scales to high dimensional inputs
and gives both the VAE encoder and decoder principled access to indicator
variables for whether a data element is missing or not. On the MNIST and SVHN
datasets we demonstrate improved marginal log-likelihood of observed data and
better missing data imputation, compared to existing approaches.
</dc:description>
 <dc:description>Comment: Accepted to ICML Workshop on the Art of Learning with Missing Values
  (Artemiss), 17 July 2020</dc:description>
 <dc:date>2020-06-09</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.05301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.05576</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-supervised Learning from a Multi-view Perspective</dc:title>
 <dc:creator>Tsai, Yao-Hung Hubert</dc:creator>
 <dc:creator>Wu, Yue</dc:creator>
 <dc:creator>Salakhutdinov, Ruslan</dc:creator>
 <dc:creator>Morency, Louis-Philippe</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  As a subset of unsupervised representation learning, self-supervised
representation learning adopts self-defined signals as supervision and uses the
learned representation for downstream tasks, such as object detection and image
captioning. Many proposed approaches for self-supervised learning follow
naturally a multi-view perspective, where the input (e.g., original images) and
the self-supervised signals (e.g., augmented images) can be seen as two
redundant views of the data. Building from this multi-view perspective, this
paper provides an information-theoretical framework to better understand the
properties that encourage successful self-supervised learning. Specifically, we
demonstrate that self-supervised learned representations can extract
task-relevant information and discard task-irrelevant information. Our
theoretical framework paves the way to a larger space of self-supervised
learning objective design. In particular, we propose a composite objective that
bridges the gap between prior contrastive and predictive learning objectives,
and introduce an additional objective term to discard task-irrelevant
information. To verify our analysis, we conduct controlled experiments to
evaluate the impact of the composite objectives. We also explore our
framework's empirical generalization beyond the multi-view perspective, where
the cross-view redundancy may not be clearly observed.
</dc:description>
 <dc:date>2020-06-09</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.05576</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.05608</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simultaneous Decision Making for Stochastic Multi-echelon Inventory
  Optimization with Deep Neural Networks as Decision Makers</dc:title>
 <dc:creator>Pirhooshyaran, Mohammad</dc:creator>
 <dc:creator>Snyder, Lawrence V.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a framework that uses deep neural networks (DNN) to optimize
inventory decisions in complex multi-echelon supply chains. We first introduce
pairwise modeling of general stochastic multi-echelon inventory optimization
(SMEIO). Then, we present a framework which uses DNN agents to directly
determine order-up-to levels between any adjacent pair of nodes in the supply
chain. Our model considers a finite horizon and accounts for the initial
inventory conditions. Our method is suitable for a wide variety of supply chain
networks, including general topologies that may contain both assembly and
distribution nodes, and systems with nonlinear cost structures. We first
numerically demonstrate the effectiveness of the method by showing that its
solutions are close to the optimal solutions for single-node and serial supply
chain networks, for which exact methods are available. Then, we investigate
more general supply chain networks and find that the proposed method performs
better in terms of both objective function values and the number of
interactions with the environment compared to alternate methods.
</dc:description>
 <dc:date>2020-06-09</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.05608</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.06038</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Map3D: Registration Based Multi-Object Tracking on 3D Serial Whole Slide
  Images</dc:title>
 <dc:creator>Deng, Ruining</dc:creator>
 <dc:creator>Yang, Haichun</dc:creator>
 <dc:creator>Jha, Aadarsh</dc:creator>
 <dc:creator>Lu, Yuzhe</dc:creator>
 <dc:creator>Chu, Peng</dc:creator>
 <dc:creator>Fogo, Agnes B.</dc:creator>
 <dc:creator>Huo, Yuankai</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  There has been a long pursuit for precise and reproducible glomerular
quantification on renal pathology to leverage both research and practice. When
digitizing the biopsy tissue samples using whole slide imaging (WSI), a set of
serial sections from the same tissue can be acquired as a stack of images,
similar to frames in a video. In radiology, the stack of images (e.g., computed
tomography) are naturally used to provide 3D context for organs, tissues, and
tumors. In pathology, it is appealing to do a similar 3D assessment. However,
the 3D identification and association of large-scale glomeruli on renal
pathology is challenging due to large tissue deformation, missing tissues, and
artifacts from WSI. In this paper, we propose a novel Multi-object Association
for Pathology in 3D (Map3D) method for automatically identifying and
associating large-scale cross-sections of 3D objects from routine serial
sectioning and WSI. The innovations of the Map3D method are three-fold: (1) the
large-scale glomerular association is formed as a new multi-object tracking
(MOT) perspective; (2) the quality-aware whole series registration is proposed
to not only provide affinity estimation but also offer automatic kidney-wise
quality assurance (QA) for registration; (3) a dual-path association method is
proposed to tackle the large deformation, missing tissues, and artifacts during
tracking. To the best of our knowledge, the Map3D method is the first approach
that enables automatic and large-scale glomerular association across 3D serial
sectioning using WSI. Our proposed method Map3D achieved MOTA= 44.6, which is
12.1% higher than the non deep learning benchmarks.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Transactions on Medical Imaging</dc:description>
 <dc:date>2020-06-10</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.06038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.06462</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning advanced mathematical computations from examples</dc:title>
 <dc:creator>Charton, Fran&#xe7;ois</dc:creator>
 <dc:creator>Hayat, Amaury</dc:creator>
 <dc:creator>Lample, Guillaume</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Using transformers over large generated datasets, we train models to learn
mathematical properties of differential systems, such as local stability,
behavior at infinity and controllability. We achieve near perfect prediction of
qualitative characteristics, and good approximations of numerical features of
the system. This demonstrates that neural networks can learn to perform complex
computations, grounded in advanced theory, from examples, without built-in
mathematical knowledge.
</dc:description>
 <dc:date>2020-06-11</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.06462</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.06527</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MMA Regularization: Decorrelating Weights of Neural Networks by
  Maximizing the Minimal Angles</dc:title>
 <dc:creator>Wang, Zhennan</dc:creator>
 <dc:creator>Xiang, Canqun</dc:creator>
 <dc:creator>Zou, Wenbin</dc:creator>
 <dc:creator>Xu, Chen</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The strong correlation between neurons or filters can significantly weaken
the generalization ability of neural networks. Inspired by the well-known
Tammes problem, we propose a novel diversity regularization method to address
this issue, which makes the normalized weight vectors of neurons or filters
distributed on a hypersphere as uniformly as possible, through maximizing the
minimal pairwise angles (MMA). This method can easily exert its effect by
plugging the MMA regularization term into the loss function with negligible
computational overhead. The MMA regularization is simple, efficient, and
effective. Therefore, it can be used as a basic regularization method in neural
network training. Extensive experiments demonstrate that MMA regularization is
able to enhance the generalization ability of various modern models and
achieves considerable performance improvements on CIFAR100 and TinyImageNet
datasets. In addition, experiments on face verification show that MMA
regularization is also effective for feature learning. Code is available at:
https://github.com/wznpub/MMA_Regularization.
</dc:description>
 <dc:description>Comment: NeurIPS2020</dc:description>
 <dc:date>2020-06-06</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.06527</dc:identifier>
 <dc:identifier>https://proceedings.neurips.cc/paper/2020/file/dcd2f3f312b6705fb06f4f9f1b55b55c-Paper.pdf</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.06877</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Precision Extraction of Emerging Concepts from Scientific
  Literature</dc:title>
 <dc:creator>King, Daniel</dc:creator>
 <dc:creator>Downey, Doug</dc:creator>
 <dc:creator>Weld, Daniel S.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Identification of new concepts in scientific literature can help power
faceted search, scientific trend analysis, knowledge-base construction, and
more, but current methods are lacking. Manual identification cannot keep up
with the torrent of new publications, while the precision of existing automatic
techniques is too low for many applications. We present an unsupervised concept
extraction method for scientific literature that achieves much higher precision
than previous work. Our approach relies on a simple but novel intuition: each
scientific concept is likely to be introduced or popularized by a single paper
that is disproportionately cited by subsequent papers mentioning the concept.
From a corpus of computer science papers on arXiv, we find that our method
achieves a Precision@1000 of 99%, compared to 86% for prior work, and a
substantially better precision-yield trade-off across the top 15,000
extractions. To stimulate research in this area, we release our code and data
(https://github.com/allenai/ForeCite).
</dc:description>
 <dc:description>Comment: Accepted to SIGIR 2020</dc:description>
 <dc:date>2020-06-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.06877</dc:identifier>
 <dc:identifier>Proceedings of the 43rd International ACM SIGIR Conference on
  Research and Development in Information Retrieval (2020) 1549-1552</dc:identifier>
 <dc:identifier>doi:10.1145/3397271.3401235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.07202</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unified analysis of discontinuous Galerkin and $C^0$-interior penalty
  finite element methods for Hamilton--Jacobi--Bellman and Isaacs equations</dc:title>
 <dc:creator>Kawecki, Ellya L.</dc:creator>
 <dc:creator>Smears, Iain</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We provide a unified analysis of a posteriori and a priori error bounds for a
broad class of discontinuous Galerkin and $C^0$-IP finite element
approximations of fully nonlinear second-order elliptic
Hamilton--Jacobi--Bellman and Isaacs equations with Cordes coefficients. We
prove the existence and uniqueness of strong solutions in $H^2$ of Isaacs
equations with Cordes coefficients posed on bounded convex domains. We then
show the reliability and efficiency of computable residual-based error
estimators for piecewise polynomial approximations on simplicial meshes in two
and three space dimensions. We introduce an abstract framework for the a priori
error analysis of a broad family of numerical methods and prove the
quasi-optimality of discrete approximations under three key conditions of
Lipschitz continuity, discrete consistency and strong monotonicity of the
numerical method. Under these conditions, we also prove convergence of the
numerical approximations in the small-mesh limit for minimal regularity
solutions. We then show that the framework applies to a range of existing
numerical methods from the literature, as well as some original variants. A key
ingredient of our results is an original analysis of the stabilization terms.
As a corollary, we also obtain a generalization of the discrete
Miranda--Talenti inequality to piecewise polynomial vector fields.
</dc:description>
 <dc:date>2020-06-12</dc:date>
 <dc:date>2020-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.07202</dc:identifier>
 <dc:identifier>ESAIM Mathematical Modelling and Numerical Analysis, 55(2),
  449-478, 2021</dc:identifier>
 <dc:identifier>doi:10.1051/m2an/2020081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.07242</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ensemble Distillation for Robust Model Fusion in Federated Learning</dc:title>
 <dc:creator>Lin, Tao</dc:creator>
 <dc:creator>Kong, Lingjing</dc:creator>
 <dc:creator>Stich, Sebastian U.</dc:creator>
 <dc:creator>Jaggi, Martin</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Federated Learning (FL) is a machine learning setting where many devices
collaboratively train a machine learning model while keeping the training data
decentralized. In most of the current training schemes the central model is
refined by averaging the parameters of the server model and the updated
parameters from the client side. However, directly averaging model parameters
is only possible if all models have the same structure and size, which could be
a restrictive constraint in many scenarios.
  In this work we investigate more powerful and more flexible aggregation
schemes for FL. Specifically, we propose ensemble distillation for model
fusion, i.e. training the central classifier through unlabeled data on the
outputs of the models from the clients. This knowledge distillation technique
mitigates privacy risk and cost to the same extent as the baseline FL
algorithms, but allows flexible aggregation over heterogeneous client models
that can differ e.g. in size, numerical precision or structure. We show in
extensive empirical experiments on various CV/NLP datasets (CIFAR-10/100,
ImageNet, AG News, SST2) and settings (heterogeneous models/data) that the
server model can be trained much faster, requiring fewer communication rounds
than any existing FL technique so far.
</dc:description>
 <dc:date>2020-06-12</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.07242</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.07702</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-Rank Factorization for Rank Minimization with Nonconvex Regularizers</dc:title>
 <dc:creator>Sagan, April</dc:creator>
 <dc:creator>Mitchell, John E.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Rank minimization is of interest in machine learning applications such as
recommender systems and robust principal component analysis. Minimizing the
convex relaxation to the rank minimization problem, the nuclear norm, is an
effective technique to solve the problem with strong performance guarantees.
However, nonconvex relaxations have less estimation bias than the nuclear norm
and can more accurately reduce the effect of noise on the measurements.
  We develop efficient algorithms based on iteratively reweighted nuclear norm
schemes, while also utilizing the low rank factorization for semidefinite
programs put forth by Burer and Monteiro. We prove convergence and
computationally show the advantages over convex relaxations and alternating
minimization methods. Additionally, the computational complexity of each
iteration of our algorithm is on par with other state of the art algorithms,
allowing us to quickly find solutions to the rank minimization problem for
large matrices.
</dc:description>
 <dc:date>2020-06-13</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.07702</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.08969</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High Dimensional Model Explanations: an Axiomatic Approach</dc:title>
 <dc:creator>Patel, Neel</dc:creator>
 <dc:creator>Strobel, Martin</dc:creator>
 <dc:creator>Zick, Yair</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Complex black-box machine learning models are regularly used in critical
decision-making domains. This has given rise to several calls for algorithmic
explainability. Many explanation algorithms proposed in literature assign
importance to each feature individually. However, such explanations fail to
capture the joint effects of sets of features. Indeed, few works so far
formally analyze high-dimensional model explanations. In this paper, we propose
a novel high dimension model explanation method that captures the joint effect
of feature subsets.
  We propose a new axiomatization for a generalization of the Banzhaf index;
our method can also be thought of as an approximation of a black-box model by a
higher-order polynomial. In other words, this work justifies the use of the
generalized Banzhaf index as a model explanation by showing that it uniquely
satisfies a set of natural desiderata and that it is the optimal local
approximation of a black-box model.
  Our empirical evaluation of our measure highlights how it manages to capture
desirable behavior, whereas other measures that do not satisfy our axioms
behave in an unpredictable manner.
</dc:description>
 <dc:description>Comment: 31 pages, 10 Figures, 2 Tables</dc:description>
 <dc:date>2020-06-16</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.08969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.09081</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Progressive Skeletonization: Trimming more fat from a network at
  initialization</dc:title>
 <dc:creator>de Jorge, Pau</dc:creator>
 <dc:creator>Sanyal, Amartya</dc:creator>
 <dc:creator>Behl, Harkirat S.</dc:creator>
 <dc:creator>Torr, Philip H. S.</dc:creator>
 <dc:creator>Rogez, Gregory</dc:creator>
 <dc:creator>Dokania, Puneet K.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Recent studies have shown that skeletonization (pruning parameters) of
networks \textit{at initialization} provides all the practical benefits of
sparsity both at inference and training time, while only marginally degrading
their performance. However, we observe that beyond a certain level of sparsity
(approx $95\%$), these approaches fail to preserve the network performance, and
to our surprise, in many cases perform even worse than trivial random pruning.
To this end, we propose an objective to find a skeletonized network with
maximum {\em foresight connection sensitivity} (FORCE) whereby the
trainability, in terms of connection sensitivity, of a pruned network is taken
into consideration. We then propose two approximate procedures to maximize our
objective (1) Iterative SNIP: allows parameters that were unimportant at
earlier stages of skeletonization to become important at later stages; and (2)
FORCE: iterative process that allows exploration by allowing already pruned
parameters to resurrect at later stages of skeletonization. Empirical analyses
on a large suite of experiments show that our approach, while providing at
least as good a performance as other recent approaches on moderate pruning
levels, provides remarkably improved performance on higher pruning levels
(could remove up to $99.5\%$ parameters while keeping the networks trainable).
Code can be found in https://github.com/naver/force.
</dc:description>
 <dc:date>2020-06-16</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.09081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.09107</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning from Demonstration with Weakly Supervised Disentanglement</dc:title>
 <dc:creator>Hristov, Yordan</dc:creator>
 <dc:creator>Ramamoorthy, Subramanian</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Robotic manipulation tasks, such as wiping with a soft sponge, require
control from multiple rich sensory modalities. Human-robot interaction, aimed
at teaching robots, is difficult in this setting as there is potential for
mismatch between human and machine comprehension of the rich data streams. We
treat the task of interpretable learning from demonstration as an optimisation
problem over a probabilistic generative model. To account for the
high-dimensionality of the data, a high-capacity neural network is chosen to
represent the model. The latent variables in this model are explicitly aligned
with high-level notions and concepts that are manifested in a set of
demonstrations. We show that such alignment is best achieved through the use of
labels from the end user, in an appropriately restricted vocabulary, in
contrast to the conventional approach of the designer picking a prior over the
latent variables. Our approach is evaluated in the context of two table-top
robot manipulation tasks performed by a PR2 robot -- that of dabbing liquids
with a sponge (forcefully pressing a sponge and moving it along a surface) and
pouring between different containers. The robot provides visual information,
arm joint positions and arm joint efforts. We have made videos of the tasks and
data available - see supplementary materials at:
https://sites.google.com/view/weak-label-lfd.
</dc:description>
 <dc:description>Comment: 18 pages, 16 figures, accepted at the International Conference on
  Learning Representations (ICLR) 2021, supplementary website at
  https://sites.google.com/view/weak-label-lfd</dc:description>
 <dc:date>2020-06-16</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.09107</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.09265</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IsarStep: a Benchmark for High-level Mathematical Reasoning</dc:title>
 <dc:creator>Li, Wenda</dc:creator>
 <dc:creator>Yu, Lei</dc:creator>
 <dc:creator>Wu, Yuhuai</dc:creator>
 <dc:creator>Paulson, Lawrence C.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>I.2.2</dc:subject>
 <dc:description>  A well-defined benchmark is essential for measuring and accelerating research
progress of machine learning models. In this paper, we present a benchmark for
high-level mathematical reasoning and study the reasoning capabilities of
neural sequence-to-sequence models. We build a non-synthetic dataset from the
largest repository of proofs written by human experts in a theorem prover. The
dataset has a broad coverage of undergraduate and research-level mathematical
and computer science theorems. In our defined task, a model is required to fill
in a missing intermediate proposition given surrounding proofs. This task
provides a starting point for the long-term goal of having machines generate
human-readable proofs automatically. Our experiments and analysis reveal that
while the task is challenging, neural models can capture non-trivial
mathematical reasoning. We further design a hierarchical transformer that
outperforms the transformer baseline.
</dc:description>
 <dc:description>Comment: 9 pages, published at ICLR 2021</dc:description>
 <dc:date>2020-06-13</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.09265</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.09332</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What's in the Image? Explorable Decoding of Compressed Images</dc:title>
 <dc:creator>Bahat, Yuval</dc:creator>
 <dc:creator>Michaeli, Tomer</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The ever-growing amounts of visual contents captured on a daily basis
necessitate the use of lossy compression methods in order to save storage space
and transmission bandwidth. While extensive research efforts are devoted to
improving compression techniques, every method inevitably discards information.
Especially at low bit rates, this information often corresponds to semantically
meaningful visual cues, so that decompression involves significant ambiguity.
In spite of this fact, existing decompression algorithms typically produce only
a single output, and do not allow the viewer to explore the set of images that
map to the given compressed code. In this work we propose the first image
decompression method to facilitate user-exploration of the diverse set of
natural images that could have given rise to the compressed input code, thus
granting users the ability to determine what could and what could not have been
there in the original scene. Specifically, we develop a novel deep-network
based decoder architecture for the ubiquitous JPEG standard, which allows
traversing the set of decompressed images that are consistent with the
compressed JPEG file. To allow for simple user interaction, we develop a
graphical user interface comprising several intuitive exploration tools,
including an automatic tool for examining specific solutions of interest. We
exemplify our framework on graphical, medical and forensic use cases,
demonstrating its wide range of potential applications.
</dc:description>
 <dc:date>2020-06-16</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.09332</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.09361</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gradient Free Minimax Optimization: Variance Reduction and Faster
  Convergence</dc:title>
 <dc:creator>Xu, Tengyu</dc:creator>
 <dc:creator>Wang, Zhe</dc:creator>
 <dc:creator>Liang, Yingbin</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Many important machine learning applications amount to solving minimax
optimization problems, and in many cases there is no access to the gradient
information, but only the function values. In this paper, we focus on such a
gradient-free setting, and consider the nonconvex-strongly-concave minimax
stochastic optimization problem. In the literature, various zeroth-order (i.e.,
gradient-free) minimax methods have been proposed, but none of them achieve the
potentially feasible computational complexity of $\mathcal{O}(\epsilon^{-3})$
suggested by the stochastic nonconvex minimization theorem. In this paper, we
adopt the variance reduction technique to design a novel zeroth-order variance
reduced gradient descent ascent (ZO-VRGDA) algorithm. We show that the ZO-VRGDA
algorithm achieves the best known query complexity of $\mathcal{O}(\kappa(d_1 +
d_2)\epsilon^{-3})$, which outperforms all previous complexity bound by orders
of magnitude, where $d_1$ and $d_2$ denote the dimensions of the optimization
variables and $\kappa$ denotes the condition number. In particular, with a new
analysis technique that we develop, our result does not rely on a diminishing
or accuracy-dependent stepsize usually required in the existing methods. To our
best knowledge, this is the first study of zeroth-order minimax optimization
with variance reduction. Experimental results on the black-box distributional
robust optimization problem demonstrates the advantageous performance of our
new algorithm.
</dc:description>
 <dc:description>Comment: This is an updated version to replace the previous arXiv post titled
  &quot;Enhanced First and Zeroth Order Variance Reduced Algorithms for Min-Max
  Optimization&quot; on 17 Jun, 2020</dc:description>
 <dc:date>2020-06-16</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.09361</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.09475</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SPEED: Secure, PrivatE, and Efficient Deep learning</dc:title>
 <dc:creator>S&#xe9;bert, Arnaud Grivet</dc:creator>
 <dc:creator>Pinot, Rafael</dc:creator>
 <dc:creator>Zuber, Martin</dc:creator>
 <dc:creator>Gouy-Pailler, C&#xe9;dric</dc:creator>
 <dc:creator>Sirdey, Renaud</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We introduce a deep learning framework able to deal with strong privacy
constraints. Based on collaborative learning, differential privacy and
homomorphic encryption, the proposed approach advances state-of-the-art of
private deep learning against a wider range of threats, in particular the
honest-but-curious server assumption. We address threats from both the
aggregation server, the global model and potentially colluding data holders.
Building upon distributed differential privacy and a homomorphic argmax
operator, our method is specifically designed to maintain low communication
loads and efficiency. The proposed method is supported by carefully crafted
theoretical results. We provide differential privacy guarantees from the point
of view of any entity having access to the final model, including colluding
data holders, as a function of the ratio of data holders who kept their noise
secret. This makes our method practical to real-life scenarios where data
holders do not trust any third party to process their datasets nor the other
data holders. Crucially the computational burden of the approach is maintained
reasonable, and, to the best of our knowledge, our framework is the first one
to be efficient enough to investigate deep learning applications while
addressing such a large scope of threats. To assess the practical usability of
our framework, experiments have been carried out on image datasets in a
classification context. We present numerical results that show that the
learning procedure is both accurate and private.
</dc:description>
 <dc:description>Comment: 32 pages, 3 figures. Mach Learn (2021)</dc:description>
 <dc:date>2020-06-16</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.09475</dc:identifier>
 <dc:identifier>doi:10.1007/s10994-021-05970-3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.09517</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Last-iterate Convergence in Constrained Saddle-point Optimization</dc:title>
 <dc:creator>Wei, Chen-Yu</dc:creator>
 <dc:creator>Lee, Chung-Wei</dc:creator>
 <dc:creator>Zhang, Mengxiao</dc:creator>
 <dc:creator>Luo, Haipeng</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Optimistic Gradient Descent Ascent (OGDA) and Optimistic Multiplicative
Weights Update (OMWU) for saddle-point optimization have received growing
attention due to their favorable last-iterate convergence. However, their
behaviors for simple bilinear games over the probability simplex are still not
fully understood - previous analysis lacks explicit convergence rates, only
applies to an exponentially small learning rate, or requires additional
assumptions such as the uniqueness of the optimal solution. In this work, we
significantly expand the understanding of last-iterate convergence for OGDA and
OMWU in the constrained setting. Specifically, for OMWU in bilinear games over
the simplex, we show that when the equilibrium is unique, linear last-iterate
convergence is achieved with a learning rate whose value is set to a universal
constant, improving the result of (Daskalakis &amp; Panageas, 2019b) under the same
assumption. We then significantly extend the results to more general objectives
and feasible sets for the projected OGDA algorithm, by introducing a sufficient
condition under which OGDA exhibits concrete last-iterate convergence rates
with a constant learning rate whose value only depends on the smoothness of the
objective function. We show that bilinear games over any polytope satisfy this
condition and OGDA converges exponentially fast even without the unique
equilibrium assumption. Our condition also holds for
strongly-convex-strongly-concave functions, recovering the result of (Hsieh et
al., 2019). Finally, we provide experimental results to further support our
theory.
</dc:description>
 <dc:date>2020-06-16</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.09517</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.10311</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SGD for Structured Nonconvex Functions: Learning Rates, Minibatching and
  Interpolation</dc:title>
 <dc:creator>Gower, Robert M.</dc:creator>
 <dc:creator>Sebbouh, Othmane</dc:creator>
 <dc:creator>Loizou, Nicolas</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Stochastic Gradient Descent (SGD) is being used routinely for optimizing
non-convex functions. Yet, the standard convergence theory for SGD in the
smooth non-convex setting gives a slow sublinear convergence to a stationary
point. In this work, we provide several convergence theorems for SGD showing
convergence to a global minimum for non-convex problems satisfying some extra
structural assumptions. In particular, we focus on two large classes of
structured non-convex functions: (i) Quasar (Strongly) Convex functions (a
generalization of convex functions) and (ii) functions satisfying the
Polyak-Lojasiewicz condition (a generalization of strongly-convex functions).
Our analysis relies on an Expected Residual condition which we show is a
strictly weaker assumption than previously used growth conditions, expected
smoothness or bounded variance assumptions. We provide theoretical guarantees
for the convergence of SGD for different step-size selections including
constant, decreasing and the recently proposed stochastic Polyak step-size. In
addition, all of our analysis holds for the arbitrary sampling paradigm, and as
such, we give insights into the complexity of minibatching and determine an
optimal minibatch size. Finally, we show that for models that interpolate the
training data, we can dispense of our Expected Residual condition and give
state-of-the-art results in this setting.
</dc:description>
 <dc:description>Comment: Proceedings of the 24th International Conference on Artificial
  Intelligence and Statistics (AISTATS) 2021</dc:description>
 <dc:date>2020-06-18</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.10311</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.10926</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strong approximation of time-changed stochastic differential equations
  involving drifts with random and non-random integrators</dc:title>
 <dc:creator>Jin, Sixian</dc:creator>
 <dc:creator>Kobayashi, Kei</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65C30, 60H10</dc:subject>
 <dc:description>  The rates of strong convergence for various approximation schemes are
investigated for a class of stochastic differential equations (SDEs) which
involve a random time change given by an inverse subordinator. SDEs to be
considered are unique in two different aspects: i) they contain two drift
terms, one driven by the random time change and the other driven by a regular,
non-random time variable; ii) the standard Lipschitz assumption is replaced by
that with a time-varying Lipschitz bound. The difficulty imposed by the first
aspect is overcome via an approach that is significantly different from a
well-known method based on the so-called duality principle. On the other hand,
the second aspect requires the establishment of a criterion for the existence
of exponential moments of functions of the random time change.
</dc:description>
 <dc:description>Comment: Restriction placed on the dimension in section 5; the second figure
  updated; minor modifications for clarification purposes made throughout</dc:description>
 <dc:date>2020-06-18</dc:date>
 <dc:date>2020-12-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.10926</dc:identifier>
 <dc:identifier>Published online in BIT Numerical Mathematics (2021)</dc:identifier>
 <dc:identifier>doi:10.1007/s10543-021-00852-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.11141</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Control of a Rigid Wing Pumping Airborne Wind Energy System in all
  Operational Phases</dc:title>
 <dc:creator>Todeschini, Davide</dc:creator>
 <dc:creator>Fagiano, Lorenzo</dc:creator>
 <dc:creator>Micheli, Claudio</dc:creator>
 <dc:creator>Cattano, Aldo</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The control design of an airborne wind energy system with rigid aircraft,
vertical take-off and landing, and pumping operation is described. A
hierarchical control structure is implemented, in order to address all
operational phases: take-off, transition to power generation, pumping energy
generation cycles, transition to hovering, and landing. Control design at all
hierarchical levels is described. The design approach is conceived and
developed with real-world applicability as main driver. Aircraft design
considerations in light of system maneuverability are presented, too, as well
as three possible alternative strategies for the retraction phase of the
pumping cycle. The automatic control approach is assessed in simulation with a
realistic model of the overall system, and the results yield a comparison among
the three retraction strategies, clearly indicating the most efficient one. The
presented results allow one to simulate the dynamical behavior of an AWE system
in all operational phases, enabling further studies on all-round system
automation, towards fully autonomous and reliable operation.
</dc:description>
 <dc:description>Comment: This is the preprint of a paper submitted to Control Engineering
  Practice</dc:description>
 <dc:date>2020-06-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.11141</dc:identifier>
 <dc:identifier>Control Engineering Practice, 2021</dc:identifier>
 <dc:identifier>doi:10.1016/j.conengprac.2021.104794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.11929</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cyber Security in the Age of COVID-19: A Timeline and Analysis of
  Cyber-Crime and Cyber-Attacks during the Pandemic</dc:title>
 <dc:creator>Lallie, Harjinder Singh</dc:creator>
 <dc:creator>Shepherd, Lynsay A.</dc:creator>
 <dc:creator>Nurse, Jason R. C.</dc:creator>
 <dc:creator>Erola, Arnau</dc:creator>
 <dc:creator>Epiphaniou, Gregory</dc:creator>
 <dc:creator>Maple, Carsten</dc:creator>
 <dc:creator>Bellekens, Xavier</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  The COVID-19 pandemic was a remarkable unprecedented event which altered the
lives of billions of citizens globally resulting in what became commonly
referred to as the new-normal in terms of societal norms and the way we live
and work. Aside from the extraordinary impact on society and business as a
whole, the pandemic generated a set of unique cyber-crime related circumstances
which also affected society and business. The increased anxiety caused by the
pandemic heightened the likelihood of cyber-attacks succeeding corresponding
with an increase in the number and range of cyber-attacks.
  This paper analyses the COVID-19 pandemic from a cyber-crime perspective and
highlights the range of cyber-attacks experienced globally during the pandemic.
Cyber-attacks are analysed and considered within the context of key global
events to reveal the modus-operandi of cyber-attack campaigns. The analysis
shows how following what appeared to be large gaps between the initial outbreak
of the pandemic in China and the first COVID-19 related cyber-attack, attacks
steadily became much more prevalent to the point that on some days, 3 or 4
unique cyber-attacks were being reported. The analysis proceeds to utilise the
UK as a case study to demonstrate how cyber-criminals leveraged key events and
governmental announcements to carefully craft and design cyber-crime campaigns.
</dc:description>
 <dc:description>Comment: 20 pages, 6 figures</dc:description>
 <dc:date>2020-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.11929</dc:identifier>
 <dc:identifier>Computers &amp; Security 2021</dc:identifier>
 <dc:identifier>doi:10.1016/j.cose.2021.102248</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.12031</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MAD-HTLC: Because HTLC is Crazy-Cheap to Attack</dc:title>
 <dc:creator>Tsabary, Itay</dc:creator>
 <dc:creator>Yechieli, Matan</dc:creator>
 <dc:creator>Manuskin, Alex</dc:creator>
 <dc:creator>Eyal, Ittay</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Smart Contracts and transactions allow users to implement elaborate
constructions on cryptocurrency blockchains like Bitcoin and Ethereum. Many of
these constructions, including operational payment channels and atomic swaps,
use a building block called Hashed Time-Locked Contract (HTLC).
  In this work, we distill from HTLC a specification (HTLC-Spec), and present
an implementation called Mutual-Assured-Destruction Hashed Time-Locked Contract
(MAD-HTLC). MAD-HTLC employs a novel approach of utilizing the existing
blockchain operators, called miners, as part of the design. If a user
misbehaves, MAD-HTLC incentivizes the miners to confiscate all her funds. We
prove MAD-HTLC's security using the UC framework and game-theoretic analysis.
We demonstrate MAD-HTLC's efficacy and analyze its overhead by instantiating it
on Bitcoin's and Ethereum's operational blockchains.
  Notably, current miner software makes only little effort to optimize revenue,
since the advantage is relatively small. However, as the demand grows and other
revenue components shrink, miners are more motivated to fully optimize their
fund intake. By patching the standard Bitcoin client, we demonstrate such
optimization is easy to implement, making the miners natural enforcers of
MAD-HTLC.
  Finally, we extend previous results regarding HTLC vulnerability to bribery
attacks. An attacker can incentivize miners to prefer her transactions by
offering high transaction fees. We demonstrate this attack can be easily
implemented by patching the Bitcoin client, and use game-theoretic tools to
qualitatively tighten the known cost bound of such bribery attacks in presence
of rational miners. We identify bribe opportunities occurring on the Bitcoin
and Ethereum main networks where a few dollars bribe could yield tens of
thousands of dollars in reward (e.g., \$2 for over \$25K).
</dc:description>
 <dc:date>2020-06-22</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.12031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.12052</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Few-shot 3D Point Cloud Semantic Segmentation</dc:title>
 <dc:creator>Zhao, Na</dc:creator>
 <dc:creator>Chua, Tat-Seng</dc:creator>
 <dc:creator>Lee, Gim Hee</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:subject>I.4.6</dc:subject>
 <dc:description>  Many existing approaches for 3D point cloud semantic segmentation are fully
supervised. These fully supervised approaches heavily rely on large amounts of
labeled training data that are difficult to obtain and cannot segment new
classes after training. To mitigate these limitations, we propose a novel
attention-aware multi-prototype transductive few-shot point cloud semantic
segmentation method to segment new classes given a few labeled examples.
Specifically, each class is represented by multiple prototypes to model the
complex data distribution of labeled points. Subsequently, we employ a
transductive label propagation method to exploit the affinities between labeled
multi-prototypes and unlabeled points, and among the unlabeled points.
Furthermore, we design an attention-aware multi-level feature learning network
to learn the discriminative features that capture the geometric dependencies
and semantic correlations between points. Our proposed method shows significant
and consistent improvements compared to baselines in different few-shot point
cloud semantic segmentation settings (i.e., 2/3-way 1/5-shot) on two benchmark
datasets. Our code is available at https://github.com/Na-Z/attMPTI.
</dc:description>
 <dc:description>Comment: CVPR 2021</dc:description>
 <dc:date>2020-06-22</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.12052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.12097</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Federated Semi-Supervised Learning with Inter-Client Consistency &amp;
  Disjoint Learning</dc:title>
 <dc:creator>Jeong, Wonyong</dc:creator>
 <dc:creator>Yoon, Jaehong</dc:creator>
 <dc:creator>Yang, Eunho</dc:creator>
 <dc:creator>Hwang, Sung Ju</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  While existing federated learning approaches mostly require that clients have
fully-labeled data to train on, in realistic settings, data obtained at the
client-side often comes without any accompanying labels. Such deficiency of
labels may result from either high labeling cost, or difficulty of annotation
due to the requirement of expert knowledge. Thus the private data at each
client may be either partly labeled, or completely unlabeled with labeled data
being available only at the server, which leads us to a new practical federated
learning problem, namely Federated Semi-Supervised Learning (FSSL). In this
work, we study two essential scenarios of FSSL based on the location of the
labeled data. The first scenario considers a conventional case where clients
have both labeled and unlabeled data (labels-at-client), and the second
scenario considers a more challenging case, where the labeled data is only
available at the server (labels-at-server). We then propose a novel method to
tackle the problems, which we refer to as Federated Matching (FedMatch).
FedMatch improves upon naive combinations of federated learning and
semi-supervised learning approaches with a new inter-client consistency loss
and decomposition of the parameters for disjoint learning on labeled and
unlabeled data. Through extensive experimental validation of our method in the
two different scenarios, we show that our method outperforms both local
semi-supervised learning and baselines which naively combine federated learning
with semi-supervised learning. The code is available at
https://github.com/wyjeong/FedMatch.
</dc:description>
 <dc:date>2020-06-22</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.12097</dc:identifier>
 <dc:identifier>International Conference on Learning Representations (ICLR 2021),
  International Workshop on Federated Learning for User Privacy and Data
  Confidentiality in Conjunction with ICML 2020 (FL-ICML'20)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.12131</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomized Runge-Kutta method -- stability and convergence under inexact
  information</dc:title>
 <dc:creator>Bochacik, Tomasz</dc:creator>
 <dc:creator>Go&#x107;win, Maciej</dc:creator>
 <dc:creator>Morkisz, Pawe&#x142; M.</dc:creator>
 <dc:creator>Przyby&#x142;owicz, Pawe&#x142;</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65C05, 65C20, 65L05, 65L06, 65L20</dc:subject>
 <dc:description>  We deal with optimal approximation of solutions of ODEs under local Lipschitz
condition and inexact discrete information about the right-hand side functions.
We show that the randomized two-stage Runge-Kutta scheme is the optimal method
among all randomized algorithms based on standard noisy information. We perform
numerical experiments that confirm our theoretical findings. Moreover, for the
optimal algorithm we rigorously investigate properties of regions of absolute
stability.
</dc:description>
 <dc:date>2020-06-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.12131</dc:identifier>
 <dc:identifier>doi:10.1016/j.jco.2021.101554</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.12227</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approaches For Multi-View Redescription Mining</dc:title>
 <dc:creator>Mihel&#x10d;i&#x107;, Matej</dc:creator>
 <dc:creator>&#x160;muc, Tomislav</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The task of redescription mining explores ways to re-describe different
subsets of entities contained in a dataset and to reveal non-trivial
associations between different subsets of attributes, called views. This
interesting and challenging task is encountered in different scientific fields,
and is addressed by a number of approaches that obtain redescriptions and allow
for the exploration and analyses of attribute associations. The main limitation
of existing approaches to this task is their inability to use more than two
views. Our work alleviates this drawback. We present a memory efficient,
extensible multi-view redescription mining framework that can be used to relate
multiple, i.e. more than two views, disjoint sets of attributes describing one
set of entities. The framework can use any multi-target regression or
multi-label classification algorithm, with models that can be represented as
sets of rules, to generate redescriptions. Multi-view redescriptions are built
using incremental view-extending heuristic from initially created two-view
redescriptions. In this work, we use different types of Predictive Clustering
trees algorithms (regular, extra, with random output selection) and the Random
Forest thereof in order to improve the quality of final redescription sets
and/or execution time needed to generate them. We provide multiple performance
analyses of the proposed framework and compare it against the naive approach to
multi-view redescription mining. We demonstrate the usefulness of the proposed
multi-view extension on several datasets, including a use-case on understanding
of machine learning models - a topic of growing importance in machine learning
and artificial intelligence in general.
</dc:description>
 <dc:description>Comment: This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</dc:description>
 <dc:date>2020-06-22</dc:date>
 <dc:date>2020-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.12227</dc:identifier>
 <dc:identifier>IEEE Access, vol. 9, pp. 19356-19378, 2021</dc:identifier>
 <dc:identifier>doi:10.1109/ACCESS.2021.3054245</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.12231</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Network with Approximation Error Being Reciprocal of Width to Power
  of Square Root of Depth</dc:title>
 <dc:creator>Shen, Zuowei</dc:creator>
 <dc:creator>Yang, Haizhao</dc:creator>
 <dc:creator>Zhang, Shijun</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A new network with super approximation power is introduced. This network is
built with Floor ($\lfloor x\rfloor$) or ReLU ($\max\{0,x\}$) activation
function in each neuron and hence we call such networks Floor-ReLU networks.
For any hyper-parameters $N\in\mathbb{N}^+$ and $L\in\mathbb{N}^+$, it is shown
that Floor-ReLU networks with width $\max\{d,\, 5N+13\}$ and depth $64dL+3$ can
uniformly approximate a H\&quot;older function $f$ on $[0,1]^d$ with an
approximation error $3\lambda d^{\alpha/2}N^{-\alpha\sqrt{L}}$, where $\alpha
\in(0,1]$ and $\lambda$ are the H\&quot;older order and constant, respectively. More
generally for an arbitrary continuous function $f$ on $[0,1]^d$ with a modulus
of continuity $\omega_f(\cdot)$, the constructive approximation rate is
$\omega_f(\sqrt{d}\,N^{-\sqrt{L}})+2\omega_f(\sqrt{d}){N^{-\sqrt{L}}}$. As a
consequence, this new class of networks overcomes the curse of dimensionality
in approximation power when the variation of $\omega_f(r)$ as $r\to 0$ is
moderate (e.g., $\omega_f(r) \lesssim r^\alpha$ for H\&quot;older continuous
functions), since the major term to be considered in our approximation rate is
essentially $\sqrt{d}$ times a function of $N$ and $L$ independent of $d$
within the modulus of continuity.
</dc:description>
 <dc:date>2020-06-22</dc:date>
 <dc:date>2020-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.12231</dc:identifier>
 <dc:identifier>Neural Computation, Volume 33, Issue 4, April 2021, Pages
  1005-1036</dc:identifier>
 <dc:identifier>doi:10.1162/neco_a_01364</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.12302</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving LIME Robustness with Smarter Locality Sampling</dc:title>
 <dc:creator>Saito, Sean</dc:creator>
 <dc:creator>Chua, Eugene</dc:creator>
 <dc:creator>Capel, Nicholas</dc:creator>
 <dc:creator>Hu, Rocco</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Explainability algorithms such as LIME have enabled machine learning systems
to adopt transparency and fairness, which are important qualities in commercial
use cases. However, recent work has shown that LIME's naive sampling strategy
can be exploited by an adversary to conceal biased, harmful behavior. We
propose to make LIME more robust by training a generative adversarial network
to sample more realistic synthetic data which the explainer uses to generate
explanations. Our experiments demonstrate that our proposed method demonstrates
an increase in accuracy across three real-world datasets in detecting biased,
adversarial behavior compared to vanilla LIME. This is achieved while
maintaining comparable explanation quality, with up to 99.94\% in top-1
accuracy in some cases.
</dc:description>
 <dc:description>Comment: AdvML '20: Workshop on Adversarial Learning Methods for Machine
  Learning and Data Mining, August 24, 2020, San Diego, CA. 5 pages, 2 figures</dc:description>
 <dc:date>2020-06-22</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.12302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.12330</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constant-Space, Constant-Randomness Verifiers with Arbitrarily Small
  Error</dc:title>
 <dc:creator>Gezer, M. Utkan</dc:creator>
 <dc:creator>Say, A. C. Cem</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  We study the capabilities of probabilistic finite-state machines that act as
verifiers for certificates of language membership for input strings, in the
regime where the verifiers are restricted to toss some fixed nonzero number of
coins regardless of the input size. Say and Yakary{\i}lmaz showed that the
class of languages that could be verified by these machines within an error
bound strictly less than $1/2$ is precisely NL, but their construction yields
verifiers with error bounds that are very close to $1/2$ for most languages in
that class when the definition of &quot;error&quot; is strengthened to include looping
forever without giving a response. We characterize a subset of NL for which
verification with arbitrarily low error is possible by these extremely weak
machines. It turns out that, for any $\varepsilon&gt;0$, one can construct a
constant-coin, constant-space verifier operating within error $\varepsilon$ for
every language that is recognizable by a linear-time multi-head
nondeterministic finite automaton (2nfa($k$)). We discuss why it is difficult
to generalize this method to all of NL, and give a reasonably tight way to
relate the power of linear-time 2nfa($k$)'s to simultaneous time-space
complexity classes defined in terms of Turing machines.
</dc:description>
 <dc:date>2020-06-22</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.12330</dc:identifier>
 <dc:identifier>doi:10.1016/j.ic.2021.104744</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.12444</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Forward-Backward Rapidly-Exploring Random Trees for Stochastic Optimal
  Control</dc:title>
 <dc:creator>Hawkins, Kelsey P.</dc:creator>
 <dc:creator>Pakniyat, Ali</dc:creator>
 <dc:creator>Theodorou, Evangelos</dc:creator>
 <dc:creator>Tsiotras, Panagiotis</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  We propose a numerical method for the computation of the forward-backward
stochastic differential equations (FBSDE) appearing in the Feynman-Kac
representation of the value function in stochastic optimal control problems. By
the use of the Girsanov change of probability measures, it is demonstrated how
a rapidly-exploring random tree (RRT) method can be utilized for the forward
integration pass, as long as the controlled drift terms are appropriately
compensated in the backward integration pass. Subsequently, a numerical
approximation of the value function is proposed by solving a series of function
approximation problems backwards in time along the edges of the constructed
RRT. Moreover, a local entropy-weighted least squares Monte Carlo (LSMC) method
is developed to concentrate function approximation accuracy in regions most
likely to be visited by optimally controlled trajectories. The results of the
proposed methodology are demonstrated on linear and nonlinear stochastic
optimal control problems with non-quadratic running costs, which reveal
significant convergence improvements over previous FBSDE-based numerical
solution methods.
</dc:description>
 <dc:date>2020-06-22</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.12444</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.12459</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IDF++: Analyzing and Improving Integer Discrete Flows for Lossless
  Compression</dc:title>
 <dc:creator>Berg, Rianne van den</dc:creator>
 <dc:creator>Gritsenko, Alexey A.</dc:creator>
 <dc:creator>Dehghani, Mostafa</dc:creator>
 <dc:creator>S&#xf8;nderby, Casper Kaae</dc:creator>
 <dc:creator>Salimans, Tim</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper we analyse and improve integer discrete flows for lossless
compression. Integer discrete flows are a recently proposed class of models
that learn invertible transformations for integer-valued random variables.
Their discrete nature makes them particularly suitable for lossless compression
with entropy coding schemes. We start by investigating a recent theoretical
claim that states that invertible flows for discrete random variables are less
flexible than their continuous counterparts. We demonstrate with a proof that
this claim does not hold for integer discrete flows due to the embedding of
data with finite support into the countably infinite integer lattice.
Furthermore, we zoom in on the effect of gradient bias due to the
straight-through estimator in integer discrete flows, and demonstrate that its
influence is highly dependent on architecture choices and less prominent than
previously thought. Finally, we show how different architecture modifications
improve the performance of this model class for lossless compression, and that
they also enable more efficient compression: a model with half the number of
flow layers performs on par with or better than the original integer discrete
flow model.
</dc:description>
 <dc:description>Comment: Accepted as a conference paper at the Ninth International Conference
  on Learning Representations (ICLR) 2021</dc:description>
 <dc:date>2020-06-22</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.12459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.13915</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchically Compositional Tasks and Deep Convolutional Networks</dc:title>
 <dc:creator>Deza, Arturo</dc:creator>
 <dc:creator>Liao, Qianli</dc:creator>
 <dc:creator>Banburski, Andrzej</dc:creator>
 <dc:creator>Poggio, Tomaso</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The main success stories of deep learning, starting with ImageNet, depend on
deep convolutional networks, which on certain tasks perform significantly
better than traditional shallow classifiers, such as support vector machines,
and also better than deep fully connected networks; but what is so special
about deep convolutional networks? Recent results in approximation theory
proved an exponential advantage of deep convolutional networks with or without
shared weights in approximating functions with hierarchical locality in their
compositional structure. More recently, the hierarchical structure was proved
to be hard to learn from data, suggesting that it is a powerful prior embedded
in the architecture of the network. These mathematical results, however, do not
say which real-life tasks correspond to input-output functions with
hierarchical locality. To evaluate this, we consider a set of visual tasks
where we disrupt the local organization of images via &quot;deterministic
scrambling&quot; to later perform a visual task on these images structurally-altered
in the same way for training and testing. For object recognition we find, as
expected, that scrambling does not affect the performance of shallow or deep
fully connected networks contrary to the out-performance of convolutional
networks. Not all tasks involving images are however affected. Texture
perception and global color estimation are much less sensitive to deterministic
scrambling showing that the underlying functions corresponding to these tasks
are not hierarchically local; and also counter-intuitively showing that these
tasks are better approximated by networks that are not deep (texture) nor
convolutional (color). Altogether, these results shed light into the importance
of matching a network architecture with its embedded prior of the task to be
learned.
</dc:description>
 <dc:description>Comment: A pre-print. Currently Under Review</dc:description>
 <dc:date>2020-06-24</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.13915</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.14147</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FastSpec: Scalable Generation and Detection of Spectre Gadgets Using
  Neural Embeddings</dc:title>
 <dc:creator>Tol, M. Caner</dc:creator>
 <dc:creator>Gulmezoglu, Berk</dc:creator>
 <dc:creator>Yurtseven, Koray</dc:creator>
 <dc:creator>Sunar, Berk</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Several techniques have been proposed to detect vulnerable Spectre gadgets in
widely deployed commercial software. Unfortunately, detection techniques
proposed so far rely on hand-written rules which fall short in covering subtle
variations of known Spectre gadgets as well as demand a huge amount of time to
analyze each conditional branch in software. Moreover, detection tool
evaluations are based only on a handful of these gadgets, as it requires
arduous effort to craft new gadgets manually.
  In this work, we employ both fuzzing and deep learning techniques to automate
the generation and detection of Spectre gadgets. We first create a diverse set
of Spectre-V1 gadgets by introducing perturbations to the known gadgets. Using
mutational fuzzing, we produce a data set with more than 1 million Spectre-V1
gadgets which is the largest Spectre gadget data set built to date. Next, we
conduct the first empirical usability study of Generative Adversarial Networks
(GANs) in the context of assembly code generation without any human
interaction. We introduce SpectreGAN which leverages masking implementation of
GANs for both learning the gadget structures and generating new gadgets. This
provides the first scalable solution to extend the variety of Spectre gadgets.
  Finally, we propose FastSpec which builds a classifier with the generated
Spectre gadgets based on a novel high dimensional Neural Embeddings technique
(BERT). For the case studies, we demonstrate that FastSpec discovers potential
gadgets with a high success rate in OpenSSL libraries and Phoronix benchmarks.
Further, FastSpec offers much greater flexibility and time-related performance
gain compared to the existing tools and therefore can be used for gadget
detection in large-scale software.
</dc:description>
 <dc:description>Comment: IEEE European Symposium on Security and Privacy 2021</dc:description>
 <dc:date>2020-06-24</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.14147</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.14195</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mobile Robot Path Planning in Dynamic Environments: A Survey</dc:title>
 <dc:creator>Cai, Kuanqi</dc:creator>
 <dc:creator>Wang, Chaoqun</dc:creator>
 <dc:creator>Cheng, Jiyu</dc:creator>
 <dc:creator>De Silva, Clarence W</dc:creator>
 <dc:creator>Meng, Max Q. -H.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  There are many challenges for robot navigation in densely populated dynamic
environments. This paper presents a survey of the path planning methods for
robot navigation in dense environments. Particularly, the path planning in the
navigation framework of mobile robots is composed of global path planning and
local path planning, with regard to the planning scope and the executability.
Within this framework, the recent progress of the path planning methods is
presented in the paper, while examining their strengths and weaknesses.
Notably, the recently developed Velocity Obstacle method and its variants that
serve as the local planner are analyzed comprehensively. Moreover, as a
model-free method that is widely used in current robot applications, the
reinforcement learning-based path planning algorithms are detailed in this
paper.
</dc:description>
 <dc:date>2020-06-25</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.14195</dc:identifier>
 <dc:identifier>Instrumentation,2019,6(02):90-100</dc:identifier>
 <dc:identifier>doi:10.15878/j.cnki.instrumentation.2019.02.010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.14953</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What they do when in doubt: a study of inductive biases in seq2seq
  learners</dc:title>
 <dc:creator>Kharitonov, Eugene</dc:creator>
 <dc:creator>Chaabouni, Rahma</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Sequence-to-sequence (seq2seq) learners are widely used, but we still have
only limited knowledge about what inductive biases shape the way they
generalize. We address that by investigating how popular seq2seq learners
generalize in tasks that have high ambiguity in the training data. We use SCAN
and three new tasks to study learners' preferences for memorization,
arithmetic, hierarchical, and compositional reasoning. Further, we connect to
Solomonoff's theory of induction and propose to use description length as a
principled and sensitive measure of inductive biases.
  In our experimental study, we find that LSTM-based learners can learn to
perform counting, addition, and multiplication by a constant from a single
training example. Furthermore, Transformer and LSTM-based learners show a bias
toward the hierarchical induction over the linear one, while CNN-based learners
prefer the opposite. On the SCAN dataset, we find that CNN-based, and, to a
lesser degree, Transformer- and LSTM-based learners have a preference for
compositional generalization over memorization. Finally, across all our
experiments, description length proved to be a sensitive measure of inductive
biases.
</dc:description>
 <dc:date>2020-06-26</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.14953</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.15222</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BERTology Meets Biology: Interpreting Attention in Protein Language
  Models</dc:title>
 <dc:creator>Vig, Jesse</dc:creator>
 <dc:creator>Madani, Ali</dc:creator>
 <dc:creator>Varshney, Lav R.</dc:creator>
 <dc:creator>Xiong, Caiming</dc:creator>
 <dc:creator>Socher, Richard</dc:creator>
 <dc:creator>Rajani, Nazneen Fatema</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Quantitative Biology - Biomolecules</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:description>  Transformer architectures have proven to learn useful representations for
protein classification and generation tasks. However, these representations
present challenges in interpretability. In this work, we demonstrate a set of
methods for analyzing protein Transformer models through the lens of attention.
We show that attention: (1) captures the folding structure of proteins,
connecting amino acids that are far apart in the underlying sequence, but
spatially close in the three-dimensional structure, (2) targets binding sites,
a key functional component of proteins, and (3) focuses on progressively more
complex biophysical properties with increasing layer depth. We find this
behavior to be consistent across three Transformer architectures (BERT, ALBERT,
XLNet) and two distinct protein datasets. We also present a three-dimensional
visualization of the interaction between attention and protein structure. Code
for visualization and analysis is available at
https://github.com/salesforce/provis.
</dc:description>
 <dc:description>Comment: To appear in ICLR 2021</dc:description>
 <dc:date>2020-06-26</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.15222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.15459</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimization and Generalization of Shallow Neural Networks with
  Quadratic Activation Functions</dc:title>
 <dc:creator>Mannelli, Stefano Sarao</dc:creator>
 <dc:creator>Vanden-Eijnden, Eric</dc:creator>
 <dc:creator>Zdeborov&#xe1;, Lenka</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the dynamics of optimization and the generalization properties of
one-hidden layer neural networks with quadratic activation function in the
over-parametrized regime where the layer width $m$ is larger than the input
dimension $d$.
  We consider a teacher-student scenario where the teacher has the same
structure as the student with a hidden layer of smaller width $m^*\le m$.
  We describe how the empirical loss landscape is affected by the number $n$ of
data samples and the width $m^*$ of the teacher network. In particular we
determine how the probability that there be no spurious minima on the empirical
loss depends on $n$, $d$, and $m^*$, thereby establishing conditions under
which the neural network can in principle recover the teacher.
  We also show that under the same conditions gradient descent dynamics on the
empirical loss converges and leads to small generalization error, i.e. it
enables recovery in practice.
  Finally we characterize the time-convergence rate of gradient descent in the
limit of a large number of samples.
  These results are confirmed by numerical experiments.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures + appendix</dc:description>
 <dc:date>2020-06-27</dc:date>
 <dc:date>2020-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.15459</dc:identifier>
 <dc:identifier>Advances in Neural Information Processing Systems, v33, page
  13445--13455, 2020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.15977</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A privacy-preserving tests optimization algorithm for epidemics
  containment</dc:title>
 <dc:creator>Nuara, Alessandro</dc:creator>
 <dc:creator>Trov&#xf2;, Francesco</dc:creator>
 <dc:creator>Gatti, Nicola</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The SARS-CoV-2 outbreak changed the everyday life of almost all the people
over the world.Currently, we are facing with the problem of containing the
spread of the virus both using the more effective forced lockdown, which has
the drawback of slowing down the economy of the involved countries, and by
identifying and isolating the positive individuals, which, instead, is an hard
task in general due to the lack of information. For this specific disease, the
identificato of the infected is particularly challenging since there exists
cathegories, namely the asymptomatics, who are positive and potentially
contagious, but do not show any of the symptoms of SARS-CoV-2. Until the
developement and distribution of a vaccine is not yet ready, we need to design
ways of selecting those individuals which are most likely infected, given the
limited amount of tests which are available each day. In this paper, we make
use of available data collected by the so called contact tracing apps to
develop an algorithm, namely PPTO, that identifies those individuals that are
most likely positive and, therefore, should be tested. While in the past these
analysis have been conducted by centralized algorithms, requiring that all the
app users data are gathered in a single database, our protocol is able to work
on a device level, by exploiting the communication of anonymized information to
other devices.
</dc:description>
 <dc:description>Comment: added figures fixed typos added table of notation</dc:description>
 <dc:date>2020-06-24</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.15977</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.16011</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intrinsic Autoencoders for Joint Neural Rendering and Intrinsic Image
  Decomposition</dc:title>
 <dc:creator>Alhaija, Hassan Abu</dc:creator>
 <dc:creator>Mustikovela, Siva Karthik</dc:creator>
 <dc:creator>Thies, Justus</dc:creator>
 <dc:creator>Jampani, Varun</dc:creator>
 <dc:creator>Nie&#xdf;ner, Matthias</dc:creator>
 <dc:creator>Geiger, Andreas</dc:creator>
 <dc:creator>Rother, Carsten</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Neural rendering techniques promise efficient photo-realistic image synthesis
while at the same time providing rich control over scene parameters by learning
the physical image formation process. While several supervised methods have
been proposed for this task, acquiring a dataset of images with accurately
aligned 3D models is very difficult. The main contribution of this work is to
lift this restriction by training a neural rendering algorithm from unpaired
data. More specifically, we propose an autoencoder for joint generation of
realistic images from synthetic 3D models while simultaneously decomposing real
images into their intrinsic shape and appearance properties. In contrast to a
traditional graphics pipeline, our approach does not require to specify all
scene properties, such as material parameters and lighting by hand. Instead, we
learn photo-realistic deferred rendering from a small set of 3D models and a
larger set of unaligned real images, both of which are easy to acquire in
practice. Simultaneously, we obtain accurate intrinsic decompositions of real
images while not requiring paired ground truth. Our experiments confirm that a
joint treatment of rendering and decomposition is indeed beneficial and that
our approach outperforms state-of-the-art image-to-image translation baselines
both qualitatively and quantitatively.
</dc:description>
 <dc:date>2020-06-29</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.16011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2006.16934</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ERNIE-ViL: Knowledge Enhanced Vision-Language Representations Through
  Scene Graph</dc:title>
 <dc:creator>Yu, Fei</dc:creator>
 <dc:creator>Tang, Jiji</dc:creator>
 <dc:creator>Yin, Weichong</dc:creator>
 <dc:creator>Sun, Yu</dc:creator>
 <dc:creator>Tian, Hao</dc:creator>
 <dc:creator>Wu, Hua</dc:creator>
 <dc:creator>Wang, Haifeng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We propose a knowledge-enhanced approach, ERNIE-ViL, which incorporates
structured knowledge obtained from scene graphs to learn joint representations
of vision-language. ERNIE-ViL tries to build the detailed semantic connections
(objects, attributes of objects and relationships between objects) across
vision and language, which are essential to vision-language cross-modal tasks.
Utilizing scene graphs of visual scenes, ERNIE-ViL constructs Scene Graph
Prediction tasks, i.e., Object Prediction, Attribute Prediction and
Relationship Prediction tasks in the pre-training phase. Specifically, these
prediction tasks are implemented by predicting nodes of different types in the
scene graph parsed from the sentence. Thus, ERNIE-ViL can learn the joint
representations characterizing the alignments of the detailed semantics across
vision and language. After pre-training on large scale image-text aligned
datasets, we validate the effectiveness of ERNIE-ViL on 5 cross-modal
downstream tasks. ERNIE-ViL achieves state-of-the-art performances on all these
tasks and ranks the first place on the VCR leaderboard with an absolute
improvement of 3.7%.
</dc:description>
 <dc:description>Comment: Paper has been published in the AAAI2021 conference</dc:description>
 <dc:date>2020-06-30</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2006.16934</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.00085</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enforcing Almost-Sure Reachability in POMDPs</dc:title>
 <dc:creator>Junges, Sebastian</dc:creator>
 <dc:creator>Jansen, Nils</dc:creator>
 <dc:creator>Seshia, Sanjit A.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Partially-Observable Markov Decision Processes (POMDPs) are a well-known
stochastic model for sequential decision making under limited information. We
consider the EXPTIME-hard problem of synthesising policies that almost-surely
reach some goal state without ever visiting a bad state. In particular, we are
interested in computing the winning region, that is, the set of system
configurations from which a policy exists that satisfies the reachability
specification. A direct application of such a winning region is the safe
exploration of POMDPs by, for instance, restricting the behavior of a
reinforcement learning agent to the region. We present two algorithms: A novel
SAT-based iterative approach and a decision-diagram based alternative. The
empirical evaluation demonstrates the feasibility and efficacy of the
approaches.
</dc:description>
 <dc:date>2020-06-30</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.00085</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.00232</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Convergent Decentralized Optimization with Compression</dc:title>
 <dc:creator>Liu, Xiaorui</dc:creator>
 <dc:creator>Li, Yao</dc:creator>
 <dc:creator>Wang, Rongrong</dc:creator>
 <dc:creator>Tang, Jiliang</dc:creator>
 <dc:creator>Yan, Ming</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Communication compression has become a key strategy to speed up distributed
optimization. However, existing decentralized algorithms with compression
mainly focus on compressing DGD-type algorithms. They are unsatisfactory in
terms of convergence rate, stability, and the capability to handle
heterogeneous data. Motivated by primal-dual algorithms, this paper proposes
the first \underline{L}in\underline{EA}r convergent \underline{D}ecentralized
algorithm with compression, LEAD. Our theory describes the coupled dynamics of
the inexact primal and dual update as well as compression error, and we provide
the first consensus error bound in such settings without assuming bounded
gradients. Experiments on convex problems validate our theoretical analysis,
and empirical study on deep neural nets shows that LEAD is applicable to
non-convex problems.
</dc:description>
 <dc:description>Comment: ICLR 2021 (International Conference on Learning Representations)</dc:description>
 <dc:date>2020-07-01</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.00232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.00491</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimisation of a Siamese Neural Network for Real-Time Energy Efficient
  Object Tracking</dc:title>
 <dc:creator>Przewlocka, Dominika</dc:creator>
 <dc:creator>Wasala, Mateusz</dc:creator>
 <dc:creator>Szolc, Hubert</dc:creator>
 <dc:creator>Blachut, Krzysztof</dc:creator>
 <dc:creator>Kryjak, Tomasz</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  In this paper the research on optimisation of visual object tracking using a
Siamese neural network for embedded vision systems is presented. It was assumed
that the solution shall operate in real-time, preferably for a high resolution
video stream, with the lowest possible energy consumption. To meet these
requirements, techniques such as the reduction of computational precision and
pruning were considered. Brevitas, a tool dedicated for optimisation and
quantisation of neural networks for FPGA implementation, was used. A number of
training scenarios were tested with varying levels of optimisations - from
integer uniform quantisation with 16 bits to ternary and binary networks. Next,
the influence of these optimisations on the tracking performance was evaluated.
It was possible to reduce the size of the convolutional filters up to 10 times
in relation to the original network. The obtained results indicate that using
quantisation can significantly reduce the memory and computational complexity
of the proposed network while still enabling precise tracking, thus allow to
use it in embedded vision systems. Moreover, quantisation of weights positively
affects the network training by decreasing overfitting.
</dc:description>
 <dc:description>Comment: 12 pages, accepted for ICCVG 2020</dc:description>
 <dc:date>2020-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.00491</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-030-59006-2_14</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.00493</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimisation of the PointPillars network for 3D object detection in
  point clouds</dc:title>
 <dc:creator>Stanisz, Joanna</dc:creator>
 <dc:creator>Lis, Konrad</dc:creator>
 <dc:creator>Kryjak, Tomasz</dc:creator>
 <dc:creator>Gorgon, Marek</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  In this paper we present our research on the optimisation of a deep neural
network for 3D object detection in a point cloud. Techniques like quantisation
and pruning available in the Brevitas and PyTorch tools were used. We performed
the experiments for the PointPillars network, which offers a reasonable
compromise between detection accuracy and calculation complexity. The aim of
this work was to propose a variant of the network which we will ultimately
implement in an FPGA device. This will allow for real-time LiDAR data
processing with low energy consumption. The obtained results indicate that even
a significant quantisation from 32-bit floating point to 2-bit integer in the
main part of the algorithm, results in 5%-9% decrease of the detection
accuracy, while allowing for almost a 16-fold reduction in size of the model.
</dc:description>
 <dc:description>Comment: 7 pages, 2 figures, submitted to SPA 2020 conference</dc:description>
 <dc:date>2020-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.00493</dc:identifier>
 <dc:identifier>doi:10.23919/SPA50552.2020.9241265</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.01659</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diagnostic Uncertainty Calibration: Towards Reliable Machine Predictions
  in Medical Domain</dc:title>
 <dc:creator>Mimori, Takahiro</dc:creator>
 <dc:creator>Sasada, Keiko</dc:creator>
 <dc:creator>Matsui, Hirotaka</dc:creator>
 <dc:creator>Sato, Issei</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We propose an evaluation framework for class probability estimates (CPEs) in
the presence of label uncertainty, which is commonly observed as diagnosis
disagreement between experts in the medical domain. We also formalize
evaluation metrics for higher-order statistics, including inter-rater
disagreement, to assess predictions on label uncertainty. Moreover, we propose
a novel post-hoc method called $alpha$-calibration, that equips neural network
classifiers with calibrated distributions over CPEs. Using synthetic
experiments and a large-scale medical imaging application, we show that our
approach significantly enhances the reliability of uncertainty estimates:
disagreement probabilities and posterior CPEs.
</dc:description>
 <dc:description>Comment: 31 pages, 6 figures</dc:description>
 <dc:date>2020-07-03</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.01659</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.02033</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Text Data Augmentation: Towards better detection of spear-phishing
  emails</dc:title>
 <dc:creator>Regina, Mehdi</dc:creator>
 <dc:creator>Meyer, Maxime</dc:creator>
 <dc:creator>Goutal, S&#xe9;bastien</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Text data augmentation, i.e., the creation of new textual data from an
existing text, is challenging. Indeed, augmentation transformations should take
into account language complexity while being relevant to the target Natural
Language Processing (NLP) task (e.g., Machine Translation, Text
Classification). Initially motivated by an application of Business Email
Compromise (BEC) detection, we propose a corpus and task agnostic augmentation
framework used as a service to augment English texts within our company. Our
proposal combines different methods, utilizing BERT language model, multi-step
back-translation and heuristics. We show that our augmentation framework
improves performances on several text classification tasks using publicly
available models and corpora as well as on a BEC detection task. We also
provide a comprehensive argumentation about the limitations of our augmentation
framework.
</dc:description>
 <dc:date>2020-07-04</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.02033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.02047</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relationship between manifold smoothness and adversarial vulnerability
  in deep learning with local errors</dc:title>
 <dc:creator>Jiang, Zijian</dc:creator>
 <dc:creator>Zhou, Jianwen</dc:creator>
 <dc:creator>Huang, Haiping</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Artificial neural networks can achieve impressive performances, and even
outperform humans in some specific tasks. Nevertheless, unlike biological
brains, the artificial neural networks suffer from tiny perturbations in
sensory input, under various kinds of adversarial attacks. It is therefore
necessary to study the origin of the adversarial vulnerability. Here, we
establish a fundamental relationship between geometry of hidden representations
(manifold perspective) and the generalization capability of the deep networks.
For this purpose, we choose a deep neural network trained by local errors, and
then analyze emergent properties of trained networks through the manifold
dimensionality, manifold smoothness, and the generalization capability. To
explore effects of adversarial examples, we consider independent Gaussian noise
attacks and fast-gradient-sign-method (FGSM) attacks. Our study reveals that a
high generalization accuracy requires a relatively fast power-law decay of the
eigen-spectrum of hidden representations. Under Gaussian attacks, the
relationship between generalization accuracy and power-law exponent is
monotonic, while a non-monotonic behavior is observed for FGSM attacks. Our
empirical study provides a route towards a final mechanistic interpretation of
adversarial vulnerability under adversarial attacks.
</dc:description>
 <dc:description>Comment: 10 pages, 8 figures, to appear in Chin. Phys. B (2021)</dc:description>
 <dc:date>2020-07-04</dc:date>
 <dc:date>2020-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.02047</dc:identifier>
 <dc:identifier>Chin. Phys. B Vol. 30, No. 4 (2021) 048702</dc:identifier>
 <dc:identifier>doi:10.1088/1674-1056/abd68e</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.02090</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Piecewise Divergence-Free Nonconforming Virtual Elements for Stokes
  Problem in Any Dimensions</dc:title>
 <dc:creator>Wei, Huayi</dc:creator>
 <dc:creator>Huang, Xuehai</dc:creator>
 <dc:creator>Li, Ao</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>76D07, 65N12, 65N22, 65N30</dc:subject>
 <dc:description>  Piecewise divergence-free nonconforming virtual elements are designed for
Stokes problem in any dimensions. After introducing a local energy projector
based on the Stokes problem and the stabilization, a divergence-free
nonconforming virtual element method is proposed for Stokes problem. A detailed
and rigorous error analysis is presented for the discrete method. An important
property in the analysis is that the local energy projector commutes with the
divergence operator. With the help of a divergence-free interpolation operator
onto a generalized Raviart-Thomas element space, a pressure-robust
nonconforming virtual element method is developed by simply modifying the right
hand side of the previous discretization. A reduced virtual element method is
also discussed. Numerical results are provided to verify the theoretical
convergence.
</dc:description>
 <dc:description>Comment: 22 pages, 2 figures</dc:description>
 <dc:date>2020-07-04</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.02090</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.02798</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gradient Origin Networks</dc:title>
 <dc:creator>Bond-Taylor, Sam</dc:creator>
 <dc:creator>Willcocks, Chris G.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>68T01 (Primary), 68T07 (Secondary)</dc:subject>
 <dc:subject>I.5.0</dc:subject>
 <dc:subject>I.4.0</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  This paper proposes a new type of generative model that is able to quickly
learn a latent representation without an encoder. This is achieved using
empirical Bayes to calculate the expectation of the posterior, which is
implemented by initialising a latent vector with zeros, then using the gradient
of the log-likelihood of the data with respect to this zero vector as new
latent points. The approach has similar characteristics to autoencoders, but
with a simpler architecture, and is demonstrated in a variational autoencoder
equivalent that permits sampling. This also allows implicit representation
networks to learn a space of implicit functions without requiring a
hypernetwork, retaining their representation advantages across datasets. The
experiments show that the proposed method converges faster, with significantly
lower reconstruction error than autoencoders, while requiring half the
parameters.
</dc:description>
 <dc:description>Comment: 16 pages, 17 figures, accepted at ICLR 2021, camera-ready version</dc:description>
 <dc:date>2020-07-06</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.02798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.03085</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wasserstein Distances for Stereo Disparity Estimation</dc:title>
 <dc:creator>Garg, Divyansh</dc:creator>
 <dc:creator>Wang, Yan</dc:creator>
 <dc:creator>Hariharan, Bharath</dc:creator>
 <dc:creator>Campbell, Mark</dc:creator>
 <dc:creator>Weinberger, Kilian Q.</dc:creator>
 <dc:creator>Chao, Wei-Lun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Existing approaches to depth or disparity estimation output a distribution
over a set of pre-defined discrete values. This leads to inaccurate results
when the true depth or disparity does not match any of these values. The fact
that this distribution is usually learned indirectly through a regression loss
causes further problems in ambiguous regions around object boundaries. We
address these issues using a new neural network architecture that is capable of
outputting arbitrary depth values, and a new loss function that is derived from
the Wasserstein distance between the true and the predicted distributions. We
validate our approach on a variety of tasks, including stereo disparity and
depth estimation, and the downstream 3D object detection. Our approach
drastically reduces the error in ambiguous regions, especially around object
boundaries that greatly affect the localization of objects in 3D, achieving the
state-of-the-art in 3D object detection for autonomous driving. Our code will
be available at https://github.com/Div99/W-Stereo-Disp.
</dc:description>
 <dc:description>Comment: Accepted to NeurIPS 2020 (spotlight)</dc:description>
 <dc:date>2020-07-06</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.03085</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.03097</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FleCSPH: The Next Generation FleCSIble Parallel Computational
  Infrastructure for Smoothed Particle Hydrodynamics</dc:title>
 <dc:creator>Loiseau, Julien</dc:creator>
 <dc:creator>Lim, Hyun</dc:creator>
 <dc:creator>Kaltenborn, Mark Alexander</dc:creator>
 <dc:creator>Korobkin, Oleg</dc:creator>
 <dc:creator>Mauney, Christopher M.</dc:creator>
 <dc:creator>Sagert, Irina</dc:creator>
 <dc:creator>Even, Wesley P.</dc:creator>
 <dc:creator>Bergen, Benjamin K.</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  FleCSPH is a smoothed particle hydrodynamics simulation tool, based on the
compile-time configurable framework FleCSI. The asynchronous distributed tree
topology combined with a fast multipole method allows FleCSPH to efficiently
compute hydrodynamics and long range particle-particle interactions. FleCSPH
provides initial data generators, particle relaxation techniques, and standard
evolution drivers, which can be easily modified and extended to user-specific
setups. Data input/output uses the H5part format, compatible with modern
visualization software.
</dc:description>
 <dc:date>2020-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.03097</dc:identifier>
 <dc:identifier>doi:10.1016/j.softx.2020.100602</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.03513</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distance-Geometric Graph Convolutional Network (DG-GCN) for
  Three-Dimensional (3D) Graphs</dc:title>
 <dc:creator>Chang, Daniel T.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The distance-geometric graph representation adopts a unified scheme
(distance) for representing the geometry of three-dimensional(3D) graphs. It is
invariant to rotation and translation of the graph and it reflects pair-wise
node interactions and their generally local nature. To facilitate the
incorporation of geometry in deep learning on 3D graphs, we propose a
message-passing graph convolutional network based on the distance-geometric
graph representation: DG-GCN (distance-geometric graph convolution network). It
utilizes continuous-filter convolutional layers, with filter-generating
networks, that enable learning of filter weights from distances, thereby
incorporating the geometry of 3D graphs in graph convolutions. Our results for
the ESOL and FreeSolv datasets show major improvement over those of standard
graph convolutions. They also show significant improvement over those of
geometric graph convolutions employing edge weight / edge distance power laws.
Our work demonstrates the utility and value of DG-GCN for end-to-end deep
learning on 3D graphs, particularly molecular graphs.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:2006.01785</dc:description>
 <dc:date>2020-07-06</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.03513</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.03574</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Provably Safe PAC-MDP Exploration Using Analogies</dc:title>
 <dc:creator>Roderick, Melrose</dc:creator>
 <dc:creator>Nagarajan, Vaishnavh</dc:creator>
 <dc:creator>Kolter, J. Zico</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A key challenge in applying reinforcement learning to safety-critical domains
is understanding how to balance exploration (needed to attain good performance
on the task) with safety (needed to avoid catastrophic failure). Although a
growing line of work in reinforcement learning has investigated this area of
&quot;safe exploration,&quot; most existing techniques either 1) do not guarantee safety
during the actual exploration process; and/or 2) limit the problem to a priori
known and/or deterministic transition dynamics with strong smoothness
assumptions. Addressing this gap, we propose Analogous Safe-state Exploration
(ASE), an algorithm for provably safe exploration in MDPs with unknown,
stochastic dynamics. Our method exploits analogies between state-action pairs
to safely learn a near-optimal policy in a PAC-MDP sense. Additionally, ASE
also guides exploration towards the most task-relevant states, which
empirically results in significant improvements in terms of sample efficiency,
when compared to existing methods.
</dc:description>
 <dc:description>Comment: 10 pages, 3 figures, In proceedings of the 24th International
  Conference on Artificial Intelligence and Statistics (AISTATS) 2021</dc:description>
 <dc:date>2020-07-07</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.03574</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.03758</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep learning of thermodynamics-aware reduced-order models from data</dc:title>
 <dc:creator>Hernandez, Quercus</dc:creator>
 <dc:creator>Badias, Alberto</dc:creator>
 <dc:creator>Gonzalez, David</dc:creator>
 <dc:creator>Chinesta, Francisco</dc:creator>
 <dc:creator>Cueto, Elias</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present an algorithm to learn the relevant latent variables of a
large-scale discretized physical system and predict its time evolution using
thermodynamically-consistent deep neural networks. Our method relies on sparse
autoencoders, which reduce the dimensionality of the full order model to a set
of sparse latent variables with no prior knowledge of the coded space
dimensionality. Then, a second neural network is trained to learn the
metriplectic structure of those reduced physical variables and predict its time
evolution with a so-called structure-preserving neural network. This data-based
integrator is guaranteed to conserve the total energy of the system and the
entropy inequality, and can be applied to both conservative and dissipative
systems. The integrated paths can then be decoded to the original
full-dimensional manifold and be compared to the ground truth solution. This
method is tested with two examples applied to fluid and solid mechanics.
</dc:description>
 <dc:description>Comment: 17 pages, 7 figures</dc:description>
 <dc:date>2020-07-03</dc:date>
 <dc:date>2021-03-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.03758</dc:identifier>
 <dc:identifier>doi:10.1016/j.cma.2021.113763</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.03794</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stability in Repeated Matching Markets</dc:title>
 <dc:creator>Liu, Ce</dc:creator>
 <dc:subject>Economics - Theoretical Economics</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  This paper develops a framework for repeated matching markets. The model
departs from the Gale-Shapley matching model by having a fixed set of
long-lived hospitals match with a new generation of short-lived residents in
every period. I show that there are two kinds of hospitals in this repeated
environment: some hospitals can be motivated dynamically to voluntarily reduce
their hiring capacity, potentially making more residents available to rural
hospitals; the others, however, are untouchable even with repeated interaction
and must obtain the same match as they do in a static matching. In large
matching markets with correlated preferences, at most a vanishingly small
fraction of the hospitals are untouchable. The vast majority of hospitals can
be motivated using dynamic incentives.
</dc:description>
 <dc:date>2020-07-07</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.03794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.03887</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Camera Pose Matters: Improving Depth Prediction by Mitigating Pose
  Distribution Bias</dc:title>
 <dc:creator>Zhao, Yunhan</dc:creator>
 <dc:creator>Kong, Shu</dc:creator>
 <dc:creator>Fowlkes, Charless</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Monocular depth predictors are typically trained on large-scale training sets
which are naturally biased w.r.t the distribution of camera poses. As a result,
trained predictors fail to make reliable depth predictions for testing examples
captured under uncommon camera poses. To address this issue, we propose two
novel techniques that exploit the camera pose during training and prediction.
First, we introduce a simple perspective-aware data augmentation that
synthesizes new training examples with more diverse views by perturbing the
existing ones in a geometrically consistent manner. Second, we propose a
conditional model that exploits the per-image camera pose as prior knowledge by
encoding it as a part of the input. We show that jointly applying the two
methods improves depth prediction on images captured under uncommon and even
never-before-seen camera poses. We show that our methods improve performance
when applied to a range of different predictor architectures. Lastly, we show
that explicitly encoding the camera pose distribution improves the
generalization performance of a synthetically trained depth predictor when
evaluated on real images.
</dc:description>
 <dc:description>Comment: Accepted at CVPR2021, Oral</dc:description>
 <dc:date>2020-07-08</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.03887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.04159</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The uncertainty principle over finite fields</dc:title>
 <dc:creator>Borello, Martino</dc:creator>
 <dc:creator>Sol&#xe9;, Patrick</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we study the uncertainty principle (UP) connecting a function
over a finite field and its Mattson-Solomon polynomial, which is a kind of
Fourier transform in positive characteristic. Three versions of the UP over
finite fields are studied, in connection with the asymptotic theory of cyclic
codes. We first show that no finite field satisfies the strong version of UP,
introduced recently by Evra, Kowalsky, Lubotzky, 2017. A refinement of the weak
version is given, by using the asymptotic Plotkin bound. A naive version, which
is the direct analogue over finite fields of the Donoho-Stark bound over the
complex numbers, is proved by using the BCH bound. It is strong enough to show
that there exist sequences of cyclic codes of length $n$, arbitrary rate, and
minimum distance $\Omega(n^\alpha)$ for all $0&lt;\alpha&lt;1/2$. Finally, a
connection with Ramsey Theory is pointed out.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2020-07-08</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.04159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.04451</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online probabilistic label trees</dc:title>
 <dc:creator>Jasinska-Kobus, Kalina</dc:creator>
 <dc:creator>Wydmuch, Marek</dc:creator>
 <dc:creator>Thiruvenkatachari, Devanathan</dc:creator>
 <dc:creator>Dembczy&#x144;ski, Krzysztof</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We introduce online probabilistic label trees (OPLTs), an algorithm that
trains a label tree classifier in a fully online manner without any prior
knowledge about the number of training instances, their features and labels.
OPLTs are characterized by low time and space complexity as well as strong
theoretical guarantees. They can be used for online multi-label and multi-class
classification, including the very challenging scenarios of one- or few-shot
learning. We demonstrate the attractiveness of OPLTs in a wide empirical study
on several instances of the tasks mentioned above.
</dc:description>
 <dc:description>Comment: Accepted at AISTATS 2021</dc:description>
 <dc:date>2020-07-08</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.04451</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.04645</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Switch CNNs with Model Agnostic Meta Learning for Fine
  Precision Visual Servoing</dc:title>
 <dc:creator>Raj, Prem</dc:creator>
 <dc:creator>Namboodiri, Vinay P.</dc:creator>
 <dc:creator>Behera, L.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional Neural Networks (CNNs) have been successfully applied for
relative camera pose estimation from labeled image-pair data, without requiring
any hand-engineered features, camera intrinsic parameters or depth information.
The trained CNN can be utilized for performing pose based visual servo control
(PBVS). One of the ways to improve the quality of visual servo output is to
improve the accuracy of the CNN for estimating the relative pose estimation.
With a given state-of-the-art CNN for relative pose regression, how can we
achieve an improved performance for visual servo control? In this paper, we
explore switching of CNNs to improve the precision of visual servo control. The
idea of switching a CNN is due to the fact that the dataset for training a
relative camera pose regressor for visual servo control must contain variations
in relative pose ranging from a very small scale to eventually a larger scale.
We found that, training two different instances of the CNN, one for
large-scale-displacements (LSD) and another for small-scale-displacements (SSD)
and switching them during the visual servo execution yields better results than
training a single CNN with the combined LSD+SSD data. However, it causes extra
storage overhead and switching decision is taken by a manually set threshold
which may not be optimal for all the scenes. To eliminate these drawbacks, we
propose an efficient switching strategy based on model agnostic meta learning
(MAML) algorithm. In this, a single model is trained to learn parameters which
are simultaneously good for multiple tasks, namely a binary classification for
switching decision, a 6DOF pose regression for LSD data and also a 6DOF pose
regression for SSD data. The proposed approach performs far better than the
naive approach, while storage and run-time overheads are almost negligible.
</dc:description>
 <dc:description>Comment: Accepted in IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS-2020). For video visit - https://youtu.be/GSG20lmWDUo</dc:description>
 <dc:date>2020-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.04645</dc:identifier>
 <dc:identifier>2020 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS), 10210-10217</dc:identifier>
 <dc:identifier>doi:10.1109/IROS45743.2020.9341756</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.04760</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human-Computer Interaction Considerations When Developing Cyber Ranges</dc:title>
 <dc:creator>Shepherd, Lynsay A.</dc:creator>
 <dc:creator>De Paoli, Stefano</dc:creator>
 <dc:creator>Conacher, Jim</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  The number of cyber-attacks are continuing to rise globally. It is therefore
vital for organisations to develop the necessary skills to secure their assets
and to protect critical national infrastructure. In this short paper, we
outline upon human-computer interaction elements which should be considered
when developing a cybersecurity training platform, in an effort to maintain
levels of user engagement. We provide an overview of existing training
platforms before covering specialist cyber ranges. Aspects of human-computer
interaction are noted with regards to their relevance in the context of cyber
ranges. We conclude with design suggestions when developing a cyber range
platform.
</dc:description>
 <dc:description>Comment: 5 pages, short discussion paper</dc:description>
 <dc:date>2020-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.04760</dc:identifier>
 <dc:identifier>2020 International Journal of Information Security and Cybercrime
  9(2), pp.28-32</dc:identifier>
 <dc:identifier>doi:10.19107/IJISC.2020.02.04</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.05663</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quasi-Periodic WaveNet: An Autoregressive Raw Waveform Generative Model
  with Pitch-dependent Dilated Convolution Neural Network</dc:title>
 <dc:creator>Wu, Yi-Chiao</dc:creator>
 <dc:creator>Hayashi, Tomoki</dc:creator>
 <dc:creator>Tobing, Patrick Lumban</dc:creator>
 <dc:creator>Kobayashi, Kazuhiro</dc:creator>
 <dc:creator>Toda, Tomoki</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  In this paper, a pitch-adaptive waveform generative model named
Quasi-Periodic WaveNet (QPNet) is proposed to improve the limited pitch
controllability of vanilla WaveNet (WN) using pitch-dependent dilated
convolution neural networks (PDCNNs). Specifically, as a probabilistic
autoregressive generation model with stacked dilated convolution layers, WN
achieves high-fidelity audio waveform generation. However, the pure-data-driven
nature and the lack of prior knowledge of audio signals degrade the pitch
controllability of WN. For instance, it is difficult for WN to precisely
generate the periodic components of audio signals when the given auxiliary
fundamental frequency ($F_{0}$) features are outside the $F_{0}$ range observed
in the training data. To address this problem, QPNet with two novel designs is
proposed. First, the PDCNN component is applied to dynamically change the
network architecture of WN according to the given auxiliary $F_{0}$ features.
Second, a cascaded network structure is utilized to simultaneously model the
long- and short-term dependencies of quasi-periodic signals such as speech. The
performances of single-tone sinusoid and speech generations are evaluated. The
experimental results show the effectiveness of the PDCNNs for unseen auxiliary
$F_{0}$ features and the effectiveness of the cascaded structure for speech
generation.
</dc:description>
 <dc:description>Comment: 15 pages, 12 figures, 11 tables</dc:description>
 <dc:date>2020-07-10</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.05663</dc:identifier>
 <dc:identifier>IEEE/ACM Transactions on Audio, Speech, and Language Processing,
  vol. 29, pp. 1134-1148, 2021</dc:identifier>
 <dc:identifier>doi:10.1109/TASLP.2021.3061245</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.06705</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised object-centric video generation and decomposition in 3D</dc:title>
 <dc:creator>Henderson, Paul</dc:creator>
 <dc:creator>Lampert, Christoph H.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A natural approach to generative modeling of videos is to represent them as a
composition of moving objects. Recent works model a set of 2D sprites over a
slowly-varying background, but without considering the underlying 3D scene that
gives rise to them. We instead propose to model a video as the view seen while
moving through a scene with multiple 3D objects and a 3D background. Our model
is trained from monocular videos without any supervision, yet learns to
generate coherent 3D scenes containing several moving objects. We conduct
detailed experiments on two datasets, going beyond the visual complexity
supported by state-of-the-art generative approaches. We evaluate our method on
depth-prediction and 3D object detection -- tasks which cannot be addressed by
those earlier works -- and show it out-performs them even on 2D instance
segmentation and tracking.
</dc:description>
 <dc:description>Comment: Appeared at NeurIPS 2020. Project page: http://pmh47.net/o3v/</dc:description>
 <dc:date>2020-07-07</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.06705</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.07375</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Concept Learners for Few-Shot Learning</dc:title>
 <dc:creator>Cao, Kaidi</dc:creator>
 <dc:creator>Brbic, Maria</dc:creator>
 <dc:creator>Leskovec, Jure</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Developing algorithms that are able to generalize to a novel task given only
a few labeled examples represents a fundamental challenge in closing the gap
between machine- and human-level performance. The core of human cognition lies
in the structured, reusable concepts that help us to rapidly adapt to new tasks
and provide reasoning behind our decisions. However, existing meta-learning
methods learn complex representations across prior labeled tasks without
imposing any structure on the learned representations. Here we propose COMET, a
meta-learning method that improves generalization ability by learning to learn
along human-interpretable concept dimensions. Instead of learning a joint
unstructured metric space, COMET learns mappings of high-level concepts into
semi-structured metric spaces, and effectively combines the outputs of
independent concept learners. We evaluate our model on few-shot tasks from
diverse domains, including fine-grained image classification, document
categorization and cell type annotation on a novel dataset from a biological
domain developed in our work. COMET significantly outperforms strong
meta-learning baselines, achieving 6-15% relative improvement on the most
challenging 1-shot learning tasks, while unlike existing methods providing
interpretations behind the model's predictions.
</dc:description>
 <dc:description>Comment: Published at ICLR 2021</dc:description>
 <dc:date>2020-07-14</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.07375</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.07788</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CANet: Context Aware Network for 3D Brain Glioma Segmentation</dc:title>
 <dc:creator>Liu, Zhihua</dc:creator>
 <dc:creator>Tong, Lei</dc:creator>
 <dc:creator>Chen, Long</dc:creator>
 <dc:creator>Zhou, Feixiang</dc:creator>
 <dc:creator>Jiang, Zheheng</dc:creator>
 <dc:creator>Zhang, Qianni</dc:creator>
 <dc:creator>Wang, Yinhai</dc:creator>
 <dc:creator>Shan, Caifeng</dc:creator>
 <dc:creator>Li, Ling</dc:creator>
 <dc:creator>Zhou, Huiyu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automated segmentation of brain glioma plays an active role in diagnosis
decision, progression monitoring and surgery planning. Based on deep neural
networks, previous studies have shown promising technologies for brain glioma
segmentation. However, these approaches lack powerful strategies to incorporate
contextual information of tumor cells and their surrounding, which has been
proven as a fundamental cue to deal with local ambiguity. In this work, we
propose a novel approach named Context-Aware Network (CANet) for brain glioma
segmentation. CANet captures high dimensional and discriminative features with
contexts from both the convolutional space and feature interaction graphs. We
further propose context guided attentive conditional random fields which can
selectively aggregate features. We evaluate our method using publicly
accessible brain glioma segmentation datasets BRATS2017, BRATS2018 and
BRATS2019. The experimental results show that the proposed algorithm has better
or competitive performance against several State-of-The-Art approaches under
different segmentation metrics on the training and validation sets.
</dc:description>
 <dc:date>2020-07-15</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.07788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.07994</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximating the (Continuous) Fr\'echet Distance</dc:title>
 <dc:creator>Colombe, Connor</dc:creator>
 <dc:creator>Fox, Kyle</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We describe the first strongly subquadratic time algorithm with
subexponential approximation ratio for approximately computing the Fr\'echet
distance between two polygonal chains. Specifically, let $P$ and $Q$ be two
polygonal chains with $n$ vertices in $d$-dimensional Euclidean space, and let
$\alpha \in [\sqrt{n}, n]$. Our algorithm deterministically finds an
$O(\alpha)$-approximate Fr\'echet correspondence in time $O((n^3 / \alpha^2)
\log n)$. In particular, we get an $O(n)$-approximation in near-linear $O(n
\log n)$ time, a vast improvement over the previously best know result, a
linear time $2^{O(n)}$-approximation. As part of our algorithm, we also
describe how to turn any approximate decision procedure for the Fr\'echet
distance into an approximate optimization algorithm whose approximation ratio
is the same up to arbitrarily small constant factors. The transformation into
an approximate optimization algorithm increases the running time of the
decision procedure by only an $O(\log n)$ factor.
</dc:description>
 <dc:description>Comment: To appear in SoCG 2021</dc:description>
 <dc:date>2020-07-15</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.07994</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.08004</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data augmentation enhanced speaker enrollment for text-dependent speaker
  verification</dc:title>
 <dc:creator>Sarkar, Achintya Kumar</dc:creator>
 <dc:creator>Sarma, Himangshu</dc:creator>
 <dc:creator>Dwivedi, Priyanka</dc:creator>
 <dc:creator>Tan, Zheng-Hua</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Data augmentation is commonly used for generating additional data from the
available training data to achieve a robust estimation of the parameters of
complex models like the one for speaker verification (SV), especially for
under-resourced applications. SV involves training speaker-independent (SI)
models and speaker-dependent models where speakers are represented by models
derived from an SI model using the training data for the particular speaker
during the enrollment phase. While data augmentation for training SI models is
well studied, data augmentation for speaker enrollment is rarely explored. In
this paper, we propose the use of data augmentation methods for generating
extra data to empower speaker enrollment. Each data augmentation method
generates a new data set. Two strategies of using the data sets are explored:
the first one is to training separate systems and fuses them at the score level
and the other is to conduct multi-conditional training. Furthermore, we study
the effect of data augmentation under noisy conditions. Experiments are
performed on RedDots challenge 2016 database, and the results validate the
effectiveness of the proposed methods.
</dc:description>
 <dc:date>2020-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.08004</dc:identifier>
 <dc:identifier>Proc. of ICEPE 2020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.08480</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Co-Attention for Conditioned Image Matching</dc:title>
 <dc:creator>Wiles, Olivia</dc:creator>
 <dc:creator>Ehrhardt, Sebastien</dc:creator>
 <dc:creator>Zisserman, Andrew</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a new approach to determine correspondences between image pairs in
the wild under large changes in illumination, viewpoint, context, and material.
While other approaches find correspondences between pairs of images by treating
the images independently, we instead condition on both images to implicitly
take account of the differences between them. To achieve this, we introduce (i)
a spatial attention mechanism (a co-attention module, CoAM) for conditioning
the learned features on both images, and (ii) a distinctiveness score used to
choose the best matches at test time. CoAM can be added to standard
architectures and trained using self-supervision or supervised data, and
achieves a significant performance improvement under hard conditions, e.g.
large viewpoint changes. We demonstrate that models using CoAM achieve state of
the art or competitive results on a wide range of tasks: local matching, camera
localization, 3D reconstruction, and image stylization.
</dc:description>
 <dc:description>Comment: Accepted at CVPR 2021. Project page:
  https://www.robots.ox.ac.uk/~ow/coam.html. Formerly D2D: Learning to find
  good correspondences for image matching and manipulation</dc:description>
 <dc:date>2020-07-16</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.08480</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.08558</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Robustness and Transferability of Convolutional Neural Networks</dc:title>
 <dc:creator>Djolonga, Josip</dc:creator>
 <dc:creator>Yung, Jessica</dc:creator>
 <dc:creator>Tschannen, Michael</dc:creator>
 <dc:creator>Romijnders, Rob</dc:creator>
 <dc:creator>Beyer, Lucas</dc:creator>
 <dc:creator>Kolesnikov, Alexander</dc:creator>
 <dc:creator>Puigcerver, Joan</dc:creator>
 <dc:creator>Minderer, Matthias</dc:creator>
 <dc:creator>D'Amour, Alexander</dc:creator>
 <dc:creator>Moldovan, Dan</dc:creator>
 <dc:creator>Gelly, Sylvain</dc:creator>
 <dc:creator>Houlsby, Neil</dc:creator>
 <dc:creator>Zhai, Xiaohua</dc:creator>
 <dc:creator>Lucic, Mario</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Modern deep convolutional networks (CNNs) are often criticized for not
generalizing under distributional shifts. However, several recent breakthroughs
in transfer learning suggest that these networks can cope with severe
distribution shifts and successfully adapt to new tasks from a few training
examples. In this work we study the interplay between out-of-distribution and
transfer performance of modern image classification CNNs for the first time and
investigate the impact of the pre-training data size, the model scale, and the
data preprocessing pipeline. We find that increasing both the training set and
model sizes significantly improve the distributional shift robustness.
Furthermore, we show that, perhaps surprisingly, simple changes in the
preprocessing such as modifying the image resolution can significantly mitigate
robustness issues in some cases. Finally, we outline the shortcomings of
existing robustness evaluation datasets and introduce a synthetic dataset
SI-Score we use for a systematic analysis across factors of variation common in
visual data such as object size and position.
</dc:description>
 <dc:description>Comment: Accepted at CVPR 2021</dc:description>
 <dc:date>2020-07-16</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.08558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.08705</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Verbal Focus-of-Attention System for Learning-from-Observation</dc:title>
 <dc:creator>Wake, Naoki</dc:creator>
 <dc:creator>Yanokura, Iori</dc:creator>
 <dc:creator>Sasabuchi, Kazuhiro</dc:creator>
 <dc:creator>Ikeuchi, Katsushi</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  The learning-from-observation (LfO) framework aims to map human
demonstrations to a robot to reduce programming effort. To this end, an LfO
system encodes a human demonstration into a series of execution units for a
robot, which are referred to as task models. Although previous research has
proposed successful task-model encoders, there has been little discussion on
how to guide a task-model encoder in a scene with spatio-temporal noises, such
as cluttered objects or unrelated human body movements. Inspired by the
function of verbal instructions guiding an observer's visual attention, we
propose a verbal focus-of-attention (FoA) system (i.e., spatio-temporal
filters) to guide a task-model encoder. For object manipulation, the system
first recognizes the name of a target object and its attributes from verbal
instructions. The information serves as a where-to-look FoA filter to confine
the areas in which the target object existed in the demonstration. The system
then detects the timings of grasp and release that occurred in the filtered
areas. The timings serve as a when-to-look FoA filter to confine the period of
object manipulation. Finally, a task-model encoder recognizes the task models
by employing FoA filters. We demonstrate the robustness of the verbal FoA in
attenuating spatio-temporal noises by comparing it with an existing action
localization network. The contributions of this study are as follows: (1) to
propose a verbal FoA for LfO, (2) to design an algorithm to calculate FoA
filters from verbal input, and (3) to demonstrate the effectiveness of a verbal
FoA in localizing an action by comparing it with a state-of-the-art vision
system.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures. Submitted to and accepted by IEEE ICRA 2021. Last
  updated March 3rd, 2021</dc:description>
 <dc:date>2020-07-16</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.08705</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.09619</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Online-Offline Method for Elliptic Homogenization Problems</dc:title>
 <dc:creator>Huang, Yufang</dc:creator>
 <dc:creator>Ming, Pingbing</dc:creator>
 <dc:creator>Song, Siqi</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We present a new numerical method for solving the elliptic homogenization
problem. The main idea is that the missing effective matrix is reconstructed by
solving the local least-squares in an offline stage, which shall be served as
the input data for the online computation. The accuracy of the proposed method
are analyzed with the aid of the refined estimates of the reconstruction
operator. Two dimensional and three dimensional numerical tests confirm the
efficiency of the proposed method, and illustrate that this online-offline
strategy may significantly reduce the cost without loss of accuracy.
</dc:description>
 <dc:date>2020-07-19</dc:date>
 <dc:date>2020-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.09619</dc:identifier>
 <dc:identifier>doi:10.4208/csiam-am.2020-0035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.09682</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Twitter and Facebook posts about COVID-19 are less likely to spread
  false and low-credibility content compared to other health topics</dc:title>
 <dc:creator>Broniatowski, David A.</dc:creator>
 <dc:creator>Kerchner, Daniel</dc:creator>
 <dc:creator>Farooq, Fouzia</dc:creator>
 <dc:creator>Huang, Xiaolei</dc:creator>
 <dc:creator>Jamison, Amelia M.</dc:creator>
 <dc:creator>Dredze, Mark</dc:creator>
 <dc:creator>Quinn, Sandra Crouse</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  On February 2, 2020, the World Health Organization declared a COVID-19 social
media &quot;infodemic&quot;, with special attention to misinformation -- frequently
understood as false claims. To understand the infodemic's scope and scale, we
analyzed over 500 million posts from Twitter and Facebook about COVID-19 and
other health topics, between March 8 and May 1, 2020. Following prior work, we
assumed URL source credibility is a proxy for false content, but we also tested
this assumption. Contrary to expectations, we found that messages about
COVID-19 were more likely to contain links to more credible sources.
Additionally, messages linking to government sources, and to news with
intermediate credibility, were shared more often, on average, than links to
non-credible sources. These results suggest that more ambiguous forms of
misinformation about COVID-19 may be more likely to be disseminated through
credible sources when compared to other health topics. Furthermore, the
assumption that credibility is an adequate proxy for false content may
overestimate the prevalence of false content online: less than 25% of posts
linking to the least credible sources contained false content. Our results
emphasize the importance of distinguishing between explicit falsehoods and more
ambiguous forms of misinformation due to the search for meaning in an
environment of scientific uncertainty.
</dc:description>
 <dc:date>2020-07-19</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.09682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.09773</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shortest Secure Path in a Voronoi Diagram</dc:title>
 <dc:creator>Har-Peled, Sariel</dc:creator>
 <dc:creator>Varadharajan, Rajgopal</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We investigate the problem of computing the shortest secure path in a Voronoi
diagram. Here, a path is secure if it is a sequence of touching Voronoi cells,
where each Voronoi cell in the path has a uniform cost of being secured.
Importantly, we allow inserting new sites, which in some cases leads to
significantly shorter paths. We present an $O(n \log n)$ time algorithm for
solving this problem in the plane, which uses a dynamic additive weighted
Voronoi diagram to compute this path. The algorithm is an interesting
combination of the continuous and discrete Dijkstra algorithms. We also
implemented the algorithm using CGAL.
</dc:description>
 <dc:date>2020-07-19</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.09773</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.10013</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resource Allocation in Virtualized CoMP-NOMA HetNets: Multi-Connectivity
  for Joint Transmission</dc:title>
 <dc:creator>Rezvani, Sepehr</dc:creator>
 <dc:creator>Mokari, Nader</dc:creator>
 <dc:creator>Javan, Mohammad R.</dc:creator>
 <dc:creator>Jorswieck, Eduard A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>90C11</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  In this work, we design a generalized joint transmission coordinated
multi-point (JT-CoMP)-non-orthogonal multiple access (NOMA) model for a
virtualized multi-infrastructure network. In this model, all users benefit from
multiple joint transmissions of CoMP thanks to the multi-connectivity
opportunity provided by wireless network virtualization (WNV) in
multi-infrastructure networks. The NOMA protocol in CoMP results in an
unlimited NOMA clustering (UNC) scheme, where the order of each NOMA cluster is
the maximum possible value. We show that UNC results in maximum successful
interference cancellation (SIC) complexity at users. In this regard, we propose
a limited NOMA clustering (LNC) scheme, where the SIC is performed to only a
subset of users. We formulate the problem of joint power allocation and user
association for the UNC and LNC schemes. Then, one globally and one locally
optimal solution are proposed for each problem based on mixed-integer monotonic
optimization and sequential programming, respectively. Numerical assessments
reveal that WNV and LNC improves users sum-rate and reduces users SIC
complexity by up to $35\%$ and $46\%$ compared to the non-virtualized CoMP-NOMA
system and UNC model, respectively. Therefore, the proposed algorithms are
suitable candidates for the implementation on open and intelligent radio access
networks.
</dc:description>
 <dc:description>Comment: 54 pages, 11 figures, submitted to IEEE Transactions on
  Communications (TCOM)</dc:description>
 <dc:date>2020-07-20</dc:date>
 <dc:date>2021-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.10013</dc:identifier>
 <dc:identifier>IEEE Transactions on Communications, 22 March 2021</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2021.3067700</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.11718</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Safety-Critical Model Predictive Control with Discrete-Time Control
  Barrier Function</dc:title>
 <dc:creator>Zeng, Jun</dc:creator>
 <dc:creator>Zhang, Bike</dc:creator>
 <dc:creator>Sreenath, Koushil</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The optimal performance of robotic systems is usually achieved near the limit
of state and input bounds. Model predictive control (MPC) is a prevalent
strategy to handle these operational constraints, however, safety still remains
an open challenge for MPC as it needs to guarantee that the system stays within
an invariant set. In order to obtain safe optimal performance in the context of
set invariance, we present a safety-critical model predictive control strategy
utilizing discrete-time control barrier functions (CBFs), which guarantees
system safety and accomplishes optimal performance via model predictive
control. We analyze the stability and the feasibility properties of our control
design. We verify the properties of our method on a 2D double integrator model
for obstacle avoidance. We also validate the algorithm numerically using a
competitive car racing example, where the ego car is able to overtake other
racing cars.
</dc:description>
 <dc:date>2020-07-22</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.11718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.11934</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Private Post-GAN Boosting</dc:title>
 <dc:creator>Neunhoeffer, Marcel</dc:creator>
 <dc:creator>Wu, Zhiwei Steven</dc:creator>
 <dc:creator>Dwork, Cynthia</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Differentially private GANs have proven to be a promising approach for
generating realistic synthetic data without compromising the privacy of
individuals. Due to the privacy-protective noise introduced in the training,
the convergence of GANs becomes even more elusive, which often leads to poor
utility in the output generator at the end of training. We propose Private
post-GAN boosting (Private PGB), a differentially private method that combines
samples produced by the sequence of generators obtained during GAN training to
create a high-quality synthetic dataset. To that end, our method leverages the
Private Multiplicative Weights method (Hardt and Rothblum, 2010) to reweight
generated samples. We evaluate Private PGB on two dimensional toy data, MNIST
images, US Census data and a standard machine learning prediction task. Our
experiments show that Private PGB improves upon a standard private GAN approach
across a collection of quality measures. We also provide a non-private variant
of PGB that improves the data quality of standard GAN training.
</dc:description>
 <dc:date>2020-07-23</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.11934</dc:identifier>
 <dc:identifier>International Conference on Learning Representations, 2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.12101</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Differentiable Programs with Admissible Neural Heuristics</dc:title>
 <dc:creator>Shah, Ameesh</dc:creator>
 <dc:creator>Zhan, Eric</dc:creator>
 <dc:creator>Sun, Jennifer J.</dc:creator>
 <dc:creator>Verma, Abhinav</dc:creator>
 <dc:creator>Yue, Yisong</dc:creator>
 <dc:creator>Chaudhuri, Swarat</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  We study the problem of learning differentiable functions expressed as
programs in a domain-specific language. Such programmatic models can offer
benefits such as composability and interpretability; however, learning them
requires optimizing over a combinatorial space of program &quot;architectures&quot;. We
frame this optimization problem as a search in a weighted graph whose paths
encode top-down derivations of program syntax. Our key innovation is to view
various classes of neural networks as continuous relaxations over the space of
programs, which can then be used to complete any partial program. This relaxed
program is differentiable and can be trained end-to-end, and the resulting
training loss is an approximately admissible heuristic that can guide the
combinatorial search. We instantiate our approach on top of the A-star
algorithm and an iteratively deepened branch-and-bound search, and use these
algorithms to learn programmatic classifiers in three sequence classification
tasks. Our experiments show that the algorithms outperform state-of-the-art
methods for program learning, and that they discover programmatic classifiers
that yield natural interpretations and achieve competitive accuracy.
</dc:description>
 <dc:description>Comment: 9 pages, published in NeurIPS 2020</dc:description>
 <dc:date>2020-07-23</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.12101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.12213</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Representation Theory of Neural Networks</dc:title>
 <dc:creator>Armenta, Marco Antonio</dc:creator>
 <dc:creator>Jodoin, Pierre-Marc</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Mathematics - Representation Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>16G20</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  In this work, we show that neural networks can be represented via the
mathematical theory of quiver representations. More specifically, we prove that
a neural network is a quiver representation with activation functions, a
mathematical object that we represent using a network quiver. Also, we show
that network quivers gently adapt to common neural network concepts such as
fully-connected layers, convolution operations, residual connections, batch
normalization, pooling operations and even randomly wired neural networks. We
show that this mathematical representation is by no means an approximation of
what neural networks are as it exactly matches reality. This interpretation is
algebraic and can be studied with algebraic methods. We also provide a quiver
representation model to understand how a neural network creates representations
from the data. We show that a neural network saves the data as quiver
representations, and maps it to a geometrical space called the moduli space,
which is given in terms of the underlying oriented graph of the network, i.e.,
its quiver. This results as a consequence of our defined objects and of
understanding how the neural network computes a prediction in a combinatorial
and algebraic way. Overall, representing neural networks through the quiver
representation theory leads to 9 consequences and 4 inquiries for future
research that we believe are of great interest to better understand what neural
networks are and how they work.
</dc:description>
 <dc:description>Comment: 52 pages</dc:description>
 <dc:date>2020-07-23</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.12213</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.12348</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Discovery of 3D Physical Objects from Video</dc:title>
 <dc:creator>Du, Yilun</dc:creator>
 <dc:creator>Smith, Kevin</dc:creator>
 <dc:creator>Ulman, Tomer</dc:creator>
 <dc:creator>Tenenbaum, Joshua</dc:creator>
 <dc:creator>Wu, Jiajun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We study the problem of unsupervised physical object discovery. While
existing frameworks aim to decompose scenes into 2D segments based off each
object's appearance, we explore how physics, especially object interactions,
facilitates disentangling of 3D geometry and position of objects from video, in
an unsupervised manner. Drawing inspiration from developmental psychology, our
Physical Object Discovery Network (POD-Net) uses both multi-scale pixel cues
and physical motion cues to accurately segment observable and partially
occluded objects of varying sizes, and infer properties of those objects. Our
model reliably segments objects on both synthetic and real scenes. The
discovered object properties can also be used to reason about physical events.
</dc:description>
 <dc:description>Comment: ICLR 2021; project webpage at http://yilundu.github.io/podnet</dc:description>
 <dc:date>2020-07-24</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.12348</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.13517</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evidence of Task-Independent Person-Specific Signatures in EEG using
  Subspace Techniques</dc:title>
 <dc:creator>Kumar, Mari Ganesh</dc:creator>
 <dc:creator>Narayanan, Shrikanth</dc:creator>
 <dc:creator>Sur, Mriganka</dc:creator>
 <dc:creator>Murthy, Hema A</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Electroencephalography (EEG) signals are promising as alternatives to other
biometrics owing to their protection against spoofing. Previous studies have
focused on capturing individual variability by analyzing
task/condition-specific EEG. This work attempts to model biometric signatures
independent of task/condition by normalizing the associated variance. Toward
this goal, the paper extends ideas from subspace-based text-independent speaker
recognition and proposes novel modifications for modeling multi-channel EEG
data. The proposed techniques assume that biometric information is present in
the entire EEG signal and accumulate statistics across time in a high
dimensional space. These high dimensional statistics are then projected to a
lower dimensional space where the biometric information is preserved. The lower
dimensional embeddings obtained using the proposed approach are shown to be
task-independent. The best subspace system identifies individuals with
accuracies of 86.4% and 35.9% on datasets with 30 and 920 subjects,
respectively, using just nine EEG channels. The paper also provides insights
into the subspace model's scalability to unseen tasks and individuals during
training and the number of channels needed for subspace modeling.
</dc:description>
 <dc:description>Comment: \copyright 2021 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works</dc:description>
 <dc:date>2020-07-27</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.13517</dc:identifier>
 <dc:identifier>IEEE Transactions on Information Forensics and Security, 2021</dc:identifier>
 <dc:identifier>doi:10.1109/TIFS.2021.3067998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.14035</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Risk-Averse MPC via Visual-Inertial Input and Recurrent Networks for
  Online Collision Avoidance</dc:title>
 <dc:creator>Schperberg, Alexander</dc:creator>
 <dc:creator>Chen, Kenny</dc:creator>
 <dc:creator>Tsuei, Stephanie</dc:creator>
 <dc:creator>Jewett, Michael</dc:creator>
 <dc:creator>Hooks, Joshua</dc:creator>
 <dc:creator>Soatto, Stefano</dc:creator>
 <dc:creator>Mehta, Ankur</dc:creator>
 <dc:creator>Hong, Dennis</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we propose an online path planning architecture that extends
the model predictive control (MPC) formulation to consider future location
uncertainties for safer navigation through cluttered environments. Our
algorithm combines an object detection pipeline with a recurrent neural network
(RNN) which infers the covariance of state estimates through each step of our
MPC's finite time horizon. The RNN model is trained on a dataset that comprises
of robot and landmark poses generated from camera images and inertial
measurement unit (IMU) readings via a state-of-the-art visual-inertial odometry
framework. To detect and extract object locations for avoidance, we use a
custom-trained convolutional neural network model in conjunction with a feature
extractor to retrieve 3D centroid and radii boundaries of nearby obstacles. The
robustness of our methods is validated on complex quadruped robot dynamics and
can be generally applied to most robotic platforms, demonstrating autonomous
behaviors that can plan fast and collision-free paths towards a goal point.
</dc:description>
 <dc:description>Comment: Accepted to the 2020 IEEE/RSJ International Conference on Intelligent
  Robots and Systems (IROS), Las Vegas, USA. First two authors contributed
  equally. For supplementary video, see
  https://www.youtube.com/watch?v=td4K55Tj-U8</dc:description>
 <dc:date>2020-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.14035</dc:identifier>
 <dc:identifier>doi:10.1109/IROS45743.2020.9341070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.14322</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Single-Letter Upper Bound on the Mismatch Capacity via Multicast
  Transmission</dc:title>
 <dc:creator>Somekh-Baruch, Anelia</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We introduce a new analysis technique to derive a single-letter upper bound
on the mismatch capacity of a stationary, single-user, memoryless channel with
a decoding metric $q$. Our bound is obtained by considering a multicast
transmission over a two-user broadcast channel with decoding metrics $q$ and
$\rho$ at the receivers, referred to as $(q,\rho)$-surely degraded. This
channel has the property that the intersection event of correct $q$-decoding of
receiver $1$ and erroneous $\rho$-decoding of receiver $2$ has zero probability
for any fixed-composition codebook of a certain composition $P$. Our bound
holds in the strong converse sense of an exponential decay of the probability
of correct decoding at rates above the bound. Further, we refine the proof and
present a bound that is at least as tight as that of any choice of $\rho$.
Several examples that demonstrate the strict improvement of our bound compared
to previous results are analyzed. Finally, we detect equivalence classes of
isomorphic channel-metric pairs $(W,q)$ that share the same mismatch capacity.
We prove that if the class contains a matched pair, then our bound is tight and
the mismatch capacity of the entire class is fully characterized and is equal
to the LM rate, which is achievable by random coding, and may be strictly lower
that the matched capacity.
</dc:description>
 <dc:description>Comment: This work was accepted (in part) for presentation at the Information
  Theory Workshop (ITW) 2020. Theorem 2 of the revised paper contains a
  potentially tighter bound compared to the former version, that does not
  depend on the metric $\rho$. The revised paper includes major editorial
  changes and rephrasing, enumerations have changed, examples were added</dc:description>
 <dc:date>2020-07-28</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.14322</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.14451</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Quantum versus Classical Learnability of Discrete Distributions</dc:title>
 <dc:creator>Sweke, Ryan</dc:creator>
 <dc:creator>Seifert, Jean-Pierre</dc:creator>
 <dc:creator>Hangleiter, Dominik</dc:creator>
 <dc:creator>Eisert, Jens</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Here we study the comparative power of classical and quantum learners for
generative modelling within the Probably Approximately Correct (PAC) framework.
More specifically we consider the following task: Given samples from some
unknown discrete probability distribution, output with high probability an
efficient algorithm for generating new samples from a good approximation of the
original distribution. Our primary result is the explicit construction of a
class of discrete probability distributions which, under the decisional
Diffie-Hellman assumption, is provably not efficiently PAC learnable by a
classical generative modelling algorithm, but for which we construct an
efficient quantum learner. This class of distributions therefore provides a
concrete example of a generative modelling problem for which quantum learners
exhibit a provable advantage over classical learning algorithms. In addition,
we discuss techniques for proving classical generative modelling hardness
results, as well as the relationship between the PAC learnability of Boolean
functions and the PAC learnability of discrete probability distributions.
</dc:description>
 <dc:description>Comment: Main theorem has been strengthened to provide a separation with
  respect to the TV-distance and an additional section on verification of
  learners has been included. Accepted in Quantum</dc:description>
 <dc:date>2020-07-28</dc:date>
 <dc:date>2021-03-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.14451</dc:identifier>
 <dc:identifier>Quantum 5, 417 (2021)</dc:identifier>
 <dc:identifier>doi:10.22331/q-2021-03-23-417</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.14812</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What My Motion tells me about Your Pose: A Self-Supervised Monocular 3D
  Vehicle Detector</dc:title>
 <dc:creator>Picron, C&#xe9;dric</dc:creator>
 <dc:creator>Chakravarty, Punarjay</dc:creator>
 <dc:creator>Roussel, Tom</dc:creator>
 <dc:creator>Tuytelaars, Tinne</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The estimation of the orientation of an observed vehicle relative to an
Autonomous Vehicle (AV) from monocular camera data is an important building
block in estimating its 6 DoF pose. Current Deep Learning based solutions for
placing a 3D bounding box around this observed vehicle are data hungry and do
not generalize well. In this paper, we demonstrate the use of monocular visual
odometry for the self-supervised fine-tuning of a model for orientation
estimation pre-trained on a reference domain. Specifically, while transitioning
from a virtual dataset (vKITTI) to nuScenes, we recover up to 70% of the
performance of a fully supervised method. We subsequently demonstrate an
optimization-based monocular 3D bounding box detector built on top of the
self-supervised vehicle orientation estimator without the requirement of
expensive labeled data. This allows 3D vehicle detection algorithms to be
self-trained from large amounts of monocular camera data from existing
commercial vehicle fleets.
</dc:description>
 <dc:description>Comment: ICRA 2021 (presentation)</dc:description>
 <dc:date>2020-07-29</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.14812</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.14928</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Development Cycle for Automated Self-Exploration of Robot Behaviors</dc:title>
 <dc:creator>Roehr, Thomas M.</dc:creator>
 <dc:creator>Harnack, Daniel</dc:creator>
 <dc:creator>W&#xf6;hrle, Hendrik</dc:creator>
 <dc:creator>Wiebe, Felix</dc:creator>
 <dc:creator>Schilling, Moritz</dc:creator>
 <dc:creator>Lima, Oscar</dc:creator>
 <dc:creator>Langosz, Malte</dc:creator>
 <dc:creator>Kumar, Shivesh</dc:creator>
 <dc:creator>Straube, Sirko</dc:creator>
 <dc:creator>Kirchner, Frank</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:description>  In this paper we introduce Q-Rock, a development cycle for the automated
self-exploration and qualification of robot behaviors. With Q-Rock, we suggest
a novel, integrative approach to automate robot development processes. Q-Rock
combines several machine learning and reasoning techniques to deal with the
increasing complexity in the design of robotic systems. The Q-Rock development
cycle consists of three complementary processes: (1) automated exploration of
capabilities that a given robotic hardware provides, (2) classification and
semantic annotation of these capabilities to generate more complex behaviors,
and (3) mapping between application requirements and available behaviors. These
processes are based on a graph-based representation of a robot's structure,
including hardware and software components. A central, scalable knowledge base
enables collaboration of robot designers including mechanical, electrical and
systems engineers, software developers and machine learning experts. In this
paper we formalize Q-Rock's integrative development cycle and highlight its
benefits with a proof-of-concept implementation and a use case demonstration.
</dc:description>
 <dc:description>Comment: 30 pages, 16 figures, 4 tables</dc:description>
 <dc:date>2020-07-29</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.14928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2007.15960</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Learning Universal Representations Across Languages</dc:title>
 <dc:creator>Wei, Xiangpeng</dc:creator>
 <dc:creator>Weng, Rongxiang</dc:creator>
 <dc:creator>Hu, Yue</dc:creator>
 <dc:creator>Xing, Luxi</dc:creator>
 <dc:creator>Yu, Heng</dc:creator>
 <dc:creator>Luo, Weihua</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recent studies have demonstrated the overwhelming advantage of cross-lingual
pre-trained models (PTMs), such as multilingual BERT and XLM, on cross-lingual
NLP tasks. However, existing approaches essentially capture the co-occurrence
among tokens through involving the masked language model (MLM) objective with
token-level cross entropy. In this work, we extend these approaches to learn
sentence-level representations and show the effectiveness on cross-lingual
understanding and generation. Specifically, we propose a Hierarchical
Contrastive Learning (HiCTL) method to (1) learn universal representations for
parallel sentences distributed in one or multiple languages and (2) distinguish
the semantically-related words from a shared cross-lingual vocabulary for each
sentence. We conduct evaluations on two challenging cross-lingual tasks, XTREME
and machine translation. Experimental results show that the HiCTL outperforms
the state-of-the-art XLM-R by an absolute gain of 4.2% accuracy on the XTREME
benchmark as well as achieves substantial improvements on both of the
high-resource and low-resource English-to-X translation tasks over strong
baselines.
</dc:description>
 <dc:description>Comment: Accepted to ICLR 2021</dc:description>
 <dc:date>2020-07-31</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2007.15960</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.00137</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MementoEmbed and Raintale for Web Archive Storytelling</dc:title>
 <dc:creator>Jones, Shawn M.</dc:creator>
 <dc:creator>Klein, Martin</dc:creator>
 <dc:creator>Weigle, Michele C.</dc:creator>
 <dc:creator>Nelson, Michael L.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3.7</dc:subject>
 <dc:subject>H.3.6</dc:subject>
 <dc:subject>H.3.4</dc:subject>
 <dc:description>  For traditional library collections, archivists can select a representative
sample from a collection and display it in a featured physical or digital
library space. Web archive collections may consist of thousands of archived
pages, or mementos. How should an archivist display this sample to drive
visitors to their collection? Search engines and social media platforms often
represent web pages as cards consisting of text snippets, titles, and images.
Web storytelling is a popular method for grouping these cards in order to
summarize a topic. Unfortunately, social media platforms are not archive-aware
and fail to consistently create a good experience for mementos. They also allow
no UI alterations for their cards. Thus, we created MementoEmbed to generate
cards for individual mementos and Raintale for creating entire stories that
archivists can export to a variety of formats.
</dc:description>
 <dc:description>Comment: 54 pages, 5 tables, 46 figures</dc:description>
 <dc:date>2020-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.00137</dc:identifier>
 <dc:identifier>Presented at the Web Archiving and Digital Libraries 2020 Workshop</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.00139</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SHARI -- An Integration of Tools to Visualize the Story of the Day</dc:title>
 <dc:creator>Jones, Shawn M.</dc:creator>
 <dc:creator>Nwala, Alexander C.</dc:creator>
 <dc:creator>Klein, Martin</dc:creator>
 <dc:creator>Weigle, Michele C.</dc:creator>
 <dc:creator>Nelson, Michael L.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3.7</dc:subject>
 <dc:subject>H.3.6</dc:subject>
 <dc:subject>H.3.4</dc:subject>
 <dc:description>  Tools such as Google News and Flipboard exist to convey daily news, but what
about the past? In this paper, we describe how to combine several existing
tools with web archive holdings to perform news analysis and visualization of
the &quot;biggest story&quot; for a given date. StoryGraph clusters news articles
together to identify a common news story. Hypercane leverages ArchiveNow to
store URLs produced by StoryGraph in web archives. Hypercane analyzes these
URLs to identify the most common terms, entities, and highest quality images
for social media storytelling. Raintale then uses the output of these tools to
produce a visualization of the news story for a given day. We name this process
SHARI (StoryGraph Hypercane ArchiveNow Raintale Integration).
</dc:description>
 <dc:description>Comment: 19 pages, 16 figures, 1 Table</dc:description>
 <dc:date>2020-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.00139</dc:identifier>
 <dc:identifier>Presented at the Web Archiving and Digital Libraries 2020 Workshop</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.00325</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bringing UMAP Closer to the Speed of Light with GPU Acceleration</dc:title>
 <dc:creator>Nolet, Corey J.</dc:creator>
 <dc:creator>Lafargue, Victor</dc:creator>
 <dc:creator>Raff, Edward</dc:creator>
 <dc:creator>Nanditale, Thejaswi</dc:creator>
 <dc:creator>Oates, Tim</dc:creator>
 <dc:creator>Zedlewski, John</dc:creator>
 <dc:creator>Patterson, Joshua</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The Uniform Manifold Approximation and Projection (UMAP) algorithm has become
widely popular for its ease of use, quality of results, and support for
exploratory, unsupervised, supervised, and semi-supervised learning. While many
algorithms can be ported to a GPU in a simple and direct fashion, such efforts
have resulted in inefficient and inaccurate versions of UMAP. We show a number
of techniques that can be used to make a faster and more faithful GPU version
of UMAP, and obtain speedups of up to 100x in practice. Many of these design
choices/lessons are general purpose and may inform the conversion of other
graph and manifold learning algorithms to use GPUs. Our implementation has been
made publicly available as part of the open source RAPIDS cuML library
(https://github.com/rapidsai/cuml).
</dc:description>
 <dc:date>2020-08-01</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.00325</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.00444</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Principles and Algorithms for Forecasting Groups of Time Series:
  Locality and Globality</dc:title>
 <dc:creator>Montero-Manso, Pablo</dc:creator>
 <dc:creator>Hyndman, Rob J</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Forecasting groups of time series is of increasing practical importance, e.g.
forecasting the demand for multiple products offered by a retailer or server
loads within a data center. The local approach to this problem considers each
time series separately and fits a function or model to each series. The global
approach fits a single function to all series. For groups of similar time
series, global methods outperform the more established local methods. However,
recent results show good performance of global models even in heterogeneous
datasets. This suggests a more general applicability of global methods,
potentially leading to more accurate tools and new scenarios to study.
  Formalizing the setting of forecasting a set of time series with local and
global methods, we provide the following contributions:
  1) Global methods are not more restrictive than local methods, both can
produce the same forecasts without any assumptions about similarity of the
series. Global models can succeed in a wider range of problems than previously
thought.
  2) Basic generalization bounds for local and global algorithms. The
complexity of local methods grows with the size of the set while it remains
constant for global methods. In large datasets, a global algorithm can afford
to be quite complex and still benefit from better generalization. These bounds
serve to clarify and support recent experimental results in the field, and
guide the design of new algorithms. For the class of autoregressive models,
this implies that global models can have much larger memory than local methods.
  3) In an extensive empirical study, purposely naive algorithms derived from
these principles, such as global linear models or deep networks result in
superior accuracy.
  In particular, global linear models can provide competitive accuracy with two
orders of magnitude fewer parameters than local methods.
</dc:description>
 <dc:description>Comment: version preprint IJF</dc:description>
 <dc:date>2020-08-02</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.00444</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.00853</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting the Humorousness of Tweets Using Gaussian Process Preference
  Learning</dc:title>
 <dc:creator>Miller, Tristan</dc:creator>
 <dc:creator>Dinh, Erik-L&#xe2;n Do</dc:creator>
 <dc:creator>Simpson, Edwin</dc:creator>
 <dc:creator>Gurevych, Iryna</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Most humour processing systems to date make at best discrete, coarse-grained
distinctions between the comical and the conventional, yet such notions are
better conceptualized as a broad spectrum. In this paper, we present a
probabilistic approach, a variant of Gaussian process preference learning
(GPPL), that learns to rank and rate the humorousness of short texts by
exploiting human preference judgments and automatically sourced linguistic
annotations. We apply our system, which is similar to one that had previously
shown good performance on English-language one-liners annotated with pairwise
humorousness annotations, to the Spanish-language data set of the
HAHA@IberLEF2019 evaluation campaign. We report system performance for the
campaign's two subtasks, humour detection and funniness score prediction, and
discuss some issues arising from the conversion between the numeric scores used
in the HAHA@IberLEF2019 data and the pairwise judgment annotations required for
our method.
</dc:description>
 <dc:description>Comment: 8 pages, 1 figure. A previous version of this paper was published as
  &quot;OFAI-UKP at HAHA@IberLEF2019: Predicting the Humorousness of Tweets Using
  Gaussian Process Preference Learning&quot; in the Proceedings of the Iberian
  Languages Evaluation Forum (IberLEF 2019), volume 2421 of CEUR Workshop
  Proceedings, pages 180-190, 2019</dc:description>
 <dc:date>2020-08-03</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.00853</dc:identifier>
 <dc:identifier>Procesamiento del Lenguaje Natural, 64:37-44, March 2020</dc:identifier>
 <dc:identifier>doi:10.26342/2020-64-4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.01352</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PDE-Driven Spatiotemporal Disentanglement</dc:title>
 <dc:creator>Don&#xe0;, J&#xe9;r&#xe9;mie</dc:creator>
 <dc:creator>Franceschi, Jean-Yves</dc:creator>
 <dc:creator>Lamprier, Sylvain</dc:creator>
 <dc:creator>Gallinari, Patrick</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A recent line of work in the machine learning community addresses the problem
of predicting high-dimensional spatiotemporal phenomena by leveraging specific
tools from the differential equations theory. Following this direction, we
propose in this article a novel and general paradigm for this task based on a
resolution method for partial differential equations: the separation of
variables. This inspiration allows us to introduce a dynamical interpretation
of spatiotemporal disentanglement. It induces a principled model based on
learning disentangled spatial and temporal representations of a phenomenon to
accurately predict future observations. We experimentally demonstrate the
performance and broad applicability of our method against prior
state-of-the-art models on physical and synthetic video datasets.
</dc:description>
 <dc:date>2020-08-04</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.01352</dc:identifier>
 <dc:identifier>The Ninth International Conference on Learning Representations,
  International Conference on Representation Learning, May 2021, Vienne,
  Austria</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.01710</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Strategic Perceptron</dc:title>
 <dc:creator>Ahmadi, Saba</dc:creator>
 <dc:creator>Beyhaghi, Hedyeh</dc:creator>
 <dc:creator>Blum, Avrim</dc:creator>
 <dc:creator>Naggita, Keziah</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The classical Perceptron algorithm provides a simple and elegant procedure
for learning a linear classifier. In each step, the algorithm observes the
sample's position and label and updates the current predictor accordingly if it
makes a mistake. However, in presence of strategic agents that desire to be
classified as positive and that are able to modify their position by a limited
amount, the classifier may not be able to observe the true position of agents
but rather a position where the agent pretends to be. Unlike the original
setting with perfect knowledge of positions, in this situation the Perceptron
algorithm fails to achieve its guarantees, and we illustrate examples with the
predictor oscillating between two solutions forever, making an unbounded number
of mistakes even though a perfect large-margin linear classifier exists. Our
main contribution is providing a modified Perceptron-style algorithm which
makes a bounded number of mistakes in presence of strategic agents with both
$\ell_2$ and weighted $\ell_1$ manipulation costs. In our baseline model,
knowledge of the manipulation costs (i.e., the extent to which an agent may
manipulate) is assumed. In our most general model, we relax this assumption and
provide an algorithm which learns and refines both the classifier and its cost
estimates to achieve good mistake bounds even when manipulation costs are
unknown.
</dc:description>
 <dc:date>2020-08-04</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.01710</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.01915</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative Ensemble Regression: Learning Particle Dynamics from
  Observations of Ensembles with Physics-Informed Deep Generative Models</dc:title>
 <dc:creator>Yang, Liu</dc:creator>
 <dc:creator>Daskalakis, Constantinos</dc:creator>
 <dc:creator>Karniadakis, George Em</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a new method for inferring the governing stochastic ordinary
differential equations (SODEs) by observing particle ensembles at discrete and
sparse time instants, i.e., multiple &quot;snapshots&quot;. Particle coordinates at a
single time instant, possibly noisy or truncated, are recorded in each snapshot
but are unpaired across the snapshots. By training a physics-informed
generative model that generates &quot;fake&quot; sample paths, we aim to fit the observed
particle ensemble distributions with a curve in the probability measure space,
which is induced from the inferred particle dynamics. We employ different
metrics to quantify the differences between distributions, e.g., the sliced
Wasserstein distances and the adversarial losses in generative adversarial
networks (GANs). We refer to this method as generative &quot;ensemble-regression&quot;
(GER), in analogy to the classic &quot;point-regression&quot;, where we infer the
dynamics by performing regression in the Euclidean space. We illustrate the GER
by learning the drift and diffusion terms of particle ensembles governed by
SODEs with Brownian motions and Levy processes up to 100 dimensions. We also
discuss how to treat cases with noisy or truncated observations. Apart from
systems consisting of independent particles, we also tackle nonlocal
interacting particle systems with unknown interaction potential parameters by
constructing a physics-informed loss function. Finally, we investigate
scenarios of paired observations and discuss how to reduce the dimensionality
in such cases by proving a convergence theorem that provides theoretical
support.
</dc:description>
 <dc:date>2020-08-04</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.01915</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.02604</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning Based Defect Detection for Solder Joints on Industrial
  X-Ray Circuit Board Images</dc:title>
 <dc:creator>Zhang, Qianru</dc:creator>
 <dc:creator>Zhang, Meng</dc:creator>
 <dc:creator>Gamanayake, Chinthaka</dc:creator>
 <dc:creator>Yuen, Chau</dc:creator>
 <dc:creator>Geng, Zehao</dc:creator>
 <dc:creator>Jayasekara, Hirunima</dc:creator>
 <dc:creator>Zhang, Xuewen</dc:creator>
 <dc:creator>Woo, Chia-wei</dc:creator>
 <dc:creator>Low, Jenny</dc:creator>
 <dc:creator>Liu, Xiang</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Quality control is of vital importance during electronics production. As the
methods of producing electronic circuits improve, there is an increasing chance
of solder defects during assembling the printed circuit board (PCB). Many
technologies have been incorporated for inspecting failed soldering, such as
X-ray imaging, optical imaging, and thermal imaging. With some advanced
algorithms, the new technologies are expected to control the production quality
based on the digital images. However, current algorithms sometimes are not
accurate enough to meet the quality control. Specialists are needed to do a
follow-up checking. For automated X-ray inspection, joint of interest on the
X-ray image is located by region of interest (ROI) and inspected by some
algorithms. Some incorrect ROIs deteriorate the inspection algorithm. The high
dimension of X-ray images and the varying sizes of image dimensions also
challenge the inspection algorithms. On the other hand, recent advances on deep
learning shed light on image-based tasks and are competitive to human levels.
In this paper, deep learning is incorporated in X-ray imaging based quality
control during PCB quality inspection. Two artificial intelligence (AI) based
models are proposed and compared for joint defect detection. The noised ROI
problem and the varying sizes of imaging dimension problem are addressed. The
efficacy of the proposed methods are verified through experimenting on a
real-world 3D X-ray dataset. By incorporating the proposed methods, specialist
inspection workload is largely saved.
</dc:description>
 <dc:description>Comment: Accepted by conference INDIN 2020</dc:description>
 <dc:date>2020-08-06</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.02604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.02661</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Emotion Modeling with Learnable Graphs and Graph Inception
  Network</dc:title>
 <dc:creator>Shirian, A.</dc:creator>
 <dc:creator>Tripathi, S.</dc:creator>
 <dc:creator>Guha, T.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Human emotion is expressed, perceived and captured using a variety of dynamic
data modalities, such as speech (verbal), videos (facial expressions) and
motion sensors (body gestures). We propose a generalized approach to emotion
recognition that can adapt across modalities by modeling dynamic data as
structured graphs. The motivation behind the graph approach is to build compact
models without compromising on performance. To alleviate the problem of optimal
graph construction, we cast this as a joint graph learning and classification
task. To this end, we present the Learnable Graph Inception Network (L-GrIN)
that jointly learns to recognize emotion and to identify the underlying graph
structure in the dynamic data. Our architecture comprises multiple novel
components: a new graph convolution operation, a graph inception layer,
learnable adjacency, and a learnable pooling function that yields a graph-level
embedding. We evaluate the proposed architecture on five benchmark emotion
recognition databases spanning three different modalities (video, audio, motion
capture), where each database captures one of the following emotional cues:
facial expressions, speech and body gestures. We achieve state-of-the-art
performance on all five databases outperforming several competitive baselines
and relevant existing methods. Our graph architecture shows superior
performance with significantly fewer parameters (compared to convolutional or
recurrent neural networks) promising its applicability to resource-constrained
devices.
</dc:description>
 <dc:date>2020-08-06</dc:date>
 <dc:date>2021-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.02661</dc:identifier>
 <dc:identifier>10.1109/TMM.2021.3059169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.02918</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polysemy Deciphering Network for Robust Human-Object Interaction
  Detection</dc:title>
 <dc:creator>Zhong, Xubin</dc:creator>
 <dc:creator>Ding, Changxing</dc:creator>
 <dc:creator>Qu, Xian</dc:creator>
 <dc:creator>Tao, Dacheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Human-Object Interaction (HOI) detection is important to human-centric scene
understanding tasks. Existing works tend to assume that the same verb has
similar visual characteristics in different HOI categories, an approach that
ignores the diverse semantic meanings of the verb. To address this issue, in
this paper, we propose a novel Polysemy Deciphering Network (PD-Net) that
decodes the visual polysemy of verbs for HOI detection in three distinct ways.
First, we refine features for HOI detection to be polysemyaware through the use
of two novel modules: namely, Language Prior-guided Channel Attention (LPCA)
and Language Prior-based Feature Augmentation (LPFA). LPCA highlights important
elements in human and object appearance features for each HOI category to be
identified; moreover, LPFA augments human pose and spatial features for HOI
detection using language priors, enabling the verb classifiers to receive
language hints that reduce intra-class variation for the same verb. Second, we
introduce a novel Polysemy-Aware Modal Fusion module (PAMF), which guides
PD-Net to make decisions based on feature types deemed more important according
to the language priors. Third, we propose to relieve the verb polysemy problem
through sharing verb classifiers for semantically similar HOI categories.
Furthermore, to expedite research on the verb polysemy problem, we build a new
benchmark dataset named HOI-VerbPolysemy (HOIVP), which includes common verbs
(predicates) that have diverse semantic meanings in the real world. Finally,
through deciphering the visual polysemy of verbs, our approach is demonstrated
to outperform state-of-the-art methods by significant margins on the HICO-DET,
V-COCO, and HOI-VP databases. Code and data in this paper are available at
https://github.com/MuchHair/PD-Net.
</dc:description>
 <dc:description>Comment: The IJCV version extended significantly from our ECCV2020 conference
  paper</dc:description>
 <dc:date>2020-08-06</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.02918</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.03286</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HoliCity: A City-Scale Data Platform for Learning Holistic 3D Structures</dc:title>
 <dc:creator>Zhou, Yichao</dc:creator>
 <dc:creator>Huang, Jingwei</dc:creator>
 <dc:creator>Dai, Xili</dc:creator>
 <dc:creator>Liu, Shichen</dc:creator>
 <dc:creator>Luo, Linjie</dc:creator>
 <dc:creator>Chen, Zhili</dc:creator>
 <dc:creator>Ma, Yi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present HoliCity, a city-scale 3D dataset with rich structural
information. Currently, this dataset has 6,300 real-world panoramas of
resolution $13312 \times 6656$ that are accurately aligned with the CAD model
of downtown London with an area of more than 20 km$^2$, in which the median
reprojection error of the alignment of an average image is less than half a
degree. This dataset aims to be an all-in-one data platform for research of
learning abstracted high-level holistic 3D structures that can be derived from
city CAD models, e.g., corners, lines, wireframes, planes, and cuboids, with
the ultimate goal of supporting real-world applications including city-scale
reconstruction, localization, mapping, and augmented reality. The accurate
alignment of the 3D CAD models and panoramas also benefits low-level 3D vision
tasks such as surface normal estimation, as the surface normal extracted from
previous LiDAR-based datasets is often noisy. We conduct experiments to
demonstrate the applications of HoliCity, such as predicting surface
segmentation, normal maps, depth maps, and vanishing points, as well as test
the generalizability of methods trained on HoliCity and other related datasets.
HoliCity is available at https://holicity.io.
</dc:description>
 <dc:date>2020-08-07</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.03286</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.03330</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Protein Structured Reservoir computing for Spike-based Pattern
  Recognition</dc:title>
 <dc:creator>Tsakalos, Karolos-Alexandros</dc:creator>
 <dc:creator>Sirakoulis, Georgios Ch.</dc:creator>
 <dc:creator>Adamatzky, Andrew</dc:creator>
 <dc:creator>Smith, Jim</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Nowadays we witness a miniaturisation trend in the semiconductor industry
backed up by groundbreaking discoveries and designs in nanoscale
characterisation and fabrication. To facilitate the trend and produce ever
smaller, faster and cheaper computing devices, the size of nanoelectronic
devices is now reaching the scale of atoms or molecules - a technical goal
undoubtedly demanding for novel devices. Following the trend, we explore an
unconventional route of implementing a reservoir computing on a single protein
molecule and introduce neuromorphic connectivity with a small-world networking
property. We have chosen Izhikevich spiking neurons as elementary processors,
corresponding to the atoms of verotoxin protein, and its molecule as a
'hardware' architecture of the communication networks connecting the
processors. We apply on a single readout layer various training methods in a
supervised fashion to investigate whether the molecular structured Reservoir
Computing (RC) system is capable to deal with machine learning benchmarks. We
start with the Remote Supervised Method, based on
Spike-Timing-Dependent-Plasticity, and carry on with linear regression and
scaled conjugate gradient back-propagation training methods. The RC network is
evaluated as a proof-of-concept on the handwritten digit images from the MNIST
dataset and demonstrates acceptable classification accuracy in comparison with
other similar approaches.
</dc:description>
 <dc:description>Comment: 15 pages, 9 figures</dc:description>
 <dc:date>2020-08-07</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.03330</dc:identifier>
 <dc:identifier>doi:10.1109/TPDS.2021.3068826</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.04147</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge Distillation-aided End-to-End Learning for Linear Precoding in
  Multiuser MIMO Downlink Systems with Finite-Rate Feedback</dc:title>
 <dc:creator>Kong, Kyeongbo</dc:creator>
 <dc:creator>Song, Woo-Jin</dc:creator>
 <dc:creator>Min, Moonsik</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We propose a deep learning-based channel estimation, quantization, feedback,
and precoding method for downlink multiuser multiple-input and multiple-output
systems. In the proposed system, channel estimation and quantization for
limited feedback are handled by a receiver deep neural network (DNN). Precoder
selection is handled by a transmitter DNN. To emulate the traditional channel
quantization, a binarization layer is adopted at each receiver DNN, and the
binarization layer is also used to enable end-to-end learning. However, this
can lead to inaccurate gradients, which can trap the receiver DNNs at a poor
local minimum during training. To address this, we consider knowledge
distillation, in which the existing DNNs are jointly trained with an auxiliary
transmitter DNN. The use of an auxiliary DNN as a teacher network allows the
receiver DNNs to additionally exploit lossless gradients, which is useful in
avoiding a poor local minimum. For the same number of feedback bits, our
DNN-based precoding scheme can achieve a higher downlink rate compared to
conventional linear precoding with codebook-based limited feedback.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, submitted to IEEE Transactions on Vehicular
  Technology</dc:description>
 <dc:date>2020-08-10</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.04147</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.04357</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Directional Laplacian Centrality for Cyber Situational Awareness</dc:title>
 <dc:creator>Aksoy, Sinan G.</dc:creator>
 <dc:creator>Purvine, Emilie</dc:creator>
 <dc:creator>Young, Stephen J.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Cyber operations is drowning in diverse, high-volume, multi-source data. In
order to get a full picture of current operations and identify malicious events
and actors analysts must see through data generated by a mix of human activity
and benign automated processes. Although many monitoring and alert systems
exist, they typically use signature-based detection methods. We introduce a
general method rooted in spectral graph theory to discover patterns and
anomalies without a priori knowledge of signatures. We derive and propose a new
graph-theoretic centrality measure based on the derivative of the graph
Laplacian matrix in the direction of a vertex. To build intuition about our
measure we show how it identifies the most central vertices in standard network
data sets and compare to other graph centrality measures. Finally, we focus our
attention on studying its effectiveness in identifying important IP addresses
in network flow data. Using both real and synthetic network flow data, we
conduct several experiments to test our measure's sensitivity to two types of
injected attack profiles, and show that vertices participating in injected
attack profiles exhibit noticeable changes in our centrality measures, even
when the injected anomalies are relatively small, and in the presence of
simulated network dynamics.
</dc:description>
 <dc:description>Comment: 25 pages, 15 figures</dc:description>
 <dc:date>2020-08-10</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.04357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.04526</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SAFRON: Stitching Across the Frontier for Generating Colorectal Cancer
  Histology Images</dc:title>
 <dc:creator>Deshpande, Srijay</dc:creator>
 <dc:creator>Minhas, Fayyaz</dc:creator>
 <dc:creator>Graham, Simon</dc:creator>
 <dc:creator>Rajpoot, Nasir</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Synthetic images can be used for the development and evaluation of deep
learning algorithms in the context of limited availability of data. In the
field of computational pathology, where histology images are large in size and
visual context is crucial, synthesis of large high resolution images via
generative modeling is a challenging task. This is due to memory and
computational constraints hindering the generation of large images. To address
this challenge, we propose a novel SAFRON (Stitching Across the FRONtiers)
framework to construct realistic, large high resolution tissue image tiles from
ground truth annotations while preserving morphological features and with
minimal boundary artifacts. We show that the proposed method can generate
realistic image tiles of arbitrarily large size after training it on relatively
small image patches. We demonstrate that our model can generate high quality
images, both visually and in terms of the Frechet Inception Distance. Compared
to other existing approaches, our framework is efficient in terms of the memory
requirements for training and also in terms of the number of computations to
construct a large high-resolution image. We also show that training on
synthetic data generated by SAFRON can significantly boost the performance of a
state-of-the-art algorithm for gland segmentation in colorectal cancer
histology images. Sample high resolution images generated using SAFRON are
available at the URL: https://warwick.ac.uk/TIALab/SAFRON
</dc:description>
 <dc:date>2020-08-11</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.04526</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.05188</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Argument against Quantum Computers, the Quantum Laws of Nature, and
  Google's Supremacy Claims</dc:title>
 <dc:creator>Kalai, Gil</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  My 2018 lecture at the ICA workshop in Singapore dealt with quantum
computation as a meeting point of the laws of computation and the laws of
quantum mechanics. We described a computational complexity argument against the
feasibility of quantum computers: we identified a very low-level complexity
class of probability distributions described by noisy intermediate-scale
quantum computers, and explained why it would allow neither good-quality
quantum error-correction nor a demonstration of &quot;quantum supremacy,&quot; namely,
the ability of quantum computers to make computations that are impossible or
extremely hard for classical computers. We went on to describe general
predictions arising from the argument and proposed general laws that manifest
the failure of quantum computers.
  In October 2019, &quot;Nature&quot; published a paper describing an experimental work
that took place at Google. The paper claims to demonstrate quantum
(computational) supremacy on a 53-qubit quantum computer, thus clearly
challenging my theory. In this paper, I will explain and discuss my work in the
perspective of Google's supremacy claims.
</dc:description>
 <dc:description>Comment: 33 pages 2 Figures. To appear in: The Intercontinental Academia,
  Laws: 'Rigidity and Dynamics,' (M. J. Hannon and E. Z. Rabinovici (ed.))
  Proceedings of the ICA Workshops 2018\&amp;2019, Singapore and Birmingham, World
  Scientific. version 2: Added section on recent developments and some minor
  changes</dc:description>
 <dc:date>2020-08-12</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.05188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.05367</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-convex Learning via Replica Exchange Stochastic Gradient MCMC</dc:title>
 <dc:creator>Deng, Wei</dc:creator>
 <dc:creator>Feng, Qi</dc:creator>
 <dc:creator>Gao, Liyao</dc:creator>
 <dc:creator>Liang, Faming</dc:creator>
 <dc:creator>Lin, Guang</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  Replica exchange Monte Carlo (reMC), also known as parallel tempering, is an
important technique for accelerating the convergence of the conventional Markov
Chain Monte Carlo (MCMC) algorithms. However, such a method requires the
evaluation of the energy function based on the full dataset and is not scalable
to big data. The na\&quot;ive implementation of reMC in mini-batch settings
introduces large biases, which cannot be directly extended to the stochastic
gradient MCMC (SGMCMC), the standard sampling method for simulating from deep
neural networks (DNNs). In this paper, we propose an adaptive replica exchange
SGMCMC (reSGMCMC) to automatically correct the bias and study the corresponding
properties. The analysis implies an acceleration-accuracy trade-off in the
numerical discretization of a Markov jump process in a stochastic environment.
Empirically, we test the algorithm through extensive experiments on various
setups and obtain the state-of-the-art results on CIFAR10, CIFAR100, and SVHN
in both supervised learning and semi-supervised learning tasks.
</dc:description>
 <dc:description>Comment: Accepted by ICML 2020</dc:description>
 <dc:date>2020-08-12</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.05367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.05519</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence of Deep Fictitious Play for Stochastic Differential Games</dc:title>
 <dc:creator>Han, Jiequn</dc:creator>
 <dc:creator>Hu, Ruimeng</dc:creator>
 <dc:creator>Long, Jihao</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Quantitative Finance - Mathematical Finance</dc:subject>
 <dc:description>  Stochastic differential games have been used extensively to model agents'
competitions in Finance, for instance, in P2P lending platforms from the
Fintech industry, the banking system for systemic risk, and insurance markets.
The recently proposed machine learning algorithm, deep fictitious play,
provides a novel efficient tool for finding Markovian Nash equilibrium of large
$N$-player asymmetric stochastic differential games [J. Han and R. Hu,
Mathematical and Scientific Machine Learning Conference, pages 221-245, PMLR,
2020]. By incorporating the idea of fictitious play, the algorithm decouples
the game into $N$ sub-optimization problems, and identifies each player's
optimal strategy with the deep backward stochastic differential equation (BSDE)
method parallelly and repeatedly. In this paper, we prove the convergence of
deep fictitious play (DFP) to the true Nash equilibrium. We can also show that
the strategy based on DFP forms an $\eps$-Nash equilibrium. We generalize the
algorithm by proposing a new approach to decouple the games, and present
numerical results of large population games showing the empirical convergence
of the algorithm beyond the technical assumptions in the theorems.
</dc:description>
 <dc:date>2020-08-12</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.05519</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.05534</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Co-training for On-board Deep Object Detection</dc:title>
 <dc:creator>Villalonga, Gabriel</dc:creator>
 <dc:creator>Lopez, Antonio M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Providing ground truth supervision to train visual models has been a
bottleneck over the years, exacerbated by domain shifts which degenerate the
performance of such models. This was the case when visual tasks relied on
handcrafted features and shallow machine learning and, despite its
unprecedented performance gains, the problem remains open within the deep
learning paradigm due to its data-hungry nature. Best performing deep
vision-based object detectors are trained in a supervised manner by relying on
human-labeled bounding boxes which localize class instances (i.e.objects)
within the training images.Thus, object detection is one of such tasks for
which human labeling is a major bottleneck. In this paper, we assess
co-training as a semi-supervised learning method for self-labeling objects in
unlabeled images, so reducing the human-labeling effort for developing deep
object detectors. Our study pays special attention to a scenario involving
domain shift; in particular, when we have automatically generated virtual-world
images with object bounding boxes and we have real-world images which are
unlabeled. Moreover, we are particularly interested in using co-training for
deep object detection in the context of driver assistance systems and/or
self-driving vehicles. Thus, using well-established datasets and protocols for
object detection in these application contexts, we will show how co-training is
a paradigm worth to pursue for alleviating object labeling, working both alone
and together with task-agnostic domain adaptation.
</dc:description>
 <dc:date>2020-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.05534</dc:identifier>
 <dc:identifier>IEEE Access 8 (2020), 194441-194456</dc:identifier>
 <dc:identifier>doi:10.1109/ACCESS.2020.3032024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.05659</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Should Not Be Contrastive in Contrastive Learning</dc:title>
 <dc:creator>Xiao, Tete</dc:creator>
 <dc:creator>Wang, Xiaolong</dc:creator>
 <dc:creator>Efros, Alexei A.</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent self-supervised contrastive methods have been able to produce
impressive transferable visual representations by learning to be invariant to
different data augmentations. However, these methods implicitly assume a
particular set of representational invariances (e.g., invariance to color), and
can perform poorly when a downstream task violates this assumption (e.g.,
distinguishing red vs. yellow cars). We introduce a contrastive learning
framework which does not require prior knowledge of specific, task-dependent
invariances. Our model learns to capture varying and invariant factors for
visual representations by constructing separate embedding spaces, each of which
is invariant to all but one augmentation. We use a multi-head network with a
shared backbone which captures information across each augmentation and alone
outperforms all baselines on downstream tasks. We further find that the
concatenation of the invariant and varying spaces performs best across all
tasks we investigate, including coarse-grained, fine-grained, and few-shot
downstream classification tasks, and various data corruptions.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2021</dc:description>
 <dc:date>2020-08-12</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.05659</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.05838</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpretable Detection of Partial Discharge in Power Lines with Deep
  Learning</dc:title>
 <dc:creator>Michau, Gabriel</dc:creator>
 <dc:creator>Hsu, Chi-Ching</dc:creator>
 <dc:creator>Fink, Olga</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Partial discharge (PD) is a common indication of faults in power systems,
such as generators, and cables. These PD can eventually result in costly
repairs and substantial power outages. PD detection traditionally relies on
hand-crafted features and domain expertise to identify very specific pulses in
the electrical current, and the performance declines in the presence of noise
or of superposed pulses. In this paper, we propose a novel end-to-end framework
based on convolutional neural networks. The framework has two contributions.
First, it does not require any feature extraction and enables robust PD
detection. Second, we devise the pulse activation map. It provides
interpretability of the results for the domain experts with the identification
of the pulses that led to the detection of the PDs. The performance is
evaluated on a public dataset for the detection of damaged power lines. An
ablation study demonstrates the benefits of each part of the proposed
framework.
</dc:description>
 <dc:description>Comment: 13 pages, 4 figures, 2 tables</dc:description>
 <dc:date>2020-08-13</dc:date>
 <dc:date>2021-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.05838</dc:identifier>
 <dc:identifier>Sensors 2021</dc:identifier>
 <dc:identifier>doi:10.3390/s21062154</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.06344</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>COVID-19 mortality analysis from soft-data multivariate curve regression
  and machine learning</dc:title>
 <dc:creator>Torres-Signes, A.</dc:creator>
 <dc:creator>Fr&#xed;as, M. P.</dc:creator>
 <dc:creator>Ruiz-Medina, M. D.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>62F40, 62F15, 62F10, 90B99</dc:subject>
 <dc:description>  A multiple objective space-time forecasting approach is presented involving
cyclical curve log-regression, and multivariate time series spatial residual
correlation analysis. Specifically, the mean quadratic loss function is
minimized in the framework of trigonometric regression. While, in our
subsequent spatial residual correlation analysis, maximization of the
likelihood allows us to compute the posterior mode in a Bayesian multivariate
time series soft-data framework. The presented approach is applied to the
analysis of COVID-19 mortality in the first wave affecting the Spanish
Communities, since March, 8, 2020 until May, 13, 2020. An empirical comparative
study with Machine Learning (ML) regression, based on random k-fold
cross-validation, and bootstrapping confidence interval and probability density
estimation, is carried out. This empirical analysis also investigates the
performance of ML regression models in a hard- and soft- data frameworks. The
results could be extrapolated to other counts, countries, and posterior
COVID-19 waves.
</dc:description>
 <dc:description>Comment: This paper is currently submitted</dc:description>
 <dc:date>2020-08-07</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.06344</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.06399</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Renormalization for Initialization of Rolling Shutter Visual-Inertial
  Odometry</dc:title>
 <dc:creator>Micusik, Branislav</dc:creator>
 <dc:creator>Evangelidis, Georgios</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper we deal with the initialization problem of a visual-inertial
odometry system with rolling shutter cameras. Initialization is a prerequisite
for using inertial signals and fusing them with visual data. We propose a novel
statistical solution to the initialization problem on visual and inertial data
simultaneously, by casting it into the renormalization scheme of Kanatani. The
renormalization is an optimization scheme which intends to reduce the inherent
statistical bias of common linear systems. We derive and present the necessary
steps and methodology specific to the initialization problem. Extensive
evaluations on ground truth exhibit superior performance and a gain in accuracy
of up to $20\%$ over the originally proposed Least Squares solution. The
renormalization performs similarly to the optimal Maximum Likelihood estimate,
despite arriving at the solution by different means. With this paper we are
adding to the set of Computer Vision problems which can be cast into the
renormalization scheme.
</dc:description>
 <dc:date>2020-08-14</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.06399</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.06979</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prediction of Homicides in Urban Centers: A Machine Learning Approach</dc:title>
 <dc:creator>Ribeiro, Jos&#xe9;</dc:creator>
 <dc:creator>Meneses, Lair</dc:creator>
 <dc:creator>Costa, Denis</dc:creator>
 <dc:creator>Miranda, Wando</dc:creator>
 <dc:creator>Alves, Ronnie</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  Relevant research has been highlighted in the computing community to develop
machine learning models capable of predicting the occurrence of crimes,
analyzing contexts of crimes, extracting profiles of individuals linked to
crime, and analyzing crimes over time. However, models capable of predicting
specific crimes, such as homicide, are not commonly found in the current
literature. This research presents a machine learning model to predict homicide
crimes, using a dataset that uses generic data (without study location
dependencies) based on incident report records for 34 different types of
crimes, along with time and space data from crime reports. Experimentally, data
from the city of Bel\'em - Par\'a, Brazil was used. These data were transformed
to make the problem generic, enabling the replication of this model to other
locations. In the research, analyses were performed with simple and robust
algorithms on the created dataset. With this, statistical tests were performed
with 11 different classification methods and the results are related to the
prediction's occurrence and non-occurrence of homicide crimes in the month
subsequent to the occurrence of other registered crimes, with 76% assertiveness
for both classes of the problem, using Random Forest. Results are considered as
a baseline for the proposed problem.
</dc:description>
 <dc:description>Comment: 17 pages, 4 tables and 3 figures, Accepted in IntelliSys 2021</dc:description>
 <dc:date>2020-08-16</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.06979</dc:identifier>
 <dc:identifier>IntelliSys 2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.07081</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MIDAS: Multi-agent Interaction-aware Decision-making with Adaptive
  Strategies for Urban Autonomous Navigation</dc:title>
 <dc:creator>Chen, Xiaoyi</dc:creator>
 <dc:creator>Chaudhari, Pratik</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Autonomous navigation in crowded, complex urban environments requires
interacting with other agents on the road. A common solution to this problem is
to use a prediction model to guess the likely future actions of other agents.
While this is reasonable, it leads to overly conservative plans because it does
not explicitly model the mutual influence of the actions of interacting agents.
This paper builds a reinforcement learning-based method named MIDAS where an
ego-agent learns to affect the control actions of other cars in urban driving
scenarios. MIDAS uses an attention-mechanism to handle an arbitrary number of
other agents and includes a &quot;driver-type&quot; parameter to learn a single policy
that works across different planning objectives. We build a simulation
environment that enables diverse interaction experiments with a large number of
agents and methods for quantitatively studying the safety, efficiency, and
interaction among vehicles. MIDAS is validated using extensive experiments and
we show that it (i) can work across different road geometries, (ii) results in
an adaptive ego policy that can be tuned easily to satisfy performance criteria
such as aggressive or cautious driving, (iii) is robust to changes in the
driving policies of external agents, and (iv) is more efficient and safer than
existing approaches to interaction-aware decision-making.
</dc:description>
 <dc:description>Comment: Code available at https://github.com/sherrychen1120/MIDAS. To be
  presented at IEEE International Conference on Robotics and Automation (ICRA),
  2021</dc:description>
 <dc:date>2020-08-17</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.07081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.07127</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DORY: Automatic End-to-End Deployment of Real-World DNNs on Low-Cost IoT
  MCUs</dc:title>
 <dc:creator>Burrello, Alessio</dc:creator>
 <dc:creator>Garofalo, Angelo</dc:creator>
 <dc:creator>Bruschi, Nazareno</dc:creator>
 <dc:creator>Tagliavini, Giuseppe</dc:creator>
 <dc:creator>Rossi, Davide</dc:creator>
 <dc:creator>Conti, Francesco</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The deployment of Deep Neural Networks (DNNs) on end-nodes at the extreme
edge of the Internet-of-Things is a critical enabler to support pervasive Deep
Learning-enhanced applications. Low-Cost MCU-based end-nodes have limited
on-chip memory and often replace caches with scratchpads, to reduce area
overheads and increase energy efficiency -- requiring explicit DMA-based memory
transfers between different levels of the memory hierarchy. Mapping modern DNNs
on these systems requires aggressive topology-dependent tiling and
double-buffering. In this work, we propose DORY (Deployment Oriented to memoRY)
- an automatic tool to deploy DNNs on low cost MCUs with typically less than
1MB of on-chip SRAM memory. DORY abstracts tiling as a Constraint Programming
(CP) problem: it maximizes L1 memory utilization under the topological
constraints imposed by each DNN layer. Then, it generates ANSI C code to
orchestrate off- and on-chip transfers and computation phases. Furthermore, to
maximize speed, DORY augments the CP formulation with heuristics promoting
performance-effective tile sizes. As a case study for DORY, we target
GreenWaves Technologies GAP8, one of the most advanced parallel ultra-low power
MCU-class devices on the market. On this device, DORY achieves up to 2.5x
better MAC/cycle than the GreenWaves proprietary software solution and 18.1x
better than the state-of-the-art result on an STM32-F746 MCU on single layers.
Using our tool, GAP-8 can perform end-to-end inference of a 1.0-MobileNet-128
network consuming just 63 pJ/MAC on average @ 4.3 fps - 15.4x better than an
STM32-F746. We release all our developments - the DORY framework, the optimized
backend kernels, and the related heuristics - as open-source software.
</dc:description>
 <dc:description>Comment: 14 pages, 12 figures, 4 tables, 2 listings. Accepted for publication
  in IEEE Transactions on Computers
  (https://ieeexplore.ieee.org/document/9381618)</dc:description>
 <dc:date>2020-08-17</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.07127</dc:identifier>
 <dc:identifier>doi:10.1109/TC.2021.3066883</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.07730</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel Extraction of Long-term Trends and Short-term Fluctuation
  Framework for Multivariate Time Series Forecasting</dc:title>
 <dc:creator>Zhou, Yifu</dc:creator>
 <dc:creator>Duan, Ziheng</dc:creator>
 <dc:creator>Xu, Haoyan</dc:creator>
 <dc:creator>Feng, Jie</dc:creator>
 <dc:creator>Ren, Anni</dc:creator>
 <dc:creator>Wang, Yueyang</dc:creator>
 <dc:creator>Wang, Xiaoqian</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Multivariate time series forecasting is widely used in various fields.
Reasonable prediction results can assist people in planning and
decision-making, generate benefits and avoid risks. Normally, there are two
characteristics of time series, that is, long-term trend and short-term
fluctuation. For example, stock prices will have a long-term upward trend with
the market, but there may be a small decline in the short term. These two
characteristics are often relatively independent of each other. However, the
existing prediction methods often do not distinguish between them, which
reduces the accuracy of the prediction model. In this paper, a MTS forecasting
framework that can capture the long-term trends and short-term fluctuations of
time series in parallel is proposed. This method uses the original time series
and its first difference to characterize long-term trends and short-term
fluctuations. Three prediction sub-networks are constructed to predict
long-term trends, short-term fluctuations and the final value to be predicted.
In the overall optimization goal, the idea of multi-task learning is used for
reference, which is to make the prediction results of long-term trends and
short-term fluctuations as close to the real values as possible while requiring
to approximate the values to be predicted. In this way, the proposed method
uses more supervision information and can more accurately capture the changing
trend of the time series, thereby improving the forecasting performance.
</dc:description>
 <dc:date>2020-08-17</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.07730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.07792</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ReLMoGen: Leveraging Motion Generation in Reinforcement Learning for
  Mobile Manipulation</dc:title>
 <dc:creator>Xia, Fei</dc:creator>
 <dc:creator>Li, Chengshu</dc:creator>
 <dc:creator>Mart&#xed;n-Mart&#xed;n, Roberto</dc:creator>
 <dc:creator>Litany, Or</dc:creator>
 <dc:creator>Toshev, Alexander</dc:creator>
 <dc:creator>Savarese, Silvio</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Many Reinforcement Learning (RL) approaches use joint control signals
(positions, velocities, torques) as action space for continuous control tasks.
We propose to lift the action space to a higher level in the form of subgoals
for a motion generator (a combination of motion planner and trajectory
executor). We argue that, by lifting the action space and by leveraging
sampling-based motion planners, we can efficiently use RL to solve complex,
long-horizon tasks that could not be solved with existing RL methods in the
original action space. We propose ReLMoGen -- a framework that combines a
learned policy to predict subgoals and a motion generator to plan and execute
the motion needed to reach these subgoals. To validate our method, we apply
ReLMoGen to two types of tasks: 1) Interactive Navigation tasks, navigation
problems where interactions with the environment are required to reach the
destination, and 2) Mobile Manipulation tasks, manipulation tasks that require
moving the robot base. These problems are challenging because they are usually
long-horizon, hard to explore during training, and comprise alternating phases
of navigation and interaction. Our method is benchmarked on a diverse set of
seven robotics tasks in photo-realistic simulation environments. In all
settings, ReLMoGen outperforms state-of-the-art Reinforcement Learning and
Hierarchical Reinforcement Learning baselines. ReLMoGen also shows outstanding
transferability between different motion generators at test time, indicating a
great potential to transfer to real robots.
</dc:description>
 <dc:description>Comment: First two authors contributed equally. Access project website at
  http://svl.stanford.edu/projects/relmogen</dc:description>
 <dc:date>2020-08-18</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.07792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.07944</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalability of Network Visualisation from a Cognitive Load Perspective</dc:title>
 <dc:creator>Yoghourdjian, Vahan</dc:creator>
 <dc:creator>Yang, Yalong</dc:creator>
 <dc:creator>Dwyer, Tim</dc:creator>
 <dc:creator>Lawrence, Lee</dc:creator>
 <dc:creator>Wybrow, Michael</dc:creator>
 <dc:creator>Marriott, Kim</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Node-link diagrams are widely used to visualise networks. However, even the
best network layout algorithms ultimately result in 'hairball' visualisations
when the graph reaches a certain degree of complexity, requiring simplification
through aggregation or interaction (such as filtering) to remain usable. Until
now, there has been little data to indicate at what level of complexity
node-link diagrams become ineffective or how visual complexity affects
cognitive load. To this end, we conducted a controlled study to understand
workload limits for a task that requires a detailed understanding of the
network topology---finding the shortest path between two nodes. We tested
performance on graphs with 25 to 175 nodes with varying density. We collected
performance measures (accuracy and response time), subjective feedback, and
physiological measures (EEG, pupil dilation, and heart rate variability). To
the best of our knowledge, this is the first network visualisation study to
include physiological measures. Our results show that people have significant
difficulty finding the shortest path in high-density node-link diagrams with
more than 50 nodes and even low-density graphs with more than 100 nodes. From
our collected EEG data we observe functional differences in brain activity
between hard and easy tasks. We found that cognitive load increased up to a
certain level of difficulty after which it decreased, likely because
participants had given up. We also explored the effects of global network
layout features such as size or number of crossings, and features of the
shortest path such as length or straightness on task difficulty. We found that
global features generally had a greater impact than those of the shortest path.
</dc:description>
 <dc:description>Comment: To be presented at IEEE Conference on Information Visualization
  (InfoVis 2020)</dc:description>
 <dc:date>2020-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.07944</dc:identifier>
 <dc:identifier>doi:10.1109/TVCG.2020.3030459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.08902</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topology Optimization and 3D printing of Large Deformation Compliant
  Mechanisms for Straining Biological Tissues</dc:title>
 <dc:creator>Kumar, P.</dc:creator>
 <dc:creator>Schmidleithner, C.</dc:creator>
 <dc:creator>Larsen, N. B.</dc:creator>
 <dc:creator>Sigmund, O.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  This paper presents a synthesis approach in a density-based topology
optimization setting to design large deformation compliant mechanisms for
inducing desired strains in biological tissues. The modelling is based on
geometrical nonlinearity together with a suitably chosen hypereleastic material
model, wherein the mechanical equilibrium equations are solved using the total
Lagrangian finite element formulation. An objective based on least-square error
with respect to target strains is formulated and minimized with the given set
of constraints and the appropriate surroundings of the tissues. To circumvent
numerical instabilities arising due to large deformation in low stiffness
design regions during topology optimization, a strain-energy based
interpolation scheme is employed. The approach uses an extended robust
formulation i.e. the eroded, intermediate and dilated projections for the
design description as well as variation in tissue stiffness. Efficacy of the
synthesis approach is demonstrated by designing various compliant mechanisms
for providing different target strains in biological tissue constructs.
Optimized compliant mechanisms are 3D-printed and their performances are
recorded in a simplified experiment and compared with simulation results
obtained by a commercial software.
</dc:description>
 <dc:description>Comment: 23 pages, 14 figures</dc:description>
 <dc:date>2020-08-20</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.08902</dc:identifier>
 <dc:identifier>Structural and Multidisciplinary Optimization, volume 63, 2021</dc:identifier>
 <dc:identifier>doi:10.1007/s00158-020-02764-4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.09008</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Fine-Grained Exact Computation in Regular Graphs</dc:title>
 <dc:creator>Amiri, Saeed Akhoondian</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We show that there is no subexponential time algorithm for computing the
exact solution of the maximum independent set problem in d-regular graphs
unless ETH fails. We expand our method to show that it helps to provide lower
bounds for other covering problems such as vertex cover and clique. We utilize
the construction to show the NP-hardness of MIS on 5-regular planar graphs,
closing the exact complexity status of the problem on regular planar graphs.
</dc:description>
 <dc:date>2020-08-20</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.09008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.09075</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Controlling Dialogue Generation with Semantic Exemplars</dc:title>
 <dc:creator>Gupta, Prakhar</dc:creator>
 <dc:creator>Bigham, Jeffrey P.</dc:creator>
 <dc:creator>Tsvetkov, Yulia</dc:creator>
 <dc:creator>Pavel, Amy</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Dialogue systems pretrained with large language models generate locally
coherent responses, but lack the fine-grained control over responses necessary
to achieve specific goals. A promising method to control response generation is
exemplar-based generation, in which models edit exemplar responses that are
retrieved from training data, or hand-written to strategically address
discourse-level goals, to fit new dialogue contexts. But, current
exemplar-based approaches often excessively copy words from the exemplar
responses, leading to incoherent replies. We present an Exemplar-based Dialogue
Generation model, EDGE, that uses the semantic frames present in exemplar
responses to guide generation. We show that controlling dialogue generation
based on the semantic frames of exemplars, rather than words in the exemplar
itself, improves the coherence of generated responses, while preserving
semantic meaning and conversation goals present in exemplar responses.
</dc:description>
 <dc:description>Comment: Accepted at NAACL 2021</dc:description>
 <dc:date>2020-08-20</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.09075</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.09094</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scruples: A Corpus of Community Ethical Judgments on 32,000 Real-Life
  Anecdotes</dc:title>
 <dc:creator>Lourie, Nicholas</dc:creator>
 <dc:creator>Bras, Ronan Le</dc:creator>
 <dc:creator>Choi, Yejin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  As AI systems become an increasing part of people's everyday lives, it
becomes ever more important that they understand people's ethical norms.
Motivated by descriptive ethics, a field of study that focuses on people's
descriptive judgments rather than theoretical prescriptions on morality, we
investigate a novel, data-driven approach to machine ethics.
  We introduce Scruples, the first large-scale dataset with 625,000 ethical
judgments over 32,000 real-life anecdotes. Each anecdote recounts a complex
ethical situation, often posing moral dilemmas, paired with a distribution of
judgments contributed by the community members. Our dataset presents a major
challenge to state-of-the-art neural language models, leaving significant room
for improvement. However, when presented with simplified moral situations, the
results are considerably more promising, suggesting that neural models can
effectively learn simpler ethical building blocks.
  A key take-away of our empirical analysis is that norms are not always
clean-cut; many situations are naturally divisive. We present a new method to
estimate the best possible performance on such tasks with inherently diverse
label distributions, and explore likelihood functions that separate intrinsic
from model uncertainty.
</dc:description>
 <dc:description>Comment: 18 pages, 14 tables, 18 figures. Accepted to AAAI 2021. For
  associated code and data, see https://github.com/allenai/scruples</dc:description>
 <dc:date>2020-08-20</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.09094</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.09275</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probability and consequences of living inside a computer simulation</dc:title>
 <dc:creator>Bibeau-Delisle, Alexandre</dc:creator>
 <dc:creator>Brassard, Gilles</dc:creator>
 <dc:subject>Physics - Popular Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  It is shown that under reasonable assumptions a Drake-style equation can be
obtained for the probability that our universe is the result of a deliberate
simulation. Evaluating loose bounds for certain terms in the equation shows
that the probability is unlikely to be as high as previously reported in the
literature, especially in a scenario where the simulations are recursive.
Furthermore, we investigate the possibility of eavesdropping from the outside
of such a simulation and introduce a general attack that can circumvent
attempts at quantum cryptography inside the simulation, even if the quantum
properties of the simulation are genuine.
</dc:description>
 <dc:description>Comment: 17 pages, 2 figures, 1 table</dc:description>
 <dc:date>2020-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.09275</dc:identifier>
 <dc:identifier>Proceedings of the Royal Society A, Vol. 477, no. 2247, March 2021</dc:identifier>
 <dc:identifier>doi:10.1098/rspa.2020.0658</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.09388</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CDE-GAN: Cooperative Dual Evolution Based Generative Adversarial Network</dc:title>
 <dc:creator>Chen, Shiming</dc:creator>
 <dc:creator>Wang, Wenjie</dc:creator>
 <dc:creator>Xia, Beihao</dc:creator>
 <dc:creator>You, Xinge</dc:creator>
 <dc:creator>Cao, Zehong</dc:creator>
 <dc:creator>Ding, Weiping</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Generative adversarial networks (GANs) have been a popular deep generative
model for real-world applications. Despite many recent efforts on GANs that
have been contributed, mode collapse and instability of GANs are still open
problems caused by their adversarial optimization difficulties. In this paper,
motivated by the cooperative co-evolutionary algorithm, we propose a
Cooperative Dual Evolution based Generative Adversarial Network (CDE-GAN) to
circumvent these drawbacks. In essence, CDE-GAN incorporates dual evolution
with respect to the generator(s) and discriminators into a unified evolutionary
adversarial framework to conduct effective adversarial multi-objective
optimization. Thus it exploits the complementary properties and injects dual
mutation diversity into training to steadily diversify the estimated density in
capturing multi-modes and improve generative performance. Specifically, CDE-GAN
decomposes the complex adversarial optimization problem into two subproblems
(generation and discrimination), and each subproblem is solved with a separated
subpopulation (E-Generator} and E-Discriminators), evolved by its own
evolutionary algorithm. Additionally, we further propose a Soft Mechanism to
balance the trade-off between E-Generators and E-Discriminators to conduct
steady training for CDE-GAN. Extensive experiments on one synthetic dataset and
three real-world benchmark image datasets demonstrate that the proposed CDE-GAN
achieves a competitive and superior performance in generating good quality and
diverse samples over baselines. The code and more generated results are
available at our project homepage:
https://shiming-chen.github.io/CDE-GAN-website/CDE-GAN.html.
</dc:description>
 <dc:description>Comment: 15 pages,6 figures,4 tables. Accepted by IEEE Transactions on
  Evolutionary Computation</dc:description>
 <dc:date>2020-08-21</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.09388</dc:identifier>
 <dc:identifier>IEEE Transactions on Evolutionary Computation, 2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.10913</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MonStereo: When Monocular and Stereo Meet at the Tail of 3D Human
  Localization</dc:title>
 <dc:creator>Bertoni, Lorenzo</dc:creator>
 <dc:creator>Kreiss, Sven</dc:creator>
 <dc:creator>Mordan, Taylor</dc:creator>
 <dc:creator>Alahi, Alexandre</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Monocular and stereo visions are cost-effective solutions for 3D human
localization in the context of self-driving cars or social robots. However,
they are usually developed independently and have their respective strengths
and limitations. We propose a novel unified learning framework that leverages
the strengths of both monocular and stereo cues for 3D human localization. Our
method jointly (i) associates humans in left-right images, (ii) deals with
occluded and distant cases in stereo settings by relying on the robustness of
monocular cues, and (iii) tackles the intrinsic ambiguity of monocular
perspective projection by exploiting prior knowledge of the human height
distribution. We specifically evaluate outliers as well as challenging
instances, such as occluded and far-away pedestrians, by analyzing the entire
error distribution and by estimating calibrated confidence intervals. Finally,
we critically review the official KITTI 3D metrics and propose a practical 3D
localization metric tailored for humans.
</dc:description>
 <dc:description>Comment: Accepted at the IEEE International Conference on Robotics and
  Automation (ICRA) 2021</dc:description>
 <dc:date>2020-08-25</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.10913</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.11174</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Obstacle Representations for Neural Motion Planning</dc:title>
 <dc:creator>Strudel, Robin</dc:creator>
 <dc:creator>Garcia, Ricardo</dc:creator>
 <dc:creator>Carpentier, Justin</dc:creator>
 <dc:creator>Laumond, Jean-Paul</dc:creator>
 <dc:creator>Laptev, Ivan</dc:creator>
 <dc:creator>Schmid, Cordelia</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Motion planning and obstacle avoidance is a key challenge in robotics
applications. While previous work succeeds to provide excellent solutions for
known environments, sensor-based motion planning in new and dynamic
environments remains difficult. In this work we address sensor-based motion
planning from a learning perspective. Motivated by recent advances in visual
recognition, we argue the importance of learning appropriate representations
for motion planning. We propose a new obstacle representation based on the
PointNet architecture and train it jointly with policies for obstacle
avoidance. We experimentally evaluate our approach for rigid body motion
planning in challenging environments and demonstrate significant improvements
of the state of the art in terms of accuracy and efficiency.
</dc:description>
 <dc:description>Comment: CoRL 2020. See the project webpage at
  https://www.di.ens.fr/willow/research/nmp_repr/</dc:description>
 <dc:date>2020-08-25</dc:date>
 <dc:date>2020-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.11174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.11393</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proof for frequency response analysis using chirp signals</dc:title>
 <dc:creator>Suresh, Resmi</dc:creator>
 <dc:creator>Rengaswamy, Raghunathan</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Hundreds of applications utilize frequency response characterization of a
system. Identification of frequency response requires long experimentation
time, use of transformation techniques and other difficulties associated with
isolating the system behavior precisely at individual frequencies. In this
work, we report a hitherto unknown result that can be leveraged to mitigate
these difficulties resulting in a tremendous reduction in the experimentation
time. This result has the possibility of revolutionizing how frequency response
studies are performed.
</dc:description>
 <dc:description>Comment: Work needs more information to be a complete document</dc:description>
 <dc:date>2020-08-26</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.11393</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.11796</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Force Fields from Active Learning for Simulation of
  Inter-Dimensional Transformation of Stanene</dc:title>
 <dc:creator>Xie, Yu</dc:creator>
 <dc:creator>Vandermause, Jonathan</dc:creator>
 <dc:creator>Sun, Lixin</dc:creator>
 <dc:creator>Cepellotti, Andrea</dc:creator>
 <dc:creator>Kozinsky, Boris</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We present a way to dramatically accelerate Gaussian process models for
interatomic force fields based on many-body kernels by mapping both forces and
uncertainties onto functions of low-dimensional features. This allows for
automated active learning of models combining near-quantum accuracy, built-in
uncertainty, and constant cost of evaluation that is comparable to classical
analytical models, capable of simulating millions of atoms. Using this
approach, we perform large scale molecular dynamics simulations of the
stability of the stanene monolayer. We discover an unusual phase transformation
mechanism of 2D stanene, where ripples lead to nucleation of bilayer defects,
densification into a disordered multilayer structure, followed by formation of
bulk liquid at high temperature or nucleation and growth of the 3D bcc crystal
at low temperature. The presented method opens possibilities for rapid
development of fast accurate uncertainty-aware models for simulating long-time
large-scale dynamics of complex materials.
</dc:description>
 <dc:description>Comment: 30 pages of main text, 14 pages of supplementary materials, 9 figures
  in total</dc:description>
 <dc:date>2020-08-26</dc:date>
 <dc:date>2021-02-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.11796</dc:identifier>
 <dc:identifier>npj Comput Mater 7, 40 (2021)</dc:identifier>
 <dc:identifier>doi:10.1038/s41524-021-00510-y</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.12160</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Perfect linear complexity profile and Apwenian sequences</dc:title>
 <dc:creator>Allouche, J. -P.</dc:creator>
 <dc:creator>Han, G. -N.</dc:creator>
 <dc:creator>Niederreiter, H.</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>11K45, 11K50, 11J70, 11B85, 11T71, 94A55</dc:subject>
 <dc:description>  Sequences with {\em perfect linear complexity profile} were defined more than
thirty years ago in the study of measures of randomness for binary sequences.
More recently {\em apwenian sequences}, first with values $\pm 1$, then with
values in $\{0, 1\}$, were introduced in the study of Hankel determinants of
automatic sequences. We explain that these two families of sequences are the
same up to indexing, and give consequences and questions that this implies. We
hope that this will help gathering two distinct communities of researchers.
</dc:description>
 <dc:date>2020-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.12160</dc:identifier>
 <dc:identifier>Finite Fields Appl. 68 (2020), 101761</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.12454</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Color and Edge-Aware Adversarial Image Perturbations</dc:title>
 <dc:creator>Bassett, Robert</dc:creator>
 <dc:creator>Graves, Mitchell</dc:creator>
 <dc:creator>Reilly, Patrick</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>68T45, 62F35</dc:subject>
 <dc:description>  Adversarial perturbation of images, in which a source image is deliberately
modified with the intent of causing a classifier to misclassify the image,
provides important insight into the robustness of image classifiers. In this
work we develop two new methods for constructing adversarial perturbations,
both of which are motivated by minimizing human ability to detect changes
between the perturbed and source image. The first of these, the Edge-Aware
method, reduces the magnitude of perturbations permitted in smooth regions of
an image where changes are more easily detected. Our second method, the
Color-Aware method, performs the perturbation in a color space which accurately
captures human ability to distinguish differences in colors, thus reducing the
perceived change. The Color-Aware and Edge-Aware methods can also be
implemented simultaneously, resulting in image perturbations which account for
both human color perception and sensitivity to changes in homogeneous regions.
Because Edge-Aware and Color-Aware modifications exist for many image
perturbations techniques, we also focus on computation to demonstrate their
potential for use within more complex perturbation schemes. We empirically
demonstrate that the Color-Aware and Edge-Aware perturbations we consider
effectively cause misclassification, are less distinguishable to human
perception, and are as easy to compute as the most efficient image perturbation
techniques. Code and demo available at
https://github.com/rbassett3/Color-and-Edge-Aware-Perturbations
</dc:description>
 <dc:date>2020-08-27</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.12454</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.12687</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Dynamic Trajectory Optimization and Control for a Quadruped Robot</dc:title>
 <dc:creator>Cebe, Oguzhan</dc:creator>
 <dc:creator>Tiseo, Carlo</dc:creator>
 <dc:creator>Xin, Guiyang</dc:creator>
 <dc:creator>Lin, Hsiu-chin</dc:creator>
 <dc:creator>Smith, Joshua</dc:creator>
 <dc:creator>Mistry, Michael</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Legged robot locomotion requires the planning of stable reference
trajectories, especially while traversing uneven terrain. The proposed
trajectory optimization framework is capable of generating dynamically stable
base and footstep trajectories for multiple steps. The locomotion task can be
defined with contact locations, base motion or both, making the algorithm
suitable for multiple scenarios (e.g., presence of moving obstacles). The
planner uses a simplified momentum-based task space model for the robot
dynamics, allowing computation times that are fast enough for online
replanning.This fast planning capabilitiy also enables the quadruped to
accommodate for drift and environmental changes. The algorithm is tested on
simulation and a real robot across multiple scenarios, which includes uneven
terrain, stairs and moving obstacles. The results show that the planner is
capable of generating stable trajectories in the real robot even when a box of
15 cm height is placed in front of its path at the last moment.
</dc:description>
 <dc:description>Comment: 7 pages, 10 figures, for video see https://bit.ly/3gyccU6</dc:description>
 <dc:date>2020-08-28</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.12687</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.12745</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DNNExplorer: A Framework for Modeling and Exploring a Novel Paradigm of
  FPGA-based DNN Accelerator</dc:title>
 <dc:creator>Zhang, Xiaofan</dc:creator>
 <dc:creator>Ye, Hanchen</dc:creator>
 <dc:creator>Wang, Junsong</dc:creator>
 <dc:creator>Lin, Yonghua</dc:creator>
 <dc:creator>Xiong, Jinjun</dc:creator>
 <dc:creator>Hwu, Wen-mei</dc:creator>
 <dc:creator>Chen, Deming</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Existing FPGA-based DNN accelerators typically fall into two design
paradigms. Either they adopt a generic reusable architecture to support
different DNN networks but leave some performance and efficiency on the table
because of the sacrifice of design specificity. Or they apply a layer-wise
tailor-made architecture to optimize layer-specific demands for computation and
resources but loose the scalability of adaptation to a wide range of DNN
networks. To overcome these drawbacks, this paper proposes a novel FPGA-based
DNN accelerator design paradigm and its automation tool, called DNNExplorer, to
enable fast exploration of various accelerator designs under the proposed
paradigm and deliver optimized accelerator architectures for existing and
emerging DNN networks. Three key techniques are essential for DNNExplorer's
improved performance, better specificity, and scalability, including (1) a
unique accelerator design paradigm with both high-dimensional design space
support and fine-grained adjustability, (2) a dynamic design space to
accommodate different combinations of DNN workloads and targeted FPGAs, and (3)
a design space exploration (DSE) engine to generate optimized accelerator
architectures following the proposed paradigm by simultaneously considering
both FPGAs' computation and memory resources and DNN networks' layer-wise
characteristics and overall complexity. Experimental results show that, for the
same FPGAs, accelerators generated by DNNExplorer can deliver up to 4.2x higher
performances (GOP/s) than the state-of-the-art layer-wise pipelined solutions
generated by DNNBuilder for VGG-like DNN with 38 CONV layers. Compared to
accelerators with generic reusable computation units, DNNExplorer achieves up
to 2.0x and 4.4x DSP efficiency improvement than a recently published
accelerator design from academia (HybridDNN) and a commercial DNN accelerator
IP (Xilinx DPU), respectively.
</dc:description>
 <dc:description>Comment: Published as a conference paper at International Conference on
  Computer Aided Design 2020 (ICCAD'20)</dc:description>
 <dc:date>2020-08-28</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.12745</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.12988</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Computation of Expectations under Spanning Tree Distributions</dc:title>
 <dc:creator>Zmigrod, Ran</dc:creator>
 <dc:creator>Vieira, Tim</dc:creator>
 <dc:creator>Cotterell, Ryan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We give a general framework for inference in spanning tree models. We propose
unified algorithms for the important cases of first-order expectations and
second-order expectations in edge-factored, non-projective spanning-tree
models. Our algorithms exploit a fundamental connection between gradients and
expectations, which allows us to derive efficient algorithms. These algorithms
are easy to implement with or without automatic differentiation software. We
motivate the development of our framework with several \emph{cautionary tales}
of previous research, which has developed numerous inefficient algorithms for
computing expectations and their gradients. We demonstrate how our framework
efficiently computes several quantities with known algorithms, including the
expected attachment score, entropy, and generalized expectation criteria. As a
bonus, we give algorithms for quantities that are missing in the literature,
including the KL divergence. In all cases, our approach matches the efficiency
of existing algorithms and, in several cases, reduces the runtime complexity by
a factor of the sentence length. We validate the implementation of our
framework through runtime experiments. We find our algorithms are up to 15 and
9 times faster than previous algorithms for computing the Shannon entropy and
the gradient of the generalized expectation objective, respectively.
</dc:description>
 <dc:date>2020-08-29</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.12988</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.13611</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Galaxy Morphology Classification using EfficientNet Architectures</dc:title>
 <dc:creator>Kalvankar, Shreyas</dc:creator>
 <dc:creator>Pandit, Hrushikesh</dc:creator>
 <dc:creator>Parwate, Pranav</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Astrophysics - Astrophysics of Galaxies</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We study the usage of EfficientNets and their applications to Galaxy
Morphology Classification. We explore the usage of EfficientNets into
predicting the vote fractions of the 79,975 testing images from the Galaxy Zoo
2 challenge on Kaggle. We evaluate this model using the standard competition
metric i.e. rmse score and rank among the top 3 on the public leaderboard with
a public score of 0.07765. We propose a fine-tuned architecture using
EfficientNetB5 to classify galaxies into seven classes - completely round
smooth, in-between smooth, cigarshaped smooth, lenticular, barred spiral,
unbarred spiral and irregular. The network along with other popular
convolutional networks are used to classify 29,941 galaxy images. Different
metrics such as accuracy, recall, precision, F1 score are used to evaluate the
performance of the model along with a comparative study of other state of the
art convolutional models to determine which one performs the best. We obtain an
accuracy of 93.7% on our classification model with an F1 score of 0.8857.
EfficientNets can be applied to large scale galaxy classification in future
optical space surveys which will provide a large amount of data such as the
Large Synoptic Space Telescope.
</dc:description>
 <dc:description>Comment: 13 pages, 7 figures, 8 tables</dc:description>
 <dc:date>2020-08-31</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.13611</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.13690</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation of machine learning algorithms for Health and Wellness
  applications: a tutorial</dc:title>
 <dc:creator>Tohka, Jussi</dc:creator>
 <dc:creator>van Gils, Mark</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Research on decision support applications in healthcare, such as those
related to diagnosis, prediction, treatment planning, etc., have seen
enormously increased interest recently. This development is thanks to the
increase in data availability as well as advances in artificial intelligence
and machine learning research. Highly promising research examples are published
daily. However, at the same time, there are some unrealistic expectations with
regards to the requirements for reliable development and objective validation
that is needed in healthcare settings. These expectations may lead to unmet
schedules and disappointments (or non-uptake) at the end-user side. It is the
aim of this tutorial to provide practical guidance on how to assess performance
reliably and efficiently and avoid common traps. Instead of giving a list of
do's and don't s, this tutorial tries to build a better understanding behind
these do's and don't s and presents both the most relevant performance
evaluation criteria as well as how to compute them. Along the way, we will
indicate common mistakes and provide references discussing various topics more
in-depth.
</dc:description>
 <dc:description>Comment: To be published in Computers in Biology and Medicine</dc:description>
 <dc:date>2020-08-31</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.13690</dc:identifier>
 <dc:identifier>doi:10.1016/j.compbiomed.2021.104324</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2008.13719</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RESA: Recurrent Feature-Shift Aggregator for Lane Detection</dc:title>
 <dc:creator>Zheng, Tu</dc:creator>
 <dc:creator>Fang, Hao</dc:creator>
 <dc:creator>Zhang, Yi</dc:creator>
 <dc:creator>Tang, Wenjian</dc:creator>
 <dc:creator>Yang, Zheng</dc:creator>
 <dc:creator>Liu, Haifeng</dc:creator>
 <dc:creator>Cai, Deng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Lane detection is one of the most important tasks in self-driving. Due to
various complex scenarios (e.g., severe occlusion, ambiguous lanes, etc.) and
the sparse supervisory signals inherent in lane annotations, lane detection
task is still challenging. Thus, it is difficult for the ordinary convolutional
neural network (CNN) to train in general scenes to catch subtle lane feature
from the raw image. In this paper, we present a novel module named REcurrent
Feature-Shift Aggregator (RESA) to enrich lane feature after preliminary
feature extraction with an ordinary CNN. RESA takes advantage of strong shape
priors of lanes and captures spatial relationships of pixels across rows and
columns. It shifts sliced feature map recurrently in vertical and horizontal
directions and enables each pixel to gather global information. RESA can
conjecture lanes accurately in challenging scenarios with weak appearance clues
by aggregating sliced feature map. Moreover, we propose a Bilateral Up-Sampling
Decoder that combines coarse-grained and fine-detailed features in the
up-sampling stage. It can recover the low-resolution feature map into
pixel-wise prediction meticulously. Our method achieves state-of-the-art
results on two popular lane detection benchmarks (CULane and Tusimple). Code
has been made available at: https://github.com/ZJULearning/resa.
</dc:description>
 <dc:date>2020-08-31</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2008.13719</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.00093</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Class-Incremental Continual Learning with Adversarial Shapley
  Value</dc:title>
 <dc:creator>Shim, Dongsub</dc:creator>
 <dc:creator>Mai, Zheda</dc:creator>
 <dc:creator>Jeong, Jihwan</dc:creator>
 <dc:creator>Sanner, Scott</dc:creator>
 <dc:creator>Kim, Hyunwoo</dc:creator>
 <dc:creator>Jang, Jongseong</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  As image-based deep learning becomes pervasive on every device, from cell
phones to smart watches, there is a growing need to develop methods that
continually learn from data while minimizing memory footprint and power
consumption. While memory replay techniques have shown exceptional promise for
this task of continual learning, the best method for selecting which buffered
images to replay is still an open question. In this paper, we specifically
focus on the online class-incremental setting where a model needs to learn new
classes continually from an online data stream. To this end, we contribute a
novel Adversarial Shapley value scoring method that scores memory data samples
according to their ability to preserve latent decision boundaries for
previously observed classes (to maintain learning stability and avoid
forgetting) while interfering with latent decision boundaries of current
classes being learned (to encourage plasticity and optimal learning of new
class boundaries). Overall, we observe that our proposed ASER method provides
competitive or improved performance compared to state-of-the-art replay-based
continual learning methods on a variety of datasets.
</dc:description>
 <dc:description>Comment: Proceedings of the 35th AAAI Conference on Artificial Intelligence
  (AAAI-21)</dc:description>
 <dc:date>2020-08-31</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.00093</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.00206</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RangeRCNN: Towards Fast and Accurate 3D Object Detection with Range
  Image Representation</dc:title>
 <dc:creator>Liang, Zhidong</dc:creator>
 <dc:creator>Zhang, Ming</dc:creator>
 <dc:creator>Zhang, Zehan</dc:creator>
 <dc:creator>Zhao, Xian</dc:creator>
 <dc:creator>Pu, Shiliang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present RangeRCNN, a novel and effective 3D object detection framework
based on the range image representation. Most existing methods are voxel-based
or point-based. Though several optimizations have been introduced to ease the
sparsity issue and speed up the running time, the two representations are still
computationally inefficient. Compared to them, the range image representation
is dense and compact which can exploit powerful 2D convolution. Even so, the
range image is not preferred in 3D object detection due to scale variation and
occlusion. In this paper, we utilize the dilated residual block (DRB) to better
adapt different object scales and obtain a more flexible receptive field.
Considering scale variation and occlusion, we propose the RV-PV-BEV (range
view-point view-bird's eye view) module to transfer features from RV to BEV.
The anchor is defined in BEV which avoids scale variation and occlusion.
Neither RV nor BEV can provide enough information for height estimation;
therefore, we propose a two-stage RCNN for better 3D detection performance. The
aforementioned point view not only serves as a bridge from RV to BEV but also
provides pointwise features for RCNN. Experiments show that RangeRCNN achieves
state-of-the-art performance on the KITTI dataset and the Waymo Open dataset,
and provides more possibilities for real-time 3D object detection. We further
introduce and discuss the data augmentation strategy for the range image based
method, which will be very valuable for future research on range image.
</dc:description>
 <dc:date>2020-08-31</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.00206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.00743</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bidirectional Attention Network for Monocular Depth Estimation</dc:title>
 <dc:creator>Aich, Shubhra</dc:creator>
 <dc:creator>Vianney, Jean Marie Uwabeza</dc:creator>
 <dc:creator>Islam, Md Amirul</dc:creator>
 <dc:creator>Kaur, Mannat</dc:creator>
 <dc:creator>Liu, Bingbing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper, we propose a Bidirectional Attention Network (BANet), an
end-to-end framework for monocular depth estimation (MDE) that addresses the
limitation of effectively integrating local and global information in
convolutional neural networks. The structure of this mechanism derives from a
strong conceptual foundation of neural machine translation, and presents a
light-weight mechanism for adaptive control of computation similar to the
dynamic nature of recurrent neural networks. We introduce bidirectional
attention modules that utilize the feed-forward feature maps and incorporate
the global context to filter out ambiguity. Extensive experiments reveal the
high degree of capability of this bidirectional attention model over
feed-forward baselines and other state-of-the-art methods for monocular depth
estimation on two challenging datasets -- KITTI and DIODE. We show that our
proposed approach either outperforms or performs at least on a par with the
state-of-the-art monocular depth estimation methods with less memory and
computational complexity.
</dc:description>
 <dc:description>Comment: Camera-ready for IEEE International Conference on Robotics and
  Automation (ICRA) 2021</dc:description>
 <dc:date>2020-09-01</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.00743</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.00887</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inspection of histological 3D reconstructions in virtual reality</dc:title>
 <dc:creator>Lobachev, Oleg</dc:creator>
 <dc:creator>Berthold, Moritz</dc:creator>
 <dc:creator>Pfeffer, Henriette</dc:creator>
 <dc:creator>Guthe, Michael</dc:creator>
 <dc:creator>Steiniger, Birte S.</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>68U05, 68U35, 92C55, 94A08</dc:subject>
 <dc:subject>I.3.7</dc:subject>
 <dc:description>  3D reconstruction is a challenging current topic in medical research. We
perform 3D reconstructions from serial sections stained by immunohistological
methods. This paper presents an immersive visualisation solution to quality
control (QC), inspect, and analyse such reconstructions. QC is essential to
establish correct digital processing methodologies. Visual analytics, such as
annotation placement, mesh painting, and classification utility, facilitates
medical research insights. We propose a visualisation in virtual reality (VR)
for these purposes. In this manner, we advance the microanatomical research of
human bone marrow and spleen. Both 3D reconstructions and original data are
available in VR. Data inspection is streamlined by subtle implementation
details and general immersion in VR.
</dc:description>
 <dc:description>Comment: Supplemental data under https://zenodo.org/record/4268535, video also
  available under https://youtu.be/FQSLiW1wQOc</dc:description>
 <dc:date>2020-09-02</dc:date>
 <dc:date>2020-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.00887</dc:identifier>
 <dc:identifier>https://www.frontiersin.org/articles/10.3389/frvir.2021.628449/abstract</dc:identifier>
 <dc:identifier>doi:10.3389/frvir.2021.628449</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.01036</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D Collision-Force-Map for Safe Human-Robot Collaboration</dc:title>
 <dc:creator>Svarny, Petr</dc:creator>
 <dc:creator>Rozlivek, Jakub</dc:creator>
 <dc:creator>Rustler, Lukas</dc:creator>
 <dc:creator>Hoffmann, Matej</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The need to guarantee safety of collaborative robots limits their
performance, in particular, their speed and hence cycle time. The standard
ISO/TS 15066 defines the Power and Force Limiting operation mode and prescribes
force thresholds that a moving robot is allowed to exert on human body parts
during impact, along with a simple formula to obtain maximum allowed speed of
the robot in the whole workspace. In this work, we measure the forces exerted
by two collaborative manipulators (UR10e and KUKA LBR iiwa) moving downward
against an impact measuring device. First, we empirically show that the impact
forces can vary by more than 100 percent within the robot workspace. The forces
are negatively correlated with the distance from the robot base and the height
in the workspace. Second, we present a data-driven model, 3D
Collision-Force-Map, predicting impact forces from distance, height, and
velocity and demonstrate that it can be trained on a limited number of data
points. Third, we analyze the force evolution upon impact and find that
clamping never occurs for the UR10e. We show that formulas relating robot mass,
velocity, and impact forces from ISO/TS 15066 are insufficient -- leading both
to significant underestimation and overestimation and thus to unnecessarily
long cycle times or even dangerous applications. We propose an empirical method
that can be deployed to quickly determine the optimal speed and position where
a task can be safely performed with maximum efficiency.
</dc:description>
 <dc:description>Comment: 8 pages, 9 figures, submitted for review</dc:description>
 <dc:date>2020-09-02</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.01036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.01424</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mononizing Binocular Videos</dc:title>
 <dc:creator>Hu, Wenbo</dc:creator>
 <dc:creator>Xia, Menghan</dc:creator>
 <dc:creator>Fu, Chi-Wing</dc:creator>
 <dc:creator>Wong, Tien-Tsin</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  This paper presents the idea ofmono-nizingbinocular videos and a frame-work
to effectively realize it. Mono-nize means we purposely convert abinocular
video into a regular monocular video with the stereo informationimplicitly
encoded in a visual but nearly-imperceptible form. Hence, wecan impartially
distribute and show the mononized video as an ordinarymonocular video. Unlike
ordinary monocular videos, we can restore from itthe original binocular video
and show it on a stereoscopic display. To start,we formulate an
encoding-and-decoding framework with the pyramidal de-formable fusion module to
exploit long-range correspondences between theleft and right views, a
quantization layer to suppress the restoring artifacts,and the compression
noise simulation module to resist the compressionnoise introduced by modern
video codecs. Our framework is self-supervised,as we articulate our objective
function with loss terms defined on the input:a monocular term for creating the
mononized video, an invertibility termfor restoring the original video, and a
temporal term for frame-to-framecoherence. Further, we conducted extensive
experiments to evaluate ourgenerated mononized videos and restored binocular
videos for diverse typesof images and 3D movies. Quantitative results on both
standard metrics anduser perception studies show the effectiveness of our
method.
</dc:description>
 <dc:description>Comment: 16 pages, 17 figures. Accepted in Siggraph Asia 2020</dc:description>
 <dc:date>2020-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.01424</dc:identifier>
 <dc:identifier>ACM Transactions on Graphics (SIGGRAPH Asia 2020 issue)</dc:identifier>
 <dc:identifier>doi:10.1145/3414685.3417764</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.01495</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounded Risk-Sensitive Markov Games: Forward Policy Design and Inverse
  Reward Learning with Iterative Reasoning and Cumulative Prospect Theory</dc:title>
 <dc:creator>Tian, Ran</dc:creator>
 <dc:creator>Sun, Liting</dc:creator>
 <dc:creator>Tomizuka, Masayoshi</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Classical game-theoretic approaches for multi-agent systems in both the
forward policy design problem and the inverse reward learning problem often
make strong rationality assumptions: agents perfectly maximize expected
utilities under uncertainties. Such assumptions, however, substantially
mismatch with observed humans' behaviors such as satisficing with sub-optimal,
risk-seeking, and loss-aversion decisions. In this paper, we investigate the
problem of bounded risk-sensitive Markov Game (BRSMG) and its inverse reward
learning problem for modeling human realistic behaviors and learning human
behavioral models. Drawing on iterative reasoning models and cumulative
prospect theory, we embrace that humans have bounded intelligence and maximize
risk-sensitive utilities in BRSMGs. Convergence analysis for both the forward
policy design and the inverse reward learning problems are established under
the BRSMG framework. We validate the proposed forward policy design and inverse
reward learning algorithms in a navigation scenario. The results show that the
behaviors of agents demonstrate both risk-averse and risk-seeking
characteristics. Moreover, in the inverse reward learning task, the proposed
bounded risk-sensitive inverse learning algorithm outperforms a baseline
risk-neutral inverse learning algorithm by effectively recovering not only more
accurate reward values but also the intelligence levels and the risk-measure
parameters given demonstrations of agents' interactive behaviors.
</dc:description>
 <dc:description>Comment: Accepted by 2021 AAAI Conference on Artificial Intelligence</dc:description>
 <dc:date>2020-09-03</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.01495</dc:identifier>
 <dc:identifier>2021 AAAI Conference on Artificial Intelligence</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.01678</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hamilton-Jacobi equations for inference of matrix tensor products</dc:title>
 <dc:creator>Chen, Hong-Bin</dc:creator>
 <dc:creator>Xia, Jiaming</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>82B44, 82D30</dc:subject>
 <dc:description>  We study the high-dimensional limit of the free energy associated with the
inference problem of finite-rank matrix tensor products. In general, we bound
the limit from above by the unique solution to a certain Hamilton-Jacobi
equation. Under additional assumptions on the nonlinearity in the equation
which is determined explicitly by the model, we identify the limit with the
solution. Two notions of solutions, weak solutions and viscosity solutions, are
considered, each of which has its own advantages and requires different
treatments. For concreteness, we apply our results to a model with i.i.d.
entries and symmetric interactions. In particular, for the first order and even
order tensor products, we identify the limit and obtain estimates on
convergence rates; for other odd orders, upper bounds are obtained.
</dc:description>
 <dc:description>Comment: 44 pages</dc:description>
 <dc:date>2020-09-03</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.01678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.01704</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Design Framework for Strongly $\chi^2$-Private Data Disclosure</dc:title>
 <dc:creator>Zamani, Amirreza</dc:creator>
 <dc:creator>Oechtering, Tobias J.</dc:creator>
 <dc:creator>Skoglund, Mikael</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study a stochastic disclosure control problem using
information-theoretic methods. The useful data to be disclosed depend on
private data that should be protected. Thus, we design a privacy mechanism to
produce new data which maximizes the disclosed information about the useful
data under a strong $\chi^2$-privacy criterion. For sufficiently small leakage,
the privacy mechanism design problem can be geometrically studied in the space
of probability distributions by a local approximation of the mutual
information. By using methods from Euclidean information geometry, the original
highly challenging optimization problem can be reduced to a problem of finding
the principal right-singular vector of a matrix, which characterizes the
optimal privacy mechanism. In two extensions we first consider a scenario where
an adversary receives a noisy version of the user's message and then we look
for a mechanism which finds $U$ based on observing $X$, maximizing the mutual
information between $U$ and $Y$ while satisfying the privacy criterion on $U$
and $Z$ under the Markov chain $(Z,Y)-X-U$.
</dc:description>
 <dc:description>Comment: 16 pages, 2 figures</dc:description>
 <dc:date>2020-09-03</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.01704</dc:identifier>
 <dc:identifier>vol. 16, pp. 2312-2325, 2021</dc:identifier>
 <dc:identifier>doi:10.1109/TIFS.2021.3053462</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.01807</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Physics-Consistent Data-driven Waveform Inversion with Adaptive Data
  Augmentation</dc:title>
 <dc:creator>Rojas-G&#xf3;mez, Ren&#xe1;n</dc:creator>
 <dc:creator>Yang, Jihyun</dc:creator>
 <dc:creator>Lin, Youzuo</dc:creator>
 <dc:creator>Theiler, James</dc:creator>
 <dc:creator>Wohlberg, Brendt</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Seismic full-waveform inversion (FWI) is a nonlinear computational imaging
technique that can provide detailed estimates of subsurface geophysical
properties. Solving the FWI problem can be challenging due to its ill-posedness
and high computational cost. In this work, we develop a new hybrid
computational approach to solve FWI that combines physics-based models with
data-driven methodologies. In particular, we develop a data augmentation
strategy that can not only improve the representativity of the training set but
also incorporate important governing physics into the training process and
therefore improve the inversion accuracy. To validate the performance, we apply
our method to synthetic elastic seismic waveform data generated from a
subsurface geologic model built on a carbon sequestration site at Kimberlina,
California. We compare our physics-consistent data-driven inversion method to
both purely physics-based and purely data-driven approaches and observe that
our method yields higher accuracy and greater generalization ability.
</dc:description>
 <dc:date>2020-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.01807</dc:identifier>
 <dc:identifier>doi:10.1109/LGRS.2020.3022021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.02019</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Learning of Robust and Safe Controllers for Cyber-Physical
  Systems</dc:title>
 <dc:creator>Bortolussi, Luca</dc:creator>
 <dc:creator>Cairoli, Francesca</dc:creator>
 <dc:creator>Carbone, Ginevra</dc:creator>
 <dc:creator>Franchina, Francesco</dc:creator>
 <dc:creator>Regolin, Enrico</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  We introduce a novel learning-based approach to synthesize safe and robust
controllers for autonomous Cyber-Physical Systems and, at the same time, to
generate challenging tests. This procedure combines formal methods for model
verification with Generative Adversarial Networks. The method learns two Neural
Networks: the first one aims at generating troubling scenarios for the
controller, while the second one aims at enforcing the safety constraints. We
test the proposed method on a variety of case studies.
</dc:description>
 <dc:date>2020-09-04</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.02019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.02188</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phenotypical Ontology Driven Framework for Multi-Task Learning</dc:title>
 <dc:creator>Ghalwash, Mohamed</dc:creator>
 <dc:creator>Yao, Zijun</dc:creator>
 <dc:creator>Chakraborty, Prithwish</dc:creator>
 <dc:creator>Codella, James</dc:creator>
 <dc:creator>Sow, Daby</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Despite the large number of patients in Electronic Health Records (EHRs), the
subset of usable data for modeling outcomes of specific phenotypes are often
imbalanced and of modest size. This can be attributed to the uneven coverage of
medical concepts in EHRs. In this paper, we propose OMTL, an Ontology-driven
Multi-Task Learning framework, that is designed to overcome such data
limitations. The key contribution of our work is the effective use of knowledge
from a predefined well-established medical relationship graph (ontology) to
construct a novel deep learning network architecture that mirrors this
ontology. It can effectively leverage knowledge from a well-established medical
relationship graph (ontology) by constructing a deep learning network
architecture that mirrors this graph. This enables common representations to be
shared across related phenotypes, and was found to improve the learning
performance. The proposed OMTL naturally allows for multitask learning of
different phenotypes on distinct predictive tasks. These phenotypes are tied
together by their semantic distance according to the external medical ontology.
Using the publicly available MIMIC-III database, we evaluate OMTL and
demonstrate its efficacy on several real patient outcome predictions over
state-of-the-art multi-task learning schemes.
</dc:description>
 <dc:description>Comment: To be appear on ACM CHIL 2021</dc:description>
 <dc:date>2020-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.02188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.02663</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DEFECTCHECKER: Automated Smart Contract Defect Detection by Analyzing
  EVM Bytecode</dc:title>
 <dc:creator>Chen, Jiachi</dc:creator>
 <dc:creator>Xia, Xin</dc:creator>
 <dc:creator>Lo, David</dc:creator>
 <dc:creator>Grundy, John</dc:creator>
 <dc:creator>Luo, Xiapu</dc:creator>
 <dc:creator>Chen, Ting</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Smart contracts are Turing-complete programs running on the blockchain. They
are immutable and cannot be modified, even when bugs are detected. Therefore,
ensuring smart contracts are bug-free and well-designed before deploying them
to the blockchain is extremely important. A contract defect is an error, flaw
or fault in a smart contract that causes it to produce an incorrect or
unexpected result, or to behave in unintended ways. Detecting and removing
contract defects can avoid potential bugs and make programs more robust. Our
previous work defined 20 contract defects for smart contracts and divided them
into five impact levels. According to our classification, contract defects with
seriousness level between 1-3 can lead to unwanted behaviors, e.g., a contract
being controlled by attackers. In this paper, we propose DefectChecker, a
symbolic execution-based approach and tool to detect eight contract defects
that can cause unwanted behaviors of smart contracts on the Ethereum blockchain
platform. DefectChecker can detect contract defects from smart contracts
bytecode. We compare DefectChecker with key previous works, including Oyente,
Mythril and Securify by using an open-source dataset. Our experimental results
show that DefectChecker performs much better than these tools in terms of both
speed and accuracy. We also applied DefectChecker to 165,621 distinct smart
contracts on the Ethereum platform. We found that 25,815 of these smart
contracts contain at least one of the contract defects that belongs to impact
level 1-3, including some real-world attacks.
</dc:description>
 <dc:date>2020-09-06</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.02663</dc:identifier>
 <dc:identifier>doi:10.1109/TSE.2021.3054928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.02742</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Matched Queues with Matching Batch Pair (m, n)</dc:title>
 <dc:creator>Liu, Heng-Li</dc:creator>
 <dc:creator>Li, Quan-Lin</dc:creator>
 <dc:creator>Zhang, Chi</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>90B06, 90B15, 90B22, 90B25, 68Q85, 60J28, 60J22</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:subject>H.3.5</dc:subject>
 <dc:subject>E.2</dc:subject>
 <dc:subject>E.3</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:subject>D.4.8</dc:subject>
 <dc:description>  In this paper, we discuss an interesting but challenging bilateral
stochastically matching problem: A more general matched queue with matching
batch pair (m, n) and two types (i.e., types A and B) of impatient customers,
where the arrivals of A- and B-customers are both Poisson processes, m
A-customers and n B-customers are matched as a group which leaves the system
immediately, and the customers' impatient behavior is to guarantee the
stability of the system. We show that this matched queue can be expressed as a
novel bidirectional level-dependent quasi-birth-and-death (QBD) process. Based
on this, we provide a detailed analysis for this matched queue, including the
system stability, the average stationary queue lengthes, and the average
sojourn time of any A-customer or B-customer. We believe that the methodology
and results developed in this paper can be applicable to dealing with more
general matched queueing systems, which are widely encountered in various
practical areas, for example, sharing economy, ridesharing platform, bilateral
market, organ transplantation, taxi services, assembly systems, and so on.
</dc:description>
 <dc:description>Comment: 52 Pages, 4 figures. arXiv admin note: text overlap with
  arXiv:2001.00946</dc:description>
 <dc:date>2020-09-06</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.02742</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.02993</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>distr6: R6 Object-Oriented Probability Distributions Interface in R</dc:title>
 <dc:creator>Sonabend, Raphael</dc:creator>
 <dc:creator>Kiraly, Franz</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  distr6 is an object-oriented (OO) probability distributions interface
leveraging the extensibility and scalability of R6, and the speed and
efficiency of Rcpp. Over 50 probability distributions are currently implemented
in the package with `core' methods including density, distribution, and
generating functions, and more `exotic' ones including hazards and distribution
function anti-derivatives. In addition to simple distributions, distr6 supports
compositions such as truncation, mixtures, and product distributions. This
paper presents the core functionality of the package and demonstrates examples
for key use-cases. In addition this paper provides a critical review of the
object-oriented programming paradigms in R and describes some novel
implementations for design patterns and core object-oriented features
introduced by the package for supporting distr6 components.
</dc:description>
 <dc:description>Comment: Accepted in The R Journal</dc:description>
 <dc:date>2020-09-07</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.02993</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.03015</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Watermarking Transformer: Towards Tracing Text Provenance
  with Data Hiding</dc:title>
 <dc:creator>Abdelnabi, Sahar</dc:creator>
 <dc:creator>Fritz, Mario</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Recent advances in natural language generation have introduced powerful
language models with high-quality output text. However, this raises concerns
about the potential misuse of such models for malicious purposes. In this
paper, we study natural language watermarking as a defense to help better mark
and trace the provenance of text. We introduce the Adversarial Watermarking
Transformer (AWT) with a jointly trained encoder-decoder and adversarial
training that, given an input text and a binary message, generates an output
text that is unobtrusively encoded with the given message. We further study
different training and inference strategies to achieve minimal changes to the
semantics and correctness of the input text.
  AWT is the first end-to-end model to hide data in text by automatically
learning -- without ground truth -- word substitutions along with their
locations in order to encode the message. We empirically show that our model is
effective in largely preserving text utility and decoding the watermark while
hiding its presence against adversaries. Additionally, we demonstrate that our
method is robust against a range of attacks.
</dc:description>
 <dc:date>2020-09-07</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.03015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.04286</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancing and Learning Denoiser without Clean Reference</dc:title>
 <dc:creator>Zhao, Rui</dc:creator>
 <dc:creator>Lun, Daniel P. K.</dc:creator>
 <dc:creator>Lam, Kin-Man</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent studies on learning-based image denoising have achieved promising
performance on various noise reduction tasks. Most of these deep denoisers are
trained either under the supervision of clean references, or unsupervised on
synthetic noise. The assumption with the synthetic noise leads to poor
generalization when facing real photographs. To address this issue, we propose
a novel deep image-denoising method by regarding the noise reduction task as a
special case of the noise transference task. Learning noise transference
enables the network to acquire the denoising ability by observing the corrupted
samples. The results on real-world denoising benchmarks demonstrate that our
proposed method achieves promising performance on removing realistic noises,
making it a potential solution to practical noise reduction problems.
</dc:description>
 <dc:date>2020-09-09</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.04286</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.04420</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cephalogram Synthesis and Landmark Detection in Dental Cone-Beam CT
  Systems</dc:title>
 <dc:creator>Huang, Yixing</dc:creator>
 <dc:creator>Fan, Fuxin</dc:creator>
 <dc:creator>Syben, Christopher</dc:creator>
 <dc:creator>Roser, Philipp</dc:creator>
 <dc:creator>Mill, Leonid</dc:creator>
 <dc:creator>Maier, Andreas</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Due to the lack of standardized 3D cephalometric analytic methodology, 2D
cephalograms synthesized from 3D cone-beam computed tomography (CBCT) volumes
are widely used for cephalometric analysis in dental CBCT systems. However,
compared with conventional X-ray film based cephalograms, such synthetic
cephalograms lack image contrast and resolution. In addition, the radiation
dose during the scan for 3D reconstruction causes potential health risks. In
this work, we propose a sigmoid-based intensity transform that uses the
nonlinear optical property of X-ray films to increase image contrast of
synthetic cephalograms. To improve image resolution, super resolution deep
learning techniques are investigated. For low dose purpose, the pixel-to-pixel
generative adversarial network (pix2pixGAN) is proposed for 2D cephalogram
synthesis directly from two CBCT projections. For landmark detection in the
synthetic cephalograms, an efficient automatic landmark detection method using
the combination of LeNet-5 and ResNet50 is proposed. Our experiments
demonstrate the efficacy of pix2pixGAN in 2D cephalogram synthesis, achieving
an average peak signal-to-noise ratio (PSNR) value of 33.8 with reference to
the cephalograms synthesized from 3D CBCT volumes. Pix2pixGAN also achieves the
best performance in super resolution, achieving an average PSNR value of 32.5
without the introduction of checkerboard or jagging artifacts. Our proposed
automatic landmark detection method achieves 86.7% successful detection rate in
the 2 mm clinical acceptable range on the ISBI Test1 data, which is comparable
to the state-of-the-art methods. The method trained on conventional
cephalograms can be directly applied to landmark detection in the synthetic
cephalograms, achieving 93.0% and 80.7% successful detection rate in 4 mm
precision range for synthetic cephalograms from 3D volumes and 2D projections
respectively.
</dc:description>
 <dc:date>2020-09-09</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.04420</dc:identifier>
 <dc:identifier>Medical Image Analysis 2021</dc:identifier>
 <dc:identifier>doi:10.1016/j.media.2021.102028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.04509</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GPU-accelerated machine learning inference as a service for computing in
  neutrino experiments</dc:title>
 <dc:creator>Wang, Michael</dc:creator>
 <dc:creator>Yang, Tingjun</dc:creator>
 <dc:creator>Flechas, Maria Acosta</dc:creator>
 <dc:creator>Harris, Philip</dc:creator>
 <dc:creator>Hawks, Benjamin</dc:creator>
 <dc:creator>Holzman, Burt</dc:creator>
 <dc:creator>Knoepfel, Kyle</dc:creator>
 <dc:creator>Krupa, Jeffrey</dc:creator>
 <dc:creator>Pedro, Kevin</dc:creator>
 <dc:creator>Tran, Nhan</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>High Energy Physics - Experiment</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  Machine learning algorithms are becoming increasingly prevalent and
performant in the reconstruction of events in accelerator-based neutrino
experiments. These sophisticated algorithms can be computationally expensive.
At the same time, the data volumes of such experiments are rapidly increasing.
The demand to process billions of neutrino events with many machine learning
algorithm inferences creates a computing challenge. We explore a computing
model in which heterogeneous computing with GPU coprocessors is made available
as a web service. The coprocessors can be efficiently and elastically deployed
to provide the right amount of computing for a given processing task. With our
approach, Services for Optimized Network Inference on Coprocessors (SONIC), we
integrate GPU acceleration specifically for the ProtoDUNE-SP reconstruction
chain without disrupting the native computing workflow. With our integrated
framework, we accelerate the most time-consuming task, track and particle
shower hit identification, by a factor of 17. This results in a factor of 2.7
reduction in the total processing time when compared with CPU-only production.
For this particular task, only 1 GPU is required for every 68 CPU threads,
providing a cost-effective solution.
</dc:description>
 <dc:description>Comment: 15 pages, 7 figures, 2 tables</dc:description>
 <dc:date>2020-09-09</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.04509</dc:identifier>
 <dc:identifier>doi:10.3389/fdata.2020.604083</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.05740</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preamble-Based Packet Detection in Wi-Fi: A Deep Learning Approach</dc:title>
 <dc:creator>Ninkovic, Vukan</dc:creator>
 <dc:creator>Vukobratovic, Dejan</dc:creator>
 <dc:creator>Valka, Aleksandar</dc:creator>
 <dc:creator>Dumic, Dejan</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Wi-Fi systems based on the family of IEEE 802.11 standards that operate in
unlicenced bands are the most popular wireless interfaces that use Listen
Before Talk (LBT) methodology for channel access. Distinctive feature of
majority of LBT-based systems is that the transmitters use preambles that
precede the data to allow the receivers to acquire initial signal detection and
synchronization. The first digital processing step at the receiver applied over
the incoming discrete-time complex-baseband samples after analog-to-digital
conversion is the packet detection step, i.e., the detection of the initial
samples of each of the frames arriving within the incoming stream. Since the
preambles usually contain repetitions of training symbols with good correlation
properties, conventional digital receivers apply correlation-based methods for
packet detection. Following the recent interest in data-based deep learning
(DL) methods for physical layer signal processing, in this paper, we challenge
the conventional methods with DL-based approach for Wi-Fi packet detection.
Using one-dimensional Convolutional Neural Networks (1D-CNN), we present a
detailed complexity vs performance analysis and comparison between conventional
and DL-based Wi-Fi packet detection approaches.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:2004.11716</dc:description>
 <dc:date>2020-09-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.05740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.06027</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ReviewViz: Assisting Developers Perform Empirical Study on Energy
  Consumption Related Reviews for Mobile Applications</dc:title>
 <dc:creator>Hadi, Mohammad Abdul</dc:creator>
 <dc:creator>Fard, Fatemeh H</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Improving the energy efficiency of mobile applications is a topic that has
gained a lot of attention recently. It has been addressed in a number of ways
such as identifying energy bugs and developing a catalog of energy patterns.
Previous work shows that users discuss the battery-related issues (energy
inefficiency or energy consumption) of the apps in their reviews. However,
there is no work that addresses the automatic extraction of battery-related
issues from users' feedback. In this paper, we report on a visualization tool
that is developed to empirically study machine learning algorithms and text
features to automatically identify the energy consumption specific reviews with
the highest accuracy. Other than the common machine learning algorithms, we
utilize deep learning models with different word embeddings to compare the
results. Furthermore, to help the developers extract the main topics that are
discussed in the reviews, two states of the art topic modeling algorithms are
applied. The visualizations of the topics represent the keywords that are
extracted for each topic along with a comparison with the results of string
matching. The developed web-browser based interactive visualization tool is a
novel framework developed with the intention of giving the app developers
insights about running time and accuracy of machine learning and deep learning
models as well as extracted topics. The tool makes it easier for the developers
to traverse through the extensive result set generated by the text
classification and topic modeling algorithms. The dynamic-data structure used
for the tool stores the baseline-results of the discussed approaches and is
updated when applied on new datasets. The tool is open-sourced to replicate the
research results.
</dc:description>
 <dc:description>Comment: 4 pages, 5 figures</dc:description>
 <dc:date>2020-09-13</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.06027</dc:identifier>
 <dc:identifier>doi:10.1145/3387905.3388605</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.06279</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Fragmentation Can Undermine the Public Health Response to COVID-19</dc:title>
 <dc:creator>Chen, Andrew Tzer-Yeu</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Responses to COVID-19 have largely been led by local, national, and
international public health agencies, who have activated their pandemic plans
and opened the epidemiological toolkit of modelling, testing, isolation and
movement restrictions, surveillance, and contact tracing. In the contemporary
tech-heavy world, many assumed that the common manual process of human
investigators and phone calls could or should be replaced by digital solutions.
But it's not as simple as &quot;add more technology&quot; - the complex way in which
users and societies interact with the technology has significant impacts on
effectiveness. When efforts are not well co-ordinated, fragmentation in system
design and user experience can negatively impact the public health response.
This article briefly covers the journey of how contact tracing registers and
digital diaries evolved in New Zealand during the COVID-19 pandemic, the
initial poor outcomes caused by the lack of central co-ordination, and the
later improvement.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures, published by ACM Interactions (online at
  https://interactions.acm.org/blog/view/how-fragmentation-can-undermine-the-public-health-response-to-covid-19,
  in magazine in 2021)</dc:description>
 <dc:date>2020-09-14</dc:date>
 <dc:date>2020-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.06279</dc:identifier>
 <dc:identifier>doi:10.1145/3448413</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.06797</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Competing AI: How does competition feedback affect machine learning?</dc:title>
 <dc:creator>Ginart, Antonio</dc:creator>
 <dc:creator>Zhang, Eva</dc:creator>
 <dc:creator>Kwon, Yongchan</dc:creator>
 <dc:creator>Zou, James</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This papers studies how competition affects machine learning (ML) predictors.
As ML becomes more ubiquitous, it is often deployed by companies to compete
over customers. For example, digital platforms like Yelp use ML to predict user
preference and make recommendations. A service that is more often queried by
users, perhaps because it more accurately anticipates user preferences, is also
more likely to obtain additional user data (e.g. in the form of a Yelp review).
Thus, competing predictors cause feedback loops whereby a predictor's
performance impacts what training data it receives and biases its predictions
over time. We introduce a flexible model of competing ML predictors that
enables both rapid experimentation and theoretical tractability. We show with
empirical and mathematical analysis that competition causes predictors to
specialize for specific sub-populations at the cost of worse performance over
the general population. We further analyze the impact of predictor
specialization on the overall prediction quality experienced by users. We show
that having too few or too many competing predictors in a market can hurt the
overall prediction quality. Our theory is complemented by experiments on
several real datasets using popular learning algorithms, such as neural
networks and nearest neighbor methods.
</dc:description>
 <dc:description>Comment: Accepted to AISTATS 2021</dc:description>
 <dc:date>2020-09-14</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.06797</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.06806</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incentive-compatible mechanisms for online resource allocation in
  mobility-as-a-service systems</dc:title>
 <dc:creator>Xi, Haoning</dc:creator>
 <dc:creator>Liu, Wei</dc:creator>
 <dc:creator>Rey, David</dc:creator>
 <dc:creator>Waller, S. Travis</dc:creator>
 <dc:creator>Kilby, Philip</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In the context of `Everything-as-a-Service', the transportation sector has
been evolving towards user-centric business models in which customized services
and mode-agnostic mobility resources are priced in a unified framework. Yet, in
the vast majority of studies on Mobility as a Service (MaaS) systems, mobility
resource pricing is based on segmented travel modes, e.g. private vehicle,
public transit and shared mobility services. This study attempts to address
this research gap by introducing innovative auction-based online MaaS
mechanisms where users can bid for any amount of mode-agnostic mobility
resources based on their willingness to pay and preferences. We take the
perspective of a MaaS regulator which aims to maximize social welfare by
allocating mobility resources to users. We propose two mechanisms which allow
users to either pay for the immediate use of mobility service (pay-as-you-go),
or to subscribe to mobility service packages (pay-as-a-package). We cast the
proposed auction-based mechanisms as online resource allocation problems where
users compete for MaaS resources and bid for travel time per trip. We propose
(integer-) linear programming formulations to accommodate user bids based on
available mobility resources in an online optimization approach. We show that
the proposed MaaS mechanisms are incentive-compatible, develop customized
online algorithms and derive performance bounds based on competitive analysis.
Extensive numerical simulations are conducted on large scale instances
generated from realistic mobility data, which highlight the benefits of the
proposed MaaS mechanisms and the effectiveness of the proposed online
optimization approaches.
</dc:description>
 <dc:date>2020-09-14</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.06806</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.06914</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The impact of social influence in Australian real-estate: market
  forecasting with a spatial agent-based model</dc:title>
 <dc:creator>Evans, Benjamin Patrick</dc:creator>
 <dc:creator>Glavatskiy, Kirill</dc:creator>
 <dc:creator>Harr&#xe9;, Michael S.</dc:creator>
 <dc:creator>Prokopenko, Mikhail</dc:creator>
 <dc:subject>Quantitative Finance - Computational Finance</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Housing markets are inherently spatial, yet many existing models fail to
capture this spatial dimension. Here we introduce a new graph-based approach
for incorporating a spatial component in a large-scale urban housing
agent-based model (ABM). The model explicitly captures several social and
economic factors that influence the agents' decision-making behaviour (such as
fear of missing out, their trend following aptitude, and the strength of their
submarket outreach), and interprets these factors in spatial terms. The
proposed model is calibrated and validated with the housing market data for the
Greater Sydney region. The ABM simulation results not only include predictions
for the overall market, but also produce area-specific forecasting at the level
of local government areas within Sydney as arising from individual buy and sell
decisions. In addition, the simulation results elucidate agent preferences in
submarkets, highlighting differences in agent behaviour, for example, between
first-time home buyers and investors, and between both local and overseas
investors.
</dc:description>
 <dc:description>Comment: 25 pages + 31 page appendix</dc:description>
 <dc:date>2020-09-15</dc:date>
 <dc:date>2021-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.06914</dc:identifier>
 <dc:identifier>doi:10.1007/s11403-021-00324-7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.07076</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comments on &quot;Design of momentum fractional LMS for Hammerstein nonlinear
  system identification with application to electrically stimulated muscle
  model&quot;</dc:title>
 <dc:creator>Wahab, Abdul</dc:creator>
 <dc:creator>Khan, Shujaat</dc:creator>
 <dc:creator>Khan, Farrukh Zeeshan</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  The purpose of this article is to discuss some aspects of the convergence
analysis performed in the paper [Design of momentum fractional LMS for
Hammerstein nonlinear system identification with application to electrically
stimulated muscle model, Eur. Phys. J. Plus (2019) \textbf{134}: 407]. It is
highlighted that the way the authors prove convergence suffers a lack of
correct and valid mathematical justifications.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:2003.09597</dc:description>
 <dc:date>2020-09-10</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.07076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.08063</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FLAME: Differentially Private Federated Learning in the Shuffle Model</dc:title>
 <dc:creator>Liu, Ruixuan</dc:creator>
 <dc:creator>Cao, Yang</dc:creator>
 <dc:creator>Chen, Hong</dc:creator>
 <dc:creator>Guo, Ruoyang</dc:creator>
 <dc:creator>Yoshikawa, Masatoshi</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Federated Learning (FL) is a promising machine learning paradigm that enables
the analyzer to train a model without collecting users' raw data. To ensure
users' privacy, differentially private federated learning has been intensively
studied. The existing works are mainly based on the \textit{curator model} or
\textit{local model} of differential privacy. However, both of them have pros
and cons. The curator model allows greater accuracy but requires a trusted
analyzer. In the local model where users randomize local data before sending
them to the analyzer, a trusted analyzer is not required but the accuracy is
limited. In this work, by leveraging the \textit{privacy amplification} effect
in the recently proposed shuffle model of differential privacy, we achieve the
best of two worlds, i.e., accuracy in the curator model and strong privacy
without relying on any trusted party. We first propose an FL framework in the
shuffle model and a simple protocol (SS-Simple) extended from existing work. We
find that SS-Simple only provides an insufficient privacy amplification effect
in FL since the dimension of the model parameter is quite large. To solve this
challenge, we propose an enhanced protocol (SS-Double) to increase the privacy
amplification effect by subsampling. Furthermore, for boosting the utility when
the model size is greater than the user population, we propose an advanced
protocol (SS-Topk) with gradient sparsification techniques. We also provide
theoretical analysis and numerical evaluations of the privacy amplification of
the proposed protocols. Experiments on real-world dataset validate that SS-Topk
improves the testing accuracy by 60.7\% than the local model based FL.
</dc:description>
 <dc:description>Comment: accepted by AAAI-21</dc:description>
 <dc:date>2020-09-17</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.08063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.08070</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Transferability of Minimal Prediction Preserving Inputs in
  Question Answering</dc:title>
 <dc:creator>Longpre, Shayne</dc:creator>
 <dc:creator>Lu, Yi</dc:creator>
 <dc:creator>DuBois, Christopher</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recent work (Feng et al., 2018) establishes the presence of short,
uninterpretable input fragments that yield high confidence and accuracy in
neural models. We refer to these as Minimal Prediction Preserving Inputs
(MPPIs). In the context of question answering, we investigate competing
hypotheses for the existence of MPPIs, including poor posterior calibration of
neural models, lack of pretraining, and &quot;dataset bias&quot; (where a model learns to
attend to spurious, non-generalizable cues in the training data). We discover a
perplexing invariance of MPPIs to random training seed, model architecture,
pretraining, and training domain. MPPIs demonstrate remarkable transferability
across domains achieving significantly higher performance than comparably short
queries. Additionally, penalizing over-confidence on MPPIs fails to improve
either generalization or adversarial robustness. These results suggest the
interpretability of MPPIs is insufficient to characterize generalization
capacity of these models. We hope this focused investigation encourages more
systematic analysis of model behavior outside of the human interpretable
distribution of examples.
</dc:description>
 <dc:date>2020-09-17</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.08070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.08453</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet
  without Tricks</dc:title>
 <dc:creator>Shen, Zhiqiang</dc:creator>
 <dc:creator>Savvides, Marios</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We introduce a simple yet effective distillation framework that is able to
boost the vanilla ResNet-50 to 80%+ Top-1 accuracy on ImageNet without tricks.
We construct such a framework through analyzing the problems in the existing
classification system and simplify the base method ensemble knowledge
distillation via discriminators by: (1) adopting the similarity loss and
discriminator only on the final outputs and (2) using the average of softmax
probabilities from all teacher ensembles as the stronger supervision.
Intriguingly, three novel perspectives are presented for distillation: (1)
weight decay can be weakened or even completely removed since the soft label
also has a regularization effect; (2) using a good initialization for students
is critical; and (3) one-hot/hard label is not necessary in the distillation
process if the weights are well initialized. We show that such a
straight-forward framework can achieve state-of-the-art results without
involving any commonly-used techniques, such as architecture modification;
outside training data beyond ImageNet; autoaug/randaug; cosine learning rate;
mixup/cutmix training; label smoothing; etc. Our method obtains 80.67% top-1
accuracy on ImageNet using a single crop-size of 224x224 with vanilla
ResNet-50, outperforming the previous state-of-the-arts by a significant margin
under the same network structure. Our result can be regarded as a strong
baseline using knowledge distillation, and to our best knowledge, this is also
the first method that is able to boost vanilla ResNet-50 to surpass 80% on
ImageNet without architecture modification or additional training data. On
smaller ResNet-18, our distillation framework consistently improves from 69.76%
to 73.19%, which shows tremendous practical values in real-world applications.
Our code and models are available at: https://github.com/szq0214/MEAL-V2.
</dc:description>
 <dc:description>Comment: 12 pages. Code and trained models are available at:
  https://github.com/szq0214/MEAL-V2</dc:description>
 <dc:date>2020-09-17</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.08453</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.08576</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pruning Neural Networks at Initialization: Why are We Missing the Mark?</dc:title>
 <dc:creator>Frankle, Jonathan</dc:creator>
 <dc:creator>Dziugaite, Gintare Karolina</dc:creator>
 <dc:creator>Roy, Daniel M.</dc:creator>
 <dc:creator>Carbin, Michael</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recent work has explored the possibility of pruning neural networks at
initialization. We assess proposals for doing so: SNIP (Lee et al., 2019),
GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude
pruning. Although these methods surpass the trivial baseline of random pruning,
they remain below the accuracy of magnitude pruning after training, and we
endeavor to understand why. We show that, unlike pruning after training,
randomly shuffling the weights these methods prune within each layer or
sampling new initial values preserves or improves accuracy. As such, the
per-weight pruning decisions made by these methods can be replaced by a
per-layer choice of the fraction of weights to prune. This property suggests
broader challenges with the underlying pruning heuristics, the desire to prune
at initialization, or both.
</dc:description>
 <dc:description>Comment: Published in ICLR 2021</dc:description>
 <dc:date>2020-09-17</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.08576</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.08709</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Progressive Semantic-Aware Style Transformation for Blind Face
  Restoration</dc:title>
 <dc:creator>Chen, Chaofeng</dc:creator>
 <dc:creator>Li, Xiaoming</dc:creator>
 <dc:creator>Yang, Lingbo</dc:creator>
 <dc:creator>Lin, Xianhui</dc:creator>
 <dc:creator>Zhang, Lei</dc:creator>
 <dc:creator>Wong, Kwan-Yee K.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Face restoration is important in face image processing, and has been widely
studied in recent years. However, previous works often fail to generate
plausible high quality (HQ) results for real-world low quality (LQ) face
images. In this paper, we propose a new progressive semantic-aware style
transformation framework, named PSFR-GAN, for face restoration. Specifically,
instead of using an encoder-decoder framework as previous methods, we formulate
the restoration of LQ face images as a multi-scale progressive restoration
procedure through semantic-aware style transformation. Given a pair of LQ face
image and its corresponding parsing map, we first generate a multi-scale
pyramid of the inputs, and then progressively modulate different scale features
from coarse-to-fine in a semantic-aware style transfer way. Compared with
previous networks, the proposed PSFR-GAN makes full use of the semantic
(parsing maps) and pixel (LQ images) space information from different scales of
input pairs. In addition, we further introduce a semantic aware style loss
which calculates the feature style loss for each semantic region individually
to improve the details of face textures. Finally, we pretrain a face parsing
network which can generate decent parsing maps from real-world LQ face images.
Experiment results show that our model trained with synthetic data can not only
produce more realistic high-resolution results for synthetic LQ inputs and but
also generalize better to natural LQ face images compared with state-of-the-art
methods. Codes are available at https://github.com/chaofengc/PSFRGAN.
</dc:description>
 <dc:description>Comment: Accepted to CVPR2021, https://github.com/chaofengc/PSFRGAN</dc:description>
 <dc:date>2020-09-18</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.08709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.08905</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deviation bound for non-causal machine learning</dc:title>
 <dc:creator>Garnier, R&#xe9;my</dc:creator>
 <dc:creator>Langhendries, Rapha&#xeb;l</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Concentration inequalities are widely used for analyzing machine learning
algorithms. However, current concentration inequalities cannot be applied to
some of the most popular deep neural networks, notably in natural language
processing. This is mostly due to the non-causal nature of such involved data,
in the sense that each data point depends on other neighbor data points. In
this paper, a framework for modeling non-causal random fields is provided and a
Hoeffding-type concentration inequality is obtained for this framework. The
proof of this result relies on a local approximation of the non-causal random
field by a function of a finite number of i.i.d. random variables.
</dc:description>
 <dc:description>Comment: under review</dc:description>
 <dc:date>2020-09-18</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.08905</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.09090</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MIRAGE: Mitigating Conflict-Based Cache Attacks with a Practical
  Fully-Associative Design</dc:title>
 <dc:creator>Saileshwar, Gururaj</dc:creator>
 <dc:creator>Qureshi, Moinuddin</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Shared processor caches are vulnerable to conflict-based side-channel
attacks, where an attacker can monitor access patterns of a victim by evicting
victim cache lines using cache-set conflicts. Recent mitigations propose
randomized mapping of addresses to cache lines to obfuscate the locations of
set-conflicts. However, these are vulnerable to new attacks that discover
conflicting sets of addresses despite such mitigations, because these designs
select eviction-candidates from a small set of conflicting lines.
  This paper presents Mirage, a practical design for a fully associative cache,
wherein eviction candidates are selected randomly from all lines resident in
the cache, to be immune to set-conflicts. A key challenge for enabling such
designs in large shared caches (containing tens of thousands of cache lines) is
the complexity of cache-lookup, as a naive design can require searching through
all the resident lines. Mirage achieves full-associativity while retaining
practical set-associative lookups by decoupling placement and replacement,
using pointer-based indirection from tag-store to data-store to allow a newly
installed address to globally evict the data of any random resident line. To
eliminate set-conflicts, Mirage provisions extra invalid tags in a
skewed-associative tag-store design where lines can be installed without
set-conflict, along with a load-aware skew-selection policy that guarantees the
availability of sets with invalid tags. Our analysis shows Mirage provides the
global eviction property of a fully-associative cache throughout system
lifetime (violations of full-associativity, i.e. set-conflicts, occur less than
once in 10^4 to 10^17 years), thus offering a principled defense against any
eviction-set discovery and any potential conflict based attacks. Mirage incurs
limited slowdown (2%) and 17-20% extra storage compared to a non-secure cache.
</dc:description>
 <dc:description>Comment: Accepted to appear in USENIX Security 2021. This camera-ready version
  has an updated Security discussion (Sec-5, Sec-6) and Appendix (new Gem5
  results) compared to previous Arxiv version</dc:description>
 <dc:date>2020-09-18</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.09090</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.09802</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Intrinsic Redundancy in Huge Natural Deduction proofs II:
  Analysing $M_{\imply}$ Super-Polynomial Proofs</dc:title>
 <dc:creator>Haeusler, Edward Hermann</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  This article precisely defines huge proofs within the system of Natural
Deduction for the Minimal implicational propositional logic \mil. This is what
we call an unlimited family of super-polynomial proofs. We consider huge
families of expanded normal form mapped proofs, a device to explicitly help to
count the E-parts of a normal proof in an adequate way. Thus, we show that for
almost all members of a super-polynomial family there at least one sub-proof or
derivation of each of them that is repeated super-polynomially many times. This
last property we call super-polynomial redundancy. Almost all, precisely means
that there is a size of the conclusion of proofs that every proof with
conclusion bigger than this size and that is huge is highly redundant too. This
result points out to a refinement of compression methods previously presented
and an alternative and simpler proof that CoNP=NP.
</dc:description>
 <dc:description>Comment: Second version only changes the format of the paper; it was correct a
  small typo in figure 5 and replaced l by \lambda in an index in the proof of
  theorem 12. arXiv admin note: text overlap with arXiv:2004.10659</dc:description>
 <dc:date>2020-09-17</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.09802</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.10142</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stereopagnosia: Fooling Stereo Networks with Adversarial Perturbations</dc:title>
 <dc:creator>Wong, Alex</dc:creator>
 <dc:creator>Mundhra, Mukund</dc:creator>
 <dc:creator>Soatto, Stefano</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We study the effect of adversarial perturbations of images on the estimates
of disparity by deep learning models trained for stereo. We show that
imperceptible additive perturbations can significantly alter the disparity map,
and correspondingly the perceived geometry of the scene. These perturbations
not only affect the specific model they are crafted for, but transfer to models
with different architecture, trained with different loss functions. We show
that, when used for adversarial data augmentation, our perturbations result in
trained models that are more robust, without sacrificing overall accuracy of
the model. This is unlike what has been observed in image classification, where
adding the perturbed images to the training set makes the model less vulnerable
to adversarial perturbations, but to the detriment of overall accuracy. We test
our method using the most recent stereo networks and evaluate their performance
on public benchmark datasets.
</dc:description>
 <dc:date>2020-09-21</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.10142</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.10369</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Goals and Measures for Analyzing Power Consumption Data in Manufacturing
  Enterprises</dc:title>
 <dc:creator>Henning, S&#xf6;ren</dc:creator>
 <dc:creator>Hasselbring, Wilhelm</dc:creator>
 <dc:creator>Burmester, Heinz</dc:creator>
 <dc:creator>M&#xf6;bius, Armin</dc:creator>
 <dc:creator>Wojcieszak, Maik</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The Internet of Things adoption in the manufacturing industry allows
enterprises to monitor their electrical power consumption in real time and at
machine level. In this paper, we follow up on such emerging opportunities for
data acquisition and show that analyzing power consumption in manufacturing
enterprises can serve a variety of purposes. Apart from the prevalent goal of
reducing overall power consumption for economical and ecological reasons, such
data can, for example, be used to improve production processes.
  Based on a literature review and expert interviews, we discuss how analyzing
power consumption data can serve the goals reporting, optimization, fault
detection, and predictive maintenance. To tackle these goals, we propose to
implement the measures real-time data processing, multi-level monitoring,
temporal aggregation, correlation, anomaly detection, forecasting,
visualization, and alerting in software.
  We transfer our findings to two manufacturing enterprises and show how the
presented goals reflect in these enterprises. In a pilot implementation of a
power consumption analytics platform, we show how our proposed measures can be
implemented with a microservice-based architecture, stream processing
techniques, and the fog computing paradigm. We provide the implementations as
open source as well as a public demo allowing to reproduce and extend our
research.
</dc:description>
 <dc:description>Comment: 24 pages</dc:description>
 <dc:date>2020-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.10369</dc:identifier>
 <dc:identifier>Journal of Data, Information and Management (2021)</dc:identifier>
 <dc:identifier>doi:10.1007/s42488-021-00043-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.10765</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Age-Net: An MRI-Based Iterative Framework for Brain Biological Age
  Estimation</dc:title>
 <dc:creator>Armanious, Karim</dc:creator>
 <dc:creator>Abdulatif, Sherif</dc:creator>
 <dc:creator>Shi, Wenbin</dc:creator>
 <dc:creator>Salian, Shashank</dc:creator>
 <dc:creator>K&#xfc;stner, Thomas</dc:creator>
 <dc:creator>Weiskopf, Daniel</dc:creator>
 <dc:creator>Hepp, Tobias</dc:creator>
 <dc:creator>Gatidis, Sergios</dc:creator>
 <dc:creator>Yang, Bin</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The concept of biological age (BA), although important in clinical practice,
is hard to grasp mainly due to the lack of a clearly defined reference
standard. For specific applications, especially in pediatrics, medical image
data are used for BA estimation in a routine clinical context. Beyond this
young age group, BA estimation is mostly restricted to whole-body assessment
using non-imaging indicators such as blood biomarkers, genetic and cellular
data. However, various organ systems may exhibit different aging
characteristics due to lifestyle and genetic factors. Thus, a whole-body
assessment of the BA does not reflect the deviations of aging behavior between
organs. To this end, we propose a new imaging-based framework for
organ-specific BA estimation. In this initial study, we focus mainly on brain
MRI. As a first step, we introduce a chronological age (CA) estimation
framework using deep convolutional neural networks (Age-Net). We quantitatively
assess the performance of this framework in comparison to existing
state-of-the-art CA estimation approaches. Furthermore, we expand upon Age-Net
with a novel iterative data-cleaning algorithm to segregate atypical-aging
patients (BA $\not \approx$ CA) from the given population. We hypothesize that
the remaining population should approximate the true BA behavior. We apply the
proposed methodology on a brain magnetic resonance image (MRI) dataset
containing healthy individuals as well as Alzheimer's patients with different
dementia ratings. We demonstrate the correlation between the predicted BAs and
the expected cognitive deterioration in Alzheimer's patients. A statistical and
visualization-based analysis has provided evidence regarding the potential and
current challenges of the proposed methodology.
</dc:description>
 <dc:description>Comment: Accepted to IEEE Transcations on Medical Imaging 2021. 13 pages, 14
  figures, 4 tables</dc:description>
 <dc:date>2020-09-22</dc:date>
 <dc:date>2021-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.10765</dc:identifier>
 <dc:identifier>doi:10.1109/TMI.2021.3066857</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.10963</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Terahertz Massive MIMO with Holographic Reconfigurable Intelligent
  Surfaces</dc:title>
 <dc:creator>Wan, Ziwei</dc:creator>
 <dc:creator>Gao, Zhen</dc:creator>
 <dc:creator>Gao, Feifei</dc:creator>
 <dc:creator>Di Renzo, Marco</dc:creator>
 <dc:creator>Alouini, Mohamed-Slim</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  We propose a holographic version of a reconfigurable intelligent surface
(RIS) and investigate its application to terahertz (THz) massive multiple-input
multiple-output systems. Capitalizing on the miniaturization of THz electronic
components, RISs can be implemented by densely packing sub-wavelength unit
cells, so as to realize continuous or quasi-continuous apertures and to enable
holographic communications. In this paper, in particular, we derive the beam
pattern of a holographic RIS. Our analysis reveals that the beam pattern of an
ideal holographic RIS can be well approximated by that of an ultra-dense RIS,
which has a more practical hardware architecture. In addition, we propose a
closed-loop channel estimation (CE) scheme to effectively estimate the
broadband channels that characterize THz massive MIMO systems aided by
holographic RISs. The proposed CE scheme includes a downlink coarse CE stage
and an uplink finer-grained CE stage. The uplink pilot signals are judiciously
designed for obtaining good CE performance. Moreover, to reduce the pilot
overhead, we introduce a compressive sensing-based CE algorithm, which exploits
the dual sparsity of THz MIMO channels in both the angular domain and delay
domain. Simulation results demonstrate the superiority of holographic RISs over
the non-holographic ones, and the effectiveness of the proposed CE scheme.
</dc:description>
 <dc:description>Comment: 17 pages, 17 figures. Accepted by IEEE Transactions on Communiations</dc:description>
 <dc:date>2020-09-23</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.10963</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2021.3064949</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.11397</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection of Iterative Adversarial Attacks via Counter Attack</dc:title>
 <dc:creator>Rottmann, Matthias</dc:creator>
 <dc:creator>Maag, Kira</dc:creator>
 <dc:creator>Peyron, Mathis</dc:creator>
 <dc:creator>Krejic, Natasa</dc:creator>
 <dc:creator>Gottschalk, Hanno</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>68T45, 62-07</dc:subject>
 <dc:description>  Deep neural networks (DNNs) have proven to be powerful tools for processing
unstructured data. However for high-dimensional data, like images, they are
inherently vulnerable to adversarial attacks. Small almost invisible
perturbations added to the input can be used to fool DNNs. Various attacks,
hardening methods and detection methods have been introduced in recent years.
Notoriously, Carlini-Wagner (CW) type attacks computed by iterative
minimization belong to those that are most difficult to detect. In this work we
outline a mathematical proof that the CW attack can be used as a detector
itself. That is, under certain assumptions and in the limit of attack
iterations this detector provides asymptotically optimal separation of original
and attacked images. In numerical experiments, we experimentally validate this
statement and furthermore obtain AUROC values up to 99.73% on CIFAR10 and
ImageNet. This is in the upper part of the spectrum of current state-of-the-art
detection rates for CW attacks.
</dc:description>
 <dc:date>2020-09-23</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.11397</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.12276</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SemanticVoxels: Sequential Fusion for 3D Pedestrian Detection using
  LiDAR Point Cloud and Semantic Segmentation</dc:title>
 <dc:creator>Fei, Juncong</dc:creator>
 <dc:creator>Chen, Wenbo</dc:creator>
 <dc:creator>Heidenreich, Philipp</dc:creator>
 <dc:creator>Wirges, Sascha</dc:creator>
 <dc:creator>Stiller, Christoph</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  3D pedestrian detection is a challenging task in automated driving because
pedestrians are relatively small, frequently occluded and easily confused with
narrow vertical objects. LiDAR and camera are two commonly used sensor
modalities for this task, which should provide complementary information.
Unexpectedly, LiDAR-only detection methods tend to outperform multisensor
fusion methods in public benchmarks. Recently, PointPainting has been presented
to eliminate this performance drop by effectively fusing the output of a
semantic segmentation network instead of the raw image information. In this
paper, we propose a generalization of PointPainting to be able to apply fusion
at different levels. After the semantic augmentation of the point cloud, we
encode raw point data in pillars to get geometric features and semantic point
data in voxels to get semantic features and fuse them in an effective way.
Experimental results on the KITTI test set show that SemanticVoxels achieves
state-of-the-art performance in both 3D and bird's eye view pedestrian
detection benchmarks. In particular, our approach demonstrates its strength in
detecting challenging pedestrian cases and outperforms current state-of-the-art
approaches.
</dc:description>
 <dc:description>Comment: Accepted to present in the 2020 IEEE International Conference on
  Multisensor Fusion and Integration (MFI 2020)</dc:description>
 <dc:date>2020-09-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.12276</dc:identifier>
 <dc:identifier>doi:10.1109/MFI49285.2020.9235240</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.12280</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Locally orderless tensor networks for classifying two- and
  three-dimensional medical images</dc:title>
 <dc:creator>Selvan, Raghavendra</dc:creator>
 <dc:creator>&#xd8;rting, Silas</dc:creator>
 <dc:creator>Dam, Erik B</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Tensor networks are factorisations of high rank tensors into networks of
lower rank tensors and have primarily been used to analyse quantum many-body
problems. Tensor networks have seen a recent surge of interest in relation to
supervised learning tasks with a focus on image classification. In this work,
we improve upon the matrix product state (MPS) tensor networks that can operate
on one-dimensional vectors to be useful for working with 2D and 3D medical
images. We treat small image regions as orderless, squeeze their spatial
information into feature dimensions and then perform MPS operations on these
locally orderless regions. These local representations are then aggregated in a
hierarchical manner to retain global structure. The proposed locally orderless
tensor network (LoTeNet) is compared with relevant methods on three datasets.
The architecture of LoTeNet is fixed in all experiments and we show it requires
lesser computational resources to attain performance on par or superior to the
compared methods.
</dc:description>
 <dc:description>Comment: Accepted for publication at the Journal of Machine Learning for
  Biomedical Imaging (MELBA) (see https://melba-journal.org). Source code at
  https://github.com/raghavian/LoTeNet_pytorch/</dc:description>
 <dc:date>2020-09-25</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.12280</dc:identifier>
 <dc:identifier>Journal of Machine Learning for Biomedical Imaging. 2021:5. pp
  1-21. Special Issue: Medical Imaging with Deep Learning (MIDL) 2020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.12643</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Inference in Text Editing</dc:title>
 <dc:creator>Shi, Ning</dc:creator>
 <dc:creator>Zeng, Ziheng</dc:creator>
 <dc:creator>Zhang, Haotian</dc:creator>
 <dc:creator>Gong, Yichen</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In neural text editing, prevalent sequence-to-sequence based approaches
directly map the unedited text either to the edited text or the editing
operations, in which the performance is degraded by the limited source text
encoding and long, varying decoding steps. To address this problem, we propose
a new inference method, Recurrence, that iteratively performs editing actions,
significantly narrowing the problem space. In each iteration, encoding the
partially edited text, Recurrence decodes the latent representation, generates
an action of short, fixed-length, and applies the action to complete a single
edit. For a comprehensive comparison, we introduce three types of text editing
tasks: Arithmetic Operators Restoration (AOR), Arithmetic Equation
Simplification (AES), Arithmetic Equation Correction (AEC). Extensive
experiments on these tasks with varying difficulties demonstrate that
Recurrence achieves improvements over conventional inference methods.
</dc:description>
 <dc:description>Comment: 12 pages, 4 figures, 3 tables, and 1 page appendix</dc:description>
 <dc:date>2020-09-26</dc:date>
 <dc:date>2020-09-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.12643</dc:identifier>
 <dc:identifier>doi:10.18653/v1/2020.findings-emnlp.159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.12648</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantitative and Qualitative Evaluation of Explainable Deep Learning
  Methods for Ophthalmic Diagnosis</dc:title>
 <dc:creator>Singh, Amitojdeep</dc:creator>
 <dc:creator>Balaji, J. Jothi</dc:creator>
 <dc:creator>Rasheed, Mohammed Abdul</dc:creator>
 <dc:creator>Jayakumar, Varadharajan</dc:creator>
 <dc:creator>Raman, Rajiv</dc:creator>
 <dc:creator>Lakshminarayanan, Vasudevan</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Background: The lack of explanations for the decisions made by algorithms
such as deep learning has hampered their acceptance by the clinical community
despite highly accurate results on multiple problems. Recently, attribution
methods have emerged for explaining deep learning models, and they have been
tested on medical imaging problems. The performance of attribution methods is
compared on standard machine learning datasets and not on medical images. In
this study, we perform a comparative analysis to determine the most suitable
explainability method for retinal OCT diagnosis.
  Methods: A commonly used deep learning model known as Inception v3 was
trained to diagnose 3 retinal diseases - choroidal neovascularization (CNV),
diabetic macular edema (DME), and drusen. The explanations from 13 different
attribution methods were rated by a panel of 14 clinicians for clinical
significance. Feedback was obtained from the clinicians regarding the current
and future scope of such methods.
  Results: An attribution method based on a Taylor series expansion, called
Deep Taylor was rated the highest by clinicians with a median rating of 3.85/5.
It was followed by two other attribution methods, Guided backpropagation and
SHAP (SHapley Additive exPlanations).
  Conclusion: Explanations of deep learning models can make them more
transparent for clinical diagnosis. This study compared different explanations
methods in the context of retinal OCT diagnosis and found that the best
performing method may not be the one considered best for other deep learning
tasks. Overall, there was a high degree of acceptance from the clinicians
surveyed in the study.
  Keywords: explainable AI, deep learning, machine learning, image processing,
Optical coherence tomography, retina, Diabetic macular edema, Choroidal
Neovascularization, Drusen
</dc:description>
 <dc:date>2020-09-26</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.12648</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.12656</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bidirectional Representation Learning from Transformers using Multimodal
  Electronic Health Record Data to Predict Depression</dc:title>
 <dc:creator>Meng, Yiwen</dc:creator>
 <dc:creator>Speier, William</dc:creator>
 <dc:creator>Ong, Michael K.</dc:creator>
 <dc:creator>Arnold, Corey W.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Advancements in machine learning algorithms have had a beneficial impact on
representation learning, classification, and prediction models built using
electronic health record (EHR) data. Effort has been put both on increasing
models' overall performance as well as improving their interpretability,
particularly regarding the decision-making process. In this study, we present a
temporal deep learning model to perform bidirectional representation learning
on EHR sequences with a transformer architecture to predict future diagnosis of
depression. This model is able to aggregate five heterogenous and
high-dimensional data sources from the EHR and process them in a temporal
manner for chronic disease prediction at various prediction windows. We applied
the current trend of pretraining and fine-tuning on EHR data to outperform the
current state-of-the-art in chronic disease prediction, and to demonstrate the
underlying relation between EHR codes in the sequence. The model generated the
highest increases of precision-recall area under the curve (PRAUC) from 0.70 to
0.76 in depression prediction compared to the best baseline model. Furthermore,
the self-attention weights in each sequence quantitatively demonstrated the
inner relationship between various codes, which improved the model's
interpretability. These results demonstrate the model's ability to utilize
heterogeneous EHR data to predict depression while achieving high accuracy and
interpretability, which may facilitate constructing clinical decision support
systems in the future for chronic disease screening and early detection.
</dc:description>
 <dc:description>Comment: in IEEE Journal of Biomedical and Health Informatics (2021)</dc:description>
 <dc:date>2020-09-26</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.12656</dc:identifier>
 <dc:identifier>doi:10.1109/JBHI.2021.3063721</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.12733</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On-The-Fly Control of Unknown Smooth Systems from Limited Data</dc:title>
 <dc:creator>Djeumou, Franck</dc:creator>
 <dc:creator>Vinod, Abraham P.</dc:creator>
 <dc:creator>Goubault, Eric</dc:creator>
 <dc:creator>Putot, Sylvie</dc:creator>
 <dc:creator>Topcu, Ufuk</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We investigate the problem of data-driven, on-the-fly control of systems with
unknown nonlinear dynamics where data from only a single finite-horizon
trajectory and possibly side information on the dynamics are available. Such
side information may include knowledge of the regularity of the dynamics,
monotonicity of the states, or decoupling in the dynamics between the states.
Specifically, we develop two algorithms, $\texttt{DaTaReach}$ and
$\texttt{DaTaControl}$, to over-approximate the reachable set and design
control signals for the system on the fly. $\texttt{DaTaReach}$ constructs a
differential inclusion that contains the unknown vector field. Then, it
computes an over-approximation of the reachable set based on interval
Taylor-based methods applied to systems with dynamics described as differential
inclusions. $\texttt{DaTaControl}$ enables convex-optimization-based,
near-optimal control using the computed over-approximation and the
receding-horizon control framework. We provide a bound on its suboptimality and
show that more data and side information enable $\texttt{DaTaControl}$ to
achieve tighter suboptimality bounds. Finally, we demonstrate the efficacy of
$\texttt{DaTaControl}$ over existing approaches on the problems of controlling
a unicycle and quadrotor systems.
</dc:description>
 <dc:description>Comment: Extended version of the final submission to the American Control
  Conference (ACC) 2021</dc:description>
 <dc:date>2020-09-26</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.12733</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.12760</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Iterative Reconstruction for Low-Dose CT using Deep Gradient Priors of
  Generative Model</dc:title>
 <dc:creator>He, Zhuonan</dc:creator>
 <dc:creator>Zhang, Yikun</dc:creator>
 <dc:creator>Guan, Yu</dc:creator>
 <dc:creator>Niu, Shanzhou</dc:creator>
 <dc:creator>Zhang, Yi</dc:creator>
 <dc:creator>Chen, Yang</dc:creator>
 <dc:creator>Liu, Qiegen</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Dose reduction in computed tomography (CT) is essential for decreasing
radiation risk in clinical applications. Iterative reconstruction is one of the
most promising ways to compensate for the increased noise due to reduction of
photon flux. Rather than most existing prior-driven algorithms that benefit
from manually designed prior functions or supervised learning schemes, in this
work we integrate the data-consistency as a conditional term into the iterative
generative model for low-dose CT. At the stage of prior learning, the gradient
of data density is directly learned from normal-dose CT images as a prior. Then
at the iterative reconstruction stage, the stochastic gradient descent is
employed to update the trained prior with annealed and conditional schemes. The
distance between the reconstructed image and the manifold is minimized along
with data fidelity during reconstruction. Experimental comparisons demonstrated
the noise reduction and detail preservation abilities of the proposed method.
</dc:description>
 <dc:date>2020-09-27</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.12760</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.12948</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding Matrix Sequences with a High Asymptotic Growth Rate for Linear
  Constrained Switching Systems</dc:title>
 <dc:creator>Zhang, Yuhao</dc:creator>
 <dc:creator>Xu, Xiangru</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Linear constrained switching systems are linear switched systems whose
switching sequences are constrained by a deterministic finite automaton. This
work investigates how to generate a sequence of matrices with an asymptotic
growth rate close to the constrained joint spectral radius (CJSR) for
constrained switching systems, based on our previous result that reveals the
equivalence of a constrained switching system and a lifted arbitrary switching
system. By using the dual solution of a sum-of-squares optimization program, an
algorithm is designed for the lifted arbitrary switching system to produce a
sequence of matrices with an asymptotic growth rate that is close to the CJSR
of the original constrained switching system. It is also shown that a type of
existing algorithms designed for arbitrary switching systems can be applied to
the lifted system such that the desired sequence of matrices can be generated
for the constrained switching system. Several numerical examples are provided
to illustrate the better performance of the proposed algorithms compared with
existing ones.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures</dc:description>
 <dc:date>2020-09-27</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.12948</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.13248</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Landscape of R packages for eXplainable Artificial Intelligence</dc:title>
 <dc:creator>Maksymiuk, Szymon</dc:creator>
 <dc:creator>Gosiewska, Alicja</dc:creator>
 <dc:creator>Biecek, Przemyslaw</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The growing availability of data and computing power fuels the development of
predictive models. In order to ensure the safe and effective functioning of
such models, we need methods for exploration, debugging, and validation. New
methods and tools for this purpose are being developed within the eXplainable
Artificial Intelligence (XAI) subdomain of machine learning. In this work (1)
we present the taxonomy of methods for model explanations, (2) we identify and
compare 27 packages available in R to perform XAI analysis, (3) we present an
example of an application of particular packages, (4) we acknowledge recent
trends in XAI. The article is primarily devoted to the tools available in R,
but since it is easy to integrate the Python code, we will also show examples
for the most popular libraries from Python.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2020-09-24</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.13248</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.13352</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of IoT-Based Load Altering Attacks Against Power Grids Using
  the Theory of Second-Order Dynamical Systems</dc:title>
 <dc:creator>Lakshminarayana, Subhash</dc:creator>
 <dc:creator>Adhikari, Sondipon</dc:creator>
 <dc:creator>Maple, Carsten</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Recent research has shown that large-scale Internet of Things (IoT)-based
load altering attacks can have a serious impact on power grid operations such
as causing unsafe frequency excursions and destabilizing the grid's control
loops. In this work, we present an analytical framework to investigate the
impact of IoT-based static/dynamic load altering attacks (S/DLAAs) on the power
grid's dynamic response. Existing work on this topic has mainly relied on
numerical simulations and, to date, there is no analytical framework to
identify the victim nodes from which that attacker can launch the most
impactful attacks. To address these shortcomings, we use results from
second-order dynamical systems to analyze the power grid frequency control loop
under S/DLAAs. We use parametric sensitivity of the system's eigensolutions to
identify victim nodes that correspond to the least-effort destabilizing DLAAs.
Further, to analyze the SLAAs, we present closed-form expression for the
system's frequency response in terms of the attacker's inputs, helping us
characterize the minimum load change required to cause unsafe frequency
excursions. Using these results, we formulate the defense against S/DLAAs as a
linear programming problem in which we determine the minimum amount of load
that needs to be secured at the victim nodes to ensure system safety/stability.
Extensive simulations conducted using benchmark IEEE-bus systems validate the
accuracy and efficacy of our approach.
</dc:description>
 <dc:date>2020-09-28</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.13352</dc:identifier>
 <dc:identifier>IEEE Trans. on Smart Grids, 2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.13416</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extendible and Efficient Python Framework for Solving Evolution
  Equations with Stabilized Discontinuous Galerkin Method</dc:title>
 <dc:creator>Dedner, Andreas</dc:creator>
 <dc:creator>Kl&#xf6;fkorn, Robert</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>65M08, 65M60, 35Q31, 35Q90, 68N99</dc:subject>
 <dc:description>  This paper discusses a Python interface for the recently published
DUNE-FEM-DG module which provides highly efficient implementations of the
Discontinuous Galerkin (DG) method for solving a wide range of non linear
partial differential equations (PDE). Although the C++ interfaces of
DUNE-FEM-DG are highly flexible and customizable, a solid knowledge of C++ is
necessary to make use of this powerful tool. With this work easier user
interfaces based on Python and the Unified Form Language are provided to open
DUNE-FEM-DG for a broader audience. The Python interfaces are demonstrated for
both parabolic and first order hyperbolic PDEs.
</dc:description>
 <dc:description>Comment: 36 pages, 15 figures, various Python code examples</dc:description>
 <dc:date>2020-09-25</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.13416</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.13609</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compositionality of Linearly Solvable Optimal Control in Networked
  Multi-Agent Systems</dc:title>
 <dc:creator>Song, Lin</dc:creator>
 <dc:creator>Wan, Neng</dc:creator>
 <dc:creator>Gahlawat, Aditya</dc:creator>
 <dc:creator>Hovakimyan, Naira</dc:creator>
 <dc:creator>Theodorou, Evangelos A.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper, we discuss the methodology of generalizing the optimal control
law from learned component tasks to unlearned composite tasks on Multi-Agent
Systems (MASs), by using the linearity composition principle of linearly
solvable optimal control (LSOC) problems. The proposed approach achieves both
the compositionality and optimality of control actions simultaneously within
the cooperative MAS framework in both discrete- and continuous-time in a
sample-efficient manner, which reduces the burden of re-computation of the
optimal control solutions for the new task on the MASs. We investigate the
application of the proposed approach on the MAS with coordination between
agents. The experiments show feasible results in investigated scenarios,
including both discrete and continuous dynamical systems for task
generalization without resampling.
</dc:description>
 <dc:description>Comment: Accepted to the 2021 American Control Conference (ACC)</dc:description>
 <dc:date>2020-09-28</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.13609</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.13770</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid Heavy-Ball Systems: Reset Methods for Optimization with
  Uncertainty</dc:title>
 <dc:creator>Le, Justin H.</dc:creator>
 <dc:creator>Teel, Andrew R.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Momentum methods for convex optimization often rely on precise choices of
algorithmic parameters, based on knowledge of problem parameters, in order to
achieve fast convergence, as well as to prevent oscillations that could
severely restrict applications of these algorithms to cyber-physical systems.
To address these issues, we propose two dynamical systems, named the Hybrid
Heavy-Ball System and Hybrid-inspired Heavy-Ball System, which employ a
feedback mechanism for driving the momentum state toward zero whenever it
points in undesired directions. We describe the relationship between the
proposed systems and their discrete-time counterparts, deriving conditions
based on linear matrix inequalities for ensuring exponential rates in both
continuous time and discrete time. We provide numerical LMI results to
illustrate the effects of our reset mechanisms on convergence rates in a
setting that simulates uncertainty of problem parameters. Finally, we
numerically demonstrate the efficiency and avoidance of oscillations of the
proposed systems when solving both strongly convex and non-strongly convex
problems.
</dc:description>
 <dc:date>2020-09-29</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.13770</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.13833</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HINT3: Raising the bar for Intent Detection in the Wild</dc:title>
 <dc:creator>Arora, Gaurav</dc:creator>
 <dc:creator>Jain, Chirag</dc:creator>
 <dc:creator>Chaturvedi, Manas</dc:creator>
 <dc:creator>Modi, Krupal</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Intent Detection systems in the real world are exposed to complexities of
imbalanced datasets containing varying perception of intent, unintended
correlations and domain-specific aberrations. To facilitate benchmarking which
can reflect near real-world scenarios, we introduce 3 new datasets created from
live chatbots in diverse domains. Unlike most existing datasets that are
crowdsourced, our datasets contain real user queries received by the chatbots
and facilitates penalising unwanted correlations grasped during the training
process. We evaluate 4 NLU platforms and a BERT based classifier and find that
performance saturates at inadequate levels on test sets because all systems
latch on to unintended patterns in training data.
</dc:description>
 <dc:description>Comment: Accepted at EMNLP-2020's Insights workshop</dc:description>
 <dc:date>2020-09-29</dc:date>
 <dc:date>2020-10-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.13833</dc:identifier>
 <dc:identifier>Proceedings of the First Workshop on Insights from Negative
  Results in NLP @ EMNLP 2020</dc:identifier>
 <dc:identifier>doi:10.18653/v1/2020.insights-1.16</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2009.14775</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cooperative Path Integral Control for Stochastic Multi-Agent Systems</dc:title>
 <dc:creator>Wan, Neng</dc:creator>
 <dc:creator>Gahlawat, Aditya</dc:creator>
 <dc:creator>Hovakimyan, Naira</dc:creator>
 <dc:creator>Theodorou, Evangelos A.</dc:creator>
 <dc:creator>Voulgaris, Petros G.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  A distributed stochastic optimal control solution is presented for
cooperative multi-agent systems. The network of agents is partitioned into
multiple factorial subsystems, each of which consists of a central agent and
neighboring agents. Local control actions that rely only on agents' local
observations are designed to optimize the joint cost functions of subsystems.
When solving for the local control actions, the joint optimality equation for
each subsystem is cast as a linear partial differential equation and solved
using the Feynman-Kac formula. The solution and the optimal control action are
then formulated as path integrals and approximated by a Monte-Carlo method.
Numerical verification is provided through a simulation example consisting of a
team of cooperative UAVs.
</dc:description>
 <dc:description>Comment: To appear in American Control Conference 2021, New Orleans, LA, USA</dc:description>
 <dc:date>2020-09-30</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2009.14775</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.00350</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Blind Federated Learning at the Wireless Edge with Low-Resolution ADC
  and DAC</dc:title>
 <dc:creator>Tegin, Busra</dc:creator>
 <dc:creator>Duman, Tolga M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We study collaborative machine learning systems where a massive dataset is
distributed across independent workers which compute their local gradient
estimates based on their own datasets. Workers send their estimates through a
multipath fading multiple access channel with orthogonal frequency division
multiplexing to mitigate the frequency selectivity of the channel. We assume
that there is no channel state information (CSI) at the workers, and the
parameter server (PS) employs multiple antennas to align the received signals.
To reduce the power consumption and the hardware costs, we employ
complex-valued low-resolution digital-to-analog converters (DACs) and
analog-to-digital converters (ADCs), at the transmitter and the receiver sides,
respectively, and study the effects of practical low-cost DACs and ADCs on the
learning performance. Our theoretical analysis shows that the impairments
caused by low-resolution DACs and ADCs, including those of one-bit DACs and
ADCs, do not prevent the convergence of the federated learning algorithm, and
the multipath channel effects vanish when a sufficient number of antennas are
used at the PS. We also validate our theoretical results via simulations, and
demonstrate that using low-resolution, even one-bit, DACs and ADCs causes only
a slight decrease in the learning accuracy.
</dc:description>
 <dc:description>Comment: 31 pages, 9 figures</dc:description>
 <dc:date>2020-10-01</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.00350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.00525</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A biologically plausible neural network for multi-channel Canonical
  Correlation Analysis</dc:title>
 <dc:creator>Lipshutz, David</dc:creator>
 <dc:creator>Bahroun, Yanis</dc:creator>
 <dc:creator>Golkar, Siavash</dc:creator>
 <dc:creator>Sengupta, Anirvan M.</dc:creator>
 <dc:creator>Chklovskii, Dmitri B.</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Cortical pyramidal neurons receive inputs from multiple distinct neural
populations and integrate these inputs in separate dendritic compartments. We
explore the possibility that cortical microcircuits implement Canonical
Correlation Analysis (CCA), an unsupervised learning method that projects the
inputs onto a common subspace so as to maximize the correlations between the
projections. To this end, we seek a multi-channel CCA algorithm that can be
implemented in a biologically plausible neural network. For biological
plausibility, we require that the network operates in the online setting and
its synaptic update rules are local. Starting from a novel CCA objective
function, we derive an online optimization algorithm whose optimization steps
can be implemented in a single-layer neural network with multi-compartmental
neurons and local non-Hebbian learning rules. We also derive an extension of
our online CCA algorithm with adaptive output rank and output whitening.
Interestingly, the extension maps onto a neural network whose neural
architecture and synaptic updates resemble neural circuitry and synaptic
plasticity observed experimentally in cortical pyramidal neurons.
</dc:description>
 <dc:description>Comment: 46 pages, 14 figures</dc:description>
 <dc:date>2020-10-01</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.00525</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.00904</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Autoregressive Entity Retrieval</dc:title>
 <dc:creator>De Cao, Nicola</dc:creator>
 <dc:creator>Izacard, Gautier</dc:creator>
 <dc:creator>Riedel, Sebastian</dc:creator>
 <dc:creator>Petroni, Fabio</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Entities are at the center of how we represent and aggregate knowledge. For
instance, Encyclopedias such as Wikipedia are structured by entities (e.g., one
per Wikipedia article). The ability to retrieve such entities given a query is
fundamental for knowledge-intensive tasks such as entity linking and
open-domain question answering. Current approaches can be understood as
classifiers among atomic labels, one for each entity. Their weight vectors are
dense entity representations produced by encoding entity meta information such
as their descriptions. This approach has several shortcomings: (i) context and
entity affinity is mainly captured through a vector dot product, potentially
missing fine-grained interactions; (ii) a large memory footprint is needed to
store dense representations when considering large entity sets; (iii) an
appropriately hard set of negative data has to be subsampled at training time.
In this work, we propose GENRE, the first system that retrieves entities by
generating their unique names, left to right, token-by-token in an
autoregressive fashion. This mitigates the aforementioned technical issues
since: (i) the autoregressive formulation directly captures relations between
context and entity name, effectively cross encoding both; (ii) the memory
footprint is greatly reduced because the parameters of our encoder-decoder
architecture scale with vocabulary size, not entity count; (iii) the softmax
loss is computed without subsampling negative data. We experiment with more
than 20 datasets on entity disambiguation, end-to-end entity linking and
document retrieval tasks, achieving new state-of-the-art or very competitive
results while using a tiny fraction of the memory footprint of competing
systems. Finally, we demonstrate that new entities can be added by simply
specifying their names. Code and pre-trained models at
https://github.com/facebookresearch/GENRE.
</dc:description>
 <dc:description>Comment: Accepted (spotlight) at International Conference on Learning
  Representations (ICLR) 2021. Code at
  https://github.com/facebookresearch/GENRE. 20 pages, 9 figures, 8 tables</dc:description>
 <dc:date>2020-10-02</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.00904</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.00977</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Group Equivariant Stand-Alone Self-Attention For Vision</dc:title>
 <dc:creator>Romero, David W.</dc:creator>
 <dc:creator>Cordonnier, Jean-Baptiste</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We provide a general self-attention formulation to impose group equivariance
to arbitrary symmetry groups. This is achieved by defining positional encodings
that are invariant to the action of the group considered. Since the group acts
on the positional encoding directly, group equivariant self-attention networks
(GSA-Nets) are steerable by nature. Our experiments on vision benchmarks
demonstrate consistent improvements of GSA-Nets over non-equivariant
self-attention networks.
</dc:description>
 <dc:description>Comment: Proceedings of the 9th International Conference on Learning
  Representations (ICLR), 2021</dc:description>
 <dc:date>2020-10-02</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.00977</dc:identifier>
 <dc:identifier>Proceedings of the International Conference on Learning
  Representations, 2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.00989</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge Graph Embeddings in Geometric Algebras</dc:title>
 <dc:creator>Xu, Chengjin</dc:creator>
 <dc:creator>Nayyeri, Mojtaba</dc:creator>
 <dc:creator>Chen, Yung-Yu</dc:creator>
 <dc:creator>Lehmann, Jens</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Knowledge graph (KG) embedding aims at embedding entities and relations in a
KG into a lowdimensional latent representation space. Existing KG embedding
approaches model entities andrelations in a KG by utilizing real-valued ,
complex-valued, or hypercomplex-valued (Quaternionor Octonion) representations,
all of which are subsumed into a geometric algebra. In this work,we introduce a
novel geometric algebra-based KG embedding framework, GeomE, which uti-lizes
multivector representations and the geometric product to model entities and
relations. Ourframework subsumes several state-of-the-art KG embedding
approaches and is advantageouswith its ability of modeling various key relation
patterns, including (anti-)symmetry, inversionand composition, rich
expressiveness with higher degree of freedom as well as good general-ization
capacity. Experimental results on multiple benchmark knowledge graphs show that
theproposed approach outperforms existing state-of-the-art models for link
prediction.
</dc:description>
 <dc:description>Comment: This paper is accepted by COLING2020</dc:description>
 <dc:date>2020-10-02</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.00989</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.01024</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Memory Clustering using Persistent Homology for Multimodality- and
  Discontinuity-Sensitive Learning of Optimal Control Warm-starts</dc:title>
 <dc:creator>Merkt, Wolfgang</dc:creator>
 <dc:creator>Ivan, Vladimir</dc:creator>
 <dc:creator>Dinev, Traiko</dc:creator>
 <dc:creator>Havoutis, Ioannis</dc:creator>
 <dc:creator>Vijayakumar, Sethu</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Shooting methods are an efficient approach to solving nonlinear optimal
control problems. As they use local optimization, they exhibit favorable
convergence when initialized with a good warm-start but may not converge at all
if provided with a poor initial guess. Recent work has focused on providing an
initial guess from a learned model trained on samples generated during an
offline exploration of the problem space. However, in practice the solutions
contain discontinuities introduced by system dynamics or the environment.
Additionally, in many cases multiple equally suitable, i.e., multi-modal,
solutions exist to solve a problem. Classic learning approaches smooth across
the boundary of these discontinuities and thus generalize poorly. In this work,
we apply tools from algebraic topology to extract information on the underlying
structure of the solution space. In particular, we introduce a method based on
persistent homology to automatically cluster the dataset of precomputed
solutions to obtain different candidate initial guesses. We then train a
Mixture-of-Experts within each cluster to predict state and control
trajectories to warm-start the optimal control solver and provide a comparison
with modality-agnostic learning. We demonstrate our method on a cart-pole toy
problem and a quadrotor avoiding obstacles, and show that clustering samples
based on inherent structure improves the warm-start quality.
</dc:description>
 <dc:description>Comment: 12 pages, 10 figures, accepted as a regular paper in IEEE
  Transactions on Robotics (T-RO). Supplementary video:
  https://youtu.be/lUULTWCFxY8 Code:
  https://github.com/wxmerkt/topological_memory_clustering The first two
  authors contributed equally</dc:description>
 <dc:date>2020-10-02</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.01024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.01059</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>$X$-Secure $T$-Private Federated Submodel Learning with Elastic Dropout
  Resilience</dc:title>
 <dc:creator>Jia, Zhuqing</dc:creator>
 <dc:creator>Jafar, Syed A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Motivated by recent interest in federated submodel learning, this work
explores the fundamental problem of privately reading from and writing to a
database comprised of $K$ files (submodels) that are stored across $N$
distributed servers according to an $X$-secure threshold secret sharing scheme.
One after another, various users wish to retrieve their desired file, locally
process the information and then update the file in the distributed database
while keeping the identity of their desired file private from any set of up to
$T$ colluding servers. The availability of servers changes over time, so
elastic dropout resilience is required. The main contribution of this work is
an adaptive scheme, called ACSA-RW, that takes advantage of all currently
available servers to reduce its communication costs, fully updates the database
after each write operation even though the database is only partially
accessible due to server dropouts, and ensures a memoryless operation of the
network in the sense that the storage structure is preserved and future users
may remain oblivious of the past history of server dropouts. The ACSA-RW
construction builds upon CSA codes that were originally introduced for XSTPIR
and have been shown to be natural solutions for secure distributed matrix
multiplication problems. ACSA-RW achieves the desired private read and write
functionality with elastic dropout resilience, matches the best results for
private-read from PIR literature, improves significantly upon available
baselines for private-write, reveals a striking symmetry between upload and
download costs, and exploits redundant storage dimensions to accommodate
arbitrary read and write dropout servers up to certain threshold values. It
also answers in the affirmative an open question by Kairouz et al. by
exploiting synergistic gains from the joint design of private read and write
operations.
</dc:description>
 <dc:date>2020-10-02</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.01059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.01065</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving the Fidelity of Mixed-Monotone Reachable Set Approximations
  via State Transformations</dc:title>
 <dc:creator>Abate, Matthew</dc:creator>
 <dc:creator>Coogan, Samuel</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  Mixed-monotone systems are separable via a decomposition function into
increasing and decreasing components, and this decomposition function allows
for embedding the system dynamics in a higher-order monotone embedding system.
Embedding the system dynamics in this way facilitates the efficient
over-approximation of reachable sets with hyperrectangles, however, unlike the
monotonicity property, which can be applied to compute, e.g., the tightest
hyperrectangle containing a reachable set, the application of the
mixed-monotonicity property generally results in conservative reachable set
approximations. In this work, explore conservatism in the method and we
consider, in particular, embedding systems that are monotone with respect to an
alternative partial order. This alternate embedding system is constructed with
a decomposition function for a related system, formed via a linear
transformation of the initial state-space. We show how these alternate
embedding systems allow for computing reachable sets with improved fidelity,
i.e., reduced conservatism.
</dc:description>
 <dc:description>Comment: 8 Page. 7 Figures. American Controls Conference 2021, To Appear. Code
  available: https://github.com/gtfactslab/Abate_ACC2021_2</dc:description>
 <dc:date>2020-10-02</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.01065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.01165</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-domain Clinical Natural Language Processing with MedCAT: the
  Medical Concept Annotation Toolkit</dc:title>
 <dc:creator>Kraljevic, Zeljko</dc:creator>
 <dc:creator>Searle, Thomas</dc:creator>
 <dc:creator>Shek, Anthony</dc:creator>
 <dc:creator>Roguski, Lukasz</dc:creator>
 <dc:creator>Noor, Kawsar</dc:creator>
 <dc:creator>Bean, Daniel</dc:creator>
 <dc:creator>Mascio, Aurelie</dc:creator>
 <dc:creator>Zhu, Leilei</dc:creator>
 <dc:creator>Folarin, Amos A</dc:creator>
 <dc:creator>Roberts, Angus</dc:creator>
 <dc:creator>Bendayan, Rebecca</dc:creator>
 <dc:creator>Richardson, Mark P</dc:creator>
 <dc:creator>Stewart, Robert</dc:creator>
 <dc:creator>Shah, Anoop D</dc:creator>
 <dc:creator>Wong, Wai Keong</dc:creator>
 <dc:creator>Ibrahim, Zina</dc:creator>
 <dc:creator>Teo, James T</dc:creator>
 <dc:creator>Dobson, Richard JB</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Electronic health records (EHR) contain large volumes of unstructured text,
requiring the application of Information Extraction (IE) technologies to enable
clinical analysis. We present the open-source Medical Concept Annotation
Toolkit (MedCAT) that provides: a) a novel self-supervised machine learning
algorithm for extracting concepts using any concept vocabulary including
UMLS/SNOMED-CT; b) a feature-rich annotation interface for customising and
training IE models; and c) integrations to the broader CogStack ecosystem for
vendor-agnostic health system deployment. We show improved performance in
extracting UMLS concepts from open datasets (F1:0.448-0.738 vs 0.429-0.650).
Further real-world validation demonstrates SNOMED-CT extraction at 3 large
London hospitals with self-supervised training over ~8.8B words from ~17M
clinical records and further fine-tuning with ~6K clinician annotated examples.
We show strong transferability (F1 &gt; 0.94) between hospitals, datasets, and
concept types indicating cross-domain EHR-agnostic utility for accelerated
clinical and research use cases.
</dc:description>
 <dc:description>Comment: Preprint: 27 Pages, 3 Figures</dc:description>
 <dc:date>2020-10-02</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.01165</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.01305</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounding Boxes Are All We Need: Street View Image Classification via
  Context Encoding of Detected Buildings</dc:title>
 <dc:creator>Zhao, Kun</dc:creator>
 <dc:creator>Liu, Yongkun</dc:creator>
 <dc:creator>Hao, Siyuan</dc:creator>
 <dc:creator>Lu, Shaoxing</dc:creator>
 <dc:creator>Liu, Hongbin</dc:creator>
 <dc:creator>Zhou, Lijian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Street view images classification aiming at urban land use analysis is
difficult because the class labels (e.g., commercial area), are concepts with
higher abstract level compared to the ones of general visual tasks (e.g.,
persons and cars). Therefore, classification models using only visual features
often fail to achieve satisfactory performance. In this paper, a novel approach
based on a &quot;Detector-Encoder-Classifier&quot; framework is proposed. Instead of
using visual features of the whole image directly as common image-level models
based on convolutional neural networks (CNNs) do, the proposed framework
firstly obtains the bounding boxes of buildings in street view images from a
detector. Their contextual information such as the co-occurrence patterns of
building classes and their layout are then encoded into metadata by the
proposed algorithm &quot;CODING&quot; (Context encOding of Detected buildINGs). Finally,
these bounding box metadata are classified by a recurrent neural network (RNN).
In addition, we made a dual-labeled dataset named &quot;BEAUTY&quot; (Building dEtection
And Urban funcTional-zone portraYing) of 19,070 street view images and 38,857
buildings based on the existing BIC GSV [1]. The dataset can be used not only
for street view image classification, but also for multi-class building
detection. Experiments on &quot;BEAUTY&quot; show that the proposed approach achieves a
12.65% performance improvement on macro-precision and 12% on macro-recall over
image-level CNN based models. Our code and dataset are available at
https://github.com/kyle-one/Context-Encoding-of-Detected-Buildings/
</dc:description>
 <dc:description>Comment: Figure 1 has been added, and the order of the rest of the figures
  continues. Figure 6 (Figure 5 of the previous version) and Figure 7 (Figure 6
  of the previous version) have been modified. Figure 7, Figure 15, and Figure
  16 of the previous versionhave have been removed. The structure of Section 4
  has been adjusted</dc:description>
 <dc:date>2020-10-03</dc:date>
 <dc:date>2020-10-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.01305</dc:identifier>
 <dc:identifier>IEEE Transactions on Geoscience and Remote Sensing 2021 (Early
  Access)</dc:identifier>
 <dc:identifier>doi:10.1109/TGRS.2021.3064316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.01373</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ethna: Analyzing the Underlying Peer-to-Peer Network of the Ethereum
  Blockchain</dc:title>
 <dc:creator>Wang, Taotao</dc:creator>
 <dc:creator>Zhao, Chonghe</dc:creator>
 <dc:creator>Yang, Qing</dc:creator>
 <dc:creator>Zhang, Shengli</dc:creator>
 <dc:creator>Liew, Soung Chang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The peer-to-peer (P2P) network of blockchain used to transport its
transactions and blocks has a high impact on the efficiency and security of the
system. The P2P network topologies of popular blockchains such as Bitcoin and
Ethereum, therefore, deserve our highest attention. The current Ethereum
blockchain explorers (e.g., Etherscan) focus on the tracking of block and
transaction records but omit the characterization of the underlying P2P
network. This work presents the Ethereum Network Analyzer (Ethna), a tool that
probes and analyzes the P2P network of the Ethereum blockchain. Unlike Bitcoin
that adopts an unstructured P2P network, Ethereum relies on the Kademlia DHT to
manage its P2P network. Therefore, the existing analytical methods for
Bitcoin-like P2P networks are not applicable to Ethereum. Ethna implements a
novel method that accurately measures the degrees of Ethereum nodes.
Furthermore, it incorporates an algorithm that derives the latency metrics of
message propagation in the Ethereum P2P network. We ran Ethna on the Ethereum
Mainnet and conducted extensive experiments to analyze the topological features
of its P2P network. Our analysis shows that the Ethereum P2P network possesses
a certain effect of small-world networks, and the degrees of nodes follow a
power-law distribution that characterizes scale-free networks.
</dc:description>
 <dc:description>Comment: 15 pages, 14 figures</dc:description>
 <dc:date>2020-10-03</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.01373</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.01733</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>D3Net: Densely connected multidilated DenseNet for music source
  separation</dc:title>
 <dc:creator>Takahashi, Naoya</dc:creator>
 <dc:creator>Mitsufuji, Yuki</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Music source separation involves a large input field to model a long-term
dependence of an audio signal. Previous convolutional neural network
(CNN)-based approaches address the large input field modeling using
sequentially down- and up-sampling feature maps or dilated convolution. In this
paper, we claim the importance of a rapid growth of a receptive field and a
simultaneous modeling of multi-resolution data in a single convolution layer,
and propose a novel CNN architecture called densely connected dilated DenseNet
(D3Net). D3Net involves a novel multi-dilated convolution that has different
dilation factors in a single layer to model different resolutions
simultaneously. By combining the multi-dilated convolution with DenseNet
architecture, D3Net avoids the aliasing problem that exists when we naively
incorporate the dilated convolution in DenseNet. Experimental results on
MUSDB18 dataset show that D3Net achieves state-of-the-art performance with an
average signal to distortion ratio (SDR) of 6.01 dB.
</dc:description>
 <dc:date>2020-10-04</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.01733</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.02011</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Physics-Informed Machine Learning Approach for Solving Heat Transfer
  Equation in Advanced Manufacturing and Engineering Applications</dc:title>
 <dc:creator>Zobeiry, Navid</dc:creator>
 <dc:creator>Humfeld, Keith D.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  A physics-informed neural network is developed to solve conductive heat
transfer partial differential equation (PDE), along with convective heat
transfer PDEs as boundary conditions (BCs), in manufacturing and engineering
applications where parts are heated in ovens. Since convective coefficients are
typically unknown, current analysis approaches based on trial and error finite
element (FE) simulations are slow. The loss function is defined based on errors
to satisfy PDE, BCs and initial condition. An adaptive normalizing scheme is
developed to reduce loss terms simultaneously. In addition, theory of heat
transfer is used for feature engineering. The predictions for 1D and 2D cases
are validated by comparing with FE results. It is shown that using engineered
features, heat transfer beyond the training zone can be predicted. Trained
model allows for fast evaluation of a range of BCs to develop feedback loops,
realizing Industry 4.0 concept of active manufacturing control based on sensor
data.
</dc:description>
 <dc:date>2020-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.02011</dc:identifier>
 <dc:identifier>Engineering Applications of Artificial Intelligence, 101 (2021)
  104232</dc:identifier>
 <dc:identifier>doi:10.1016/j.engappai.2021.104232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.02089</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CopulaGNN: Towards Integrating Representational and Correlational Roles
  of Graphs in Graph Neural Networks</dc:title>
 <dc:creator>Ma, Jiaqi</dc:creator>
 <dc:creator>Chang, Bo</dc:creator>
 <dc:creator>Zhang, Xuefei</dc:creator>
 <dc:creator>Mei, Qiaozhu</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Graph-structured data are ubiquitous. However, graphs encode diverse types of
information and thus play different roles in data representation. In this
paper, we distinguish the \textit{representational} and the
\textit{correlational} roles played by the graphs in node-level prediction
tasks, and we investigate how Graph Neural Network (GNN) models can effectively
leverage both types of information. Conceptually, the representational
information provides guidance for the model to construct better node features;
while the correlational information indicates the correlation between node
outcomes conditional on node features. Through a simulation study, we find that
many popular GNN models are incapable of effectively utilizing the
correlational information. By leveraging the idea of the copula, a principled
way to describe the dependence among multivariate random variables, we offer a
general solution. The proposed Copula Graph Neural Network (CopulaGNN) can take
a wide range of GNN models as base models and utilize both representational and
correlational information stored in the graphs. Experimental results on two
types of regression tasks verify the effectiveness of the proposed method.
</dc:description>
 <dc:description>Comment: ICLR 2021</dc:description>
 <dc:date>2020-10-05</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.02089</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.02114</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Explaining The Efficacy of Counterfactually Augmented Data</dc:title>
 <dc:creator>Kaushik, Divyansh</dc:creator>
 <dc:creator>Setlur, Amrith</dc:creator>
 <dc:creator>Hovy, Eduard</dc:creator>
 <dc:creator>Lipton, Zachary C.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In attempts to produce ML models less reliant on spurious patterns in NLP
datasets, researchers have recently proposed curating counterfactually
augmented data (CAD) via a human-in-the-loop process in which given some
documents and their (initial) labels, humans must revise the text to make a
counterfactual label applicable. Importantly, edits that are not necessary to
flip the applicable label are prohibited. Models trained on the augmented data
appear, empirically, to rely less on semantically irrelevant words and to
generalize better out of domain. While this work draws loosely on causal
thinking, the underlying causal model (even at an abstract level) and the
principles underlying the observed out-of-domain improvements remain unclear.
In this paper, we introduce a toy analog based on linear Gaussian models,
observing interesting relationships between causal models, measurement noise,
out-of-domain generalization, and reliance on spurious signals. Our analysis
provides some insights that help to explain the efficacy of CAD. Moreover, we
develop the hypothesis that while adding noise to causal features should
degrade both in-domain and out-of-domain performance, adding noise to
non-causal features should lead to relative improvements in out-of-domain
performance. This idea inspires a speculative test for determining whether a
feature attribution technique has identified the causal spans. If adding noise
(e.g., by random word flips) to the highlighted spans degrades both in-domain
and out-of-domain performance on a battery of challenge datasets, but adding
noise to the complement gives improvements out-of-domain, it suggests we have
identified causal spans. We present a large-scale empirical study comparing
spans edited to create CAD to those selected by attention and saliency maps.
Across numerous domains and models, we find that the hypothesized phenomenon is
pronounced for CAD.
</dc:description>
 <dc:description>Comment: Published at ICLR 2021</dc:description>
 <dc:date>2020-10-05</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.02114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.02329</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>InfoBERT: Improving Robustness of Language Models from An Information
  Theoretic Perspective</dc:title>
 <dc:creator>Wang, Boxin</dc:creator>
 <dc:creator>Wang, Shuohang</dc:creator>
 <dc:creator>Cheng, Yu</dc:creator>
 <dc:creator>Gan, Zhe</dc:creator>
 <dc:creator>Jia, Ruoxi</dc:creator>
 <dc:creator>Li, Bo</dc:creator>
 <dc:creator>Liu, Jingjing</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Large-scale language models such as BERT have achieved state-of-the-art
performance across a wide range of NLP tasks. Recent studies, however, show
that such BERT-based models are vulnerable facing the threats of textual
adversarial attacks. We aim to address this problem from an
information-theoretic perspective, and propose InfoBERT, a novel learning
framework for robust fine-tuning of pre-trained language models. InfoBERT
contains two mutual-information-based regularizers for model training: (i) an
Information Bottleneck regularizer, which suppresses noisy mutual information
between the input and the feature representation; and (ii) a Robust Feature
regularizer, which increases the mutual information between local robust
features and global features. We provide a principled way to theoretically
analyze and improve the robustness of representation learning for language
models in both standard and adversarial training. Extensive experiments
demonstrate that InfoBERT achieves state-of-the-art robust accuracy over
several adversarial datasets on Natural Language Inference (NLI) and Question
Answering (QA) tasks. Our code is available at
https://github.com/AI-secure/InfoBERT.
</dc:description>
 <dc:description>Comment: Accepted to ICLR 2021. 23 pages, 9 tables, 3 figures</dc:description>
 <dc:date>2020-10-05</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.02329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.02347</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning with Instance-Dependent Label Noise: A Sample Sieve Approach</dc:title>
 <dc:creator>Cheng, Hao</dc:creator>
 <dc:creator>Zhu, Zhaowei</dc:creator>
 <dc:creator>Li, Xingyu</dc:creator>
 <dc:creator>Gong, Yifei</dc:creator>
 <dc:creator>Sun, Xing</dc:creator>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Human-annotated labels are often prone to noise, and the presence of such
noise will degrade the performance of the resulting deep neural network (DNN)
models. Much of the literature (with several recent exceptions) of learning
with noisy labels focuses on the case when the label noise is independent of
features. Practically, annotations errors tend to be instance-dependent and
often depend on the difficulty levels of recognizing a certain task. Applying
existing results from instance-independent settings would require a significant
amount of estimation of noise rates. Therefore, providing theoretically
rigorous solutions for learning with instance-dependent label noise remains a
challenge. In this paper, we propose CORES$^{2}$ (COnfidence REgularized Sample
Sieve), which progressively sieves out corrupted examples. The implementation
of CORES$^{2}$ does not require specifying noise rates and yet we are able to
provide theoretical guarantees of CORES$^{2}$ in filtering out the corrupted
examples. This high-quality sample sieve allows us to treat clean examples and
the corrupted ones separately in training a DNN solution, and such a separation
is shown to be advantageous in the instance-dependent noise setting. We
demonstrate the performance of CORES$^{2}$ on CIFAR10 and CIFAR100 datasets
with synthetic instance-dependent label noise and Clothing1M with real-world
human noise. As of independent interests, our sample sieve provides a generic
machinery for anatomizing noisy datasets and provides a flexible interface for
various robust training techniques to further improve the performance. Code is
available at https://github.com/UCSC-REAL/cores.
</dc:description>
 <dc:description>Comment: ICLR 2021</dc:description>
 <dc:date>2020-10-05</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.02347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.02354</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Traveling Observer Model: Multi-task Learning Through Spatial
  Variable Embeddings</dc:title>
 <dc:creator>Meyerson, Elliot</dc:creator>
 <dc:creator>Miikkulainen, Risto</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  This paper frames a general prediction system as an observer traveling around
a continuous space, measuring values at some locations, and predicting them at
others. The observer is completely agnostic about any particular task being
solved; it cares only about measurement locations and their values. This
perspective leads to a machine learning framework in which seemingly unrelated
tasks can be solved by a single model, by embedding their input and output
variables into a shared space. An implementation of the framework is developed
in which these variable embeddings are learned jointly with internal model
parameters. In experiments, the approach is shown to (1) recover intuitive
locations of variables in space and time, (2) exploit regularities across
related datasets with completely disjoint input and output spaces, and (3)
exploit regularities across seemingly unrelated tasks, outperforming
task-specific single-task models and multi-task learning alternatives. The
results suggest that even seemingly unrelated tasks may originate from similar
underlying processes, a fact that the traveling observer model can use to make
better predictions.
</dc:description>
 <dc:description>Comment: Accepted for spotlight presentation as a conference paper at ICLR
  2021. Main paper: 9 pages; with references: 12 pages; with appendix: 17
  pages. Best viewed in color</dc:description>
 <dc:date>2020-10-05</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.02354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.02379</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Parallel Batch-Dynamic Data Structure for the Closest Pair Problem</dc:title>
 <dc:creator>Wang, Yiqiu</dc:creator>
 <dc:creator>Yu, Shangdi</dc:creator>
 <dc:creator>Gu, Yan</dc:creator>
 <dc:creator>Shun, Julian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We propose a theoretically-efficient and practical parallel batch-dynamic
data structure for the closest pair problem. Our solution is based on a serial
dynamic closest pair data structure by Golin et al., and supports batches of
insertions and deletions in parallel. For a data set of size $n$, our data
structure supports a batch of insertions or deletions of size $m$ in
$O(m(1+\log ((n+m)/m)))$ expected work and $O(\log (n+m)\log^*(n+m))$ depth
with high probability, and takes linear space. The key techniques for achieving
these bounds are a new work-efficient parallel batch-dynamic binary heap, and
careful management of the computation across sets of points to minimize work
and depth.
  We provide an optimized multicore implementation of our data structure using
dynamic hash tables, parallel heaps, and dynamic $k$-d trees. Our experiments
on a variety of synthetic and real-world data sets show that it achieves a
parallel speedup of up to 38.57x (15.10x on average) on 48 cores with
hyper-threading. In addition, we also implement and compare four parallel
algorithms for static closest pair problem, for which we are not aware of any
existing practical implementations. On 48 cores with hyper-threading, the
static algorithms achieve up to 51.45x (29.42x on average) speedup, and Rabin's
algorithm performs the best on average. Comparing our dynamic algorithm to the
fastest static algorithm, we find that it is advantageous to use the dynamic
algorithm for batch sizes of up to 20\% of the data set. As far as we know, our
work is the first to experimentally evaluate parallel closest pair algorithms,
in both the static and the dynamic settings.
</dc:description>
 <dc:date>2020-10-05</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.02379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.02618</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A faster algorithm for finding Tarski fixed points</dc:title>
 <dc:creator>Fearnley, John</dc:creator>
 <dc:creator>P&#xe1;lv&#xf6;lgyi, D&#xf6;m&#xf6;t&#xf6;r</dc:creator>
 <dc:creator>Savani, Rahul</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Dang et al. have given an algorithm that can find a Tarski fixed point in a
$k$-dimensional lattice of width $n$ using $O(\log^{k} n)$ queries. Multiple
authors have conjectured that this algorithm is optimal [Dang et al., Etessami
et al.], and indeed this has been proven for two-dimensional instances
[Etessami et al.]. We show that these conjectures are false in dimension three
or higher by giving an $O(\log^2 n)$ query algorithm for the three-dimensional
Tarski problem. We also give a new decomposition theorem for $k$-dimensional
Tarski problems which, in combination with our new algorithm for three
dimensions, gives an $O(\log^{2 \lceil k/3 \rceil} n)$ query algorithm for the
$k$-dimensional problem.
</dc:description>
 <dc:date>2020-10-06</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.02618</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.03325</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contour Primitive of Interest Extraction Network Based on One-Shot
  Learning for Object-Agnostic Vision Measurement</dc:title>
 <dc:creator>Qin, Fangbo</dc:creator>
 <dc:creator>Qin, Jie</dc:creator>
 <dc:creator>Huang, Siyu</dc:creator>
 <dc:creator>Xu, De</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image contour based vision measurement is widely applied in robot
manipulation and industrial automation. It is appealing to realize
object-agnostic vision system, which can be conveniently reused for various
types of objects. We propose the contour primitive of interest extraction
network (CPieNet) based on the one-shot learning framework. First, CPieNet is
featured by that its contour primitive of interest (CPI) output, a designated
regular contour part lying on a specified object, provides the essential
geometric information for vision measurement. Second, CPieNet has the one-shot
learning ability, utilizing a support sample to assist the perception of the
novel object. To realize lower-cost training, we generate support-query sample
pairs from unpaired online public images, which cover a wide range of object
categories. To obtain single-pixel wide contour for precise measurement, the
Gabor-filters based non-maximum suppression is designed to thin the raw
contour. For the novel CPI extraction task, we built the Object Contour
Primitives dataset using online public images, and the Robotic Object Contour
Measurement dataset using a camera mounted on a robot. The effectiveness of the
proposed methods is validated by a series of experiments.
</dc:description>
 <dc:description>Comment: Accepted by IEEE ICRA 2021</dc:description>
 <dc:date>2020-10-07</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.03325</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.03697</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Critique of Self-Expressive Deep Subspace Clustering</dc:title>
 <dc:creator>Haeffele, Benjamin D.</dc:creator>
 <dc:creator>You, Chong</dc:creator>
 <dc:creator>Vidal, Ren&#xe9;</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Subspace clustering is an unsupervised clustering technique designed to
cluster data that is supported on a union of linear subspaces, with each
subspace defining a cluster with dimension lower than the ambient space. Many
existing formulations for this problem are based on exploiting the
self-expressive property of linear subspaces, where any point within a subspace
can be represented as linear combination of other points within the subspace.
To extend this approach to data supported on a union of non-linear manifolds,
numerous studies have proposed learning an embedding of the original data using
a neural network which is regularized by a self-expressive loss function on the
data in the embedded space to encourage a union of linear subspaces prior on
the data in the embedded space. Here we show that there are a number of
potential flaws with this approach which have not been adequately addressed in
prior work. In particular, we show the model formulation is often ill-posed in
that it can lead to a degenerate embedding of the data, which need not
correspond to a union of subspaces at all and is poorly suited for clustering.
We validate our theoretical results experimentally and also repeat prior
experiments reported in the literature, where we conclude that a significant
portion of the previously claimed performance benefits can be attributed to an
ad-hoc post processing step rather than the deep subspace clustering model.
</dc:description>
 <dc:description>Comment: Published as a conference paper at the International Conference on
  Learning Representations (ICLR) 2021</dc:description>
 <dc:date>2020-10-07</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.03697</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.04004</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerating Simulation of Stiff Nonlinear Systems using Continuous-Time
  Echo State Networks</dc:title>
 <dc:creator>Anantharaman, Ranjan</dc:creator>
 <dc:creator>Ma, Yingbo</dc:creator>
 <dc:creator>Gowda, Shashi</dc:creator>
 <dc:creator>Laughman, Chris</dc:creator>
 <dc:creator>Shah, Viral</dc:creator>
 <dc:creator>Edelman, Alan</dc:creator>
 <dc:creator>Rackauckas, Chris</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  Modern design, control, and optimization often requires simulation of highly
nonlinear models, leading to prohibitive computational costs. These costs can
be amortized by evaluating a cheap surrogate of the full model. Here we present
a general data-driven method, the continuous-time echo state network (CTESN),
for generating surrogates of nonlinear ordinary differential equations with
dynamics at widely separated timescales. We empirically demonstrate
near-constant time performance using our CTESNs on a physically motivated
scalable model of a heating system whose full execution time increases
exponentially, while maintaining relative error of within 0.2 %. We also show
that our model captures fast transients as well as slow dynamics effectively,
while other techniques such as physics informed neural networks have
difficulties trying to train and predict the highly nonlinear behavior of these
models.
</dc:description>
 <dc:date>2020-10-07</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.04004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.04712</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gaussian Process (GP)-based Learning Control of Selective Laser Melting
  Process</dc:title>
 <dc:creator>Asadi, Farshid</dc:creator>
 <dc:creator>Olleak, Alaa A.</dc:creator>
 <dc:creator>Yi, Jingang</dc:creator>
 <dc:creator>Guo, Yuebin</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Selective laser melting (SLM) is one of emerging processes for effective
metal additive manufacturing. Due to complex heat exchange and material phase
changes, it is challenging to accurately model the SLM dynamics and design
robust control of SLM process. In this paper, we first present a data-driven
Gaussian process based dynamic model for SLM process and then design a model
predictive control to regulate the melt pool size. Physical and process
constraints are considered in the controller design. The learning model and
control design are tested and validated with high-fidelity finite element
simulation. The comparison results with other control design demonstrate the
efficacy of the control design.
</dc:description>
 <dc:date>2020-10-09</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.04712</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.05316</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence to the fixed-node limit in deep variational Monte Carlo</dc:title>
 <dc:creator>Sch&#xe4;tzle, Zeno</dc:creator>
 <dc:creator>Hermann, Jan</dc:creator>
 <dc:creator>No&#xe9;, Frank</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Variational quantum Monte Carlo (QMC) is an ab-initio method for solving the
electronic Schr\&quot;odinger equation that is exact in principle, but limited by
the flexibility of the available ansatzes in practice. The recently introduced
deep QMC approach, specifically two deep-neural-network ansatzes PauliNet and
FermiNet, allows variational QMC to reach the accuracy of diffusion QMC, but
little is understood about the convergence behavior of such ansatzes. Here, we
analyze how deep variational QMC approaches the fixed-node limit with
increasing network size. First, we demonstrate that a deep neural network can
overcome the limitations of a small basis set and reach the mean-field
complete-basis-set limit. Moving to electron correlation, we then perform an
extensive hyperparameter scan of a deep Jastrow factor for LiH and H$_4$ and
find that variational energies at the fixed-node limit can be obtained with a
sufficiently large network. Finally, we benchmark mean-field and many-body
ansatzes on H$_2$O, increasing the fraction of recovered fixed-node correlation
energy of single-determinant Slater--Jastrow-type ansatzes by half an order of
magnitude compared to previous variational QMC results and demonstrate that a
single-determinant Slater--Jastrow--backflow version of the ansatz overcomes
the fixed-node limitations. This analysis helps understanding the superb
accuracy of deep variational ansatzes in comparison to the traditional trial
wavefunctions at the respective level of theory, and will guide future
improvements of the neural network architectures in deep QMC.
</dc:description>
 <dc:description>Comment: This article may be downloaded for personal use only. Any other use
  requires prior permission of the author and AIP Publishing. This article
  appeared in J. Chem. Phys., vol. 154, no. 12, p. 124108, Mar. 2021 and may be
  found at https://doi.org/10.1063/5.0032836</dc:description>
 <dc:date>2020-10-11</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.05316</dc:identifier>
 <dc:identifier>doi:10.1063/5.0032836</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.05761</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Risks of Invariant Risk Minimization</dc:title>
 <dc:creator>Rosenfeld, Elan</dc:creator>
 <dc:creator>Ravikumar, Pradeep</dc:creator>
 <dc:creator>Risteski, Andrej</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Invariant Causal Prediction (Peters et al., 2016) is a technique for
out-of-distribution generalization which assumes that some aspects of the data
distribution vary across the training set but that the underlying causal
mechanisms remain constant. Recently, Arjovsky et al. (2019) proposed Invariant
Risk Minimization (IRM), an objective based on this idea for learning deep,
invariant features of data which are a complex function of latent variables;
many alternatives have subsequently been suggested. However, formal guarantees
for all of these works are severely lacking. In this paper, we present the
first analysis of classification under the IRM objective--as well as these
recently proposed alternatives--under a fairly natural and general model. In
the linear case, we show simple conditions under which the optimal solution
succeeds or, more often, fails to recover the optimal invariant predictor. We
furthermore present the very first results in the non-linear regime: we
demonstrate that IRM can fail catastrophically unless the test data are
sufficiently similar to the training distribution--this is precisely the issue
that it was intended to solve. Thus, in this setting we find that IRM and its
alternatives fundamentally do not improve over standard Empirical Risk
Minimization.
</dc:description>
 <dc:description>Comment: ICLR 2021 Camera-Ready</dc:description>
 <dc:date>2020-10-12</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.05761</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.06721</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ensemble Distillation for Structured Prediction: Calibrated, Accurate,
  Fast-Choose Three</dc:title>
 <dc:creator>Reich, Steven</dc:creator>
 <dc:creator>Mueller, David</dc:creator>
 <dc:creator>Andrews, Nicholas</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Modern neural networks do not always produce well-calibrated predictions,
even when trained with a proper scoring function such as cross-entropy. In
classification settings, simple methods such as isotonic regression or
temperature scaling may be used in conjunction with a held-out dataset to
calibrate model outputs. However, extending these methods to structured
prediction is not always straightforward or effective; furthermore, a held-out
calibration set may not always be available. In this paper, we study ensemble
distillation as a general framework for producing well-calibrated structured
prediction models while avoiding the prohibitive inference-time cost of
ensembles. We validate this framework on two tasks: named-entity recognition
and machine translation. We find that, across both tasks, ensemble distillation
produces models which retain much of, and occasionally improve upon, the
performance and calibration benefits of ensembles, while only requiring a
single model during test-time.
</dc:description>
 <dc:description>Comment: EMNLP 2020. v2: Changed formatting of title in metadata; no other
  changes</dc:description>
 <dc:date>2020-10-13</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.06721</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.06948</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Graph Networks for Particle Simulations</dc:title>
 <dc:creator>Martinkus, Karolis</dc:creator>
 <dc:creator>Lucchi, Aurelien</dc:creator>
 <dc:creator>Perraudin, Nathana&#xeb;l</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Learning system dynamics directly from observations is a promising direction
in machine learning due to its potential to significantly enhance our ability
to understand physical systems. However, the dynamics of many real-world
systems are challenging to learn due to the presence of nonlinear potentials
and a number of interactions that scales quadratically with the number of
particles $N$, as in the case of the N-body problem. In this work, we introduce
an approach that transforms a fully-connected interaction graph into a
hierarchical one which reduces the number of edges to $O(N)$. This results in
linear time and space complexity while the pre-computation of the hierarchical
graph requires $O(N\log (N))$ time and $O(N)$ space. Using our approach, we are
able to train models on much larger particle counts, even on a single GPU. We
evaluate how the phase space position accuracy and energy conservation depend
on the number of simulated particles. Our approach retains high accuracy and
efficiency even on large-scale gravitational N-body simulations which are
impossible to run on a single machine if a fully-connected graph is used.
Similar results are also observed when simulating Coulomb interactions.
Furthermore, we make several important observations regarding the performance
of this new hierarchical model, including: i) its accuracy tends to improve
with the number of particles in the simulation and ii) its generalisation to
unseen particle counts is also much better than for models that use all
$O(N^2)$ interactions.
</dc:description>
 <dc:description>Comment: 19 pages, 20 figures, AAAI 2021</dc:description>
 <dc:date>2020-10-14</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.06948</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.07279</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Positioning yourself in the maze of Neural Text Generation: A
  Task-Agnostic Survey</dc:title>
 <dc:creator>Chandu, Khyathi Raghavi</dc:creator>
 <dc:creator>Black, Alan W</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Neural text generation metamorphosed into several critical natural language
applications ranging from text completion to free form narrative generation. In
order to progress research in text generation, it is critical to absorb the
existing research works and position ourselves in this massively growing field.
Specifically, this paper surveys the fundamental components of modeling
approaches relaying task agnostic impacts across various generation tasks such
as storytelling, summarization, translation etc., In this context, we present
an abstraction of the imperative techniques with respect to learning paradigms,
pretraining, modeling approaches, decoding and the key challenges outstanding
in the field in each of them. Thereby, we deliver a one-stop destination for
researchers in the field to facilitate a perspective on where to situate their
work and how it impacts other closely related generation tasks.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2020-10-14</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.07279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.07429</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Autonomous UAV Exploration of Dynamic Environments via Incremental
  Sampling and Probabilistic Roadmap</dc:title>
 <dc:creator>Xu, Zhefan</dc:creator>
 <dc:creator>Deng, Di</dc:creator>
 <dc:creator>Shimada, Kenji</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Autonomous exploration requires robots to generate informative trajectories
iteratively. Although sampling-based methods are highly efficient in unmanned
aerial vehicle exploration, many of these methods do not effectively utilize
the sampled information from the previous planning iterations, leading to
redundant computation and longer exploration time. Also, few have explicitly
shown their exploration ability in dynamic environments even though they can
run real-time. To overcome these limitations, we propose a novel dynamic
exploration planner (DEP) for exploring unknown environments using incremental
sampling and Probabilistic Roadmap (PRM). In our sampling strategy, nodes are
added incrementally and distributed evenly in the explored region, yielding the
best viewpoints. To further shortening exploration time and ensuring safety,
our planner optimizes paths locally and refine them based on the Euclidean
Signed Distance Function (ESDF) map. Meanwhile, as the multi-query planner, PRM
allows the proposed planner to quickly search alternative paths to avoid
dynamic obstacles for safe exploration. Simulation experiments show that our
method safely explores dynamic environments and outperforms the benchmark
planners in terms of exploration time, path length, and computational time.
</dc:description>
 <dc:description>Comment: 8 Pages, 9 Figures, and 5 Tables. Video Link:
  https://youtu.be/ileyP4DRBjU. Github Link: https://github.com/Zhefan-Xu/DEP</dc:description>
 <dc:date>2020-10-14</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.07429</dc:identifier>
 <dc:identifier>IEEE Robotics and Automation Letters, Volume: 6, Issue: 2, April
  2021. Page(s): 2729 - 2736</dc:identifier>
 <dc:identifier>doi:10.1109/LRA.2021.3062008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.07432</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Viewmaker Networks: Learning Views for Unsupervised Representation
  Learning</dc:title>
 <dc:creator>Tamkin, Alex</dc:creator>
 <dc:creator>Wu, Mike</dc:creator>
 <dc:creator>Goodman, Noah</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Many recent methods for unsupervised representation learning train models to
be invariant to different &quot;views,&quot; or distorted versions of an input. However,
designing these views requires considerable trial and error by human experts,
hindering widespread adoption of unsupervised representation learning methods
across domains and modalities. To address this, we propose viewmaker networks:
generative models that learn to produce useful views from a given input.
Viewmakers are stochastic bounded adversaries: they produce views by generating
and then adding an $\ell_p$-bounded perturbation to the input, and are trained
adversarially with respect to the main encoder network. Remarkably, when
pretraining on CIFAR-10, our learned views enable comparable transfer accuracy
to the well-tuned SimCLR augmentations -- despite not including transformations
like cropping or color jitter. Furthermore, our learned views significantly
outperform baseline augmentations on speech recordings (+9% points, on average)
and wearable sensor data (+17% points). Viewmakers can also be combined with
handcrafted views: they improve robustness to common image corruptions and can
increase transfer performance in cases where handcrafted views are less
explored. These results suggest that viewmakers may provide a path towards more
general representation learning algorithms -- reducing the domain expertise and
effort needed to pretrain on a much wider set of domains. Code is available at
https://github.com/alextamkin/viewmaker.
</dc:description>
 <dc:description>Comment: ICLR 2021</dc:description>
 <dc:date>2020-10-14</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.07432</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.07441</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Auto-calibration Method Using Stop Signs for Urban Autonomous Driving
  Applications</dc:title>
 <dc:creator>Han, Yunhai</dc:creator>
 <dc:creator>Liu, Yuhan</dc:creator>
 <dc:creator>Paz, David</dc:creator>
 <dc:creator>Christensen, Henrik</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Calibration of sensors is fundamental to robust performance for intelligent
vehicles. In natural environments, disturbances can easily challenge
calibration. One possibility is to use natural objects of known shape to
recalibrate sensors. An approach based on recognition of traffic signs, such as
stop signs, and use of them for recalibration of cameras is presented. The
approach is based on detection, geometry estimation, calibration, and recursive
updating. Results from natural environments are presented that clearly show
convergence and improved performance.
</dc:description>
 <dc:description>Comment: 7 pages, 7 figures, 1 table, Accepted to ICRA 2021</dc:description>
 <dc:date>2020-10-14</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.07441</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.07865</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Update Frequently, Update Fast: Retraining Semantic Parsing Systems in a
  Fraction of Time</dc:title>
 <dc:creator>Lialin, Vladislav</dc:creator>
 <dc:creator>Goel, Rahul</dc:creator>
 <dc:creator>Simanovsky, Andrey</dc:creator>
 <dc:creator>Rumshisky, Anna</dc:creator>
 <dc:creator>Shah, Rushin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Currently used semantic parsing systems deployed in voice assistants can
require weeks to train. Datasets for these models often receive small and
frequent updates, data patches. Each patch requires training a new model. To
reduce training time, one can fine-tune the previously trained model on each
patch, but naive fine-tuning exhibits catastrophic forgetting - degradation of
the model performance on the data not represented in the data patch. In this
work, we propose a simple method that alleviates catastrophic forgetting and
show that it is possible to match the performance of a model trained from
scratch in less than 10% of a time via fine-tuning. The key to achieving this
is supersampling and EWC regularization. We demonstrate the effectiveness of
our method on multiple splits of the Facebook TOP and SNIPS datasets.
</dc:description>
 <dc:date>2020-10-15</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.07865</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.07997</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RGB-D SLAM with Structural Regularities</dc:title>
 <dc:creator>Li, Yanyan</dc:creator>
 <dc:creator>Yunus, Raza</dc:creator>
 <dc:creator>Brasch, Nikolas</dc:creator>
 <dc:creator>Navab, Nassir</dc:creator>
 <dc:creator>Tombari, Federico</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This work proposes a RGB-D SLAM system specifically designed for structured
environments and aimed at improved tracking and mapping accuracy by relying on
geometric features that are extracted from the surrounding. Structured
environments offer, in addition to points, also an abundance of geometrical
features such as lines and planes, which we exploit to design both the tracking
and mapping components of our SLAM system. For the tracking part, we explore
geometric relationships between these features based on the assumption of a
Manhattan World (MW). We propose a decoupling-refinement method based on
points, lines, and planes, as well as the use of Manhattan relationships in an
additional pose refinement module. For the mapping part, different levels of
maps from sparse to dense are reconstructed at a low computational cost. We
propose an instance-wise meshing strategy to build a dense map by meshing plane
instances independently. The overall performance in terms of pose estimation
and reconstruction is evaluated on public benchmarks and shows improved
performance compared to state-of-the-art methods. The code is released at
\url{https://github.com/yanyan-li/PlanarSLAM}
</dc:description>
 <dc:date>2020-10-15</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.07997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.08007</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuum-Armed Bandits: A Function Space Perspective</dc:title>
 <dc:creator>Singh, Shashank</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  Continuum-armed bandits (a.k.a., black-box or $0^{th}$-order optimization)
involves optimizing an unknown objective function given an oracle that
evaluates the function at a query point, with the goal of using as few query
points as possible. In the most well-studied case, the objective function is
assumed to be Lipschitz continuous and minimax rates of simple and cumulative
regrets are known in both noiseless and noisy settings. This paper studies
continuum-armed bandits under more general smoothness conditions, namely Besov
smoothness conditions, on the objective function. In both noiseless and noisy
conditions, we derive minimax rates under simple and cumulative regrets. Our
results show that minimax rates over objective functions in a Besov space are
identical to minimax rates over objective functions in the smallest H\&quot;older
space into which the Besov space embeds.
</dc:description>
 <dc:date>2020-10-15</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.08007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.08056</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IoT Platform for COVID-19 Prevention and Control: A Survey</dc:title>
 <dc:creator>Dong, Yudi</dc:creator>
 <dc:creator>Yao, Yu-Dong</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  As a result of the worldwide transmission of severe acute respiratory
syndrome coronavirus 2 (SARS-CoV-2), coronavirus disease 2019 (COVID-19) has
evolved into an unprecedented pandemic. Currently, with unavailable
pharmaceutical treatments and vaccines, this novel coronavirus results in a
great impact on public health, human society, and global economy, which is
likely to last for many years. One of the lessons learned from the COVID-19
pandemic is that a long-term system with non-pharmaceutical interventions for
preventing and controlling new infectious diseases is desirable to be
implemented. Internet of things (IoT) platform is preferred to be utilized to
achieve this goal, due to its ubiquitous sensing ability and seamless
connectivity. IoT technology is changing our lives through smart healthcare,
smart home, and smart city, which aims to build a more convenient and
intelligent community. This paper presents how the IoT could be incorporated
into the epidemic prevention and control system. Specifically, we demonstrate a
potential fog-cloud combined IoT platform that can be used in the systematic
and intelligent COVID-19 prevention and control, which involves five
interventions including COVID-19 Symptom Diagnosis, Quarantine Monitoring,
Contact Tracing &amp; Social Distancing, COVID-19 Outbreak Forecasting, and
SARS-CoV-2 Mutation Tracking. We investigate and review the state-of-the-art
literatures of these five interventions to present the capabilities of IoT in
countering against the current COVID-19 pandemic or future infectious disease
epidemics.
</dc:description>
 <dc:description>Comment: 12 pages; Submitted to IEEE Internet of Things Journal</dc:description>
 <dc:date>2020-10-15</dc:date>
 <dc:date>2020-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.08056</dc:identifier>
 <dc:identifier>IEEE Access 2021</dc:identifier>
 <dc:identifier>doi:10.1109/ACCESS.2021.3068276</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.08121</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Optimization for Coordinated Charging Control of Commercial
  Electric Vehicles Under Distributed Hydrogen Energy Supply</dc:title>
 <dc:creator>Long, Teng</dc:creator>
 <dc:creator>Jia, Qing-Shan</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  The transition to the zero-carbon power system is underway accelerating
recently. Hydrogen energy and electric vehicles (EVs) are promising solutions
on the supply and demand sides. This paper presents a novel architecture that
includes hydrogen production stations (HPSs), fast charging stations (FCSs),
and commercial EVs. The proposed architecture jointly optimizes the distributed
hydrogen energy dispatch and the EV charging location selection, and is
formulated by a time-varying bi-level bipartite graph (T-BBG) model for
real-time operation. We develop a bi-level iteration optimization method
combining linear programming (LP) and Kuhn-Munkres (KM) algorithm to solve the
joint problem whose optimality is proved theoretically. The effectiveness of
the proposed architecture on reducing the operating cost is verified via case
studies in Shanghai. The proposed method outperforms other strategies and
improves the performance by at least 13% which shows the potential economic
benefits of the joint architecture. The convergence and impact of the pile
number, battery capacity, EV speed and penalty factor are assessed.
</dc:description>
 <dc:date>2020-10-15</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.08121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.08124</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Risk-Aware Decision Making in Service Robots to Minimize Risk of Patient
  Falls in Hospitals</dc:title>
 <dc:creator>Novin, Roya Sabbagh</dc:creator>
 <dc:creator>Yazdani, Amir</dc:creator>
 <dc:creator>Merryweather, Andrew</dc:creator>
 <dc:creator>Hermans, Tucker</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Planning under uncertainty is a crucial capability for autonomous systems to
operate reliably in uncertain and dynamic environments. The concern of safety
becomes even more critical in healthcare settings where robots interact with
human patients. In this paper, we propose a novel risk-aware planning framework
to minimize the risk of falls by providing a patient with an assistive device.
Our approach combines learning-based prediction with model-based control to
plan for the fall prevention task. This provides advantages compared to
end-to-end learning methods in which the robot's performance is limited to
specific scenarios, or purely model-based approaches that use relatively simple
function approximators and are prone to high modeling errors. We compare
various risk metrics and the results from simulated scenarios show that using
the proposed cost function, the robot can plan interventions to avoid high fall
score events.
</dc:description>
 <dc:description>Comment: 7 pages + 2 page supplementary</dc:description>
 <dc:date>2020-10-15</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.08124</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.08252</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hyperparameter Auto-tuning in Self-Supervised Robotic Learning</dc:title>
 <dc:creator>Huang, Jiancong</dc:creator>
 <dc:creator>Rojas, Juan</dc:creator>
 <dc:creator>Zimmer, Matthieu</dc:creator>
 <dc:creator>Wu, Hongmin</dc:creator>
 <dc:creator>Guan, Yisheng</dc:creator>
 <dc:creator>Weng, Paul</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Policy optimization in reinforcement learning requires the selection of
numerous hyperparameters across different environments. Fixing them incorrectly
may negatively impact optimization performance leading notably to insufficient
or redundant learning. Insufficient learning (due to convergence to local
optima) results in under-performing policies whilst redundant learning wastes
time and resources. The effects are further exacerbated when using single
policies to solve multi-task learning problems. Observing that the Evidence
Lower Bound (ELBO) used in Variational Auto-Encoders correlates with the
diversity of image samples, we propose an auto-tuning technique based on the
ELBO for self-supervised reinforcement learning. Our approach can auto-tune
three hyperparameters: the replay buffer size, the number of policy gradient
updates during each epoch, and the number of exploration steps during each
epoch. We use a state-of-the-art self-supervised robot learning framework
(Reinforcement Learning with Imagined Goals (RIG) using Soft Actor-Critic) as
baseline for experimental verification. Experiments show that our method can
auto-tune online and yields the best performance at a fraction of the time and
computational resources. Code, video, and appendix for simulated and real-robot
experiments can be found at the project page \url{www.JuanRojas.net/autotune}.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures, Published in IEEE Robotics and Automation
  Letters; Presented at The 2021 International Conference on Robotics and
  Automation (ICRA 2021); Presented at Deep RL Workshop, NeurIPS 2020</dc:description>
 <dc:date>2020-10-16</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.08252</dc:identifier>
 <dc:identifier>IEEE Robotics and Automation Letters, Volume:6, Issue:2, P.
  3537-3544, April 2021</dc:identifier>
 <dc:identifier>doi:10.1109/LRA.2021.3064509</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.08516</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Biomedical Interactions with Higher-Order Graph Convolutional
  Networks</dc:title>
 <dc:creator>KC, Kishan</dc:creator>
 <dc:creator>Li, Rui</dc:creator>
 <dc:creator>Cui, Feng</dc:creator>
 <dc:creator>Haake, Anne</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Biomedical interaction networks have incredible potential to be useful in the
prediction of biologically meaningful interactions, identification of network
biomarkers of disease, and the discovery of putative drug targets. Recently,
graph neural networks have been proposed to effectively learn representations
for biomedical entities and achieved state-of-the-art results in biomedical
interaction prediction. These methods only consider information from immediate
neighbors but cannot learn a general mixing of features from neighbors at
various distances. In this paper, we present a higher-order graph convolutional
network (HOGCN) to aggregate information from the higher-order neighborhood for
biomedical interaction prediction. Specifically, HOGCN collects feature
representations of neighbors at various distances and learns their linear
mixing to obtain informative representations of biomedical entities.
Experiments on four interaction networks, including protein-protein, drug-drug,
drug-target, and gene-disease interactions, show that HOGCN achieves more
accurate and calibrated predictions. HOGCN performs well on noisy, sparse
interaction networks when feature representations of neighbors at various
distances are considered. Moreover, a set of novel interaction predictions are
validated by literature-based case studies.
</dc:description>
 <dc:date>2020-10-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.08516</dc:identifier>
 <dc:identifier>doi:10.1109/tcbb.2021.3059415</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.09323</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-view Subspace Clustering Networks with Local and Global Graph
  Information</dc:title>
 <dc:creator>Zheng, Qinghai</dc:creator>
 <dc:creator>Zhu, Jihua</dc:creator>
 <dc:creator>Ma, Yuanyuan</dc:creator>
 <dc:creator>Li, Zhongyu</dc:creator>
 <dc:creator>Tian, Zhiqiang</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  This study investigates the problem of multi-view subspace clustering, the
goal of which is to explore the underlying grouping structure of data collected
from different fields or measurements. Since data do not always comply with the
linear subspace models in many real-world applications, most existing
multi-view subspace clustering methods that based on the shallow linear
subspace models may fail in practice. Furthermore, underlying graph information
of multi-view data is always ignored in most existing multi-view subspace
clustering methods. To address aforementioned limitations, we proposed the
novel multi-view subspace clustering networks with local and global graph
information, termed MSCNLG, in this paper. Specifically, autoencoder networks
are employed on multiple views to achieve latent smooth representations that
are suitable for the linear assumption. Simultaneously, by integrating fused
multi-view graph information into self-expressive layers, the proposed MSCNLG
obtains the common shared multi-view subspace representation, which can be used
to get clustering results by employing the standard spectral clustering
algorithm. As an end-to-end trainable framework, the proposed method fully
investigates the valuable information of multiple views. Comprehensive
experiments on six benchmark datasets validate the effectiveness and
superiority of the proposed MSCNLG.
</dc:description>
 <dc:date>2020-10-19</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.09323</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.09515</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Transformation Invariance in Contrastive Representation
  Learning</dc:title>
 <dc:creator>Foster, Adam</dc:creator>
 <dc:creator>Pukdee, Rattana</dc:creator>
 <dc:creator>Rainforth, Tom</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose methods to strengthen the invariance properties of representations
obtained by contrastive learning. While existing approaches implicitly induce a
degree of invariance as representations are learned, we look to more directly
enforce invariance in the encoding process. To this end, we first introduce a
training objective for contrastive learning that uses a novel regularizer to
control how the representation changes under transformation. We show that
representations trained with this objective perform better on downstream tasks
and are more robust to the introduction of nuisance transformations at test
time. Second, we propose a change to how test time representations are
generated by introducing a feature averaging approach that combines encodings
from multiple transformations of the original input, finding that this leads to
across the board performance gains. Finally, we introduce the novel Spirograph
dataset to explore our ideas in the context of a differentiable generative
process with multiple downstream tasks, showing that our techniques for
learning invariance are highly beneficial.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2021</dc:description>
 <dc:date>2020-10-19</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.09515</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.09875</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Ensembles and Data Augmentation can Harm your Calibration</dc:title>
 <dc:creator>Wen, Yeming</dc:creator>
 <dc:creator>Jerfel, Ghassen</dc:creator>
 <dc:creator>Muller, Rafael</dc:creator>
 <dc:creator>Dusenberry, Michael W.</dc:creator>
 <dc:creator>Snoek, Jasper</dc:creator>
 <dc:creator>Lakshminarayanan, Balaji</dc:creator>
 <dc:creator>Tran, Dustin</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Ensemble methods which average over multiple neural network predictions are a
simple approach to improve a model's calibration and robustness. Similarly,
data augmentation techniques, which encode prior information in the form of
invariant feature transformations, are effective for improving calibration and
robustness. In this paper, we show a surprising pathology: combining ensembles
and data augmentation can harm model calibration. This leads to a trade-off in
practice, whereby improved accuracy by combining the two techniques comes at
the expense of calibration. On the other hand, selecting only one of the
techniques ensures good uncertainty estimates at the expense of accuracy. We
investigate this pathology and identify a compounding under-confidence among
methods which marginalize over sets of weights and data augmentation techniques
which soften labels. Finally, we propose a simple correction, achieving the
best of both worlds with significant accuracy and calibration gains over using
only ensembles or data augmentation individually. Applying the correction
produces new state-of-the art in uncertainty calibration across CIFAR-10,
CIFAR-100, and ImageNet.
</dc:description>
 <dc:date>2020-10-19</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.09875</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.10023</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigations on $c$-(almost) perfect nonlinear functions</dc:title>
 <dc:creator>Mesnager, Sihem</dc:creator>
 <dc:creator>Riera, Constanza</dc:creator>
 <dc:creator>Stanica, Pantelimon</dc:creator>
 <dc:creator>Yan, Haode</dc:creator>
 <dc:creator>Zhou, Zhengchun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>06E30, 11T06, 94A60, 94D10</dc:subject>
 <dc:description>  In a prior paper \cite{EFRST20}, two of us, along with P. Ellingsen, P. Felke
and A. Tkachenko, 1defined a new (output) multiplicative differential, and the
corresponding $c$-differential uniformity, which has the potential of extending
differential cryptanalysis. Here, we continue the work, by looking at some APN
functions through the mentioned concept and showing that their $c$-differential
uniformity increases significantly, in some cases.
</dc:description>
 <dc:description>Comment: 19 pages. arXiv admin note: text overlap with arXiv:2003.13019</dc:description>
 <dc:date>2020-10-18</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.10023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.10261</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AutoBSS: An Efficient Algorithm for Block Stacking Style Search</dc:title>
 <dc:creator>Zhang, Yikang</dc:creator>
 <dc:creator>Zhang, Jian</dc:creator>
 <dc:creator>Zhong, Zhao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Neural network architecture design mostly focuses on the new convolutional
operator or special topological structure of network block, little attention is
drawn to the configuration of stacking each block, called Block Stacking Style
(BSS). Recent studies show that BSS may also have an unneglectable impact on
networks, thus we design an efficient algorithm to search it automatically. The
proposed method, AutoBSS, is a novel AutoML algorithm based on Bayesian
optimization by iteratively refining and clustering Block Stacking Style Code
(BSSC), which can find optimal BSS in a few trials without biased evaluation.
On ImageNet classification task, ResNet50/MobileNetV2/EfficientNet-B0 with our
searched BSS achieve 79.29%/74.5%/77.79%, which outperform the original
baselines by a large margin. More importantly, experimental results on model
compression, object detection and instance segmentation show the strong
generalizability of the proposed AutoBSS, and further verify the unneglectable
impact of BSS on neural networks.
</dc:description>
 <dc:description>Comment: NeurIPS 2020</dc:description>
 <dc:date>2020-10-20</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.10261</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.10763</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement learning using Deep Q Networks and Q learning accurately
  localizes brain tumors on MRI with very small training sets</dc:title>
 <dc:creator>Stember, Joseph N</dc:creator>
 <dc:creator>Shalu, Hrithwik</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Purpose Supervised deep learning in radiology suffers from notorious inherent
limitations: 1) It requires large, hand-annotated data sets, 2) It is
non-generalizable, and 3) It lacks explainability and intuition. We have
recently proposed Reinforcement Learning to address all threes. However, we
applied it to images with radiologist eye tracking points, which limits the
state-action space. Here we generalize the Deep-Q Learning to a gridworld-based
environment, so that only the images and image masks are required.
  Materials and Methods We trained a Deep Q network on 30 two-dimensional image
slices from the BraTS brain tumor database. Each image contained one lesion. We
then tested the trained Deep Q network on a separate set of 30 testing set
images. For comparison, we also trained and tested a keypoint detection
supervised deep learning network for the same set of training / testing images.
  Results Whereas the supervised approach quickly overfit the training data,
and predicably performed poorly on the testing set (11\% accuracy), the Deep-Q
learning approach showed progressive improved generalizability to the testing
set over training time, reaching 70\% accuracy.
  Conclusion We have shown a proof-of-principle application of reinforcement
learning to radiological images, here using 2D contrast-enhanced MRI brain
images with the goal of localizing brain tumors. This represents a
generalization of recent work to a gridworld setting, naturally suitable for
analyzing medical images.
</dc:description>
 <dc:date>2020-10-21</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.10763</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.10781</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent neural network-based volumetric fluorescence microscopy</dc:title>
 <dc:creator>Huang, Luzhe</dc:creator>
 <dc:creator>Luo, Yilin</dc:creator>
 <dc:creator>Rivenson, Yair</dc:creator>
 <dc:creator>Ozcan, Aydogan</dc:creator>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Physics - Biological Physics</dc:subject>
 <dc:description>  Volumetric imaging of samples using fluorescence microscopy plays an
important role in various fields including physical, medical and life sciences.
Here we report a deep learning-based volumetric image inference framework that
uses 2D images that are sparsely captured by a standard wide-field fluorescence
microscope at arbitrary axial positions within the sample volume. Through a
recurrent convolutional neural network, which we term as Recurrent-MZ, 2D
fluorescence information from a few axial planes within the sample is
explicitly incorporated to digitally reconstruct the sample volume over an
extended depth-of-field. Using experiments on C. Elegans and nanobead samples,
Recurrent-MZ is demonstrated to increase the depth-of-field of a 63x/1.4NA
objective lens by approximately 50-fold, also providing a 30-fold reduction in
the number of axial scans required to image the same sample volume. We further
illustrated the generalization of this recurrent network for 3D imaging by
showing its resilience to varying imaging conditions, including e.g., different
sequences of input images, covering various axial permutations and unknown
axial positioning errors. Recurrent-MZ demonstrates the first application of
recurrent neural networks in microscopic image reconstruction and provides a
flexible and rapid volumetric imaging framework, overcoming the limitations of
current 3D scanning microscopy tools.
</dc:description>
 <dc:description>Comment: 17 pages, 7 figures</dc:description>
 <dc:date>2020-10-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.10781</dc:identifier>
 <dc:identifier>Light: Science &amp; Applications (2021)</dc:identifier>
 <dc:identifier>doi:10.1038/s41377-021-00506-9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.10852</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gender Prediction Based on Vietnamese Names with Machine Learning
  Techniques</dc:title>
 <dc:creator>To, Huy Quoc</dc:creator>
 <dc:creator>Van Nguyen, Kiet</dc:creator>
 <dc:creator>Nguyen, Ngan Luu-Thuy</dc:creator>
 <dc:creator>Nguyen, Anh Gia-Tuan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  As biological gender is one of the aspects of presenting individual human,
much work has been done on gender classification based on people names. The
proposals for English and Chinese languages are tremendous; still, there have
been few works done for Vietnamese so far. We propose a new dataset for gender
prediction based on Vietnamese names. This dataset comprises over 26,000 full
names annotated with genders. This dataset is available on our website for
research purposes. In addition, this paper describes six machine learning
algorithms (Support Vector Machine, Multinomial Naive Bayes, Bernoulli Naive
Bayes, Decision Tree, Random Forrest and Logistic Regression) and a deep
learning model (LSTM) with fastText word embedding for gender prediction on
Vietnamese names. We create a dataset and investigate the impact of each name
component on detecting gender. As a result, the best F1-score that we have
achieved is up to 96% on LSTM model and we generate a web API based on our
trained model.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures. NLPIR 2020: 4th International Conference on
  Natural Language Processing and Information Retrieval</dc:description>
 <dc:date>2020-10-21</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.10852</dc:identifier>
 <dc:identifier>doi:10.1145/3443279.3443309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.11083</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Pixel-wise Structured Sparse Network for Efficient CNNs</dc:title>
 <dc:creator>Tang, Chen</dc:creator>
 <dc:creator>Sun, Wenyu</dc:creator>
 <dc:creator>Yuan, Zhuqing</dc:creator>
 <dc:creator>Liu, Yongpan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  To accelerate deep CNN models, this paper proposes a novel spatially adaptive
framework that can dynamically generate pixel-wise sparsity according to the
input image. The sparse scheme is pixel-wise refined, regional adaptive under a
unified importance map, which makes it friendly to hardware implementation. A
sparse controlling method is further presented to enable online adjustment for
applications with different precision/latency requirements. The sparse model is
applicable to a wide range of vision tasks. Experimental results show that this
method efficiently improve the computing efficiency for both image
classification using ResNet-18 and super resolution using SRResNet. On image
classification task, our method can save 30%-70% MACs with a slightly drop in
top-1 and top-5 accuracy. On super resolution task, our method can reduce more
than 90% MACs while only causing around 0.1 dB and 0.01 decreasing in PSNR and
SSIM. Hardware validation is also included.
</dc:description>
 <dc:date>2020-10-21</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.11083</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.11092</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stacking Neural Network Models for Automatic Short Answer Scoring</dc:title>
 <dc:creator>Rajagede, Rian Adam</dc:creator>
 <dc:creator>Hastuti, Rochana Prih</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Automatic short answer scoring is one of the text classification problems to
assess students' answers during exams automatically. Several challenges can
arise in making an automatic short answer scoring system, one of which is the
quantity and quality of the data. The data labeling process is not easy because
it requires a human annotator who is an expert in their field. Further, the
data imbalance process is also a challenge because the number of labels for
correct answers is always much less than the wrong answers. In this paper, we
propose the use of a stacking model based on neural network and XGBoost for
classification process with sentence embedding feature. We also propose to use
data upsampling method to handle imbalance classes and hyperparameters
optimization algorithm to find a robust model automatically. We use Ukara 1.0
Challenge dataset and our best model obtained an F1-score of 0.821 exceeding
the previous work at the same dataset.
</dc:description>
 <dc:description>Comment: submitted to The 5th International Conference on Information
  Technology and Digital Applications 2020</dc:description>
 <dc:date>2020-10-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.11092</dc:identifier>
 <dc:identifier>doi:10.1088/1757-899X/1077/1/012013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.11290</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unrolling of Deep Graph Total Variation for Image Denoising</dc:title>
 <dc:creator>Vu, Huy</dc:creator>
 <dc:creator>Cheung, Gene</dc:creator>
 <dc:creator>Eldar, Yonina C.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  While deep learning (DL) architectures like convolutional neural networks
(CNNs) have enabled effective solutions in image denoising, in general their
implementations overly rely on training data, lack interpretability, and
require tuning of a large parameter set. In this paper, we combine classical
graph signal filtering with deep feature learning into a competitive hybrid
design -- one that utilizes interpretable analytical low-pass graph filters and
employs 80% fewer network parameters than state-of-the-art DL denoising scheme
DnCNN. Specifically, to construct a suitable similarity graph for graph
spectral filtering, we first adopt a CNN to learn feature representations per
pixel, and then compute feature distances to establish edge weights. Given a
constructed graph, we next formulate a convex optimization problem for
denoising using a graph total variation (GTV) prior. Via a $l_1$ graph
Laplacian reformulation, we interpret its solution in an iterative procedure as
a graph low-pass filter and derive its frequency response. For fast filter
implementation, we realize this response using a Lanczos approximation.
Experimental results show that in the case of statistical mistmatch, our
algorithm outperformed DnCNN by up to 3dB in PSNR.
</dc:description>
 <dc:date>2020-10-21</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.11290</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.11398</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DPD-InfoGAN: Differentially Private Distributed InfoGAN</dc:title>
 <dc:creator>Mugunthan, Vaikkunth</dc:creator>
 <dc:creator>Gokul, Vignesh</dc:creator>
 <dc:creator>Kagal, Lalana</dc:creator>
 <dc:creator>Dubnov, Shlomo</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Generative Adversarial Networks (GANs) are deep learning architectures
capable of generating synthetic datasets. Despite producing high-quality
synthetic images, the default GAN has no control over the kinds of images it
generates. The Information Maximizing GAN (InfoGAN) is a variant of the default
GAN that introduces feature-control variables that are automatically learned by
the framework, hence providing greater control over the different kinds of
images produced. Due to the high model complexity of InfoGAN, the generative
distribution tends to be concentrated around the training data points. This is
a critical problem as the models may inadvertently expose the sensitive and
private information present in the dataset. To address this problem, we propose
a differentially private version of InfoGAN (DP-InfoGAN). We also extend our
framework to a distributed setting (DPD-InfoGAN) to allow clients to learn
different attributes present in other clients' datasets in a privacy-preserving
manner. In our experiments, we show that both DP-InfoGAN and DPD-InfoGAN can
synthesize high-quality images with flexible control over image attributes
while preserving privacy.
</dc:description>
 <dc:date>2020-10-21</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.11398</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.11584</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flexibility management with virtual batteries of thermostatically
  controlled loads: real-time control system and potential in Spain</dc:title>
 <dc:creator>Mart&#xed;n-Crespo, Alejandro</dc:creator>
 <dc:creator>Saludes-Rodil, Sergio</dc:creator>
 <dc:creator>Baeyens, Enrique</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Load flexibility management is a promising approach to face the problem of
balancing generation and demand in electrical grids. This problem is becoming
increasingly difficult due to the variability of renewable energies.
Thermostatically controlled loads can be aggregated and managed by a virtual
battery, and they provide a cost-effective and efficient alternative to
physical storage systems to mitigate the inherent variability of renewable
energy sources. But virtual batteries require of an accurate control system
being capable of tracking frequency regulation signals with minimal error. A
real-time control system allowing virtual batteries to accurately track
frequency or power signals is developed. The performance of this controller is
validated for a virtual battery composed of 1,000 thermostatically controlled
loads. Using virtual batteries equipped with the developed controller, a study
focused on residential thermostatically controlled loads in Spain is performed.
The results of the study quantify the potential of this technology in a country
with different climate areas and provides insight about the feasibility of
virtual batteries as enablers of electrical systems with high levels of
penetration of renewable energy sources.
</dc:description>
 <dc:description>Comment: 26 pages, 13 figures</dc:description>
 <dc:date>2020-10-22</dc:date>
 <dc:date>2021-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.11584</dc:identifier>
 <dc:identifier>Energies 2021, 14(6), 1711</dc:identifier>
 <dc:identifier>doi:10.3390/en14061711</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.11659</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Network-based Acoustic Vehicle Counting</dc:title>
 <dc:creator>Djukanovi&#x107;, Slobodan</dc:creator>
 <dc:creator>Patel, Yash</dc:creator>
 <dc:creator>Matas, Ji&#x159;i</dc:creator>
 <dc:creator>Virtanen, Tuomas</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  This paper addresses acoustic vehicle counting using one-channel audio. We
predict the pass-by instants of vehicles from local minima of clipped
vehicle-to-microphone distance. This distance is predicted from audio using a
two-stage (coarse-fine) regression, with both stages realised via neural
networks (NNs). Experiments show that the NN-based distance regression
outperforms by far the previously proposed support vector regression. The $
95\% $ confidence interval for the mean of vehicle counting error is within
$[0.28\%, -0.55\%]$. Besides the minima-based counting, we propose a deep
learning counting that operates on the predicted distance without detecting
local minima. Although outperformed in accuracy by the former approach, deep
counting has a significant advantage in that it does not depend on minima
detection parameters. Results also show that removing low frequencies in
features improves the counting performance.
</dc:description>
 <dc:date>2020-10-22</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.11659</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.11757</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Analysis of CNN-based Spatio-temporal Representations for Action
  Recognition</dc:title>
 <dc:creator>Chen, Chun-Fu</dc:creator>
 <dc:creator>Panda, Rameswar</dc:creator>
 <dc:creator>Ramakrishnan, Kandan</dc:creator>
 <dc:creator>Feris, Rogerio</dc:creator>
 <dc:creator>Cohn, John</dc:creator>
 <dc:creator>Oliva, Aude</dc:creator>
 <dc:creator>Fan, Quanfu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In recent years, a number of approaches based on 2D or 3D convolutional
neural networks (CNN) have emerged for video action recognition, achieving
state-of-the-art results on several large-scale benchmark datasets. In this
paper, we carry out in-depth comparative analysis to better understand the
differences between these approaches and the progress made by them. To this
end, we develop an unified framework for both 2D-CNN and 3D-CNN action models,
which enables us to remove bells and whistles and provides a common ground for
fair comparison. We then conduct an effort towards a large-scale analysis
involving over 300 action recognition models. Our comprehensive analysis
reveals that a) a significant leap is made in efficiency for action
recognition, but not in accuracy; b) 2D-CNN and 3D-CNN models behave similarly
in terms of spatio-temporal representation abilities and transferability. Our
codes are available at https://github.com/IBM/action-recognition-pytorch.
</dc:description>
 <dc:description>Comment: CVPR 2021 camera-ready version. Codes and models are available on
  https://github.com/IBM/action-recognition-pytorch</dc:description>
 <dc:date>2020-10-22</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.11757</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.12423</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GraphSpeech: Syntax-Aware Graph Attention Network For Neural Speech
  Synthesis</dc:title>
 <dc:creator>Liu, Rui</dc:creator>
 <dc:creator>Sisman, Berrak</dc:creator>
 <dc:creator>Li, Haizhou</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Attention-based end-to-end text-to-speech synthesis (TTS) is superior to
conventional statistical methods in many ways. Transformer-based TTS is one of
such successful implementations. While Transformer TTS models the speech frame
sequence well with a self-attention mechanism, it does not associate input text
with output utterances from a syntactic point of view at sentence level. We
propose a novel neural TTS model, denoted as GraphSpeech, that is formulated
under graph neural network framework. GraphSpeech encodes explicitly the
syntactic relation of input lexical tokens in a sentence, and incorporates such
information to derive syntactically motivated character embeddings for TTS
attention mechanism. Experiments show that GraphSpeech consistently outperforms
the Transformer TTS baseline in terms of spectrum and prosody rendering of
utterances.
</dc:description>
 <dc:description>Comment: To appear at ICASSP'2021 (Accepted). (Speech samples:
  https://ttslr.github.io/GraphSpeech/)</dc:description>
 <dc:date>2020-10-23</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.12423</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.12673</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Minimum Word Error Rate Training of the Hybrid Autoregressive
  Transducer</dc:title>
 <dc:creator>Lu, Liang</dc:creator>
 <dc:creator>Meng, Zhong</dc:creator>
 <dc:creator>Kanda, Naoyuki</dc:creator>
 <dc:creator>Li, Jinyu</dc:creator>
 <dc:creator>Gong, Yifan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Hybrid Autoregressive Transducer (HAT) is a recently proposed end-to-end
acoustic model that extends the standard Recurrent Neural Network Transducer
(RNN-T) for the purpose of the external language model (LM) fusion. In HAT, the
blank probability and the label probability are estimated using two separate
probability distributions, which provides a more accurate solution for internal
LM score estimation, and thus works better when combining with an external LM.
Previous work mainly focuses on HAT model training with the negative
log-likelihood loss, while in this paper, we study the minimum word error rate
(MWER) training of HAT -- a criterion that is closer to the evaluation metric
for speech recognition, and has been successfully applied to other types of
end-to-end models such as sequence-to-sequence (S2S) and RNN-T models. From
experiments with around 30,000 hours of training data, we show that MWER
training can improve the accuracy of HAT models, while at the same time,
improving the robustness of the model against the decoding hyper-parameters
such as length normalization and decoding beam during inference.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure. Accepted to ICASSP 2021, but we withdrawn due to a
  bug in code. We updated the results after the bug fix, and submitted the
  paper to Interspeech 2021</dc:description>
 <dc:date>2020-10-23</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.12673</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.12812</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Frustratingly Easy Approach for Entity and Relation Extraction</dc:title>
 <dc:creator>Zhong, Zexuan</dc:creator>
 <dc:creator>Chen, Danqi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  End-to-end relation extraction aims to identify named entities and extract
relations between them. Most recent work models these two subtasks jointly,
either by casting them in one structured prediction framework, or performing
multi-task learning through shared representations. In this work, we present a
simple pipelined approach for entity and relation extraction, and establish the
new state-of-the-art on standard benchmarks (ACE04, ACE05 and SciERC),
obtaining a 1.7%-2.8% absolute improvement in relation F1 over previous joint
models with the same pre-trained encoders. Our approach essentially builds on
two independent encoders and merely uses the entity model to construct the
input for the relation model. Through a series of careful examinations, we
validate the importance of learning distinct contextual representations for
entities and relations, fusing entity information early in the relation model,
and incorporating global context. Finally, we also present an efficient
approximation to our approach which requires only one pass of both entity and
relation encoders at inference time, achieving an 8-16$\times$ speedup with a
slight reduction in accuracy.
</dc:description>
 <dc:description>Comment: NAACL 2021. Our code and models are available at
  https://github.com/princeton-nlp/PURE</dc:description>
 <dc:date>2020-10-24</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.12812</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.12850</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CoCo: Controllable Counterfactuals for Evaluating Dialogue State
  Trackers</dc:title>
 <dc:creator>Li, Shiyang</dc:creator>
 <dc:creator>Yavuz, Semih</dc:creator>
 <dc:creator>Hashimoto, Kazuma</dc:creator>
 <dc:creator>Li, Jia</dc:creator>
 <dc:creator>Niu, Tong</dc:creator>
 <dc:creator>Rajani, Nazneen</dc:creator>
 <dc:creator>Yan, Xifeng</dc:creator>
 <dc:creator>Zhou, Yingbo</dc:creator>
 <dc:creator>Xiong, Caiming</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Dialogue state trackers have made significant progress on benchmark datasets,
but their generalization capability to novel and realistic scenarios beyond the
held-out conversations is less understood. We propose controllable
counterfactuals (CoCo) to bridge this gap and evaluate dialogue state tracking
(DST) models on novel scenarios, i.e., would the system successfully tackle the
request if the user responded differently but still consistently with the
dialogue flow? CoCo leverages turn-level belief states as counterfactual
conditionals to produce novel conversation scenarios in two steps: (i)
counterfactual goal generation at turn-level by dropping and adding slots
followed by replacing slot values, (ii) counterfactual conversation generation
that is conditioned on (i) and consistent with the dialogue flow. Evaluating
state-of-the-art DST models on MultiWOZ dataset with CoCo-generated
counterfactuals results in a significant performance drop of up to 30.8% (from
49.4% to 18.6%) in absolute joint goal accuracy. In comparison, widely used
techniques like paraphrasing only affect the accuracy by at most 2%. Human
evaluations show that COCO-generated conversations perfectly reflect the
underlying user goal with more than 95% accuracy and are as human-like as the
original conversations, further strengthening its reliability and promise to be
adopted as part of the robustness evaluation of DST models.
</dc:description>
 <dc:description>Comment: ICLR 2021</dc:description>
 <dc:date>2020-10-24</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.12850</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.13132</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiscale Score Matching for Out-of-Distribution Detection</dc:title>
 <dc:creator>Mahmood, Ahsan</dc:creator>
 <dc:creator>Oliva, Junier</dc:creator>
 <dc:creator>Styner, Martin</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We present a new methodology for detecting out-of-distribution (OOD) images
by utilizing norms of the score estimates at multiple noise scales. A score is
defined to be the gradient of the log density with respect to the input data.
Our methodology is completely unsupervised and follows a straight forward
training scheme. First, we train a deep network to estimate scores for levels
of noise. Once trained, we calculate the noisy score estimates for N
in-distribution samples and take the L2-norms across the input dimensions
(resulting in an NxL matrix). Then we train an auxiliary model (such as a
Gaussian Mixture Model) to learn the in-distribution spatial regions in this
L-dimensional space. This auxiliary model can now be used to identify points
that reside outside the learned space. Despite its simplicity, our experiments
show that this methodology significantly outperforms the state-of-the-art in
detecting out-of-distribution images. For example, our method can effectively
separate CIFAR-10 (inlier) and SVHN (OOD) images, a setting which has been
previously shown to be difficult for deep likelihood models.
</dc:description>
 <dc:date>2020-10-25</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.13132</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.13166</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Curriculum Learning</dc:title>
 <dc:creator>Wang, Xin</dc:creator>
 <dc:creator>Chen, Yudong</dc:creator>
 <dc:creator>Zhu, Wenwu</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Curriculum learning (CL) is a training strategy that trains a machine
learning model from easier data to harder data, which imitates the meaningful
learning order in human curricula. As an easy-to-use plug-in, the CL strategy
has demonstrated its power in improving the generalization capacity and
convergence rate of various models in a wide range of scenarios such as
computer vision and natural language processing etc. In this survey article, we
comprehensively review CL from various aspects including motivations,
definitions, theories, and applications. We discuss works on curriculum
learning within a general CL framework, elaborating on how to design a manually
predefined curriculum or an automatic curriculum. In particular, we summarize
existing CL designs based on the general framework of Difficulty
Measurer+Training Scheduler and further categorize the methodologies for
automatic CL into four groups, i.e., Self-paced Learning, Transfer Teacher, RL
Teacher, and Other Automatic CL. We also analyze principles to select different
CL designs that may benefit practical applications. Finally, we present our
insights on the relationships connecting CL and other machine learning concepts
including transfer learning, meta-learning, continual learning and active
learning, etc., then point out challenges in CL as well as potential future
research directions deserving further investigations.
</dc:description>
 <dc:description>Comment: 20 pages, 7 figures, Accepted by IEEE Transactions on Pattern
  Analysis and Machine Intelligence 2021 (TPAMI)</dc:description>
 <dc:date>2020-10-25</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.13166</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.13308</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometrically Matched Multi-source Microscopic Image Synthesis Using
  Bidirectional Adversarial Networks</dc:title>
 <dc:creator>Zhuang, Jun</dc:creator>
 <dc:creator>Wang, Dali</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Microscopic images from multiple modalities can produce plentiful
experimental information. In practice, biological or physical constraints under
a given observation period may prevent researchers from acquiring enough
microscopic scanning. Recent studies demonstrate that image synthesis is one of
the popular approaches to release such constraints. Nonetheless, most existing
synthesis approaches only translate images from the source domain to the target
domain without solid geometric associations. To embrace this challenge, we
propose an innovative model architecture, BANIS, to synthesize diversified
microscopic images from multi-source domains with distinct geometric features.
The experimental outcomes indicate that BANIS successfully synthesizes
favorable image pairs on C. elegans microscopy embryonic images. To the best of
our knowledge, BANIS is the first application to synthesize microscopic images
that associate distinct spatial geometric features from multi-source domains.
</dc:description>
 <dc:description>Comment: Published in MICAD 2021</dc:description>
 <dc:date>2020-10-25</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.13308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.13355</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PSF-LO: Parameterized Semantic Features Based Lidar Odometry</dc:title>
 <dc:creator>Chen, Guibin</dc:creator>
 <dc:creator>Wang, Bosheng</dc:creator>
 <dc:creator>Wang, Xiaoliang</dc:creator>
 <dc:creator>Deng, Huanjun</dc:creator>
 <dc:creator>Wang, Bing</dc:creator>
 <dc:creator>Zhang, Shuo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Lidar odometry (LO) is a key technology in numerous reliable and accurate
localization and mapping systems of autonomous driving. The state-of-the-art LO
methods generally leverage geometric information to perform point cloud
registration. Furthermore, obtaining point cloud semantic information which can
describe the environment more abundantly will help for the registration. We
present a novel semantic lidar odometry method based on self-designed
parameterized semantic features (PSFs) to achieve low-drift ego-motion
estimation for autonomous vehicle in realtime. We first use a convolutional
neural network-based algorithm to obtain point-wise semantics from the input
laser point cloud, and then use semantic labels to separate the road, building,
traffic sign and pole-like point cloud and fit them separately to obtain
corresponding PSFs. A fast PSF-based matching enable us to refine geometric
features (GeFs) registration, reducing the impact of blurred submap surface on
the accuracy of GeFs matching. Besides, we design an efficient method to
accurately recognize and remove the dynamic objects while retaining static ones
in the semantic point cloud, which are beneficial to further improve the
accuracy of LO. We evaluated our method, namely PSF-LO, on the public dataset
KITTI Odometry Benchmark and ranked #1 among semantic lidar methods with an
average translation error of 0.82% in the test dataset at the time of writing.
</dc:description>
 <dc:description>Comment: Accepted in International Conference on Robotics and Automation
  (ICRA) 2021</dc:description>
 <dc:date>2020-10-26</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.13355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.13392</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Containing Future Epidemics with Trustworthy Federated Systems for
  Ubiquitous Warning and Response</dc:title>
 <dc:creator>Carrillo, Dick</dc:creator>
 <dc:creator>Nguyen, Lam Duc</dc:creator>
 <dc:creator>Nardelli, Pedro H. J.</dc:creator>
 <dc:creator>Pournaras, Evangelos</dc:creator>
 <dc:creator>Morita, Plinio</dc:creator>
 <dc:creator>Rodr&#xed;guez, Dem&#xf3;stenes Z.</dc:creator>
 <dc:creator>Dzaferagic, Merim</dc:creator>
 <dc:creator>Siljak, Harun</dc:creator>
 <dc:creator>Jung, Alexander</dc:creator>
 <dc:creator>H&#xe9;bert-Dufresne, Laurent</dc:creator>
 <dc:creator>Macaluso, Irene</dc:creator>
 <dc:creator>Ullah, Mehar</dc:creator>
 <dc:creator>Fraidenraich, Gustavo</dc:creator>
 <dc:creator>Popovski, Petar</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this paper, we propose a global digital platform to avoid and combat
epidemics by providing relevant real-time information to support selective
lockdowns. It leverages the pervasiveness of wireless connectivity while being
trustworthy and secure. The proposed system is conceptualized to be
decentralized yet federated, based on ubiquitous public systems and active
citizen participation. Its foundations lie on the principle of informational
self-determination. We argue that only in this way it can become a trustworthy
and legitimate public good infrastructure for citizens by balancing the
asymmetry of the different hierarchical levels within the federated
organization while providing highly effective detection and guiding mitigation
measures towards graceful lockdown of the society. To exemplify the proposed
system, we choose the remote patient monitoring as use case. In which, the
integration of distributed ledger technologies with narrowband IoT technology
is evaluated considering different number of endorsed peers. An experimental
proof of concept setup is used to evaluate the performance of this integration,
in which the end-to-end latency is slightly increased when a new endorsed
element is added. However, the system reliability, privacy, and
interoperability are guaranteed. In this sense, we expect active participation
of empowered citizens to supplement the more usual top-down management of
epidemics.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures, Accepted for Publication</dc:description>
 <dc:date>2020-10-26</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.13392</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.13660</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social learning under inferential attacks</dc:title>
 <dc:creator>Ntemos, Konstantinos</dc:creator>
 <dc:creator>Bordignon, Virginia</dc:creator>
 <dc:creator>Vlaski, Stefan</dc:creator>
 <dc:creator>Sayed, Ali H.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  A common assumption in the social learning literature is that agents exchange
information in an unselfish manner. In this work, we consider the scenario
where a subset of agents aims at driving the network beliefs to the wrong
hypothesis. The adversaries are unaware of the true hypothesis. However, they
will &quot;blend in&quot; by behaving similarly to the other agents and will manipulate
the likelihood functions used in the belief update process to launch
inferential attacks. We will characterize the conditions under which the
network is misled. Then, we will explain that it is possible for such attacks
to succeed by showing that strategies exist that can be adopted by the
malicious agents for this purpose. We examine both situations in which the
agents have minimal or no information about the network model.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures</dc:description>
 <dc:date>2020-10-26</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.13660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.13787</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Inference With Bayesian Neural Networks: An Application to
  Strong Gravitational Lensing</dc:title>
 <dc:creator>Wagner-Carena, Sebastian</dc:creator>
 <dc:creator>Park, Ji Won</dc:creator>
 <dc:creator>Birrer, Simon</dc:creator>
 <dc:creator>Marshall, Philip J.</dc:creator>
 <dc:creator>Roodman, Aaron</dc:creator>
 <dc:creator>Wechsler, Risa H.</dc:creator>
 <dc:subject>Astrophysics - Cosmology and Nongalactic Astrophysics</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In the past few years, approximate Bayesian Neural Networks (BNNs) have
demonstrated the ability to produce statistically consistent posteriors on a
wide range of inference problems at unprecedented speed and scale. However, any
disconnect between training sets and the distribution of real-world objects can
introduce bias when BNNs are applied to data. This is a common challenge in
astrophysics and cosmology, where the unknown distribution of objects in our
Universe is often the science goal. In this work, we incorporate BNNs with
flexible posterior parameterizations into a hierarchical inference framework
that allows for the reconstruction of population hyperparameters and removes
the bias introduced by the training distribution. We focus on the challenge of
producing posterior PDFs for strong gravitational lens mass model parameters
given Hubble Space Telescope (HST) quality single-filter, lens-subtracted,
synthetic imaging data. We show that the posterior PDFs are sufficiently
accurate (i.e., statistically consistent with the truth) across a wide variety
of power-law elliptical lens mass distributions. We then apply our approach to
test data sets whose lens parameters are drawn from distributions that are
drastically different from the training set. We show that our hierarchical
inference framework mitigates the bias introduced by an unrepresentative
training set's interim prior. Simultaneously, given a sufficiently broad
training set, we can precisely reconstruct the population hyperparameters
governing our test distributions. Our full pipeline, from training to
hierarchical inference on thousands of lenses, can be run in a day. The
framework presented here will allow us to efficiently exploit the full
constraining power of future ground- and space-based surveys.
</dc:description>
 <dc:description>Comment: Accepted by ApJ. Code available at
  https://github.com/swagnercarena/ovejero</dc:description>
 <dc:date>2020-10-26</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.13787</dc:identifier>
 <dc:identifier>ApJ 909 187 (2021)</dc:identifier>
 <dc:identifier>doi:10.3847/1538-4357/abdf59</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.13890</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How We Refactor and How We Document it? On the Use of Supervised Machine
  Learning Algorithms to Classify Refactoring Documentation</dc:title>
 <dc:creator>AlOmar, Eman Abdullah</dc:creator>
 <dc:creator>Peruma, Anthony</dc:creator>
 <dc:creator>Mkaouer, Mohamed Wiem</dc:creator>
 <dc:creator>Newman, Christian</dc:creator>
 <dc:creator>Ouni, Ali</dc:creator>
 <dc:creator>Kessentini, Marouane</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Refactoring is the art of improving the design of a system without altering
its external behavior. Refactoring has become a well established and
disciplined software engineering practice that has attracted a significant
amount of research presuming that refactoring is primarily motivated by the
need to improve system structures. However, recent studies have shown that
developers may incorporate refactorings in other development activities that go
beyond improving the design. Unfortunately, these studies are limited to
developer interviews and a reduced set of projects. To cope with the
above-mentioned limitations, we aim to better understand what motivates
developers to apply refactoring by mining and classifying a large set of
111,884 commits containing refactorings, extracted from 800 Java projects. We
trained a multi-class classifier to categorize these commits into 3 categories,
namely, Internal QA, External QA, and Code Smell Resolution, along with the
traditional BugFix and Functional categories. This classification challenges
the original definition of refactoring, being exclusive to improving the design
and fixing code smells. Further, to better understand our classification
results, we analyzed commit messages to extract textual patterns that
developers regularly use to describe their refactorings. The results show that
(1) fixing code smells is not the main driver for developers to refactoring
their codebases. Refactoring is solicited for a wide variety of reasons, going
beyond its traditional definition; (2) the distribution of refactorings differs
between production and test files; (3) developers use several patterns to
purposefully target refactoring; (4) the textual patterns, extracted from
commit messages, provide better coverage for how developers document their
refactorings.
</dc:description>
 <dc:date>2020-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.13890</dc:identifier>
 <dc:identifier>Expert Systems with Applications. 167 (2021) 114176</dc:identifier>
 <dc:identifier>doi:10.1016/j.eswa.2020.114176</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.13929</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HarperValleyBank: A Domain-Specific Spoken Dialog Corpus</dc:title>
 <dc:creator>Wu, Mike</dc:creator>
 <dc:creator>Nafziger, Jonathan</dc:creator>
 <dc:creator>Scodary, Anthony</dc:creator>
 <dc:creator>Maas, Andrew</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We introduce HarperValleyBank, a free, public domain spoken dialog corpus.
The data simulate simple consumer banking interactions, containing about 23
hours of audio from 1,446 human-human conversations between 59 unique speakers.
We selected intents and utterance templates to allow realistic variation while
controlling overall task complexity and limiting vocabulary size to about 700
unique words. We provide audio data along with transcripts and annotations for
speaker identity, caller intent, dialog actions, and emotional valence. The
data size and domain specificity makes for quick transcription experiments with
modern end-to-end neural approaches. Further, we provide baselines for
representation learning, adapting recent work to embed waveforms for downstream
prediction tasks. Our experiments show that tasks using our annotations are
sensitive to both the model choice and corpus size.
</dc:description>
 <dc:description>Comment: 5 pages content, 1 page of references</dc:description>
 <dc:date>2020-10-26</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.13929</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.13952</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Adversarial Domain Separation Framework for Septic Shock Early
  Prediction Across EHR Systems</dc:title>
 <dc:creator>Khoshnevisan, Farzaneh</dc:creator>
 <dc:creator>Chi, Min</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Modeling patient disease progression using Electronic Health Records (EHRs)
is critical to assist clinical decision making. While most of prior work has
mainly focused on developing effective disease progression models using EHRs
collected from an individual medical system, relatively little work has
investigated building robust yet generalizable diagnosis models across
different systems. In this work, we propose a general domain adaptation (DA)
framework that tackles two categories of discrepancies in EHRs collected from
different medical systems: one is caused by heterogeneous patient populations
(covariate shift) and the other is caused by variations in data collection
procedures (systematic bias). Prior research in DA has mainly focused on
addressing covariate shift but not systematic bias. In this work, we propose an
adversarial domain separation framework that addresses both categories of
discrepancies by maintaining one globally-shared invariant latent
representation across all systems} through an adversarial learning process,
while also allocating a domain-specific model for each system to extract local
latent representations that cannot and should not be unified across systems.
Moreover, our proposed framework is based on variational recurrent neural
network (VRNN) because of its ability to capture complex temporal dependencies
and handling missing values in time-series data. We evaluate our framework for
early diagnosis of an extremely challenging condition, septic shock, using two
real-world EHRs from distinct medical systems in the U.S. The results show that
by separating globally-shared from domain-specific representations, our
framework significantly improves septic shock early prediction performance in
both EHRs and outperforms the current state-of-the-art DA models.
</dc:description>
 <dc:description>Comment: to be published in 2020 IEEE International Conference on Big Data</dc:description>
 <dc:date>2020-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.13952</dc:identifier>
 <dc:identifier>doi:10.1109/BigData50022.2020.9378058</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.14163</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Location Information for RIS-aided mmWave MIMO Communications</dc:title>
 <dc:creator>He, Jiguang</dc:creator>
 <dc:creator>Wymeersch, Henk</dc:creator>
 <dc:creator>Juntti, Markku</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Location information offered by external positioning systems, e.g., satellite
navigation, can be used as prior information in the process of beam alignment
and channel parameter estimation for reconfigurable intelligent surface
(RIS)-aided millimeter wave (mmWave) multiple-input multiple-output networks.
Benefiting from the availability of such prior information, albeit imperfect,
the beam alignment and channel parameter estimation processes can be
significantly accelerated with less candidate beams explored at all the
terminals. We propose a practical channel parameter estimation method via
atomic norm minimization, which outperforms the standard beam alignment in
terms of both the mean square error and the effective spectrum efficiency for
the same training overhead.
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures, accepted IEEE Wireless Communications Letters for
  possible publication</dc:description>
 <dc:date>2020-10-27</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.14163</dc:identifier>
 <dc:identifier>doi:10.1109/LWC.2021.3067474</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.14226</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Range-Net: A High Precision Streaming SVD for Big Data Applications</dc:title>
 <dc:creator>Singh, Gurpreet</dc:creator>
 <dc:creator>Gupta, Soumyajit</dc:creator>
 <dc:creator>Lease, Matthew</dc:creator>
 <dc:creator>Dawson, Clint</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In a Big Data setting computing the dominant SVD factors is restrictive due
to the main memory requirements. Recently introduced streaming Randomized SVD
schemes work under the restrictive assumption that the singular value spectrum
of the data has exponential decay. This is seldom true for any practical data.
Although these methods are claimed to be applicable to scientific computations
due to associated tail-energy error bounds, the approximation errors in the
singular vectors and values are high when the aforementioned assumption does
not hold. Furthermore from a practical perspective, oversampling can still be
memory intensive or worse can exceed the feature dimension of the data. To
address these issues, we present Range-Net as an alternative to randomized SVD
that satisfies the tail-energy lower bound given by Eckart-Young-Mirsky (EYM)
theorem. Range-Net is a deterministic two-stage neural optimization approach
with random initialization, where the main memory requirement depends
explicitly on the feature dimension and desired rank, independent of the sample
dimension. The data samples are read in a streaming setting with the network
minimization problem converging to the desired rank-r approximation. Range-Net
is fully interpretable where all the network outputs and weights have a
specific meaning. We provide theoretical guarantees that Range-Net extracted
SVD factors satisfy EYM tail-energy lower bound at machine precision. Our
numerical experiments on real data at various scales confirms this bound. A
comparison against the state of the art streaming Randomized SVD shows that
Range-Net accuracy is better by six orders of magnitude while being memory
efficient.
</dc:description>
 <dc:date>2020-10-27</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.14226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.15579</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A semi-supervised autoencoder framework for joint generation and
  classification of breathing</dc:title>
 <dc:creator>Pastor-Serrano, Oscar</dc:creator>
 <dc:creator>Lathouwers, Danny</dc:creator>
 <dc:creator>Perk&#xf3;, Zolt&#xe1;n</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  One of the main problems with biomedical signals is the limited amount of
patient-specific data and the significant amount of time needed to record the
sufficient number of samples needed for diagnostic and treatment purposes. In
this study, we present a framework to simultaneously generate and classify
biomedical time series based on a modified Adversarial Autoencoder (AAE)
algorithm and one-dimensional convolutions. Our work is based on breathing time
series, with specific motivation to capture breathing motion during
radiotherapy lung cancer treatments. First, we explore the potential in using
the Variational Autoencoder (VAE) and AAE algorithms to model breathing from
individual patients. We extend the AAE algorithm to allow joint semi-supervised
classification and generation of different types of signals. To simplify the
modeling task, we introduce a pre-processing and post-processing compressing
algorithm that transforms the multi-dimensional time series into vectors
containing time and position values, which are transformed back into time
series through an additional neural network. By incorporating few labeled
samples during training, our model outperforms other purely discriminative
networks in classifying breathing baseline shift irregularities from a dataset
completely different from the training set. To our knowledge, the presented
framework is the first approach that unifies generation and classification
within a single model for this type of biomedical data, enabling both computer
aided diagnosis and augmentation of labeled samples within a single framework.
</dc:description>
 <dc:date>2020-10-19</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.15579</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.15947</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PAL : Pretext-based Active Learning</dc:title>
 <dc:creator>Bhatnagar, Shubhang</dc:creator>
 <dc:creator>Goyal, Sachin</dc:creator>
 <dc:creator>Tank, Darshan</dc:creator>
 <dc:creator>Sethi, Amit</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The goal of pool-based active learning is to judiciously select a fixed-sized
subset of unlabeled samples from a pool to query an oracle for their labels, in
order to maximize the accuracy of a supervised learner. However, the unsaid
requirement that the oracle should always assign correct labels is unreasonable
for most situations. We propose an active learning technique for deep neural
networks that is more robust to mislabeling than the previously proposed
techniques. Previous techniques rely on the task network itself to estimate the
novelty of the unlabeled samples, but learning the task (generalization) and
selecting samples (out-of-distribution detection) can be conflicting goals. We
use a separate network to score the unlabeled samples for selection. The
scoring network relies on self-supervision for modeling the distribution of the
labeled samples to reduce the dependency on potentially noisy labels. To
counter the paucity of data, we also deploy another head on the scoring network
for regularization via multi-task learning and use an unusual self-balancing
hybrid scoring function. Furthermore, we divide each query into sub-queries
before labeling to ensure that the query has diverse samples. In addition to
having a higher tolerance to mislabeling of samples by the oracle, the
resultant technique also produces competitive accuracy in the absence of label
noise. The technique also handles the introduction of new classes on-the-fly
well by temporarily increasing the sampling rate of these classes.
</dc:description>
 <dc:date>2020-10-29</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.15947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.16267</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring Dynamic Context for Multi-path Trajectory Prediction</dc:title>
 <dc:creator>Cheng, Hao</dc:creator>
 <dc:creator>Liao, Wentong</dc:creator>
 <dc:creator>Tang, Xuejiao</dc:creator>
 <dc:creator>Yang, Michael Ying</dc:creator>
 <dc:creator>Sester, Monika</dc:creator>
 <dc:creator>Rosenhahn, Bodo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  To accurately predict future positions of different agents in traffic
scenarios is crucial for safely deploying intelligent autonomous systems in the
real-world environment. However, it remains a challenge due to the behavior of
a target agent being affected by other agents dynamically and there being more
than one socially possible paths the agent could take. In this paper, we
propose a novel framework, named Dynamic Context Encoder Network (DCENet). In
our framework, first, the spatial context between agents is explored by using
self-attention architectures. Then, the two-stream encoders are trained to
learn temporal context between steps by taking the respective observed
trajectories and the extracted dynamic spatial context as input. The
spatial-temporal context is encoded into a latent space using a Conditional
Variational Auto-Encoder (CVAE) module. Finally, a set of future trajectories
for each agent is predicted conditioned on the learned spatial-temporal context
by sampling from the latent space, repeatedly. DCENet is evaluated on one of
the most popular challenging benchmarks for trajectory forecasting Trajnet and
reports a new state-of-the-art performance. It also demonstrates superior
performance evaluated on the benchmark inD for mixed traffic at intersections.
A series of ablation studies is conducted to validate the effectiveness of each
proposed module. Our code is available at https://github.com/wtliao/DCENet.
</dc:description>
 <dc:description>Comment: accpeted by ICRA 2021, code available</dc:description>
 <dc:date>2020-10-30</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.16267</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.16272</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PATHoBot: A Robot for Glasshouse Crop Phenotyping and Intervention</dc:title>
 <dc:creator>Smitt, Claus</dc:creator>
 <dc:creator>Halstead, Michael</dc:creator>
 <dc:creator>Zaenker, Tobias</dc:creator>
 <dc:creator>Bennewitz, Maren</dc:creator>
 <dc:creator>McCool, Chris</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present PATHoBot an autonomous crop surveying and intervention robot for
glasshouse environments. The aim of this platform is to autonomously gather
high quality data and also estimate key phenotypic parameters. To achieve this
we retro-fit an off-the-shelf pipe-rail trolley with an array of multi-modal
cameras, navigation sensors and a robotic arm for close surveying tasks and
intervention. In this paper we describe PATHoBot design choices made to ensure
proper operation in a commercial glasshouse environment. As a surveying
platform we collect a number of datasets which include both sweet pepper and
tomatoes. We show how PATHoBot enables novel surveillance approaches by first
improving our previous work on fruit counting by incorporating wheel odometry
and depth information. We find that by introducing re-projection and depth
information we are able to achieve an absolute improvement of 20 points over
the baseline technique in an &quot;in the wild&quot; situation. Finally, we present a 3D
mapping case study, further showcasing PATHoBot's crop surveying capabilities.
</dc:description>
 <dc:date>2020-10-30</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.16272</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2010.16322</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepWay: a Deep Learning Waypoint Estimator for Global Path Generation</dc:title>
 <dc:creator>Mazzia, Vittorio</dc:creator>
 <dc:creator>Salvetti, Francesco</dc:creator>
 <dc:creator>Aghi, Diego</dc:creator>
 <dc:creator>Chiaberge, Marcello</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Agriculture 3.0 and 4.0 have gradually introduced service robotics and
automation into several agricultural processes, mostly improving crops quality
and seasonal yield. Row-based crops are the perfect settings to test and deploy
smart machines capable of monitoring and manage the harvest. In this context,
global path generation is essential either for ground or aerial vehicles, and
it is the starting point for every type of mission plan. Nevertheless, little
attention has been currently given to this problem by the research community
and global path generation automation is still far to be solved. In order to
generate a viable path for an autonomous machine, the presented research
proposes a feature learning fully convolutional model capable of estimating
waypoints given an occupancy grid map. In particular, we apply the proposed
data-driven methodology to the specific case of row-based crops with the
general objective to generate a global path able to cover the extension of the
crop completely. Extensive experimentation with a custom made synthetic dataset
and real satellite-derived images of different scenarios have proved the
effectiveness of our methodology and demonstrated the feasibility of an
end-to-end and completely autonomous global path planner.
</dc:description>
 <dc:description>Comment: Submitted to Computers and Electronics in Agriculture</dc:description>
 <dc:date>2020-10-30</dc:date>
 <dc:date>2021-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2010.16322</dc:identifier>
 <dc:identifier>Volume 184, May 2021, 106091</dc:identifier>
 <dc:identifier>doi:10.1016/j.compag.2021.106091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.00050</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dataset Meta-Learning from Kernel Ridge-Regression</dc:title>
 <dc:creator>Nguyen, Timothy</dc:creator>
 <dc:creator>Chen, Zhourong</dc:creator>
 <dc:creator>Lee, Jaehoon</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  One of the most fundamental aspects of any machine learning algorithm is the
training data used by the algorithm. We introduce the novel concept of
$\epsilon$-approximation of datasets, obtaining datasets which are much smaller
than or are significant corruptions of the original training data while
maintaining similar model performance. We introduce a meta-learning algorithm
called Kernel Inducing Points (KIP) for obtaining such remarkable datasets,
inspired by the recent developments in the correspondence between
infinitely-wide neural networks and kernel ridge-regression (KRR). For KRR
tasks, we demonstrate that KIP can compress datasets by one or two orders of
magnitude, significantly improving previous dataset distillation and subset
selection methods while obtaining state of the art results for MNIST and
CIFAR-10 classification. Furthermore, our KIP-learned datasets are transferable
to the training of finite-width neural networks even beyond the lazy-training
regime, which leads to state of the art results for neural network dataset
distillation with potential applications to privacy-preservation.
</dc:description>
 <dc:description>Comment: Accepted to ICLR 2021. Open source implementation:
  https://colab.sandbox.google.com/github/google-research/google-research/blob/master/kip/KIP.ipynb</dc:description>
 <dc:date>2020-10-30</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.00050</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.00223</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Journal Coverage of Web of Science, Scopus and Dimensions: A
  Comparative Analysis</dc:title>
 <dc:creator>Singh, Vivek Kumar</dc:creator>
 <dc:creator>Singh, Prashasti</dc:creator>
 <dc:creator>Karmakar, Mousumi</dc:creator>
 <dc:creator>Leta, Jacqueline</dc:creator>
 <dc:creator>Mayr, Philipp</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Traditionally, Web of Science and Scopus have been the two most widely used
databases for bibliometric analyses. However, during the last few years some
new scholarly databases, such as Dimensions, have come up. Several previous
studies have compared different databases, either through a direct comparison
of article coverage or by comparing the citations across the databases. This
article attempts to compare the journal coverage of the three databases: Web of
Science, Scopus and Dimensions. The most recent master journal lists of the
three databases have been used for the purpose of identifying the overlapping
and unique journals covered in the databases. The results indicate that the
databases have significantly different journal coverage, with the Web of
Science being most selective and Dimensions being the most exhaustive. About
99.11% and 96.61% of the journals indexed in Web of Science are also indexed in
Scopus and Dimensions, respectively. Scopus has 96.42% of its indexed journals
also covered by Dimensions. Dimensions database has the most exhaustive
coverage, with 82.22% more journals covered as compared to Web of Science and
48.17% more journals covered as compared to Scopus. We also analysed the
research outputs for 20 highly productive countries for the 2010-2019 period,
as indexed in the three databases, and identified database-induced variations
in research output volume, rank and global share of different countries. In
addition to variations in overall coverage of research output from different
countries, the three databases appear to have differential coverage of
different disciplines.
</dc:description>
 <dc:description>Comment: Submitted to Scientometrics</dc:description>
 <dc:date>2020-10-31</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.00223</dc:identifier>
 <dc:identifier>Scientometrics 2021</dc:identifier>
 <dc:identifier>doi:10.1007/s11192-021-03948-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.00491</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MRPB 1.0: A Unified Benchmark for the Evaluation of Mobile Robot Local
  Planning Approaches</dc:title>
 <dc:creator>Wen, Jian</dc:creator>
 <dc:creator>Zhang, Xuebo</dc:creator>
 <dc:creator>Bi, Qingchen</dc:creator>
 <dc:creator>Pan, Zhangchao</dc:creator>
 <dc:creator>Feng, Yanghe</dc:creator>
 <dc:creator>Yuan, Jing</dc:creator>
 <dc:creator>Fang, Yongchun</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Local planning is one of the key technologies for mobile robots to achieve
full autonomy and has been widely investigated. To evaluate mobile robot local
planning approaches in a unified and comprehensive way, a mobile robot local
planning benchmark called MRPB 1.0 is newly proposed in this paper. The
benchmark facilitates both motion planning researchers who want to compare the
performance of a new local planner relative to many other state-of-the-art
approaches as well as end users in the mobile robotics industry who want to
select a local planner that performs best on some problems of interest. We
elaborately design various simulation scenarios to challenge the applicability
of local planners, including large-scale, partially unknown, and dynamic
complex environments. Furthermore, three types of principled evaluation metrics
are carefully designed to quantitatively evaluate the performance of local
planners, wherein the safety, efficiency, and smoothness of motions are
comprehensively considered. We present the application of the proposed
benchmark in two popular open-source local planners to show the practicality of
the benchmark. In addition, some insights and guidelines about the design and
selection of local planners are also provided. The benchmark website contains
all data of the designed simulation scenarios, detailed descriptions of these
scenarios, and example code.
</dc:description>
 <dc:description>Comment: 2021 IEEE International Conference on Robotics and Automation (ICRA),
  accepted</dc:description>
 <dc:date>2020-11-01</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.00491</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.00563</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Robot Trajectories subject to Kinematic Joint Constraints</dc:title>
 <dc:creator>Kiemel, Jonas C.</dc:creator>
 <dc:creator>Kr&#xf6;ger, Torsten</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present an approach to learn fast and dynamic robot motions without
exceeding limits on the position $\theta$, velocity $\dot{\theta}$,
acceleration $\ddot{\theta}$ and jerk $\dddot{\theta}$ of each robot joint.
Movements are generated by mapping the predictions of a neural network to
safely executable joint accelerations. The neural network is invoked
periodically and trained via reinforcement learning. Our main contribution is
an analytical procedure for calculating safe joint accelerations, which
considers the prediction frequency $f_N$ of the neural network. As a result,
the frequency $f_N$ can be freely chosen and treated as a hyperparameter. We
show that our approach is preferable to penalizing constraint violations as it
provides explicit guarantees and does not distort the desired optimization
target. In addition, the influence of the selected prediction frequency on the
learning performance and on the computing effort is highlighted by various
experiments.
</dc:description>
 <dc:description>Comment: IEEE International Conference on Robotics and Automation (ICRA 2021);
  7 pages, 7 figures</dc:description>
 <dc:date>2020-11-01</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.00563</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.00596</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bracketing Encodings for 2-Planar Dependency Parsing</dc:title>
 <dc:creator>Strzyz, Michalina</dc:creator>
 <dc:creator>Vilares, David</dc:creator>
 <dc:creator>G&#xf3;mez-Rodr&#xed;guez, Carlos</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>68T50</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We present a bracketing-based encoding that can be used to represent any
2-planar dependency tree over a sentence of length n as a sequence of n labels,
hence providing almost total coverage of crossing arcs in sequence labeling
parsing. First, we show that existing bracketing encodings for parsing as
labeling can only handle a very mild extension of projective trees. Second, we
overcome this limitation by taking into account the well-known property of
2-planarity, which is present in the vast majority of dependency syntactic
structures in treebanks, i.e., the arcs of a dependency tree can be split into
two planes such that arcs in a given plane do not cross. We take advantage of
this property to design a method that balances the brackets and that encodes
the arcs belonging to each of those planes, allowing for almost unrestricted
non-projectivity (round 99.9% coverage) in sequence labeling parsing. The
experiments show that our linearizations improve over the accuracy of the
original bracketing encoding in highly non-projective treebanks (on average by
0.4 LAS), while achieving a similar speed. Also, they are especially suitable
when PoS tags are not used as input parameters to the models.
</dc:description>
 <dc:description>Comment: COLING2020 (long papers), 13 pages (incl. appendix) with corrected
  parsing speeds for Danish and Gothic</dc:description>
 <dc:date>2020-11-01</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.00596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.00601</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate Solutions to a Class of Reachability Games</dc:title>
 <dc:creator>Fridovich-Keil, David</dc:creator>
 <dc:creator>Tomlin, Claire J.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper, we present a method for finding approximate Nash equilibria in
a broad class of reachability games. These games are often used to formulate
both collision avoidance and goal satisfaction. Our method is computationally
efficient, running in real-time for scenarios involving multiple players and
more than ten state dimensions. The proposed approach forms a family of
increasingly exact approximations to the original game. Our results
characterize the quality of these approximations and show operation in a
receding horizon, minimally-invasive control context. Additionally, as a
special case, our method reduces to local gradient-based optimization in the
single-player (optimal control) setting, for which a wide variety of efficient
algorithms exist.
</dc:description>
 <dc:description>Comment: Conference paper at ICRA 2021</dc:description>
 <dc:date>2020-11-01</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.00601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.00632</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synthesis of Discounted-Reward Optimal Policies for Markov Decision
  Processes Under Linear Temporal Logic Specifications</dc:title>
 <dc:creator>Kalagarla, Krishna C.</dc:creator>
 <dc:creator>Jain, Rahul</dc:creator>
 <dc:creator>Nuzzo, Pierluigi</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  We present a method to find an optimal policy with respect to a reward
function for a discounted Markov decision process under general linear temporal
logic (LTL) specifications. Previous work has either focused on maximizing a
cumulative reward objective under finite-duration tasks, specified by
syntactically co-safe LTL, or maximizing an average reward for persistent
(e.g., surveillance) tasks. This paper extends and generalizes these results by
introducing a pair of occupancy measures to express the LTL satisfaction
objective and the expected discounted reward objective, respectively. These
occupancy measures are then connected to a single policy via a novel reduction
resulting in a mixed integer linear program whose solution provides an optimal
policy. Our formulation can also be extended to include additional constraints
with respect to secondary reward functions. We illustrate the effectiveness of
our approach in the context of robotic motion planning for complex missions
under uncertainty and performance objectives.
</dc:description>
 <dc:description>Comment: Accepted for ACC 2021</dc:description>
 <dc:date>2020-11-01</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.00632</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.00642</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Technical Report: Reactive Planning for Mobile Manipulation Tasks in
  Unexplored Semantic Environments</dc:title>
 <dc:creator>Vasilopoulos, Vasileios</dc:creator>
 <dc:creator>Kantaros, Yiannis</dc:creator>
 <dc:creator>Pappas, George J.</dc:creator>
 <dc:creator>Koditschek, Daniel E.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Complex manipulation tasks, such as rearrangement planning of numerous
objects, are combinatorially hard problems. Existing algorithms either do not
scale well or assume a great deal of prior knowledge about the environment, and
few offer any rigorous guarantees. In this paper, we propose a novel hybrid
control architecture for achieving such tasks with mobile manipulators. On the
discrete side, we enrich a temporal logic specification with mobile
manipulation primitives such as moving to a point, and grasping or moving an
object. Such specifications are translated to an automaton representation,
which orchestrates the physical grounding of the task to mobility or
manipulation controllers. The grounding from the discrete to the continuous
reactive controller is online and can respond to the discovery of unknown
obstacles or decide to push out of the way movable objects that prohibit task
accomplishment. Despite the problem complexity, we prove that, under specific
conditions, our architecture enjoys provable completeness on the discrete side,
provable termination on the continuous side, and avoids all obstacles in the
environment. Simulations illustrate the efficiency of our architecture that can
handle tasks of increased complexity while also responding to unknown obstacles
or unanticipated adverse configurations.
</dc:description>
 <dc:description>Comment: Technical Report accompanying the paper &quot;Reactive Planning for Mobile
  Manipulation Tasks in Unexplored Semantic Environments&quot; at ICRA 2021 (12
  pages, 7 figures)</dc:description>
 <dc:date>2020-11-01</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.00642</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.00778</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Sequences of Manipulation Primitives for Robotic Assembly</dc:title>
 <dc:creator>Vuong, Nghia</dc:creator>
 <dc:creator>Pham, Hung</dc:creator>
 <dc:creator>Pham, Quang-Cuong</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper explores the idea that skillful assembly is best represented as
dynamic sequences of Manipulation Primitives, and that such sequences can be
automatically discovered by Reinforcement Learning. Manipulation Primitives,
such as &quot;Move down until contact&quot;, &quot;Slide along x while maintaining contact
with the surface&quot;, have enough complexity to keep the search tree shallow, yet
are generic enough to generalize across a wide range of assembly tasks.
Moreover, the additional &quot;semantics&quot; of the Manipulation Primitives make them
more robust in sim2real and against model/environment variations and
uncertainties, as compared to more elementary actions. Policies are learned in
simulation, and then transferred onto a physical platform. Direct sim2real
transfer (without retraining in real) achieves excellent success rates on
challenging assembly tasks, such as round peg insertion with 0.04 mm clearance
or square peg insertion with large hole position/orientation estimation errors.
</dc:description>
 <dc:description>Comment: 7 pages, 7 figures</dc:description>
 <dc:date>2020-11-02</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.00778</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.00836</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ant Colony Inspired Machine Learning Algorithm for Identifying and
  Emulating Virtual Sensors</dc:title>
 <dc:creator>Mani, Pranav</dc:creator>
 <dc:creator>Gopi, ES</dc:creator>
 <dc:creator>Kumaran, Koushik</dc:creator>
 <dc:creator>Shekhar, Hrishikesh</dc:creator>
 <dc:creator>Chandra, Sharan</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  The scale of systems employed in industrial environments demands a large
number of sensors to facilitate meticulous monitoring and functioning. These
requirements could potentially lead to inefficient system designs. The data
coming from various sensors are often correlated due to the underlying
relations in the system parameters that the sensors monitor. In theory, it
should be possible to emulate the output of certain sensors based on other
sensors. Tapping into such possibilities holds tremendous advantages in terms
of reducing system design complexity. In order to identify the subset of
sensors whose readings can be emulated, the sensors must be grouped into
clusters. Complex systems generally have a large quantity of sensors that
collect and store data over prolonged periods of time. This leads to the
accumulation of massive amounts of data. In this paper we propose an end-to-end
algorithmic solution, to realise virtual sensors in such systems. This
algorithm splits the dataset into blocks and clusters each of them
individually. It then fuses these clustering solutions to obtain a global
solution using an Ant Colony inspired technique, FAC2T. Having grouped the
sensors into clusters, we select representative sensors from each cluster.
These sensors are retained in the system while the other sensors readings are
emulated by applying supervised learning algorithms.
</dc:description>
 <dc:description>Comment: 9 Pages, 7 Figures. This work has been submitted to the IEEE for
  possible publication. Copyright may be transferred without notice, after
  which this version may no longer be accessible. All Authors are Co-First
  Authors</dc:description>
 <dc:date>2020-11-02</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.00836</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.00900</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Channel Estimation for RIS-assisted Millimeter-wave MIMO Systems</dc:title>
 <dc:creator>Deepak, Battu</dc:creator>
 <dc:creator>Sankar, R. S. Prasobh</dc:creator>
 <dc:creator>Chepuri, Sundeep Prabhakar</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Channel estimation in reconfigurable intelligent surface (RIS) assisted
multiple input multiple output (MIMO) communication systems is challenging as
pilots cannot be decoded at or transmitted from a RIS with only passive
elements. We assume an angular model for the line-of-sight channel between the
user equipment (UE) and the RIS and between the RIS and the base station (BS)
with no direct path between the UE and BS. In this letter, assuming that we can
compute the RIS-BS channel (up to a complex path gain) from their known
locations, we first discuss the ambiguity involved in estimating the UE-RIS
channel. We propose a multiple channel sounding procedure in which we observe
the channel through different RIS phase shifts and present an algorithm for
channel estimation to resolve this ambiguity. Through simulations, we show that
the proposed method is comparable to an oracle estimator, which perfectly knows
the BS, UE, and RIS locations.
</dc:description>
 <dc:date>2020-11-02</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.00900</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.01126</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ProbRobScene: A Probabilistic Specification Language for 3D Robotic
  Manipulation Environments</dc:title>
 <dc:creator>Innes, Craig</dc:creator>
 <dc:creator>Ramamoorthy, Subramanian</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Robotic control tasks are often first run in simulation for the purposes of
verification, debugging and data augmentation. Many methods exist to specify
what task a robot must complete, but few exist to specify what range of
environments a user expects such tasks to be achieved in. ProbRobScene is a
probabilistic specification language for describing robotic manipulation
environments. Using the language, a user need only specify the relational
constraints that must hold between objects in a scene. ProbRobScene will then
automatically generate scenes which conform to this specification. By combining
aspects of probabilistic programming languages and convex geometry, we provide
a method for sampling this space of possible environments efficiently. We
demonstrate the usefulness of our language by using it to debug a robotic
controller in a tabletop robot manipulation environment.
</dc:description>
 <dc:date>2020-11-02</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.01126</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.01153</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Perceive, Attend, and Drive: Learning Spatial Attention for Safe
  Self-Driving</dc:title>
 <dc:creator>Wei, Bob</dc:creator>
 <dc:creator>Ren, Mengye</dc:creator>
 <dc:creator>Zeng, Wenyuan</dc:creator>
 <dc:creator>Liang, Ming</dc:creator>
 <dc:creator>Yang, Bin</dc:creator>
 <dc:creator>Urtasun, Raquel</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In this paper, we propose an end-to-end self-driving network featuring a
sparse attention module that learns to automatically attend to important
regions of the input. The attention module specifically targets motion
planning, whereas prior literature only applied attention in perception tasks.
Learning an attention mask directly targeted for motion planning significantly
improves the planner safety by performing more focused computation.
Furthermore, visualizing the attention improves interpretability of end-to-end
self-driving.
</dc:description>
 <dc:description>Comment: ICRA 2021</dc:description>
 <dc:date>2020-11-02</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.01153</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.01404</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faraway-Frustum: Dealing with Lidar Sparsity for 3D Object Detection
  using Fusion</dc:title>
 <dc:creator>Zhang, Haolin</dc:creator>
 <dc:creator>Yang, Dongfang</dc:creator>
 <dc:creator>Yurtsever, Ekim</dc:creator>
 <dc:creator>Redmill, Keith A.</dc:creator>
 <dc:creator>&#xd6;zg&#xfc;ner, &#xdc;mit</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Learned pointcloud representations do not generalize well with an increase in
distance to the sensor. For example, at a range greater than 60 meters, the
sparsity of lidar pointclouds reaches to a point where even humans cannot
discern object shapes from each other. However, this distance should not be
considered very far for fast-moving vehicles: A vehicle can traverse 60 meters
under two seconds while moving at 70 mph. For safe and robust driving
automation, acute 3D object detection at these ranges is indispensable. Against
this backdrop, we introduce faraway-frustum: a novel fusion strategy for
detecting faraway objects. The main strategy is to depend solely on the 2D
vision for recognizing object class, as object shape does not change
drastically with an increase in depth, and use pointcloud data for object
localization in the 3D space for faraway objects. For closer objects, we use
learned pointcloud representations instead, following state-of-the-art. This
strategy alleviates the main shortcoming of object detection with learned
pointcloud representations. Experiments on the KITTI dataset demonstrate that
our method outperforms state-of-the-art by a considerable margin for faraway
object detection in bird's-eye-view and 3D. Our code is open-source and
publicly available: https://github.com/dongfang-steven-yang/faraway-frustum.
</dc:description>
 <dc:date>2020-11-02</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.01404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.01483</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design Paradigms Based on Spring Agonists for Underactuated Robot Hands:
  Concepts and Application</dc:title>
 <dc:creator>Chen, Tianjian</dc:creator>
 <dc:creator>Zhang, Tianyi</dc:creator>
 <dc:creator>Ciocarlie, Matei</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper, we focus on a rarely used paradigm in the design of
underactuated robot hands: the use of springs as agonists and tendons as
antagonists. We formalize this approach in a design matrix also considering its
interplay with the underactuation method used (one tendon for multiple joints
vs. multiple tendons on one motor shaft). We then show how different cells in
this design matrix can be combined in order to facilitate the implementation of
desired postural synergies with a single motor. Furthermore, we show that when
agonist and antagonist tendons are combined on the same motor shaft, the
resulting spring force cancellation can be leveraged to produce multiple
desirable behaviors, which we demonstrate in a physical prototype.
</dc:description>
 <dc:description>Comment: Published in the International Conference on Robotics and Automation
  (ICRA) 2021</dc:description>
 <dc:date>2020-11-03</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.01483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.01573</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Laser-based Dual-arm System for Precise Control of Collaborative
  Robots</dc:title>
 <dc:creator>Silv&#xe9;rio, Jo&#xe3;o</dc:creator>
 <dc:creator>Clivaz, Guillaume</dc:creator>
 <dc:creator>Calinon, Sylvain</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Collaborative robots offer increased interaction capabilities at relatively
low cost but in contrast to their industrial counterparts they inevitably lack
precision. Moreover, in addition to the robots' own imperfect models,
day-to-day operations entail various sources of errors that despite being small
rapidly accumulate. This happens as tasks change and robots are re-programmed,
often requiring time-consuming calibrations. These aspects strongly limit the
application of collaborative robots in tasks demanding high precision (e.g.
watch-making). We address this problem by relying on a dual-arm system with
laser-based sensing to measure relative poses between objects of interest and
compensate for pose errors coming from robot proprioception. Our approach
leverages previous knowledge of object 3D models in combination with point
cloud registration to efficiently extract relevant poses and compute corrective
trajectories. This results in high-precision assembly behaviors. The approach
is validated in a needle threading experiment, with a 150{\mu}m thread and a
300{\mu}m hole, and a USB insertion task using two 7-axis Panda robots.
</dc:description>
 <dc:date>2020-11-03</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.01573</dc:identifier>
 <dc:identifier>IEEE International Conference on Robotics and Automation (ICRA)
  2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.01613</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Universal Gating Network for Mixtures of Experts</dc:title>
 <dc:creator>Kang, Chen Wen</dc:creator>
 <dc:creator>Hong, Chua Meng</dc:creator>
 <dc:creator>Maul, Tomas</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The combination and aggregation of knowledge from multiple neural networks
can be commonly seen in the form of mixtures of experts. However, such
combinations are usually done using networks trained on the same tasks, with
little mention of the combination of heterogeneous pre-trained networks,
especially in the data-free regime. This paper proposes multiple data-free
methods for the combination of heterogeneous neural networks, ranging from the
utilization of simple output logit statistics, to training specialized gating
networks. The gating networks decide whether specific inputs belong to specific
networks based on the nature of the expert activations generated. The
experiments revealed that the gating networks, including the universal gating
approach, constituted the most accurate approach, and therefore represent a
pragmatic step towards applications with heterogeneous mixtures of experts in a
data-free regime. The code for this project is hosted on github at
https://github.com/cwkang1998/network-merging.
</dc:description>
 <dc:description>Comment: Appl Intell (2021)</dc:description>
 <dc:date>2020-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.01613</dc:identifier>
 <dc:identifier>doi:10.1007/s10489-021-02301-w</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.01689</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved unsupervised physics-informed deep learning for intravoxel
  incoherent motion modeling and evaluation in pancreatic cancer patients</dc:title>
 <dc:creator>Kaandorp, Misha P. T.</dc:creator>
 <dc:creator>Barbieri, Sebastiano</dc:creator>
 <dc:creator>Klaassen, Remy</dc:creator>
 <dc:creator>van Laarhoven, Hanneke W. M.</dc:creator>
 <dc:creator>Crezee, Hans</dc:creator>
 <dc:creator>While, Peter T.</dc:creator>
 <dc:creator>Nederveen, Aart J.</dc:creator>
 <dc:creator>Gurney-Champion, Oliver J.</dc:creator>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  ${\bf Purpose}$: Earlier work showed that IVIM-NET$_{orig}$, an unsupervised
physics-informed deep neural network, was more accurate than other
state-of-the-art intravoxel-incoherent motion (IVIM) fitting approaches to DWI.
This study presents an improved version: IVIM-NET$_{optim}$, and characterizes
its superior performance in pancreatic ductal adenocarcinoma (PDAC) patients.
${\bf Method}$: In simulations (SNR=20), the accuracy, independence and
consistency of IVIM-NET were evaluated for combinations of hyperparameters (fit
S0, constraints, network architecture, # hidden layers, dropout, batch
normalization, learning rate), by calculating the NRMSE, Spearman's $\rho$, and
the coefficient of variation (CV$_{NET}$), respectively. The best performing
network, IVIM-NET$_{optim}$ was compared to least squares (LS) and a Bayesian
approach at different SNRs. IVIM-NET$_{optim}$'s performance was evaluated in
23 PDAC patients. 14 of the patients received no treatment between scan
sessions and 9 received chemoradiotherapy between sessions. Intersession
within-subject standard deviations (wSD) and treatment-induced changes were
assessed. ${\bf Results}$: In simulations, IVIM-NET$_{optim}$ outperformed
IVIM-NET$_{orig}$ in accuracy (NRMSE(D)=0.18 vs 0.20; NMRSE(f)=0.22 vs 0.27;
NMRSE(D*)=0.39 vs 0.39), independence ($\rho$(D*,f)=0.22 vs 0.74) and
consistency (CV$_{NET}$ (D)=0.01 vs 0.10; CV$_{NET}$ (f)=0.02 vs 0.05;
CV$_{NET}$ (D*)=0.04 vs 0.11). IVIM-NET$_{optim}$ showed superior performance
to the LS and Bayesian approaches at SNRs&lt;50. In vivo, IVIM-NET$_{optim}$
sshowed significantly less noisy parameter maps with lower wSD for D and f than
the alternatives. In the treated cohort, IVIM-NET$_{optim}$ detected the most
individual patients with significant parameter changes compared to day-to-day
variations. ${\bf Conclusion}$: IVIM-NET$_{optim}$ is recommended for IVIM
fitting to DWI data.
</dc:description>
 <dc:date>2020-11-03</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.01689</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.01758</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Representation Matters: Improving Perception and Exploration for
  Robotics</dc:title>
 <dc:creator>Wulfmeier, Markus</dc:creator>
 <dc:creator>Byravan, Arunkumar</dc:creator>
 <dc:creator>Hertweck, Tim</dc:creator>
 <dc:creator>Higgins, Irina</dc:creator>
 <dc:creator>Gupta, Ankush</dc:creator>
 <dc:creator>Kulkarni, Tejas</dc:creator>
 <dc:creator>Reynolds, Malcolm</dc:creator>
 <dc:creator>Teplyashin, Denis</dc:creator>
 <dc:creator>Hafner, Roland</dc:creator>
 <dc:creator>Lampe, Thomas</dc:creator>
 <dc:creator>Riedmiller, Martin</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Projecting high-dimensional environment observations into lower-dimensional
structured representations can considerably improve data-efficiency for
reinforcement learning in domains with limited data such as robotics. Can a
single generally useful representation be found? In order to answer this
question, it is important to understand how the representation will be used by
the agent and what properties such a 'good' representation should have. In this
paper we systematically evaluate a number of common learnt and hand-engineered
representations in the context of three robotics tasks: lifting, stacking and
pushing of 3D blocks. The representations are evaluated in two use-cases: as
input to the agent, or as a source of auxiliary tasks. Furthermore, the value
of each representation is evaluated in terms of three properties:
dimensionality, observability and disentanglement. We can significantly improve
performance in both use-cases and demonstrate that some representations can
perform commensurate to simulator states as agent inputs. Finally, our results
challenge common intuitions by demonstrating that: 1) dimensionality strongly
matters for task generation, but is negligible for inputs, 2) observability of
task-relevant aspects mostly affects the input representation use-case, and 3)
disentanglement leads to better auxiliary tasks, but has only limited benefits
for input representations. This work serves as a step towards a more systematic
understanding of what makes a 'good' representation for control in robotics,
enabling practitioners to make more informed choices for developing new learned
or hand-engineered representations.
</dc:description>
 <dc:description>Comment: Published at ICRA 2021</dc:description>
 <dc:date>2020-11-03</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.01758</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.01809</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kinodynamic Motion Planning for Multi-Legged Robot Jumping via
  Mixed-Integer Convex Program</dc:title>
 <dc:creator>Ding, Yanran</dc:creator>
 <dc:creator>Li, Chuanzheng</dc:creator>
 <dc:creator>Park, Hae-Won</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper proposes a kinodynamic motion planning framework for multi-legged
robot jumping based on the mixed-integer convex program (MICP), which
simultaneously reasons about centroidal motion, contact points, wrench, and
gait sequences. This method uniquely combines configuration space
discretization and the construction of feasible wrench polytope (FWP) to encode
kinematic constraints, actuator limit, friction cone constraint, and gait
sequencing into a single MICP. The MICP could be efficiently solved to the
global optimum by off-the-shelf numerical solvers and provide highly dynamic
jumping motions without requiring initial guesses. Simulation and experimental
results demonstrate that the proposed method could find novel and dexterous
maneuvers that are directly deployable on the two-legged robot platform to
traverse through challenging terrains.
</dc:description>
 <dc:date>2020-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.01809</dc:identifier>
 <dc:identifier>2020 International Conference on Intelligent Robots and Systems
  (IROS), pp. 3998-4005, IEEE</dc:identifier>
 <dc:identifier>doi:10.1109/IROS45743.2020.9341572</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.01834</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement Learning for Test Case Prioritization</dc:title>
 <dc:creator>Bagherzadeh, Mojtaba</dc:creator>
 <dc:creator>Kahani, Nafiseh</dc:creator>
 <dc:creator>Briand, Lionel</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Continuous Integration (CI) significantly reduces integration problems,
speeds up development time, and shortens release time. However, it also
introduces new challenges for quality assurance activities, including
regression testing, which is the focus of this work. Though various approaches
for test case prioritization have shown to be very promising in the context of
regression testing, specific techniques must be designed to deal with the
dynamic nature and timing constraints of CI.
  Recently, Reinforcement Learning (RL) has shown great potential in various
challenging scenarios that require continuous adaptation, such as game playing,
real-time ads bidding, and recommender systems. Inspired by this line of work
and building on initial efforts in supporting test case prioritization with RL
techniques, we perform here a comprehensive investigation of RL-based test case
prioritization in a CI context. To this end, taking test case prioritization as
a ranking problem, we model the sequential interactions between the CI
environment and a test case prioritization agent as an RL problem, using three
alternative ranking models. We then rely on carefully selected and tailored
state-of-the-art RL techniques to automatically and continuously learn a test
case prioritization strategy, whose objective is to be as close as possible to
the optimal one. Our extensive experimental analysis shows that the best RL
solutions provide a significant accuracy improvement over previous RL-based
work, with prioritization strategies getting close to being optimal, thus
paving the way for using RL to prioritize test cases in a CI context.
</dc:description>
 <dc:date>2020-11-03</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.01834</dc:identifier>
 <dc:identifier>IEEE Transactions on Software Engineering (TSE). (2021) 1-21</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.01868</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonlinear Two-Time-Scale Stochastic Approximation: Convergence and
  Finite-Time Performance</dc:title>
 <dc:creator>Doan, Thinh T.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Two-time-scale stochastic approximation, a generalized version of the popular
stochastic approximation, has found broad applications in many areas including
stochastic control, optimization, and machine learning. Despite its popularity,
theoretical guarantees of this method, especially its finite-time performance,
are mostly achieved for the linear case while the results for the nonlinear
counterpart are very sparse. Motivated by the classic control theory for
singularly perturbed systems, we study in this paper the asymptotic convergence
and finite-time analysis of the nonlinear two-time-scale stochastic
approximation. Under some fairly standard assumptions, we provide a formula
that characterizes the rate of convergence of the main iterates to the desired
solutions. In particular, we show that the method achieves a convergence in
expectation at a rate $\mathcal{O}(1/k^{2/3})$, where $k$ is the number of
iterations. The key idea in our analysis is to properly choose the two step
sizes to characterize the coupling between the fast and slow-time-scale
iterates.
</dc:description>
 <dc:date>2020-11-03</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.01868</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.01882</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Planning Against Stealthy Attacks via Model-Free Reinforcement
  Learning</dc:title>
 <dc:creator>Bozkurt, Alper Kamil</dc:creator>
 <dc:creator>Wang, Yu</dc:creator>
 <dc:creator>Pajic, Miroslav</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We consider the problem of security-aware planning in an unknown stochastic
environment, in the presence of attacks on control signals (i.e., actuators) of
the robot. We model the attacker as an agent who has the full knowledge of the
controller as well as the employed intrusion-detection system and who wants to
prevent the controller from performing tasks while staying stealthy. We
formulate the problem as a stochastic game between the attacker and the
controller and present an approach to express the objective of such an agent
and the controller as a combined linear temporal logic (LTL) formula. We then
show that the planning problem, described formally as the problem of satisfying
an LTL formula in a stochastic game, can be solved via model-free reinforcement
learning when the environment is completely unknown. Finally, we illustrate and
evaluate our methods on two robotic planning case studies.
</dc:description>
 <dc:date>2020-11-03</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.01882</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.02030</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PyLightcurve-torch: a transit modelling package for deep learning
  applications in PyTorch</dc:title>
 <dc:creator>Morvan, Mario</dc:creator>
 <dc:creator>Tsiaras, Angelos</dc:creator>
 <dc:creator>Nikolaou, Nikolaos</dc:creator>
 <dc:creator>Waldmann, Ingo P.</dc:creator>
 <dc:subject>Astrophysics - Earth and Planetary Astrophysics</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  We present a new open source python package, based on PyLightcurve and
PyTorch, tailored for efficient computation and automatic differentiation of
exoplanetary transits. The classes and functions implemented are fully
vectorised, natively GPU-compatible and differentiable with respect to the
stellar and planetary parameters. This makes PyLightcurve-torch suitable for
traditional forward computation of transits, but also extends the range of
possible applications with inference and optimisation algorithms requiring
access to the gradients of the physical model. This endeavour is aimed at
fostering the use of deep learning in exoplanets research, motivated by an ever
increasing amount of stellar light curves data and various incentives for the
improvement of detection and characterisation techniques.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures; submission status updated, fig 2 caption added</dc:description>
 <dc:date>2020-11-03</dc:date>
 <dc:date>2020-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.02030</dc:identifier>
 <dc:identifier>doi:10.1088/1538-3873/abe6e8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.02092</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Soft Robot Optimal Control Via Reduced Order Finite Element Models</dc:title>
 <dc:creator>Tonkens, Sander</dc:creator>
 <dc:creator>Lorenzetti, Joseph</dc:creator>
 <dc:creator>Pavone, Marco</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Finite element methods have been successfully used to develop physics-based
models of soft robots that capture the nonlinear dynamic behavior induced by
continuous deformation. These high-fidelity models are therefore ideal for
designing controllers for complex dynamic tasks such as trajectory optimization
and trajectory tracking. However, finite element models are also typically very
high-dimensional, which makes real-time control challenging. In this work we
propose an approach for finite element model-based control of soft robots that
leverages model order reduction techniques to significantly increase
computational efficiency. In particular, a constrained optimal control problem
is formulated based on a nonlinear reduced order finite element model and is
solved via sequential convex programming. This approach is demonstrated through
simulation of a cable-driven soft robot for a constrained trajectory tracking
task, where a 9768-dimensional finite element model is used for controller
design.
</dc:description>
 <dc:description>Comment: To appear at the IEEE International Conference on Robotics and
  Automation (ICRA) 2021, Xi'An, China</dc:description>
 <dc:date>2020-11-03</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.02092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.02160</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Augmentation for End-to-end Code-switching Speech Recognition</dc:title>
 <dc:creator>Du, Chenpeng</dc:creator>
 <dc:creator>Li, Hao</dc:creator>
 <dc:creator>Lu, Yizhou</dc:creator>
 <dc:creator>Wang, Lan</dc:creator>
 <dc:creator>Qian, Yanmin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Training a code-switching end-to-end automatic speech recognition (ASR) model
normally requires a large amount of data, while code-switching data is often
limited. In this paper, three novel approaches are proposed for code-switching
data augmentation. Specifically, they are audio splicing with the existing
code-switching data, and TTS with new code-switching texts generated by word
translation or word insertion. Our experiments on 200 hours Mandarin-English
code-switching dataset show that all the three proposed approaches yield
significant improvements on code-switching ASR individually. Moreover, all the
proposed approaches can be combined with recent popular SpecAugment, and an
addition gain can be obtained. WER is significantly reduced by relative 24.0%
compared to the system without any data augmentation, and still relative 13.0%
gain compared to the system with only SpecAugment
</dc:description>
 <dc:description>Comment: Accepted by SLT2021</dc:description>
 <dc:date>2020-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.02160</dc:identifier>
 <dc:identifier>2021 IEEE Spoken Language Technology Workshop (SLT)</dc:identifier>
 <dc:identifier>doi:10.1109/slt48900.2021.9383620</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.02235</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Supporting the Detection of Software Supply Chain Attacks through
  Unsupervised Signature Generation</dc:title>
 <dc:creator>Ohm, Marc</dc:creator>
 <dc:creator>Kempf, Lukas</dc:creator>
 <dc:creator>Boes, Felix</dc:creator>
 <dc:creator>Meier, Michael</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Trojanized software packages used in software supply chain attacks constitute
an emerging threat. Unfortunately, there is still a lack of scalable approaches
that allow automated and timely detection of malicious software packages and
thus most detections are based on manual labor and expertise. However, it has
been observed that most attack campaigns comprise multiple packages that share
the same or similar malicious code. We leverage that fact to automatically
reproduce manually identified clusters of known malicious packages that have
been used in real world attacks, thus, reducing the need for expert knowledge
and manual inspection. Our approach, AST Clustering using MCL to mimic
Expertise (ACME), yields promising results with a $F_{1}$ score of 0.99.
Signatures are automatically generated based on characteristic code fragments
from clusters and are subsequently used to scan the whole npm registry for
unreported malicious packages. We are able to identify and report six malicious
packages that have been removed from npm consequentially. Therefore, our
approach can support analysts by reducing manual labor and hence may be
employed to timely detect possible software supply chain attacks.
</dc:description>
 <dc:date>2020-11-04</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.02235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.02258</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Concentration Inequalities for Statistical Inference</dc:title>
 <dc:creator>Zhang, Huiming</dc:creator>
 <dc:creator>Chen, Song Xi</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>60F10, 60G50, 62E17</dc:subject>
 <dc:description>  This paper gives a review of concentration inequalities which are widely
employed in non-asymptotical analyses of mathematical statistics in a wide
range of settings, from distribution-free to distribution-dependent, from
sub-Gaussian to sub-exponential, sub-Gamma, and sub-Weibull random variables,
and from the mean to the maximum concentration. This review provides results in
these settings with some fresh new results. Given the increasing popularity of
high-dimensional data and inference, results in the context of high-dimensional
linear and Poisson regressions are also provided. We aim to illustrate the
concentration inequalities with known constants and to improve existing bounds
with sharper constants.
</dc:description>
 <dc:description>Comment: Invited review article on constants-specified concentration
  inequalities published in Communications in Mathematical Research</dc:description>
 <dc:date>2020-11-04</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.02258</dc:identifier>
 <dc:identifier>Communications in Mathematical Research. 37(1), 1-85 (2021)</dc:identifier>
 <dc:identifier>doi:10.4208/cmr.2020-0041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.02404</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamics Randomization Revisited:A Case Study for Quadrupedal Locomotion</dc:title>
 <dc:creator>Xie, Zhaoming</dc:creator>
 <dc:creator>Da, Xingye</dc:creator>
 <dc:creator>van de Panne, Michiel</dc:creator>
 <dc:creator>Babich, Buck</dc:creator>
 <dc:creator>Garg, Animesh</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Understanding the gap between simulation and reality is critical for
reinforcement learning with legged robots, which are largely trained in
simulation. However, recent work has resulted in sometimes conflicting
conclusions with regard to which factors are important for success, including
the role of dynamics randomization. In this paper, we aim to provide clarity
and understanding on the role of dynamics randomization in learning robust
locomotion policies for the Laikago quadruped robot. Surprisingly, in contrast
to prior work with the same robot model, we find that direct sim-to-real
transfer is possible without dynamics randomization or on-robot adaptation
schemes. We conduct extensive ablation studies in a sim-to-sim setting to
understand the key issues underlying successful policy transfer, including
other design decisions that can impact policy robustness. We further ground our
conclusions via sim-to-real experiments with various gaits, speeds, and
stepping frequencies. Additional Details:
https://www.pair.toronto.edu/understanding-dr/.
</dc:description>
 <dc:date>2020-11-04</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.02404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.02538</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Direction Matters: On the Implicit Bias of Stochastic Gradient Descent
  with Moderate Learning Rate</dc:title>
 <dc:creator>Wu, Jingfeng</dc:creator>
 <dc:creator>Zou, Difan</dc:creator>
 <dc:creator>Braverman, Vladimir</dc:creator>
 <dc:creator>Gu, Quanquan</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Understanding the algorithmic bias of \emph{stochastic gradient descent}
(SGD) is one of the key challenges in modern machine learning and deep learning
theory. Most of the existing works, however, focus on \emph{very small or even
infinitesimal} learning rate regime, and fail to cover practical scenarios
where the learning rate is \emph{moderate and annealing}. In this paper, we
make an initial attempt to characterize the particular regularization effect of
SGD in the moderate learning rate regime by studying its behavior for
optimizing an overparameterized linear regression problem. In this case, SGD
and GD are known to converge to the unique minimum-norm solution; however, with
the moderate and annealing learning rate, we show that they exhibit different
\emph{directional bias}: SGD converges along the large eigenvalue directions of
the data matrix, while GD goes after the small eigenvalue directions.
Furthermore, we show that such directional bias does matter when early stopping
is adopted, where the SGD output is nearly optimal but the GD output is
suboptimal. Finally, our theory explains several folk arts in practice used for
SGD hyperparameter tuning, such as (1) linearly scaling the initial learning
rate with batch size; and (2) overrunning SGD with high learning rate even when
the loss stops decreasing.
</dc:description>
 <dc:description>Comment: ICLR 2021 Camera Ready</dc:description>
 <dc:date>2020-11-04</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.02538</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.02578</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning and Evaluating Representations for Deep One-class
  Classification</dc:title>
 <dc:creator>Sohn, Kihyuk</dc:creator>
 <dc:creator>Li, Chun-Liang</dc:creator>
 <dc:creator>Yoon, Jinsung</dc:creator>
 <dc:creator>Jin, Minho</dc:creator>
 <dc:creator>Pfister, Tomas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a two-stage framework for deep one-class classification. We first
learn self-supervised representations from one-class data, and then build
one-class classifiers on learned representations. The framework not only allows
to learn better representations, but also permits building one-class
classifiers that are faithful to the target task. We argue that classifiers
inspired by the statistical perspective in generative or discriminative models
are more effective than existing approaches, such as a normality score from a
surrogate classifier. We thoroughly evaluate different self-supervised
representation learning algorithms under the proposed framework for one-class
classification. Moreover, we present a novel distribution-augmented contrastive
learning that extends training distributions via data augmentation to obstruct
the uniformity of contrastive representations. In experiments, we demonstrate
state-of-the-art performance on visual domain one-class classification
benchmarks, including novelty and anomaly detection. Finally, we present visual
explanations, confirming that the decision-making process of deep one-class
classifiers is intuitive to humans. The code is available at
https://github.com/google-research/deep_representation_one_class.
</dc:description>
 <dc:description>Comment: Published at International Conference on Learning Representation
  (ICLR) 2021. The first two authors contributed equally</dc:description>
 <dc:date>2020-11-04</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.02578</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.02604</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Post Hoc Context for Faster Learning in Bandit Settings with
  Applications in Robot-Assisted Feeding</dc:title>
 <dc:creator>Gordon, Ethan K.</dc:creator>
 <dc:creator>Roychowdhury, Sumegh</dc:creator>
 <dc:creator>Bhattacharjee, Tapomayukh</dc:creator>
 <dc:creator>Jamieson, Kevin</dc:creator>
 <dc:creator>Srinivasa, Siddhartha S.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Autonomous robot-assisted feeding requires the ability to acquire a wide
variety of food items. However, it is impossible for such a system to be
trained on all types of food in existence. Therefore, a key challenge is
choosing a manipulation strategy for a previously unseen food item. Previous
work showed that the problem can be represented as a linear bandit with visual
context. However, food has a wide variety of multi-modal properties relevant to
manipulation that can be hard to distinguish visually. Our key insight is that
we can leverage the haptic context we collect during and after manipulation
(i.e., &quot;post hoc&quot;) to learn some of these properties and more quickly adapt our
visual model to previously unseen food. In general, we propose a modified
linear contextual bandit framework augmented with post hoc context observed
after action selection to empirically increase learning speed and reduce
cumulative regret. Experiments on synthetic data demonstrate that this effect
is more pronounced when the dimensionality of the context is large relative to
the post hoc context or when the post hoc context model is particularly easy to
learn. Finally, we apply this framework to the bite acquisition problem and
demonstrate the acquisition of 8 previously unseen types of food with 21% fewer
failures across 64 attempts.
</dc:description>
 <dc:description>Comment: 6 pages + references, 5 figures, to appear in ICRA 2021</dc:description>
 <dc:date>2020-11-04</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.02604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.02749</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Straggler Mitigation through Unequal Error Protection for Distributed
  Matrix Multiplication</dc:title>
 <dc:creator>Tegin, Busra</dc:creator>
 <dc:creator>Hernandez, Eduin E.</dc:creator>
 <dc:creator>Rini, Stefano</dc:creator>
 <dc:creator>Duman, Tolga M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Large-scale machine learning and data mining methods routinely distribute
computations across multiple agents to parallelize processing. The time
required for computation at the agents is affected by the availability of local
resources giving rise to the &quot;straggler problem&quot; in which the computation
results are held back by unresponsive agents. For this problem, linear coding
of the matrix sub-blocks can be used to introduce resilience toward straggling.
The Parameter Server (PS) utilizes a channel code and distributes the matrices
to the workers for multiplication. It then produces an approximation to the
desired matrix multiplication using the results of the computations received at
a given deadline. In this paper, we propose to employ Unequal Error Protection
(UEP) codes to alleviate the straggler problem. The resiliency level of each
sub-block is chosen according to its norm as blocks with larger norms have
higher effects on the result of the matrix multiplication. We validate the
effectiveness of our scheme both theoretically and through numerical
evaluations. We derive a theoretical characterization of the performance of UEP
using random linear codes, and compare it the case of equal error protection.
We also apply the proposed coding strategy to the computation of the
back-propagation step in the training of a Deep Neural Network (DNN), for which
we investigate the fundamental trade-off between precision and the time
required for the computations.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures</dc:description>
 <dc:date>2020-11-05</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.02749</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.02827</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Weighted Least Squares Estimator Based on ADMM</dc:title>
 <dc:creator>Liu, Shun</dc:creator>
 <dc:creator>Li, Zhifei</dc:creator>
 <dc:creator>Zhang, Weifang</dc:creator>
 <dc:creator>Liang, Yan</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Wireless sensor network has recently received much attention due to its broad
applicability and ease-of-installation. This paper is concerned with a
distributed state estimation problem, where all sensor nodes are required to
achieve a consensus estimation. The weighted least squares (WLS) estimator is
an appealing way to handle this problem since it does not need any prior
distribution information. To this end, we first exploit the equivalent relation
between the information filter and WLS estimator. Then, we establish an
optimization problem under the relation coupled with a consensus constraint.
Finally, the consensus-based distributed WLS problem is tackled by the
alternating direction method of multiplier (ADMM). Numerical simulation
together with theoretical analysis testify the convergence and consensus
estimations between nodes.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures, The manuscript has been submitted to 17th
  International Wireless Communications &amp; Mobile Computing Conference - IWCMC
  2021</dc:description>
 <dc:date>2020-11-05</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.02827</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.03139</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ellipse Loss for Scene-Compliant Motion Prediction</dc:title>
 <dc:creator>Cui, Henggang</dc:creator>
 <dc:creator>Shajari, Hoda</dc:creator>
 <dc:creator>Yalamanchi, Sai</dc:creator>
 <dc:creator>Djuric, Nemanja</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Motion prediction is a critical part of self-driving technology, responsible
for inferring future behavior of traffic actors in autonomous vehicle's
surroundings. In order to ensure safe and efficient operations, prediction
models need to output accurate trajectories that obey the map constraints. In
this paper, we address this task and propose a novel ellipse loss that allows
the models to better reason about scene compliance and predict more realistic
trajectories. Ellipse loss penalizes off-road predictions directly in a
supervised manner, by projecting the output trajectories into the top-down map
frame using a differentiable trajectory rasterizer module. Moreover, it takes
into account actor dimensions and orientation, providing more direct training
signals to the model. We applied ellipse loss to a recently proposed
state-of-the-art joint detection-prediction model to showcase its benefits.
Evaluation on large-scale autonomous driving data strongly indicates that the
method allows for more accurate and more realistic trajectory predictions.
</dc:description>
 <dc:description>Comment: Henggang Cui and Hoda Shajari contributed equally to this work.
  Accepted for publication at IEEE International Conference on Robotics and
  Automation (ICRA) 2021</dc:description>
 <dc:date>2020-11-05</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.03139</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.03142</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contact Localization for Robot Arms in Motion without Torque Sensing</dc:title>
 <dc:creator>Liang, Jacky</dc:creator>
 <dc:creator>Kroemer, Oliver</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Detecting and localizing contacts is essential for robot manipulators to
perform contact-rich tasks in unstructured environments. While robot skins can
localize contacts on the surface of robot arms, these sensors are not yet
robust or easily accessible. As such, prior works have explored using
proprioceptive observations, such as joint velocities and torques, to perform
contact localization. Many past approaches assume the robot is static during
contact incident, a single contact is made at a time, or having access to
accurate dynamics models and joint torque sensing. In this work, we relax these
assumptions and propose using Domain Randomization to train a neural network to
localize contacts of robot arms in motion without joint torque observations.
Our method uses a novel cylindrical projection encoding of the robot arm
surface, which allows the network to use convolution layers to process input
features and transposed convolution layers to predict contacts. The trained
network achieves a contact detection accuracy of 91.5% and a mean contact
localization error of 3.0cm. We further demonstrate an application of the
contact localization model in an obstacle mapping task, evaluated in both
simulation and the real world.
</dc:description>
 <dc:description>Comment: International Conference on Robotics and Automation (ICRA). May 2021</dc:description>
 <dc:date>2020-11-05</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.03142</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.03659</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ROBIN: a Graph-Theoretic Approach to Reject Outliers in Robust
  Estimation using Invariants</dc:title>
 <dc:creator>Shi, Jingnan</dc:creator>
 <dc:creator>Yang, Heng</dc:creator>
 <dc:creator>Carlone, Luca</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Many estimation problems in robotics, computer vision, and learning require
estimating unknown quantities in the face of outliers. Outliers are typically
the result of incorrect data association or feature matching, and it is common
to have problems where more than 90% of the measurements used for estimation
are outliers. While current approaches for robust estimation are able to deal
with moderate amounts of outliers, they fail to produce accurate estimates in
the presence of many outliers. This paper develops an approach to prune
outliers. First, we develop a theory of invariance that allows us to quickly
check if a subset of measurements are mutually compatible without explicitly
solving the estimation problem. Second, we develop a graph-theoretic framework,
where measurements are modeled as vertices and mutual compatibility is captured
by edges. We generalize existing results showing that the inliers form a clique
in this graph and typically belong to the maximum clique. We also show that in
practice the maximum k-core of the compatibility graph provides an
approximation of the maximum clique, while being faster to compute in large
problems. These two contributions leads to ROBIN, our approach to Reject
Outliers Based on INvariants, which allows us to quickly prune outliers in
generic estimation problems. We demonstrate ROBIN in four geometric perception
problems and show it boosts robustness of existing solvers while running in
milliseconds in large problems.
</dc:description>
 <dc:date>2020-11-06</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.03659</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.03981</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning-based 3D Occupancy Prediction for Autonomous Navigation in
  Occluded Environments</dc:title>
 <dc:creator>Wang, Lizi</dc:creator>
 <dc:creator>Ye, Hongkai</dc:creator>
 <dc:creator>Wang, Qianhao</dc:creator>
 <dc:creator>Gao, Yuman</dc:creator>
 <dc:creator>Xu, Chao</dc:creator>
 <dc:creator>Gao, Fei</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In autonomous navigation of mobile robots, sensors suffer from massive
occlusion in cluttered environments, leaving significant amount of space
unknown during planning. In practice, treating the unknown space in optimistic
or pessimistic ways both set limitations on planning performance, thus
aggressiveness and safety cannot be satisfied at the same time. However, humans
can infer the exact shape of the obstacles from only partial observation and
generate non-conservative trajectories that avoid possible collisions in
occluded space. Mimicking human behavior, in this paper, we propose a method
based on deep neural network to predict occupancy distribution of unknown space
reliably. Specifically, the proposed method utilizes contextual information of
environments and learns from prior knowledge to predict obstacle distributions
in occluded space. We use unlabeled and no-ground-truth data to train our
network and successfully apply it to real-time navigation in unseen
environments without any refinement. Results show that our method leverages the
performance of a kinodynamic planner by improving security with no reduction of
speed in clustered environments.
</dc:description>
 <dc:date>2020-11-08</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.03981</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.03988</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online power system parameter estimation and optimal operation</dc:title>
 <dc:creator>Du, Xu</dc:creator>
 <dc:creator>Engelmann, Alexander</dc:creator>
 <dc:creator>Faulwasser, Timm</dc:creator>
 <dc:creator>Houska, Boris</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  The integration of renewables into electrical grids calls for
optimization-based control schemes requiring reliable grid models. Classically,
parameter estimation and optimization-based control is often decoupled, which
leads to high system operation cost in the estimation procedure. The present
work proposes a method for simultaneously minimizing grid operation cost and
optimally estimating line parameters based on methods for the optimal design of
experiments. This method leads to a substantial reduction in cost for optimal
estimation and in higher accuracy in the parameters compared with standard
Optimal Power Flow and maximum-likelihood estimation. We illustrate the
performance of the proposed method on a benchmark system.
</dc:description>
 <dc:date>2020-11-08</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.03988</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.03991</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The NederDrone: A hybrid lift, hybrid energy hydrogen UAV</dc:title>
 <dc:creator>De Wagter, Christophe</dc:creator>
 <dc:creator>Remes, Bart</dc:creator>
 <dc:creator>Smeur, Ewoud</dc:creator>
 <dc:creator>van Tienen, Freek</dc:creator>
 <dc:creator>Ruijsink, Rick</dc:creator>
 <dc:creator>van Hecke, Kevin</dc:creator>
 <dc:creator>van der Horst, Erik</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  A lot of UAV applications require vertical take-off and landing (VTOL)
combined with very long-range or endurance. Transitioning UAVs have been
proposed to combine the VTOL capabilities of helicopters with the efficient
long-range flight properties of fixed-wing aircraft. But energy is still a
bottleneck for many electric long endurance applications. While solar power
technology and battery technology have improved a lot, in rougher conditions
they still respectively lack the power or total amount of energy required for
many real-world situations. In this paper, we introduce the NederDrone, a
hybrid lift, hybrid energy hydrogen-powered UAV which can perform vertical
take-off and landings using 12 propellers while flying efficiently in forward
flight thanks to its fixed wings. The energy is supplied from a mix of
hydrogen-driven fuel-cells to store large amounts of energy and battery power
for high power situations. The hydrogen is stored in a pressurized cylinder
around which the UAV is optimized. This paper analyses the selection of the
concept, the implemented safety elements, the electronics and flight control
and shows flight data including a 3h38 flight at sea, starting and landing on a
small moving ship.
</dc:description>
 <dc:date>2020-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.03991</dc:identifier>
 <dc:identifier>doi:10.1016/j.ijhydene.2021.02.053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.04251</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement Learning for Autonomous Driving with Latent State
  Inference and Spatial-Temporal Relationships</dc:title>
 <dc:creator>Ma, Xiaobai</dc:creator>
 <dc:creator>Li, Jiachen</dc:creator>
 <dc:creator>Kochenderfer, Mykel J.</dc:creator>
 <dc:creator>Isele, David</dc:creator>
 <dc:creator>Fujimura, Kikuo</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Deep reinforcement learning (DRL) provides a promising way for learning
navigation in complex autonomous driving scenarios. However, identifying the
subtle cues that can indicate drastically different outcomes remains an open
problem with designing autonomous systems that operate in human environments.
In this work, we show that explicitly inferring the latent state and encoding
spatial-temporal relationships in a reinforcement learning framework can help
address this difficulty. We encode prior knowledge on the latent states of
other drivers through a framework that combines the reinforcement learner with
a supervised learner. In addition, we model the influence passing between
different vehicles through graph neural networks (GNNs). The proposed framework
significantly improves performance in the context of navigating T-intersections
compared with state-of-the-art baseline approaches.
</dc:description>
 <dc:description>Comment: ICRA 2021</dc:description>
 <dc:date>2020-11-09</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.04251</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.04654</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Assessing the Feasibility of Web-Request Prediction Models on Mobile
  Platforms</dc:title>
 <dc:creator>Zhao, Yixue</dc:creator>
 <dc:creator>Yin, Siwei</dc:creator>
 <dc:creator>Sejfia, Adriana</dc:creator>
 <dc:creator>Laser, Marcelo Schmitt</dc:creator>
 <dc:creator>Wang, Haoyu</dc:creator>
 <dc:creator>Medvidovic, Nenad</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Prefetching web pages is a well-studied solution to reduce network latency by
predicting users' future actions based on their past behaviors. However, such
techniques are largely unexplored on mobile platforms. Today's privacy
regulations make it infeasible to explore prefetching with the usual strategy
of amassing large amounts of data over long periods and constructing
conventional, &quot;large&quot; prediction models. Our work is based on the observation
that this may not be necessary: Given previously reported mobile-device usage
trends (e.g., repetitive behaviors in brief bursts), we hypothesized that
prefetching should work effectively with &quot;small&quot; models trained on mobile-user
requests collected during much shorter time periods. To test this hypothesis,
we constructed a framework for automatically assessing prediction models, and
used it to conduct an extensive empirical study based on over 15 million HTTP
requests collected from nearly 11,500 mobile users during a 24-hour period,
resulting in over 7 million models. Our results demonstrate the feasibility of
prefetching with small models on mobile platforms, directly motivating future
work in this area. We further introduce several strategies for improving
prediction models while reducing the model size. Finally, our framework
provides the foundation for future explorations of effective prediction models
across a range of usage scenarios.
</dc:description>
 <dc:description>Comment: MOBILESoft 2021</dc:description>
 <dc:date>2020-11-10</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.04654</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.04704</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Domain Semirings United</dc:title>
 <dc:creator>Fahrenberg, Uli</dc:creator>
 <dc:creator>Johansen, Christian</dc:creator>
 <dc:creator>Struth, Georg</dc:creator>
 <dc:creator>Ziemi&#xe1;nski, Krzysztof</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03B45, 06F0, 16Y60</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  Domain operations on semirings have been axiomatised in two different ways:
by a map from an additively idempotent semiring into a boolean subalgebra of
the semiring bounded by the additive and multiplicative unit of the semiring,
or by an endofunction on a semiring that induces a distributive lattice bounded
by the two units as its image. This note presents classes of semirings where
these approaches coincide.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2020-11-09</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.04704</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.04825</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Agent Active Search using Realistic Depth-Aware Noise Model</dc:title>
 <dc:creator>Ghods, Ramina</dc:creator>
 <dc:creator>Durkin, William J.</dc:creator>
 <dc:creator>Schneider, Jeff</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  The active search for objects of interest in an unknown environment has many
robotics applications including search and rescue, detecting gas leaks or
locating animal poachers. Existing algorithms often prioritize the location
accuracy of objects of interest while other practical issues such as the
reliability of object detection as a function of distance and lines of sight
remain largely ignored. Additionally, in many active search scenarios,
communication infrastructure may be unreliable or unestablished, making
centralized control of multiple agents impractical. We present an algorithm
called Noise-Aware Thompson Sampling (NATS) that addresses these issues for
multiple ground-based robots performing active search considering two sources
of sensory information from monocular optical imagery and depth maps. By
utilizing Thompson Sampling, NATS allows for decentralized coordination among
multiple agents. NATS also considers object detection uncertainty from depth as
well as environmental occlusions and operates while remaining agnostic of the
number of objects of interest. Using simulation results, we show that NATS
significantly outperforms existing methods such as information-greedy policies
or exhaustive search. We demonstrate the real-world viability of NATS using a
pseudo-realistic environment created in the Unreal Engine 4 game development
platform with the AirSim plugin.
</dc:description>
 <dc:description>Comment: To appear at the 2021 IEEE International Conference on Robotics and
  Automation (ICRA), extended version</dc:description>
 <dc:date>2020-11-09</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.04825</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.04828</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Efficient Constraint Graph Sampling for Robotic Sequential
  Manipulation</dc:title>
 <dc:creator>Ortiz-Haro, Joaquim</dc:creator>
 <dc:creator>Hartmann, Valentin N.</dc:creator>
 <dc:creator>Oguz, Ozgur S.</dc:creator>
 <dc:creator>Toussaint, Marc</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Efficient sampling from constraint manifolds, and thereby generating a
diverse set of solutions for feasibility problems, is a fundamental challenge.
We consider the case where a problem is factored, that is, the underlying
nonlinear program is decomposed into differentiable equality and inequality
constraints, each of which depends only on some variables. Such problems are at
the core of efficient and robust sequential robot manipulation planning. Naive
sequential conditional sampling of individual variables, as well as fully joint
sampling of all variables at once (e.g., leveraging optimization methods), can
be highly inefficient and non-robust. We propose a novel framework to learn how
to break the overall problem into smaller sequential sampling problems.
Specifically, we leverage Monte-Carlo Tree Search to learn assignment orders
for the variable-subsets, in order to minimize the computation time to generate
feasible full samples. This strategy allows us to efficiently compute a set of
diverse valid robot configurations for mode-switches within sequential
manipulation tasks, which are waypoints for subsequent trajectory optimization
or sampling-based motion planning algorithms. We show that the learning method
quickly converges to the best sampling strategy for a given problem, and
outperforms user-defined orderings or fully joint optimization, while providing
a higher sample diversity.
</dc:description>
 <dc:date>2020-11-09</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.04828</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.04840</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robots of the Lost Arc: Self-Supervised Learning to Dynamically
  Manipulate Fixed-Endpoint Cables</dc:title>
 <dc:creator>Zhang, Harry</dc:creator>
 <dc:creator>Ichnowski, Jeffrey</dc:creator>
 <dc:creator>Seita, Daniel</dc:creator>
 <dc:creator>Wang, Jonathan</dc:creator>
 <dc:creator>Huang, Huang</dc:creator>
 <dc:creator>Goldberg, Ken</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We explore how high-speed robot arm motions can dynamically manipulate cables
to vault over obstacles, knock objects from pedestals, and weave between
obstacles. In this paper, we propose a self-supervised learning framework that
enables a UR5 robot to perform these three tasks. The framework finds a 3D apex
point for the robot arm, which, together with a task-specific trajectory
function, defines an arcing motion that dynamically manipulates the cable to
perform tasks with varying obstacle and target locations. The trajectory
function computes minimum-jerk motions that are constrained to remain within
joint limits and to travel through the 3D apex point by repeatedly solving
quadratic programs to find the shortest and fastest feasible motion. We
experiment with 5 physical cables with different thickness and mass and compare
performance against two baselines in which a human chooses the apex point.
Results suggest that a baseline with a fixed apex across the three tasks
achieves respective success rates of 51.7%, 36.7%, and 15.0%, and a baseline
with human-specified, task-specific apex points achieves 66.7%, 56.7%, and
15.0% success rate respectively, while the robot using the learned apex point
can achieve success rates of 81.7% in vaulting, 65.0% in knocking, and 60.0% in
weaving. Code, data, and supplementary materials are available at https:
//sites.google.com/berkeley.edu/dynrope/home.
</dc:description>
 <dc:date>2020-11-09</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.04840</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.04853</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social-STAGE: Spatio-Temporal Multi-Modal Future Trajectory Forecast</dc:title>
 <dc:creator>Malla, Srikanth</dc:creator>
 <dc:creator>Choi, Chiho</dc:creator>
 <dc:creator>Dariush, Behzad</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper considers the problem of multi-modal future trajectory forecast
with ranking. Here, multi-modality and ranking refer to the multiple plausible
path predictions and the confidence in those predictions, respectively. We
propose Social-STAGE, Social interaction-aware Spatio-Temporal multi-Attention
Graph convolution network with novel Evaluation for multi-modality. Our main
contributions include analysis and formulation of multi-modality with ranking
using interaction and multi-attention, and introduction of new metrics to
evaluate the diversity and associated confidence of multi-modal predictions. We
evaluate our approach on existing public datasets ETH and UCY and show that the
proposed algorithm outperforms the state of the arts on these datasets.
</dc:description>
 <dc:description>Comment: ICRA 2021</dc:description>
 <dc:date>2020-11-09</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.04853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.04872</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Closed-Form Method for Optimal Hybrid Force-Velocity
  Control</dc:title>
 <dc:creator>Hou, Yifan</dc:creator>
 <dc:creator>Mason, Matthew T.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper derives a closed-form method for computing hybrid force-velocity
control. The key idea is to maximize the kinematic conditioning of the
mechanical system, which includes a robot, free objects, a rigid environment
and contact constraints. The method is complete, in that it always produces an
optimal/near optimal solution when a solution exists. It is efficient, since it
is in closed form, avoiding the iterative search of previous work. We test the
method on 78,000 randomly generated test cases. The method outperforms our
previous search-based technique by being from 7 to 40 times faster, while
consistently producing better solutions in the sense of robustness to kinematic
singularity. We also test the method in several representative manipulation
experiments.
</dc:description>
 <dc:description>Comment: To appear in ICRA 2021</dc:description>
 <dc:date>2020-11-09</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.04872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.05160</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mapping Stencils on Coarse-grained Reconfigurable Spatial Architecture</dc:title>
 <dc:creator>Tithi, Jesmin Jahan</dc:creator>
 <dc:creator>Petrini, Fabrizio</dc:creator>
 <dc:creator>Rong, Hongbo</dc:creator>
 <dc:creator>Valentin, Andrei</dc:creator>
 <dc:creator>Ebeling, Carl</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Stencils represent a class of computational patterns where an output grid
point depends on a fixed shape of neighboring points in an input grid. Stencil
computations are prevalent in scientific applications engaging a significant
portion of supercomputing resources. Therefore, it has been always important to
optimize stencil programs for the best performance. A rich body of research has
focused on optimizing stencil computations on almost all parallel
architectures. Stencil applications have regular dependency patterns, inherent
pipeline-parallelism, and plenty of data reuse. This makes these applications a
perfect match for a coarse-grained reconfigurable spatial architecture (CGRA).
A CGRA consists of many simple, small processing elements (PEs) connected with
an on-chip network. Each PE can be configured to execute part of a stencil
computation and all PEs run in parallel; the network can also be configured so
that data loaded can be passed from a PE to a neighbor PE directly and thus
reused by many PEs without register spilling and memory traffic. How to
efficiently map a stencil computation to a CGRA is the key to performance. In
this paper, we show a few unique and generalizable ways of mapping one- and
multidimensional stencil computations to a CGRA, fully exploiting the data
reuse opportunities and parallelism. Our simulation experiments demonstrate
that these mappings are efficient and enable the CGRA to outperform
state-of-the-art GPUs.
</dc:description>
 <dc:description>Comment: 9 Pages</dc:description>
 <dc:date>2020-11-06</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.05160</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.05558</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intentonomy: a Dataset and Study towards Human Intent Understanding</dc:title>
 <dc:creator>Jia, Menglin</dc:creator>
 <dc:creator>Wu, Zuxuan</dc:creator>
 <dc:creator>Reiter, Austin</dc:creator>
 <dc:creator>Cardie, Claire</dc:creator>
 <dc:creator>Belongie, Serge</dc:creator>
 <dc:creator>Lim, Ser-Nam</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  An image is worth a thousand words, conveying information that goes beyond
the physical visual content therein. In this paper, we study the intent behind
social media images with an aim to analyze how visual information can help the
recognition of human intent. Towards this goal, we introduce an intent dataset,
Intentonomy, comprising 14K images covering a wide range of everyday scenes.
These images are manually annotated with 28 intent categories that are derived
from a social psychology taxonomy. We then systematically study whether, and to
what extent, commonly used visual information, i.e., object and context,
contribute to human motive understanding. Based on our findings, we conduct
further study to quantify the effect of attending to object and context classes
as well as textual information in the form of hashtags when training an intent
classifier. Our results quantitatively and qualitatively shed light on how
visual and textual information can produce observable effects when predicting
intent.
</dc:description>
 <dc:description>Comment: CVPR2021</dc:description>
 <dc:date>2020-11-11</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.05558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.05748</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-To-End Semi-supervised Learning for Differentiable Particle Filters</dc:title>
 <dc:creator>Wen, Hao</dc:creator>
 <dc:creator>Chen, Xiongjie</dc:creator>
 <dc:creator>Papagiannis, Georgios</dc:creator>
 <dc:creator>Hu, Conghui</dc:creator>
 <dc:creator>Li, Yunpeng</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recent advances in incorporating neural networks into particle filters
provide the desired flexibility to apply particle filters in large-scale
real-world applications. The dynamic and measurement models in this framework
are learnable through the differentiable implementation of particle filters.
Past efforts in optimising such models often require the knowledge of true
states which can be expensive to obtain or even unavailable in practice. In
this paper, in order to reduce the demand for annotated data, we present an
end-to-end learning objective based upon the maximisation of a
pseudo-likelihood function which can improve the estimation of states when
large portion of true states are unknown. We assess performance of the proposed
method in state estimation tasks in robotics with simulated and real-world
datasets.
</dc:description>
 <dc:description>Comment: Accepted in ICRA 2021</dc:description>
 <dc:date>2020-11-11</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.05748</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.05798</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Software Framework for Testing of Automated Driving Systems in a Dynamic
  Traffic Environment</dc:title>
 <dc:creator>Nalic, Demin</dc:creator>
 <dc:creator>Pandurevic, Aleksa</dc:creator>
 <dc:creator>Eichberger, Arno</dc:creator>
 <dc:creator>Rogic, Branko</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Virtual testing of automated driving systems (ADS) has become an essential
part of testing procedures for all automation levels. As ADS from automation
level 3 and up are very complex, virtual testing for such systems is
inevitable. The complexity of these levels lies in the modelling and
calculation demand for the virtual environment which consists of roads,
traffic, static and dynamic objects as well as the modelling of the car itself.
For safety and performance analyses of ADS, the most important part is the
modelling and consideration of road traffic participants. There is multiple
traffic flow simulation software (TFSS) which are used to reproduce realistic
traffic behavior and are integrated directly or over interfaces with vehicle
simulation software (VSS). For these software environments, the possibility to
manipulate traffic participants in a defined manner e.g. in the vicinity of the
vehicle under test or implementing defined driver models for traffic vehicles
is beneficial. In this paper, we present a software framework based on the
external driver model interface provided by Vissim. This framework makes it
possible to easily manipulate traffic participants for testing purposes of ADS.
</dc:description>
 <dc:description>Comment: The paper was rejected</dc:description>
 <dc:date>2020-11-09</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.05798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.06049</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Colorado in Context: Congressional Redistricting and Competing Fairness
  Criteria in Colorado</dc:title>
 <dc:creator>Clelland, Jeanne</dc:creator>
 <dc:creator>Colgate, Haley</dc:creator>
 <dc:creator>DeFord, Daryl</dc:creator>
 <dc:creator>Malmskog, Beth</dc:creator>
 <dc:creator>Sancier-Barbosa, Flavia</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  In this paper, we apply techniques of ensemble analysis to understand the
political baseline for Congressional representation in Colorado. We generate a
large random sample of reasonable redistricting plans and determine the
partisan balance of each district using returns from state-wide elections in
2018, and analyze the 2011/2012 enacted districts in this context. Colorado
recently adopted a new framework for redistricting, creating an independent
commission to draw district boundaries, prohibiting partisan bias and
incumbency considerations, requiring that political boundaries (such as
counties) be preserved as much as possible, and also requiring that mapmakers
maximize the number of competitive districts. We investigate the relationships
between partisan outcomes, number of counties which are split, and number of
competitive districts in a plan. This paper also features two novel
improvements in methodology--a more rigorous statistical framework for
understanding necessary sample size, and a weighted-graph method for generating
random plans which split approximately as few counties as acceptable
human-drawn maps.
</dc:description>
 <dc:description>Comment: 39 pages, 21 figures, 9 tables</dc:description>
 <dc:date>2020-11-11</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.06049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.06296</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-World Anomaly Detection by using Digital Twin Systems and
  Weakly-Supervised Learning</dc:title>
 <dc:creator>Castellani, Andrea</dc:creator>
 <dc:creator>Schmitt, Sebastian</dc:creator>
 <dc:creator>Squartini, Stefano</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The continuously growing amount of monitored data in the Industry 4.0 context
requires strong and reliable anomaly detection techniques. The advancement of
Digital Twin technologies allows for realistic simulations of complex
machinery, therefore, it is ideally suited to generate synthetic datasets for
the use in anomaly detection approaches when compared to actual measurement
data. In this paper, we present novel weakly-supervised approaches to anomaly
detection for industrial settings. The approaches make use of a Digital Twin to
generate a training dataset which simulates the normal operation of the
machinery, along with a small set of labeled anomalous measurement from the
real machinery. In particular, we introduce a clustering-based approach, called
Cluster Centers (CC), and a neural architecture based on the Siamese
Autoencoders (SAE), which are tailored for weakly-supervised settings with very
few labeled data samples. The performance of the proposed methods is compared
against various state-of-the-art anomaly detection algorithms on an application
to a real-world dataset from a facility monitoring system, by using a multitude
of performance measures. Also, the influence of hyper-parameters related to
feature extraction and network architecture is investigated. We find that the
proposed SAE based solutions outperform state-of-the-art anomaly detection
approaches very robustly for many different hyper-parameter settings on all
performance measures.
</dc:description>
 <dc:description>Comment: in IEEE Transactions on Industrial Informatics</dc:description>
 <dc:date>2020-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.06296</dc:identifier>
 <dc:identifier>IEEE Transactions on Industrial Informatics, 2020</dc:identifier>
 <dc:identifier>doi:10.1109/TII.2020.3019788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.06749</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Legged Soft Robot Platform for Dynamic Locomotion</dc:title>
 <dc:creator>Xia, Boxi</dc:creator>
 <dc:creator>Fu, Jiaming</dc:creator>
 <dc:creator>Zhu, Hongbo</dc:creator>
 <dc:creator>Song, Zhicheng</dc:creator>
 <dc:creator>Jiang, Yibo</dc:creator>
 <dc:creator>Lipson, Hod</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present an open-source untethered quadrupedal soft robot platform for
dynamic locomotion (e.g., high-speed running and backflipping). The robot is
mostly soft (80 vol.%) while driven by four geared servo motors. The robot's
soft body and soft legs were 3D printed with gyroid infill using a flexible
material, enabling it to conform to the environment and passively stabilize
during locomotion on multi-terrain environments. In addition, we simulated the
robot in a real-time soft body simulation. With tuned gaits in simulation, the
real robot can locomote at a speed of 0.9 m/s (2.5 body length/second),
substantially faster than most untethered legged soft robots published to date.
We hope this platform, along with its verified simulator, can catalyze the
development of soft robotics.
</dc:description>
 <dc:description>Comment: Submitted to ICRA2021</dc:description>
 <dc:date>2020-11-12</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.06749</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.06829</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Migration-Related Semantic Concepts for the Retrieval of Relevant Video
  Content</dc:title>
 <dc:creator>Erick, Elejalde</dc:creator>
 <dc:creator>Damianos, Galanopoulos</dc:creator>
 <dc:creator>Claudia, Niederee</dc:creator>
 <dc:creator>Vasileios, Mezaris</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Migration, and especially irregular migration, is a critical issue for border
agencies and society in general. Migration-related situations and decisions are
influenced by various factors, including the perceptions about migration routes
and target countries. An improved understanding of such factors can be achieved
by systematic automated analyses of media and social media channels, and the
videos and images published in them. However, the multifaceted nature of
migration and the variety of ways migration-related aspects are expressed in
images and videos make the finding and automated analysis of migration-related
multimedia content a challenging task. We propose a novel approach that
effectively bridges the gap between a substantiated domain understanding -
encapsulated into a set of Migration-related semantic concepts - and the
expression of such concepts in a video, by introducing an advanced video
analysis and retrieval method for this purpose.
</dc:description>
 <dc:date>2020-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.06829</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-030-71711-7_34</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.06874</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Medical symptom recognition from patient text: An active learning
  approach for long-tailed multilabel distributions</dc:title>
 <dc:creator>Mottaghi, Ali</dc:creator>
 <dc:creator>Sarma, Prathusha K</dc:creator>
 <dc:creator>Amatriain, Xavier</dc:creator>
 <dc:creator>Yeung, Serena</dc:creator>
 <dc:creator>Kannan, Anitha</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We study the problem of medical symptoms recognition from patient text, for
the purposes of gathering pertinent information from the patient (known as
history-taking). A typical patient text is often descriptive of the symptoms
the patient is experiencing and a single instance of such a text can be
&quot;labeled&quot; with multiple symptoms. This makes learning a medical symptoms
recognizer challenging on account of i) the lack of availability of voluminous
annotated data as well as ii) the large unknown universe of multiple symptoms
that a single text can map to. Furthermore, patient text is often characterized
by a long tail in the data (i.e., some labels/symptoms occur more frequently
than others for e.g &quot;fever&quot; vs &quot;hematochezia&quot;). In this paper, we introduce an
active learning method that leverages underlying structure of a continually
refined, learned latent space to select the most informative examples to label.
This enables the selection of the most informative examples that progressively
increases the coverage on the universe of symptoms via the learned model,
despite the long tail in data distribution.
</dc:description>
 <dc:date>2020-11-12</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.06874</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.06982</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-layered tensor networks for image classification</dc:title>
 <dc:creator>Selvan, Raghavendra</dc:creator>
 <dc:creator>&#xd8;rting, Silas</dc:creator>
 <dc:creator>Dam, Erik B</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The recently introduced locally orderless tensor network (LoTeNet) for
supervised image classification uses matrix product state (MPS) operations on
grids of transformed image patches. The resulting patch representations are
combined back together into the image space and aggregated hierarchically using
multiple MPS blocks per layer to obtain the final decision rules. In this work,
we propose a non-patch based modification to LoTeNet that performs one MPS
operation per layer, instead of several patch-level operations. The spatial
information in the input images to MPS blocks at each layer is squeezed into
the feature dimension, similar to LoTeNet, to maximise retained spatial
correlation between pixels when images are flattened into 1D vectors. The
proposed multi-layered tensor network (MLTN) is capable of learning linear
decision boundaries in high dimensional spaces in a multi-layered setting,
which results in a reduction in the computation cost compared to LoTeNet
without any degradation in performance.
</dc:description>
 <dc:description>Comment: Updated version with exact computation costs. 6 pages. Accepted to
  the First Workshop on Quantum Tensor Networks in Machine Learning. In
  conjunction with 34th NeurIPS, 2020. Source code at
  https://github.com/raghavian/mltn</dc:description>
 <dc:date>2020-11-13</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.06982</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.07044</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tactile SLAM: Real-time inference of shape and pose from planar pushing</dc:title>
 <dc:creator>Suresh, Sudharshan</dc:creator>
 <dc:creator>Bauza, Maria</dc:creator>
 <dc:creator>Yu, Kuan-Ting</dc:creator>
 <dc:creator>Mangelson, Joshua G.</dc:creator>
 <dc:creator>Rodriguez, Alberto</dc:creator>
 <dc:creator>Kaess, Michael</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Tactile perception is central to robot manipulation in unstructured
environments. However, it requires contact, and a mature implementation must
infer object models while also accounting for the motion induced by the
interaction. In this work, we present a method to estimate both object shape
and pose in real-time from a stream of tactile measurements. This is applied
towards tactile exploration of an unknown object by planar pushing. We consider
this as an online SLAM problem with a nonparametric shape representation. Our
formulation of tactile inference alternates between Gaussian process implicit
surface regression and pose estimation on a factor graph. Through a combination
of local Gaussian processes and fixed-lag smoothing, we infer object shape and
pose in real-time. We evaluate our system across different objects in both
simulated and real-world planar pushing tasks.
</dc:description>
 <dc:description>Comment: Camera-ready version to be presented at the 2021 IEEE International
  Conference on Robotics and Automation (ICRA 2021). For associated video file,
  see https://youtu.be/wdyagx5MM40</dc:description>
 <dc:date>2020-11-13</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.07044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.07183</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gaussian Process-based Min-norm Stabilizing Controller for
  Control-Affine Systems with Uncertain Input Effects and Dynamics</dc:title>
 <dc:creator>Casta&#xf1;eda, Fernando</dc:creator>
 <dc:creator>Choi, Jason J.</dc:creator>
 <dc:creator>Zhang, Bike</dc:creator>
 <dc:creator>Tomlin, Claire J.</dc:creator>
 <dc:creator>Sreenath, Koushil</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper presents a method to design a min-norm Control Lyapunov Function
(CLF)-based stabilizing controller for a control-affine system with uncertain
dynamics using Gaussian Process (GP) regression. In order to estimate both
state and input-dependent model uncertainty, we propose a novel compound kernel
that captures the control-affine nature of the problem. Furthermore, by the use
of GP Upper Confidence Bound analysis, we provide probabilistic bounds of the
regression error, leading to the formulation of a CLF-based stability chance
constraint which can be incorporated in a min-norm optimization problem. We
show that this resulting optimization problem is convex, and we call it
Gaussian Process-based Control Lyapunov Function Second-Order Cone Program
(GP-CLF-SOCP). The data-collection process and the training of the GP
regression model are carried out in an episodic learning fashion. We validate
the proposed algorithm and controller in numerical simulations of an inverted
pendulum and a kinematic bicycle model, resulting in stable trajectories which
are very similar to the ones obtained if we actually knew the true plant
dynamics.
</dc:description>
 <dc:description>Comment: The first two authors contributed equally. To appear at the 2021
  American Control Conference (ACC)</dc:description>
 <dc:date>2020-11-13</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.07183</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.07232</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual Tool for Assessing Stability of DER Configurations on Three-Phase
  Radial Networks</dc:title>
 <dc:creator>Swartz, Jaimie</dc:creator>
 <dc:creator>Wais, Brittany</dc:creator>
 <dc:creator>Ratnam, Elizabeth</dc:creator>
 <dc:creator>von Meier, Alexandra</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  We present a method and tool for evaluating the placement of Distributed
Energy Resources (DER) on distribution circuits in order to control voltages
and power flows. Our previous work described Phasor-Based Control (PBC), a
novel control framework where DERs inject real and reactive power to track
voltage magnitude and phase angle targets. Here, we employ linearized power
flow equations and integral controllers to develop a linear state space model
for PBC acting on a three-phase unbalanced network. We use this model to
evaluate whether a given inverter-based DER configuration admits a stable set
of controller gains, which cannot be done by analyzing controllability nor by
using the Lyapunov equation. Instead, we sample over a parameter space to
identify a stable set of controller gains. Our stability analysis requires only
a line impedance model and does not entail simulating the system or solving an
optimization problem. We incorporate this assessment into a publicly available
visualization tool and demonstrate three processes for evaluating many control
configurations on the IEEE 123-node test feeder (123NF).
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures (figure added to section II.A for clarity),
  accepted to IEEE PowerTech 2021, for associated code see
  https://github.com/jaimiosyncrasy/heatMap</dc:description>
 <dc:date>2020-11-14</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.07232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.07271</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FedRec: Federated Learning of Universal Receivers over Fading Channels</dc:title>
 <dc:creator>Mashhadi, Mahdi Boloursaz</dc:creator>
 <dc:creator>Shlezinger, Nir</dc:creator>
 <dc:creator>Eldar, Yonina C.</dc:creator>
 <dc:creator>Gunduz, Deniz</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Wireless communications is often subject to channel fading. Various
statistical models have been proposed to capture the inherent randomness in
fading, and conventional model-based receiver designs rely on accurate
knowledge of this underlying distribution, which, in practice, may be complex
and intractable. In this work, we propose a neural network-based symbol
detection technique for downlink fading channels, which is based on the maximum
a-posteriori probability (MAP) detector. To enable training on a diverse
ensemble of fading realizations, we propose a federated training scheme, in
which multiple users collaborate to jointly learn a universal data-driven
detector, hence the name FedRec. The performance of the resulting receiver is
shown to approach the MAP performance in diverse channel conditions without
requiring knowledge of the fading statistics, while inducing a substantially
reduced communication overhead in its training procedure compared to
centralized training.
</dc:description>
 <dc:description>Comment: Submitted for publication</dc:description>
 <dc:date>2020-11-14</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.07271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.07370</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Locomotion and Control of a Friction-Driven Tripedal Robot</dc:title>
 <dc:creator>Hermes, Mark</dc:creator>
 <dc:creator>McLaughlin, Taylor</dc:creator>
 <dc:creator>Luhar, Mitul</dc:creator>
 <dc:creator>Nguyen, Quan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This letter considers control of a radially symmetric tripedal
friction-driven robot. The robot features 3 servo motors mounted on a 3-D
printed chassis 7 cm from the center of mass and separated 120 degrees. These
motors drive limbs, which impart frictional reactive forces on the body.
Experimental observations performed on a uniform friction surface validated a
mathematical model for robot motion. This model was used to create a gait map,
which features instantaneous omni-directional control. We demonstrated line
following using live feedback from an overhead tracking camera.
Proportional-Integral error compensation performance was compared to a basic
position update procedure on a rectangular course. The controller reduced path
error by approximately $46\%$. The error compensator is also able to correct
for aerodynamic disturbances generated by a high-volume industrial fan with a
mean flow speed of $5.5ms^{-1}$, reducing path error by $65\%$ relative to the
basic position update procedure.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures</dc:description>
 <dc:date>2020-11-14</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.07370</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.07428</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pollen Grain Microscopic Image Classification Using an Ensemble of
  Fine-Tuned Deep Convolutional Neural Networks</dc:title>
 <dc:creator>Mahbod, Amirreza</dc:creator>
 <dc:creator>Schaefer, Gerald</dc:creator>
 <dc:creator>Ecker, Rupert</dc:creator>
 <dc:creator>Ellinger, Isabella</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Pollen grain micrograph classification has multiple applications in medicine
and biology. Automatic pollen grain image classification can alleviate the
problems of manual categorisation such as subjectivity and time constraints.
While a number of computer-based methods have been introduced in the literature
to perform this task, classification performance needs to be improved for these
methods to be useful in practice.
  In this paper, we present an ensemble approach for pollen grain microscopic
image classification into four categories: Corylus Avellana well-developed
pollen grain, Corylus Avellana anomalous pollen grain, Alnus well-developed
pollen grain, and non-pollen (debris) instances. In our approach, we develop a
classification strategy that is based on fusion of four state-of-the-art
fine-tuned convolutional neural networks, namely EfficientNetB0,
EfficientNetB1, EfficientNetB2 and SeResNeXt-50 deep models. These models are
trained with images of three fixed sizes (224x224, 240x240, and 260x260 pixels)
and their prediction probability vectors are then fused in an ensemble method
to form a final classification vector for a given pollen grain image.
  Our proposed method is shown to yield excellent classification performance,
obtaining an accuracy of of 94.48% and a weighted F1-score of 94.54% on the
ICPR 2020 Pollen Grain Classification Challenge training dataset based on
five-fold cross-validation. Evaluated on the test set of the challenge, our
approach achieved a very competitive performance in comparison to the top
ranked approaches with an accuracy and a weighted F1-score of 96.28% and
96.30%, respectively.
</dc:description>
 <dc:description>Comment: Accepted for the Artificial Intelligence for Healthcare Applications
  workshop at the 25th International Conference on Pattern Recognition (ICPR
  2020)</dc:description>
 <dc:date>2020-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.07428</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-030-68763-2_26</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.07748</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Uncertainty Quantification for Deep Object Pose Estimation</dc:title>
 <dc:creator>Shi, Guanya</dc:creator>
 <dc:creator>Zhu, Yifeng</dc:creator>
 <dc:creator>Tremblay, Jonathan</dc:creator>
 <dc:creator>Birchfield, Stan</dc:creator>
 <dc:creator>Ramos, Fabio</dc:creator>
 <dc:creator>Anandkumar, Animashree</dc:creator>
 <dc:creator>Zhu, Yuke</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Deep learning-based object pose estimators are often unreliable and
overconfident especially when the input image is outside the training domain,
for instance, with sim2real transfer. Efficient and robust uncertainty
quantification (UQ) in pose estimators is critically needed in many robotic
tasks. In this work, we propose a simple, efficient, and plug-and-play UQ
method for 6-DoF object pose estimation. We ensemble 2-3 pre-trained models
with different neural network architectures and/or training data sources, and
compute their average pairwise disagreement against one another to obtain the
uncertainty quantification. We propose four disagreement metrics, including a
learned metric, and show that the average distance (ADD) is the best
learning-free metric and it is only slightly worse than the learned metric,
which requires labeled target data. Our method has several advantages compared
to the prior art: 1) our method does not require any modification of the
training process or the model inputs; and 2) it needs only one forward pass for
each model. We evaluate the proposed UQ method on three tasks where our
uncertainty quantification yields much stronger correlations with pose
estimation errors than the baselines. Moreover, in a real robot grasping task,
our method increases the grasping success rate from 35% to 90%.
</dc:description>
 <dc:description>Comment: Video and code are available at https://sites.google.com/view/fastuq</dc:description>
 <dc:date>2020-11-16</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.07748</dc:identifier>
 <dc:identifier>International Conferenceon Robotics and Automation (ICRA), 2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.07752</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strongly Local Hypergraph Diffusions for Clustering and Semi-supervised
  Learning</dc:title>
 <dc:creator>Liu, Meng</dc:creator>
 <dc:creator>Veldt, Nate</dc:creator>
 <dc:creator>Song, Haoyu</dc:creator>
 <dc:creator>Li, Pan</dc:creator>
 <dc:creator>Gleich, David F.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Hypergraph-based machine learning methods are now widely recognized as
important for modeling and using higher-order and multiway relationships
between data objects. Local hypergraph clustering and semi-supervised learning
specifically involve finding a well-connected set of nodes near a given set of
labeled vertices. Although many methods for local clustering exist for graphs,
there are relatively few for localized clustering in hypergraphs. Moreover,
those that exist often lack flexibility to model a general class of hypergraph
cut functions or cannot scale to large problems. To tackle these issues, this
paper proposes a new diffusion-based hypergraph clustering algorithm that
solves a quadratic hypergraph cut based objective akin to a hypergraph analog
of Andersen-Chung-Lang personalized PageRank clustering for graphs. We prove
that, for graphs with fixed maximum hyperedge size, this method is strongly
local, meaning that its runtime only depends on the size of the output instead
of the size of the hypergraph and is highly scalable. Moreover, our method
enables us to compute with a wide variety of cardinality-based hypergraph cut
functions. We also prove that the clusters found by solving the new objective
function satisfy a Cheeger-like quality guarantee. We demonstrate that on large
real-world hypergraphs our new method finds better clusters and runs much
faster than existing approaches. Specifically, it runs in few seconds for
hypergraphs with a few million hyperedges compared with minutes for flow-based
technique. We furthermore show that our framework is general enough that can
also be used to solve other p-norm based cut objectives on hypergraphs. Our
code is available \url{github.com/MengLiuPurdue/LHQD}.
</dc:description>
 <dc:date>2020-11-16</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.07752</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.07774</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DSIC: Dynamic Sample-Individualized Connector for Multi-Scale Object
  Detection</dc:title>
 <dc:creator>Li, Zekun</dc:creator>
 <dc:creator>Liu, Yufan</dc:creator>
 <dc:creator>Li, Bing</dc:creator>
 <dc:creator>Hu, Weiming</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Although object detection has reached a milestone thanks to the great success
of deep learning, the scale variation is still the key challenge. Integrating
multi-level features is presented to alleviate the problems, like the classic
Feature Pyramid Network (FPN) and its improvements. However, the specifically
designed feature integration modules of these methods may not have the optimal
architecture for feature fusion. Moreover, these models have fixed
architectures and data flow paths, when fed with various samples. They cannot
adjust and be compatible with each kind of data. To overcome the above
limitations, we propose a Dynamic Sample-Individualized Connector (DSIC) for
multi-scale object detection. It dynamically adjusts network connections to fit
different samples. In particular, DSIC consists of two components: Intra-scale
Selection Gate (ISG) and Cross-scale Selection Gate (CSG). ISG adaptively
extracts multi-level features from backbone as the input of feature
integration. CSG automatically activate informative data flow paths based on
the multi-level features. Furthermore, these two components are both
plug-and-play and can be embedded in any backbone. Experimental results
demonstrate that the proposed method outperforms the state-of-the-arts.
</dc:description>
 <dc:date>2020-11-16</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.07774</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.08436</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shared Cross-Modal Trajectory Prediction for Autonomous Driving</dc:title>
 <dc:creator>Choi, Chiho</dc:creator>
 <dc:creator>Choi, Joon Hee</dc:creator>
 <dc:creator>Li, Jiachen</dc:creator>
 <dc:creator>Malla, Srikanth</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Predicting future trajectories of traffic agents in highly interactive
environments is an essential and challenging problem for the safe operation of
autonomous driving systems. On the basis of the fact that self-driving vehicles
are equipped with various types of sensors (e.g., LiDAR scanner, RGB camera,
radar, etc.), we propose a Cross-Modal Embedding framework that aims to benefit
from the use of multiple input modalities. At training time, our model learns
to embed a set of complementary features in a shared latent space by jointly
optimizing the objective functions across different types of input data. At
test time, a single input modality (e.g., LiDAR data) is required to generate
predictions from the input perspective (i.e., in the LiDAR space), while taking
advantages from the model trained with multiple sensor modalities. An extensive
evaluation is conducted to show the efficacy of the proposed framework using
two benchmark driving datasets.
</dc:description>
 <dc:description>Comment: CVPR 2021 [Oral]</dc:description>
 <dc:date>2020-11-15</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.08436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.08447</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact recovery of Planted Cliques in Semi-random graphs</dc:title>
 <dc:creator>Khanna, Yash</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we study the Planted Clique problem in a semi-random model.
Our model is inspired from the Feige-Kilian model [FK01] which has been studied
in many other works [FK00, Ste17, MMT20] for a variety of graph problems. Our
algorithm and analysis is on similar lines to the one studied for the Densest
$k$-subgraph problem in the recent work of Khanna and Louis [KL20]. However
since our algorithm fully recovers the planted clique w.h.p. (for a &quot;large&quot;
range of input parameters), we require some new ideas.
  As a by-product of our main result, we give an alternate SDP based rounding
algorithm (with matching guarantees) for solving the Planted Clique problem in
a random graph. Also, we are able to solve special cases of the models
introduced for the Densest $k$-subgraph problem in [KL20], when the planted
subgraph is a clique instead of an arbitrary $d$-regular graph.
</dc:description>
 <dc:description>Comment: 21 pages</dc:description>
 <dc:date>2020-11-17</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.08447</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.08740</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global Road Damage Detection: State-of-the-art Solutions</dc:title>
 <dc:creator>Arya, Deeksha</dc:creator>
 <dc:creator>Maeda, Hiroya</dc:creator>
 <dc:creator>Ghosh, Sanjay Kumar</dc:creator>
 <dc:creator>Toshniwal, Durga</dc:creator>
 <dc:creator>Omata, Hiroshi</dc:creator>
 <dc:creator>Kashiyama, Takehiro</dc:creator>
 <dc:creator>Sekimoto, Yoshihide</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This paper summarizes the Global Road Damage Detection Challenge (GRDDC), a
Big Data Cup organized as a part of the IEEE International Conference on Big
Data'2020. The Big Data Cup challenges involve a released dataset and a
well-defined problem with clear evaluation metrics. The challenges run on a
data competition platform that maintains a leaderboard for the participants. In
the presented case, the data constitute 26336 road images collected from India,
Japan, and the Czech Republic to propose methods for automatically detecting
road damages in these countries. In total, 121 teams from several countries
registered for this competition. The submitted solutions were evaluated using
two datasets test1 and test2, comprising 2,631 and 2,664 images. This paper
encapsulates the top 12 solutions proposed by these teams. The best performing
model utilizes YOLO-based ensemble learning to yield an F1 score of 0.67 on
test1 and 0.66 on test2. The paper concludes with a review of the facets that
worked well for the presented challenge and those that could be improved in
future challenges.
</dc:description>
 <dc:description>Comment: 11 Pages, 2 Figures, 3 Tables</dc:description>
 <dc:date>2020-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.08740</dc:identifier>
 <dc:identifier>doi:10.1109/BigData50022.2020.9377790</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.09040</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Your &quot;Flamingo&quot; is My &quot;Bird&quot;: Fine-Grained, or Not</dc:title>
 <dc:creator>Chang, Dongliang</dc:creator>
 <dc:creator>Pang, Kaiyue</dc:creator>
 <dc:creator>Zheng, Yixiao</dc:creator>
 <dc:creator>Ma, Zhanyu</dc:creator>
 <dc:creator>Song, Yi-Zhe</dc:creator>
 <dc:creator>Guo, Jun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Whether what you see in Figure 1 is a &quot;flamingo&quot; or a &quot;bird&quot;, is the question
we ask in this paper. While fine-grained visual classification (FGVC) strives
to arrive at the former, for the majority of us non-experts just &quot;bird&quot; would
probably suffice. The real question is therefore -- how can we tailor for
different fine-grained definitions under divergent levels of expertise. For
that, we re-envisage the traditional setting of FGVC, from single-label
classification, to that of top-down traversal of a pre-defined coarse-to-fine
label hierarchy -- so that our answer becomes
&quot;bird&quot;--&gt;&quot;Phoenicopteriformes&quot;--&gt;&quot;Phoenicopteridae&quot;--&gt;&quot;flamingo&quot;. To approach
this new problem, we first conduct a comprehensive human study where we confirm
that most participants prefer multi-granularity labels, regardless whether they
consider themselves experts. We then discover the key intuition that:
coarse-level label prediction exacerbates fine-grained feature learning, yet
fine-level feature betters the learning of coarse-level classifier. This
discovery enables us to design a very simple albeit surprisingly effective
solution to our new problem, where we (i) leverage level-specific
classification heads to disentangle coarse-level features with fine-grained
ones, and (ii) allow finer-grained features to participate in coarser-grained
label predictions, which in turn helps with better disentanglement. Experiments
show that our method achieves superior performance in the new FGVC setting, and
performs better than state-of-the-art on traditional single-label FGVC problem
as well. Thanks to its simplicity, our method can be easily implemented on top
of any existing FGVC frameworks and is parameter-free.
</dc:description>
 <dc:description>Comment: Accepted as an oral of CVPR2021. Code:
  https://github.com/PRIS-CV/Fine-Grained-or-Not</dc:description>
 <dc:date>2020-11-17</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.09040</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.09069</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A large-scale comparison of social media coverage and mentions captured
  by the two altmetric aggregators- Altmetric.com and PlumX</dc:title>
 <dc:creator>Karmakar, Mousumi</dc:creator>
 <dc:creator>Banshal, Sumit Kumar</dc:creator>
 <dc:creator>Singh, Vivek Kumar</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  The increased social media attention to scholarly articles has resulted in
efforts to create platforms &amp; services to track and measure the social media
transactions around scholarly articles in different social platforms (such as
Twitter, Blog, Facebook) and academic social networks (such as Mendeley,
Academia and ResearchGate). Altmetric.com and PlumX are two popular aggregators
that track social media activity around scholarly articles from a variety of
social platforms and provide the coverage and transaction data to researchers
for various purposes. However, some previous studies have shown that the social
media data captured by the two aggregators have differences in terms of
coverage and magnitude of mentions. This paper aims to revisit the question by
doing a large-scale analysis of social media mentions of a data sample of
1,785,149 publication records (drawn from multiple disciplines, demographies,
publishers). Results obtained show that PlumX tracks more wide sources and more
articles as compared to Altmetric.com. However, the coverage and average
mentions of the two aggregators vary across different social media platforms,
with Altmetric.com recording higher mentions in Twitter and Blog, and PlumX
recording higher mentions in Facebook and Mendeley, for the same set of
articles. The coverage and average mentions captured by the two aggregators
across different document types, disciplines and publishers is also analyzed.
</dc:description>
 <dc:description>Comment: 23 pages including 4 figures and 7 tables</dc:description>
 <dc:date>2020-11-17</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.09069</dc:identifier>
 <dc:identifier>Scientometrics 2021</dc:identifier>
 <dc:identifier>doi:10.1007/s11192-021-03941-y</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.09230</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FixBi: Bridging Domain Spaces for Unsupervised Domain Adaptation</dc:title>
 <dc:creator>Na, Jaemin</dc:creator>
 <dc:creator>Jung, Heechul</dc:creator>
 <dc:creator>Chang, Hyung Jin</dc:creator>
 <dc:creator>Hwang, Wonjun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Unsupervised domain adaptation (UDA) methods for learning domain invariant
representations have achieved remarkable progress. However, most of the studies
were based on direct adaptation from the source domain to the target domain and
have suffered from large domain discrepancies. In this paper, we propose a UDA
method that effectively handles such large domain discrepancies. We introduce a
fixed ratio-based mixup to augment multiple intermediate domains between the
source and target domain. From the augmented-domains, we train the
source-dominant model and the target-dominant model that have complementary
characteristics. Using our confidence-based learning methodologies, e.g.,
bidirectional matching with high-confidence predictions and self-penalization
using low-confidence predictions, the models can learn from each other or from
its own results. Through our proposed methods, the models gradually transfer
domain knowledge from the source to the target domain. Extensive experiments
demonstrate the superiority of our proposed method on three public benchmarks:
Office-31, Office-Home, and VisDA-2017.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2021</dc:description>
 <dc:date>2020-11-18</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.09230</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.09563</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robustified Domain Adaptation</dc:title>
 <dc:creator>Zhang, Jiajin</dc:creator>
 <dc:creator>Chao, Hanqing</dc:creator>
 <dc:creator>Yan, Pingkun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Unsupervised domain adaptation (UDA) is widely used to transfer knowledge
from a labeled source domain to an unlabeled target domain with different data
distribution. While extensive studies attested that deep learning models are
vulnerable to adversarial attacks, the adversarial robustness of models in
domain adaptation application has largely been overlooked. This paper points
out that the inevitable domain distribution deviation in UDA is a critical
barrier to model robustness on the target domain. To address the problem, we
propose a novel Class-consistent Unsupervised Robust Domain Adaptation (CURDA)
framework for training robust UDA models. With the introduced contrastive
robust training and source anchored adversarial contrastive losses, our
proposed CURDA framework can effectively robustify UDA models by simultaneously
minimizing the data distribution deviation and the distance between target
domain clean-adversarial pairs without creating classification confusion.
Experiments on several public benchmarks show that CURDA can significantly
improve model robustness in the target domain with only minor cost of accuracy
on the clean samples.
</dc:description>
 <dc:date>2020-11-18</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.09563</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.09594</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Multi-view Depth Estimation with Predicted Uncertainty</dc:title>
 <dc:creator>Ke, Tong</dc:creator>
 <dc:creator>Do, Tien</dc:creator>
 <dc:creator>Vuong, Khiem</dc:creator>
 <dc:creator>Sartipi, Kourosh</dc:creator>
 <dc:creator>Roumeliotis, Stergios I.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper, we address the problem of estimating dense depth from a
sequence of images using deep neural networks. Specifically, we employ a
dense-optical-flow network to compute correspondences and then triangulate the
point cloud to obtain an initial depth map.Parts of the point cloud, however,
may be less accurate than others due to lack of common observations or small
parallax. To further increase the triangulation accuracy, we introduce a
depth-refinement network (DRN) that optimizes the initial depth map based on
the image's contextual cues. In particular, the DRN contains an iterative
refinement module (IRM) that improves the depth accuracy over iterations by
refining the deep features. Lastly, the DRN also predicts the uncertainty in
the refined depths, which is desirable in applications such as measurement
selection for scene reconstruction. We show experimentally that our algorithm
outperforms state-of-the-art approaches in terms of depth accuracy, and verify
that our predicted uncertainty is highly correlated to the actual depth error.
</dc:description>
 <dc:description>Comment: IEEE International Conference on Robotics and Automation (ICRA 2021)</dc:description>
 <dc:date>2020-11-18</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.09594</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.09949</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reconfigurable Intelligent Surface Optimal Placement in Millimeter-Wave
  Networks</dc:title>
 <dc:creator>Ntontin, Konstantinos</dc:creator>
 <dc:creator>Boulogeorgos, Alexandros-Apostolos A.</dc:creator>
 <dc:creator>Selimis, Dimitrios</dc:creator>
 <dc:creator>Lazarakis, Fotis</dc:creator>
 <dc:creator>Alexiou, Angeliki</dc:creator>
 <dc:creator>Chatzinotas, Symeon</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  This work discusses the optimal reconfigurable intelligent surface placement
in highly-directional millimeter wave links. In particular, we present a novel
system model that takes into account the relationship between the transmission
beam footprint at the RIS plane and the RIS size. Subsequently, based on the
model we derive the end-to-end expression of the received signal power and,
furthermore, provide approximate closed-form expressions in the case that the
RIS size is either much smaller or at least equal to the transmission beam
footprint. Moreover, building upon the expressions, we derive the optimal RIS
placement that maximizes the end-to-end signal-to-noise ratio. Finally, we
substantiate the analytical findings by means of simulations, which reveal
important trends regarding the optimal RIS placement according to the system
parameters.
</dc:description>
 <dc:description>Comment: 15 pages, 11 figures</dc:description>
 <dc:date>2020-11-19</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.09949</dc:identifier>
 <dc:identifier>IEEE Open Journal of the Communications Society, March, 2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.10036</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Dynamics of Training Attention Models</dc:title>
 <dc:creator>Lu, Haoye</dc:creator>
 <dc:creator>Mao, Yongyi</dc:creator>
 <dc:creator>Nayak, Amiya</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The attention mechanism has been widely used in deep neural networks as a
model component. By now, it has become a critical building block in many
state-of-the-art natural language models. Despite its great success established
empirically, the working mechanism of attention has not been investigated at a
sufficient theoretical depth to date. In this paper, we set up a simple text
classification task and study the dynamics of training a simple attention-based
classification model using gradient descent. In this setting, we show that, for
the discriminative words that the model should attend to, a persisting identity
exists relating its embedding and the inner product of its key and the query.
This allows us to prove that training must converge to attending to the
discriminative words when the attention output is classified by a linear
classifier. Experiments are performed, which validate our theoretical analysis
and provide further insights.
</dc:description>
 <dc:date>2020-11-19</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.10036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.10095</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Locally-Aware Constrained Games on Networks</dc:title>
 <dc:creator>Peng, Guanze</dc:creator>
 <dc:creator>Li, Tao</dc:creator>
 <dc:creator>Liu, Shutian</dc:creator>
 <dc:creator>Chen, Juntao</dc:creator>
 <dc:creator>Zhu, Quanyan</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Network games have been instrumental in understanding strategic behaviors
over networks for applications such as critical infrastructure networks, social
networks, and cyber-physical systems. One critical challenge of network games
is that the behaviors of the players are constrained by the underlying physical
laws or safety rules, and the players may not have complete knowledge of
network-wide constraints. To this end, this paper proposes a game framework to
study constrained games on networks, where the players are locally aware of the
constraints. We use \textit{awareness levels} to capture the scope of the
network constraints that players are aware of. We first define and show the
existence of generalized Nash equilibria (GNE) of the game, and point out that
higher awareness levels of the players would lead to a larger set of GNE
solutions. We use necessary and sufficient conditions to characterize the GNE,
and propose the concept of the dual game to show that one can convert a
locally-aware constrained game into a two-layer unconstrained game problem. We
use linear quadratic games as case studies to corroborate the analytical
results, and in particular, show the duality between Bertrand games and Cournot
games.%, where each layer comprises an unconstrained game.
</dc:description>
 <dc:date>2020-11-19</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.10095</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.10144</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpretable and Transferable Models to Understand the Impact of
  Lockdown Measures on Local Air Quality</dc:title>
 <dc:creator>Einsiedler, Johanna</dc:creator>
 <dc:creator>Cheng, Yun</dc:creator>
 <dc:creator>Papst, Franz</dc:creator>
 <dc:creator>Saukh, Olga</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The COVID-19 related lockdown measures offer a unique opportunity to
understand how changes in economic activity and traffic affect ambient air
quality and how much pollution reduction potential can the society offer
through digitalization and mobilitylimiting policies. In this work, we estimate
pollution reduction over the lockdown period by using the measurements from
ground air pollution monitoring stations, training a long-term prediction model
and comparing its predictions to measured values over the lockdown month.We
show that our models achieve state-of-the-art performance on the data from air
pollution measurement stations in Switzerland and in China: evaluate up to
-15.8% / +34.4% change in NO2 / PM10 in Zurich; -35.3 % / -3.5 % and -42.4 % /
-34.7 % in NO2 / PM2.5 in Beijing and Wuhan respectively. Our reduction
estimates are consistent with recent publications, yet in contrast to prior
works, our method takes local weather into account. What can we learn from
pollution emissions during lockdown? The lockdown period was too short to train
meaningful models from scratch. To tackle this problem, we use transfer
learning to newly fit only traffic-dependent variables. We show that the
resulting models are accurate, suitable for an analysis of the post-lockdown
period and capable of estimating the future air pollution reduction potential.
</dc:description>
 <dc:date>2020-11-19</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.10144</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.10250</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consistency-Aware Graph Network for Human Interaction Understanding</dc:title>
 <dc:creator>Wang, Zhenhua</dc:creator>
 <dc:creator>Meng, Jiajun</dc:creator>
 <dc:creator>Guo, Dongyan</dc:creator>
 <dc:creator>Zhang, Jianhua</dc:creator>
 <dc:creator>Shi, Javen Qinfeng</dc:creator>
 <dc:creator>Chen, Shengyong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Compared with the progress made on human activity classification, much less
success has been achieved on human interaction understanding (HIU). Apart from
the latter task is much more challenging, the main cause is that recent
approaches learn human interactive relations via shallow graphical models,
which is inadequate to model complicated human interactions. In this paper, we
propose a consistency-aware graph network, which combines the representative
ability of graph network and the consistency-aware reasoning to facilitate the
HIU task. Our network consists of three components, a backbone CNN to extract
image features, a factor graph network to learn third-order interactive
relations among participants, and a consistency-aware reasoning module to
enforce labeling and grouping consistencies. Our key observation is that the
consistency-aware-reasoning bias for HIU can be embedded into an energy
function, minimizing which delivers consistent predictions. An efficient
mean-field inference algorithm is proposed, such that all modules of our
network could be trained jointly in an end-to-end manner. Experimental results
show that our approach achieves leading performance on three benchmarks.
</dc:description>
 <dc:date>2020-11-20</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.10250</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.10481</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Positivity preserving high order schemes for angiogenesis models</dc:title>
 <dc:creator>Carpio, A.</dc:creator>
 <dc:creator>Cebrian, E.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Hypoxy induced angiogenesis processes can be described coupling an
integrodifferential kinetic equation of Fokker-Planck type with a diffusion
equation for the angiogenic factor. We propose high order positivity preserving
schemes to approximate the marginal tip density by combining an asymptotic
reduction with weighted essentially non oscillatory and strong stability
preserving time discretization. We show that soliton-like solutions
representing blood vessel formation and spread towards hypoxic regions are
captured.
</dc:description>
 <dc:date>2020-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.10481</dc:identifier>
 <dc:identifier>International Journal of Nonlinear Sciences and Numerical
  Simulation 2021</dc:identifier>
 <dc:identifier>doi:10.1515/ijnsns-2021-0112</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.10610</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SReachTools Kernel Module: Data-Driven Stochastic Reachability Using
  Hilbert Space Embeddings of Distributions</dc:title>
 <dc:creator>Thorpe, Adam J.</dc:creator>
 <dc:creator>Ortiz, Kendric R.</dc:creator>
 <dc:creator>Oishi, Meeko M. K.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  We present algorithms for performing data-driven stochastic reachability as
an addition to SReachTools, an open-source stochastic reachability toolbox. Our
method leverages a class of machine learning techniques known as kernel
embeddings of distributions to approximate the safety probabilities for a wide
variety of stochastic reachability problems. By representing the probability
distributions of the system state as elements in a reproducing kernel Hilbert
space, we can learn the &quot;best fit&quot; distribution via a simple regularized
least-squares problem, and then compute the stochastic reachability safety
probabilities as simple linear operations. This technique admits finite sample
bounds and has known convergence in probability. We implement these methods as
part of SReachTools, and demonstrate their use on a double integrator system,
on a million-dimensional repeated planar quadrotor system, and a cart-pole
system with a black-box neural network controller.
</dc:description>
 <dc:date>2020-11-20</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.10610</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.10726</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Object Rearrangement Using Learned Implicit Collision Functions</dc:title>
 <dc:creator>Danielczuk, Michael</dc:creator>
 <dc:creator>Mousavian, Arsalan</dc:creator>
 <dc:creator>Eppner, Clemens</dc:creator>
 <dc:creator>Fox, Dieter</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Robotic object rearrangement combines the skills of picking and placing
objects. When object models are unavailable, typical collision-checking models
may be unable to predict collisions in partial point clouds with occlusions,
making generation of collision-free grasping or placement trajectories
challenging. We propose a learned collision model that accepts scene and query
object point clouds and predicts collisions for 6DOF object poses within the
scene. We train the model on a synthetic set of 1 million scene/object point
cloud pairs and 2 billion collision queries. We leverage the learned collision
model as part of a model predictive path integral (MPPI) policy in a tabletop
rearrangement task and show that the policy can plan collision-free grasps and
placements for objects unseen in training in both simulated and physical
cluttered scenes with a Franka Panda robot. The learned model outperforms both
traditional pipelines and learned ablations by 9.8% in accuracy on a dataset of
simulated collision queries and is 75x faster than the best-performing
baseline. Videos and supplementary material are available at
https://research.nvidia.com/publication/2021-03_Object-Rearrangement-Using.
</dc:description>
 <dc:description>Comment: First two authors contributed equally. 2021 IEEE International
  Conference on Robotics and Automation. 8 pages, 4 figures, 3 tables</dc:description>
 <dc:date>2020-11-21</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.10726</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.10804</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BARS: Joint Search of Cell Topology and Layout for Accurate and
  Efficient Binary ARchitectures</dc:title>
 <dc:creator>Zhao, Tianchen</dc:creator>
 <dc:creator>Ning, Xuefei</dc:creator>
 <dc:creator>Shi, Xiangsheng</dc:creator>
 <dc:creator>Yang, Songyi</dc:creator>
 <dc:creator>Liang, Shuang</dc:creator>
 <dc:creator>Lei, Peng</dc:creator>
 <dc:creator>Chen, Jianfei</dc:creator>
 <dc:creator>Yang, Huazhong</dc:creator>
 <dc:creator>Wang, Yu</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Binary Neural Networks (BNNs) have received significant attention due to
their promising efficiency. Currently, most BNN studies directly adopt
widely-used CNN architectures, which can be suboptimal for BNNs. This paper
proposes a novel Binary ARchitecture Search (BARS) flow to discover superior
binary architecture in a large design space. Specifically, we analyze the
information bottlenecks that are related to both the topology and layout
architecture design choices. And we propose to automatically search for the
optimal information flow. To achieve that, we design a two-level (Macro &amp;
Micro) search space tailored for BNNs and apply a differentiable neural
architecture search (NAS) to explore this search space efficiently. The
macro-level search space includes width and depth decisions, which is required
for better balancing the model performance and complexity. We also design the
micro-level search space to strengthen the information flow for BNN. %A notable
challenge of BNN architecture search lies in that binary operations exacerbate
the &quot;collapse&quot; problem of differentiable NAS, for which we incorporate various
search and derive strategies to stabilize the search process. On CIFAR-10, BARS
achieves 1.5% higher accuracy with 2/3 binary operations and 1/10
floating-point operations comparing with existing BNN NAS studies. On ImageNet,
with similar resource consumption, BARS-discovered architecture achieves a 6%
accuracy gain than hand-crafted binary ResNet-18 architectures and outperforms
other binary architectures while fully binarizing the architecture backbone.
</dc:description>
 <dc:date>2020-11-21</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.10804</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.10830</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boundary-sensitive Pre-training for Temporal Localization in Videos</dc:title>
 <dc:creator>Xu, Mengmeng</dc:creator>
 <dc:creator>Perez-Rua, Juan-Manuel</dc:creator>
 <dc:creator>Escorcia, Victor</dc:creator>
 <dc:creator>Martinez, Brais</dc:creator>
 <dc:creator>Zhu, Xiatian</dc:creator>
 <dc:creator>Zhang, Li</dc:creator>
 <dc:creator>Ghanem, Bernard</dc:creator>
 <dc:creator>Xiang, Tao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Many video analysis tasks require temporal localization thus detection of
content changes. However, most existing models developed for these tasks are
pre-trained on general video action classification tasks. This is because large
scale annotation of temporal boundaries in untrimmed videos is expensive.
Therefore no suitable datasets exist for temporal boundary-sensitive
pre-training. In this paper for the first time, we investigate model
pre-training for temporal localization by introducing a novel
boundary-sensitive pretext (BSP) task. Instead of relying on costly manual
annotations of temporal boundaries, we propose to synthesize temporal
boundaries in existing video action classification datasets. With the
synthesized boundaries, BSP can be simply conducted via classifying the
boundary types. This enables the learning of video representations that are
much more transferable to downstream temporal localization tasks. Extensive
experiments show that the proposed BSP is superior and complementary to the
existing action classification based pre-training counterpart, and achieves new
state-of-the-art performance on several temporal localization tasks.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures</dc:description>
 <dc:date>2020-11-21</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.10830</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.11167</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Selectivity and Competition of the Mind's Eye in Visual Perception</dc:title>
 <dc:creator>Kim, Edward</dc:creator>
 <dc:creator>Daniali, Maryam</dc:creator>
 <dc:creator>Rego, Jocelyn</dc:creator>
 <dc:creator>Kenyon, Garrett T.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Research has shown that neurons within the brain are selective to certain
stimuli. For example, the fusiform face area (FFA) region is known by
neuroscientists to selectively activate when people see faces over non-face
objects. However, the mechanisms by which the primary visual system directs
information to the correct higher levels of the brain are currently unknown. In
our work, we mimic several high-level neural mechanisms of perception by
creating a novel computational model that incorporates lateral and top down
feedback in the form of hierarchical competition. Not only do we show that
these elements can help explain the information flow and selectivity of high
level areas within the brain, we also demonstrate that these neural mechanisms
provide the foundation of a novel classification framework that rivals
traditional supervised learning in computer vision. Additionally, we present
both quantitative and qualitative results that demonstrate that our generative
framework is consistent with neurological themes and enables simple, yet robust
category level classification.
</dc:description>
 <dc:description>Comment: 8 pages, under review</dc:description>
 <dc:date>2020-11-22</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.11167</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.11181</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On InstaHide, Phase Retrieval, and Sparse Matrix Factorization</dc:title>
 <dc:creator>Chen, Sitan</dc:creator>
 <dc:creator>Li, Xiaoxiao</dc:creator>
 <dc:creator>Song, Zhao</dc:creator>
 <dc:creator>Zhuo, Danyang</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this work, we examine the security of InstaHide, a scheme recently
proposed by [Huang, Song, Li and Arora, ICML'20] for preserving the security of
private datasets in the context of distributed learning. To generate a
synthetic training example to be shared among the distributed learners,
InstaHide takes a convex combination of private feature vectors and randomly
flips the sign of each entry of the resulting vector with probability 1/2. A
salient question is whether this scheme is secure in any provable sense,
perhaps under a plausible hardness assumption and assuming the distributions
generating the public and private data satisfy certain properties.
  We show that the answer to this appears to be quite subtle and closely
related to the average-case complexity of a new multi-task, missing-data
version of the classic problem of phase retrieval. Motivated by this
connection, we design a provable algorithm that can recover private vectors
using only the public vectors and synthetic vectors generated by InstaHide,
under the assumption that the private and public vectors are isotropic
Gaussian.
</dc:description>
 <dc:description>Comment: 30 pages, to appear in ICLR 2021, v2: updated discussion of follow-up
  work</dc:description>
 <dc:date>2020-11-22</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.11181</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.11682</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Construction of Nonlinear Models over Normalized Data</dc:title>
 <dc:creator>Chen, Zhaoyue</dc:creator>
 <dc:creator>Koudas, Nick</dc:creator>
 <dc:creator>Zhang, Zhe</dc:creator>
 <dc:creator>Yu, Xiaohui</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Machine Learning (ML) applications are proliferating in the enterprise.
Relational data which are prevalent in enterprise applications are typically
normalized; as a result, data has to be denormalized via primary/foreign-key
joins to be provided as input to ML algorithms. In this paper, we study the
implementation of popular nonlinear ML models, Gaussian Mixture Models (GMM)
and Neural Networks (NN), over normalized data addressing both cases of binary
and multi-way joins over normalized relations.
  For the case of GMM, we show how it is possible to decompose computation in a
systematic way both for binary joins and for multi-way joins to construct
mixture models. We demonstrate that by factoring the computation, one can
conduct the training of the models much faster compared to other applicable
approaches, without any loss in accuracy.
  For the case of NN, we propose algorithms to train the network taking
normalized data as the input. Similarly, we present algorithms that can conduct
the training of the network in a factorized way and offer performance
advantages. The redundancy introduced by denormalization can be exploited for
certain types of activation functions. However, we demonstrate that attempting
to explore this redundancy is helpful up to a certain point; exploring
redundancy at higher layers of the network will always result in increased
costs and is not recommended.
  We present the results of a thorough experimental evaluation, varying several
parameters of the input relations involved and demonstrate that our proposals
for the training of GMM and NN yield drastic performance improvements typically
starting at 100%, which become increasingly higher as parameters of the
underlying data vary, without any loss in accuracy.
</dc:description>
 <dc:description>Comment: Accepted at IEEE International Conference on Data Engineering (ICDE
  2021)</dc:description>
 <dc:date>2020-11-23</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.11682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.11724</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rotation-Only Bundle Adjustment</dc:title>
 <dc:creator>Lee, Seong Hun</dc:creator>
 <dc:creator>Civera, Javier</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel method for estimating the global rotations of the cameras
independently of their positions and the scene structure. When two calibrated
cameras observe five or more of the same points, their relative rotation can be
recovered independently of the translation. We extend this idea to multiple
views, thereby decoupling the rotation estimation from the translation and
structure estimation. Our approach provides several benefits such as complete
immunity to inaccurate translations and structure, and the accuracy improvement
when used with rotation averaging. We perform extensive evaluations on both
synthetic and real datasets, demonstrating consistent and significant gains in
accuracy when used with the state-of-the-art rotation averaging method.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2021</dc:description>
 <dc:date>2020-11-23</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.11724</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.11731</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HistoGAN: Controlling Colors of GAN-Generated and Real Images via Color
  Histograms</dc:title>
 <dc:creator>Afifi, Mahmoud</dc:creator>
 <dc:creator>Brubaker, Marcus A.</dc:creator>
 <dc:creator>Brown, Michael S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While generative adversarial networks (GANs) can successfully produce
high-quality images, they can be challenging to control. Simplifying GAN-based
image generation is critical for their adoption in graphic design and artistic
work. This goal has led to significant interest in methods that can intuitively
control the appearance of images generated by GANs. In this paper, we present
HistoGAN, a color histogram-based method for controlling GAN-generated images'
colors. We focus on color histograms as they provide an intuitive way to
describe image color while remaining decoupled from domain-specific semantics.
Specifically, we introduce an effective modification of the recent StyleGAN
architecture to control the colors of GAN-generated images specified by a
target color histogram feature. We then describe how to expand HistoGAN to
recolor real images. For image recoloring, we jointly train an encoder network
along with HistoGAN. The recoloring model, ReHistoGAN, is an unsupervised
approach trained to encourage the network to keep the original image's content
while changing the colors based on the given target histogram. We show that
this histogram-based approach offers a better way to control GAN-generated and
real images' colors while producing more compelling results compared to
existing alternative strategies.
</dc:description>
 <dc:description>Comment: CVPR 2021</dc:description>
 <dc:date>2020-11-23</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.11731</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.11950</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Search4Code: Code Search Intent Classification Using Weak Supervision</dc:title>
 <dc:creator>Rao, Nikitha</dc:creator>
 <dc:creator>Bansal, Chetan</dc:creator>
 <dc:creator>Guan, Joe</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Developers use search for various tasks such as finding code, documentation,
debugging information, etc. In particular, web search is heavily used by
developers for finding code examples and snippets during the coding process.
Recently, natural language based code search has been an active area of
research. However, the lack of real-world large-scale datasets is a significant
bottleneck. In this work, we propose a weak supervision based approach for
detecting code search intent in search queries for C# and Java programming
languages. We evaluate the approach against several baselines on a real-world
dataset comprised of over 1 million queries mined from Bing web search engine
and show that the CNN based model can achieve an accuracy of 77% and 76% for C#
and Java respectively. Furthermore, we are also releasing Search4Code, the
first large-scale real-world dataset of code search queries mined from Bing web
search engine. We hope that the dataset will aid future research on code
search.
</dc:description>
 <dc:description>Comment: Dataset for this paper is available here:
  https://github.com/microsoft/Search4Code</dc:description>
 <dc:date>2020-11-24</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.11950</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.12172</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>VIGOR: Cross-View Image Geo-localization beyond One-to-one Retrieval</dc:title>
 <dc:creator>Zhu, Sijie</dc:creator>
 <dc:creator>Yang, Taojiannan</dc:creator>
 <dc:creator>Chen, Chen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Cross-view image geo-localization aims to determine the locations of
street-view query images by matching with GPS-tagged reference images from
aerial view. Recent works have achieved surprisingly high retrieval accuracy on
city-scale datasets. However, these results rely on the assumption that there
exists a reference image exactly centered at the location of any query image,
which is not applicable for practical scenarios. In this paper, we redefine
this problem with a more realistic assumption that the query image can be
arbitrary in the area of interest and the reference images are captured before
the queries emerge. This assumption breaks the one-to-one retrieval setting of
existing datasets as the queries and reference images are not perfectly aligned
pairs, and there may be multiple reference images covering one query location.
To bridge the gap between this realistic setting and existing datasets, we
propose a new large-scale benchmark -- VIGOR -- for cross-View Image
Geo-localization beyond One-to-one Retrieval. We benchmark existing
state-of-the-art methods and propose a novel end-to-end framework to localize
the query in a coarse-to-fine manner. Apart from the image-level retrieval
accuracy, we also evaluate the localization accuracy in terms of the actual
distance (meters) using the raw GPS data. Extensive experiments are conducted
under different application scenarios to validate the effectiveness of the
proposed method. The results indicate that cross-view geo-localization in this
realistic setting is still challenging, fostering new research in this
direction. Our dataset and code will be released at
\url{https://github.com/Jeff-Zilence/VIGOR}
</dc:description>
 <dc:description>Comment: CVPR 2021</dc:description>
 <dc:date>2020-11-24</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.12172</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.12222</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovering Hidden Physics Behind Transport Dynamics</dc:title>
 <dc:creator>Liu, Peirong</dc:creator>
 <dc:creator>Tian, Lin</dc:creator>
 <dc:creator>Zhang, Yubo</dc:creator>
 <dc:creator>Aylward, Stephen R.</dc:creator>
 <dc:creator>Lee, Yueh Z.</dc:creator>
 <dc:creator>Niethammer, Marc</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Transport processes are ubiquitous. They are, for example, at the heart of
optical flow approaches; or of perfusion imaging, where blood transport is
assessed, most commonly by injecting a tracer. An advection-diffusion equation
is widely used to describe these transport phenomena. Our goal is estimating
the underlying physics of advection-diffusion equations, expressed as velocity
and diffusion tensor fields. We propose a learning framework (YETI) building on
an auto-encoder structure between 2D and 3D image time-series, which
incorporates the advection-diffusion model. To help with identifiability, we
develop an advection-diffusion simulator which allows pre-training of our model
by supervised learning using the velocity and diffusion tensor fields. Instead
of directly learning these velocity and diffusion tensor fields, we introduce
representations that assure incompressible flow and symmetric positive
semi-definite diffusion fields and demonstrate the additional benefits of these
representations on improving estimation accuracy. We further use transfer
learning to apply YETI on a public brain magnetic resonance (MR) perfusion
dataset of stroke patients and show its ability to successfully distinguish
stroke lesions from normal brain regions via the estimated velocity and
diffusion tensor fields.
</dc:description>
 <dc:description>Comment: Accepted as ORAL at CVPR 2021 (20 pages, 13 figures)</dc:description>
 <dc:date>2020-11-24</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.12222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.12505</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy-preserving Collaborative Learning with Automatic Transformation
  Search</dc:title>
 <dc:creator>Gao, Wei</dc:creator>
 <dc:creator>Guo, Shangwei</dc:creator>
 <dc:creator>Zhang, Tianwei</dc:creator>
 <dc:creator>Qiu, Han</dc:creator>
 <dc:creator>Wen, Yonggang</dc:creator>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Collaborative learning has gained great popularity due to its benefit of data
privacy protection: participants can jointly train a Deep Learning model
without sharing their training sets. However, recent works discovered that an
adversary can fully recover the sensitive training samples from the shared
gradients. Such reconstruction attacks pose severe threats to collaborative
learning. Hence, effective mitigation solutions are urgently desired.
  In this paper, we propose to leverage data augmentation to defeat
reconstruction attacks: by preprocessing sensitive images with
carefully-selected transformation policies, it becomes infeasible for the
adversary to extract any useful information from the corresponding gradients.
We design a novel search method to automatically discover qualified policies.
We adopt two new metrics to quantify the impacts of transformations on data
privacy and model usability, which can significantly accelerate the search
speed. Comprehensive evaluations demonstrate that the policies discovered by
our method can defeat existing reconstruction attacks in collaborative
learning, with high efficiency and negligible impact on the model performance.
</dc:description>
 <dc:description>Comment: 17 pages, 16 figures, CVPR2021 oral</dc:description>
 <dc:date>2020-11-24</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.12505</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.12536</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vocal Tract Length Perturbation for Text-Dependent Speaker Verification
  with Autoregressive Prediction Coding</dc:title>
 <dc:creator>Sarkar, Achintya kr.</dc:creator>
 <dc:creator>Tan, Zheng-Hua</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  In this letter, we propose a vocal tract length (VTL) perturbation method for
text-dependent speaker verification (TD-SV), in which a set of TD-SV systems
are trained, one for each VTL factor, and score-level fusion is applied to make
a final decision. Next, we explore the bottleneck (BN) feature extracted by
training deep neural networks with a self-supervised objective, autoregressive
predictive coding (APC), for TD-SV and compare it with the well-studied
speaker-discriminant BN feature. The proposed VTL method is then applied to APC
and speaker-discriminant BN features. In the end, we combine the VTL
perturbation systems trained on MFCC and the two BN features in the score
domain. Experiments are performed on the RedDots challenge 2016 database of
TD-SV using short utterances with Gaussian mixture model-universal background
model and i-vector techniques. Results show the proposed methods significantly
outperform the baselines.
</dc:description>
 <dc:description>Comment: Copyright (c) 2021 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works</dc:description>
 <dc:date>2020-11-25</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.12536</dc:identifier>
 <dc:identifier>IEEE Signal Processing Letters, vol. 28, pp. 364-368, 2021</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2021.3055180</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.13074</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Omni-GAN: On the Secrets of cGANs and Beyond</dc:title>
 <dc:creator>Zhou, Peng</dc:creator>
 <dc:creator>Xie, Lingxi</dc:creator>
 <dc:creator>Ni, Bingbing</dc:creator>
 <dc:creator>Geng, Cong</dc:creator>
 <dc:creator>Tian, Qi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The conditional generative adversarial network (cGAN) is a powerful tool of
generating high-quality images, but existing approaches mostly suffer
unsatisfying performance or the risk of mode collapse. This paper presents
Omni-GAN, a variant of cGAN that reveals the devil in designing a proper
discriminator for training the model. The key is to ensure that the
discriminator receives strong supervision to perceive the concepts and moderate
regularization to avoid collapse. Omni-GAN is easily implemented and freely
integrated with off-the-shelf encoding methods (e.g., implicit neural
representation, INR). Experiments validate the superior performance of Omni-GAN
and Omni-INR-GAN in a wide range of image generation and restoration tasks. In
particular, Omni-INR-GAN sets new records on the ImageNet dataset with
impressive Inception scores of 262.85 and 343.22 for the image sizes of 128 and
256, respectively, surpassing the previous records by 100+ points. Moreover,
leveraging the generator prior, Omni-INR-GAN can extrapolate low-resolution
images to arbitrary resolution, even up to x60+ higher resolution. Code is
available.
</dc:description>
 <dc:description>Comment: Introducing Omni-INR-GAN, which can extrapolate low-resolution images
  to arbitrary resolution</dc:description>
 <dc:date>2020-11-25</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.13074</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.13114</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Computational Approach to Historical Ontologies</dc:title>
 <dc:creator>Kelly, Mat</dc:creator>
 <dc:creator>Greenberg, Jane</dc:creator>
 <dc:creator>Rauch, Christopher B.</dc:creator>
 <dc:creator>Grabus, Sam</dc:creator>
 <dc:creator>Boone, Joan P.</dc:creator>
 <dc:creator>Kunze, John A.</dc:creator>
 <dc:creator>Logan, Peter Melville</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3.7</dc:subject>
 <dc:description>  This paper presents a use case exploring the application of the Archival
Resource Key (ARK) persistent identifier for promoting and maintaining
ontologies. In particular, we look at improving computation with an in-house
ontology server in the context of temporally aligned vocabularies. This effort
demonstrates the utility of ARKs in preparing historical ontologies for
computational archival science.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures. To be published in Proceedings of the 2020 IEEE
  International Conference on Big Data (IEEE Big Data 2020)</dc:description>
 <dc:date>2020-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.13114</dc:identifier>
 <dc:identifier>2020 IEEE International Conference on Big Data (Big Data),
  Atlanta, GA, USA, 2020, pp. 1878-1883</dc:identifier>
 <dc:identifier>doi:10.1109/BigData50022.2020.9378268</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.13377</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Well Do Self-Supervised Models Transfer?</dc:title>
 <dc:creator>Ericsson, Linus</dc:creator>
 <dc:creator>Gouk, Henry</dc:creator>
 <dc:creator>Hospedales, Timothy M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Self-supervised visual representation learning has seen huge progress
recently, but no large scale evaluation has compared the many models now
available. We evaluate the transfer performance of 13 top self-supervised
models on 40 downstream tasks, including many-shot and few-shot recognition,
object detection, and dense prediction. We compare their performance to a
supervised baseline and show that on most tasks the best self-supervised models
outperform supervision, confirming the recently observed trend in the
literature. We find ImageNet Top-1 accuracy to be highly correlated with
transfer to many-shot recognition, but increasingly less so for few-shot,
object detection and dense prediction. No single self-supervised method
dominates overall, suggesting that universal pre-training is still unsolved.
Our analysis of features suggests that top self-supervised learners fail to
preserve colour information as well as supervised alternatives, but tend to
induce better classifier calibration, and less attentive overfitting than
supervised learners.
</dc:description>
 <dc:description>Comment: CVPR 2021. Code available at
  https://github.com/linusericsson/ssl-transfer</dc:description>
 <dc:date>2020-11-26</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.13377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.13475</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fine-Grained Re-Identification</dc:title>
 <dc:creator>Pathak, Priyank</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Research into the task of re-identification (ReID) is picking up momentum in
computer vision for its many use cases and zero-shot learning nature. This
paper proposes a computationally efficient fine-grained ReID model, FGReID,
which is among the first models to unify image and video ReID while keeping the
number of training parameters minimal. FGReID takes advantage of video-based
pre-training and spatial feature attention to improve performance on both video
and image ReID tasks. FGReID achieves state-of-the-art (SOTA) on MARS,
iLIDS-VID, and PRID-2011 video person ReID benchmarks. Eliminating temporal
pooling yields an image ReID model that surpasses SOTA on CUHK01 and Market1501
image person ReID benchmarks. The FGReID achieves near SOTA performance on the
vehicle ReID dataset VeRi as well, demonstrating its ability to generalize.
Additionally we do an ablation study analyzing the key features influencing
model performance on ReID tasks. Finally, we discuss the moral dilemmas related
to ReID tasks, including the potential for misuse. Code for this work is
publicly available at https:
//github.com/ppriyank/Fine-grained-ReIdentification.
</dc:description>
 <dc:date>2020-11-26</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.13475</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.13553</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Association: Remind Your GAN not to Forget</dc:title>
 <dc:creator>Gu, Yi</dc:creator>
 <dc:creator>Li, Jie</dc:creator>
 <dc:creator>Gao, Yuting</dc:creator>
 <dc:creator>Chen, Ruoxin</dc:creator>
 <dc:creator>Wu, Chentao</dc:creator>
 <dc:creator>Cai, Feiyang</dc:creator>
 <dc:creator>Wang, Chao</dc:creator>
 <dc:creator>Zhang, Zirui</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Neural networks are susceptible to catastrophic forgetting. They fail to
preserve previously acquired knowledge when adapting to new tasks. Inspired by
human associative memory system, we propose a brain-like approach that imitates
the associative learning process to achieve continual learning. We design a
heuristics mechanism to potentiatively stimulate the model, which guides the
model to recall the historical episodes based on the current circumstance and
obtained association experience. Besides, a distillation measure is added to
depressively alter the efficacy of synaptic transmission, which dampens the
feature reconstruction learning for new task. The framework is mediated by
potentiation and depression stimulation that play opposing roles in directing
synaptic and behavioral plasticity. It requires no access to the original data
and is more similar to human cognitive process. Experiments demonstrate the
effectiveness of our method in alleviating catastrophic forgetting on
image-to-image translation tasks.
</dc:description>
 <dc:date>2020-11-26</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.13553</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.13650</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deformed Implicit Field: Modeling 3D Shapes with Learned Dense
  Correspondence</dc:title>
 <dc:creator>Deng, Yu</dc:creator>
 <dc:creator>Yang, Jiaolong</dc:creator>
 <dc:creator>Tong, Xin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel Deformed Implicit Field (DIF) representation for modeling
3D shapes of a category and generating dense correspondences among shapes. With
DIF, a 3D shape is represented by a template implicit field shared across the
category, together with a 3D deformation field and a correction field dedicated
for each shape instance. Shape correspondences can be easily established using
their deformation fields. Our neural network, dubbed DIF-Net, jointly learns a
shape latent space and these fields for 3D objects belonging to a category
without using any correspondence or part label. The learned DIF-Net can also
provides reliable correspondence uncertainty measurement reflecting shape
structure discrepancy. Experiments show that DIF-Net not only produces
high-fidelity 3D shapes but also builds high-quality dense correspondences
across different shapes. We also demonstrate several applications such as
texture transfer and shape editing, where our method achieves compelling
results that cannot be achieved by previous methods.
</dc:description>
 <dc:description>Comment: CVPR21 camera ready version</dc:description>
 <dc:date>2020-11-27</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.13650</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.13677</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-EMD: Self-Supervised Object Detection without ImageNet</dc:title>
 <dc:creator>Liu, Songtao</dc:creator>
 <dc:creator>Li, Zeming</dc:creator>
 <dc:creator>Sun, Jian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a novel self-supervised representation learning
method, Self-EMD, for object detection. Our method directly trained on
unlabeled non-iconic image dataset like COCO, instead of commonly used
iconic-object image dataset like ImageNet. We keep the convolutional feature
maps as the image embedding to preserve spatial structures and adopt Earth
Mover's Distance (EMD) to compute the similarity between two embeddings. Our
Faster R-CNN (ResNet50-FPN) baseline achieves 39.8% mAP on COCO, which is on
par with the state of the art self-supervised methods pre-trained on ImageNet.
More importantly, it can be further improved to 40.4% mAP with more unlabeled
images, showing its great potential for leveraging more easily obtained
unlabeled data. Code will be made available.
</dc:description>
 <dc:date>2020-11-27</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.13677</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.13917</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Task Programming: Learning Data Efficient Behavior Representations</dc:title>
 <dc:creator>Sun, Jennifer J.</dc:creator>
 <dc:creator>Kennedy, Ann</dc:creator>
 <dc:creator>Zhan, Eric</dc:creator>
 <dc:creator>Anderson, David J.</dc:creator>
 <dc:creator>Yue, Yisong</dc:creator>
 <dc:creator>Perona, Pietro</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Specialized domain knowledge is often necessary to accurately annotate
training sets for in-depth analysis, but can be burdensome and time-consuming
to acquire from domain experts. This issue arises prominently in automated
behavior analysis, in which agent movements or actions of interest are detected
from video tracking data. To reduce annotation effort, we present TREBA: a
method to learn annotation-sample efficient trajectory embedding for behavior
analysis, based on multi-task self-supervised learning. The tasks in our method
can be efficiently engineered by domain experts through a process we call &quot;task
programming&quot;, which uses programs to explicitly encode structured knowledge
from domain experts. Total domain expert effort can be reduced by exchanging
data annotation time for the construction of a small number of programmed
tasks. We evaluate this trade-off using data from behavioral neuroscience, in
which specialized domain knowledge is used to identify behaviors. We present
experimental results in three datasets across two domains: mice and fruit
flies. Using embeddings from TREBA, we reduce annotation burden by up to a
factor of 10 without compromising accuracy compared to state-of-the-art
features. Our results thus suggest that task programming and self-supervision
can be an effective way to reduce annotation effort for domain experts.
</dc:description>
 <dc:description>Comment: To appear in as an Oral in CVPR 2021. Code:
  https://github.com/neuroethology/TREBA. Project page:
  https://sites.google.com/view/task-programming</dc:description>
 <dc:date>2020-11-27</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.13917</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.13922</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Recurrent Vision-and-Language BERT for Navigation</dc:title>
 <dc:creator>Hong, Yicong</dc:creator>
 <dc:creator>Wu, Qi</dc:creator>
 <dc:creator>Qi, Yuankai</dc:creator>
 <dc:creator>Rodriguez-Opazo, Cristian</dc:creator>
 <dc:creator>Gould, Stephen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Accuracy of many visiolinguistic tasks has benefited significantly from the
application of vision-and-language(V&amp;L) BERT. However, its application for the
task of vision-and-language navigation (VLN) remains limited. One reason for
this is the difficulty adapting the BERT architecture to the partially
observable Markov decision process present in VLN, requiring history-dependent
attention and decision making. In this paper we propose a recurrent BERT model
that is time-aware for use in VLN. Specifically, we equip the BERT model with a
recurrent function that maintains cross-modal state information for the agent.
Through extensive experiments on R2R and REVERIE we demonstrate that our model
can replace more complex encoder-decoder models to achieve state-of-the-art
results. Moreover, our approach can be generalised to other transformer-based
architectures, supports pre-training, and is capable of solving navigation and
referring expression tasks simultaneously.
</dc:description>
 <dc:date>2020-11-25</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.13922</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.14107</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hijack-GAN: Unintended-Use of Pretrained, Black-Box GANs</dc:title>
 <dc:creator>Wang, Hui-Po</dc:creator>
 <dc:creator>Yu, Ning</dc:creator>
 <dc:creator>Fritz, Mario</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  While Generative Adversarial Networks (GANs) show increasing performance and
the level of realism is becoming indistinguishable from natural images, this
also comes with high demands on data and computation. We show that
state-of-the-art GAN models -- such as they are being publicly released by
researchers and industry -- can be used for a range of applications beyond
unconditional image generation. We achieve this by an iterative scheme that
also allows gaining control over the image generation process despite the
highly non-linear latent spaces of the latest GAN models. We demonstrate that
this opens up the possibility to re-use state-of-the-art, difficult to train,
pre-trained GANs with a high level of control even if only black-box access is
granted. Our work also raises concerns and awareness that the use cases of a
published GAN model may well reach beyond the creators' intention, which needs
to be taken into account before a full public release. Code is available at
https://github.com/a514514772/hijackgan.
</dc:description>
 <dc:description>Comment: Accepted by CVPR 2021</dc:description>
 <dc:date>2020-11-28</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.14107</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.14148</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rules of the Road: Safety and Liveness Guarantees for Autonomous
  Vehicles</dc:title>
 <dc:creator>Cai, Karena X.</dc:creator>
 <dc:creator>Phan-Minh, Tung</dc:creator>
 <dc:creator>Chung, Soon-Jo</dc:creator>
 <dc:creator>Murray, Richard M.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  The ability to guarantee safety and progress for all vehicles is vital to the
success of the autonomous vehicle industry. We present a framework for
designing autonomous vehicle behavior in a way that is safe and guarantees
progress for all agents. In this paper, we first introduce a new game paradigm
which we term the quasi-simultaneous game. We then define an agent protocol
that all agents must use to make decisions in this quasi-simultaneous game
setting. According to the protocol, agents first select an intended action
using a behavioral profile. Then, the protocol defines whether an agent has
precedence to take its intended action or must take a sub-optimal action. The
protocol ensures safety under all traffic conditions and liveness for all
agents under `sparse' traffic conditions. We provide proofs of correctness of
the protocol and validate our results in simulation.
</dc:description>
 <dc:description>Comment: 20 pages, 10 figures</dc:description>
 <dc:date>2020-11-28</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.14148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.14580</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust and Private Learning of Halfspaces</dc:title>
 <dc:creator>Ghazi, Badih</dc:creator>
 <dc:creator>Kumar, Ravi</dc:creator>
 <dc:creator>Manurangsi, Pasin</dc:creator>
 <dc:creator>Nguyen, Thao</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this work, we study the trade-off between differential privacy and
adversarial robustness under L2-perturbations in the context of learning
halfspaces. We prove nearly tight bounds on the sample complexity of robust
private learning of halfspaces for a large regime of parameters. A highlight of
our results is that robust and private learning is harder than robust or
private learning alone. We complement our theoretical analysis with
experimental results on the MNIST and USPS datasets, for a learning algorithm
that is both differentially private and adversarially robust.
</dc:description>
 <dc:description>Comment: AISTATS 2021</dc:description>
 <dc:date>2020-11-30</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.14580</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.14631</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-MPI: Cross-scale Stereo for Image Super-Resolution using
  Multiplane Images</dc:title>
 <dc:creator>Zhou, Yuemei</dc:creator>
 <dc:creator>Wu, Gaochang</dc:creator>
 <dc:creator>Fu, Ying</dc:creator>
 <dc:creator>Li, Kun</dc:creator>
 <dc:creator>Liu, Yebin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Various combinations of cameras enrich computational photography, among which
reference-based superresolution (RefSR) plays a critical role in multiscale
imaging systems. However, existing RefSR approaches fail to accomplish
high-fidelity super-resolution under a large resolution gap, e.g., 8x
upscaling, due to the lower consideration of the underlying scene structure. In
this paper, we aim to solve the RefSR problem in actual multiscale camera
systems inspired by multiplane image (MPI) representation. Specifically, we
propose Cross-MPI, an end-to-end RefSR network composed of a novel plane-aware
attention-based MPI mechanism, a multiscale guided upsampling module as well as
a super-resolution (SR) synthesis and fusion module. Instead of using a direct
and exhaustive matching between the cross-scale stereo, the proposed
plane-aware attention mechanism fully utilizes the concealed scene structure
for efficient attention-based correspondence searching. Further combined with a
gentle coarse-to-fine guided upsampling strategy, the proposed Cross-MPI can
achieve a robust and accurate detail transmission. Experimental results on both
digitally synthesized and optical zoom cross-scale data show that the Cross-MPI
framework can achieve superior performance against the existing RefSR methods
and is a real fit for actual multiscale camera systems even with large-scale
differences.
</dc:description>
 <dc:date>2020-11-30</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.14631</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.14642</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vehicle Reconstruction and Texture Estimation Using Deep Implicit
  Semantic Template Mapping</dc:title>
 <dc:creator>Zhao, Xiaochen</dc:creator>
 <dc:creator>Zheng, Zerong</dc:creator>
 <dc:creator>Ji, Chaonan</dc:creator>
 <dc:creator>Liu, Zhenyi</dc:creator>
 <dc:creator>Lin, Siyou</dc:creator>
 <dc:creator>Yu, Tao</dc:creator>
 <dc:creator>Suo, Jinli</dc:creator>
 <dc:creator>Liu, Yebin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce VERTEX, an effective solution to recover 3D shape and intrinsic
texture of vehicles from uncalibrated monocular input in real-world street
environments. To fully utilize the template prior of vehicles, we propose a
novel geometry and texture joint representation, based on implicit semantic
template mapping. Compared to existing representations which infer 3D texture
distribution, our method explicitly constrains the texture distribution on the
2D surface of the template as well as avoids limitations of fixed resolution
and topology. Moreover, by fusing the global and local features together, our
approach is capable to generate consistent and detailed texture in both visible
and invisible areas. We also contribute a new synthetic dataset containing 830
elaborate textured car models labeled with sparse key points and rendered using
Physically Based Rendering (PBRT) system with measured HDRI skymaps to obtain
highly realistic images. Experiments demonstrate the superior performance of
our approach on both testing dataset and in-the-wild images. Furthermore, the
presented technique enables additional applications such as 3D vehicle texture
transfer and material identification.
</dc:description>
 <dc:date>2020-11-30</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.14642</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.14670</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Meta Batch-Instance Normalization for Generalizable Person
  Re-Identification</dc:title>
 <dc:creator>Choi, Seokeon</dc:creator>
 <dc:creator>Kim, Taekyung</dc:creator>
 <dc:creator>Jeong, Minki</dc:creator>
 <dc:creator>Park, Hyoungseob</dc:creator>
 <dc:creator>Kim, Changick</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Although supervised person re-identification (Re-ID) methods have shown
impressive performance, they suffer from a poor generalization capability on
unseen domains. Therefore, generalizable Re-ID has recently attracted growing
attention. Many existing methods have employed an instance normalization
technique to reduce style variations, but the loss of discriminative
information could not be avoided. In this paper, we propose a novel
generalizable Re-ID framework, named Meta Batch-Instance Normalization
(MetaBIN). Our main idea is to generalize normalization layers by simulating
unsuccessful generalization scenarios beforehand in the meta-learning pipeline.
To this end, we combine learnable batch-instance normalization layers with
meta-learning and investigate the challenging cases caused by both batch and
instance normalization layers. Moreover, we diversify the virtual simulations
via our meta-train loss accompanied by a cyclic inner-updating manner to boost
generalization capability. After all, the MetaBIN framework prevents our model
from overfitting to the given source styles and improves the generalization
capability to unseen domains without additional data augmentation or
complicated network design. Extensive experimental results show that our model
outperforms the state-of-the-art methods on the large-scale domain
generalization Re-ID benchmark and the cross-domain Re-ID problem. The source
code is available at: https://github.com/bismex/MetaBIN.
</dc:description>
 <dc:description>Comment: CVPR 2021</dc:description>
 <dc:date>2020-11-30</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.14670</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.14842</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse-View Spectral CT Reconstruction Using Deep Learning</dc:title>
 <dc:creator>Mustafa, Wail</dc:creator>
 <dc:creator>Kehl, Christian</dc:creator>
 <dc:creator>Olsen, Ulrik Lund</dc:creator>
 <dc:creator>Gregersen, S&#xf8;ren Kimmer Schou</dc:creator>
 <dc:creator>Malmgren-Hansen, David</dc:creator>
 <dc:creator>Kehres, Jan</dc:creator>
 <dc:creator>Dahl, Anders Bjorholm</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Spectral computed tomography (CT) is an emerging technology capable of
providing high chemical specificity, which is crucial for many applications
such as detecting threats in luggage. This type of application requires both
fast and high-quality image reconstruction and is often based on sparse-view
(few) projections. The conventional filtered back projection (FBP) method is
fast but it produces low-quality images dominated by noise and artifacts in
sparse-view CT. Iterative methods with, e.g., total variation regularizers can
circumvent that but they are computationally expensive, as the computational
load proportionally increases with the number of spectral channels. Instead, we
propose an approach for fast reconstruction of sparse-view spectral CT data
using a U-Net convolutional neural network architecture with multi-channel
input and output. The network is trained to output high-quality CT images from
FBP input image reconstructions. Our method is fast at run-time and because the
internal convolutions are shared between the channels, the computational load
increases only at the first and last layers, making it an efficient approach to
process spectral data with a large number of channels. We have validated our
approach using real CT scans. Our results show qualitatively and quantitatively
that our approach outperforms the state-of-the-art iterative methods.
Furthermore, the results indicate that the network can exploit the coupling of
the channels to enhance the overall quality and robustness.
</dc:description>
 <dc:description>Comment: 13 pages, 9 figures, submitted to The IEEE Transactions on
  Computational Imaging</dc:description>
 <dc:date>2020-11-30</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.14842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2011.15007</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RealCause: Realistic Causal Inference Benchmarking</dc:title>
 <dc:creator>Neal, Brady</dc:creator>
 <dc:creator>Huang, Chin-Wei</dc:creator>
 <dc:creator>Raghupathi, Sunand</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  There are many different causal effect estimators in causal inference.
However, it is unclear how to choose between these estimators because there is
no ground-truth for causal effects. A commonly used option is to simulate
synthetic data, where the ground-truth is known. However, the best causal
estimators on synthetic data are unlikely to be the best causal estimators on
real data. An ideal benchmark for causal estimators would both (a) yield
ground-truth values of the causal effects and (b) be representative of real
data. Using flexible generative models, we provide a benchmark that both yields
ground-truth and is realistic. Using this benchmark, we evaluate over 1500
different causal estimators and provide evidence that it is rational to choose
hyperparameters for causal estimators using predictive metrics.
</dc:description>
 <dc:date>2020-11-30</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2011.15007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.00057</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Move to See Better: Self-Improving Embodied Object Detection</dc:title>
 <dc:creator>Fang, Zhaoyuan</dc:creator>
 <dc:creator>Jain, Ayush</dc:creator>
 <dc:creator>Sarch, Gabriel</dc:creator>
 <dc:creator>Harley, Adam W.</dc:creator>
 <dc:creator>Fragkiadaki, Katerina</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Passive methods for object detection and segmentation treat images of the
same scene as individual samples and do not exploit object permanence across
multiple views. Generalization to novel or difficult viewpoints thus requires
additional training with lots of annotations. In contrast, humans often
recognize objects by simply moving around, to get more informative viewpoints.
In this paper, we propose a method for improving object detection in testing
environments, assuming nothing but an embodied agent with a pre-trained 2D
object detector. Our agent collects multi-view data, generates 2D and 3D
pseudo-labels, and fine-tunes its detector in a self-supervised manner.
Experiments on both indoor and outdoor datasets show that (1) our method
obtains high-quality 2D and 3D pseudo-labels from multi-view RGB-D data; (2)
fine-tuning with these pseudo-labels improves the 2D detector significantly in
the test environment; (3) training a 3D detector with our pseudo-labels
outperforms a prior self-supervised method by a large margin; (4) given weak
supervision, our method can generate better pseudo-labels for novel objects.
</dc:description>
 <dc:description>Comment: First three authors contributed equally. Project Page:
  https://ayushjain1144.github.io/SeeingByMoving/</dc:description>
 <dc:date>2020-11-30</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.00057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.00226</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymmetric Quantum Concatenated and Tensor Product Codes with Large
  Z-Distances</dc:title>
 <dc:creator>Fan, Jihao</dc:creator>
 <dc:creator>Li, Jun</dc:creator>
 <dc:creator>Wang, Jianxin</dc:creator>
 <dc:creator>Wei, Zhihui</dc:creator>
 <dc:creator>Hsieh, Min-Hsiu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  In this paper, we present a new construction of asymmetric quantum codes
(AQCs) by combining classical concatenated codes (CCs) with tensor product
codes (TPCs), called asymmetric quantum concatenated and tensor product codes
(AQCTPCs) which have the following three advantages. First, only the outer
codes in AQCTPCs need to satisfy the orthogonal constraint in quantum codes,
and any classical linear code can be used for the inner, which makes AQCTPCs
very easy to construct. Second, most AQCTPCs are highly degenerate, which means
they can correct many more errors than their classical TPC counterparts.
Consequently, we construct several families of AQCs with better parameters than
known results in the literature. Third, AQCTPCs can be efficiently decoded
although they are degenerate, provided that the inner and outer codes are
efficiently decodable. In particular, we significantly reduce the inner
decoding complexity of TPCs from $\Omega(n_2a^{n_1})(a&gt;1)$ to $O(n_2)$ by
considering error degeneracy, where $n_1$ and $n_2$ are the block length of the
inner code and the outer code, respectively. Furthermore, we generalize our
concatenation scheme by using the generalized CCs and TPCs correspondingly.
</dc:description>
 <dc:description>Comment: 36pages, accepted by IEEE Transactions on Communications</dc:description>
 <dc:date>2020-11-30</dc:date>
 <dc:date>2021-03-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.00226</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2021.3064566</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.00321</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Disentangling Label Distribution for Long-tailed Visual Recognition</dc:title>
 <dc:creator>Hong, Youngkyu</dc:creator>
 <dc:creator>Han, Seungju</dc:creator>
 <dc:creator>Choi, Kwanghee</dc:creator>
 <dc:creator>Seo, Seokjun</dc:creator>
 <dc:creator>Kim, Beomsu</dc:creator>
 <dc:creator>Chang, Buru</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The current evaluation protocol of long-tailed visual recognition trains the
classification model on the long-tailed source label distribution and evaluates
its performance on the uniform target label distribution. Such protocol has
questionable practicality since the target may also be long-tailed. Therefore,
we formulate long-tailed visual recognition as a label shift problem where the
target and source label distributions are different. One of the significant
hurdles in dealing with the label shift problem is the entanglement between the
source label distribution and the model prediction. In this paper, we focus on
disentangling the source label distribution from the model prediction. We first
introduce a simple but overlooked baseline method that matches the target label
distribution by post-processing the model prediction trained by the
cross-entropy loss and the Softmax function. Although this method surpasses
state-of-the-art methods on benchmark datasets, it can be further improved by
directly disentangling the source label distribution from the model prediction
in the training phase. Thus, we propose a novel method, LAbel distribution
DisEntangling (LADE) loss based on the optimal bound of Donsker-Varadhan
representation. LADE achieves state-of-the-art performance on benchmark
datasets such as CIFAR-100-LT, Places-LT, ImageNet-LT, and iNaturalist 2018.
Moreover, LADE outperforms existing methods on various shifted target label
distributions, showing the general adaptability of our proposed method.
</dc:description>
 <dc:description>Comment: CVPR 2021</dc:description>
 <dc:date>2020-12-01</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.00321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.00461</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Anomaly Detection From Semantic Similarity Scores</dc:title>
 <dc:creator>Rafiee, Nima</dc:creator>
 <dc:creator>Gholamipoor, Rahil</dc:creator>
 <dc:creator>Kollmann, Markus</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Classifying samples as in-distribution or out-of-distribution (OOD) is a
challenging problem of anomaly detection and a strong test of the
generalisation power for models of the in-distribution. In this paper, we
present a simple and generic framework, {\it SemSAD}, that makes use of a
semantic similarity score to carry out anomaly detection. The idea is to first
find for any test example the semantically closest examples in the training
set, where the semantic relation between examples is quantified by the cosine
similarity between feature vectors that leave semantics unchanged under
transformations, such as geometric transformations (images), time shifts (audio
signals), and synonymous word substitutions (text). A trained discriminator is
then used to classify a test example as OOD if the semantic similarity to its
nearest neighbours is significantly lower than the corresponding similarity for
test examples from the in-distribution. We are able to outperform previous
approaches for anomaly, novelty, or out-of-distribution detection in the visual
domain by a large margin. In particular, we obtain AUROC values close to one
for the challenging task of detecting examples from CIFAR-10 as
out-of-distribution given CIFAR-100 as in-distribution, without making use of
label information.
</dc:description>
 <dc:description>Comment: The reported AUROC values are wrong due to an implementation error.
  In short, there was information leakage by Batch Normalisation during
  training the discriminator</dc:description>
 <dc:date>2020-12-01</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.00461</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.00825</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Study of Checkpointing in Large Scale Training of Deep Neural Networks</dc:title>
 <dc:creator>Rojas, Elvis</dc:creator>
 <dc:creator>Kahira, Albert Njoroge</dc:creator>
 <dc:creator>Meneses, Esteban</dc:creator>
 <dc:creator>Gomez, Leonardo Bautista</dc:creator>
 <dc:creator>Badia, Rosa M</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Deep learning (DL) applications are increasingly being deployed on HPC
systems, to leverage the massive parallelism and computing power of those
systems for DL model training. While significant effort has been put to
facilitate distributed training by DL frameworks, fault tolerance has been
largely ignored. In this work, we evaluate checkpoint-restart, a common fault
tolerance technique in HPC workloads. We perform experiments with three
state-of-the-art DL frameworks common in HPC Chainer, PyTorch, and TensorFlow).
We evaluate the computational cost of checkpointing, file formats and file
sizes, the impact of scale, and deterministic checkpointing. Our evaluation
shows some critical differences in checkpoint mechanisms and exposes several
bottlenecks in existing checkpointing implementations. We provide discussion
points that can aid users in selecting a fault-tolerant framework to use in
HPC. We also provide takeaway points that framework developers can use to
facilitate better checkpointing of DL workloads in HPC.
</dc:description>
 <dc:date>2020-12-01</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.00825</dc:identifier>
 <dc:identifier>2020 International Conference on High Performance Computing &amp;
  Simulation (HPCS20)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.01158</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Single-Shot Freestyle Dance Reenactment</dc:title>
 <dc:creator>Gafni, Oran</dc:creator>
 <dc:creator>Ashual, Oron</dc:creator>
 <dc:creator>Wolf, Lior</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The task of motion transfer between a source dancer and a target person is a
special case of the pose transfer problem, in which the target person changes
their pose in accordance with the motions of the dancer.
  In this work, we propose a novel method that can reanimate a single image by
arbitrary video sequences, unseen during training. The method combines three
networks: (i) a segmentation-mapping network, (ii) a realistic frame-rendering
network, and (iii) a face refinement network. By separating this task into
three stages, we are able to attain a novel sequence of realistic frames,
capturing natural motion and appearance. Our method obtains significantly
better visual quality than previous methods and is able to animate diverse body
types and appearances, which are captured in challenging poses, as shown in the
experiments and supplementary video.
</dc:description>
 <dc:date>2020-12-02</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.01158</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.01405</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning View-Disentangled Human Pose Representation by Contrastive
  Cross-View Mutual Information Maximization</dc:title>
 <dc:creator>Zhao, Long</dc:creator>
 <dc:creator>Wang, Yuxiao</dc:creator>
 <dc:creator>Zhao, Jiaping</dc:creator>
 <dc:creator>Yuan, Liangzhe</dc:creator>
 <dc:creator>Sun, Jennifer J.</dc:creator>
 <dc:creator>Schroff, Florian</dc:creator>
 <dc:creator>Adam, Hartwig</dc:creator>
 <dc:creator>Peng, Xi</dc:creator>
 <dc:creator>Metaxas, Dimitris</dc:creator>
 <dc:creator>Liu, Ting</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce a novel representation learning method to disentangle
pose-dependent as well as view-dependent factors from 2D human poses. The
method trains a network using cross-view mutual information maximization
(CV-MIM) which maximizes mutual information of the same pose performed from
different viewpoints in a contrastive learning manner. We further propose two
regularization terms to ensure disentanglement and smoothness of the learned
representations. The resulting pose representations can be used for cross-view
action recognition. To evaluate the power of the learned representations, in
addition to the conventional fully-supervised action recognition settings, we
introduce a novel task called single-shot cross-view action recognition. This
task trains models with actions from only one single viewpoint while models are
evaluated on poses captured from all possible viewpoints. We evaluate the
learned representations on standard benchmarks for action recognition, and show
that (i) CV-MIM performs competitively compared with the state-of-the-art
models in the fully-supervised scenarios; (ii) CV-MIM outperforms other
competing methods by a large margin in the single-shot cross-view setting;
(iii) and the learned representations can significantly boost the performance
when reducing the amount of supervised training data. Our code is made publicly
available at
https://github.com/google-research/google-research/tree/master/poem
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2021 (Oral presentation). Code is available at
  https://github.com/google-research/google-research/tree/master/poem</dc:description>
 <dc:date>2020-12-02</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.01405</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.01793</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-Supervised Learning with Variational Bayesian Inference and Maximum
  Uncertainty Regularization</dc:title>
 <dc:creator>Do, Kien</dc:creator>
 <dc:creator>Tran, Truyen</dc:creator>
 <dc:creator>Venkatesh, Svetha</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We propose two generic methods for improving semi-supervised learning (SSL).
The first integrates weight perturbation (WP) into existing &quot;consistency
regularization&quot; (CR) based methods. We implement WP by leveraging variational
Bayesian inference (VBI). The second method proposes a novel consistency loss
called &quot;maximum uncertainty regularization&quot; (MUR). While most consistency
losses act on perturbations in the vicinity of each data point, MUR actively
searches for &quot;virtual&quot; points situated beyond this region that cause the most
uncertain class predictions. This allows MUR to impose smoothness on a wider
area in the input-output manifold. Our experiments show clear improvements in
classification errors of various CR based methods when they are combined with
VBI or MUR or both.
</dc:description>
 <dc:description>Comment: Accepted to AAAI 2021</dc:description>
 <dc:date>2020-12-03</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.01793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.01909</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Patch2Pix: Epipolar-Guided Pixel-Level Correspondences</dc:title>
 <dc:creator>Zhou, Qunjie</dc:creator>
 <dc:creator>Sattler, Torsten</dc:creator>
 <dc:creator>Leal-Taixe, Laura</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The classical matching pipeline used for visual localization typically
involves three steps: (i) local feature detection and description, (ii) feature
matching, and (iii) outlier rejection. Recently emerged correspondence networks
propose to perform those steps inside a single network but suffer from low
matching resolution due to the memory bottleneck. In this work, we propose a
new perspective to estimate correspondences in a detect-to-refine manner, where
we first predict patch-level match proposals and then refine them. We present
Patch2Pix, a novel refinement network that refines match proposals by
regressing pixel-level matches from the local regions defined by those
proposals and jointly rejecting outlier matches with confidence scores.
Patch2Pix is weakly supervised to learn correspondences that are consistent
with the epipolar geometry of an input image pair. We show that our refinement
network significantly improves the performance of correspondence networks on
image matching, homography estimation, and localization tasks. In addition, we
show that our learned refinement generalizes to fully-supervised methods
without re-training, which leads us to state-of-the-art localization
performance. The code is available at https://github.com/GrumpyZhou/patch2pix.
</dc:description>
 <dc:description>Comment: CVPR2021 Camera Ready Version</dc:description>
 <dc:date>2020-12-03</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.01909</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.01942</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Clustering-based Automatic Construction of Legal Entity Knowledge Base
  from Contracts</dc:title>
 <dc:creator>Song, Fuqi</dc:creator>
 <dc:creator>de la Clergerie, &#xc9;ric</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In contract analysis and contract automation, a knowledge base (KB) of legal
entities is fundamental for performing tasks such as contract verification,
contract generation and contract analytic. However, such a KB does not always
exist nor can be produced in a short time. In this paper, we propose a
clustering-based approach to automatically generate a reliable knowledge base
of legal entities from given contracts without any supplemental references. The
proposed method is robust to different types of errors brought by
pre-processing such as Optical Character Recognition (OCR) and Named Entity
Recognition (NER), as well as editing errors such as typos. We evaluate our
method on a dataset that consists of 800 real contracts with various qualities
from 15 clients. Compared to the collected ground-truth data, our method is
able to recall 84\% of the knowledge.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures</dc:description>
 <dc:date>2020-11-18</dc:date>
 <dc:date>2020-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.01942</dc:identifier>
 <dc:identifier>doi:10.1109/BigData50022.2020.9378166</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.02148</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph-SIM: A Graph-based Spatiotemporal Interaction Modelling for
  Pedestrian Action Prediction</dc:title>
 <dc:creator>Yau, Tiffany</dc:creator>
 <dc:creator>Malekmohammadi, Saber</dc:creator>
 <dc:creator>Rasouli, Amir</dc:creator>
 <dc:creator>Lakner, Peter</dc:creator>
 <dc:creator>Rohani, Mohsen</dc:creator>
 <dc:creator>Luo, Jun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  One of the most crucial yet challenging tasks for autonomous vehicles in
urban environments is predicting the future behaviour of nearby pedestrians,
especially at points of crossing. Predicting behaviour depends on many social
and environmental factors, particularly interactions between road users.
Capturing such interactions requires a global view of the scene and dynamics of
the road users in three-dimensional space. This information, however, is
missing from the current pedestrian behaviour benchmark datasets. Motivated by
these challenges, we propose 1) a novel graph-based model for predicting
pedestrian crossing action. Our method models pedestrians' interactions with
nearby road users through clustering and relative importance weighting of
interactions using features obtained from the bird's-eye-view. 2) We introduce
a new dataset that provides 3D bounding box and pedestrian behavioural
annotations for the existing nuScenes dataset. On the new data, our approach
achieves state-of-the-art performance by improving on various metrics by more
than 15% in comparison to existing methods. The dataset is available at
https://github.com/huawei-noah/datasets/PePScenes.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures, 4 tables, accepted at ICRA 2021</dc:description>
 <dc:date>2020-12-03</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.02148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.02174</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Text-to-speech for the hearing impaired</dc:title>
 <dc:creator>Schlittenlacher, Josef</dc:creator>
 <dc:creator>Baer, Thomas</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Text-to-speech (TTS) systems offer the opportunity to compensate for a
hearing loss at the source rather than correcting for it at the receiving end.
This removes limitations such as time constraints for algorithms that amplify a
sound in a hearing aid and can lead to higher speech quality. We propose an
algorithm that restores loudness to normal perception at a high resolution in
time, frequency and level, and embed it in a TTS system that uses Tacotron2 and
WaveGlow to produce individually amplified speech. Subjective evaluations of
speech quality showed that the proposed algorithm led to high-quality audio
with sound quality similar to original or linearly amplified speech but
considerably higher speech intelligibility in noise. Transfer learning led to a
quick adaptation of the produced spectra from original speech to individually
amplified speech, resulted in high speech quality and intelligibility, and thus
gives us a way to train an individual TTS system efficiently.
</dc:description>
 <dc:date>2020-12-03</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.02174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.02189</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learned Initializations for Optimizing Coordinate-Based Neural
  Representations</dc:title>
 <dc:creator>Tancik, Matthew</dc:creator>
 <dc:creator>Mildenhall, Ben</dc:creator>
 <dc:creator>Wang, Terrance</dc:creator>
 <dc:creator>Schmidt, Divi</dc:creator>
 <dc:creator>Srinivasan, Pratul P.</dc:creator>
 <dc:creator>Barron, Jonathan T.</dc:creator>
 <dc:creator>Ng, Ren</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Coordinate-based neural representations have shown significant promise as an
alternative to discrete, array-based representations for complex low
dimensional signals. However, optimizing a coordinate-based network from
randomly initialized weights for each new signal is inefficient. We propose
applying standard meta-learning algorithms to learn the initial weight
parameters for these fully-connected networks based on the underlying class of
signals being represented (e.g., images of faces or 3D models of chairs).
Despite requiring only a minor change in implementation, using these learned
initial weights enables faster convergence during optimization and can serve as
a strong prior over the signal class being modeled, resulting in better
generalization when only partial observations of a given signal are available.
We explore these benefits across a variety of tasks, including representing 2D
images, reconstructing CT scans, and recovering 3D shapes and scenes from 2D
image observations.
</dc:description>
 <dc:description>Comment: Project page: https://www.matthewtancik.com/learnit</dc:description>
 <dc:date>2020-12-03</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.02189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.02216</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Light Euclidean Steiner Spanners in the Plane</dc:title>
 <dc:creator>Bhore, Sujoy</dc:creator>
 <dc:creator>T&#xf3;th, Csaba D.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Lightness is a fundamental parameter for Euclidean spanners; it is the ratio
of the spanner weight to the weight of the minimum spanning tree of a finite
set of points in $\mathbb{R}^d$. In a recent breakthrough, Le and Solomon
(2019) established the precise dependencies on $\varepsilon&gt;0$ and $d\in
\mathbb{N}$ of the minimum lightness of $(1+\varepsilon)$-spanners, and
observed that additional Steiner points can substantially improve the
lightness. Le and Solomon (2020) constructed Steiner $(1+\varepsilon)$-spanners
of lightness $O(\varepsilon^{-1}\log\Delta)$ in the plane, where $\Delta\geq
\Omega(\sqrt{n})$ is the \emph{spread} of the point set, defined as the ratio
between the maximum and minimum distance between a pair of points. They also
constructed spanners of lightness $\tilde{O}(\varepsilon^{-(d+1)/2})$ in
dimensions $d\geq 3$. Recently, Bhore and T\'{o}th (2020) established a lower
bound of $\Omega(\varepsilon^{-d/2})$ for the lightness of Steiner
$(1+\varepsilon)$-spanners in $\mathbb{R}^d$, for $d\ge 2$. The central open
problem in this area is to close the gap between the lower and upper bounds in
all dimensions $d\geq 2$.
  In this work, we show that for every finite set of points in the plane and
every $\varepsilon&gt;0$, there exists a Euclidean Steiner
$(1+\varepsilon)$-spanner of lightness $O(\varepsilon^{-1})$; this matches the
lower bound for $d=2$. We generalize the notion of shallow light trees, which
may be of independent interest, and use directional spanners and a modified
window partitioning scheme to achieve a tight weight analysis.
</dc:description>
 <dc:description>Comment: 29 pages, 14 figures. A 17-page extended abstract will appear in the
  Proceedings of the 37th International Symposium on Computational Geometry</dc:description>
 <dc:date>2020-12-03</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.02216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.02333</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CutQC: Using Small Quantum Computers for Large Quantum Circuit
  Evaluations</dc:title>
 <dc:creator>Tang, Wei</dc:creator>
 <dc:creator>Tomesh, Teague</dc:creator>
 <dc:creator>Suchara, Martin</dc:creator>
 <dc:creator>Larson, Jeffrey</dc:creator>
 <dc:creator>Martonosi, Margaret</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Quantum computing (QC) is a new paradigm offering the potential of
exponential speedups over classical computing for certain computational
problems. Each additional qubit doubles the size of the computational state
space available to a QC algorithm. This exponential scaling underlies QC's
power, but today's Noisy Intermediate-Scale Quantum (NISQ) devices face
significant engineering challenges in scalability. The set of quantum circuits
that can be reliably run on NISQ devices is limited by their noisy operations
and low qubit counts.
  This paper introduces CutQC, a scalable hybrid computing approach that
combines classical computers and quantum computers to enable evaluation of
quantum circuits that cannot be run on classical or quantum computers alone.
CutQC cuts large quantum circuits into smaller subcircuits, allowing them to be
executed on smaller quantum devices. Classical postprocessing can then
reconstruct the output of the original circuit. This approach offers
significant runtime speedup compared with the only viable current
alternative--purely classical simulations--and demonstrates evaluation of
quantum circuits that are larger than the limit of QC or classical simulation.
Furthermore, in real-system runs, CutQC achieves much higher quantum circuit
evaluation fidelity using small prototype quantum computers than the
state-of-the-art large NISQ devices achieve. Overall, this hybrid approach
allows users to leverage classical and quantum computing resources to evaluate
quantum programs far beyond the reach of either one alone.
</dc:description>
 <dc:description>Comment: 14 pages, 12 figures, In Proceedings of the 26th ACM International
  Conference on Architectural Support for Programming Languages and Operating
  Systems (ASPLOS '21), April 19-23, 2021, Virtual, USA. ACM, New York, NY, USA</dc:description>
 <dc:date>2020-12-03</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.02333</dc:identifier>
 <dc:identifier>doi:10.1145/3445814.3446758</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.02423</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constrained Risk-Averse Markov Decision Processes</dc:title>
 <dc:creator>Ahmadi, Mohamadreza</dc:creator>
 <dc:creator>Rosolia, Ugo</dc:creator>
 <dc:creator>Ingham, Michel D.</dc:creator>
 <dc:creator>Murray, Richard M.</dc:creator>
 <dc:creator>Ames, Aaron D.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We consider the problem of designing policies for Markov decision processes
(MDPs) with dynamic coherent risk objectives and constraints. We begin by
formulating the problem in a Lagrangian framework. Under the assumption that
the risk objectives and constraints can be represented by a Markov risk
transition mapping, we propose an optimization-based method to synthesize
Markovian policies that lower-bound the constrained risk-averse problem. We
demonstrate that the formulated optimization problems are in the form of
difference convex programs (DCPs) and can be solved by the disciplined
convex-concave programming (DCCP) framework. We show that these results
generalize linear programs for constrained MDPs with total discounted expected
costs and constraints. Finally, we illustrate the effectiveness of the proposed
method with numerical experiments on a rover navigation problem involving
conditional-value-at-risk (CVaR) and entropic-value-at-risk (EVaR) coherent
risk measures.
</dc:description>
 <dc:description>Comment: Draft Accepted for Presentation at The Thirty-Fifth AAAI Conference
  on Artificial Intelligence (AAAI-21), Feb. 2-9, 2021</dc:description>
 <dc:date>2020-12-04</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.02423</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.02818</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Encoding the latent posterior of Bayesian Neural Networks for
  uncertainty quantification</dc:title>
 <dc:creator>Franchi, Gianni</dc:creator>
 <dc:creator>Bursuc, Andrei</dc:creator>
 <dc:creator>Aldea, Emanuel</dc:creator>
 <dc:creator>Dubuisson, Severine</dc:creator>
 <dc:creator>Bloch, Isabelle</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Bayesian neural networks (BNNs) have been long considered an ideal, yet
unscalable solution for improving the robustness and the predictive uncertainty
of deep neural networks. While they could capture more accurately the posterior
distribution of the network parameters, most BNN approaches are either limited
to small networks or rely on constraining assumptions such as parameter
independence. These drawbacks have enabled prominence of simple, but
computationally heavy approaches such as Deep Ensembles, whose training and
testing costs increase linearly with the number of networks. In this work we
aim for efficient deep BNNs amenable to complex computer vision architectures,
e.g. ResNet50 DeepLabV3+, and tasks, e.g. semantic segmentation, with fewer
assumptions on the parameters. We achieve this by leveraging variational
autoencoders (VAEs) to learn the interaction and the latent distribution of the
parameters at each network layer. Our approach, Latent-Posterior BNN (LP-BNN),
is compatible with the recent BatchEnsemble method, leading to highly efficient
({in terms of computation and} memory during both training and testing)
ensembles. LP-BNN s attain competitive results across multiple metrics in
several challenging benchmarks for image classification, semantic segmentation
and out-of-distribution detection.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2020-12-04</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.02818</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.02907</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Depth estimation on embedded computers for robot swarms in forest</dc:title>
 <dc:creator>Niu, Chaoyue</dc:creator>
 <dc:creator>Tarapore, Danesh</dc:creator>
 <dc:creator>Zauner, Klaus-Peter</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Robot swarms to date are not prepared for autonomous navigation such as path
planning and obstacle detection in forest floor, unable to achieve low-cost.
The development of depth sensing and embedded computing hardware paves the way
for swarm of terrestrial robots. The goal of this research is to improve this
situation by developing low cost vision system for small ground robots to
rapidly perceive terrain. We develop two depth estimation models and evaluate
their performance on Raspberry Pi 4 and Jetson Nano in terms of accuracy,
runtime and model size of depth estimation models, as well as memory
consumption, power draw, temperature, and cost of above two embedded on-board
computers. Our research demonstrated that auto-encoder network deployed on
Raspberry Pi 4 runs at a power consumption of 3.4 W, memory consumption of
about 200 MB, and mean runtime of 13 ms. This can be to meet our requirement
for low-cost swarm of robots. Moreover, our analysis also indicated multi-scale
deep network performs better for predicting depth map from blurred RGB images
caused by camera motion. This paper mainly describes depth estimation models
trained on our own dataset recorded in forest, and their performance on
embedded on-board computers.
</dc:description>
 <dc:description>Comment: the depth estimation models cannot perform well in a forest</dc:description>
 <dc:date>2020-12-04</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.02907</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.03021</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Depth estimation from 4D light field videos</dc:title>
 <dc:creator>Kinoshita, Takahiro</dc:creator>
 <dc:creator>Ono, Satoshi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Depth (disparity) estimation from 4D Light Field (LF) images has been a
research topic for the last couple of years. Most studies have focused on depth
estimation from static 4D LF images while not considering temporal information,
i.e., LF videos. This paper proposes an end-to-end neural network architecture
for depth estimation from 4D LF videos. This study also constructs a
medium-scale synthetic 4D LF video dataset that can be used for training deep
learning-based methods. Experimental results using synthetic and real-world 4D
LF videos show that temporal information contributes to the improvement of
depth estimation accuracy in noisy regions. Dataset and code is available at:
https://mediaeng-lfv.github.io/LFV_Disparity_Estimation
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures, International Workshop on Advanced Image
  Technology (IWAIT) 2021</dc:description>
 <dc:date>2020-12-05</dc:date>
 <dc:date>2020-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.03021</dc:identifier>
 <dc:identifier>doi:10.1117/12.2591012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.03023</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Volumetric Occupancy Mapping With Probabilistic Depth Completion for
  Robotic Navigation</dc:title>
 <dc:creator>Popovic, Marija</dc:creator>
 <dc:creator>Thomas, Florian</dc:creator>
 <dc:creator>Papatheodorou, Sotiris</dc:creator>
 <dc:creator>Funk, Nils</dc:creator>
 <dc:creator>Vidal-Calleja, Teresa</dc:creator>
 <dc:creator>Leutenegger, Stefan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In robotic applications, a key requirement for safe and efficient motion
planning is the ability to map obstacle-free space in unknown, cluttered 3D
environments. However, commodity-grade RGB-D cameras commonly used for sensing
fail to register valid depth values on shiny, glossy, bright, or distant
surfaces, leading to missing data in the map. To address this issue, we propose
a framework leveraging probabilistic depth completion as an additional input
for spatial mapping. We introduce a deep learning architecture providing
uncertainty estimates for the depth completion of RGB-D images. Our pipeline
exploits the inferred missing depth values and depth uncertainty to complement
raw depth images and improve the speed and quality of free space mapping.
Evaluations on synthetic data show that our approach maps significantly more
correct free space with relatively low error when compared against using raw
data alone in different indoor environments; thereby producing more complete
maps that can be directly used for robotic navigation tasks. The performance of
our framework is validated using real-world data.
</dc:description>
 <dc:description>Comment: 8 pages, 10 figures, submission to IEEE Robotics and Automation
  Letters (revised)</dc:description>
 <dc:date>2020-12-05</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.03023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.03242</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Esophageal Tumor Segmentation in CT Images using Dilated Dense Attention
  Unet (DDAUnet)</dc:title>
 <dc:creator>Yousefi, Sahar</dc:creator>
 <dc:creator>Sokooti, Hessam</dc:creator>
 <dc:creator>Elmahdy, Mohamed S.</dc:creator>
 <dc:creator>Lips, Irene M.</dc:creator>
 <dc:creator>Shalmani, Mohammad T. Manzuri</dc:creator>
 <dc:creator>Zinkstok, Roel T.</dc:creator>
 <dc:creator>Dankers, Frank J. W. M.</dc:creator>
 <dc:creator>Staring, Marius</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Manual or automatic delineation of the esophageal tumor in CT images is known
to be very challenging. This is due to the low contrast between the tumor and
adjacent tissues, the anatomical variation of the esophagus, as well as the
occasional presence of foreign bodies (e.g. feeding tubes). Physicians
therefore usually exploit additional knowledge such as endoscopic findings,
clinical history, additional imaging modalities like PET scans. Achieving his
additional information is time-consuming, while the results are error-prone and
might lead to non-deterministic results. In this paper we aim to investigate if
and to what extent a simplified clinical workflow based on CT alone, allows one
to automatically segment the esophageal tumor with sufficient quality. For this
purpose, we present a fully automatic end-to-end esophageal tumor segmentation
method based on convolutional neural networks (CNNs). The proposed network,
called Dilated Dense Attention Unet (DDAUnet), leverages spatial and channel
attention gates in each dense block to selectively concentrate on determinant
feature maps and regions. Dilated convolutional layers are used to manage GPU
memory and increase the network receptive field. We collected a dataset of 792
scans from 288 distinct patients including varying anatomies with \mbox{air
pockets}, feeding tubes and proximal tumors. Repeatability and reproducibility
studies were conducted for three distinct splits of training and validation
sets. The proposed network achieved a $\mathrm{DSC}$ value of $0.79 \pm 0.20$,
a mean surface distance of $5.4 \pm 20.2mm$ and $95\%$ Hausdorff distance of
$14.7 \pm 25.0mm$ for 287 test scans, demonstrating promising results with a
simplified clinical workflow based on CT alone. Our code is publicly available
via \url{https://github.com/yousefis/DenseUnet_Esophagus_Segmentation}.
</dc:description>
 <dc:date>2020-12-06</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.03242</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.03308</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TediGAN: Text-Guided Diverse Face Image Generation and Manipulation</dc:title>
 <dc:creator>Xia, Weihao</dc:creator>
 <dc:creator>Yang, Yujiu</dc:creator>
 <dc:creator>Xue, Jing-Hao</dc:creator>
 <dc:creator>Wu, Baoyuan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  In this work, we propose TediGAN, a novel framework for multi-modal image
generation and manipulation with textual descriptions. The proposed method
consists of three components: StyleGAN inversion module, visual-linguistic
similarity learning, and instance-level optimization. The inversion module maps
real images to the latent space of a well-trained StyleGAN. The
visual-linguistic similarity learns the text-image matching by mapping the
image and text into a common embedding space. The instance-level optimization
is for identity preservation in manipulation. Our model can produce diverse and
high-quality images with an unprecedented resolution at 1024. Using a control
mechanism based on style-mixing, our TediGAN inherently supports image
synthesis with multi-modal inputs, such as sketches or semantic labels, with or
without instance guidance. To facilitate text-guided multi-modal synthesis, we
propose the Multi-Modal CelebA-HQ, a large-scale dataset consisting of real
face images and corresponding semantic segmentation map, sketch, and textual
descriptions. Extensive experiments on the introduced dataset demonstrate the
superior performance of our proposed method. Code and data are available at
https://github.com/weihaox/TediGAN.
</dc:description>
 <dc:description>Comment: CVPR 2021. Code: https://github.com/weihaox/TediGAN Data:
  https://github.com/weihaox/Multi-Modal-CelebA-HQ Video:
  https://youtu.be/L8Na2f5viAM</dc:description>
 <dc:date>2020-12-06</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.03308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.03544</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-End Object Detection with Fully Convolutional Network</dc:title>
 <dc:creator>Wang, Jianfeng</dc:creator>
 <dc:creator>Song, Lin</dc:creator>
 <dc:creator>Li, Zeming</dc:creator>
 <dc:creator>Sun, Hongbin</dc:creator>
 <dc:creator>Sun, Jian</dc:creator>
 <dc:creator>Zheng, Nanning</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Mainstream object detectors based on the fully convolutional network has
achieved impressive performance. While most of them still need a hand-designed
non-maximum suppression (NMS) post-processing, which impedes fully end-to-end
training. In this paper, we give the analysis of discarding NMS, where the
results reveal that a proper label assignment plays a crucial role. To this
end, for fully convolutional detectors, we introduce a Prediction-aware
One-To-One (POTO) label assignment for classification to enable end-to-end
detection, which obtains comparable performance with NMS. Besides, a simple 3D
Max Filtering (3DMF) is proposed to utilize the multi-scale features and
improve the discriminability of convolutions in the local region. With these
techniques, our end-to-end framework achieves competitive performance against
many state-of-the-art detectors with NMS on COCO and CrowdHuman datasets. The
code is available at https://github.com/Megvii-BaseDetection/DeFCN .
</dc:description>
 <dc:description>Comment: Accepted to CVPR2021</dc:description>
 <dc:date>2020-12-07</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.03544</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.03662</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Confidence-aware Non-repetitive Multimodal Transformers for TextCaps</dc:title>
 <dc:creator>Wang, Zhaokai</dc:creator>
 <dc:creator>Bao, Renda</dc:creator>
 <dc:creator>Wu, Qi</dc:creator>
 <dc:creator>Liu, Si</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  When describing an image, reading text in the visual scene is crucial to
understand the key information. Recent work explores the TextCaps task, i.e.
image captioning with reading Optical Character Recognition (OCR) tokens, which
requires models to read text and cover them in generated captions. Existing
approaches fail to generate accurate descriptions because of their (1) poor
reading ability; (2) inability to choose the crucial words among all extracted
OCR tokens; (3) repetition of words in predicted captions. To this end, we
propose a Confidence-aware Non-repetitive Multimodal Transformers (CNMT) to
tackle the above challenges. Our CNMT consists of a reading, a reasoning and a
generation modules, in which Reading Module employs better OCR systems to
enhance text reading ability and a confidence embedding to select the most
noteworthy tokens. To address the issue of word redundancy in captions, our
Generation Module includes a repetition mask to avoid predicting repeated word
in captions. Our model outperforms state-of-the-art models on TextCaps dataset,
improving from 81.0 to 93.0 in CIDEr. Our source code is publicly available.
</dc:description>
 <dc:description>Comment: 9 pages; Accepted by AAAI 2021</dc:description>
 <dc:date>2020-12-07</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.03662</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.03663</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Metric Learning-based Image Retrieval System for Chest Radiograph
  and its Clinical Applications in COVID-19</dc:title>
 <dc:creator>Zhong, Aoxiao</dc:creator>
 <dc:creator>Li, Xiang</dc:creator>
 <dc:creator>Wu, Dufan</dc:creator>
 <dc:creator>Ren, Hui</dc:creator>
 <dc:creator>Kim, Kyungsang</dc:creator>
 <dc:creator>Kim, Younggon</dc:creator>
 <dc:creator>Buch, Varun</dc:creator>
 <dc:creator>Neumark, Nir</dc:creator>
 <dc:creator>Bizzo, Bernardo</dc:creator>
 <dc:creator>Tak, Won Young</dc:creator>
 <dc:creator>Park, Soo Young</dc:creator>
 <dc:creator>Lee, Yu Rim</dc:creator>
 <dc:creator>Kang, Min Kyu</dc:creator>
 <dc:creator>Park, Jung Gil</dc:creator>
 <dc:creator>Kim, Byung Seok</dc:creator>
 <dc:creator>Chung, Woo Jin</dc:creator>
 <dc:creator>Guo, Ning</dc:creator>
 <dc:creator>Dayan, Ittai</dc:creator>
 <dc:creator>Kalra, Mannudeep K.</dc:creator>
 <dc:creator>Li, Quanzheng</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In recent years, deep learning-based image analysis methods have been widely
applied in computer-aided detection, diagnosis and prognosis, and has shown its
value during the public health crisis of the novel coronavirus disease 2019
(COVID-19) pandemic. Chest radiograph (CXR) has been playing a crucial role in
COVID-19 patient triaging, diagnosing and monitoring, particularly in the
United States. Considering the mixed and unspecific signals in CXR, an image
retrieval model of CXR that provides both similar images and associated
clinical information can be more clinically meaningful than a direct image
diagnostic model. In this work we develop a novel CXR image retrieval model
based on deep metric learning. Unlike traditional diagnostic models which aims
at learning the direct mapping from images to labels, the proposed model aims
at learning the optimized embedding space of images, where images with the same
labels and similar contents are pulled together. It utilizes multi-similarity
loss with hard-mining sampling strategy and attention mechanism to learn the
optimized embedding space, and provides similar images to the query image. The
model is trained and validated on an international multi-site COVID-19 dataset
collected from 3 different sources. Experimental results of COVID-19 image
retrieval and diagnosis tasks show that the proposed model can serve as a
robust solution for CXR analysis and patient management for COVID-19. The model
is also tested on its transferability on a different clinical decision support
task, where the pre-trained model is applied to extract image features from a
new dataset without any further training. These results demonstrate our deep
metric learning based image retrieval model is highly efficient in the CXR
retrieval, diagnosis and prognosis, and thus has great clinical value for the
treatment and management of COVID-19 patients.
</dc:description>
 <dc:description>Comment: Aoxiao Zhong and Xiang Li contribute equally to this work</dc:description>
 <dc:date>2020-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.03663</dc:identifier>
 <dc:identifier>Medical Image Analysis. 70 (2021) 101993</dc:identifier>
 <dc:identifier>doi:10.1016/j.media.2021.101993</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.03768</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Tactile Models for Factor Graph-based Estimation</dc:title>
 <dc:creator>Sodhi, Paloma</dc:creator>
 <dc:creator>Kaess, Michael</dc:creator>
 <dc:creator>Mukadam, Mustafa</dc:creator>
 <dc:creator>Anderson, Stuart</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We're interested in the problem of estimating object states from touch during
manipulation under occlusions. In this work, we address the problem of
estimating object poses from touch during planar pushing. Vision-based tactile
sensors provide rich, local image measurements at the point of contact. A
single such measurement, however, contains limited information and multiple
measurements are needed to infer latent object state. We solve this inference
problem using a factor graph. In order to incorporate tactile measurements in
the graph, we need local observation models that can map high-dimensional
tactile images onto a low-dimensional state space. Prior work has used
low-dimensional force measurements or engineered functions to interpret tactile
measurements. These methods, however, can be brittle and difficult to scale
across objects and sensors. Our key insight is to directly learn tactile
observation models that predict the relative pose of the sensor given a pair of
tactile images. These relative poses can then be incorporated as factors within
a factor graph. We propose a two-stage approach: first we learn local tactile
observation models supervised with ground truth data, and then integrate these
models along with physics and geometric factors within a factor graph
optimizer. We demonstrate reliable object tracking using only tactile feedback
for 150 real-world planar pushing sequences with varying trajectories across
three object shapes. Supplementary video: https://youtu.be/y1kBfSmi8w0
</dc:description>
 <dc:description>Comment: Accepted to ICRA 2021</dc:description>
 <dc:date>2020-12-07</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.03768</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.04327</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Settling the complexity of Nash equilibrium in congestion games</dc:title>
 <dc:creator>Babichenko, Yakov</dc:creator>
 <dc:creator>Rubinstein, Aviad</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We consider (i) the problem of finding a (possibly mixed) Nash equilibrium in
congestion games, and (ii) the problem of finding an (exponential precision)
fixed point of the gradient descent dynamics of a smooth function $f:[0,1]^n
\rightarrow \mathbb{R}$. We prove that these problems are equivalent. Our
result holds for various explicit descriptions of $f$, ranging from (almost
general) arithmetic circuits, to degree-$5$ polynomials. By a very recent
result of [Fearnley, Goldberg, Hollender, Savani '20] this implies that these
problems are PPAD$\cap$PLS-complete. As a corollary, we also obtain the
following equivalence of complexity classes: CCLS = PPAD$\cap$PLS.
</dc:description>
 <dc:date>2020-12-08</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.04327</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.04381</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep learning for clustering of continuous gravitational wave candidates
  II: identification of low-SNR candidates</dc:title>
 <dc:creator>Beheshtipour, Banafsheh</dc:creator>
 <dc:creator>Papa, Maria Alessandra</dc:creator>
 <dc:subject>General Relativity and Quantum Cosmology</dc:subject>
 <dc:subject>Astrophysics - High Energy Astrophysical Phenomena</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Broad searches for continuous gravitational wave signals rely on hierarchies
of follow-up stages for candidates above a given significance threshold. An
important step to simplify these follow-ups and reduce the computational cost
is to bundle together in a single follow-up nearby candidates. This step is
called clustering and we investigate carrying it out with a deep learning
network. In our first paper [1], we implemented a deep learning clustering
network capable of correctly identifying clusters due to large signals. In this
paper, a network is implemented that can detect clusters due to much fainter
signals. These two networks are complementary and we show that a cascade of the
two networks achieves an excellent detection efficiency across a wide range of
signal strengths, with a false alarm rate comparable/lower than that of methods
currently in use.
</dc:description>
 <dc:date>2020-12-08</dc:date>
 <dc:date>2021-02-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.04381</dc:identifier>
 <dc:identifier>Phys. Rev. D 103, 064027 (2021)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevD.103.064027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.04512</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SSCNav: Confidence-Aware Semantic Scene Completion for Visual Semantic
  Navigation</dc:title>
 <dc:creator>Liang, Yiqing</dc:creator>
 <dc:creator>Chen, Boyuan</dc:creator>
 <dc:creator>Song, Shuran</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper focuses on visual semantic navigation, the task of producing
actions for an active agent to navigate to a specified target object category
in an unknown environment. To complete this task, the algorithm should
simultaneously locate and navigate to an instance of the category. In
comparison to the traditional point goal navigation, this task requires the
agent to have a stronger contextual prior to indoor environments. We introduce
SSCNav, an algorithm that explicitly models scene priors using a
confidence-aware semantic scene completion module to complete the scene and
guide the agent's navigation planning. Given a partial observation of the
environment, SSCNav first infers a complete scene representation with semantic
labels for the unobserved scene together with a confidence map associated with
its own prediction. Then, a policy network infers the action from the scene
completion result and confidence map. Our experiments demonstrate that the
proposed scene completion module improves the efficiency of the downstream
navigation policies. Video, code, and data: https://sscnav.cs.columbia.edu/
</dc:description>
 <dc:date>2020-12-08</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.04512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.04520</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Numerical analysis of a wave equation for lossy media obeying a
  frequency power law</dc:title>
 <dc:creator>Baker, Katherine</dc:creator>
 <dc:creator>Banjai, Lehel</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:description>  We study a wave equation with a nonlocal time fractional damping term that
models the effects of acoustic attenuation characterized by a frequency
dependence power law. First we prove existence of a unique solution to this
equation with particular attention paid to the handling of the fractional
derivative. Then we derive an explicit time stepping scheme based on the finite
element method in space and a combination of convolution quadrature and second
order central differences in time. We conduct a full error analysis of the
mixed time discretization and in turn the fully space time discretized scheme.
Error estimates are given for both smooth solutions and solutions with a
singularity at $t = 0$ of a type that is typical for equations involving
fractional time-derivatives. A number of numerical results are presented to
support the error analysis.
</dc:description>
 <dc:description>Comment: For code used in numerics see,
  https://github.com/bakerks/Szabos-fractional-wave-eqaution</dc:description>
 <dc:date>2020-12-08</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.04520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.04689</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Dataset and Application for Facial Recognition of Individual Gorillas
  in Zoo Environments</dc:title>
 <dc:creator>Brookes, Otto</dc:creator>
 <dc:creator>Burghardt, Tilo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We put forward a video dataset with 5k+ facial bounding box annotations
across a troop of 7 western lowland gorillas at Bristol Zoo Gardens. Training
on this dataset, we implement and evaluate a standard deep learning pipeline on
the task of facially recognising individual gorillas in a zoo environment. We
show that a basic YOLOv3-powered application is able to perform identifications
at 92% mAP when utilising single frames only. Tracking-by-detection-association
and identity voting across short tracklets yields an improved robust
performance of 97% mAP. To facilitate easy utilisation for enriching the
research capabilities of zoo environments, we publish the code, video dataset,
weights, and ground-truth annotations at data.bris.ac.uk.
</dc:description>
 <dc:date>2020-12-08</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.04689</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.04728</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Mechanics: Symmetry and Broken Conservation Laws in Deep Learning
  Dynamics</dc:title>
 <dc:creator>Kunin, Daniel</dc:creator>
 <dc:creator>Sagastuy-Brena, Javier</dc:creator>
 <dc:creator>Ganguli, Surya</dc:creator>
 <dc:creator>Yamins, Daniel L. K.</dc:creator>
 <dc:creator>Tanaka, Hidenori</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Understanding the dynamics of neural network parameters during training is
one of the key challenges in building a theoretical foundation for deep
learning. A central obstacle is that the motion of a network in
high-dimensional parameter space undergoes discrete finite steps along complex
stochastic gradients derived from real-world datasets. We circumvent this
obstacle through a unifying theoretical framework based on intrinsic symmetries
embedded in a network's architecture that are present for any dataset. We show
that any such symmetry imposes stringent geometric constraints on gradients and
Hessians, leading to an associated conservation law in the continuous-time
limit of stochastic gradient descent (SGD), akin to Noether's theorem in
physics. We further show that finite learning rates used in practice can
actually break these symmetry induced conservation laws. We apply tools from
finite difference methods to derive modified gradient flow, a differential
equation that better approximates the numerical trajectory taken by SGD at
finite learning rates. We combine modified gradient flow with our framework of
symmetries to derive exact integral expressions for the dynamics of certain
parameter combinations. We empirically validate our analytic expressions for
learning dynamics on VGG-16 trained on Tiny ImageNet. Overall, by exploiting
symmetry, our work demonstrates that we can analytically describe the learning
dynamics of various parameter combinations at finite learning rates and batch
sizes for state of the art architectures trained on any dataset.
</dc:description>
 <dc:description>Comment: 30 pages, 17 figures, ICLR 2021</dc:description>
 <dc:date>2020-12-08</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.04728</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.04781</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>You Only Need Adversarial Supervision for Semantic Image Synthesis</dc:title>
 <dc:creator>Sushko, Vadim</dc:creator>
 <dc:creator>Sch&#xf6;nfeld, Edgar</dc:creator>
 <dc:creator>Zhang, Dan</dc:creator>
 <dc:creator>Gall, Juergen</dc:creator>
 <dc:creator>Schiele, Bernt</dc:creator>
 <dc:creator>Khoreva, Anna</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Despite their recent successes, GAN models for semantic image synthesis still
suffer from poor image quality when trained with only adversarial supervision.
Historically, additionally employing the VGG-based perceptual loss has helped
to overcome this issue, significantly improving the synthesis quality, but at
the same time limiting the progress of GAN models for semantic image synthesis.
In this work, we propose a novel, simplified GAN model, which needs only
adversarial supervision to achieve high quality results. We re-design the
discriminator as a semantic segmentation network, directly using the given
semantic label maps as the ground truth for training. By providing stronger
supervision to the discriminator as well as to the generator through spatially-
and semantically-aware discriminator feedback, we are able to synthesize images
of higher fidelity with better alignment to their input label maps, making the
use of the perceptual loss superfluous. Moreover, we enable high-quality
multi-modal image synthesis through global and local sampling of a 3D noise
tensor injected into the generator, which allows complete or partial image
change. We show that images synthesized by our model are more diverse and
follow the color and texture distributions of real images more closely. We
achieve an average improvement of $6$ FID and $5$ mIoU points over the state of
the art across different datasets using only adversarial supervision.
</dc:description>
 <dc:description>Comment: Published at ICLR 2021 (Main Conference). Code repository:
  https://github.com/boschresearch/OASIS</dc:description>
 <dc:date>2020-12-08</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.04781</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.04832</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proactive Interaction Framework for Intelligent Social Receptionist
  Robots</dc:title>
 <dc:creator>Xue, Yang</dc:creator>
 <dc:creator>Wang, Fan</dc:creator>
 <dc:creator>Tian, Hao</dc:creator>
 <dc:creator>Zhao, Min</dc:creator>
 <dc:creator>Li, Jiangyong</dc:creator>
 <dc:creator>Pan, Haiqing</dc:creator>
 <dc:creator>Dong, Yueqiang</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Proactive human-robot interaction (HRI) allows the receptionist robots to
actively greet people and offer services based on vision, which has been found
to improve acceptability and customer satisfaction. Existing approaches are
either based on multi-stage decision processes or based on end-to-end decision
models. However, the rule-based approaches require sedulous expert efforts and
only handle minimal pre-defined scenarios. On the other hand, existing works
with end-to-end models are limited to very general greetings or few behavior
patterns (typically less than 10). To address those challenges, we propose a
new end-to-end framework, the TransFormer with Visual Tokens for Human-Robot
Interaction (TFVT-HRI). The proposed framework extracts visual tokens of
relative objects from an RGB camera first. To ensure the correct interpretation
of the scenario, a transformer decision model is then employed to process the
visual tokens, which is augmented with the temporal and spatial information. It
predicts the appropriate action to take in each scenario and identifies the
right target. Our data is collected from an in-service receptionist robot in an
office building, which is then annotated by experts for appropriate proactive
behavior. The action set includes 1000+ diverse patterns by combining language,
emoji expression, and body motions. We compare our model with other SOTA
end-to-end models on both offline test sets and online user experiments in
realistic office building environments to validate this framework. It is
demonstrated that the decision model achieves SOTA performance in action
triggering and selection, resulting in more humanness and intelligence when
compared with the previous reactive reception policies.
</dc:description>
 <dc:description>Comment: Accepted to 2021 IEEE International Conference on Robotics and
  Automation (ICRA)</dc:description>
 <dc:date>2020-12-08</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.04832</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.04842</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving the Fairness of Deep Generative Models without Retraining</dc:title>
 <dc:creator>Tan, Shuhan</dc:creator>
 <dc:creator>Shen, Yujun</dc:creator>
 <dc:creator>Zhou, Bolei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Generative Adversarial Networks (GANs) advance face synthesis through
learning the underlying distribution of observed data. Despite the high-quality
generated faces, some minority groups can be rarely generated from the trained
models due to a biased image generation process. To study the issue, we first
conduct an empirical study on a pre-trained face synthesis model. We observe
that after training the GAN model not only carries the biases in the training
data but also amplifies them to some degree in the image generation process. To
further improve the fairness of image generation, we propose an interpretable
baseline method to balance the output facial attributes without retraining. The
proposed method shifts the interpretable semantic distribution in the latent
space for a more balanced image generation while preserving the sample
diversity. Besides producing more balanced data regarding a particular
attribute (e.g., race, gender, etc.), our method is generalizable to handle
more than one attribute at a time and synthesize samples of fine-grained
subgroups. We further show the positive applicability of the balanced data
sampled from GANs to quantify the biases in other face recognition systems,
like commercial face attribute classifiers and face super-resolution
algorithms.
</dc:description>
 <dc:description>Comment: Project page: https://genforce.github.io/fairgen/</dc:description>
 <dc:date>2020-12-08</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.04842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.04910</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Improved Deterministic Parameterized Algorithm for Cactus Vertex
  Deletion</dc:title>
 <dc:creator>Aoike, Yuuki</dc:creator>
 <dc:creator>Gima, Tatsuya</dc:creator>
 <dc:creator>Hanaka, Tesshu</dc:creator>
 <dc:creator>Kiyomi, Masashi</dc:creator>
 <dc:creator>Kobayashi, Yasuaki</dc:creator>
 <dc:creator>Kobayashi, Yusuke</dc:creator>
 <dc:creator>Kurita, Kazuhiro</dc:creator>
 <dc:creator>Otachi, Yota</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A cactus is a connected graph that does not contain $K_4 - e$ as a minor.
Given a graph $G = (V, E)$ and integer $k \ge 0$, Cactus Vertex Deletion (also
known as Diamond Hitting Set) is the problem of deciding whether $G$ has a
vertex set of size at most $k$ whose removal leaves a forest of cacti. The
current best deterministic parameterized algorithm for this problem was due to
Bonnet et al. [WG 2016], which runs in time $26^kn^{O(1)}$, where $n$ is the
number of vertices of $G$. In this paper, we design a deterministic algorithm
for Cactus Vertex Deletion, which runs in time $17.64^kn^{O(1)}$. As a
straightforward application of our algorithm, we give a $17.64^kn^{O(1)}$-time
algorithm for Even Cycle Transversal. The idea behind this improvement is to
apply the measure and conquer analysis with a slightly elaborate measure of
instances.
</dc:description>
 <dc:description>Comment: 11 pages, 1 figure</dc:description>
 <dc:date>2020-12-09</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.04910</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.05364</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Numerical bifurcation analysis of renewal equations via pseudospectral
  approximation</dc:title>
 <dc:creator>Scarabel, Francesca</dc:creator>
 <dc:creator>Diekmann, Odo</dc:creator>
 <dc:creator>Vermiglio, Rossana</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We propose an approximation of nonlinear renewal equations by means of
ordinary differential equations. We consider the integrated state, which is
absolutely continuous and satisfies a delay differential equation. By applying
the pseudospectral approach to the abstract formulation of the differential
equation, we obtain an approximating system of ordinary differential equations.
We present convergence proofs for equilibria and the associated characteristic
roots, and we use some models from ecology and epidemiology to illustrate the
benefits of the approach to perform numerical bifurcation analyses of
equilibria and periodic solutions. The numerical simulations show that the
implementation of the new approximating system is ten times more efficient than
the one originally proposed in [Breda et al, SIAM Journal on Applied Dynamical
Systems, 2016], as it avoids the numerical inversion of an algebraic equation.
</dc:description>
 <dc:date>2020-12-09</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.05364</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.05551</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DI-Fusion: Online Implicit 3D Reconstruction with Deep Priors</dc:title>
 <dc:creator>Huang, Jiahui</dc:creator>
 <dc:creator>Huang, Shi-Sheng</dc:creator>
 <dc:creator>Song, Haoxuan</dc:creator>
 <dc:creator>Hu, Shi-Min</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Previous online 3D dense reconstruction methods struggle to achieve the
balance between memory storage and surface quality, largely due to the usage of
stagnant underlying geometry representation, such as TSDF (truncated signed
distance functions) or surfels, without any knowledge of the scene priors. In
this paper, we present DI-Fusion (Deep Implicit Fusion), based on a novel 3D
representation, i.e. Probabilistic Local Implicit Voxels (PLIVoxs), for online
3D reconstruction with a commodity RGB-D camera. Our PLIVox encodes scene
priors considering both the local geometry and uncertainty parameterized by a
deep neural network. With such deep priors, we are able to perform online
implicit 3D reconstruction achieving state-of-the-art camera trajectory
estimation accuracy and mapping quality, while achieving better storage
efficiency compared with previous online 3D reconstruction approaches. Our
implementation is available at https://www.github.com/huangjh-pub/di-fusion.
</dc:description>
 <dc:date>2020-12-10</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.05551</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.05710</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Look Before you Speak: Visually Contextualized Utterances</dc:title>
 <dc:creator>Seo, Paul Hongsuck</dc:creator>
 <dc:creator>Nagrani, Arsha</dc:creator>
 <dc:creator>Schmid, Cordelia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  While most conversational AI systems focus on textual dialogue only,
conditioning utterances on visual context (when it's available) can lead to
more realistic conversations. Unfortunately, a major challenge for
incorporating visual context into conversational dialogue is the lack of
large-scale labeled datasets. We provide a solution in the form of a new
visually conditioned Future Utterance Prediction task. Our task involves
predicting the next utterance in a video, using both visual frames and
transcribed speech as context. By exploiting the large number of instructional
videos online, we train a model to solve this task at scale, without the need
for manual annotations. Leveraging recent advances in multimodal learning, our
model consists of a novel co-attentional multimodal video transformer, and when
trained on both textual and visual context, outperforms baselines that use
textual inputs alone. Further, we demonstrate that our model trained for this
task on unlabelled videos achieves state-of-the-art performance on a number of
downstream VideoQA benchmarks such as MSRVTT-QA, MSVD-QA, ActivityNet-QA and
How2QA.
</dc:description>
 <dc:date>2020-12-10</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.05710</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.05765</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep-CR MTLR: a Multi-Modal Approach for Cancer Survival Prediction with
  Competing Risks</dc:title>
 <dc:creator>Kim, Sejin</dc:creator>
 <dc:creator>Kazmierski, Michal</dc:creator>
 <dc:creator>Haibe-Kains, Benjamin</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Accurate survival prediction is crucial for development of precision cancer
medicine, creating the need for new sources of prognostic information.
Recently, there has been significant interest in exploiting routinely collected
clinical and medical imaging data to discover new prognostic markers in
multiple cancer types. However, most of the previous studies focus on
individual data modalities alone and do not make use of recent advances in
machine learning for survival prediction. We present Deep-CR MTLR -- a novel
machine learning approach for accurate cancer survival prediction from
multi-modal clinical and imaging data in the presence of competing risks based
on neural networks and an extension of the multi-task logistic regression
framework. We demonstrate improved prognostic performance of the multi-modal
approach over single modality predictors in a cohort of 2552 head and neck
cancer patients, particularly for cancer specific survival, where our approach
achieves 2-year AUROC of 0.774 and $C$-index of 0.788.
</dc:description>
 <dc:description>Comment: Accepted at AAAI Spring Symposium 2021 (SP-ACA)</dc:description>
 <dc:date>2020-12-10</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.05765</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.06070</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Submodular Meta-Learning</dc:title>
 <dc:creator>Tang, Shaojie</dc:creator>
 <dc:creator>Yuan, Jing</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Meta-Learning has gained increasing attention in the machine learning and
artificial intelligence communities. In this paper, we introduce and study an
adaptive submodular meta-learning problem. The input of our problem is a set of
items, where each item has a random state which is initially unknown. The only
way to observe an item's state is to select that item. Our objective is to
adaptively select a group of items that achieve the best performance over a set
of tasks, where each task is represented as an adaptive submodular function
that maps sets of items and their states to a real number. To reduce the
computational cost while maintaining a personalized solution for each future
task, we first select an initial solution set based on previously observed
tasks, then adaptively add the remaining items to the initial solution set when
a new task arrives. As compared to the solution where a brand new solution is
computed for each new task, our meta-learning based approach leads to lower
computational overhead at test time since the initial solution set is
pre-computed in the training stage. To solve this problem, we propose a
two-phase greedy policy and show that it achieves a $1/2$ approximation ratio
for the monotone case. For the non-monotone case, we develop a two-phase
randomized greedy policy that achieves a $1/32$ approximation ratio.
</dc:description>
 <dc:date>2020-12-10</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.06070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.06262</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Morphology Matters: A Multilingual Language Modeling Analysis</dc:title>
 <dc:creator>Park, Hyunji Hayley</dc:creator>
 <dc:creator>Zhang, Katherine J.</dc:creator>
 <dc:creator>Haley, Coleman</dc:creator>
 <dc:creator>Steimel, Kenneth</dc:creator>
 <dc:creator>Liu, Han</dc:creator>
 <dc:creator>Schwartz, Lane</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Prior studies in multilingual language modeling (e.g., Cotterell et al.,
2018; Mielke et al., 2019) disagree on whether or not inflectional morphology
makes languages harder to model. We attempt to resolve the disagreement and
extend those studies. We compile a larger corpus of 145 Bible translations in
92 languages and a larger number of typological features. We fill in missing
typological data for several languages and consider corpus-based measures of
morphological complexity in addition to expert-produced typological features.
We find that several morphological measures are significantly associated with
higher surprisal when LSTM models are trained with BPE-segmented data. We also
investigate linguistically-motivated subword segmentation strategies like
Morfessor and Finite-State Transducers (FSTs) and find that these segmentation
strategies yield better performance and reduce the impact of a language's
morphology on language modeling.
</dc:description>
 <dc:description>Comment: To appear in TACL, a pre-MIT Press publication version; 15 pages, 3
  figures; for the datasets, see
  https://github.com/hayleypark/MorphologyMatters</dc:description>
 <dc:date>2020-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.06262</dc:identifier>
 <dc:identifier>Transactions of the Association for Computational Linguistics 9
  (2021) 261-276</dc:identifier>
 <dc:identifier>doi:10.1162/tacl_a_00365</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.06516</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection of Binary Square Fiducial Markers Using an Event Camera</dc:title>
 <dc:creator>Sarmadi, Hamid</dc:creator>
 <dc:creator>Mu&#xf1;oz-Salinas, Rafael</dc:creator>
 <dc:creator>Olivares-Mendez, Miguel A.</dc:creator>
 <dc:creator>Medina-Carnicer, Rafael</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Event cameras are a new type of image sensors that output changes in light
intensity (events) instead of absolute intensity values. They have a very high
temporal resolution and a high dynamic range. In this paper, we propose a
method to detect and decode binary square markers using an event camera. We
detect the edges of the markers by detecting line segments in an image created
from events in the current packet. The line segments are combined to form
marker candidates. The bit value of marker cells is decoded using the events on
their borders. To the best of our knowledge, no other approach exists for
detecting square binary markers directly from an event camera using only the
CPU unit in real-time. Experimental results show that the performance of our
proposal is much superior to the one from the RGB ArUco marker detector. The
proposed method can achieve the real-time performance on a single CPU thread.
</dc:description>
 <dc:description>Comment: An error in the abstract of the IEEE Access version has been
  corrected in this version. Link to the IEEE Access paper:
  https://doi.org/10.1109/ACCESS.2021.3058423</dc:description>
 <dc:date>2020-12-11</dc:date>
 <dc:date>2021-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.06516</dc:identifier>
 <dc:identifier>doi:10.1109/ACCESS.2021.3058423</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.06828</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On partially homogeneous nearest-neighbour random walks in the quarter
  plane and their application in the analysis of two-dimensional queues with
  limited state-dependency</dc:title>
 <dc:creator>Dimitriou, Ioannis</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>60K25, 68M20, 90B22</dc:subject>
 <dc:description>  This work deals with the stationary analysis of two-dimensional partially
homogeneous nearest-neighbour random walks. Such type of random walks are
characterized by the fact that the one-step transition probabilities are
functions of the state-space. We show that its stationary behaviour is
investigated by solving a finite system of linear equations, two matrix
functional equations, and a functional equation with the aid of the theory of
Riemann (-Hilbert) boundary value problems. This work is strongly motivated by
emerging applications in flow level performance of wireless networks that give
rise in queueing models with scalable service capacity, as well as in
queue-based random access protocols, where the network's parameters are
functions of the queue lengths. A simple numerical illustration, along with
some details on the numerical implementation are also presented.
</dc:description>
 <dc:date>2020-12-12</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.06828</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.07436</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Informer: Beyond Efficient Transformer for Long Sequence Time-Series
  Forecasting</dc:title>
 <dc:creator>Zhou, Haoyi</dc:creator>
 <dc:creator>Zhang, Shanghang</dc:creator>
 <dc:creator>Peng, Jieqi</dc:creator>
 <dc:creator>Zhang, Shuai</dc:creator>
 <dc:creator>Li, Jianxin</dc:creator>
 <dc:creator>Xiong, Hui</dc:creator>
 <dc:creator>Zhang, Wancai</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Many real-world applications require the prediction of long sequence
time-series, such as electricity consumption planning. Long sequence
time-series forecasting (LSTF) demands a high prediction capacity of the model,
which is the ability to capture precise long-range dependency coupling between
output and input efficiently. Recent studies have shown the potential of
Transformer to increase the prediction capacity. However, there are several
severe issues with Transformer that prevent it from being directly applicable
to LSTF, including quadratic time complexity, high memory usage, and inherent
limitation of the encoder-decoder architecture. To address these issues, we
design an efficient transformer-based model for LSTF, named Informer, with
three distinctive characteristics: (i) a $ProbSparse$ self-attention mechanism,
which achieves $O(L \log L)$ in time complexity and memory usage, and has
comparable performance on sequences' dependency alignment. (ii) the
self-attention distilling highlights dominating attention by halving cascading
layer input, and efficiently handles extreme long input sequences. (iii) the
generative style decoder, while conceptually simple, predicts the long
time-series sequences at one forward operation rather than a step-by-step way,
which drastically improves the inference speed of long-sequence predictions.
Extensive experiments on four large-scale datasets demonstrate that Informer
significantly outperforms existing methods and provides a new solution to the
LSTF problem.
</dc:description>
 <dc:description>Comment: 8 pages (main), 5 pages (appendix) and to be appeared in AAAI2021</dc:description>
 <dc:date>2020-12-14</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.07436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.07477</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aggregative Self-Supervised Feature Learning from a Limited Sample</dc:title>
 <dc:creator>Zhu, Jiuwen</dc:creator>
 <dc:creator>Li, Yuexiang</dc:creator>
 <dc:creator>Zhou, S. Kevin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Self-supervised learning (SSL) is an efficient approach that addresses the
issue of limited training data and annotation shortage. The key part in SSL is
its proxy task that defines the supervisory signals and drives the learning
toward effective feature representations. However, most SSL approaches usually
focus on a single proxy task, which greatly limits the expressive power of the
learned features and therefore deteriorates the network generalization
capacity. In this regard, we hereby propose two strategies of aggregation in
terms of complementarity of various forms to boost the robustness of
self-supervised learned features. We firstly propose a principled framework of
multi-task aggregative self-supervised learning from a limited sample to form a
unified representation, with an intent of exploiting feature complementarity
among different tasks. Then, in self-aggregative SSL, we propose to
self-complement an existing proxy task with an auxiliary loss function based on
a linear centered kernel alignment metric, which explicitly promotes the
exploring of where are uncovered by the features learned from a proxy task at
hand to further boost the modeling capability. Our extensive experiments on 2D
natural image and 3D medical image classification tasks under limited data and
annotation scenarios confirm that the proposed aggregation strategies
successfully boost the classification accuracy.
</dc:description>
 <dc:date>2020-12-14</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.07477</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.07717</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Panoptic Segmentation at All Scales</dc:title>
 <dc:creator>Porzi, Lorenzo</dc:creator>
 <dc:creator>Bul&#xf2;, Samuel Rota</dc:creator>
 <dc:creator>Kontschieder, Peter</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Crop-based training strategies decouple training resolution from GPU memory
consumption, allowing the use of large-capacity panoptic segmentation networks
on multi-megapixel images. Using crops, however, can introduce a bias towards
truncating or missing large objects. To address this, we propose a novel
crop-aware bounding box regression loss (CABB loss), which promotes predictions
to be consistent with the visible parts of the cropped objects, while not
over-penalizing them for extending outside of the crop. We further introduce a
novel data sampling and augmentation strategy which improves generalization
across scales by counteracting the imbalanced distribution of object sizes.
Combining these two contributions with a carefully designed, top-down panoptic
segmentation architecture, we obtain new state-of-the-art results on the
challenging Mapillary Vistas (MVD), Indian Driving and Cityscapes datasets,
surpassing the previously best approach on MVD by +4.5% PQ and +5.2% mAP.
</dc:description>
 <dc:date>2020-12-14</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.07717</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.08125</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Energy-Based Models by Diffusion Recovery Likelihood</dc:title>
 <dc:creator>Gao, Ruiqi</dc:creator>
 <dc:creator>Song, Yang</dc:creator>
 <dc:creator>Poole, Ben</dc:creator>
 <dc:creator>Wu, Ying Nian</dc:creator>
 <dc:creator>Kingma, Diederik P.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  While energy-based models (EBMs) exhibit a number of desirable properties,
training and sampling on high-dimensional datasets remains challenging.
Inspired by recent progress on diffusion probabilistic models, we present a
diffusion recovery likelihood method to tractably learn and sample from a
sequence of EBMs trained on increasingly noisy versions of a dataset. Each EBM
is trained with recovery likelihood, which maximizes the conditional
probability of the data at a certain noise level given their noisy versions at
a higher noise level. Optimizing recovery likelihood is more tractable than
marginal likelihood, as sampling from the conditional distributions is much
easier than sampling from the marginal distributions. After training,
synthesized images can be generated by the sampling process that initializes
from Gaussian white noise distribution and progressively samples the
conditional distributions at decreasingly lower noise levels. Our method
generates high fidelity samples on various image datasets. On unconditional
CIFAR-10 our method achieves FID 9.58 and inception score 8.30, superior to the
majority of GANs. Moreover, we demonstrate that unlike previous work on EBMs,
our long-run MCMC samples from the conditional distributions do not diverge and
still represent realistic images, allowing us to accurately estimate the
normalized density of data even for high-dimensional datasets. Our
implementation is available at https://github.com/ruiqigao/recovery_likelihood.
</dc:description>
 <dc:date>2020-12-15</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.08125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.08174</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards open and expandable cognitive AI architectures for large-scale
  multi-agent human-robot collaborative learning</dc:title>
 <dc:creator>Papadopoulos, Georgios Th.</dc:creator>
 <dc:creator>Antona, Margherita</dc:creator>
 <dc:creator>Stephanidis, Constantine</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Learning from Demonstration (LfD) constitutes one of the most robust
methodologies for constructing efficient cognitive robotic systems. Despite the
large body of research works already reported, current key technological
challenges include those of multi-agent learning and long-term autonomy.
Towards this direction, a novel cognitive architecture for multi-agent LfD
robotic learning is introduced, targeting to enable the reliable deployment of
open, scalable and expandable robotic systems in large-scale and complex
environments. In particular, the designed architecture capitalizes on the
recent advances in the Artificial Intelligence (AI) field, by establishing a
Federated Learning (FL)-based framework for incarnating a multi-human
multi-robot collaborative learning environment. The fundamental
conceptualization relies on employing multiple AI-empowered cognitive processes
(implementing various robotic tasks) that operate at the edge nodes of a
network of robotic platforms, while global AI models (underpinning the
aforementioned robotic tasks) are collectively created and shared among the
network, by elegantly combining information from a large number of human-robot
interaction instances. Regarding pivotal novelties, the designed cognitive
architecture a) introduces a new FL-based formalism that extends the
conventional LfD learning paradigm to support large-scale multi-agent
operational settings, b) elaborates previous FL-based self-learning robotic
schemes so as to incorporate the human in the learning loop and c) consolidates
the fundamental principles of FL with additional sophisticated AI-enabled
learning methodologies for modelling the multi-level inter-dependencies among
the robotic tasks. The applicability of the proposed framework is explained
using an example of a real-world industrial case study for agile
production-based Critical Raw Materials (CRM) recovery.
</dc:description>
 <dc:date>2020-12-15</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.08174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.08565</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Personalized Federated Learning with First Order Model Optimization</dc:title>
 <dc:creator>Zhang, Michael</dc:creator>
 <dc:creator>Sapra, Karan</dc:creator>
 <dc:creator>Fidler, Sanja</dc:creator>
 <dc:creator>Yeung, Serena</dc:creator>
 <dc:creator>Alvarez, Jose M.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  While federated learning traditionally aims to train a single global model
across decentralized local datasets, one model may not always be ideal for all
participating clients. Here we propose an alternative, where each client only
federates with other relevant clients to obtain a stronger model per
client-specific objectives. To achieve this personalization, rather than
computing a single model average with constant weights for the entire
federation as in traditional FL, we efficiently calculate optimal weighted
model combinations for each client, based on figuring out how much a client can
benefit from another's model. We do not assume knowledge of any underlying data
distributions or client similarities, and allow each client to optimize for
arbitrary target distributions of interest, enabling greater flexibility for
personalization. We evaluate and characterize our method on a variety of
federated settings, datasets, and degrees of local data heterogeneity. Our
method outperforms existing alternatives, while also enabling new features for
personalized FL such as transfer outside of local data distributions.
</dc:description>
 <dc:description>Comment: ICLR 2021</dc:description>
 <dc:date>2020-12-15</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.08565</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.08674</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wasserstein Contrastive Representation Distillation</dc:title>
 <dc:creator>Chen, Liqun</dc:creator>
 <dc:creator>Wang, Dong</dc:creator>
 <dc:creator>Gan, Zhe</dc:creator>
 <dc:creator>Liu, Jingjing</dc:creator>
 <dc:creator>Henao, Ricardo</dc:creator>
 <dc:creator>Carin, Lawrence</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The primary goal of knowledge distillation (KD) is to encapsulate the
information of a model learned from a teacher network into a student network,
with the latter being more compact than the former. Existing work, e.g., using
Kullback-Leibler divergence for distillation, may fail to capture important
structural knowledge in the teacher network and often lacks the ability for
feature generalization, particularly in situations when teacher and student are
built to address different classification tasks. We propose Wasserstein
Contrastive Representation Distillation (WCoRD), which leverages both primal
and dual forms of Wasserstein distance for KD. The dual form is used for global
knowledge transfer, yielding a contrastive learning objective that maximizes
the lower bound of mutual information between the teacher and the student
networks. The primal form is used for local contrastive knowledge transfer
within a mini-batch, effectively matching the distributions of features between
the teacher and the student networks. Experiments demonstrate that the proposed
WCoRD method outperforms state-of-the-art approaches on privileged information
distillation, model compression and cross-modal transfer.
</dc:description>
 <dc:description>Comment: Accepted by CVPR 2021</dc:description>
 <dc:date>2020-12-15</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.08674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.08734</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Graph Capsule Network</dc:title>
 <dc:creator>Yang, Jinyu</dc:creator>
 <dc:creator>Zhao, Peilin</dc:creator>
 <dc:creator>Rong, Yu</dc:creator>
 <dc:creator>Yan, Chaochao</dc:creator>
 <dc:creator>Li, Chunyuan</dc:creator>
 <dc:creator>Ma, Hehuan</dc:creator>
 <dc:creator>Huang, Junzhou</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Graph Neural Networks (GNNs) draw their strength from explicitly modeling the
topological information of structured data. However, existing GNNs suffer from
limited capability in capturing the hierarchical graph representation which
plays an important role in graph classification. In this paper, we innovatively
propose hierarchical graph capsule network (HGCN) that can jointly learn node
embeddings and extract graph hierarchies. Specifically, disentangled graph
capsules are established by identifying heterogeneous factors underlying each
node, such that their instantiation parameters represent different properties
of the same entity. To learn the hierarchical representation, HGCN
characterizes the part-whole relationship between lower-level capsules (part)
and higher-level capsules (whole) by explicitly considering the structure
information among the parts. Experimental studies demonstrate the effectiveness
of HGCN and the contribution of each component.
</dc:description>
 <dc:description>Comment: AAAI 2021; Code: https://github.com/uta-smile/HGCN</dc:description>
 <dc:date>2020-12-15</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.08734</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.08939</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SS-SFDA : Self-Supervised Source-Free Domain Adaptation for Road
  Segmentation in Hazardous Environments</dc:title>
 <dc:creator>Kothandaraman, Divya</dc:creator>
 <dc:creator>Chandra, Rohan</dc:creator>
 <dc:creator>Manocha, Dinesh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a novel approach for unsupervised road segmentation in adverse
weather conditions such as rain or fog. This includes a new algorithm for
source-free domain adaptation (SFDA) using self-supervised learning. Moreover,
our approach uses several techniques to address various challenges in SFDA and
improve performance, including online generation of pseudo-labels and
self-attention as well as use of curriculum learning, entropy minimization and
model distillation. We have evaluated the performance on $6$ datasets
corresponding to real and synthetic adverse weather conditions. Our method
outperforms all prior works on unsupervised road segmentation and SFDA by at
least 10.26%, and improves the training time by 18-180x. Moreover, our
self-supervised algorithm exhibits similar accuracy performance in terms of
mIOU score as compared to prior supervised methods.
</dc:description>
 <dc:date>2020-11-27</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.08939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.08974</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Permutation Guided Node Representations for Link Prediction</dc:title>
 <dc:creator>Roy, Indradyumna</dc:creator>
 <dc:creator>De, Abir</dc:creator>
 <dc:creator>Chakrabarti, Soumen</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  After observing a snapshot of a social network, a link prediction (LP)
algorithm identifies node pairs between which new edges will likely materialize
in future. Most LP algorithms estimate a score for currently non-neighboring
node pairs, and rank them by this score. Recent LP systems compute this score
by comparing dense, low dimensional vector representations of nodes. Graph
neural networks (GNNs), in particular graph convolutional networks (GCNs), are
popular examples. For two nodes to be meaningfully compared, their embeddings
should be indifferent to reordering of their neighbors. GNNs typically use
simple, symmetric set aggregators to ensure this property, but this design
decision has been shown to produce representations with limited expressive
power. Sequence encoders are more expressive, but are permutation sensitive by
design. Recent efforts to overcome this dilemma turn out to be unsatisfactory
for LP tasks. In response, we propose PermGNN, which aggregates neighbor
features using a recurrent, order-sensitive aggregator and directly minimizes
an LP loss while it is `attacked' by adversarial generator of neighbor
permutations. By design, PermGNN{} has more expressive power compared to
earlier symmetric aggregators. Next, we devise an optimization framework to map
PermGNN's node embeddings to a suitable locality-sensitive hash, which speeds
up reporting the top-$K$ most likely edges for the LP task. Our experiments on
diverse datasets show that \our outperforms several state-of-the-art link
predictors by a significant margin, and can predict the most likely edges fast.
</dc:description>
 <dc:description>Comment: Rectified an error in evaluation in earlier 60-40 splits</dc:description>
 <dc:date>2020-12-12</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.08974</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.09159</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DECOR-GAN: 3D Shape Detailization by Conditional Refinement</dc:title>
 <dc:creator>Chen, Zhiqin</dc:creator>
 <dc:creator>Kim, Vladimir G.</dc:creator>
 <dc:creator>Fisher, Matthew</dc:creator>
 <dc:creator>Aigerman, Noam</dc:creator>
 <dc:creator>Zhang, Hao</dc:creator>
 <dc:creator>Chaudhuri, Siddhartha</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We introduce a deep generative network for 3D shape detailization, akin to
stylization with the style being geometric details. We address the challenge of
creating large varieties of high-resolution and detailed 3D geometry from a
small set of exemplars by treating the problem as that of geometric detail
transfer. Given a low-resolution coarse voxel shape, our network refines it,
via voxel upsampling, into a higher-resolution shape enriched with geometric
details. The output shape preserves the overall structure (or content) of the
input, while its detail generation is conditioned on an input &quot;style code&quot;
corresponding to a detailed exemplar. Our 3D detailization via conditional
refinement is realized by a generative adversarial network, coined DECOR-GAN.
The network utilizes a 3D CNN generator for upsampling coarse voxels and a 3D
PatchGAN discriminator to enforce local patches of the generated model to be
similar to those in the training detailed shapes. During testing, a style code
is fed into the generator to condition the refinement. We demonstrate that our
method can refine a coarse shape into a variety of detailed shapes with
different styles. The generated results are evaluated in terms of content
preservation, plausibility, and diversity. Comprehensive ablation studies are
conducted to validate our network designs. Code is available at
https://github.com/czq142857/DECOR-GAN.
</dc:description>
 <dc:description>Comment: CVPR 2021 (oral). Code: https://github.com/czq142857/DECOR-GAN</dc:description>
 <dc:date>2020-12-16</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.09159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.09333</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Learning of Local Discriminative Representation for Medical
  Images</dc:title>
 <dc:creator>Chen, Huai</dc:creator>
 <dc:creator>Li, Jieyu</dc:creator>
 <dc:creator>Wang, Renzhen</dc:creator>
 <dc:creator>Huang, Yijie</dc:creator>
 <dc:creator>Meng, Fanrui</dc:creator>
 <dc:creator>Meng, Deyu</dc:creator>
 <dc:creator>Peng, Qing</dc:creator>
 <dc:creator>Wang, Lisheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Local discriminative representation is needed in many medical image analysis
tasks such as identifying sub-types of lesion or segmenting detailed components
of anatomical structures. However, the commonly applied supervised
representation learning methods require a large amount of annotated data, and
unsupervised discriminative representation learning distinguishes different
images by learning a global feature, both of which are not suitable for
localized medical image analysis tasks. In order to avoid the limitations of
these two methods, we introduce local discrimination into unsupervised
representation learning in this work. The model contains two branches: one is
an embedding branch which learns an embedding function to disperse dissimilar
pixels over a low-dimensional hypersphere; and the other is a clustering branch
which learns a clustering function to classify similar pixels into the same
cluster. These two branches are trained simultaneously in a mutually beneficial
pattern, and the learnt local discriminative representations are able to well
measure the similarity of local image regions. These representations can be
transferred to enhance various downstream tasks. Meanwhile, they can also be
applied to cluster anatomical structures from unlabeled medical images under
the guidance of topological priors from simulation or other structures with
similar topological characteristics. The effectiveness and usefulness of the
proposed method are demonstrated by enhancing various downstream tasks and
clustering anatomical structures in retinal images and chest X-ray images.
</dc:description>
 <dc:description>Comment: Accepted by IPMI2021</dc:description>
 <dc:date>2020-12-16</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.09333</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.09344</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Learning for Detecting Data Exfiltration: A Review</dc:title>
 <dc:creator>Sabir, Bushra</dc:creator>
 <dc:creator>Ullah, Faheem</dc:creator>
 <dc:creator>Babar, M. Ali</dc:creator>
 <dc:creator>Gaire, Raj</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Context: Research at the intersection of cybersecurity, Machine Learning
(ML), and Software Engineering (SE) has recently taken significant steps in
proposing countermeasures for detecting sophisticated data exfiltration
attacks. It is important to systematically review and synthesize the ML-based
data exfiltration countermeasures for building a body of knowledge on this
important topic. Objective: This paper aims at systematically reviewing
ML-based data exfiltration countermeasures to identify and classify ML
approaches, feature engineering techniques, evaluation datasets, and
performance metrics used for these countermeasures. This review also aims at
identifying gaps in research on ML-based data exfiltration countermeasures.
Method: We used a Systematic Literature Review (SLR) method to select and
review {92} papers. Results: The review has enabled us to (a) classify the ML
approaches used in the countermeasures into data-driven, and behaviour-driven
approaches, (b) categorize features into six types: behavioural, content-based,
statistical, syntactical, spatial and temporal, (c) classify the evaluation
datasets into simulated, synthesized, and real datasets and (d) identify 11
performance measures used by these studies. Conclusion: We conclude that: (i)
the integration of data-driven and behaviour-driven approaches should be
explored; (ii) There is a need of developing high quality and large size
evaluation datasets; (iii) Incremental ML model training should be incorporated
in countermeasures; (iv) resilience to adversarial learning should be
considered and explored during the development of countermeasures to avoid
poisoning attacks; and (v) the use of automated feature engineering should be
encouraged for efficiently detecting data exfiltration attacks.
</dc:description>
 <dc:date>2020-12-16</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.09344</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.09607</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kernelized Classification in Deep Networks</dc:title>
 <dc:creator>Jayasumana, Sadeep</dc:creator>
 <dc:creator>Ramalingam, Srikumar</dc:creator>
 <dc:creator>Kumar, Sanjiv</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a kernelized classification layer for deep networks. Although
conventional deep networks introduce an abundance of nonlinearity for
representation (feature) learning, they almost universally use a linear
classifier on the learned feature vectors. We advocate a nonlinear
classification layer by using the kernel trick on the softmax cross-entropy
loss function during training and the scorer function during testing. However,
the choice of the kernel remains a challenge. To tackle this, we theoretically
show the possibility of optimizing over all possible positive definite kernels
applicable to our problem setting. This theory is then used to device a new
kernelized classification layer that learns the optimal kernel function for a
given problem automatically within the deep network itself. We show the
usefulness of the proposed nonlinear classification layer on several datasets
and tasks.
</dc:description>
 <dc:date>2020-12-08</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.09607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.09740</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding the Behaviour of Contrastive Loss</dc:title>
 <dc:creator>Wang, Feng</dc:creator>
 <dc:creator>Liu, Huaping</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Unsupervised contrastive learning has achieved outstanding success, while the
mechanism of contrastive loss has been less studied. In this paper, we
concentrate on the understanding of the behaviours of unsupervised contrastive
loss. We will show that the contrastive loss is a hardness-aware loss function,
and the temperature {\tau} controls the strength of penalties on hard negative
samples. The previous study has shown that uniformity is a key property of
contrastive learning. We build relations between the uniformity and the
temperature {\tau} . We will show that uniformity helps the contrastive
learning to learn separable features, however excessive pursuit to the
uniformity makes the contrastive loss not tolerant to semantically similar
samples, which may break the underlying semantic structure and be harmful to
the formation of features useful for downstream tasks. This is caused by the
inherent defect of the instance discrimination objective. Specifically,
instance discrimination objective tries to push all different instances apart,
ignoring the underlying relations between samples. Pushing semantically
consistent samples apart has no positive effect for acquiring a prior
informative to general downstream tasks. A well-designed contrastive loss
should have some extents of tolerance to the closeness of semantically similar
samples. Therefore, we find that the contrastive loss meets a
uniformity-tolerance dilemma, and a good choice of temperature can compromise
these two properties properly to both learn separable features and tolerant to
semantically similar samples, improving the feature qualities and the
downstream performances.
</dc:description>
 <dc:description>Comment: Accepted to CVPR2021</dc:description>
 <dc:date>2020-12-15</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.09740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.09842</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>$\mathbb{X}$Resolution Correspondence Networks</dc:title>
 <dc:creator>Tinchev, Georgi</dc:creator>
 <dc:creator>Li, Shuda</dc:creator>
 <dc:creator>Han, Kai</dc:creator>
 <dc:creator>Mitchell, David</dc:creator>
 <dc:creator>Kouskouridas, Rigas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we aim at establishing accurate dense correspondences between
a pair of images with overlapping field of view under challenging illumination
variation, viewpoint changes, and style differences. Through an extensive
ablation study of the state-of-the-art correspondence networks, we surprisingly
discovered that the widely adopted 4D correlation tensor and its related
learning and processing modules could be de-parameterised and removed from
training with merely a minor impact over the final matching accuracy. Disabling
these computational expensive modules dramatically speeds up the training
procedure and allows to use 4 times bigger batch size, which in turn
compensates for the accuracy drop. Together with a multi-GPU inference stage,
our method facilitates the systematic investigation of the relationship between
matching accuracy and up-sampling resolution of the native testing images from
1280 to 4K. This leads to discovery of the existence of an optimal resolution
$\mathbb{X}$ that produces accurate matching performance surpassing the
state-of-the-art methods particularly over the lower error band on public
benchmarks for the proposed network.
</dc:description>
 <dc:description>Comment: Preprint. Code is available at https://xyz-r-d.github.io/xrcnet</dc:description>
 <dc:date>2020-12-17</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.09842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.09919</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Verification of Optimized Code: Correct High-speed X25519</dc:title>
 <dc:creator>Schoolderman, Marc</dc:creator>
 <dc:creator>Moerman, Jonathan</dc:creator>
 <dc:creator>Smetsers, Sjaak</dc:creator>
 <dc:creator>van Eekelen, Marko</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.3</dc:subject>
 <dc:subject>E.3</dc:subject>
 <dc:description>  Code that is highly optimized poses a problem for program-level verification:
programmers can employ various clever tricks that are non-trivial to reason
about. For cryptography on low-power devices, it is nonetheless crucial that
implementations be functionally correct, secure, and efficient. These are
usually crafted in hand-optimized machine code that eschew conventional control
flow as much as possible.
  We have formally verified such code: a library which implements elliptic
curve cryptography on 8-bit AVR microcontrollers. The chosen implementation is
the most efficient currently known for this microarchitecture. It consists of
over 3000 lines of assembly instructions. Building on earlier work, we use the
Why3 platform to model the code and prove verification conditions, using
automated provers. We expect the approach to be re-usable and adaptable, and it
allows for validation. Furthermore, an error in the original implementation was
found and corrected, at the same time reducing its memory footprint. This shows
that practical verification of cutting-edge code is not only possible, but can
in fact add to its efficiency -- and is clearly necessary.
</dc:description>
 <dc:description>Comment: 19 pages, 5 figures. accepted at NFM 2021 (without appendix)</dc:description>
 <dc:date>2020-12-17</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.09919</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.10079</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enabling Retrain-free Deep Neural Network Pruning using Surrogate
  Lagrangian Relaxation</dc:title>
 <dc:creator>Gurevin, Deniz</dc:creator>
 <dc:creator>Zhou, Shanglin</dc:creator>
 <dc:creator>Pepin, Lynn</dc:creator>
 <dc:creator>Li, Bingbing</dc:creator>
 <dc:creator>Bragin, Mikhail</dc:creator>
 <dc:creator>Ding, Caiwen</dc:creator>
 <dc:creator>Miao, Fei</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Network pruning is a widely used technique to reduce computation cost and
model size for deep neural networks. However, the typical three-stage pipeline,
i.e., training, pruning and retraining (fine-tuning) significantly increases
the overall training trails. In this paper, we develop a systematic
weight-pruning optimization approach based on Surrogate Lagrangian relaxation
(SLR), which is tailored to overcome difficulties caused by the discrete nature
of the weight-pruning problem while ensuring fast convergence. We further
accelerate the convergence of the SLR by using quadratic penalties. Model
parameters obtained by SLR during the training phase are much closer to their
optimal values as compared to those obtained by other state-of-the-art methods.
We evaluate the proposed method on image classification tasks, i.e., ResNet-18
and ResNet-50 using ImageNet, and ResNet-18, ResNet-50 and VGG-16 using
CIFAR-10, as well as object detection tasks, i.e., YOLOv3 and YOLOv3-tiny using
COCO 2014 and Ultra-Fast-Lane-Detection using TuSimple lane detection dataset.
Experimental results demonstrate that our SLR-based weight-pruning optimization
approach achieves higher compression rate than state-of-the-arts under the same
accuracy requirement. It also achieves a high model accuracy even at the
hard-pruning stage without retraining (reduces the traditional three-stage
pruning to two-stage). Given a limited budget of retraining epochs, our
approach quickly recovers the model accuracy.
</dc:description>
 <dc:date>2020-12-18</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.10079</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.10586</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding Sparse Structures for Domain Specific Neural Machine Translation</dc:title>
 <dc:creator>Liang, Jianze</dc:creator>
 <dc:creator>Zhao, Chengqi</dc:creator>
 <dc:creator>Wang, Mingxuan</dc:creator>
 <dc:creator>Qiu, Xipeng</dc:creator>
 <dc:creator>Li, Lei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Neural machine translation often adopts the fine-tuning approach to adapt to
specific domains. However, nonrestricted fine-tuning can easily degrade on the
general domain and over-fit to the target domain. To mitigate the issue, we
propose Prune-Tune, a novel domain adaptation method via gradual pruning. It
learns tiny domain-specific sub-networks during fine-tuning on new domains.
Prune-Tune alleviates the over-fitting and the degradation problem without
model modification. Furthermore, Prune-Tune is able to sequentially learn a
single network with multiple disjoint domain-specific sub-networks for multiple
domains. Empirical experiment results show that Prune-Tune outperforms several
strong competitors in the target domain test set without sacrificing the
quality on the general domain in both single and multi-domain settings. The
source code and data are available at https://github.com/ohlionel/Prune-Tune.
</dc:description>
 <dc:description>Comment: Accepted to AAAI 2021</dc:description>
 <dc:date>2020-12-18</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.10586</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.10631</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BAF-Detector: An Efficient CNN-Based Detector for Photovoltaic Cell
  Defect Detection</dc:title>
 <dc:creator>Su, Binyi</dc:creator>
 <dc:creator>Chen, Haiyong</dc:creator>
 <dc:creator>Zhou, Zhong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The multi-scale defect detection for photovoltaic (PV) cell
electroluminescence (EL) images is a challenging task, due to the feature
vanishing as network deepens. To address this problem, an attention-based
top-down and bottom-up architecture is developed to accomplish multi-scale
feature fusion. This architecture, called Bidirectional Attention Feature
Pyramid Network (BAFPN), can make all layers of the pyramid share similar
semantic features. In BAFPN, cosine similarity is employed to measure the
importance of each pixel in the fused features. Furthermore, a novel object
detector is proposed, called BAF-Detector, which embeds BAFPN into Region
Proposal Network (RPN) in Faster RCNN+FPN. BAFPN improves the robustness of the
network to scales, thus the proposed detector achieves a good performance in
multi-scale defects detection task. Finally, the experimental results on a
large-scale EL dataset including 3629 images, 2129 of which are defective, show
that the proposed method achieves 98.70% (F-measure), 88.07% (mAP), and 73.29%
(IoU) in terms of multi-scale defects classification and detection results in
raw PV cell EL images.
</dc:description>
 <dc:date>2020-12-19</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.10631</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.10968</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Auto-Encoded Reservoir Computing for Turbulence Learning</dc:title>
 <dc:creator>Doan, Nguyen Anh Khoa</dc:creator>
 <dc:creator>Polifke, Wolfgang</dc:creator>
 <dc:creator>Magri, Luca</dc:creator>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We present an Auto-Encoded Reservoir-Computing (AE-RC) approach to learn the
dynamics of a 2D turbulent flow. The AE-RC consists of an Autoencoder, which
discovers an efficient manifold representation of the flow state, and an Echo
State Network, which learns the time evolution of the flow in the manifold. The
AE-RC is able to both learn the time-accurate dynamics of the flow and predict
its first-order statistical moments. The AE-RC approach opens up new
possibilities for the spatio-temporal prediction of turbulence with machine
learning.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures</dc:description>
 <dc:date>2020-12-20</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.10968</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.11150</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Unsupervised Image Clustering With Robust Learning</dc:title>
 <dc:creator>Park, Sungwon</dc:creator>
 <dc:creator>Han, Sungwon</dc:creator>
 <dc:creator>Kim, Sundong</dc:creator>
 <dc:creator>Kim, Danu</dc:creator>
 <dc:creator>Park, Sungkyu</dc:creator>
 <dc:creator>Hong, Seunghoon</dc:creator>
 <dc:creator>Cha, Meeyoung</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Unsupervised image clustering methods often introduce alternative objectives
to indirectly train the model and are subject to faulty predictions and
overconfident results. To overcome these challenges, the current research
proposes an innovative model RUC that is inspired by robust learning. RUC's
novelty is at utilizing pseudo-labels of existing image clustering models as a
noisy dataset that may include misclassified samples. Its retraining process
can revise misaligned knowledge and alleviate the overconfidence problem in
predictions. The model's flexible structure makes it possible to be used as an
add-on module to other clustering methods and helps them achieve better
performance on multiple datasets. Extensive experiments show that the proposed
model can adjust the model confidence with better calibration and gain
additional robustness against adversarial noise.
</dc:description>
 <dc:description>Comment: Accepted at CVPR2021</dc:description>
 <dc:date>2020-12-21</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.11150</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.11490</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CSKG: The CommonSense Knowledge Graph</dc:title>
 <dc:creator>Ilievski, Filip</dc:creator>
 <dc:creator>Szekely, Pedro</dc:creator>
 <dc:creator>Zhang, Bin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Sources of commonsense knowledge support applications in natural language
understanding, computer vision, and knowledge graphs. Given their
complementarity, their integration is desired. Yet, their different foci,
modeling approaches, and sparse overlap make integration difficult. In this
paper, we consolidate commonsense knowledge by following five principles, which
we apply to combine seven key sources into a first integrated CommonSense
Knowledge Graph (CSKG). We analyze CSKG and its various text and graph
embeddings, showing that CSKG is well-connected and that its embeddings provide
a useful entry point to the graph. We demonstrate how CSKG can provide evidence
for generalizable downstream reasoning and for pre-training of language models.
CSKG and all its embeddings are made publicly available to support further
research on commonsense knowledge integration and reasoning.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:2006.06114</dc:description>
 <dc:date>2020-12-21</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.11490</dc:identifier>
 <dc:identifier>ESWC 2021 Resource Track</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.11685</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Methods for Effective, Efficient, and Exposure-Aware Information
  Retrieval</dc:title>
 <dc:creator>Mitra, Bhaskar</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Neural networks with deep architectures have demonstrated significant
performance improvements in computer vision, speech recognition, and natural
language processing. The challenges in information retrieval (IR), however, are
different from these other application areas. A common form of IR involves
ranking of documents--or short passages--in response to keyword-based queries.
Effective IR systems must deal with query-document vocabulary mismatch problem,
by modeling relationships between different query and document terms and how
they indicate relevance. Models should also consider lexical matches when the
query contains rare terms--such as a person's name or a product model
number--not seen during training, and to avoid retrieving semantically related
but irrelevant results. In many real-life IR tasks, the retrieval involves
extremely large collections--such as the document index of a commercial Web
search engine--containing billions of documents. Efficient IR methods should
take advantage of specialized IR data structures, such as inverted index, to
efficiently retrieve from large collections. Given an information need, the IR
system also mediates how much exposure an information artifact receives by
deciding whether it should be displayed, and where it should be positioned,
among other results. Exposure-aware IR systems may optimize for additional
objectives, besides relevance, such as parity of exposure for retrieved items
and content publishers. In this thesis, we present novel neural architectures
and methods motivated by the specific needs and challenges of IR tasks.
</dc:description>
 <dc:description>Comment: PhD thesis, Univ College London (2020)</dc:description>
 <dc:date>2020-12-21</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.11685</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.11761</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounding the Complexity of Formally Verifying Neural Networks: A
  Geometric Approach</dc:title>
 <dc:creator>Ferlez, James</dc:creator>
 <dc:creator>Shoukry, Yasser</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In this paper, we consider the computational complexity of formally verifying
the behavior of Rectified Linear Unit (ReLU) Neural Networks (NNs), where
verification entails determining whether the NN satisfies convex polytopic
specifications. Specifically, we show that for two different NN architectures
-- shallow NNs and Two-Level Lattice (TLL) NNs -- the verification problem with
(convex) polytopic constraints is polynomial in the number of neurons in the NN
to be verified, when all other aspects of the verification problem held fixed.
We achieve these complexity results by exhibiting explicit (but similar)
verification algorithms for each type of architecture. Both algorithms
efficiently translate the NN parameters into a partitioning of the NN's input
space by means of hyperplanes; this has the effect of partitioning the original
verification problem into polynomially many sub-verification problems derived
from the geometry of the neurons. We show that these sub-problems may be chosen
so that the NN is purely affine within each, and hence each sub-problem is
solvable in polynomial time by means of a Linear Program (LP). Thus, a
polynomial-time algorithm for the original verification problem can be obtained
using known algorithms for enumerating the regions in a hyperplane arrangement.
Finally, we adapt our proposed algorithms to the verification of dynamical
systems, specifically when these NN architectures are used as state-feedback
controllers for LTI systems. We further evaluate the viability of this approach
numerically.
</dc:description>
 <dc:date>2020-12-21</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.11761</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.11803</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling Deep Learning Based Privacy Attacks on Physical Mail</dc:title>
 <dc:creator>Huang, Bingyao</dc:creator>
 <dc:creator>Lian, Ruyi</dc:creator>
 <dc:creator>Samaras, Dimitris</dc:creator>
 <dc:creator>Ling, Haibin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Mail privacy protection aims to prevent unauthorized access to hidden content
within an envelope since normal paper envelopes are not as safe as we think. In
this paper, for the first time, we show that with a well designed deep learning
model, the hidden content may be largely recovered without opening the
envelope. We start by modeling deep learning-based privacy attacks on physical
mail content as learning the mapping from the camera-captured envelope front
face image to the hidden content, then we explicitly model the mapping as a
combination of perspective transformation, image dehazing and denoising using a
deep convolutional neural network, named Neural-STE (See-Through-Envelope). We
show experimentally that hidden content details, such as texture and image
structure, can be clearly recovered. Finally, our formulation and model allow
us to design envelopes that can counter deep learning-based privacy attacks on
physical mail.
</dc:description>
 <dc:description>Comment: Source code: https://github.com/BingyaoHuang/Neural-STE</dc:description>
 <dc:date>2020-12-21</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.11803</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.11835</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovering Robust Convolutional Architecture at Targeted Capacity: A
  Multi-Shot Approach</dc:title>
 <dc:creator>Ning, Xuefei</dc:creator>
 <dc:creator>Zhao, Junbo</dc:creator>
 <dc:creator>Li, Wenshuo</dc:creator>
 <dc:creator>Zhao, Tianchen</dc:creator>
 <dc:creator>Zheng, Yin</dc:creator>
 <dc:creator>Yang, Huazhong</dc:creator>
 <dc:creator>Wang, Yu</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Convolutional neural networks (CNNs) are vulnerable to adversarial examples,
and studies show that increasing the model capacity of an architecture topology
(e.g., width expansion) can bring consistent robustness improvements. This
reveals a clear robustness-efficiency trade-off that should be considered in
architecture design. In this paper, considering scenarios with capacity budget,
we aim to discover adversarially robust architecture at targeted capacities.
Recent studies employed one-shot neural architecture search (NAS) to discover
robust architectures. However, since the capacities of different topologies
cannot be aligned in the search process, one-shot NAS methods favor topologies
with larger capacities in the supernet. And the discovered topology might be
suboptimal when augmented to the targeted capacity. We propose a novel
multi-shot NAS method to address this issue and explicitly search for robust
architectures at targeted capacities. At the targeted FLOPs of 2000M, the
discovered MSRobNet-2000 outperforms the recent NAS-discovered architecture
RobNet-large under various criteria by a large margin of 4%-7%. And at the
targeted FLOPs of 1560M, MSRobNet-1560 surpasses another NAS-discovered
architecture RobNet-free by 2.3% and 1.3% in the clean and PGD-7 accuracies,
respectively. All codes are available at https://github.com/walkerning/aw\_nas.
</dc:description>
 <dc:description>Comment: 9 pages, 9 pages appendices</dc:description>
 <dc:date>2020-12-22</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.11835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.11847</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Multiscale Feature Learning for Overlapping Chromosome
  Segmentation</dc:title>
 <dc:creator>Mei, Liye</dc:creator>
 <dc:creator>Yu, Yalan</dc:creator>
 <dc:creator>Weng, Yueyun</dc:creator>
 <dc:creator>Guo, Xiaopeng</dc:creator>
 <dc:creator>Liu, Yan</dc:creator>
 <dc:creator>Wang, Du</dc:creator>
 <dc:creator>Liu, Sheng</dc:creator>
 <dc:creator>Zhou, Fuling</dc:creator>
 <dc:creator>Lei, Cheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Chromosome karyotype analysis is of great clinical importance in the
diagnosis and treatment of diseases, especially for genetic diseases. Since
manual analysis is highly time and effort consuming, computer-assisted
automatic chromosome karyotype analysis based on images is routinely used to
improve the efficiency and accuracy of the analysis. Due to the strip shape of
the chromosomes, they easily get overlapped with each other when imaged,
significantly affecting the accuracy of the analysis afterward. Conventional
overlapping chromosome segmentation methods are usually based on manually
tagged features, hence, the performance of which is easily affected by the
quality, such as resolution and brightness, of the images. To address the
problem, in this paper, we present an adversarial multiscale feature learning
framework to improve the accuracy and adaptability of overlapping chromosome
segmentation. Specifically, we first adopt the nested U-shape network with
dense skip connections as the generator to explore the optimal representation
of the chromosome images by exploiting multiscale features. Then we use the
conditional generative adversarial network (cGAN) to generate images similar to
the original ones, the training stability of which is enhanced by applying the
least-square GAN objective. Finally, we employ Lovasz-Softmax to help the model
converge in a continuous optimization setting. Comparing with the established
algorithms, the performance of our framework is proven superior by using public
datasets in eight evaluation criteria, showing its great potential in
overlapping chromosome segmentation
</dc:description>
 <dc:date>2020-12-22</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.11847</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.12265</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative Interventions for Causal Learning</dc:title>
 <dc:creator>Mao, Chengzhi</dc:creator>
 <dc:creator>Cha, Augustine</dc:creator>
 <dc:creator>Gupta, Amogh</dc:creator>
 <dc:creator>Wang, Hao</dc:creator>
 <dc:creator>Yang, Junfeng</dc:creator>
 <dc:creator>Vondrick, Carl</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We introduce a framework for learning robust visual representations that
generalize to new viewpoints, backgrounds, and scene contexts. Discriminative
models often learn naturally occurring spurious correlations, which cause them
to fail on images outside of the training distribution. In this paper, we show
that we can steer generative models to manufacture interventions on features
caused by confounding factors. Experiments, visualizations, and theoretical
results show this method learns robust representations more consistent with the
underlying causal relationships. Our approach improves performance on multiple
datasets demanding out-of-distribution generalization, and we demonstrate
state-of-the-art performance generalizing from ImageNet to ObjectNet dataset.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2021</dc:description>
 <dc:date>2020-12-22</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.12265</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.12485</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global Models for Time Series Forecasting: A Simulation Study</dc:title>
 <dc:creator>Hewamalage, Hansika</dc:creator>
 <dc:creator>Bergmeir, Christoph</dc:creator>
 <dc:creator>Bandara, Kasun</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In the current context of Big Data, the nature of many forecasting problems
has changed from predicting isolated time series to predicting many time series
from similar sources. This has opened up the opportunity to develop competitive
global forecasting models that simultaneously learn from many time series. But,
it still remains unclear when global forecasting models can outperform the
univariate benchmarks, especially along the dimensions of the
homogeneity/heterogeneity of series, the complexity of patterns in the series,
the complexity of forecasting models, and the lengths/number of series. Our
study attempts to address this problem through investigating the effect from
these factors, by simulating a number of datasets that have controllable time
series characteristics. Specifically, we simulate time series from simple data
generating processes (DGP), such as Auto Regressive (AR) and Seasonal AR, to
complex DGPs, such as Chaotic Logistic Map, Self-Exciting Threshold
Auto-Regressive, and Mackey-Glass Equations. The data heterogeneity is
introduced by mixing time series generated from several DGPs into a single
dataset. The lengths and the number of series in the dataset are varied in
different scenarios. We perform experiments on these datasets using global
forecasting models including Recurrent Neural Networks (RNN), Feed-Forward
Neural Networks, Pooled Regression (PR) models and Light Gradient Boosting
Models (LGBM), and compare their performance against standard statistical
univariate forecasting techniques. Our experiments demonstrate that when
trained as global forecasting models, techniques such as RNNs and LGBMs, which
have complex non-linear modelling capabilities, are competitive methods in
general under challenging forecasting scenarios such as series having short
lengths, datasets with heterogeneous series and having minimal prior knowledge
of the patterns of the series.
</dc:description>
 <dc:date>2020-12-22</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.12485</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.13148</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Objective Class-based Micro-Expression Recognition through Simultaneous
  Action Unit Detection and Feature Aggregation</dc:title>
 <dc:creator>Zhou, Ling</dc:creator>
 <dc:creator>Mao, Qirong</dc:creator>
 <dc:creator>Dong, Ming</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Micro-Expression Recognition (MER) is a challenging task as the subtle
changes occur over different action regions of a face. Changes in facial action
regions are formed as Action Units (AUs), and AUs in micro-expressions can be
seen as the actors in cooperative group activities. In this paper, we propose a
novel deep neural network model for objective class-based MER, which
simultaneously detects AUs and aggregates AU-level features into
micro-expression-level representation through Graph Convolutional Networks
(GCN). Specifically, we propose two new strategies in our AU detection module
for more effective AU feature learning: the attention mechanism and the
balanced detection loss function. With those two strategies, features are
learned for all the AUs in a unified model, eliminating the error-prune
landmark detection process and tedious separate training for each AU. Moreover,
our model incorporates a tailored objective class-based AU knowledge-graph,
which facilitates the GCN to aggregate the AU-level features into a
micro-expression-level feature representation. Extensive experiments on two
tasks in MEGC 2018 show that our approach significantly outperforms the current
state-of-the-arts in MER. Additionally, we also report our single model-based
micro-expression AU detection results.
</dc:description>
 <dc:date>2020-12-24</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.13148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.13185</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>REM-Net: Recursive Erasure Memory Network for Commonsense Evidence
  Refinement</dc:title>
 <dc:creator>Huang, Yinya</dc:creator>
 <dc:creator>Fang, Meng</dc:creator>
 <dc:creator>Zhan, Xunlin</dc:creator>
 <dc:creator>Cao, Qingxing</dc:creator>
 <dc:creator>Liang, Xiaodan</dc:creator>
 <dc:creator>Lin, Liang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  When answering a question, people often draw upon their rich world knowledge
in addition to the particular context. While recent works retrieve supporting
facts/evidence from commonsense knowledge bases to supply additional
information to each question, there is still ample opportunity to advance it on
the quality of the evidence. It is crucial since the quality of the evidence is
the key to answering commonsense questions, and even determines the upper bound
on the QA systems performance. In this paper, we propose a recursive erasure
memory network (REM-Net) to cope with the quality improvement of evidence. To
address this, REM-Net is equipped with a module to refine the evidence by
recursively erasing the low-quality evidence that does not explain the question
answering. Besides, instead of retrieving evidence from existing knowledge
bases, REM-Net leverages a pre-trained generative model to generate candidate
evidence customized for the question. We conduct experiments on two commonsense
question answering datasets, WIQA and CosmosQA. The results demonstrate the
performance of REM-Net and show that the refined evidence is explainable.
</dc:description>
 <dc:description>Comment: Accepted by AAAI 2021</dc:description>
 <dc:date>2020-12-24</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.13185</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.13224</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning-based hierarchical control of water reservoir systems</dc:title>
 <dc:creator>Kergus, Pauline</dc:creator>
 <dc:creator>Formentin, Simone</dc:creator>
 <dc:creator>Giuliani, Matteo</dc:creator>
 <dc:creator>Castelletti, Andrea</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  The optimal control of a water reservoir systems represents a challenging
problem, due to uncertain hydrologic inputs and the need to adapt to changing
environment and varying control objectives. In this work, we propose a
real-time learning-based control strategy based on a hierarchical predictive
control architecture. Two control loops are implemented: the inner loop is
aimed to make the overall dynamics similar to an assigned linear through
data-driven control design, then the outer economic model-predictive controller
compensates for model mismatches, enforces suitable constraints, and boosts the
tracking performance. The effectiveness of the proposed approach as compared to
traditional dynamic programming strategies is illustrated on an accurate
simulator of the Hoa Binh reservoir in Vietnam. Results show that the proposed
approach performs better than the one based on stochastic dynamic programming.
</dc:description>
 <dc:date>2020-12-24</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.13224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.13253</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Soft-IntroVAE: Analyzing and Improving the Introspective Variational
  Autoencoder</dc:title>
 <dc:creator>Daniel, Tal</dc:creator>
 <dc:creator>Tamar, Aviv</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The recently introduced introspective variational autoencoder (IntroVAE)
exhibits outstanding image generations, and allows for amortized inference
using an image encoder. The main idea in IntroVAE is to train a VAE
adversarially, using the VAE encoder to discriminate between generated and real
data samples. However, the original IntroVAE loss function relied on a
particular hinge-loss formulation that is very hard to stabilize in practice,
and its theoretical convergence analysis ignored important terms in the loss.
In this work, we take a step towards better understanding of the IntroVAE
model, its practical implementation, and its applications. We propose the
Soft-IntroVAE, a modified IntroVAE that replaces the hinge-loss terms with a
smooth exponential loss on generated samples. This change significantly
improves training stability, and also enables theoretical analysis of the
complete algorithm. Interestingly, we show that the IntroVAE converges to a
distribution that minimizes a sum of KL distance from the data distribution and
an entropy term. We discuss the implications of this result, and demonstrate
that it induces competitive image generation and reconstruction. Finally, we
describe two applications of Soft-IntroVAE to unsupervised image translation
and out-of-distribution detection, and demonstrate compelling results. Code and
additional information is available on the project website --
https://taldatech.github.io/soft-intro-vae-web
</dc:description>
 <dc:description>Comment: CVPR 2021, Extended version. Code and additional information is
  available on the project website -
  https://taldatech.github.io/soft-intro-vae-web</dc:description>
 <dc:date>2020-12-24</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.13253</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.13321</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised deep clustering and reinforcement learning can accurately
  segment MRI brain tumors with very small training sets</dc:title>
 <dc:creator>Stember, Joseph</dc:creator>
 <dc:creator>Shalu, Hrithwik</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Purpose: Lesion segmentation in medical imaging is key to evaluating
treatment response. We have recently shown that reinforcement learning can be
applied to radiological images for lesion localization. Furthermore, we
demonstrated that reinforcement learning addresses important limitations of
supervised deep learning; namely, it can eliminate the requirement for large
amounts of annotated training data and can provide valuable intuition lacking
in supervised approaches. However, we did not address the fundamental task of
lesion/structure-of-interest segmentation. Here we introduce a method combining
unsupervised deep learning clustering with reinforcement learning to segment
brain lesions on MRI.
  Materials and Methods: We initially clustered images using unsupervised deep
learning clustering to generate candidate lesion masks for each MRI image. The
user then selected the best mask for each of 10 training images. We then
trained a reinforcement learning algorithm to select the masks. We tested the
corresponding trained deep Q network on a separate testing set of 10 images.
For comparison, we also trained and tested a U-net supervised deep learning
network on the same set of training/testing images.
  Results: Whereas the supervised approach quickly overfit the training data
and predictably performed poorly on the testing set (16% average Dice score),
the unsupervised deep clustering and reinforcement learning achieved an average
Dice score of 83%.
  Conclusion: We have demonstrated a proof-of-principle application of
unsupervised deep clustering and reinforcement learning to segment brain
tumors. The approach represents human-allied AI that requires minimal input
from the radiologist without the need for hand-traced annotation.
</dc:description>
 <dc:date>2020-12-24</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.13321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.13626</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting the patient's need for help with machine learning</dc:title>
 <dc:creator>Lahti, Lauri</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Developing machine learning models to support health analytics requires
increased understanding about statistical properties of self-rated expression
statements. We analyzed self-rated expression statements concerning the
coronavirus COVID-19 epidemic to identify statistically significant differences
between groups of respondents and to detect the patient's need for help with
machine learning. Our quantitative study gathered the &quot;need for help&quot; ratings
for twenty health-related expression statements concerning the coronavirus
epidemic on a 11-point Likert scale, and nine answers about the person's health
and wellbeing, sex and age. Online respondents between 30 May and 3 August 2020
were recruited from Finnish patient and disabled people's organizations, other
health-related organizations and professionals, and educational institutions
(n=673). We analyzed rating differences and dependencies with Kendall
rank-correlation and cosine similarity measures and tests of Wilcoxon rank-sum,
Kruskal-Wallis and one-way analysis of variance (ANOVA) between groups, and
carried out machine learning experiments with a basic implementation of a
convolutional neural network algorithm. We found statistically significant
correlations and high cosine similarity values between various health-related
expression statement pairs concerning the &quot;need for help&quot; ratings and a
background question pair. We also identified statistically significant rating
differences for several health-related expression statements in respect to
groupings based on the answer values of background questions, such as the
ratings of suspecting to have the coronavirus infection and having it depending
on the estimated health condition, quality of life and sex. Our experiments
with a convolutional neural network algorithm showed the applicability of
machine learning to support detecting the need for help in the patient's
expressions.
</dc:description>
 <dc:description>Comment: Corresponding author: Lauri Lahti (email: lauri.lahti@aalto.fi). The
  first manuscript version of this research article was self-archived
  (arXiv:2012.13626) on 24 December 2020 and this second manuscript version on
  23 March 2021. Changes include extensions, clarifications and corrections.
  This article contains 26 pages, 7 tables and 5 figures. Supplemented with
  Appendix A (12 pages)</dc:description>
 <dc:date>2020-12-25</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.13626</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.13693</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial Reasoning from Natural Language Instructions for Robot
  Manipulation</dc:title>
 <dc:creator>Venkatesh, Sagar Gubbi</dc:creator>
 <dc:creator>Biswas, Anirban</dc:creator>
 <dc:creator>Upadrashta, Raviteja</dc:creator>
 <dc:creator>Srinivasan, Vikram</dc:creator>
 <dc:creator>Talukdar, Partha</dc:creator>
 <dc:creator>Amrutur, Bharadwaj</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Robots that can manipulate objects in unstructured environments and
collaborate with humans can benefit immensely by understanding natural
language. We propose a pipelined architecture of two stages to perform spatial
reasoning on the text input. All the objects in the scene are first localized,
and then the instruction for the robot in natural language and the localized
co-ordinates are mapped to the start and end co-ordinates corresponding to the
locations where the robot must pick up and place the object respectively. We
show that representing the localized objects by quantizing their positions to a
binary grid is preferable to representing them as a list of 2D co-ordinates. We
also show that attention improves generalization and can overcome biases in the
dataset. The proposed method is used to pick-and-place playing cards using a
robot arm.
</dc:description>
 <dc:description>Comment: Accepted for ICRA 2021</dc:description>
 <dc:date>2020-12-26</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.13693</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.13695</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Translating Natural Language Instructions to Computer Programs for Robot
  Manipulation</dc:title>
 <dc:creator>Venkatesh, Sagar Gubbi</dc:creator>
 <dc:creator>Upadrashta, Raviteja</dc:creator>
 <dc:creator>Amrutur, Bharadwaj</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  It is highly desirable for robots that work alongside humans to be able to
understand instructions in natural language. Existing language conditioned
imitation learning models directly predict the actuator commands from the image
observation and the instruction text. Rather than directly predicting actuator
commands, we propose translating the natural language instruction to a Python
function which queries the scene by accessing the output of the object detector
and controls the robot to perform the specified task. This enables the use of
non-differentiable modules such as a constraint solver when computing commands
to the robot. Moreover, the labels in this setup are significantly more
informative computer programs that capture the intent of the expert rather than
teleoperated demonstrations. We show that the proposed method performs better
than training a neural network to directly predict the robot actions.
</dc:description>
 <dc:description>Comment: Submitted to IROS 2021</dc:description>
 <dc:date>2020-12-26</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.13695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.14114</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The graph energy game</dc:title>
 <dc:creator>Arizmendi, Gerardo</dc:creator>
 <dc:creator>Arizmendi, Octavio</dc:creator>
 <dc:subject>Mathematics - Spectral Theory</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>91A12, 91A43, 05C57, 05C50</dc:subject>
 <dc:description>  We study the graph energy from a cooperative game viewpoint. We introduce
\emph{the graph energy game} and show various properties. In particular, we see
that it is a superadditive game and that the energy of a vertex, as defined in
Arizmendi and Juarez-Romero (2018), belongs to the core of the game. These
properties imply new bounds for the energy of graphs. We also consider a
version based on $p$-Schatten norms.
</dc:description>
 <dc:description>Comment: 15 pages, 3 figures</dc:description>
 <dc:date>2020-12-28</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.14114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.14660</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Theoretical Analysis of the Repetition Problem in Text Generation</dc:title>
 <dc:creator>Fu, Zihao</dc:creator>
 <dc:creator>Lam, Wai</dc:creator>
 <dc:creator>So, Anthony Man-Cho</dc:creator>
 <dc:creator>Shi, Bei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Text generation tasks, including translation, summarization, language models,
and etc. see rapid growth during recent years. Despite the remarkable
achievements, the repetition problem has been observed in nearly all text
generation models undermining the generation performance extensively. To solve
the repetition problem, many methods have been proposed, but there is no
existing theoretical analysis to show why this problem happens and how it is
resolved. In this paper, we propose a new framework for theoretical analysis
for the repetition problem. We first define the Average Repetition Probability
(ARP) to characterize the repetition problem quantitatively. Then, we conduct
an extensive analysis of the Markov generation model and derive several upper
bounds of the average repetition probability with intuitive understanding. We
show that most of the existing methods are essentially minimizing the upper
bounds explicitly or implicitly. Grounded on our theory, we show that the
repetition problem is, unfortunately, caused by the traits of our language
itself. One major reason is attributed to the fact that there exist too many
words predicting the same word as the subsequent word with high probability.
Consequently, it is easy to go back to that word and form repetitions and we
dub it as the high inflow problem. Furthermore, we derive a concentration bound
of the average repetition probability for a general generation model. Finally,
based on the theoretical upper bounds, we propose a novel rebalanced encoding
approach to alleviate the high inflow problem. The experimental results show
that our theoretical framework is applicable in general generation models and
our proposed rebalanced encoding approach alleviates the repetition problem
significantly. The source code of this paper can be obtained from
https://github.com/fuzihaofzh/repetition-problem-nlg.
</dc:description>
 <dc:description>Comment: AAAI 21 Paper with Appendix</dc:description>
 <dc:date>2020-12-29</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.14660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.14778</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Semilattices and Semimodules</dc:title>
 <dc:creator>Bonchi, Filippo</dc:creator>
 <dc:creator>Santamaria, Alessio</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  We describe the canonical weak distributive law $\delta \colon \mathcal S
\mathcal P \to \mathcal P \mathcal S$ of the powerset monad $\mathcal P$ over
the $S$-left-semimodule monad $\mathcal S$, for a class of semirings $S$. We
show that the composition of $\mathcal P$ with $\mathcal S$ by means of such
$\delta$ yields almost the monad of convex subsets previously introduced by
Jacobs: the only difference consists in the absence in Jacobs's monad of the
empty convex set. We provide a handy characterisation of the canonical weak
lifting of $\mathcal P$ to $\mathbb{EM}(\mathcal S)$ as well as an algebraic
theory for the resulting composed monad. Finally, we restrict the composed
monad to finitely generated convex subsets and we show that it is presented by
an algebraic theory combining semimodules and semilattices with bottom, which
are the algebras for the finite powerset monad $\mathcal P_f$.
</dc:description>
 <dc:date>2020-12-29</dc:date>
 <dc:date>2021-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.14778</dc:identifier>
 <dc:identifier>Foundations of Software Science and Computation Structures.
  FOSSACS 2021. Lecture Notes in Computer Science, vol 12650 (2021), pp
  102-123. Springer, Cham</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-030-71995-1_6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.14791</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Drift-Aware Multi-Memory Model for Imbalanced Data Streams</dc:title>
 <dc:creator>Abolfazli, Amir</dc:creator>
 <dc:creator>Ntoutsi, Eirini</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Online class imbalance learning deals with data streams that are affected by
both concept drift and class imbalance. Online learning tries to find a
trade-off between exploiting previously learned information and incorporating
new information into the model. This requires both the incremental update of
the model and the ability to unlearn outdated information. The improper use of
unlearning, however, can lead to the retroactive interference problem, a
phenomenon that occurs when newly learned information interferes with the old
information and impedes the recall of previously learned information. The
problem becomes more severe when the classes are not equally represented,
resulting in the removal of minority information from the model. In this work,
we propose the Drift-Aware Multi-Memory Model (DAM3), which addresses the class
imbalance problem in online learning for memory-based models. DAM3 mitigates
class imbalance by incorporating an imbalance-sensitive drift detector,
preserving a balanced representation of classes in the model, and resolving
retroactive interference using a working memory that prevents the forgetting of
old information. We show through experiments on real-world and synthetic
datasets that the proposed method mitigates class imbalance and outperforms the
state-of-the-art methods.
</dc:description>
 <dc:date>2020-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.14791</dc:identifier>
 <dc:identifier>doi:10.1109/BigData50022.2020.9378101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.14848</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tube-enhanced Multi-stage MPC for Flexible Robust Control of Constrained
  Linear Systems with Additive and Parametric Uncertainties</dc:title>
 <dc:creator>Subramanian, Sankaranarayanan</dc:creator>
 <dc:creator>Lucia, Sergio</dc:creator>
 <dc:creator>Paulen, Radoslav</dc:creator>
 <dc:creator>Engell, Sebastian</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  The trade-off between optimality and complexity has been one of the most
important challenges in the field of robust Model Predictive Control (MPC). To
address the challenge, we propose a flexible robust MPC scheme by synergizing
the multi-stage and tube-based MPC approaches. The key idea is to exploit the
non-conservatism of the multi-stage MPC and the simplicity of the tube-based
MPC. The proposed scheme provides two options for the user to determine the
trade-off depending on the application: the choice of the robust horizon and
the classification of the uncertainties. Beyond the robust horizon, the
branching of the scenario-tree employed in multi-stage MPC is avoided with the
help of tubes. The growth of the problem size with respect to the number of
uncertainties is reduced by handling \emph{small} uncertainties via an
invariant tube that can be computed offline. This results in linear growth of
the problem size beyond the robust horizon and no growth of the problem size
concerning small magnitude uncertainties. The proposed approach helps to
achieve a desired trade-off between optimality and complexity compared to
existing robust MPC approaches. We show that the proposed approach is robustly
asymptotically stable. Its advantages are demonstrated for a CSTR example.
</dc:description>
 <dc:description>Comment: 37 pages, 10 figures, 2 tables. Journal under review</dc:description>
 <dc:date>2020-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.14848</dc:identifier>
 <dc:identifier>doi:10.1002/rnc.5486</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.14970</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Alternative Paths Planner (APP) for Provably Fixed-time Manipulation
  Planning in Semi-structured Environments</dc:title>
 <dc:creator>Islam, Fahad</dc:creator>
 <dc:creator>Paxton, Chris</dc:creator>
 <dc:creator>Eppner, Clemens</dc:creator>
 <dc:creator>Peele, Bryan</dc:creator>
 <dc:creator>Likhachev, Maxim</dc:creator>
 <dc:creator>Fox, Dieter</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In many applications, including logistics and manufacturing, robot
manipulators operate in semi-structured environments alongside humans or other
robots. These environments are largely static, but they may contain some
movable obstacles that the robot must avoid. Manipulation tasks in these
applications are often highly repetitive, but require fast and reliable motion
planning capabilities, often under strict time constraints. Existing
preprocessing-based approaches are beneficial when the environments are
highly-structured, but their performance degrades in the presence of movable
obstacles, since these are not modelled a priori. We propose a novel
preprocessing-based method called Alternative Paths Planner (APP) that provides
provably fixed-time planning guarantees in semi-structured environments. APP
plans a set of alternative paths offline such that, for any configuration of
the movable obstacles, at least one of the paths from this set is
collision-free. During online execution, a collision-free path can be looked up
efficiently within a few microseconds. We evaluate APP on a 7 DoF robot arm in
semi-structured domains of varying complexity and demonstrate that APP is
several orders of magnitude faster than state-of-the-art motion planners for
each domain. We further validate this approach with real-time experiments on a
robotic manipulator.
</dc:description>
 <dc:date>2020-12-29</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.14970</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.15175</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rethinking the Heatmap Regression for Bottom-up Human Pose Estimation</dc:title>
 <dc:creator>Luo, Zhengxiong</dc:creator>
 <dc:creator>Wang, Zhicheng</dc:creator>
 <dc:creator>Huang, Yan</dc:creator>
 <dc:creator>Tan, Tieniu</dc:creator>
 <dc:creator>Zhou, Erjin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Heatmap regression has become the most prevalent choice for nowadays human
pose estimation methods. The ground-truth heatmaps are usually constructed via
covering all skeletal keypoints by 2D gaussian kernels. The standard deviations
of these kernels are fixed. However, for bottom-up methods, which need to
handle a large variance of human scales and labeling ambiguities, the current
practice seems unreasonable. To better cope with these problems, we propose the
scale-adaptive heatmap regression (SAHR) method, which can adaptively adjust
the standard deviation for each keypoint. In this way, SAHR is more tolerant of
various human scales and labeling ambiguities. However, SAHR may aggravate the
imbalance between fore-background samples, which potentially hurts the
improvement of SAHR. Thus, we further introduce the weight-adaptive heatmap
regression (WAHR) to help balance the fore-background samples. Extensive
experiments show that SAHR together with WAHR largely improves the accuracy of
bottom-up human pose estimation. As a result, we finally outperform the
state-of-the-art model by +1.5AP and achieve 72.0AP on COCO test-dev2017, which
is com-arable with the performances of most top-down methods. Source codes are
available at https://github.com/greatlog/SWAHR-HumanPose.
</dc:description>
 <dc:description>Comment: Accepted by CVPR2021</dc:description>
 <dc:date>2020-12-30</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.15175</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2012.15838</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Body: Implicit Neural Representations with Structured Latent
  Codes for Novel View Synthesis of Dynamic Humans</dc:title>
 <dc:creator>Peng, Sida</dc:creator>
 <dc:creator>Zhang, Yuanqing</dc:creator>
 <dc:creator>Xu, Yinghao</dc:creator>
 <dc:creator>Wang, Qianqian</dc:creator>
 <dc:creator>Shuai, Qing</dc:creator>
 <dc:creator>Bao, Hujun</dc:creator>
 <dc:creator>Zhou, Xiaowei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper addresses the challenge of novel view synthesis for a human
performer from a very sparse set of camera views. Some recent works have shown
that learning implicit neural representations of 3D scenes achieves remarkable
view synthesis quality given dense input views. However, the representation
learning will be ill-posed if the views are highly sparse. To solve this
ill-posed problem, our key idea is to integrate observations over video frames.
To this end, we propose Neural Body, a new human body representation which
assumes that the learned neural representations at different frames share the
same set of latent codes anchored to a deformable mesh, so that the
observations across frames can be naturally integrated. The deformable mesh
also provides geometric guidance for the network to learn 3D representations
more efficiently. To evaluate our approach, we create a multi-view dataset
named ZJU-MoCap that captures performers with complex motions. Experiments on
ZJU-MoCap show that our approach outperforms prior works by a large margin in
terms of novel view synthesis quality. We also demonstrate the capability of
our approach to reconstruct a moving person from a monocular video on the
People-Snapshot dataset. The code and dataset are available at
https://zju3dv.github.io/neuralbody/.
</dc:description>
 <dc:description>Comment: CVPR 2021. Project page: https://zju3dv.github.io/neuralbody/</dc:description>
 <dc:date>2020-12-31</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2012.15838</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.00002</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic-differentiated Physics-Informed Echo State Network (API-ESN)</dc:title>
 <dc:creator>Racca, Alberto</dc:creator>
 <dc:creator>Magri, Luca</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:description>  We propose the Automatic-differentiated Physics-Informed Echo State Network
(API-ESN). The network is constrained by the physical equations through the
reservoir's exact time-derivative, which is computed by automatic
differentiation. As compared to the original Physics-Informed Echo State
Network, the accuracy of the time-derivative is increased by up to seven orders
of magnitude. This increased accuracy is key in chaotic dynamical systems,
where errors grows exponentially in time. The network is showcased in the
reconstruction of unmeasured (hidden) states of a chaotic system. The API-ESN
eliminates a source of error, which is present in existing physics-informed
echo state networks, in the computation of the time-derivative. This opens up
new possibilities for an accurate reconstruction of chaotic dynamical states.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures</dc:description>
 <dc:date>2020-12-28</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.00002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.00200</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>More than just an auxiliary loss: Anti-spoofing Backbone Training via
  Adversarial Pseudo-depth Generation</dc:title>
 <dc:creator>Paik, Chang Keun</dc:creator>
 <dc:creator>Ko, Naeun</dc:creator>
 <dc:creator>Yoo, Youngjoon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper, a new method of training pipeline is discussed to achieve
significant performance on the task of anti-spoofing with RGB image. We explore
and highlight the impact of using pseudo-depth to pre-train a network that will
be used as the backbone to the final classifier. While the usage of
pseudo-depth for anti-spoofing task is not a new idea on its own, previous
endeavours utilize pseudo-depth simply as another medium to extract features
for performing prediction, or as part of many auxiliary losses in aiding the
training of the main classifier, normalizing the importance of pseudo-depth as
just another semantic information. Through this work, we argue that there
exists a significant advantage in training the final classifier can be gained
by the pre-trained generator learning to predict the corresponding pseudo-depth
of a given facial image, from a Generative Adversarial Network framework. Our
experimental results indicate that our method results in a much more adaptable
system that can generalize beyond intra-dataset samples, but to inter-dataset
samples, which it has never seen before during training. Quantitatively, our
method approaches the baseline performance of the current state of the art
anti-spoofing models with 15.8x less parameters used. Moreover, experiments
showed that the introduced methodology performs well only using basic binary
label without additional semantic information which indicates potential
benefits of this work in industrial and application based environment where
trade-off between additional labelling and resources are considered.
</dc:description>
 <dc:date>2021-01-01</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.00200</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.00337</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Biologically Inspired Hexagonal Deep Learning for Hexagonal Image
  Generation</dc:title>
 <dc:creator>Schlosser, Tobias</dc:creator>
 <dc:creator>Beuth, Frederik</dc:creator>
 <dc:creator>Kowerko, Danny</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Whereas conventional state-of-the-art image processing systems of recording
and output devices almost exclusively utilize square arranged methods,
biological models, however, suggest an alternative, evolutionarily-based
structure. Inspired by the human visual perception system, hexagonal image
processing in the context of machine learning offers a number of key advantages
that can benefit both researchers and users alike. The hexagonal deep learning
framework Hexnet leveraged in this contribution serves therefore the generation
of hexagonal images by utilizing hexagonal deep neural networks (H-DNN). As the
results of our created test environment show, the proposed models can surpass
current approaches of conventional image generation. While resulting in a
reduction of the models' complexity in the form of trainable parameters, they
furthermore allow an increase of test rates in comparison to their square
counterparts.
</dc:description>
 <dc:description>Comment: Accepted for: 2020 IEEE 27th International Conference on Image
  Processing (ICIP); this article draws heavily from arXiv:1911.11251</dc:description>
 <dc:date>2021-01-01</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.00337</dc:identifier>
 <dc:identifier>doi:10.1109/ICIP40778.2020.9190995</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.00442</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CryoNuSeg: A Dataset for Nuclei Instance Segmentation of Cryosectioned
  H&amp;E-Stained Histological Images</dc:title>
 <dc:creator>Mahbod, Amirreza</dc:creator>
 <dc:creator>Schaefer, Gerald</dc:creator>
 <dc:creator>Bancher, Benjamin</dc:creator>
 <dc:creator>L&#xf6;w, Christine</dc:creator>
 <dc:creator>Dorffner, Georg</dc:creator>
 <dc:creator>Ecker, Rupert</dc:creator>
 <dc:creator>Ellinger, Isabella</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Nuclei instance segmentation plays an important role in the analysis of
Hematoxylin and Eosin (H&amp;E)-stained images. While supervised deep learning
(DL)-based approaches represent the state-of-the-art in automatic nuclei
instance segmentation, annotated datasets are required to train these models.
There are two main types of tissue processing protocols, namely formalin-fixed
paraffin-embedded samples (FFPE) and frozen tissue samples (FS). Although
FFPE-derived H&amp;E stained tissue sections are the most widely used samples, H&amp;E
staining on frozen sections derived from FS samples is a relevant method in
intra-operative surgical sessions as it can be performed fast. Due to
differences in the protocols of these two types of samples, the derived images
and in particular the nuclei appearance may be different in the acquired whole
slide images. Analysis of FS-derived H&amp;E stained images can be more challenging
as rapid preparation, staining, and scanning of FS sections may lead to
deterioration in image quality.
  In this paper, we introduce CryoNuSeg, the first fully annotated FS-derived
cryosectioned and H&amp;E-stained nuclei instance segmentation dataset. The dataset
contains images from 10 human organs that were not exploited in other publicly
available datasets, and is provided with three manual mark-ups to allow
measuring intra-observer and inter-observer variability. Moreover, we
investigate the effects of tissue fixation/embedding protocol (i.e., FS or
FFPE) on the automatic nuclei instance segmentation performance of one of the
state-of-the-art DL approaches. We also create a baseline segmentation
benchmark for the dataset that can be used in future research.
  A step-by-step guide to generate the dataset as well as the full dataset and
other detailed information are made available to fellow researchers at
https://github.com/masih4/CryoNuSeg.
</dc:description>
 <dc:date>2021-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.00442</dc:identifier>
 <dc:identifier>doi:10.1016/j.compbiomed.2021.104349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.00515</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A General Deep Reinforcement Learning Framework for Grant-Free NOMA
  Optimization in mURLLC</dc:title>
 <dc:creator>Liu, Yan</dc:creator>
 <dc:creator>Deng, Yansha</dc:creator>
 <dc:creator>Zhou, Hui</dc:creator>
 <dc:creator>Elkashlan, Maged</dc:creator>
 <dc:creator>Nallanathan, Arumugam</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Grant-free non-orthogonal multiple access (GF-NOMA) is a potential technique
to support massive Ultra-Reliable and Low-Latency Communication (mURLLC)
service. However, the dynamic resource configuration in GF-NOMA systems is
challenging due to random traffics and collisions, that are unknown at the base
station (BS). Meanwhile, joint consideration of the latency and reliability
requirements makes the resource configuration of GF-NOMA for mURLLC more
complex. To address this problem, we develop a general learning framework for
signature-based GF-NOMA in mURLLC service taking into account the multiple
access signature collision, the UE detection, as well as the data decoding
procedures for the K-repetition GF and the Proactive GF schemes. The goal of
our learning framework is to maximize the long-term average number of
successfully served users (UEs) under the latency constraint. We first perform
a real-time repetition value configuration based on a double deep Q-Network
(DDQN) and then propose a Cooperative Multi-Agent learning technique based on
the DQN (CMA-DQN) to optimize the configuration of both the repetition values
and the contention-transmission unit (CTU) numbers. Our results show that the
number of successfully served UEs under the same latency constraint in our
proposed learning framework is up to ten times for the K-repetition scheme, and
two times for the Proactive scheme, more than that with fixed repetition values
and CTU numbers. In addition, the superior performance of CMA-DQN over the
conventional load estimation-based approach (LE-URC) demonstrates its
capability in dynamically configuring in long term. Importantly, our general
learning framework can be used to optimize the resource configuration problems
in all the signature-based GF-NOMA schemes.
</dc:description>
 <dc:description>Comment: 31 pages, 15 figures</dc:description>
 <dc:date>2021-01-02</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.00515</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.00545</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action
  Localization</dc:title>
 <dc:creator>Islam, Ashraful</dc:creator>
 <dc:creator>Long, Chengjiang</dc:creator>
 <dc:creator>Radke, Richard</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Weakly supervised temporal action localization is a challenging vision task
due to the absence of ground-truth temporal locations of actions in the
training videos. With only video-level supervision during training, most
existing methods rely on a Multiple Instance Learning (MIL) framework to
predict the start and end frame of each action category in a video. However,
the existing MIL-based approach has a major limitation of only capturing the
most discriminative frames of an action, ignoring the full extent of an
activity. Moreover, these methods cannot model background activity effectively,
which plays an important role in localizing foreground activities. In this
paper, we present a novel framework named HAM-Net with a hybrid attention
mechanism which includes temporal soft, semi-soft and hard attentions to
address these issues. Our temporal soft attention module, guided by an
auxiliary background class in the classification module, models the background
activity by introducing an &quot;action-ness&quot; score for each video snippet.
Moreover, our temporal semi-soft and hard attention modules, calculating two
attention scores for each video snippet, help to focus on the less
discriminative frames of an action to capture the full action boundary. Our
proposed approach outperforms recent state-of-the-art methods by at least 2.2%
mAP at IoU threshold 0.5 on the THUMOS14 dataset, and by at least 1.3% mAP at
IoU threshold 0.75 on the ActivityNet1.2 dataset. Code can be found at:
https://github.com/asrafulashiq/hamnet.
</dc:description>
 <dc:description>Comment: Extended version/preprint of a AAAI 2021 paper</dc:description>
 <dc:date>2021-01-02</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.00545</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.01121</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Competition and Stochasticity for Adversarial Robustness in Deep
  Learning</dc:title>
 <dc:creator>Panousis, Konstantinos P.</dc:creator>
 <dc:creator>Chatzis, Sotirios</dc:creator>
 <dc:creator>Alexos, Antonios</dc:creator>
 <dc:creator>Theodoridis, Sergios</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This work addresses adversarial robustness in deep learning by considering
deep networks with stochastic local winner-takes-all (LWTA) activations. This
type of network units result in sparse representations from each model layer,
as the units are organized in blocks where only one unit generates a non-zero
output. The main operating principle of the introduced units lies on stochastic
arguments, as the network performs posterior sampling over competing units to
select the winner. We combine these LWTA arguments with tools from the field of
Bayesian non-parametrics, specifically the stick-breaking construction of the
Indian Buffet Process, to allow for inferring the sub-part of each layer that
is essential for modeling the data at hand. Then, inference is performed by
means of stochastic variational Bayes. We perform a thorough experimental
evaluation of our model using benchmark datasets. As we show, our method
achieves high robustness to adversarial perturbations, with state-of-the-art
performance in powerful adversarial attack schemes.
</dc:description>
 <dc:description>Comment: Accepted AISTATS 2021. arXiv admin note: text overlap with
  arXiv:2006.10620</dc:description>
 <dc:date>2021-01-04</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.01121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.01297</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Composable Geometric Motion Policies using Multi-Task Pullback Bundle
  Dynamical Systems</dc:title>
 <dc:creator>Bylard, Andrew</dc:creator>
 <dc:creator>Bonalli, Riccardo</dc:creator>
 <dc:creator>Pavone, Marco</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Despite decades of work in fast reactive planning and control, challenges
remain in developing reactive motion policies on non-Euclidean manifolds and
enforcing constraints while avoiding undesirable potential function local
minima. This work presents a principled method for designing and fusing desired
robot task behaviors into a stable robot motion policy, leveraging the
geometric structure of non-Euclidean manifolds, which are prevalent in robot
configuration and task spaces. Our Pullback Bundle Dynamical Systems (PBDS)
framework drives desired task behaviors and prioritizes tasks using separate
position-dependent and position/velocity-dependent Riemannian metrics,
respectively, thus simplifying individual task design and modular composition
of tasks. For enforcing constraints, we provide a class of metric-based tasks,
eliminating local minima by imposing non-conflicting potential functions only
for goal region attraction. We also provide a geometric optimization problem
for combining tasks inspired by Riemannian Motion Policies (RMPs) that reduces
to a simple least-squares problem, and we show that our approach is
geometrically well-defined. We demonstrate the PBDS framework on the sphere
$\mathbb S^2$ and at 300-500 Hz on a manipulator arm, and we provide task
design guidance and an open-source Julia library implementation. Overall, this
work presents a fast, easy-to-use framework for generating motion policies
without unwanted potential function local minima on general manifolds.
</dc:description>
 <dc:date>2021-01-04</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.01297</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.01601</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bilateral Grid Learning for Stereo Matching Networks</dc:title>
 <dc:creator>Xu, Bin</dc:creator>
 <dc:creator>Xu, Yuhua</dc:creator>
 <dc:creator>Yang, Xiaoli</dc:creator>
 <dc:creator>Jia, Wei</dc:creator>
 <dc:creator>Guo, Yulan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Real-time performance of stereo matching networks is important for many
applications, such as automatic driving, robot navigation and augmented reality
(AR). Although significant progress has been made in stereo matching networks
in recent years, it is still challenging to balance real-time performance and
accuracy. In this paper, we present a novel edge-preserving cost volume
upsampling module based on the slicing operation in the learned bilateral grid.
The slicing layer is parameter-free, which allows us to obtain a high quality
cost volume of high resolution from a low-resolution cost volume under the
guide of the learned guidance map efficiently. The proposed cost volume
upsampling module can be seamlessly embedded into many existing stereo matching
networks, such as GCNet, PSMNet, and GANet. The resulting networks are
accelerated several times while maintaining comparable accuracy. Furthermore,
we design a real-time network (named BGNet) based on this module, which
outperforms existing published real-time deep stereo matching networks, as well
as some complex networks on the KITTI stereo datasets. The code is available at
https://github.com/YuhuaXu/BGNet.
</dc:description>
 <dc:description>Comment: CVPR 2021</dc:description>
 <dc:date>2021-01-01</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.01601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.01708</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Priori Generalization Analysis of the Deep Ritz Method for Solving
  High Dimensional Elliptic Equations</dc:title>
 <dc:creator>Lu, Jianfeng</dc:creator>
 <dc:creator>Lu, Yulong</dc:creator>
 <dc:creator>Wang, Min</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper concerns the a priori generalization analysis of the Deep Ritz
Method (DRM) [W. E and B. Yu, 2017], a popular neural-network-based method for
solving high dimensional partial differential equations. We derive the
generalization error bounds of two-layer neural networks in the framework of
the DRM for solving two prototype elliptic PDEs: Poisson equation and static
Schr\&quot;odinger equation on the $d$-dimensional unit hypercube. Specifically, we
prove that the convergence rates of generalization errors are independent of
the dimension $d$, under the a priori assumption that the exact solutions of
the PDEs lie in a suitable low-complexity space called spectral Barron space.
Moreover, we give sufficient conditions on the forcing term and the potential
function which guarantee that the solutions are spectral Barron functions. We
achieve this by developing a new solution theory for the PDEs on the spectral
Barron space, which can be viewed as an analog of the classical Sobolev
regularity theory for PDEs.
</dc:description>
 <dc:description>Comment: Revised the definition of Barron space and updated the proofs induced
  by the changes</dc:description>
 <dc:date>2021-01-05</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.01708</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.01950</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HERMES: Scalable, Secure, and Privacy-Enhancing Vehicle Access System</dc:title>
 <dc:creator>Symeonidis, Iraklis</dc:creator>
 <dc:creator>Rotaru, Dragos</dc:creator>
 <dc:creator>Mustafa, Mustafa A.</dc:creator>
 <dc:creator>Mennink, Bart</dc:creator>
 <dc:creator>Preneel, Bart</dc:creator>
 <dc:creator>Papadimitratos, Panos</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We propose HERMES, a scalable, secure, and privacy-enhancing system for users
to share and access vehicles. HERMES securely outsources operations of vehicle
access token generation to a set of untrusted servers. It builds on an earlier
proposal, namely SePCAR [1], and extends the system design for improved
efficiency and scalability. To cater to system and user needs for secure and
private computations, HERMES utilizes and combines several cryptographic
primitives with secure multiparty computation efficiently. It conceals secret
keys of vehicles and transaction details from the servers, including vehicle
booking details, access token information, and user and vehicle identities. It
also provides user accountability in case of disputes. Besides, we provide
semantic security analysis and prove that HERMES meets its security and privacy
requirements. Last but not least, we demonstrate that HERMES is efficient and,
in contrast to SePCAR, scales to a large number of users and vehicles, making
it practical for real-world deployments. We build our evaluations with two
different multiparty computation protocols: HtMAC-MiMC and CBC-MAC-AES. Our
results demonstrate that HERMES with HtMAC-MiMC requires only approx 1,83 ms
for generating an access token for a single-vehicle owner and approx 11,9 ms
for a large branch of rental companies with over a thousand vehicles. It
handles 546 and 84 access token generations per second, respectively. This
results in HERMES being 696 (with HtMAC-MiMC) and 42 (with CBC-MAC-AES) times
faster compared to in SePCAR for a single-vehicle owner access token
generation. Furthermore, we show that HERMES is practical on the vehicle side,
too, as access token operations performed on a prototype vehicle on-board unit
take only approx 62,087 ms.
</dc:description>
 <dc:date>2021-01-06</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.01950</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.02504</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Quantum Computing and Network Control for Accelerated VQE</dc:title>
 <dc:creator>DiAdamo, Stephen</dc:creator>
 <dc:creator>Ghibaudi, Marco</dc:creator>
 <dc:creator>Cruise, James</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Interconnecting small quantum computers will be essential in the future for
creating large scale, robust quantum computers. Methods for distributing
monolithic quantum algorithms efficiently are thus needed. In this work we
consider an approach for distributing the accelerated variational quantum
eigensolver (AVQE) algorithm over arbitrary sized - in terms of number of
qubits - distributed quantum computers. We consider approaches for distributing
qubit assignments of the Ansatz states required to estimate the expectation
value of Hamiltonian operators in quantum chemistry in a parallelized
computation and provide a systematic approach to generate distributed quantum
circuits for distributed quantum computing. Moreover, we propose an
architecture for a distributed quantum control system in the settings of
centralized and decentralized network control.
</dc:description>
 <dc:description>Comment: This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</dc:description>
 <dc:date>2021-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.02504</dc:identifier>
 <dc:identifier>IEEE Transactions on Quantum Engineering 2021</dc:identifier>
 <dc:identifier>doi:10.1109/TQE.2021.3057908</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.02591</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Data Management in Neutron Scattering Data Reduction Workflows
  at ORNL</dc:title>
 <dc:creator>Godoy, William F</dc:creator>
 <dc:creator>Peterson, Peter F</dc:creator>
 <dc:creator>Hahn, Steven E</dc:creator>
 <dc:creator>Billings, Jay J</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Oak Ridge National Laboratory (ORNL) experimental neutron science facilities
produce 1.2\,TB a day of raw event-based data that is stored using the standard
metadata-rich NeXus schema built on top of the HDF5 file format. Performance of
several data reduction workflows is largely determined by the amount of time
spent on the loading and processing algorithms in Mantid, an open-source data
analysis framework used across several neutron sciences facilities around the
world. The present work introduces new data management algorithms to address
identified input output (I/O) bottlenecks on Mantid. First, we introduce an
in-memory binary-tree metadata index that resemble NeXus data access patterns
to provide a scalable search and extraction mechanism. Second, data
encapsulation in Mantid algorithms is optimally redesigned to reduce the total
compute and memory runtime footprint associated with metadata I/O
reconstruction tasks. Results from this work show speed ups in wall-clock time
on ORNL data reduction workflows, ranging from 11\% to 30\% depending on the
complexity of the targeted instrument-specific data. Nevertheless, we highlight
the need for more research to address reduction challenges as experimental data
volumes increase.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures, International Workshop on Big Data Reduction held
  with 2020 IEEE International Conference on Big Data</dc:description>
 <dc:date>2021-01-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.02591</dc:identifier>
 <dc:identifier>doi:10.1109/BigData50022.2020.9377836</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.02839</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Domain Adaptation of Black-Box Source Models</dc:title>
 <dc:creator>Zhang, Haojian</dc:creator>
 <dc:creator>Zhang, Yabin</dc:creator>
 <dc:creator>Jia, Kui</dc:creator>
 <dc:creator>Zhang, Lei</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Unsupervised domain adaptation (UDA) aims to learn models for a target domain
of unlabeled data by transferring knowledge from a labeled source domain. In
the traditional UDA setting, labeled source data are assumed to be available
for adaptation. Due to increasing concerns for data privacy, source-free UDA is
highly appreciated as a new UDA setting, where only a trained source model is
assumed to be available, while labeled source data remain private. However,
trained source models may also be unavailable in practice since source models
may have commercial values and exposing source models brings risks to the
source domain, e.g., problems of model misuse and white-box attacks. In this
work, we study a subtly different setting, named Black-Box Unsupervised Domain
Adaptation (B$^2$UDA), where only the application programming interface of
source model is accessible to the target domain; in other words, the source
model itself is kept as a black-box one. To tackle B$^2$UDA, we propose a
simple yet effective method, termed Iterative Learning with Noisy Labels
(IterLNL). With black-box models as tools of noisy labeling, IterLNL conducts
noisy labeling and learning with noisy labels (LNL), iteratively. To facilitate
the implementation of LNL in B$^2$UDA, we estimate the noise rate from model
predictions of unlabeled target data and propose category-wise sampling to
tackle the unbalanced label noise among categories. Experiments on benchmark
datasets show the efficacy of IterLNL. Given neither source data nor source
models, IterLNL performs comparably with traditional UDA methods that make full
use of labeled source data.
</dc:description>
 <dc:date>2021-01-07</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.02839</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.02997</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differentially Private Federated Learning for Cancer Prediction</dc:title>
 <dc:creator>Beguier, Constance</dc:creator>
 <dc:creator>Terrail, Jean Ogier du</dc:creator>
 <dc:creator>Meah, Iqraa</dc:creator>
 <dc:creator>Andreux, Mathieu</dc:creator>
 <dc:creator>Tramel, Eric W.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Since 2014, the NIH funded iDASH (integrating Data for Analysis,
Anonymization, SHaring) National Center for Biomedical Computing has hosted
yearly competitions on the topic of private computing for genomic data. For one
track of the 2020 iteration of this competition, participants were challenged
to produce an approach to federated learning (FL) training of genomic cancer
prediction models using differential privacy (DP), with submissions ranked
according to held-out test accuracy for a given set of DP budgets. More
precisely, in this track, we are tasked with training a supervised model for
the prediction of breast cancer occurrence from genomic data split between two
virtual centers while ensuring data privacy with respect to model transfer via
DP. In this article, we present our 3rd place submission to this competition.
During the competition, we encountered two main challenges discussed in this
article: i) ensuring correctness of the privacy budget evaluation and ii)
achieving an acceptable trade-off between prediction performance and privacy
budget.
</dc:description>
 <dc:date>2021-01-08</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.02997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.03024</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LiteMuL: A Lightweight On-Device Sequence Tagger using Multi-task
  Learning</dc:title>
 <dc:creator>Kumari, Sonal</dc:creator>
 <dc:creator>Agarwal, Vibhav</dc:creator>
 <dc:creator>Challa, Bharath</dc:creator>
 <dc:creator>Chalamalasetti, Kranti</dc:creator>
 <dc:creator>Ghosh, Sourav</dc:creator>
 <dc:creator>Harshavardhana</dc:creator>
 <dc:creator>Raja, Barath Raj Kandur</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Named entity detection and Parts-of-speech tagging are the key tasks for many
NLP applications. Although the current state of the art methods achieved near
perfection for long, formal, structured text there are hindrances in deploying
these models on memory-constrained devices such as mobile phones. Furthermore,
the performance of these models is degraded when they encounter short,
informal, and casual conversations. To overcome these difficulties, we present
LiteMuL - a lightweight on-device sequence tagger that can efficiently process
the user conversations using a Multi-Task Learning (MTL) approach. To the best
of our knowledge, the proposed model is the first on-device MTL neural model
for sequence tagging. Our LiteMuL model is about 2.39 MB in size and achieved
an accuracy of 0.9433 (for NER), 0.9090 (for POS) on the CoNLL 2003 dataset.
The proposed LiteMuL not only outperforms the current state of the art results
but also surpasses the results of our proposed on-device task-specific models,
with accuracy gains of up to 11% and model-size reduction by 50%-56%. Our model
is competitive with other MTL approaches for NER and POS tasks while outshines
them with a low memory footprint. We also evaluated our model on custom-curated
user conversations and observed impressive results.
</dc:description>
 <dc:description>Comment: Published in 2021 IEEE 15th International Conference on Semantic
  Computing (ICSC); Candidate for Best Paper Award</dc:description>
 <dc:date>2020-12-15</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.03024</dc:identifier>
 <dc:identifier>2021 IEEE 15th International Conference on Semantic Computing
  (ICSC), Laguna Hills, CA, USA, 2021, pp. 1-8</dc:identifier>
 <dc:identifier>doi:10.1109/ICSC50631.2021.00007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.03273</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust and Scalable Routing with Multi-Agent Deep Reinforcement Learning
  for MANETs</dc:title>
 <dc:creator>Kaviani, Saeed</dc:creator>
 <dc:creator>Ryu, Bo</dc:creator>
 <dc:creator>Ahmed, Ejaz</dc:creator>
 <dc:creator>Larson, Kevin A.</dc:creator>
 <dc:creator>Le, Anh</dc:creator>
 <dc:creator>Yahja, Alex</dc:creator>
 <dc:creator>Kim, Jae H.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Highly dynamic mobile ad-hoc networks (MANETs) are continuing to serve as one
of the most challenging environments to develop and deploy robust, efficient,
and scalable routing protocols. In this paper, we present DeepCQ+ routing
which, in a novel manner, integrates emerging multi-agent deep reinforcement
learning (MADRL) techniques into existing Q-learning-based routing protocols
and their variants, and achieves persistently higher performance across a wide
range of MANET configurations while training only on a limited range of network
parameters and conditions. Quantitatively, DeepCQ+ shows consistently higher
end-to-end throughput with lower overhead compared to its Q-learning-based
counterparts with the overall gain of 10-15% in its efficiency. Qualitatively
and more significantly, DeepCQ+ maintains remarkably similar performance gains
under many scenarios that it was not trained for in terms of network sizes,
mobility conditions, and traffic dynamics. To the best of our knowledge, this
is the first successful demonstration of MADRL for the MANET routing problem
that achieves and maintains a high degree of scalability and robustness even in
the environments that are outside the trained range of scenarios. This implies
that the proposed hybrid design approach of DeepCQ+ that combines MADRL and
Q-learning significantly increases its practicality and explainability because
the real-world MANET environment will likely vary outside the trained range of
MANET scenarios.
</dc:description>
 <dc:description>Comment: 14 pages, 8 figures</dc:description>
 <dc:date>2021-01-08</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.03273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.03697</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RepVGG: Making VGG-style ConvNets Great Again</dc:title>
 <dc:creator>Ding, Xiaohan</dc:creator>
 <dc:creator>Zhang, Xiangyu</dc:creator>
 <dc:creator>Ma, Ningning</dc:creator>
 <dc:creator>Han, Jungong</dc:creator>
 <dc:creator>Ding, Guiguang</dc:creator>
 <dc:creator>Sun, Jian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We present a simple but powerful architecture of convolutional neural
network, which has a VGG-like inference-time body composed of nothing but a
stack of 3x3 convolution and ReLU, while the training-time model has a
multi-branch topology. Such decoupling of the training-time and inference-time
architecture is realized by a structural re-parameterization technique so that
the model is named RepVGG. On ImageNet, RepVGG reaches over 80% top-1 accuracy,
which is the first time for a plain model, to the best of our knowledge. On
NVIDIA 1080Ti GPU, RepVGG models run 83% faster than ResNet-50 or 101% faster
than ResNet-101 with higher accuracy and show favorable accuracy-speed
trade-off compared to the state-of-the-art models like EfficientNet and RegNet.
The code and trained models are available at
https://github.com/megvii-model/RepVGG.
</dc:description>
 <dc:description>Comment: CVPR 2021</dc:description>
 <dc:date>2021-01-10</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.03697</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.04340</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Take More Positives: An Empirical Study of Contrastive Learing in
  Unsupervised Person Re-Identification</dc:title>
 <dc:creator>He, Xuanyu</dc:creator>
 <dc:creator>Zhang, Wei</dc:creator>
 <dc:creator>Song, Ran</dc:creator>
 <dc:creator>Zhang, Qian</dc:creator>
 <dc:creator>Lan, Xiangyuan</dc:creator>
 <dc:creator>Ma, Lin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Unsupervised person re-identification (re-ID) aims at closing the performance
gap to supervised methods. These methods build reliable relationship between
data points while learning representations. However, we empirically show that
the reason why they are successful is not only their label generation
mechanisms, but also their unexplored designs. By studying two unsupervised
person re-ID methods in a cross-method way, we point out a hard negative
problem is handled implicitly by their designs of data augmentations and PK
sampler respectively. In this paper, we find another simple solution for the
problem, i.e., taking more positives during training, by which we generate
pseudo-labels and update models in an iterative manner. Based on our findings,
we propose a contrastive learning method without a memory back for unsupervised
person re-ID. Our method works well on benchmark datasets and outperforms the
state-of-the-art methods. Code will be made available.
</dc:description>
 <dc:description>Comment: Technical report, 10 pages</dc:description>
 <dc:date>2021-01-12</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.04340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.04827</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Urban land-use analysis using proximate sensing imagery: a survey</dc:title>
 <dc:creator>Qiao, Zhinan</dc:creator>
 <dc:creator>Yuan, Xiaohui</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Urban regions are complicated functional systems that are closely associated
with and reshaped by human activities. The propagation of online geographic
information-sharing platforms and mobile devices equipped with Global
Positioning System (GPS) greatly proliferates proximate sensing images taken
near or on the ground at a close distance to urban targets. Studies leveraging
proximate sensing imagery have demonstrated great potential to address the need
for local data in urban land-use analysis. This paper reviews and summarizes
the state-of-the-art methods and publicly available datasets from proximate
sensing to support land-use analysis. We identify several research problems in
the perspective of examples to support training of models and means of
integrating diverse data sets. Our discussions highlight the challenges,
strategies, and opportunities faced by the existing methods using proximate
sensing imagery in urban land-use studies.
</dc:description>
 <dc:date>2021-01-12</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.04827</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.06067</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constraint Handling in Continuous-Time DDP-Based Model Predictive
  Control</dc:title>
 <dc:creator>Sleiman, Jean-Pierre</dc:creator>
 <dc:creator>Farshidian, Farbod</dc:creator>
 <dc:creator>Hutter, Marco</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The Sequential Linear Quadratic (SLQ) algorithm is a continuous-time variant
of the well-known Differential Dynamic Programming (DDP) technique with a
Gauss-Newton Hessian approximation. This family of methods has gained
popularity in the robotics community due to its efficiency in solving complex
trajectory optimization problems. However, one major drawback of DDP-based
formulations is their inability to properly incorporate path constraints. In
this paper, we address this issue by devising a constrained SLQ algorithm that
handles a mixture of constraints with a previously implemented projection
technique and a new augmented-Lagrangian approach. By providing an appropriate
multiplier update law, and by solving a single inner and outer loop iteration,
we are able to retrieve suboptimal solutions at rates suitable for real-time
model-predictive control applications. We particularly focus on the
inequality-constrained case, where three augmented-Lagrangian penalty functions
are introduced, along with their corresponding multiplier update rules. These
are then benchmarked against a relaxed log-barrier formulation in a cart-pole
swing up example, an obstacle-avoidance task, and an object-pushing task with a
quadrupedal mobile manipulator.
</dc:description>
 <dc:date>2021-01-15</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.06067</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.06141</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Operationalizing Framing to Support Multiperspective Recommendations of
  Opinion Pieces</dc:title>
 <dc:creator>Mulder, Mats</dc:creator>
 <dc:creator>Inel, Oana</dc:creator>
 <dc:creator>Oosterman, Jasper</dc:creator>
 <dc:creator>Tintarev, Nava</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Diversity in personalized news recommender systems is often defined as
dissimilarity, and based on topic diversity (e.g., corona versus farmers
strike). Diversity in news media, however, is understood as multiperspectivity
(e.g., different opinions on corona measures), and arguably a key
responsibility of the press in a democratic society. While viewpoint diversity
is often considered synonymous with source diversity in communication science
domain, in this paper, we take a computational view. We operationalize the
notion of framing, adopted from communication science. We apply this notion to
a re-ranking of topic-relevant recommended lists, to form the basis of a novel
viewpoint diversification method. Our offline evaluation indicates that the
proposed method is capable of enhancing the viewpoint diversity of
recommendation lists according to a diversity metric from literature. In an
online study, on the Blendle platform, a Dutch news aggregator platform, with
more than 2000 users, we found that users are willing to consume viewpoint
diverse news recommendations. We also found that presentation characteristics
significantly influence the reading behaviour of diverse recommendations. These
results suggest that future research on presentation aspects of recommendations
can be just as important as novel viewpoint diversification methods to truly
achieve multiperspectivity in online news environments.
</dc:description>
 <dc:description>Comment: Accepted to ACM FAccT 2021,
  https://facctconference.org/2021/acceptedpapers.html</dc:description>
 <dc:date>2021-01-15</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.06141</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.06184</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal-Relational CrossTransformers for Few-Shot Action Recognition</dc:title>
 <dc:creator>Perrett, Toby</dc:creator>
 <dc:creator>Masullo, Alessandro</dc:creator>
 <dc:creator>Burghardt, Tilo</dc:creator>
 <dc:creator>Mirmehdi, Majid</dc:creator>
 <dc:creator>Damen, Dima</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel approach to few-shot action recognition, finding
temporally-corresponding frame tuples between the query and videos in the
support set. Distinct from previous few-shot works, we construct class
prototypes using the CrossTransformer attention mechanism to observe relevant
sub-sequences of all support videos, rather than using class averages or single
best matches. Video representations are formed from ordered tuples of varying
numbers of frames, which allows sub-sequences of actions at different speeds
and temporal offsets to be compared.
  Our proposed Temporal-Relational CrossTransformers (TRX) achieve
state-of-the-art results on few-shot splits of Kinetics, Something-Something V2
(SSv2), HMDB51 and UCF101. Importantly, our method outperforms prior work on
SSv2 by a wide margin (12%) due to the its ability to model temporal relations.
A detailed ablation showcases the importance of matching to multiple support
set videos and learning higher-order relational CrossTransformers.
</dc:description>
 <dc:description>Comment: Accepted in CVPR 2021</dc:description>
 <dc:date>2021-01-15</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.06184</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.06326</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grid Search Hyperparameter Benchmarking of BERT, ALBERT, and LongFormer
  on DuoRC</dc:title>
 <dc:creator>Quijano, Alex John</dc:creator>
 <dc:creator>Nguyen, Sam</dc:creator>
 <dc:creator>Ordonez, Juanita</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The purpose of this project is to evaluate three language models named BERT,
ALBERT, and LongFormer on the Question Answering dataset called DuoRC. The
language model task has two inputs, a question, and a context. The context is a
paragraph or an entire document while the output is the answer based on the
context. The goal is to perform grid search hyperparameter fine-tuning using
DuoRC. Pretrained weights of the models are taken from the Huggingface library.
Different sets of hyperparameters are used to fine-tune the models using two
versions of DuoRC which are the SelfRC and the ParaphraseRC. The results show
that the ALBERT (pretrained using the SQuAD1 dataset) has an F1 score of 76.4
and an accuracy score of 68.52 after fine-tuning on the SelfRC dataset. The
Longformer model (pretrained using the SQuAD and SelfRC datasets) has an F1
score of 52.58 and an accuracy score of 46.60 after fine-tuning on the
ParaphraseRC dataset. The current results outperformed the results from the
previous model by DuoRC.
</dc:description>
 <dc:description>Comment: 9 pages, 2 figures, 2 tables</dc:description>
 <dc:date>2021-01-15</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.06326</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.06605</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MultiBodySync: Multi-Body Segmentation and Motion Estimation via 3D Scan
  Synchronization</dc:title>
 <dc:creator>Huang, Jiahui</dc:creator>
 <dc:creator>Wang, He</dc:creator>
 <dc:creator>Birdal, Tolga</dc:creator>
 <dc:creator>Sung, Minhyuk</dc:creator>
 <dc:creator>Arrigoni, Federica</dc:creator>
 <dc:creator>Hu, Shi-Min</dc:creator>
 <dc:creator>Guibas, Leonidas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We present MultiBodySync, a novel, end-to-end trainable multi-body motion
segmentation and rigid registration framework for multiple input 3D point
clouds. The two non-trivial challenges posed by this multi-scan multibody
setting that we investigate are: (i) guaranteeing correspondence and
segmentation consistency across multiple input point clouds capturing different
spatial arrangements of bodies or body parts; and (ii) obtaining robust
motion-based rigid body segmentation applicable to novel object categories. We
propose an approach to address these issues that incorporates spectral
synchronization into an iterative deep declarative network, so as to
simultaneously recover consistent correspondences as well as motion
segmentation. At the same time, by explicitly disentangling the correspondence
and motion segmentation estimation modules, we achieve strong generalizability
across different object categories. Our extensive evaluations demonstrate that
our method is effective on various datasets ranging from rigid parts in
articulated objects to individually moving objects in a 3D scene, be it
single-view or full point clouds.
</dc:description>
 <dc:description>Comment: Contact: huang-jh18&lt;at&gt;mails&lt;dot&gt;tsinghua&lt;dot&gt;edu&lt;dot&gt;cn</dc:description>
 <dc:date>2021-01-17</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.06605</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.06640</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating informativeness of samples with Smooth Unique Information</dc:title>
 <dc:creator>Harutyunyan, Hrayr</dc:creator>
 <dc:creator>Achille, Alessandro</dc:creator>
 <dc:creator>Paolini, Giovanni</dc:creator>
 <dc:creator>Majumder, Orchid</dc:creator>
 <dc:creator>Ravichandran, Avinash</dc:creator>
 <dc:creator>Bhotika, Rahul</dc:creator>
 <dc:creator>Soatto, Stefano</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We define a notion of information that an individual sample provides to the
training of a neural network, and we specialize it to measure both how much a
sample informs the final weights and how much it informs the function computed
by the weights. Though related, we show that these quantities have a
qualitatively different behavior. We give efficient approximations of these
quantities using a linearized network and demonstrate empirically that the
approximation is accurate for real-world architectures, such as pre-trained
ResNets. We apply these measures to several problems, such as dataset
summarization, analysis of under-sampled classes, comparison of informativeness
of different data sources, and detection of adversarial and corrupted examples.
Our work generalizes existing frameworks but enjoys better computational
properties for heavily over-parametrized models, which makes it possible to
apply it to real-world networks.
</dc:description>
 <dc:description>Comment: ICLR 2021, 22 pages</dc:description>
 <dc:date>2021-01-17</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.06640</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.06948</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Physical Layer Security for Reconfigurable Intelligent Surface
  aided NOMA 6G Networks</dc:title>
 <dc:creator>Zhang, Zhe</dc:creator>
 <dc:creator>Zhang, Chensi</dc:creator>
 <dc:creator>Jiang, Chengjun</dc:creator>
 <dc:creator>Jia, Fan</dc:creator>
 <dc:creator>Ge, Jianhua</dc:creator>
 <dc:creator>Gong, Fengkui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  The intrinsic integration of the nonorthogonal multiple access (NOMA) and
reconfigurable intelligent surface (RIS) techniques is envisioned to be a
promising approach to significantly improve both the spectrum efficiency and
energy efficiency for future wireless communication networks. In this paper,
the physical layer security (PLS) for a RIS-aided NOMA 6G networks is
investigated, in which a RIS is deployed to assist the two &quot;dead zone&quot; NOMA
users and both internal and external eavesdropping are considered. For the
scenario with only internal eavesdropping, we consider the worst case that the
near-end user is untrusted and may try to intercept the information of far-end
user. A joint beamforming and power allocation sub-optimal scheme is proposed
to improve the system PLS. Then we extend our work to a scenario with both
internal and external eavesdropping. Two sub-scenarios are considered in this
scenario: one is the sub-scenario without channel state information (CSI) of
eavesdroppers, and another is the sub-scenario where the eavesdroppers' CSI are
available. For the both sub-scenarios, a noise beamforming scheme is introduced
to be against the external eavesdroppers. An optimal power allocation scheme is
proposed to further improve the system physical security for the second
sub-scenario. Simulation results show the superior performance of the proposed
schemes. Moreover, it has also been shown that increasing the number of
reflecting elements can bring more gain in secrecy performance than that of the
transmit antennas.
</dc:description>
 <dc:date>2021-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.06948</dc:identifier>
 <dc:identifier>doi:10.1109/TVT.2021.3068774</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.08134</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Zero-Cost Proxies for Lightweight NAS</dc:title>
 <dc:creator>Abdelfattah, Mohamed S.</dc:creator>
 <dc:creator>Mehrotra, Abhinav</dc:creator>
 <dc:creator>Dudziak, &#x141;ukasz</dc:creator>
 <dc:creator>Lane, Nicholas D.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Neural Architecture Search (NAS) is quickly becoming the standard methodology
to design neural network models. However, NAS is typically compute-intensive
because multiple models need to be evaluated before choosing the best one. To
reduce the computational power and time needed, a proxy task is often used for
evaluating each model instead of full training. In this paper, we evaluate
conventional reduced-training proxies and quantify how well they preserve
ranking between multiple models during search when compared with the rankings
produced by final trained accuracy. We propose a series of zero-cost proxies,
based on recent pruning literature, that use just a single minibatch of
training data to compute a model's score. Our zero-cost proxies use 3 orders of
magnitude less computation but can match and even outperform conventional
proxies. For example, Spearman's rank correlation coefficient between final
validation accuracy and our best zero-cost proxy on NAS-Bench-201 is 0.82,
compared to 0.61 for EcoNAS (a recently proposed reduced-training proxy).
Finally, we use these zero-cost proxies to enhance existing NAS search
algorithms such as random search, reinforcement learning, evolutionary search
and predictor-based search. For all search methodologies and across three
different NAS datasets, we are able to significantly improve sample efficiency,
and thereby decrease computation, by using our zero-cost proxies. For example
on NAS-Bench-101, we achieved the same accuracy 4$\times$ quicker than the best
previous result. Our code is made public at:
https://github.com/mohsaied/zero-cost-nas.
</dc:description>
 <dc:description>Comment: ICLR 2021</dc:description>
 <dc:date>2021-01-20</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.08134</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.08200</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synthesizing Context-free Grammars from Recurrent Neural Networks
  (Extended Version)</dc:title>
 <dc:creator>Yellin, Daniel M.</dc:creator>
 <dc:creator>Weiss, Gail</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We present an algorithm for extracting a subclass of the context free
grammars (CFGs) from a trained recurrent neural network (RNN). We develop a new
framework, pattern rule sets (PRSs), which describe sequences of deterministic
finite automata (DFAs) that approximate a non-regular language. We present an
algorithm for recovering the PRS behind a sequence of such automata, and apply
it to the sequences of automata extracted from trained RNNs using the L*
algorithm. We then show how the PRS may converted into a CFG, enabling a
familiar and useful presentation of the learned language.
  Extracting the learned language of an RNN is important to facilitate
understanding of the RNN and to verify its correctness. Furthermore, the
extracted CFG can augment the RNN in classifying correct sentences, as the
RNN's predictive accuracy decreases when the recursion depth and distance
between matching delimiters of its input sequences increases.
</dc:description>
 <dc:description>Comment: Extended version of paper to appear in TACAS 2021</dc:description>
 <dc:date>2021-01-20</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.08200</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.08458</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>UNIT: Unifying Tensorized Instruction Compilation</dc:title>
 <dc:creator>Weng, Jian</dc:creator>
 <dc:creator>Jain, Animesh</dc:creator>
 <dc:creator>Wang, Jie</dc:creator>
 <dc:creator>Wang, Leyuan</dc:creator>
 <dc:creator>Wang, Yida</dc:creator>
 <dc:creator>Nowatzki, Tony</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Because of the increasing demand for computation in DNN, researchers develope
both hardware and software mechanisms to reduce the compute and memory burden.
A widely adopted approach is to use mixed precision data types. However, it is
hard to leverage mixed precision without hardware support because of the
overhead of data casting. Hardware vendors offer tensorized instructions for
mixed-precision tensor operations, like Intel VNNI, Tensor Core, and ARM-DOT.
These instructions involve a computing idiom that reduces multiple low
precision elements into one high precision element. The lack of compilation
techniques for this makes it hard to utilize these instructions: Using
vendor-provided libraries for computationally-intensive kernels is inflexible
and prevents further optimizations, and manually writing hardware intrinsics is
error-prone and difficult for programmers. Some prior works address this
problem by creating compilers for each instruction. This requires excessive
effort when it comes to many tensorized instructions. In this work, we develop
a compiler framework to unify the compilation for these instructions -- a
unified semantics abstraction eases the integration of new instructions, and
reuses the analysis and transformations. Tensorized instructions from different
platforms can be compiled via UNIT with moderate effort for favorable
performance. Given a tensorized instruction and a tensor operation, UNIT
automatically detects the applicability, transforms the loop organization of
the operation,and rewrites the loop body to leverage the tensorized
instruction. According to our evaluation, UNIT can target various mainstream
hardware platforms. The generated end-to-end inference model achieves 1.3x
speedup over Intel oneDNN on an x86 CPU, 1.75x speedup over Nvidia cuDNN on an
NvidiaGPU, and 1.13x speedup over a carefully tuned TVM solution for ARM DOT on
an ARM CPU.
</dc:description>
 <dc:description>Comment: 13 pages, 13 figures, and 1 table</dc:description>
 <dc:date>2021-01-21</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.08458</dc:identifier>
 <dc:identifier>2021 IEEE/ACM International Symposium on Code Generation and
  Optimization (CGO), Seoul, Korea (South), 2021, pp. 77-89</dc:identifier>
 <dc:identifier>doi:10.1109/CGO51591.2021.9370330</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.08833</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SSTVOS: Sparse Spatiotemporal Transformers for Video Object Segmentation</dc:title>
 <dc:creator>Duke, Brendan</dc:creator>
 <dc:creator>Ahmed, Abdalla</dc:creator>
 <dc:creator>Wolf, Christian</dc:creator>
 <dc:creator>Aarabi, Parham</dc:creator>
 <dc:creator>Taylor, Graham W.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we introduce a Transformer-based approach to video object
segmentation (VOS). To address compounding error and scalability issues of
prior work, we propose a scalable, end-to-end method for VOS called Sparse
Spatiotemporal Transformers (SST). SST extracts per-pixel representations for
each object in a video using sparse attention over spatiotemporal features. Our
attention-based formulation for VOS allows a model to learn to attend over a
history of multiple frames and provides suitable inductive bias for performing
correspondence-like computations necessary for solving motion segmentation. We
demonstrate the effectiveness of attention-based over recurrent networks in the
spatiotemporal domain. Our method achieves competitive results on YouTube-VOS
and DAVIS 2017 with improved scalability and robustness to occlusions compared
with the state of the art. Code is available at
https://github.com/dukebw/SSTVOS.
</dc:description>
 <dc:description>Comment: CVPR 2021 (Oral)</dc:description>
 <dc:date>2021-01-21</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.08833</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.09042</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PEQcheck: Localized and Context-aware Checking of Functional Equivalence
  (Technical Report)</dc:title>
 <dc:creator>Jakobs, Marie-Christine</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Refactorings must not alter the program's functionality. However, not all
refactorings fulfill this requirement. Hence, one must explicitly check that a
refactoring does not alter the functionality. Since one rarely has a formal
specification of the program's behavior, we utilize the original program as
functional specification. Then, we check whether the original and refactored
program are functionally equivalent. To this end, we apply a common idea and
reduce equivalence checking to program verification. To increase efficiency,
our equivalence checker PEQcheck constructs one verification task per
refactored code segment instead of one per function as typically done by prior
work. In addition, PEQcheck considers the context of the code segments. For
instance, only variables that are modified and live are required to be
equivalent and read-only variables may be shared between original and
refactored code segments. We show that PEQcheck is sound.Moreover, our
evaluation testifies that the localized and context-aware checking performed by
\peqcheck can indeed be beneficial.
</dc:description>
 <dc:date>2021-01-22</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.09042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.09116</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid Rotation Averaging: A Fast and Robust Rotation Averaging Approach</dc:title>
 <dc:creator>Chen, Yu</dc:creator>
 <dc:creator>Zhao, Ji</dc:creator>
 <dc:creator>Kneip, Laurent</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We address rotation averaging (RA) and its application to real-world 3D
reconstruction. Local optimisation based approaches are the de facto choice,
though they only guarantee a local optimum. Global optimisers ensure global
optimality in low noise conditions, but they are inefficient and may easily
deviate under the influence of outliers or elevated noise levels. We push the
envelope of rotation averaging by leveraging the advantages of a global RA
method and a local RA method. Combined with a fast view graph filtering as
preprocessing, the proposed hybrid approach is robust to outliers. We further
apply the proposed hybrid rotation averaging approach to incremental Structure
from Motion (SfM), the accuracy and robustness of SfM are both improved by
adding the resulting global rotations as regularisers to bundle adjustment.
Overall, we demonstrate high practicality of the proposed method as bad camera
poses are effectively corrected and drift is reduced.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2021-01-22</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.09116</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.09347</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Distributed Optimization in the Presence of Malicious Agents</dc:title>
 <dc:creator>Emiola, Iyanuoluwa</dc:creator>
 <dc:creator>Njilla, Laurent</dc:creator>
 <dc:creator>Enyioha, Chinwendu</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we consider an unconstrained distributed optimization problem
over a network of agents, in which some agents are adversarial. We solve the
problem via gradient-based distributed optimization algorithm and characterize
the effect of the adversarial agents on the convergence of the algorithm to the
optimal solution. The attack model considered is such that agents locally
perturb their iterates before broadcasting it to neighbors; and we analyze the
case in which the adversarial agents cooperate in perturbing their estimates
and the case where each adversarial agent acts independently. Based on the
attack model adopted in the paper, we show that the solution converges to the
neighborhood of the optimal solution and depends on the magnitude of the attack
(perturbation) term. The analyses presented establishes conditions under which
the malicious agents have enough information to obstruct convergence to the
optimal solution by the non-adversarial agents.
</dc:description>
 <dc:date>2021-01-22</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.09347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.09635</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>WangchanBERTa: Pretraining transformer-based Thai Language Models</dc:title>
 <dc:creator>Lowphansirikul, Lalita</dc:creator>
 <dc:creator>Polpanumas, Charin</dc:creator>
 <dc:creator>Jantrakulchai, Nawat</dc:creator>
 <dc:creator>Nutanong, Sarana</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Transformer-based language models, more specifically BERT-based architectures
have achieved state-of-the-art performance in many downstream tasks. However,
for a relatively low-resource language such as Thai, the choices of models are
limited to training a BERT-based model based on a much smaller dataset or
finetuning multi-lingual models, both of which yield suboptimal downstream
performance. Moreover, large-scale multi-lingual pretraining does not take into
account language-specific features for Thai. To overcome these limitations, we
pretrain a language model based on RoBERTa-base architecture on a large,
deduplicated, cleaned training set (78GB in total size), curated from diverse
domains of social media posts, news articles and other publicly available
datasets. We apply text processing rules that are specific to Thai most
importantly preserving spaces, which are important chunk and sentence
boundaries in Thai before subword tokenization. We also experiment with
word-level, syllable-level and SentencePiece tokenization with a smaller
dataset to explore the effects on tokenization on downstream performance. Our
model wangchanberta-base-att-spm-uncased trained on the 78.5GB dataset
outperforms strong baselines (NBSVM, CRF and ULMFit) and multi-lingual models
(XLMR and mBERT) on both sequence classification and token classification tasks
in human-annotated, mono-lingual contexts.
</dc:description>
 <dc:description>Comment: 24 pages, edited the citation of the syllable-level tokenizer from
  [Chormai et al., 2020] to [Phatthiyaphaibun et al., 2020] as the authors used
  the syllable-level tokenizer from PyThaiNLP [Phatthiyaphaibun et al., 2020]
  in the experiments</dc:description>
 <dc:date>2021-01-23</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.09635</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.10368</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Meta-Learning for Effective Multi-task and Multilingual Modelling</dc:title>
 <dc:creator>Tarunesh, Ishan</dc:creator>
 <dc:creator>Khyalia, Sushil</dc:creator>
 <dc:creator>Kumar, Vishwajeet</dc:creator>
 <dc:creator>Ramakrishnan, Ganesh</dc:creator>
 <dc:creator>Jyothi, Preethi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Natural language processing (NLP) tasks (e.g. question-answering in English)
benefit from knowledge of other tasks (e.g. named entity recognition in
English) and knowledge of other languages (e.g. question-answering in Spanish).
Such shared representations are typically learned in isolation, either across
tasks or across languages. In this work, we propose a meta-learning approach to
learn the interactions between both tasks and languages. We also investigate
the role of different sampling strategies used during meta-learning. We present
experiments on five different tasks and six different languages from the XTREME
multilingual benchmark dataset. Our meta-learned model clearly improves in
performance compared to competitive baseline models that also include
multi-task baselines. We also present zero-shot evaluations on unseen target
languages to demonstrate the utility of our proposed model.
</dc:description>
 <dc:description>Comment: In Proceedings of The 16th Conference of the European Chapter of the
  Association for Computational Linguistics (EACL 2021)</dc:description>
 <dc:date>2021-01-25</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.10368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.10492</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Non-line-of-sight Imaging with Two-step Deep Remapping</dc:title>
 <dc:creator>Zhu, Dayu</dc:creator>
 <dc:creator>Cai, Wenshan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Conventional imaging only records photons directly sent from the object to
the detector, while non-line-of-sight (NLOS) imaging takes the indirect light
into account. Most NLOS solutions employ a transient scanning process, followed
by a physical based algorithm to reconstruct the NLOS scenes. However, the
transient detection requires sophisticated apparatus, with long scanning time
and low robustness to ambient environment, and the reconstruction algorithms
are typically time-consuming and computationally expensive. Here we propose a
new NLOS solution to address the above defects, with innovations on both
equipment and algorithm. We apply inexpensive commercial Lidar for detection,
with much higher scanning speed and better compatibility to real-world imaging.
Our reconstruction framework is deep learning based, with a generative two-step
remapping strategy to guarantee high reconstruction fidelity. The overall
detection and reconstruction process allows for millisecond responses, with
reconstruction precision of millimeter level. We have experimentally tested the
proposed solution on both synthetic and real objects, and further demonstrated
our method to be applicable to full-color NLOS imaging.
</dc:description>
 <dc:date>2021-01-25</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.10492</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.10500</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ADMM-based Adaptive Sampling Strategy for Nonholonomic Mobile Robotic
  Sensor Networks</dc:title>
 <dc:creator>Le, Viet-Anh</dc:creator>
 <dc:creator>Nguyen, Linh</dc:creator>
 <dc:creator>Nghiem, Truong X.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper discusses the adaptive sampling problem in a nonholonomic mobile
robotic sensor network for efficiently monitoring a spatial field. It is
proposed to employ Gaussian process to model a spatial phenomenon and predict
it at unmeasured positions, which enables the sampling optimization problem to
be formulated by the use of the log determinant of a predicted covariance
matrix at next sampling locations. The control, movement and nonholonomic
dynamics constraints of the mobile sensors are also considered in the adaptive
sampling optimization problem. In order to tackle the nonlinearity and
nonconvexity of the objective function in the optimization problem we first
exploit the linearized alternating direction method of multipliers (L-ADMM)
method that can effectively simplify the objective function, though it is
computationally expensive since a nonconvex problem needs to be solved exactly
in each iteration. We then propose a novel approach called the successive
convexified ADMM (SC-ADMM) that sequentially convexify the nonlinear dynamic
constraints so that the original optimization problem can be split into convex
subproblems. It is noted that both the L-ADMM algorithm and our SC-ADMM
approach can solve the sampling optimization problem in either a centralized or
a distributed manner. We validated the proposed approaches in 1000 experiments
in a synthetic environment with a real-world dataset, where the obtained
results suggest that both the L-ADMM and SC- ADMM techniques can provide good
accuracy for the monitoring purpose. However, our proposed SC-ADMM approach
computationally outperforms the L-ADMM counterpart, demonstrating its better
practicality.
</dc:description>
 <dc:description>Comment: submitted to IEEE Sensors Journal, revised version</dc:description>
 <dc:date>2021-01-25</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.10500</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.10942</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Absolute Value Constraint: The Reason for Invalid Performance Evaluation
  Results of Neural Network Models for Stock Price Prediction</dc:title>
 <dc:creator>Wei, Yi</dc:creator>
 <dc:subject>Quantitative Finance - Statistical Finance</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Neural networks for stock price prediction(NNSPP) have been popular for
decades. However, most of its study results remain in the research paper and
cannot truly play a role in the securities market. One of the main reasons
leading to this situation is that the prediction error(PE) based evaluation
results have statistical flaws. Its prediction results cannot represent the
most critical financial direction attributes. So it cannot provide investors
with convincing, interpretable, and consistent model performance evaluation
results for practical applications in the securities market. To illustrate, we
have used data selected from 20 stock datasets over six years from the Shanghai
and Shenzhen stock market in China, and 20 stock datasets from NASDAQ and NYSE
in the USA. We implement six shallow and deep neural networks to predict stock
prices and use four prediction error measures for evaluation. The results show
that the prediction error value only partially reflects the model accuracy of
the stock price prediction, and cannot reflect the change in the direction of
the model predicted stock price. This characteristic determines that PE is not
suitable as an evaluation indicator of NNSPP. Otherwise, it will bring huge
potential risks to investors. Therefore, this paper establishes an experiment
platform to confirm that the PE method is not suitable for the NNSPP
evaluation, and provides a theoretical basis for the necessity of creating a
new NNSPP evaluation method in the future.
</dc:description>
 <dc:date>2021-01-10</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.10942</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.11093</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Monotone Energy-Aware Information Gathering for Heterogeneous Robot
  Teams</dc:title>
 <dc:creator>Cai, Xiaoyi</dc:creator>
 <dc:creator>Schlotfeldt, Brent</dc:creator>
 <dc:creator>Khosoussi, Kasra</dc:creator>
 <dc:creator>Atanasov, Nikolay</dc:creator>
 <dc:creator>Pappas, George J.</dc:creator>
 <dc:creator>How, Jonathan P.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  This paper considers the problem of planning trajectories for a team of
sensor-equipped robots to reduce uncertainty about a dynamical process.
Optimizing the trade-off between information gain and energy cost (e.g.,
control effort, distance travelled) is desirable but leads to a non-monotone
objective function in the set of robot trajectories. Therefore, common
multi-robot planning algorithms based on techniques such as coordinate descent
lose their performance guarantees. Methods based on local search provide
performance guarantees for optimizing a non-monotone submodular function, but
require access to all robots' trajectories, making it not suitable for
distributed execution. This work proposes a distributed planning approach based
on local search and shows how lazy/greedy methods can be adopted to reduce the
computation and communication of the approach. We demonstrate the efficacy of
the proposed method by coordinating robot teams composed of both ground and
aerial vehicles with different sensing/control profiles and evaluate the
algorithm's performance in two target tracking scenarios. Compared to the naive
distributed execution of local search, our approach saves up to 60%
communication and 80--92% computation on average when coordinating up to 10
robots, while outperforming the coordinate descent based algorithm in achieving
a desirable trade-off between sensing and energy cost.
</dc:description>
 <dc:description>Comment: To appear in ICRA 2021. Video:
  https://www.youtube.com/watch?v=xWgFi6fwex0</dc:description>
 <dc:date>2021-01-26</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.11093</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.11404</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Open-source Library of Large Integer Polynomial Multipliers</dc:title>
 <dc:creator>Imran, Malik</dc:creator>
 <dc:creator>Abideen, Zain Ul</dc:creator>
 <dc:creator>Pagliarini, Samuel</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Polynomial multiplication is a bottleneck in most of the public-key
cryptography protocols, including Elliptic-curve cryptography and several of
the post-quantum cryptography algorithms presently being studied. In this
paper, we present a library of various large integer polynomial multipliers to
be used in hardware cryptocores. Our library contains both digitized and
non-digitized multiplier flavours for circuit designers to choose from. The
library is supported by a C++ generator that automatically produces the
multipliers' logic in Verilog HDL that is amenable for FPGA and ASIC designs.
Moreover, for ASICs, it also generates configurable and parameterizable
synthesis scripts. The features of the generator allow for a quick generation
and assessment of several architectures at the same time, thus allowing a
designer to easily explore the (complex) optimization search space of
polynomial multiplication.
</dc:description>
 <dc:description>Comment: This paper has been accepted for conference proceeding in DDECS 2021
  - April 7-9 2021 Vienna, Austria</dc:description>
 <dc:date>2021-01-27</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.11404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.12355</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Petri Dish for Histopathology Image Analysis</dc:title>
 <dc:creator>Wei, Jerry</dc:creator>
 <dc:creator>Suriawinata, Arief</dc:creator>
 <dc:creator>Ren, Bing</dc:creator>
 <dc:creator>Liu, Xiaoying</dc:creator>
 <dc:creator>Lisovsky, Mikhail</dc:creator>
 <dc:creator>Vaickus, Louis</dc:creator>
 <dc:creator>Brown, Charles</dc:creator>
 <dc:creator>Baker, Michael</dc:creator>
 <dc:creator>Tomita, Naofumi</dc:creator>
 <dc:creator>Torresani, Lorenzo</dc:creator>
 <dc:creator>Wei, Jason</dc:creator>
 <dc:creator>Hassanpour, Saeed</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  With the rise of deep learning, there has been increased interest in using
neural networks for histopathology image analysis, a field that investigates
the properties of biopsy or resected specimens traditionally manually examined
under a microscope by pathologists. However, challenges such as limited data,
costly annotation, and processing high-resolution and variable-size images make
it difficult to quickly iterate over model designs. Throughout scientific
history, many significant research directions have leveraged small-scale
experimental setups as petri dishes to efficiently evaluate exploratory ideas.
In this paper, we introduce a minimalist histopathology image analysis dataset
(MHIST), an analogous petri dish for histopathology image analysis. MHIST is a
binary classification dataset of 3,152 fixed-size images of colorectal polyps,
each with a gold-standard label determined by the majority vote of seven
board-certified gastrointestinal pathologists and annotator agreement level.
MHIST occupies less than 400 MB of disk space, and a ResNet-18 baseline can be
trained to convergence on MHIST in just 6 minutes using 3.5 GB of memory on a
NVIDIA RTX 3090. As example use cases, we use MHIST to study natural questions
such as how dataset size, network depth, transfer learning, and
high-disagreement examples affect model performance. By introducing MHIST, we
hope to not only help facilitate the work of current histopathology imaging
researchers, but also make the field more-accessible to the general community.
Our dataset is available at https://bmirds.github.io/MHIST.
</dc:description>
 <dc:description>Comment: In proceedings of Artificial Intelligence in Medicine (AIME) 2021</dc:description>
 <dc:date>2021-01-28</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.12355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2101.12624</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MRIReco.jl: An MRI Reconstruction Framework written in Julia</dc:title>
 <dc:creator>Knopp, Tobias</dc:creator>
 <dc:creator>Grosser, Mirco</dc:creator>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Purpose: The aim of this work is to develop a high-performance, flexible and
easy-to-use MRI reconstruction framework using the scientific programming
language Julia.
  Methods: Julia is a modern, general purpose programming language with strong
features in the area of signal / image processing and numerical computing. It
has a high-level syntax but still generates efficient machine code that is
usually as fast as comparable C/C++ applications. In addition to the language
features itself, Julia has a sophisticated package management system that makes
proper modularization of functionality across different packages feasible. Our
developed MRI reconstruction framework MRIReco.jl can therefore reuse existing
functionality from other Julia packages and concentrate on the MRI-related
parts. This includes common imaging operators and support for MRI raw data
formats.
  Results: MRIReco.jl is a simple to use framework with a high degree of
accessibility. While providing a simple-to-use interface, many of its
components can easily be extended and customized. The performance of MRIReco.jl
is compared to the Berkeley Advanced Reconstruction Toolbox (BART) and we show
that the Julia framework achieves comparable reconstruction speed as the
popular C/C++ library.
  Conclusion: Modern programming languages can bridge the gap between high
performance and accessible implementations. MRIReco.jl leverages this fact and
contributes a promising environment for future algorithmic development in MRI
reconstruction.
</dc:description>
 <dc:date>2021-01-29</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2101.12624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.00109</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SCAN: A Spatial Context Attentive Network for Joint Multi-Agent Intent
  Prediction</dc:title>
 <dc:creator>Sekhon, Jasmine</dc:creator>
 <dc:creator>Fleming, Cody</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Safe navigation of autonomous agents in human centric environments requires
the ability to understand and predict motion of neighboring pedestrians.
However, predicting pedestrian intent is a complex problem. Pedestrian motion
is governed by complex social navigation norms, is dependent on neighbors'
trajectories, and is multimodal in nature. In this work, we propose SCAN, a
Spatial Context Attentive Network that can jointly predict socially-acceptable
multiple future trajectories for all pedestrians in a scene. SCAN encodes the
influence of spatially close neighbors using a novel spatial attention
mechanism in a manner that relies on fewer assumptions, is parameter efficient,
and is more interpretable compared to state-of-the-art spatial attention
approaches. Through experiments on several datasets we demonstrate that our
approach can also quantitatively outperform state of the art trajectory
prediction methods in terms of accuracy of predicted intent.
</dc:description>
 <dc:date>2021-01-29</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.00109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.00515</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classification of Shoulder X-Ray Images with Deep Learning Ensemble
  Models</dc:title>
 <dc:creator>Uysal, Fatih</dc:creator>
 <dc:creator>Hardala&#xe7;, F&#x131;rat</dc:creator>
 <dc:creator>Peker, Ozan</dc:creator>
 <dc:creator>Tolunay, Tolga</dc:creator>
 <dc:creator>Tokg&#xf6;z, Nil</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Fractures occur in the shoulder area, which has a wider range of motion than
other joints in the body, for various reasons. To diagnose these fractures,
data gathered from Xradiation (X-ray), magnetic resonance imaging (MRI), or
computed tomography (CT) are used. This study aims to help physicians by
classifying shoulder images taken from X-ray devices as fracture / non-fracture
with artificial intelligence. For this purpose, the performances of 26 deep
learning-based pretrained models in the detection of shoulder fractures were
evaluated on the musculoskeletal radiographs (MURA) dataset, and two ensemble
learning models (EL1 and EL2) were developed. The pretrained models used are
ResNet, ResNeXt, DenseNet, VGG, Inception, MobileNet, and their spinal fully
connected (Spinal FC) versions. In the EL1 and EL2 models developed using
pretrained models with the best performance, test accuracy was 0.8455,0.8472,
Cohens kappa was 0.6907, 0.6942 and the area that was related with fracture
class under the receiver operating characteristic (ROC) curve (AUC) was
0.8862,0.8695. As a result of 28 different classifications in total, the
highest test accuracy and Cohens kappa values were obtained in the EL2 model,
and the highest AUC value was obtained in the EL1 model.
</dc:description>
 <dc:description>Comment: This paper is accepted at Applied Sciences, MDPI, 2021, 11(6), 2723.
  Section: &quot;Applied Biosciences and Bioengineering&quot;. Special Issue: &quot;Advancing
  Biomedical Image Retrieval and Classification for Computer Aided Diagnosis&quot;</dc:description>
 <dc:date>2021-01-31</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.00515</dc:identifier>
 <dc:identifier>Applied Sciences, MDPI, 2021, 11(6), 2723. Section: &quot;Applied
  Biosciences and Bioengineering&quot;. Special Issue: &quot;Advancing Biomedical Image
  Retrieval and Classification for Computer Aided Diagnosis&quot;</dc:identifier>
 <dc:identifier>doi:10.3390/app11062723</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.00697</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Zero-Error Sum Modulo Two with a Common Observation</dc:title>
 <dc:creator>Sefidgaran, Milad</dc:creator>
 <dc:creator>Tchamkerten, Aslan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates the classical modulo two sum problem in source
coding, but with a common observation: a transmitter observes $(X,Z)$, the
other transmitter observes $(Y,Z)$, and the receiver wants to compute $X \oplus
Y$ without error. Through a coupling argument, this paper establishes a new
lower bound on the sum-rate when $X-Z-Y$ forms a Markov chain.
</dc:description>
 <dc:description>Comment: Accepted for presentation at IEEE ITW 2020</dc:description>
 <dc:date>2021-02-01</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.00697</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.00724</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Side-Channel Trojan Insertion -- a Practical Foundry-Side Attack via ECO</dc:title>
 <dc:creator>Perez, Tiago</dc:creator>
 <dc:creator>Imran, Malik</dc:creator>
 <dc:creator>Vaz, Pablo</dc:creator>
 <dc:creator>Pagliarini, Samuel</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Design companies often outsource their integrated circuit (IC) fabrication to
third parties where ICs are susceptible to malicious acts such as the insertion
of a side-channel hardware trojan horse (SCT). In this paper, we present a
framework for designing and inserting an SCT based on an engineering change
order (ECO) flow, which makes it the first to disclose how effortlessly a
trojan can be inserted into an IC. The trojan is designed with the goal of
leaking multiple bits per power signature reading. Our findings and results
show that a rogue element within a foundry has, today, all means necessary for
performing a foundry-side attack via ECO.
</dc:description>
 <dc:date>2021-02-01</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.00724</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.01187</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enjoy Your Editing: Controllable GANs for Image Editing via Latent Space
  Navigation</dc:title>
 <dc:creator>Zhuang, Peiye</dc:creator>
 <dc:creator>Koyejo, Oluwasanmi</dc:creator>
 <dc:creator>Schwing, Alexander G.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Controllable semantic image editing enables a user to change entire image
attributes with a few clicks, e.g., gradually making a summer scene look like
it was taken in winter. Classic approaches for this task use a Generative
Adversarial Net (GAN) to learn a latent space and suitable latent-space
transformations. However, current approaches often suffer from attribute edits
that are entangled, global image identity changes, and diminished
photo-realism. To address these concerns, we learn multiple attribute
transformations simultaneously, integrate attribute regression into the
training of transformation functions, and apply a content loss and an
adversarial loss that encourages the maintenance of image identity and
photo-realism. We propose quantitative evaluation strategies for measuring
controllable editing performance, unlike prior work, which primarily focuses on
qualitative evaluation. Our model permits better control for both single- and
multiple-attribute editing while preserving image identity and realism during
transformation. We provide empirical results for both natural and synthetic
images, highlighting that our model achieves state-of-the-art performance for
targeted image manipulation.
</dc:description>
 <dc:description>Comment: Accepted to ICLR 2021. 14 pages, 15 figures</dc:description>
 <dc:date>2021-02-01</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.01187</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.01191</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tight Integration of Feature-based Relocalization in Monocular Direct
  Visual Odometry</dc:title>
 <dc:creator>Gladkova, Mariia</dc:creator>
 <dc:creator>Wang, Rui</dc:creator>
 <dc:creator>Zeller, Niclas</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we propose a framework for integrating map-based relocalization
into online direct visual odometry. To achieve map-based relocalization for
direct methods, we integrate image features into Direct Sparse Odometry (DSO)
and rely on feature matching to associate online visual odometry (VO) with a
previously built map. The integration of the relocalization poses is threefold.
Firstly, they are incorporated as pose priors in the direct image alignment of
the front-end tracking. Secondly, they are tightly integrated into the back-end
bundle adjustment. Thirdly, an online fusion module is further proposed to
combine relative VO poses and global relocalization poses in a pose graph to
estimate keyframe-wise smooth and globally accurate poses. We evaluate our
method on two multi-weather datasets showing the benefits of integrating
different handcrafted and learned features and demonstrating promising
improvements on camera tracking accuracy.
</dc:description>
 <dc:description>Comment: ICRA 2021 camera-ready submission; 7 pages, 5 figures and 3 tables</dc:description>
 <dc:date>2021-02-01</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.01191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.01540</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Targeted Branching for the Maximum Independent Set Problem</dc:title>
 <dc:creator>Hespe, Demian</dc:creator>
 <dc:creator>Lamm, Sebastian</dc:creator>
 <dc:creator>Schorr, Christian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Finding a maximum independent set is a fundamental NP-hard problem that is
used in many real-world applications. Given an unweighted graph, this problem
asks for a maximum cardinality set of pairwise non-adjacent vertices. Some of
the most successful algorithms for this problem are based on the
branch-and-bound or branch-and-reduce paradigms. In particular,
branch-and-reduce algorithms, which combine branch-and-bound with reduction
rules, achieved substantial results, solving many previously infeasible
instances. These results were to a large part achieved by developing new, more
practical reduction rules. However, other components that have been shown to
have an impact on the performance of these algorithms have not received as much
attention. One of these is the branching strategy, which determines what vertex
is included or excluded in a potential solution. The most commonly used
strategy selects vertices based on their degree and does not take into account
other factors that contribute to the performance. In this work, we develop and
evaluate several novel branching strategies for both branch-and-bound and
branch-and-reduce algorithms. Our strategies are based on one of two
approaches. They either (1) aim to decompose the graph into two or more
connected components which can then be solved independently, or (2) try to
remove vertices that hinder the application of a reduction rule. Our
experiments on a large set of real-world instances indicate that our strategies
are able to improve the performance of the state-of-the-art branch-and-reduce
algorithms. To be more specific, our reduction-based packing branching rule is
able to outperform the default branching strategy of selecting a vertex of
highest degree on 65% of all instances tested. Furthermore, our
decomposition-based strategy based on edge cuts is able to achieve a speedup of
2.29 on sparse networks (1.22 on all instances).
</dc:description>
 <dc:date>2021-02-02</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.01540</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.01770</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A privacy-preserving approach to streaming eye-tracking data</dc:title>
 <dc:creator>David-John, Brendan</dc:creator>
 <dc:creator>Hosfelt, Diane</dc:creator>
 <dc:creator>Butler, Kevin</dc:creator>
 <dc:creator>Jain, Eakta</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Eye-tracking technology is being increasingly integrated into mixed reality
devices. Although critical applications are being enabled, there are
significant possibilities for violating user privacy expectations. We show that
there is an appreciable risk of unique user identification even under natural
viewing conditions in virtual reality. This identification would allow an app
to connect a user's personal ID with their work ID without needing their
consent, for example. To mitigate such risks we propose a framework that
incorporates gatekeeping via the design of the application programming
interface and via software-implemented privacy mechanisms. Our results indicate
that these mechanisms can reduce the rate of identification from as much as 85%
to as low as 30%. The impact of introducing these mechanisms is less than
1.5$^\circ$ error in gaze position for gaze prediction. Gaze data streams can
thus be made private while still allowing for gaze prediction, for example,
during foveated rendering. Our approach is the first to support
privacy-by-design in the flow of eye-tracking data within mixed reality use
cases.
</dc:description>
 <dc:description>Comment: 12 pages, 4 figures, to appear in IEEE TVCG Special Issue on IEEE VR
  2021</dc:description>
 <dc:date>2021-02-02</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.01770</dc:identifier>
 <dc:identifier>doi:10.1109/TVCG.2021.3067787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.02024</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Sneaking as a Playful Input Modality for Virtual Environments</dc:title>
 <dc:creator>Cmentowski, Sebastian</dc:creator>
 <dc:creator>Krekhov, Andrey</dc:creator>
 <dc:creator>Zenner, Andr&#xe9;</dc:creator>
 <dc:creator>Kucharski, Daniel</dc:creator>
 <dc:creator>Kr&#xfc;ger, Jens</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Using virtual reality setups, users can fade out of their surroundings and
dive fully into a thrilling and appealing virtual environment. The success of
such immersive experiences depends heavily on natural and engaging interactions
with the virtual world. As developers tend to focus on intuitive hand controls,
other aspects of the broad range of full-body capabilities are easily left
vacant. One repeatedly overlooked input modality is the user's gait. Even
though users may walk physically to explore the environment, it usually does
not matter how they move. However, gait-based interactions, using the variety
of information contained in human gait, could offer interesting benefits for
immersive experiences. For instance, stealth VR-games could profit from this
additional range of interaction fidelity in the form of a sneaking-based input
modality.
  In our work, we explore the potential of sneaking as a playful input modality
for virtual environments. Therefore, we discuss possible sneaking-based
gameplay mechanisms and develop three technical approaches, including precise
foot-tracking and two abstraction levels. Our evaluation reveals the potential
of sneaking-based interactions in IVEs, offering unique challenges and
thrilling gameplay. For these interactions, precise tracking of individual
footsteps is unnecessary, as a more abstract approach focusing on the players'
intention offers the same experience while providing better comprehensible
feedback. Based on these findings, we discuss the broader potential and
individual strengths of our gait-centered interactions.
</dc:description>
 <dc:description>Comment: to appear: accepted IEEE VR 2021 conference paper</dc:description>
 <dc:date>2021-02-03</dc:date>
 <dc:date>2021-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.02024</dc:identifier>
 <dc:identifier>doi:10.1109/VR50410.2021.00071</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.02344</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Horizontally Fused Training Array: An Effective Hardware Utilization
  Squeezer for Training Novel Deep Learning Models</dc:title>
 <dc:creator>Wang, Shang</dc:creator>
 <dc:creator>Yang, Peiming</dc:creator>
 <dc:creator>Zheng, Yuxuan</dc:creator>
 <dc:creator>Li, Xin</dc:creator>
 <dc:creator>Pekhimenko, Gennady</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Driven by the tremendous effort in researching novel deep learning (DL)
algorithms, the training cost of developing new models increases staggeringly
in recent years. We analyze GPU cluster usage statistics from a top research
institute for more insights into the hardware efficiency achieved by typical DL
training jobs. Our study reveals that single-accelerator training jobs can
dominate the cluster-wide resource consumption when launched repetitively
(e.g., for hyper-parameter tuning) while severely under-utilizing the hardware.
Fortunately, we observe that such workloads have the following unique
characteristics: (i) the models among jobs often have the same types of
operators with the same shapes, and (ii) the inter-model horizontal fusion of
such operators is mathematically equivalent to other already well-optimized
operators. Thus, to help DL researchers and practitioners effectively improve
the hardware utilization of their novel DL training workloads, we propose
Horizontally Fused Training Array (HFTA). HFTA is a new DL framework extension
library that horizontally fuses the models from different repetitive jobs
deeply down to operators and then trains them simultaneously on a shared
accelerator. To show the generality of our solution, we apply HFTA to six DL
models training on state-of-the-art accelerators (GPUs and TPUs). Our results
indicate that HFTA is highly effective in improving hardware utilization and
achieves up to $15.1 \times$ higher training throughput vs. the standard
practice of running each job on a separate accelerator.
</dc:description>
 <dc:description>Comment: In Proceedings of the 4th MLSys Conference, San Jose, CA, USA, 2021.
  (
  https://proceedings.mlsys.org/paper/2021/hash/a97da629b098b75c294dffdc3e463904-Abstract.html
  )</dc:description>
 <dc:date>2021-02-03</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.02344</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.02751</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-Supervised Action Recognition with Temporal Contrastive Learning</dc:title>
 <dc:creator>Singh, Ankit</dc:creator>
 <dc:creator>Chakraborty, Omprakash</dc:creator>
 <dc:creator>Varshney, Ashutosh</dc:creator>
 <dc:creator>Panda, Rameswar</dc:creator>
 <dc:creator>Feris, Rogerio</dc:creator>
 <dc:creator>Saenko, Kate</dc:creator>
 <dc:creator>Das, Abir</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Learning to recognize actions from only a handful of labeled videos is a
challenging problem due to the scarcity of tediously collected activity labels.
We approach this problem by learning a two-pathway temporal contrastive model
using unlabeled videos at two different speeds leveraging the fact that
changing video speed does not change an action. Specifically, we propose to
maximize the similarity between encoded representations of the same video at
two different speeds as well as minimize the similarity between different
videos played at different speeds. This way we use the rich supervisory
information in terms of `time' that is present in otherwise unsupervised pool
of videos. With this simple yet effective strategy of manipulating video
playback rates, we considerably outperform video extensions of sophisticated
state-of-the-art semi-supervised image recognition methods across multiple
diverse benchmark datasets and network architectures. Interestingly, our
proposed approach benefits from out-of-domain unlabeled videos showing
generalization and robustness. We also perform rigorous ablations and analysis
to validate our approach. Project page: https://cvir.github.io/TCL/.
</dc:description>
 <dc:description>Comment: Accepted in CVPR 2021</dc:description>
 <dc:date>2021-02-04</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.02751</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.02895</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep reinforcement learning-based image classification achieves perfect
  testing set accuracy for MRI brain tumors with a training set of only 30
  images</dc:title>
 <dc:creator>Stember, Joseph</dc:creator>
 <dc:creator>Shalu, Hrithwik</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Purpose: Image classification may be the fundamental task in imaging
artificial intelligence. We have recently shown that reinforcement learning can
achieve high accuracy for lesion localization and segmentation even with
minuscule training sets. Here, we introduce reinforcement learning for image
classification. In particular, we apply the approach to normal vs.
tumor-containing 2D MRI brain images.
  Materials and Methods: We applied multi-step image classification to allow
for combined Deep Q learning and TD(0) Q learning. We trained on a set of 30
images (15 normal and 15 tumor-containing). We tested on a separate set of 30
images (15 normal and 15 tumor-containing). For comparison, we also trained and
tested a supervised deep-learning classification network on the same set of
training and testing images.
  Results: Whereas the supervised approach quickly overfit the training data
and as expected performed poorly on the testing set (57% accuracy, just over
random guessing), the reinforcement learning approach achieved an accuracy of
100%.
  Conclusion: We have shown a proof-of-principle application of reinforcement
learning to the classification of brain tumors. We achieved perfect testing set
accuracy with a training set of merely 30 images.
</dc:description>
 <dc:date>2021-02-04</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.02895</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.03292</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph Transformation for Enzymatic Mechanisms</dc:title>
 <dc:creator>Andersen, Jakob L.</dc:creator>
 <dc:creator>Fagerberg, Rolf</dc:creator>
 <dc:creator>Flamm, Christoph</dc:creator>
 <dc:creator>Fontana, Walter</dc:creator>
 <dc:creator>Kol&#x10d;&#xe1;k, Juraj</dc:creator>
 <dc:creator>Laurent, Christophe V. F. P.</dc:creator>
 <dc:creator>Merkle, Daniel</dc:creator>
 <dc:creator>N&#xf8;jaard, Nikolai</dc:creator>
 <dc:subject>Quantitative Biology - Molecular Networks</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  Motivation: The design of enzymes is as challenging as it is consequential
for making chemical synthesis in medical and industrial applications more
efficient, cost-effective and environmentally friendly. While several aspects
of this complex problem are computationally assisted, the drafting of catalytic
mechanisms, i.e. the specification of the chemical steps-and hence intermediate
states-that the enzyme is meant to implement, is largely left to human
expertise. The ability to capture specific chemistries of multi-step catalysis
in a fashion that enables its computational construction and design is
therefore highly desirable and would equally impact the elucidation of existing
enzymatic reactions whose mechanisms are unknown. Results: We use the
mathematical framework of graph transformation to express the distinction
between rules and reactions in chemistry. We derive about 1000 rules for amino
acid side chain chemistry from the M-CSA database, a curated repository of
enzymatic mechanisms. Using graph transformation we are able to propose
hundreds of hypothetical catalytic mechanisms for a large number of unrelated
reactions in the Rhea database. We analyze these mechanisms to find that they
combine in chemically sound fashion individual steps from a variety of known
multi-step mechanisms, showing that plausible novel mechanisms for catalysis
can be constructed computationally.
</dc:description>
 <dc:description>Comment: Preprint submitted to ISMB/ECCB 2021. Prototype implementation source
  code available at https://github.com/Nojgaard/mechsearch Live demo available
  at https://cheminf.imada.sdu.dk/mechsearch/ Supplementary material available
  at https://cheminf.imada.sdu.dk/preprints/ECCB-2021</dc:description>
 <dc:date>2021-02-05</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.03292</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.04378</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TransReID: Transformer-based Object Re-Identification</dc:title>
 <dc:creator>He, Shuting</dc:creator>
 <dc:creator>Luo, Hao</dc:creator>
 <dc:creator>Wang, Pichao</dc:creator>
 <dc:creator>Wang, Fan</dc:creator>
 <dc:creator>Li, Hao</dc:creator>
 <dc:creator>Jiang, Wei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Extracting robust feature representation is one of the key challenges in
object re-identification (ReID). Although convolution neural network
(CNN)-based methods have achieved great success, they only process one local
neighborhood at a time and suffer from information loss on details caused by
convolution and downsampling operators (e.g. pooling and strided convolution).
To overcome these limitations, we propose a pure transformer-based object ReID
framework named TransReID. Specifically, we first encode an image as a sequence
of patches and build a transformer-based strong baseline with a few critical
improvements, which achieves competitive results on several ReID benchmarks
with CNN-based methods. To further enhance the robust feature learning in the
context of transformers, two novel modules are carefully designed. (i) The
jigsaw patch module (JPM) is proposed to rearrange the patch embeddings via
shift and patch shuffle operations which generates robust features with
improved discrimination ability and more diversified coverage. (ii) The side
information embeddings (SIE) is introduced to mitigate feature bias towards
camera/view variations by plugging in learnable embeddings to incorporate these
non-visual clues. To the best of our knowledge, this is the first work to adopt
a pure transformer for ReID research. Experimental results of TransReID are
superior promising, which achieve state-of-the-art performance on both person
and vehicle ReID benchmarks.
</dc:description>
 <dc:description>Comment: Code is available at https://github.com/heshuting555/TransReID</dc:description>
 <dc:date>2021-02-08</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.04378</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.05164</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonstochastic Bandits with Infinitely Many Experts</dc:title>
 <dc:creator>Meng, X. Flora</dc:creator>
 <dc:creator>Sarkar, Tuhin</dc:creator>
 <dc:creator>Dahleh, Munther A.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the problem of nonstochastic bandits with expert advice, extending
the setting from finitely many experts to any countably infinite set: A learner
aims to maximize the total reward by taking actions sequentially based on
bandit feedback while benchmarking against a set of experts. We propose a
variant of Exp4.P that, for finitely many experts, enables inference of correct
expert rankings while preserving the order of the regret upper bound. We then
incorporate the variant into a meta-algorithm that works on infinitely many
experts. We prove a high-probability upper bound of $\tilde{\mathcal{O}} \big(
i^*K + \sqrt{KT} \big)$ on the regret, up to polylog factors, where $i^*$ is
the unknown position of the best expert, $K$ is the number of actions, and $T$
is the time horizon. We also provide an example of structured experts and
discuss how to expedite learning in such case. Our meta-learning algorithm
achieves optimal regret up to polylog factors when $i^* = \tilde{\mathcal{O}}
\big( \sqrt{T/K} \big)$. If a prior distribution is assumed to exist for $i^*$,
the probability of optimality increases with $T$, the rate of which can be
fast.
</dc:description>
 <dc:description>Comment: Added numerical experiments</dc:description>
 <dc:date>2021-02-09</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.05164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.05188</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CaPC Learning: Confidential and Private Collaborative Learning</dc:title>
 <dc:creator>Choquette-Choo, Christopher A.</dc:creator>
 <dc:creator>Dullerud, Natalie</dc:creator>
 <dc:creator>Dziedzic, Adam</dc:creator>
 <dc:creator>Zhang, Yunxiang</dc:creator>
 <dc:creator>Jha, Somesh</dc:creator>
 <dc:creator>Papernot, Nicolas</dc:creator>
 <dc:creator>Wang, Xiao</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Machine learning benefits from large training datasets, which may not always
be possible to collect by any single entity, especially when using
privacy-sensitive data. In many contexts, such as healthcare and finance,
separate parties may wish to collaborate and learn from each other's data but
are prevented from doing so due to privacy regulations. Some regulations
prevent explicit sharing of data between parties by joining datasets in a
central location (confidentiality). Others also limit implicit sharing of data,
e.g., through model predictions (privacy). There is currently no method that
enables machine learning in such a setting, where both confidentiality and
privacy need to be preserved, to prevent both explicit and implicit sharing of
data. Federated learning only provides confidentiality, not privacy, since
gradients shared still contain private information. Differentially private
learning assumes unreasonably large datasets. Furthermore, both of these
learning paradigms produce a central model whose architecture was previously
agreed upon by all parties rather than enabling collaborative learning where
each party learns and improves their own local model. We introduce Confidential
and Private Collaborative (CaPC) learning, the first method provably achieving
both confidentiality and privacy in a collaborative setting. We leverage secure
multi-party computation (MPC), homomorphic encryption (HE), and other
techniques in combination with privately aggregated teacher models. We
demonstrate how CaPC allows participants to collaborate without having to
explicitly join their training sets or train a central model. Each party is
able to improve the accuracy and fairness of their model, even in settings
where each party has a model that performs well on their own dataset or when
datasets are not IID and model architectures are heterogeneous across parties.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2021</dc:description>
 <dc:date>2021-02-09</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.05188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.05196</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Once is Never Enough: Foundations for Sound Statistical Inference in Tor
  Network Experimentation</dc:title>
 <dc:creator>Jansen, Rob</dc:creator>
 <dc:creator>Tracey, Justin</dc:creator>
 <dc:creator>Goldberg, Ian</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Tor is a popular low-latency anonymous communication system that focuses on
usability and performance: a faster network will attract more users, which in
turn will improve the anonymity of everyone using the system. The standard
practice for previous research attempting to enhance Tor performance is to draw
conclusions from the observed results of a single simulation for standard Tor
and for each research variant. But because the simulations are run in sampled
Tor networks, it is possible that sampling error alone could cause the observed
effects. Therefore, we call into question the practical meaning of any
conclusions that are drawn without considering the statistical significance of
the reported results.
  In this paper, we build foundations upon which we improve the Tor
experimental method. First, we present a new Tor network modeling methodology
that produces more representative Tor networks as well as new and improved
experimentation tools that run Tor simulations faster and at a larger scale
than was previously possible. We showcase these contributions by running
simulations with 6,489 relays and 792k simultaneously active users, the largest
known Tor network simulations and the first at a network scale of 100%. Second,
we present new statistical methodologies through which we: (i) show that
running multiple simulations in independently sampled networks is necessary in
order to produce informative results; and (ii) show how to use the results from
multiple simulations to conduct sound statistical inference. We present a case
study using 420 simulations to demonstrate how to apply our methodologies to a
concrete set of Tor experiments and how to analyze the results.
</dc:description>
 <dc:date>2021-02-09</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.05196</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.05439</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Student sentiment Analysis Using Classification With Feature Extraction
  Techniques</dc:title>
 <dc:creator>Tamrakar, Latika</dc:creator>
 <dc:creator>Shrivastava, Dr. Padmavati</dc:creator>
 <dc:creator>Ghosh, Dr. S. M.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Technical growths have empowered, numerous revolutions in the educational
system by acquainting with technology into the classroom and by elevating the
learning experience. Nowadays Web-based learning is getting much popularity.
This paper describes the web-based learning and their effectiveness towards
students. One of the prime factors in education or learning system is feedback;
it is beneficial to learning if it must be used effectively. In this paper, we
worked on how machine learning techniques like Logistic Regression (LR),
Support Vector Machine (SVM), Naive Bayes (NB), Decision Tree (DT) can be
applied over Web-based learning, emphasis given on sentiment present in the
feedback students. We also work on two types of Feature Extraction Technique
(FETs) namely Count Vector (CVr) or Bag of Words) (BoW) and Term Frequency and
Inverse Document Frequency (TF-IDF) Vector. In the research study, it is our
goal for our proposed LR, SVM, NB, and DT models to classify the presence of
Student Feedback Dataset (SFB) with improved accuracy with cleaned dataset and
feature extraction techniques. The SFB is one of the significant concerns among
the student sentimental analysis.
</dc:description>
 <dc:description>Comment: need to rework in this paper</dc:description>
 <dc:date>2021-02-01</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.05439</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.05888</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Brain Modelling as a Service: The Virtual Brain on EBRAINS</dc:title>
 <dc:creator>Schirner, Michael</dc:creator>
 <dc:creator>Domide, Lia</dc:creator>
 <dc:creator>Perdikis, Dionysios</dc:creator>
 <dc:creator>Triebkorn, Paul</dc:creator>
 <dc:creator>Stefanovski, Leon</dc:creator>
 <dc:creator>Pai, Roopa</dc:creator>
 <dc:creator>Popa, Paula</dc:creator>
 <dc:creator>Valean, Bogdan</dc:creator>
 <dc:creator>Palmer, Jessica</dc:creator>
 <dc:creator>Langford, Chlo&#xea;</dc:creator>
 <dc:creator>Blickensd&#xf6;rfer, Andr&#xe9;</dc:creator>
 <dc:creator>van der Vlag, Michiel</dc:creator>
 <dc:creator>Diaz-Pier, Sandra</dc:creator>
 <dc:creator>Peyser, Alexander</dc:creator>
 <dc:creator>Klijn, Wouter</dc:creator>
 <dc:creator>Pleiter, Dirk</dc:creator>
 <dc:creator>Nahm, Anne</dc:creator>
 <dc:creator>Schmid, Oliver</dc:creator>
 <dc:creator>Woodman, Marmaduke</dc:creator>
 <dc:creator>Zehl, Lyuba</dc:creator>
 <dc:creator>Fousek, Jan</dc:creator>
 <dc:creator>Petkoski, Spase</dc:creator>
 <dc:creator>Kusch, Lionel</dc:creator>
 <dc:creator>Hashemi, Meysam</dc:creator>
 <dc:creator>Marinazzo, Daniele</dc:creator>
 <dc:creator>Mangin, Jean-Fran&#xe7;ois</dc:creator>
 <dc:creator>Fl&#xf6;el, Agnes</dc:creator>
 <dc:creator>Akintoye, Simisola</dc:creator>
 <dc:creator>Stahl, Bernd Carsten</dc:creator>
 <dc:creator>Cepic, Michael</dc:creator>
 <dc:creator>Johnson, Emily</dc:creator>
 <dc:creator>Deco, Gustavo</dc:creator>
 <dc:creator>McIntosh, Anthony R.</dc:creator>
 <dc:creator>Hilgetag, Claus C.</dc:creator>
 <dc:creator>Morgan, Marc</dc:creator>
 <dc:creator>Schuller, Bernd</dc:creator>
 <dc:creator>Upton, Alex</dc:creator>
 <dc:creator>McMurtrie, Colin</dc:creator>
 <dc:creator>Dickscheid, Timo</dc:creator>
 <dc:creator>Bjaalie, Jan G.</dc:creator>
 <dc:creator>Amunts, Katrin</dc:creator>
 <dc:creator>Mersmann, Jochen</dc:creator>
 <dc:creator>Jirsa, Viktor</dc:creator>
 <dc:creator>Ritter, Petra</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  The Virtual Brain (TVB) is now available as open-source cloud ecosystem on
EBRAINS, a shared digital research platform for brain science. It offers
services for constructing, simulating and analysing brain network models (BNMs)
including the TVB network simulator; magnetic resonance imaging (MRI)
processing pipelines to extract structural and functional connectomes;
multiscale co-simulation of spiking and large-scale networks; a domain specific
language for automatic high-performance code generation from user-specified
models; simulation-ready BNMs of patients and healthy volunteers; Bayesian
inference of epilepsy spread; data and code for mouse brain simulation; and
extensive educational material. TVB cloud services facilitate reproducible
online collaboration and discovery of data assets, models, and software
embedded in scalable and secure workflows, a precondition for research on large
cohort data sets, better generalizability and clinical translation.
</dc:description>
 <dc:date>2021-02-11</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.05888</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.06020</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Making Paper Reviewing Robust to Bid Manipulation Attacks</dc:title>
 <dc:creator>Wu, Ruihan</dc:creator>
 <dc:creator>Guo, Chuan</dc:creator>
 <dc:creator>Wu, Felix</dc:creator>
 <dc:creator>Kidambi, Rahul</dc:creator>
 <dc:creator>van der Maaten, Laurens</dc:creator>
 <dc:creator>Weinberger, Kilian Q.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Most computer science conferences rely on paper bidding to assign reviewers
to papers. Although paper bidding enables high-quality assignments in days of
unprecedented submission numbers, it also opens the door for dishonest
reviewers to adversarially influence paper reviewing assignments. Anecdotal
evidence suggests that some reviewers bid on papers by &quot;friends&quot; or colluding
authors, even though these papers are outside their area of expertise, and
recommend them for acceptance without considering the merit of the work. In
this paper, we study the efficacy of such bid manipulation attacks and find
that, indeed, they can jeopardize the integrity of the review process. We
develop a novel approach for paper bidding and assignment that is much more
robust against such attacks. We show empirically that our approach provides
robustness even when dishonest reviewers collude, have full knowledge of the
assignment system's internal workings, and have access to the system's inputs.
In addition to being more robust, the quality of our paper review assignments
is comparable to that of current, non-robust assignment approaches.
</dc:description>
 <dc:date>2021-02-09</dc:date>
 <dc:date>2021-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.06020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.06154</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EvoSplit: An evolutionary approach to split a multi-label data set into
  disjoint subsets</dc:title>
 <dc:creator>Florez-Revuelta, Francisco</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  This paper presents a new evolutionary approach, EvoSplit, for the
distribution of multi-label data sets into disjoint subsets for supervised
machine learning. Currently, data set providers either divide a data set
randomly or using iterative stratification, a method that aims to maintain the
label (or label pair) distribution of the original data set into the different
subsets. Following the same aim, this paper first introduces a single-objective
evolutionary approach that tries to obtain a split that maximizes the
similarity between those distributions independently. Second, a new
multi-objective evolutionary algorithm is presented to maximize the similarity
considering simultaneously both distributions (labels and label pairs). Both
approaches are validated using well-known multi-label data sets as well as
large image data sets currently used in computer vision and machine learning
applications. EvoSplit improves the splitting of a data set in comparison to
the iterative stratification following different measures: Label Distribution,
Label Pair Distribution, Examples Distribution, folds and fold-label pairs with
zero positive examples.
</dc:description>
 <dc:date>2021-02-11</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.06154</dc:identifier>
 <dc:identifier>Applied Sciences. 2021; 11(6):2823</dc:identifier>
 <dc:identifier>doi:10.3390/app11062823</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.06272</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Extractive Summarization using Pointwise Mutual Information</dc:title>
 <dc:creator>Padmakumar, Vishakh</dc:creator>
 <dc:creator>He, He</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Unsupervised approaches to extractive summarization usually rely on a notion
of sentence importance defined by the semantic similarity between a sentence
and the document. We propose new metrics of relevance and redundancy using
pointwise mutual information (PMI) between sentences, which can be easily
computed by a pre-trained language model. Intuitively, a relevant sentence
allows readers to infer the document content (high PMI with the document), and
a redundant sentence can be inferred from the summary (high PMI with the
summary). We then develop a greedy sentence selection algorithm to maximize
relevance and minimize redundancy of extracted sentences. We show that our
method outperforms similarity-based methods on datasets in a range of domains
including news, medical journal articles, and personal anecdotes.
</dc:description>
 <dc:description>Comment: To appear at EACL 2021</dc:description>
 <dc:date>2021-02-11</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.06272</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.06684</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepGLEAM: A hybrid mechanistic and deep learning model for COVID-19
  forecasting</dc:title>
 <dc:creator>Wu, Dongxia</dc:creator>
 <dc:creator>Gao, Liyao</dc:creator>
 <dc:creator>Xiong, Xinyue</dc:creator>
 <dc:creator>Chinazzi, Matteo</dc:creator>
 <dc:creator>Vespignani, Alessandro</dc:creator>
 <dc:creator>Ma, Yi-An</dc:creator>
 <dc:creator>Yu, Rose</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We introduce DeepGLEAM, a hybrid model for COVID-19 forecasting. DeepGLEAM
combines a mechanistic stochastic simulation model GLEAM with deep learning. It
uses deep learning to learn the correction terms from GLEAM, which leads to
improved performance. We further integrate various uncertainty quantification
methods to generate confidence intervals. We demonstrate DeepGLEAM on
real-world COVID-19 mortality forecasting tasks.
</dc:description>
 <dc:date>2021-02-12</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.06684</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.07193</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human-Robot Handshaking: A Review</dc:title>
 <dc:creator>Prasad, Vignesh</dc:creator>
 <dc:creator>Stock-Homburg, Ruth</dc:creator>
 <dc:creator>Peters, Jan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  For some years now, the use of social, anthropomorphic robots in various
situations has been on the rise. These are robots developed to interact with
humans and are equipped with corresponding extremities. They already support
human users in various industries, such as retail, gastronomy, hotels,
education and healthcare. During such Human-Robot Interaction (HRI) scenarios,
physical touch plays a central role in the various applications of social
robots as interactive non-verbal behaviour is a key factor in making the
interaction more natural. Shaking hands is a simple, natural interaction used
commonly in many social contexts and is seen as a symbol of greeting, farewell
and congratulations. In this paper, we take a look at the existing state of
Human-Robot Handshaking research, categorise the works based on their focus
areas, draw out the major findings of these areas while analysing their
pitfalls. We mainly see that some form of synchronisation exists during the
different phases of the interaction. In addition to this, we also find that
additional factors like gaze, voice facial expressions etc. can affect the
perception of a robotic handshake and that internal factors like personality
and mood can affect the way in which handshaking behaviours are executed by
humans. Based on the findings and insights, we finally discuss possible ways
forward for research on such physically interactive behaviours.
</dc:description>
 <dc:description>Comment: Pre-print version. Accepted for publication in the International
  Journal of Social Robotics</dc:description>
 <dc:date>2021-02-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.07193</dc:identifier>
 <dc:identifier>doi:10.1007/s12369-021-00763-z</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.07510</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Plug-and-Play gradient-based denoisers applied to CT image enhancement</dc:title>
 <dc:creator>Cascarano, Pasquale</dc:creator>
 <dc:creator>Piccolomini, Elena Loli</dc:creator>
 <dc:creator>Morotti, Elena</dc:creator>
 <dc:creator>Sebastiani, Andrea</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>65K10, 65R30, 68U10, 68T07, 65F22</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>G.1.10</dc:subject>
 <dc:subject>I.4.3</dc:subject>
 <dc:subject>I.4.4</dc:subject>
 <dc:subject>I.4.5</dc:subject>
 <dc:subject>I.4.6</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.0</dc:subject>
 <dc:subject>I.4.3</dc:subject>
 <dc:description>  Blur and noise corrupting Computed Tomography (CT) images can hide or distort
small but important details, negatively affecting the diagnosis. In this paper,
we present a novel gradient-based Plug-and-Play algorithm, constructed on the
Half-Quadratic Splitting scheme, and we apply it to restore CT images. In
particular, we consider different schemes encompassing external and internal
denoisers as priors, defined on the image gradient domain. The internal prior
is based on the Total Variation functional. The external denoiser is
implemented by a deep Convolutional Neural Network (CNN) trained on the
gradient domain (and not on the image one, as in state-of-the-art works). We
also prove a general fixed-point convergence theorem under weak assumptions on
both internal and external denoisers. The experiments confirm the effectiveness
of the proposed framework in restoring blurred noisy CT images, both in
simulated and real medical settings. The achieved enhancements in the restored
images are really remarkable, if compared to the results of many
state-of-the-art methods.
</dc:description>
 <dc:description>Comment: Submitted to journal</dc:description>
 <dc:date>2021-02-15</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.07510</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.07890</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Interpolation Accuracy Comparison: Gravity Model Versus Radial
  Basis Function</dc:title>
 <dc:creator>Ghasemi, Amirehsan</dc:creator>
 <dc:creator>Msechu, Kelvin J</dc:creator>
 <dc:creator>Ghasemi, Arash</dc:creator>
 <dc:creator>Onyango, Mbakisya A.</dc:creator>
 <dc:creator>Fomunung, Ignatius</dc:creator>
 <dc:creator>Owino, Joseph</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  In this paper, the accuracy of two mesh-free approximation approaches, the
Gravity model and Radial Basis Function, are compared. The two schemes'
convergence behaviors prove that RBF is faster and more accurate than the
Gravity model. As a case study, the interpolation of temperature at different
locations in Tennesse, USA, are compared. Delaunay mesh generation is used to
create random points inside and on the border, which data can be incorporated
in these locations. 49 MERRA weather stations as used as data sources to
provide the temperature at a specific day and hour. The contours of
interpolated temperatures provided in the result section assert RBF is a more
accurate method than the Gravity model by showing a smoother and broader range
of interpolated data.
</dc:description>
 <dc:date>2021-02-15</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.07890</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.07930</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Thermodynamically Consistent Algorithms for Models of Diblock Copolymer
  Solutions Interacting with Electric and Magnetic Fields</dc:title>
 <dc:creator>Shen, Xiaowen</dc:creator>
 <dc:creator>Wang, Qi</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We derive thermodynamically consistent models for diblock copolymer solutions
coupled with the electric and magnetic field, respectively. These models
satisfy the second law of thermodynamics and therefore are therefore
thermodynamically consistent. We then design a set of 2nd order, linear,
semi-discrete schemes for the models using the energy quadratization method and
the supplementary variable method, respectively, which preserve energy
dissipation rates of the models. The spatial discretization is carried out
subsequently using 2nd order finite difference methods, leading to fully
discrete algorithms that preserve discrete energy-dissipation-rates of the
models so that the resulting fully discrete models are thermodynamically
consistent. Convergence rates are numerically confirmed through mesh refinement
tests and several numerical examples are given to demonstrate the role of the
mobility in pattern formation, defect removing effect of both electric and
magnetic fields as well as the hysteresis effect for applied external fields in
copolymer solutions.
</dc:description>
 <dc:date>2021-02-15</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.07930</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.08078</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Restore from Restored: Single-image Inpainting</dc:title>
 <dc:creator>Lee, Eunhye</dc:creator>
 <dc:creator>Kim, Jeongmu</dc:creator>
 <dc:creator>Kim, Jisu</dc:creator>
 <dc:creator>Kim, Tae Hyun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent image inpainting methods show promising results due to the power of
deep learning, which can explore external information available from a large
training dataset. However, many state-of-the-art inpainting networks are still
limited in exploiting internal information available in the given input image
at test time. To mitigate this problem, we present a novel and efficient
self-supervised fine-tuning algorithm that can adapt the parameters of fully
pre-trained inpainting networks without using ground-truth target images. We
update the parameters of the pre-trained state-of-the-art inpainting networks
by utilizing existing self-similar patches within the given input image without
changing network architecture and improve the inpainting quality by a large
margin. Qualitative and quantitative experimental results demonstrate the
superiority of the proposed algorithm, and we achieve state-of-the-art
inpainting results on publicly available numerous benchmark datasets.
</dc:description>
 <dc:date>2021-02-16</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.08078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.08112</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multigrid and saddle-point preconditioners for unfitted finite element
  modelling of inclusions</dc:title>
 <dc:creator>Kothari, Hardik</dc:creator>
 <dc:creator>Krause, Rolf</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  In this work, we consider the modeling of inclusions in the material using an
unfitted finite element method. In the unfitted methods, structured background
meshes are used and only the underlying finite element space is modified to
incorporate the discontinuities, such as inclusions. Hence, the unfitted
methods provide a more flexible framework for modeling the materials with
multiple inclusions. We employ the method of Lagrange multipliers for enforcing
the interface conditions between the inclusions and matrix, this gives rise to
the linear system of equations of saddle point type. We utilize the Uzawa
method for solving the saddle point system and propose preconditioning
strategies for primal and dual systems.
  For the dual systems, we review and compare the preconditioning strategies
that are developed for FETI and SIMPLE methods. While for the primal system, we
employ a tailored multigrid method specifically developed for the unfitted
meshes. Lastly, the comparison between the proposed preconditioners is made
through several numerical experiments.
</dc:description>
 <dc:date>2021-02-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.08112</dc:identifier>
 <dc:identifier>doi:10.23967/wccm-eccomas.2020.211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.08145</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hough2Map -- Iterative Event-based Hough Transform for High-Speed
  Railway Mapping</dc:title>
 <dc:creator>Tschopp, Florian</dc:creator>
 <dc:creator>von Einem, Cornelius</dc:creator>
 <dc:creator>Cramariuc, Andrei</dc:creator>
 <dc:creator>Hug, David</dc:creator>
 <dc:creator>Palmer, Andrew William</dc:creator>
 <dc:creator>Siegwart, Roland</dc:creator>
 <dc:creator>Chli, Margarita</dc:creator>
 <dc:creator>Nieto, Juan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  To cope with the growing demand for transportation on the railway system,
accurate, robust, and high-frequency positioning is required to enable a safe
and efficient utilization of the existing railway infrastructure. As a basis
for a localization system we propose a complete on-board mapping pipeline able
to map robust meaningful landmarks, such as poles from power lines, in the
vicinity of the vehicle. Such poles are good candidates for reliable and long
term landmarks even through difficult weather conditions or seasonal changes.
To address the challenges of motion blur and illumination changes in railway
scenarios we employ a Dynamic Vision Sensor, a novel event-based camera. Using
a sideways oriented on-board camera, poles appear as vertical lines. To map
such lines in a real-time event stream, we introduce Hough2Map, a novel
consecutive iterative event-based Hough transform framework capable of
detecting, tracking, and triangulating close-by structures. We demonstrate the
mapping reliability and accuracy of Hough2Map on real-world data in typical
usage scenarios and evaluate using surveyed infrastructure ground truth maps.
Hough2Map achieves a detection reliability of up to 92% and a mapping root mean
square error accuracy of 1.1518m.
</dc:description>
 <dc:description>Comment: Florian Tschopp, Cornelius von Einem, and Andrei Cramariuc
  contributed equally to this work</dc:description>
 <dc:date>2021-02-16</dc:date>
 <dc:date>2021-02-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.08145</dc:identifier>
 <dc:identifier>IEEE Robotics and Automation Letters ( Volume: 6, Issue: 2, April
  2021)</dc:identifier>
 <dc:identifier>doi:10.1109/LRA.2021.3061404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.08159</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RMIX: Learning Risk-Sensitive Policies for Cooperative Reinforcement
  Learning Agents</dc:title>
 <dc:creator>Qiu, Wei</dc:creator>
 <dc:creator>Wang, Xinrun</dc:creator>
 <dc:creator>Yu, Runsheng</dc:creator>
 <dc:creator>He, Xu</dc:creator>
 <dc:creator>Wang, Rundong</dc:creator>
 <dc:creator>An, Bo</dc:creator>
 <dc:creator>Obraztsova, Svetlana</dc:creator>
 <dc:creator>Rabinovich, Zinovi</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Current value-based multi-agent reinforcement learning methods optimize
individual Q values to guide individuals' behaviours via centralized training
with decentralized execution (CTDE). However, such expected, i.e.,
risk-neutral, Q value is not sufficient even with CTDE due to the randomness of
rewards and the uncertainty in environments, which causes the failure of these
methods to train coordinating agents in complex environments. To address these
issues, we propose RMIX, a novel cooperative MARL method with the Conditional
Value at Risk (CVaR) measure over the learned distributions of individuals' Q
values. Specifically, we first learn the return distributions of individuals to
analytically calculate CVaR for decentralized execution. Then, to handle the
temporal nature of the stochastic outcomes during executions, we propose a
dynamic risk level predictor for risk level tuning. Finally, we optimize the
CVaR policies with CVaR values used to estimate the target in TD error during
centralized training and the CVaR values are used as auxiliary local rewards to
update the local distribution via Quantile Regression loss. Empirically, we
show that our method significantly outperforms state-of-the-art methods on
challenging StarCraft II tasks, demonstrating enhanced coordination and
improved sample efficiency.
</dc:description>
 <dc:description>Comment: ICLR 2021 submission version:
  https://openreview.net/forum?id=1EVb8XRBDNr</dc:description>
 <dc:date>2021-02-16</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.08159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.08461</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>(-k)-critical trees and k-minimal trees</dc:title>
 <dc:creator>Marweni, Walid</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  In a graph $G=(V,E)$, a module is a vertex subset $M$ of $V$ such that every
vertex outside $M$ is adjacent to all or none of $M$. For example, $\emptyset$,
$\{x\}$ $(x\in V )$ and $V$ are modules of $G$, called trivial modules. A
graph, all the modules of which are trivial, is prime; otherwise, it is
decomposable. A vertex $x$ of a prime graph $G$ is critical if $G - x$ is
decomposable. Moreover, a prime graph with $k$ non-critical vertices is called
$(-k)$-critical graph. A prime graph $G$ is $k$-minimal if there is some
$k$-vertex set $X$ of vertices such that there is no proper induced subgraph of
$G$ containing $X$ is prime. From this perspective, I. Boudabbous proposes to
find the $(-k)$-critical graphs and $k$-minimal graphs for some integer $k$
even in a particular case of graphs. This research paper attempts to answer I.
Boudabbous's question. First, it describes the $(-k)$-critical tree. As a
corollary, we determine the number of nonisomorphic $(-k)$-critical tree with
$n$ vertices where $k\in \{1,2,\lfloor\frac{n}{2}\rfloor\}$. Second, it provide
a complete characterization of the $k$-minimal tree. As a corollary, we
determine the number of nonisomorphic $k$-minimal tree with $n$ vertices where
$k\leq 3$.
</dc:description>
 <dc:description>Comment: 14 pages and 5 figures</dc:description>
 <dc:date>2021-02-16</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.08461</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.08596</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consistent Right-Invariant Fixed-Lag Smoother with Application to Visual
  Inertial SLAM</dc:title>
 <dc:creator>Huai, Jianzhu</dc:creator>
 <dc:creator>Lin, Yukai</dc:creator>
 <dc:creator>Zhuang, Yuan</dc:creator>
 <dc:creator>Shi, Min</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  State estimation problems without absolute position measurements routinely
arise in navigation of unmanned aerial vehicles, autonomous ground vehicles,
etc., whose proper operation relies on accurate state estimates and reliable
covariances. Unaware of absolute positions, these problems have immanent
unobservable directions. Traditional causal estimators, however, usually gain
spurious information on the unobservable directions, leading to over-confident
covariance inconsistent with actual estimator errors. The consistency problem
of fixed-lag smoothers (FLSs) has only been attacked by the first estimate
Jacobian (FEJ) technique because of the complexity to analyze their
observability property. But the FEJ has several drawbacks hampering its wide
adoption. To ensure the consistency of a FLS, this paper introduces the right
invariant error formulation into the FLS framework. To our knowledge, we are
the first to analyze the observability of a FLS with the right invariant error.
Our main contributions are twofold. As the first novelty, to bypass the
complexity of analysis with the classic observability matrix, we show that
observability analysis of FLSs can be done equivalently on the linearized
system. Second, we prove that the inconsistency issue in the traditional FLS
can be elegantly solved by the right invariant error formulation without
artificially correcting Jacobians. By applying the proposed FLS to the
monocular visual inertial simultaneous localization and mapping (SLAM) problem,
we confirm that the method consistently estimates covariance similarly to a
batch smoother in simulation and that our method achieved comparable accuracy
as traditional FLSs on real data.
</dc:description>
 <dc:description>Comment: 13 pages, 4 figures, AAAI 2021 Conference</dc:description>
 <dc:date>2021-02-17</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.08596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.08628</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge discovery from emergency ambulance dispatch during COVID-19: A
  case study of Nagoya City, Japan</dc:title>
 <dc:creator>Rashed, Essam A.</dc:creator>
 <dc:creator>Kodera, Sachiko</dc:creator>
 <dc:creator>Shirakami, Hidenobu</dc:creator>
 <dc:creator>Kawaguchi, Ryotetsu</dc:creator>
 <dc:creator>Watanabe, Kazuhiro</dc:creator>
 <dc:creator>Hirata, Akimasa</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  Accurate forecasting of medical service requirements is an important big data
problem that is crucial for resource management in critical times such as
natural disasters and pandemics. With the global spread of coronavirus disease
2019 (COVID-19), several concerns have been raised regarding the ability of
medical systems to handle sudden changes in the daily routines of healthcare
providers. One significant problem is the management of ambulance dispatch and
control during a pandemic. To help address this problem, we first analyze
ambulance dispatch data records from April 2014 to August 2020 for Nagoya City,
Japan. Significant changes were observed in the data during the pandemic,
including the state of emergency (SoE) declared across Japan. In this study, we
propose a deep learning framework based on recurrent neural networks to
estimate the number of emergency ambulance dispatches (EADs) during a SoE. The
fusion of data includes environmental factors, the localization data of mobile
phone users, and the past history of EADs, thereby providing a general
framework for knowledge discovery and better resource management. The results
indicate that the proposed blend of training data can be used efficiently in a
real-world estimation of EAD requirements during periods of high uncertainties
such as pandemics.
</dc:description>
 <dc:description>Comment: 15 pages, 12 figures, 2 tables</dc:description>
 <dc:date>2021-02-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.08628</dc:identifier>
 <dc:identifier>Journal of Biomedical Informatics, 2021</dc:identifier>
 <dc:identifier>doi:10.1016/j.jbi.2021.103743</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.08688</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Switch Spaces: Learning Product Spaces with Sparse Gating</dc:title>
 <dc:creator>Zhang, Shuai</dc:creator>
 <dc:creator>Tay, Yi</dc:creator>
 <dc:creator>Jiang, Wenqi</dc:creator>
 <dc:creator>Juan, Da-cheng</dc:creator>
 <dc:creator>Zhang, Ce</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Learning embedding spaces of suitable geometry is critical for representation
learning. In order for learned representations to be effective and efficient,
it is ideal that the geometric inductive bias aligns well with the underlying
structure of the data. In this paper, we propose Switch Spaces, a data-driven
approach for learning representations in product space. Specifically, product
spaces (or manifolds) are spaces of mixed curvature, i.e., a combination of
multiple euclidean and non-euclidean (hyperbolic, spherical) manifolds. To this
end, we introduce sparse gating mechanisms that learn to choose, combine and
switch spaces, allowing them to be switchable depending on the input data with
specialization. Additionally, the proposed method is also efficient and has a
constant computational complexity regardless of the model size. Experiments on
knowledge graph completion and item recommendations show that the proposed
switch space achieves new state-of-the-art performances, outperforming pure
product spaces and recently proposed task-specific models.
</dc:description>
 <dc:date>2021-02-17</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.08688</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.08778</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-Scale Benchmarks for the Job Shop Scheduling Problem</dc:title>
 <dc:creator>Da Col, Giacomo</dc:creator>
 <dc:creator>Teppan, Erich</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  This report contains the description of two novel job shop scheduling
benchmarks that resemble instances of real scheduling problem as they appear in
industry. In particular, the aim was to provide large-scale benchmarks (up to 1
million operations) to test the state-of-the-art scheduling solutions on
problems that are closer to what occurs in a real industrial context. The first
benchmark is an extension of the well known Taillard benchmark (1992), while
the second is a collection of scheduling instances with a known-optimum
solution.
</dc:description>
 <dc:date>2021-01-25</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.08778</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.08975</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Doubly Robust Estimator from Non-stationary Logging Policy
  under a Convergence of Average Probability</dc:title>
 <dc:creator>Kato, Masahiro</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Economics - Econometrics</dc:subject>
 <dc:description>  Adaptive experiments, including efficient average treatment effect estimation
and multi-armed bandit algorithms, have garnered attention in various
applications, such as social experiments, clinical trials, and online
advertisement optimization. This paper considers estimating the mean outcome of
an action from samples obtained in adaptive experiments. In causal inference,
the mean outcome of an action has a crucial role, and the estimation is an
essential task, where the average treatment effect estimation and off-policy
value estimation are its variants. In adaptive experiments, the probability of
choosing an action (logging policy) is allowed to be sequentially updated based
on past observations. Due to this logging policy depending on the past
observations, the samples are often not independent and identically distributed
(i.i.d.), making developing an asymptotically normal estimator difficult. A
typical approach for this problem is to assume that the logging policy
converges in a time-invariant function. However, this assumption is restrictive
in various applications, such as when the logging policy fluctuates or becomes
zero at some periods. To mitigate this limitation, we propose another
assumption that the average logging policy converges to a time-invariant
function and show the doubly robust (DR) estimator's asymptotic normality.
Under the assumption, the logging policy itself can fluctuate or be zero for
some actions. We also show the empirical properties by simulations.
</dc:description>
 <dc:date>2021-02-17</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.08975</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.09105</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepMetaHandles: Learning Deformation Meta-Handles of 3D Meshes with
  Biharmonic Coordinates</dc:title>
 <dc:creator>Liu, Minghua</dc:creator>
 <dc:creator>Sung, Minhyuk</dc:creator>
 <dc:creator>Mech, Radomir</dc:creator>
 <dc:creator>Su, Hao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We propose DeepMetaHandles, a 3D conditional generative model based on mesh
deformation. Given a collection of 3D meshes of a category and their
deformation handles (control points), our method learns a set of meta-handles
for each shape, which are represented as combinations of the given handles. The
disentangled meta-handles factorize all the plausible deformations of the
shape, while each of them corresponds to an intuitive deformation. A new
deformation can then be generated by sampling the coefficients of the
meta-handles in a specific range. We employ biharmonic coordinates as the
deformation function, which can smoothly propagate the control points'
translations to the entire mesh. To avoid learning zero deformation as
meta-handles, we incorporate a target-fitting module which deforms the input
mesh to match a random target. To enhance deformations' plausibility, we employ
a soft-rasterizer-based discriminator that projects the meshes to a 2D space.
Our experiments demonstrate the superiority of the generated deformations as
well as the interpretability and consistency of the learned meta-handles.
</dc:description>
 <dc:description>Comment: CVPR2021 oral</dc:description>
 <dc:date>2021-02-17</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.09105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.09139</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding algorithmic collusion with experience replay</dc:title>
 <dc:creator>Han, Bingyan</dc:creator>
 <dc:subject>Economics - General Economics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In an infinitely repeated pricing game, pricing algorithms based on
artificial intelligence (Q-learning) may consistently learn to charge
supra-competitive prices even without communication. Although concerns on
algorithmic collusion have arisen, little is known on underlying factors. In
this work, we experimentally analyze the dynamics of algorithms with three
variants of experience replay. Algorithmic collusion still has roots in human
preferences. Randomizing experience yields prices close to the static Bertrand
equilibrium and higher prices are easily restored by favoring the latest
experience. Moreover, relative performance concerns also stabilize the
collusion. Finally, we investigate the scenarios with heterogeneous agents and
test robustness on various factors.
</dc:description>
 <dc:description>Comment: References updated. Comments are welcome</dc:description>
 <dc:date>2021-02-17</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.09139</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.09334</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>StablePose: Learning 6D Object Poses from Geometrically Stable Patches</dc:title>
 <dc:creator>Shi, Yifei</dc:creator>
 <dc:creator>Huang, Junwen</dc:creator>
 <dc:creator>Xu, Xin</dc:creator>
 <dc:creator>Zhang, Yifan</dc:creator>
 <dc:creator>Xu, Kai</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce the concept of geometric stability to the problem of 6D object
pose estimation and propose to learn pose inference based on geometrically
stable patches extracted from observed 3D point clouds. According to the theory
of geometric stability analysis, a minimal set of three planar/cylindrical
patches are geometrically stable and determine the full 6DoFs of the object
pose. We train a deep neural network to regress 6D object pose based on
geometrically stable patch groups via learning both intra-patch geometric
features and inter-patch contextual features. A subnetwork is jointly trained
to predict per-patch poses. This auxiliary task is a relaxation of the group
pose prediction: A single patch cannot determine the full 6DoFs but is able to
improve pose accuracy in its corresponding DoFs. Working with patch groups
makes our method generalize well for random occlusion and unseen instances. The
method is easily amenable to resolve symmetry ambiguities. Our method achieves
the state-of-the-art results on public benchmarks compared not only to
depth-only but also to RGBD methods. It also performs well in category-level
pose estimation.
</dc:description>
 <dc:description>Comment: CVPR 2021, 10 pages</dc:description>
 <dc:date>2021-02-18</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.09334</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.09419</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ReSonAte: A Runtime Risk Assessment Framework for Autonomous Systems</dc:title>
 <dc:creator>Hartsell, Charles</dc:creator>
 <dc:creator>Ramakrishna, Shreyas</dc:creator>
 <dc:creator>Dubey, Abhishek</dc:creator>
 <dc:creator>Stojcsics, Daniel</dc:creator>
 <dc:creator>Mahadevan, Nagabhushan</dc:creator>
 <dc:creator>Karsai, Gabor</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Autonomous CPSs are often required to handle uncertainties and self-manage
the system operation in response to problems and increasing risk in the
operating paradigm. This risk may arise due to distribution shifts,
environmental context, or failure of software or hardware components.
Traditional techniques for risk assessment focus on design-time techniques such
as hazard analysis, risk reduction, and assurance cases among others. However,
these static, design-time techniques do not consider the dynamic contexts and
failures the systems face at runtime. We hypothesize that this requires a
dynamic assurance approach that computes the likelihood of unsafe conditions or
system failures considering the safety requirements, assumptions made at design
time, past failures in a given operating context, and the likelihood of system
component failures. We introduce the ReSonAte dynamic risk estimation framework
for autonomous systems. ReSonAte reasons over Bow-Tie Diagrams (BTDs) which
capture information about hazard propagation paths and control strategies. Our
innovation is the extension of the BTD formalism with attributes for modeling
the conditional relationships with the state of the system and environment. We
also describe a technique for estimating these conditional relationships and
equations for estimating risk based on the state of the system and environment.
To help with this process, we provide a scenario modeling procedure that can
use the prior distributions of the scenes and threat conditions to generate the
data required for estimating the conditional relationships. To improve
scalability and reduce the amount of data required, this process considers each
control strategy in isolation and composes several single-variate distributions
into one complete multi-variate distribution for the control strategy in
question.
</dc:description>
 <dc:description>Comment: Accepted as long paper at SEAMS 2021</dc:description>
 <dc:date>2021-02-18</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.09419</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.09687</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SQAPlanner: Generating Data-Informed Software Quality Improvement Plans</dc:title>
 <dc:creator>Rajapaksha, Dilini</dc:creator>
 <dc:creator>Tantithamthavorn, Chakkrit</dc:creator>
 <dc:creator>Jiarpakdee, Jirayus</dc:creator>
 <dc:creator>Bergmeir, Christoph</dc:creator>
 <dc:creator>Grundy, John</dc:creator>
 <dc:creator>Buntine, Wray</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Software Quality Assurance (SQA) planning aims to define proactive plans,
such as defining maximum file size, to prevent the occurrence of software
defects in future releases. To aid this, defect prediction models have been
proposed to generate insights as the most important factors that are associated
with software quality. Such insights that are derived from traditional defect
models are far from actionable-i.e., practitioners still do not know what they
should do or avoid to decrease the risk of having defects, and what is the risk
threshold for each metric. A lack of actionable guidance and risk threshold can
lead to inefficient and ineffective SQA planning processes. In this paper, we
investigate the practitioners' perceptions of current SQA planning activities,
current challenges of such SQA planning activities, and propose four types of
guidance to support SQA planning. We then propose and evaluate our AI-Driven
SQAPlanner approach, a novel approach for generating four types of guidance and
their associated risk thresholds in the form of rule-based explanations for the
predictions of defect prediction models. Finally, we develop and evaluate an
information visualization for our SQAPlanner approach. Through the use of
qualitative survey and empirical evaluation, our results lead us to conclude
that SQAPlanner is needed, effective, stable, and practically applicable. We
also find that 80% of our survey respondents perceived that our visualization
is more actionable. Thus, our SQAPlanner paves a way for novel research in
actionable software analytics-i.e., generating actionable guidance on what
should practitioners do and not do to decrease the risk of having defects to
support SQA planning.
</dc:description>
 <dc:description>Comment: This work has been Accepted by the IEEE Transactions on Software
  Engineering. Copyright may be transferred without notice, after which this
  version may no longer be accessible 24 pages</dc:description>
 <dc:date>2021-02-18</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.09687</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.10006</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Overview of Forks and Coordination in Blockchain Development</dc:title>
 <dc:creator>Yiu, Neo C. K.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Blockchain is a continuously developing technology that has made digital
transactions and related computing operations more transparent and secure
through globally distributed and decentralized management of states, as well as
the strong immutability of blocks mined and transactions validated in a network
enabled by the blockchain technology. This manuscript is aimed at elaborating
the concept of blockchain technology alongside its coordination and
implementation with other emerging technologies, such as smart contract, which
works with different blockchain frameworks, as well as enabling anonymous
transactions and decentralized consensus amongst different untrusting parties.
The discussion of blockchain forks is also covered in this manuscript,
depicting fork events created in the blockchain process, their brief history,
types, and impacts upon the blockchain development and operation.
</dc:description>
 <dc:date>2021-02-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.10006</dc:identifier>
 <dc:identifier>doi:10.13140/RG.2.2.36579.07207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.10044</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interest-aware Message-Passing GCN for Recommendation</dc:title>
 <dc:creator>Liu, Fan</dc:creator>
 <dc:creator>Cheng, Zhiyong</dc:creator>
 <dc:creator>Zhu, Lei</dc:creator>
 <dc:creator>Gao, Zan</dc:creator>
 <dc:creator>Nie, Liqiang</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Graph Convolution Networks (GCNs) manifest great potential in recommendation.
This is attributed to their capability on learning good user and item
embeddings by exploiting the collaborative signals from the high-order
neighbors. Like other GCN models, the GCN based recommendation models also
suffer from the notorious over-smoothing problem - when stacking more layers,
node embeddings become more similar and eventually indistinguishable, resulted
in performance degradation. The recently proposed LightGCN and LR-GCN alleviate
this problem to some extent, however, we argue that they overlook an important
factor for the over-smoothing problem in recommendation, that is, high-order
neighboring users with no common interests of a user can be also involved in
the user's embedding learning in the graph convolution operation. As a result,
the multi-layer graph convolution will make users with dissimilar interests
have similar embeddings. In this paper, we propose a novel Interest-aware
Message-Passing GCN (IMP-GCN) recommendation model, which performs high-order
graph convolution inside subgraphs. The subgraph consists of users with similar
interests and their interacted items. To form the subgraphs, we design an
unsupervised subgraph generation module, which can effectively identify users
with common interests by exploiting both user feature and graph structure. To
this end, our model can avoid propagating negative information from high-order
neighbors into embedding learning. Experimental results on three large-scale
benchmark datasets show that our model can gain performance improvement by
stacking more layers and outperform the state-of-the-art GCN-based
recommendation models significantly.
</dc:description>
 <dc:description>Comment: WWW 2021, 10 pages</dc:description>
 <dc:date>2021-02-19</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.10044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.10220</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Making an $H$-Free Graph $k$-Colorable</dc:title>
 <dc:creator>Fox, Jacob</dc:creator>
 <dc:creator>Himwich, Zoe</dc:creator>
 <dc:creator>Mani, Nitya</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C35, 05C38, 05D40</dc:subject>
 <dc:description>  We study the following question: how few edges can we delete from any
$H$-free graph on $n$ vertices in order to make the resulting graph
$k$-colorable? It turns out that various classical problems in extremal graph
theory are special cases of this question. For $H$ any fixed odd cycle, we
determine the answer up to a constant factor when $n$ is sufficiently large. We
also prove an upper bound when $H$ is a fixed clique that we conjecture is
tight up to a constant factor, and prove upper bounds for more general families
of graphs. We apply our results to get a new bound on the maximum cut of graphs
with a forbidden odd cycle in terms of the number of edges.
</dc:description>
 <dc:description>Comment: 21 pages</dc:description>
 <dc:date>2021-02-19</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.10220</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.10448</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An ecologically valid examination of event-based and time-based
  prospective memory using immersive virtual reality: the effects of delay and
  task type on everyday prospective memory</dc:title>
 <dc:creator>Kourtesis, Panagiotis</dc:creator>
 <dc:creator>Collina, Simona</dc:creator>
 <dc:creator>Doumas, Leonidas A. A.</dc:creator>
 <dc:creator>MacPherson, Sarah E.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:subject>K.4.0</dc:subject>
 <dc:description>  Recent research has focused on assessing either event- or time-based
prospective memory (PM) using laboratory tasks. Yet, the findings pertaining to
PM performance on laboratory tasks are often inconsistent with the findings on
corresponding naturalistic experiments. Ecologically valid neuropsychological
tasks resemble the complexity and cognitive demands of everyday tasks, offer an
adequate level of experimental control, and allow a generalisation of the
findings to everyday performance. The Virtual Reality Everyday Assessment Lab
(VR-EAL), an immersive virtual reality neuropsychological battery with enhanced
ecological validity, was implemented to comprehensively assess everyday PM
(i.e., focal and non-focal event-based, and time-based). The effects of the
length of delay between encoding and initiating the PM intention and the type
of PM task on everyday PM performance were examined. The results revealed that
everyday PM performance was affected by the length of delay rather than the
type of PM task. The effect of the length of delay differentially affected
performance on the focal, non-focal, and time-based tasks and was proportional
to the PM cue focality (i.e., semantic relationship with the intended action).
This study also highlighted methodological considerations such as the
differentiation between functioning and ability, distinction of cue attributes,
and the necessity of ecological validity.
</dc:description>
 <dc:description>Comment: 9 Figures, 4 Tables</dc:description>
 <dc:date>2021-02-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.10448</dc:identifier>
 <dc:identifier>doi:10.1080/09658211.2021.1904996</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.10566</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Projection-Stable Grammatical Model for the Distributed Execution of
  Administrative Processes with Emphasis on Actors' Views</dc:title>
 <dc:creator>Ndadji, Milliam Maxime Zekeng</dc:creator>
 <dc:creator>Tchendji, Maurice Tchoup&#xe9;</dc:creator>
 <dc:creator>Djamegni, Cl&#xe9;mentin Tayou</dc:creator>
 <dc:creator>Parigot, Didier</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  During the last two decades, the decentralized execution of business
processes has been one of the main research topics in Business Process
Management. Several models (languages) for processes' specification in order to
facilitate their distributed execution, have been proposed. LSAWfP is among the
most recent in this area: it helps to specify administrative processes with
grammatical models indicating, in addition to their fundamental elements, the
permissions (reading, writing and execution) of each actor in relation to each
of their tasks. In this paper, we present a model for a completely
decentralized and artifact-centric execution of administrative processes
specified using LSAWfP. The presented model puts particular emphasis on actors'
views: it then allows the confidential execution of certain tasks by ensuring
that, each actor potentially has only a partial perception of the processes'
global execution states. The model thus solves a very important problem in
business process execution, which is often sidelined in existing approaches. To
accomplish this, the model rely on three projection algorithms allowing to
partially replicate the processes' global execution states at a given moment,
to consistently update the obtained partial states and to deduce new coherent
global states. The proposal of these three algorithms, the proof of underlying
mathematical tools' stability and a proposal of their implementation, are this
paper's main contributions.
</dc:description>
 <dc:date>2021-02-21</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.10566</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.10607</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Semantic Segmentation of Tuberculosis-consistent findings in
  Chest X-rays Using Augmented Training of Modality-specific U-Net Models with
  Weak Localizations</dc:title>
 <dc:creator>Rajaraman, Sivaramakrishnan</dc:creator>
 <dc:creator>Folio, Les</dc:creator>
 <dc:creator>Dimperio, Jane</dc:creator>
 <dc:creator>Alderson, Philip</dc:creator>
 <dc:creator>Antani, Sameer</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4, I.5</dc:subject>
 <dc:description>  Deep learning (DL) has drawn tremendous attention in object localization and
recognition for both natural and medical images. U-Net segmentation models have
demonstrated superior performance compared to conventional handcrafted
feature-based methods. Medical image modality-specific DL models are better at
transferring domain knowledge to a relevant target task than those that are
pretrained on stock photography images. This helps improve model adaptation,
generalization, and class-specific region of interest (ROI) localization. In
this study, we train chest X-ray (CXR) modality-specific U-Nets and other
state-of-the-art U-Net models for semantic segmentation of tuberculosis
(TB)-consistent findings. Automated segmentation of such manifestations could
help radiologists reduce errors and supplement decision-making while improving
patient care and productivity. Our approach uses the publicly available TBX11K
CXR dataset with weak TB annotations, typically provided as bounding boxes, to
train a set of U-Net models. Next, we improve the results by augmenting the
training data with weak localizations, post-processed into an ROI mask, from a
DL classifier that is trained to classify CXRs as showing normal lungs or
suspected TB manifestations. Test data are individually derived from the TBX11K
CXR training distribution and other cross-institutional collections including
the Shenzhen TB and Montgomery TB CXR datasets. We observe that our augmented
training strategy helped the CXR modality-specific U-Net models achieve
superior performance with test data derived from the TBX11K CXR training
distribution as well as from cross-institutional collections (p &lt; 0.05).
</dc:description>
 <dc:description>Comment: 31 pages, 19 figures, journal publication</dc:description>
 <dc:date>2021-02-21</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.10607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.10864</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Subword Pooling Makes a Difference</dc:title>
 <dc:creator>&#xc1;cs, Judit</dc:creator>
 <dc:creator>K&#xe1;d&#xe1;r, &#xc1;kos</dc:creator>
 <dc:creator>Kornai, Andr&#xe1;s</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Contextual word-representations became a standard in modern natural language
processing systems. These models use subword tokenization to handle large
vocabularies and unknown words. Word-level usage of such systems requires a way
of pooling multiple subwords that correspond to a single word. In this paper we
investigate how the choice of subword pooling affects the downstream
performance on three tasks: morphological probing, POS tagging and NER, in 9
typologically diverse languages. We compare these in two massively multilingual
models, mBERT and XLM-RoBERTa. For morphological tasks, the widely used `choose
the first subword' is the worst strategy and the best results are obtained by
using attention over the subwords. For POS tagging both of these strategies
perform poorly and the best choice is to use a small LSTM over the subwords.
The same strategy works best for NER and we show that mBERT is better than
XLM-RoBERTa in all 9 languages. We publicly release all code, data and the full
result tables at \url{https://github.com/juditacs/subword-choice}.
</dc:description>
 <dc:date>2021-02-22</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.10864</dc:identifier>
 <dc:identifier>EACL2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.10908</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>InaudibleKey: Generic Inaudible Acoustic Signal based Key Agreement
  Protocol for Mobile Devices</dc:title>
 <dc:creator>Xu, Weitao</dc:creator>
 <dc:creator>Li, Zhenjiang</dc:creator>
 <dc:creator>Xue, Wanli</dc:creator>
 <dc:creator>Yu, Xiaotong</dc:creator>
 <dc:creator>Wei, Bo</dc:creator>
 <dc:creator>Wang, Jia</dc:creator>
 <dc:creator>Luo, Chengwen</dc:creator>
 <dc:creator>Li, Wei</dc:creator>
 <dc:creator>Zomaya, Albert Y.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>C.2.0</dc:subject>
 <dc:description>  Secure Device-to-Device (D2D) communication is becoming increasingly
important with the ever-growing number of Internet-of-Things (IoT) devices in
our daily life. To achieve secure D2D communication, the key agreement between
different IoT devices without any prior knowledge is becoming desirable.
Although various approaches have been proposed in the literature, they suffer
from a number of limitations, such as low key generation rate and short pairing
distance. In this paper, we present InaudibleKey, an inaudible acoustic
signal-based key generation protocol for mobile devices. Based on acoustic
channel reciprocity, InaudibleKey exploits the acoustic channel frequency
response of two legitimate devices as a common secret to generating keys.
InaudibleKey employs several novel technologies to significantly improve its
performance. We conduct extensive experiments to evaluate the proposed system
in different real environments. Compared to state-of-the-art works,
InaudibleKey improves key generation rate by 3-145 times, extends pairing
distance by 3.2-44 times, and reduces information reconciliation counts by
2.5-16 times. Security analysis demonstrates that InaudibleKey is resilient to
a number of malicious attacks. We also implement InaudibleKey on modern
smartphones and resource-limited IoT devices. Results show that it is
energy-efficient and can run on both powerful and resource-limited IoT devices
without incurring excessive resource consumption.
</dc:description>
 <dc:description>Comment: 13 pages, 11 figures, IPSN 2021</dc:description>
 <dc:date>2021-02-22</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.10908</dc:identifier>
 <dc:identifier>doi:10.1145/3412382.3458260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.10963</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smart Contract Security: a Practitioners' Perspective</dc:title>
 <dc:creator>Wan, Zhiyuan</dc:creator>
 <dc:creator>Xia, Xin</dc:creator>
 <dc:creator>Lo, David</dc:creator>
 <dc:creator>Chen, Jiachi</dc:creator>
 <dc:creator>Luo, Xiapu</dc:creator>
 <dc:creator>Yang, Xiaohu</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Smart contracts have been plagued by security incidents, which resulted in
substantial financial losses. Given numerous research efforts in addressing the
security issues of smart contracts, we wondered how software practitioners
build security into smart contracts in practice. We performed a mixture of
qualitative and quantitative studies with 13 interviewees and 156 survey
respondents from 35 countries across six continents to understand
practitioners' perceptions and practices on smart contract security. Our study
uncovers practitioners' motivations and deterrents of smart contract security,
as well as how security efforts and strategies fit into the development
lifecycle. We also find that blockchain platforms have a statistically
significant impact on practitioners' security perceptions and practices of
smart contract development. Based on our findings, we highlight future research
directions and provide recommendations for practitioners.
</dc:description>
 <dc:description>Comment: Technical Track paper, the 43rd ACM/IEEE International Conference on
  Software Engineering (ICSE 2021)</dc:description>
 <dc:date>2021-02-22</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.10963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.11171</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>WLAN-Log-Based Superspreader Detection in the COVID-19 Pandemic</dc:title>
 <dc:creator>Zhang, Cheng</dc:creator>
 <dc:creator>Pan, Yunze</dc:creator>
 <dc:creator>Zhang, Yunqi</dc:creator>
 <dc:creator>Champion, Adam C.</dc:creator>
 <dc:creator>Shen, Zhaohui</dc:creator>
 <dc:creator>Xuan, Dong</dc:creator>
 <dc:creator>Lin, Zhiqiang</dc:creator>
 <dc:creator>Shroff, Ness B.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Identifying &quot;superspreaders&quot; of disease is a pressing concern for society
during pandemics such as COVID-19. Superspreaders represent a group of people
who have much more social contacts than others. The widespread deployment of
WLAN infrastructure enables non-invasive contact tracing via people's
ubiquitous mobile devices. This technology offers promise for detecting
superspreaders. In this paper, we propose a general framework for
WLAN-log-based superspreader detection. In our framework, we first use WLAN
logs to construct contact graphs by jointly considering human symmetric and
asymmetric interactions. Next, we adopt three vertex centrality measurements
over the contact graphs to generate three groups of superspreader candidates.
Finally, we leverage SEIR simulation to determine groups of superspreaders
among these candidates, who are the most critical individuals for the spread of
disease based on the simulation results. We have implemented our framework and
evaluate it over a WLAN dataset with 41 million log entries from a large-scale
university. Our evaluation shows superspreaders exist on university campuses.
They change over the first few weeks of a semester, but stabilize throughout
the rest of the term. The data also demonstrate that both symmetric and
asymmetric contact tracing can discover superspreaders, but the latter performs
better with daily contact graphs. Further, the evaluation shows no consistent
differences among three vertex centrality measures for long-term (i.e., weekly)
contact graphs, which necessitates the inclusion of SEIR simulation in our
framework. We believe our proposed framework and these results may provide
timely guidance for public health administrators regarding effective testing,
intervention, and vaccination policies.
</dc:description>
 <dc:description>Comment: Accepted to Elsevier High-Confidence Computing Journal</dc:description>
 <dc:date>2021-02-22</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.11171</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.11491</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Driven Testing of Cyber Physical Systems</dc:title>
 <dc:creator>Humeniuk, Dmytro</dc:creator>
 <dc:creator>Antoniol, Giuliano</dc:creator>
 <dc:creator>Khomh, Foutse</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Consumer grade cyber-physical systems (CPS) are becoming an integral part of
our life, automatizing and simplifying everyday tasks. Indeed, due to complex
interactions between hardware, networking and software, developing and testing
such systems is known to be a challenging task. Various quality assurance and
testing strategies have been proposed. The most common approach for
pre-deployment testing is to model the system and run simulations with models
or software in the loop. In practice, most often, tests are run for a small
number of simulations, which are selected based on the engineers' domain
knowledge and experience. In this paper we propose an approach to automatically
generate fault-revealing test cases for CPS. We have implemented our approach
in Python, using standard frameworks and used it to generate scenarios
violating temperature constraints for a smart thermostat implemented as a part
of our IoT testbed. Data collected from an application managing a smart
building have been used to learn models of the environment under ever changing
conditions. The suggested approach allowed us to identify several pit-fails,
scenarios (i.e., environment conditions and inputs), where the system behaves
not as expected.
</dc:description>
 <dc:description>Comment: 4 pages, to be published in SBST2021 workshop proceedings</dc:description>
 <dc:date>2021-02-22</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.11491</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.11730</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RGB-D Railway Platform Monitoring and Scene Understanding for Enhanced
  Passenger Safety</dc:title>
 <dc:creator>Wallner, Marco</dc:creator>
 <dc:creator>Steininger, Daniel</dc:creator>
 <dc:creator>Widhalm, Verena</dc:creator>
 <dc:creator>Sch&#xf6;rghuber, Matthias</dc:creator>
 <dc:creator>Beleznai, Csaba</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automated monitoring and analysis of passenger movement in safety-critical
parts of transport infrastructures represent a relevant visual surveillance
task. Recent breakthroughs in visual representation learning and spatial
sensing opened up new possibilities for detecting and tracking humans and
objects within a 3D spatial context. This paper proposes a flexible analysis
scheme and a thorough evaluation of various processing pipelines to detect and
track humans on a ground plane, calibrated automatically via stereo depth and
pedestrian detection. We consider multiple combinations within a set of RGB-
and depth-based detection and tracking modalities. We exploit the modular
concepts of Meshroom [2] and demonstrate its use as a generic vision processing
pipeline and scalable evaluation framework. Furthermore, we introduce a novel
open RGB-D railway platform dataset with annotations to support research
activities in automated RGB-D surveillance. We present quantitative results for
multiple object detection and tracking for various algorithmic combinations on
our dataset. Results indicate that the combined use of depth-based spatial
information and learned representations yields substantially enhanced detection
and tracking accuracies. As demonstrated, these enhancements are especially
pronounced in adverse situations when occlusions and objects not captured by
learned representations are present.
</dc:description>
 <dc:description>Comment: The final authenticated version is available online at
  https://doi.org/10.1007/978-3-030-68787-8_47</dc:description>
 <dc:date>2021-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.11730</dc:identifier>
 <dc:identifier>Pattern Recognition. ICPR International Workshops and Challenges.
  ICPR 2021. Lecture Notes in Computer Science, vol 12667. Springer, Cham</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-030-68787-8_47</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.11965</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modular Design Patterns for Hybrid Learning and Reasoning Systems: a
  taxonomy, patterns and use cases</dc:title>
 <dc:creator>van Bekkum, Michael</dc:creator>
 <dc:creator>de Boer, Maaike</dc:creator>
 <dc:creator>van Harmelen, Frank</dc:creator>
 <dc:creator>Meyer-Vitali, Andr&#xe9;</dc:creator>
 <dc:creator>Teije, Annette ten</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The unification of statistical (data-driven) and symbolic (knowledge-driven)
methods is widely recognised as one of the key challenges of modern AI. Recent
years have seen large number of publications on such hybrid neuro-symbolic AI
systems. That rapidly growing literature is highly diverse and mostly
empirical, and is lacking a unifying view of the large variety of these hybrid
systems. In this paper we analyse a large body of recent literature and we
propose a set of modular design patterns for such hybrid, neuro-symbolic
systems. We are able to describe the architecture of a very large number of
hybrid systems by composing only a small set of elementary patterns as building
blocks.
  The main contributions of this paper are: 1) a taxonomically organised
vocabulary to describe both processes and data structures used in hybrid
systems; 2) a set of 15+ design patterns for hybrid AI systems, organised in a
set of elementary patterns and a set of compositional patterns; 3) an
application of these design patterns in two realistic use-cases for hybrid AI
systems. Our patterns reveal similarities between systems that were not
recognised until now. Finally, our design patterns extend and refine Kautz'
earlier attempt at categorising neuro-symbolic architectures.
</dc:description>
 <dc:description>Comment: 20 pages, 22 figures, accepted for publication in the International
  Journal of Applied Intelligence</dc:description>
 <dc:date>2021-02-23</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.11965</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.12072</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Durable Top-K Instant-Stamped Temporal Records with User-Specified
  Scoring Functions</dc:title>
 <dc:creator>Gao, Junyang</dc:creator>
 <dc:creator>Sintos, Stavros</dc:creator>
 <dc:creator>Agarwal, Pankaj K.</dc:creator>
 <dc:creator>Yang, Jun</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  A way of finding interesting or exceptional records from instant-stamped
temporal data is to consider their &quot;durability,&quot; or, intuitively speaking, how
well they compare with other records that arrived earlier or later, and how
long they retain their supremacy. For example, people are naturally fascinated
by claims with long durability, such as: &quot;On January 22, 2006, Kobe Bryant
dropped 81 points against Toronto Raptors. Since then, this scoring record has
yet to be broken.&quot; In general, given a sequence of instant-stamped records,
suppose that we can rank them by a user-specified scoring function $f$, which
may consider multiple attributes of a record to compute a single score for
ranking. This paper studies &quot;durable top-$k$ queries&quot;, which find records whose
scores were within top-$k$ among those records within a &quot;durability window&quot; of
given length, e.g., a 10-year window starting/ending at the timestamp of the
record. The parameter $k$, the length of the durability window, and parameters
of the scoring function (which capture user preference) can all be given at the
query time. We illustrate why this problem formulation yields more meaningful
answers in some practical situations than other similar types of queries
considered previously. We propose new algorithms for solving this problem, and
provide a comprehensive theoretical analysis on the complexities of the problem
itself and of our algorithms. Our algorithms vastly outperform various
baselines (by up to two orders of magnitude on real and synthetic datasets).
</dc:description>
 <dc:description>Comment: in ICDE 2021</dc:description>
 <dc:date>2021-02-24</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.12072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.12593</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AniGAN: Style-Guided Generative Adversarial Networks for Unsupervised
  Anime Face Generation</dc:title>
 <dc:creator>Li, Bing</dc:creator>
 <dc:creator>Zhu, Yuanlue</dc:creator>
 <dc:creator>Wang, Yitong</dc:creator>
 <dc:creator>Lin, Chia-Wen</dc:creator>
 <dc:creator>Ghanem, Bernard</dc:creator>
 <dc:creator>Shen, Linlin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper, we propose a novel framework to translate a portrait
photo-face into an anime appearance. Our aim is to synthesize anime-faces which
are style-consistent with a given reference anime-face. However, unlike typical
translation tasks, such anime-face translation is challenging due to complex
variations of appearances among anime-faces. Existing methods often fail to
transfer the styles of reference anime-faces, or introduce noticeable
artifacts/distortions in the local shapes of their generated faces. We propose
AniGAN, a novel GAN-based translator that synthesizes high-quality anime-faces.
Specifically, a new generator architecture is proposed to simultaneously
transfer color/texture styles and transform local facial shapes into anime-like
counterparts based on the style of a reference anime-face, while preserving the
global structure of the source photo-face. We propose a double-branch
discriminator to learn both domain-specific distributions and domain-shared
distributions, helping generate visually pleasing anime-faces and effectively
mitigate artifacts. Extensive experiments on selfie2anime and a new face2anime
dataset qualitatively and quantitatively demonstrate the superiority of our
method over state-of-the-art methods. The new dataset is available at
https://github.com/bing-li-ai/AniGAN .
</dc:description>
 <dc:date>2021-02-24</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.12593</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.12730</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Swivel: Hardening WebAssembly against Spectre</dc:title>
 <dc:creator>Narayan, Shravan</dc:creator>
 <dc:creator>Disselkoen, Craig</dc:creator>
 <dc:creator>Moghimi, Daniel</dc:creator>
 <dc:creator>Cauligi, Sunjay</dc:creator>
 <dc:creator>Johnson, Evan</dc:creator>
 <dc:creator>Gang, Zhao</dc:creator>
 <dc:creator>Vahldiek-Oberwagner, Anjo</dc:creator>
 <dc:creator>Sahita, Ravi</dc:creator>
 <dc:creator>Shacham, Hovav</dc:creator>
 <dc:creator>Tullsen, Dean</dc:creator>
 <dc:creator>Stefan, Deian</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:description>  We describe Swivel, a new compiler framework for hardening WebAssembly (Wasm)
against Spectre attacks. Outside the browser, Wasm has become a popular
lightweight, in-process sandbox and is, for example, used in production to
isolate different clients on edge clouds and function-as-a-service platforms.
Unfortunately, Spectre attacks can bypass Wasm's isolation guarantees. Swivel
hardens Wasm against this class of attacks by ensuring that potentially
malicious code can neither use Spectre attacks to break out of the Wasm sandbox
nor coerce victim code-another Wasm client or the embedding process-to leak
secret data.
  We describe two Swivel designs, a software-only approach that can be used on
existing CPUs, and a hardware-assisted approach that uses extension available
in Intel 11th generation CPUs. For both, we evaluate a randomized approach that
mitigates Spectre and a deterministic approach that eliminates Spectre
altogether. Our randomized implementations impose under 10.3% overhead on the
Wasm-compatible subset of SPEC 2006, while our deterministic implementations
impose overheads between 3.3% and 240.2%. Though high on some benchmarks,
Swivel's overhead is still between 9x and 36.3x smaller than existing defenses
that rely on pipeline fences.
</dc:description>
 <dc:description>Comment: Accepted at USENIX 21</dc:description>
 <dc:date>2021-02-25</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.12730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.12759</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binary segmentation of medical images using implicit spline
  representations and deep learning</dc:title>
 <dc:creator>Barrowclough, Oliver J. D.</dc:creator>
 <dc:creator>Muntingh, Georg</dc:creator>
 <dc:creator>Nainamalai, Varatharajan</dc:creator>
 <dc:creator>Stangeby, Ivar</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>68U10, 68T45</dc:subject>
 <dc:subject>I.4.6</dc:subject>
 <dc:description>  We propose a novel approach to image segmentation based on combining implicit
spline representations with deep convolutional neural networks. This is done by
predicting the control points of a bivariate spline function whose zero-set
represents the segmentation boundary. We adapt several existing neural network
architectures and design novel loss functions that are tailored towards
providing implicit spline curve approximations. The method is evaluated on a
congenital heart disease computed tomography medical imaging dataset.
Experiments are carried out by measuring performance in various standard
metrics for different networks and loss functions. We determine that splines of
bidegree $(1,1)$ with $128\times128$ coefficient resolution performed optimally
for $512\times 512$ resolution CT images. For our best network, we achieve an
average volumetric test Dice score of almost 92%, which reaches the state of
the art for this congenital heart disease dataset.
</dc:description>
 <dc:description>Comment: 17 pages, 5 figures</dc:description>
 <dc:date>2021-02-25</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.12759</dc:identifier>
 <dc:identifier>Computer Aided Geometric Design, Volume 85, 2021</dc:identifier>
 <dc:identifier>doi:10.1016/j.cagd.2021.101972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.12994</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>$FM^2$: Field-matrixed Factorization Machines for Recommender Systems</dc:title>
 <dc:creator>Sun, Yang</dc:creator>
 <dc:creator>Pan, Junwei</dc:creator>
 <dc:creator>Zhang, Alex</dc:creator>
 <dc:creator>Flores, Aaron</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Click-through rate (CTR) prediction plays a critical role in recommender
systems and online advertising. The data used in these applications are
multi-field categorical data, where each feature belongs to one field. Field
information is proved to be important and there are several works considering
fields in their models. In this paper, we proposed a novel approach to model
the field information effectively and efficiently. The proposed approach is a
direct improvement of FwFM, and is named as Field-matrixed Factorization
Machines (FmFM, or $FM^2$). We also proposed a new explanation of FM and FwFM
within the FmFM framework, and compared it with the FFM. Besides pruning the
cross terms, our model supports field-specific variable dimensions of embedding
vectors, which acts as soft pruning. We also proposed an efficient way to
minimize the dimension while keeping the model performance. The FmFM model can
also be optimized further by caching the intermediate vectors, and it only
takes thousands of floating-point operations (FLOPs) to make a prediction. Our
experiment results show that it can out-perform the FFM, which is more complex.
The FmFM model's performance is also comparable to DNN models which require
much more FLOPs in runtime.
</dc:description>
 <dc:description>Comment: In Proceedings of the Web Conference 2021 (WWW 2021), April 19-23,
  2021, Ljubljana, Slovenia. 10 pages</dc:description>
 <dc:date>2021-02-19</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.12994</dc:identifier>
 <dc:identifier>doi:10.1145/3442381.3449930</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.13162</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unfounded Sets for Disjunctive Hybrid MKNF Knowledge Bases</dc:title>
 <dc:creator>Killen, Spencer</dc:creator>
 <dc:creator>You, Jia-Huai</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Combining the closed-world reasoning of answer set programming (ASP) with the
open-world reasoning of ontologies broadens the space of applications of
reasoners. Disjunctive hybrid MKNF knowledge bases succinctly extend ASP and in
some cases without increasing the complexity of reasoning tasks. However, in
many cases, solver development is lagging behind. As the result, the only known
method of solving disjunctive hybrid MKNF knowledge bases is based on
guess-and-verify, as formulated by Motik and Rosati in their original work. A
main obstacle is understanding how constraint propagation may be performed by a
solver, which, in the context of ASP, centers around the computation of
\textit{unfounded atoms}, the atoms that are false given a partial
interpretation. In this work, we build towards improving solvers for hybrid
MKNF knowledge bases with disjunctive rules: We formalize a notion of unfounded
sets for these knowledge bases, identify lower complexity bounds, and
demonstrate how we might integrate these developments into a solver. We discuss
challenges introduced by ontologies that are not present in the development of
solvers for disjunctive logic programs, which warrant some deviations from
traditional definitions of unfounded sets. We compare our work with prior
definitions of unfounded sets.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2021-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.13162</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.13192</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PlaceRAN: Optimal Placement of Virtualized Network Functions in the
  Next-generation Radio Access Networks</dc:title>
 <dc:creator>Morais, Fernando Zanferrari</dc:creator>
 <dc:creator>de Almeida, Gabriel Matheus</dc:creator>
 <dc:creator>Pinto, Leizer</dc:creator>
 <dc:creator>Cardoso, Kleber Vieira</dc:creator>
 <dc:creator>Contreras, Luis M.</dc:creator>
 <dc:creator>Righi, Rodrigo da Rosa</dc:creator>
 <dc:creator>Both, Cristiano Bonato</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The fifth-generation mobile evolution enables several transformations on Next
Generation Radio Access Networks (NG-RAN). The RAN protocol stack is splitting
into eight possible disaggregated options combined into three network units,
i.e., Central, Distributed, and Radio. Besides that, further advances allow the
RAN software to be virtualized on top of general-purpose vendor-neutral
hardware, dealing with the concept of virtualized RAN (vRAN). The disaggregated
network units initiatives reach full interoperability based on the Open RAN
(O-RAN). The combination of NG-RAN and vRAN results in vNG-RAN, enabling the
management of disaggregated units and protocols as a set of radio functions.
The placement of these functions is challenging since the best decision can be
based on multiple constraints, such as the RAN protocol stack split, routing
paths of transport networks with restricted bandwidth and latency requirements,
different topologies and link capabilities, asymmetric computational resources,
etc. This article proposes the first exact model for the placement optimization
of radio functions for vNG-RAN planning, named PlaceRAN. The main objective is
to minimize the computing resources and maximize the aggregation of radio
functions. The PlaceRAN evaluation considered two realistic network topologies.
Our results reveal that the PlaceRAN model achieves an optimized
high-performance aggregation level, it is flexible for RAN deployment
overcoming the network restrictions, and it is up to date with the most
advanced vNG-RAN design and development.
</dc:description>
 <dc:date>2021-02-25</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.13192</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.13220</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semidefinite Relaxations of Products of Nonnegative Forms on the Sphere</dc:title>
 <dc:creator>Yuan, Chenyang</dc:creator>
 <dc:creator>Parrilo, Pablo A.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>90C23, 90C22 (Primary) 14P10, 90C59, 68w25, 68Q25 (Secondary)</dc:subject>
 <dc:description>  We study the problem of maximizing the geometric mean of $d$ low-degree
non-negative forms on the real or complex sphere in $n$ variables. We show that
this highly non-convex problem is NP-hard even when the forms are quadratic and
is equivalent to optimizing a homogeneous polynomial of degree $O(d)$ on the
sphere. The standard Sum-of-Squares based convex relaxation for this polynomial
optimization problem requires solving a semidefinite program (SDP) of size
$n^{O(d)}$, with multiplicative approximation guarantees of
$\Omega(\frac{1}{n})$. We exploit the compact representation of this polynomial
to introduce a SDP relaxation of size polynomial in $n$ and $d$, and prove that
it achieves a constant factor multiplicative approximation when maximizing the
geometric mean of non-negative quadratic forms. We also show that this analysis
is asymptotically tight, with a sequence of instances where the gap between the
relaxation and true optimum approaches this constant factor as $d \rightarrow
\infty$. Next we propose a series of intermediate relaxations of increasing
complexity that interpolate to the full Sum-of-Squares relaxation, as well as a
rounding algorithm that finds an approximate solution from the solution of any
intermediate relaxation. Finally we show that this approach can be generalized
for relaxations of products of non-negative forms of any degree.
</dc:description>
 <dc:description>Comment: 26 pages, 3 figures. New Section 2.4 and fixed typos involving Fact
  4.4</dc:description>
 <dc:date>2021-02-25</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.13220</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2102.13338</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Behavioral Input-Output Parametrization of Control Policies with
  Suboptimality Guarantees</dc:title>
 <dc:creator>Furieri, Luca</dc:creator>
 <dc:creator>Guo, Baiwei</dc:creator>
 <dc:creator>Martin, Andrea</dc:creator>
 <dc:creator>Ferrari-Trecate, Giancarlo</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Recent work in data-driven control has revived behavioral theory to perform a
variety of complex control tasks, by directly plugging libraries of past
input-output trajectories into optimal control problems. Despite recent
advances, a key aspect remains unclear: how and to what extent do
noise-corrupted data impact control performance? In this work, we provide a
quantitative answer to this question. We formulate a Behavioral version of the
Input-Output Parametrization (BIOP) for the optimal predictive control of
unknown systems using output-feedback dynamic control policies. The main
advantages of the proposed framework are that 1) the state-space parameters and
the initial state need not be specified for controller synthesis, 2) it can be
used in combination with state-of-the-art impulse response estimators, and 3)
it allows to recover suboptimality results on learning the Linear Quadratic
Gaussian (LQG) controller, therefore revealing, in a quantitative way, how the
level of noise in the data affects the performance of behavioral methods.
Specifically, it is shown that the performance degrades linearly with the
prediction error of the behavioral model. We conclude the paper with numerical
experiments to validate our results.
</dc:description>
 <dc:description>Comment: Baiwei Guo and Andrea Martin contributed equally to this work</dc:description>
 <dc:date>2021-02-26</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2102.13338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.00366</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Confronting Machine Learning With Financial Research</dc:title>
 <dc:creator>Lommers, Kristof</dc:creator>
 <dc:creator>Harzli, Ouns El</dc:creator>
 <dc:creator>Kim, Jack</dc:creator>
 <dc:subject>Quantitative Finance - Statistical Finance</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Economics - Econometrics</dc:subject>
 <dc:description>  This study aims to examine the challenges and applications of machine
learning for financial research. Machine learning algorithms have been
developed for certain data environments which substantially differ from the one
we encounter in finance. Not only do difficulties arise due to some of the
idiosyncrasies of financial markets, there is a fundamental tension between the
underlying paradigm of machine learning and the research philosophy in
financial economics. Given the peculiar features of financial markets and the
empirical framework within social science, various adjustments have to be made
to the conventional machine learning methodology. We discuss some of the main
challenges of machine learning in finance and examine how these could be
accounted for. Despite some of the challenges, we argue that machine learning
could be unified with financial research to become a robust complement to the
econometrician's toolbox. Moreover, we discuss the various applications of
machine learning in the research process such as estimation, empirical
discovery, testing, causal inference and prediction.
</dc:description>
 <dc:date>2021-02-27</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.00366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.00528</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Medical Image Classification with Label Noise Using
  Dual-uncertainty Estimation</dc:title>
 <dc:creator>Ju, Lie</dc:creator>
 <dc:creator>Wang, Xin</dc:creator>
 <dc:creator>Wang, Lin</dc:creator>
 <dc:creator>Mahapatra, Dwarikanath</dc:creator>
 <dc:creator>Zhao, Xin</dc:creator>
 <dc:creator>Harandi, Mehrtash</dc:creator>
 <dc:creator>Drummond, Tom</dc:creator>
 <dc:creator>Liu, Tongliang</dc:creator>
 <dc:creator>Ge, Zongyuan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep neural networks are known to be data-driven and label noise can have a
marked impact on model performance. Recent studies have shown great robustness
to classic image recognition even under a high noisy rate. In medical
applications, learning from datasets with label noise is more challenging since
medical imaging datasets tend to have asymmetric (class-dependent) noise and
suffer from high observer variability.
  In this paper, we systematically discuss and define the two common types of
label noise in medical images - disagreement label noise from inconsistency
expert opinions and single-target label noise from wrong diagnosis record. We
then propose an uncertainty estimation-based framework to handle these two
label noise amid the medical image classification task. We design a
dual-uncertainty estimation approach to measure the disagreement label noise
and single-target label noise via Direct Uncertainty Prediction and
Monte-Carlo-Dropout.
  A boosting-based curriculum training procedure is later introduced for robust
learning. We demonstrate the effectiveness of our method by conducting
extensive experiments on three different diseases: skin lesions, prostate
cancer, and retinal diseases. We also release a large re-engineered database
that consists of annotations from more than ten ophthalmologists with an
unbiased golden standard dataset for evaluation and benchmarking.
</dc:description>
 <dc:date>2021-02-28</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.00528</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.00571</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Optimization of SU3_Bench on Xeon and Programmable
  Integrated Unified Memory Architecture</dc:title>
 <dc:creator>Tithi, Jesmin Jahan</dc:creator>
 <dc:creator>Checconi, Fabio</dc:creator>
 <dc:creator>Doerfler, Douglas</dc:creator>
 <dc:creator>Petrini, Fabrizio</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  SU3\_Bench is a microbenchmark developed to explore performance portability
across multiple programming models/methodologies using a simple, but
nontrivial, mathematical kernel. This kernel has been derived from the MILC
lattice quantum chromodynamics (LQCD) code. SU3\_Bench is bandwidth bound and
generates regular compute and data access patterns. Therefore, on most
traditional CPU and GPU-based systems, its performance is mainly determined by
the achievable memory bandwidth. Although SU3\_Bench is a simple kernel,
experience says its subtleties require a certain amount of tweaking to achieve
peak performance for a given programming model and hardware, making performance
portability challenging. In this paper, we share some of the challenges in
obtaining the peak performance for SU3\_Bench on a state-of-the-art Intel Xeon
machine, due to the nuances of variable definition, the nature of
compiler-provided default constructors, how memory is accessed at object
creation time, and the NUMA effects on the machine. We discuss how to tackle
those challenges to improve SU3\_Bench's performance by \(2\times\) compared to
the original OpenMP implementation available at Github. This provides a
valuable lesson for other similar kernels.
  Expanding on the performance portability aspects, we also show early results
obtained porting SU3\_Bench to the new Intel Programmable Integrated Unified
Memory Architecture (PIUMA), characterized by a more balanced flops-to-byte
ratio. This paper shows that it is not the usual bandwidth or flops, rather the
pipeline throughput, that determines SU3\_Bench's performance on PIUMA.
Finally, we show how to improve performance on PIUMA and how that compares with
the performance on Xeon, which has around one order of magnitude more
flops-per-byte.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2021-02-28</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.00571</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.00616</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Human-like Hand Reaching for Human-Robot Handshaking</dc:title>
 <dc:creator>Prasad, Vignesh</dc:creator>
 <dc:creator>Stock-Homburg, Ruth</dc:creator>
 <dc:creator>Peters, Jan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  One of the first and foremost non-verbal interactions that humans perform is
a handshake. It has an impact on first impressions as touch can convey complex
emotions. This makes handshaking an important skill for the repertoire of a
social robot. In this paper, we present a novel framework for learning reaching
behaviours for human-robot handshaking behaviours for humanoid robots solely
using third-person human-human interaction data. This is especially useful for
non-backdrivable robots that cannot be taught by demonstrations via kinesthetic
teaching. Our approach can be easily executed on different humanoid robots.
This removes the need for re-training, which is especially tedious when
training with human-interaction partners. We show this by applying the learnt
behaviours on two different humanoid robots with similar degrees of freedom but
different shapes and control limits.
</dc:description>
 <dc:description>Comment: Accepted in ICRA'21</dc:description>
 <dc:date>2021-02-28</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.00616</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.00705</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A low-degree strictly conservative finite element method for
  incompressible flows</dc:title>
 <dc:creator>Zeng, Huilan</dc:creator>
 <dc:creator>Zhang, Chen-Song</dc:creator>
 <dc:creator>Zhang, Shuo</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  In this paper, a new $P_{2}-P_{1}$ finite element pair is proposed for
incompressible fluid. For this pair, the discrete inf-sup condition and the
discrete Korn's inequality hold on general triangulations. It yields exactly
divergence-free velocity approximations when applied to models of
incompressible flows. The robust capacity of the pair for incompressible flows
are verified theoretically and numerically.
</dc:description>
 <dc:description>Comment: 28 pages, 22 figures</dc:description>
 <dc:date>2021-02-28</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.00705</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.00986</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fixed-Time Convergent Control Barrier Functions for Coupled Multi-Agent
  Systems Under STL Tasks</dc:title>
 <dc:creator>Sharifi, Maryam</dc:creator>
 <dc:creator>Dimarogonas, Dimos V.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents a control strategy based on a new notion of time-varying
fixed-time convergent control barrier functions (TFCBFs) for a class of coupled
multi-agent systems under signal temporal logic (STL) tasks. In this framework,
each agent is assigned a local STL task regradless of the tasks of other
agents. Each task may be dependent on the behavior of other agents which may
cause conflicts on the satisfaction of all tasks. Our approach finds a robust
solution to guarantee the fixed-time satisfaction of STL tasks in a least
violating way and independent of the agents' initial condition in the presence
of undesired violation effects of the neighbor agents. Particularly, the robust
performance of the task satisfactions can be adjusted in a user-specified way.
</dc:description>
 <dc:description>Comment: Accepted in ECC 2021</dc:description>
 <dc:date>2021-03-01</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.00986</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.01100</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Categorical Depth Distribution Network for Monocular 3D Object Detection</dc:title>
 <dc:creator>Reading, Cody</dc:creator>
 <dc:creator>Harakeh, Ali</dc:creator>
 <dc:creator>Chae, Julia</dc:creator>
 <dc:creator>Waslander, Steven L.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Monocular 3D object detection is a key problem for autonomous vehicles, as it
provides a solution with simple configuration compared to typical multi-sensor
systems. The main challenge in monocular 3D detection lies in accurately
predicting object depth, which must be inferred from object and scene cues due
to the lack of direct range measurement. Many methods attempt to directly
estimate depth to assist in 3D detection, but show limited performance as a
result of depth inaccuracy. Our proposed solution, Categorical Depth
Distribution Network (CaDDN), uses a predicted categorical depth distribution
for each pixel to project rich contextual feature information to the
appropriate depth interval in 3D space. We then use the computationally
efficient bird's-eye-view projection and single-stage detector to produce the
final output bounding boxes. We design CaDDN as a fully differentiable
end-to-end approach for joint depth estimation and object detection. We
validate our approach on the KITTI 3D object detection benchmark, where we rank
1st among published monocular methods. We also provide the first monocular 3D
detection results on the newly released Waymo Open Dataset. We provide a code
release for CaDDN which is made available.
</dc:description>
 <dc:description>Comment: Accepted in CVPR 2021</dc:description>
 <dc:date>2021-03-01</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.01100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.01171</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Expected Value of Communication for Planning in Ad Hoc Teamwork</dc:title>
 <dc:creator>Macke, William</dc:creator>
 <dc:creator>Mirsky, Reuth</dc:creator>
 <dc:creator>Stone, Peter</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>I.2.m</dc:subject>
 <dc:description>  A desirable goal for autonomous agents is to be able to coordinate on the fly
with previously unknown teammates. Known as &quot;ad hoc teamwork&quot;, enabling such a
capability has been receiving increasing attention in the research community.
One of the central challenges in ad hoc teamwork is quickly recognizing the
current plans of other agents and planning accordingly. In this paper, we focus
on the scenario in which teammates can communicate with one another, but only
at a cost. Thus, they must carefully balance plan recognition based on
observations vs. that based on communication. This paper proposes a new metric
for evaluating how similar are two policies that a teammate may be following -
the Expected Divergence Point (EDP). We then present a novel planning algorithm
for ad hoc teamwork, determining which query to ask and planning accordingly.
We demonstrate the effectiveness of this algorithm in a range of increasingly
general communication in ad hoc teamwork problems.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figure, Published at AAAI 2021</dc:description>
 <dc:date>2021-03-01</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.01171</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.01179</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Noncoding RNAs and deep learning neural network discriminate
  multi-cancer types</dc:title>
 <dc:creator>Wang, Anyou</dc:creator>
 <dc:creator>Hai, Rong</dc:creator>
 <dc:creator>Rider, Paul J</dc:creator>
 <dc:creator>He, Qianchuan</dc:creator>
 <dc:subject>Quantitative Biology - Molecular Networks</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Detecting cancers at early stages can dramatically reduce mortality rates.
Therefore, practical cancer screening at the population level is needed. Here,
we develop a comprehensive detection system to classify all common cancer
types. By integrating artificial intelligence deep learning neural network and
noncoding RNA biomarkers selected from massive data, our system can accurately
detect cancer vs healthy object with 96.3% of AUC of ROC (Area Under Curve of a
Receiver Operating Characteristic curve). Intriguinely, with no more than 6
biomarkers, our approach can easily discriminate any individual cancer type vs
normal with 99% to 100% AUC. Furthermore, a comprehensive marker panel can
simultaneously multi-classify all common cancers with a stable 78% of accuracy
at heterological cancerous tissues and conditions. This provides a valuable
framework for large scale cancer screening. The AI models and plots of results
were available in https://combai.org/ai/cancerdetection/
</dc:description>
 <dc:description>Comment: 7 pages and 3 figures</dc:description>
 <dc:date>2021-03-01</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.01179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.01362</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Operator inference of non-Markovian terms for learning reduced models
  from partially observed state trajectories</dc:title>
 <dc:creator>Uy, Wayne Isaac Tan</dc:creator>
 <dc:creator>Peherstorfer, Benjamin</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  This work introduces a non-intrusive model reduction approach for learning
reduced models from partially observed state trajectories of high-dimensional
dynamical systems. The proposed approach compensates for the loss of
information due to the partially observed states by constructing non-Markovian
reduced models that make future-state predictions based on a history of reduced
states, in contrast to traditional Markovian reduced models that rely on the
current reduced state alone to predict the next state. The core contributions
of this work are a data sampling scheme to sample partially observed states
from high-dimensional dynamical systems and a formulation of a regression
problem to fit the non-Markovian reduced terms to the sampled states. Under
certain conditions, the proposed approach recovers from data the very same
non-Markovian terms that one obtains with intrusive methods that require the
governing equations and discrete operators of the high-dimensional dynamical
system. Numerical results demonstrate that the proposed approach leads to
non-Markovian reduced models that are predictive far beyond the training
regime. Additionally, in the numerical experiments, the proposed approach
learns non-Markovian reduced models from trajectories with only 20% observed
state components that are about as accurate as traditional Markovian reduced
models fitted to trajectories with 99% observed components.
</dc:description>
 <dc:date>2021-03-01</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.01362</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.01566</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contextually Guided Convolutional Neural Networks for Learning Most
  Transferable Representations</dc:title>
 <dc:creator>Kursun, Olcay</dc:creator>
 <dc:creator>Dinc, Semih</dc:creator>
 <dc:creator>Favorov, Oleg V.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Deep Convolutional Neural Networks (CNNs), trained extensively on very large
labeled datasets, learn to recognize inferentially powerful features in their
input patterns and represent efficiently their objective content. Such
objectivity of their internal representations enables deep CNNs to readily
transfer and successfully apply these representations to new classification
tasks. Deep CNNs develop their internal representations through a challenging
process of error backpropagation-based supervised training. In contrast, deep
neural networks of the cerebral cortex develop their even more powerful
internal representations in an unsupervised process, apparently guided at a
local level by contextual information. Implementing such local contextual
guidance principles in a single-layer CNN architecture, we propose an efficient
algorithm for developing broad-purpose representations (i.e., representations
transferable to new tasks without additional training) in shallow CNNs trained
on limited-size datasets. A contextually guided CNN (CG-CNN) is trained on
groups of neighboring image patches picked at random image locations in the
dataset. Such neighboring patches are likely to have a common context and
therefore are treated for the purposes of training as belonging to the same
class. Across multiple iterations of such training on different context-sharing
groups of image patches, CNN features that are optimized in one iteration are
then transferred to the next iteration for further optimization, etc. In this
process, CNN features acquire higher pluripotency, or inferential utility for
any arbitrary classification task, which we quantify as a transfer utility. In
our application to natural images, we find that CG-CNN features show the same,
if not higher, transfer utility and classification accuracy as comparable
transferable features in the first CNN layer of the well-known deep networks.
</dc:description>
 <dc:date>2021-03-02</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.01566</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.01644</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting latent representation of sparse semantic layers for improved
  short-term motion prediction with Capsule Networks</dc:title>
 <dc:creator>Dulian, Albert</dc:creator>
 <dc:creator>Murray, John C.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  As urban environments manifest high levels of complexity it is of vital
importance that safety systems embedded within autonomous vehicles (AVs) are
able to accurately anticipate short-term future motion of nearby agents. This
problem can be further understood as generating a sequence of coordinates
describing the future motion of the tracked agent. Various proposed approaches
demonstrate significant benefits of using a rasterised top-down image of the
road, with a combination of Convolutional Neural Networks (CNNs), for
extraction of relevant features that define the road structure (eg. driveable
areas, lanes, walkways). In contrast, this paper explores use of Capsule
Networks (CapsNets) in the context of learning a hierarchical representation of
sparse semantic layers corresponding to small regions of the High-Definition
(HD) map. Each region of the map is dismantled into separate geometrical layers
that are extracted with respect to the agent's current position. By using an
architecture based on CapsNets the model is able to retain hierarchical
relationships between detected features within images whilst also preventing
loss of spatial data often caused by the pooling operation. We train and
evaluate our model on publicly available dataset nuTonomy scenes and compare it
to recently published methods. We show that our model achieves significant
improvement over recently published works on deterministic prediction, whilst
drastically reducing the overall size of the network.
</dc:description>
 <dc:date>2021-03-02</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.01644</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.01849</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HED-UNet: Combined Segmentation and Edge Detection for Monitoring the
  Antarctic Coastline</dc:title>
 <dc:creator>Heidler, Konrad</dc:creator>
 <dc:creator>Mou, Lichao</dc:creator>
 <dc:creator>Baumhoer, Celia</dc:creator>
 <dc:creator>Dietz, Andreas</dc:creator>
 <dc:creator>Zhu, Xiao Xiang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:description>  Deep learning-based coastline detection algorithms have begun to outshine
traditional statistical methods in recent years. However, they are usually
trained only as single-purpose models to either segment land and water or
delineate the coastline. In contrast to this, a human annotator will usually
keep a mental map of both segmentation and delineation when performing manual
coastline detection. To take into account this task duality, we therefore
devise a new model to unite these two approaches in a deep learning model. By
taking inspiration from the main building blocks of a semantic segmentation
framework (UNet) and an edge detection framework (HED), both tasks are combined
in a natural way. Training is made efficient by employing deep supervision on
side predictions at multiple resolutions. Finally, a hierarchical attention
mechanism is introduced to adaptively merge these multiscale predictions into
the final model output. The advantages of this approach over other traditional
and deep learning-based methods for coastline detection are demonstrated on a
dataset of Sentinel-1 imagery covering parts of the Antarctic coast, where
coastline detection is notoriously difficult. An implementation of our method
is available at \url{https://github.com/khdlr/HED-UNet}.
</dc:description>
 <dc:description>Comment: This work has been accepted by IEEE TGRS for publication. Copyright
  may be transferred without notice, after which this version may no longer be
  accessible</dc:description>
 <dc:date>2021-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.01849</dc:identifier>
 <dc:identifier>doi:10.1109/TGRS.2021.3064606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.01903</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Relation Reasoning for Shot-Stable Few-Shot Object Detection</dc:title>
 <dc:creator>Zhu, Chenchen</dc:creator>
 <dc:creator>Chen, Fangyi</dc:creator>
 <dc:creator>Ahmed, Uzair</dc:creator>
 <dc:creator>Shen, Zhiqiang</dc:creator>
 <dc:creator>Savvides, Marios</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Few-shot object detection is an imperative and long-lasting problem due to
the inherent long-tail distribution of real-world data. Its performance is
largely affected by the data scarcity of novel classes. But the semantic
relation between the novel classes and the base classes is constant regardless
of the data availability. In this work, we investigate utilizing this semantic
relation together with the visual information and introduce explicit relation
reasoning into the learning of novel object detection. Specifically, we
represent each class concept by a semantic embedding learned from a large
corpus of text. The detector is trained to project the image representations of
objects into this embedding space. We also identify the problems of trivially
using the raw embeddings with a heuristic knowledge graph and propose to
augment the embeddings with a dynamic relation graph. As a result, our few-shot
detector, termed SRR-FSD, is robust and stable to the variation of shots of
novel objects. Experiments show that SRR-FSD can achieve competitive results at
higher shots, and more importantly, a significantly better performance given
both lower explicit and implicit shots. The benchmark protocol with implicit
shots removed from the pretrained classification dataset can serve as a more
realistic setting for future research.
</dc:description>
 <dc:description>Comment: CVPR 2021</dc:description>
 <dc:date>2021-03-02</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.01903</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.01933</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PHASE: PHysically-grounded Abstract Social Events for Machine Social
  Perception</dc:title>
 <dc:creator>Netanyahu, Aviv</dc:creator>
 <dc:creator>Shu, Tianmin</dc:creator>
 <dc:creator>Katz, Boris</dc:creator>
 <dc:creator>Barbu, Andrei</dc:creator>
 <dc:creator>Tenenbaum, Joshua B.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The ability to perceive and reason about social interactions in the context
of physical environments is core to human social intelligence and human-machine
cooperation. However, no prior dataset or benchmark has systematically
evaluated physically grounded perception of complex social interactions that go
beyond short actions, such as high-fiving, or simple group activities, such as
gathering. In this work, we create a dataset of physically-grounded abstract
social events, PHASE, that resemble a wide range of real-life social
interactions by including social concepts such as helping another agent. PHASE
consists of 2D animations of pairs of agents moving in a continuous space
generated procedurally using a physics engine and a hierarchical planner.
Agents have a limited field of view, and can interact with multiple objects, in
an environment that has multiple landmarks and obstacles. Using PHASE, we
design a social recognition task and a social prediction task. PHASE is
validated with human experiments demonstrating that humans perceive rich
interactions in the social events, and that the simulated agents behave
similarly to humans. As a baseline model, we introduce a Bayesian inverse
planning approach, SIMPLE (SIMulation, Planning and Local Estimation), which
outperforms state-of-the-art feed-forward neural networks. We hope that PHASE
can serve as a difficult new challenge for developing new models that can
recognize complex social interactions.
</dc:description>
 <dc:description>Comment: The first two authors contributed equally; AAAI 2021; 13 pages, 7
  figures; Project page: https://www.tshu.io/PHASE</dc:description>
 <dc:date>2021-03-02</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.01933</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.02143</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random Feature Attention</dc:title>
 <dc:creator>Peng, Hao</dc:creator>
 <dc:creator>Pappas, Nikolaos</dc:creator>
 <dc:creator>Yogatama, Dani</dc:creator>
 <dc:creator>Schwartz, Roy</dc:creator>
 <dc:creator>Smith, Noah A.</dc:creator>
 <dc:creator>Kong, Lingpeng</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Transformers are state-of-the-art models for a variety of sequence modeling
tasks. At their core is an attention function which models pairwise
interactions between the inputs at every timestep. While attention is powerful,
it does not scale efficiently to long sequences due to its quadratic time and
space complexity in the sequence length. We propose RFA, a linear time and
space attention that uses random feature methods to approximate the softmax
function, and explore its application in transformers. RFA can be used as a
drop-in replacement for conventional softmax attention and offers a
straightforward way of learning with recency bias through an optional gating
mechanism. Experiments on language modeling and machine translation demonstrate
that RFA achieves similar or better performance compared to strong transformer
baselines. In the machine translation experiment, RFA decodes twice as fast as
a vanilla transformer. Compared to existing efficient transformer variants, RFA
is competitive in terms of both accuracy and efficiency on three long text
classification datasets. Our analysis shows that RFA's efficiency gains are
especially notable on long sequences, suggesting that RFA will be particularly
useful in tasks that require working with large inputs, fast decoding speed, or
low memory footprints.
</dc:description>
 <dc:description>Comment: ICLR 2021</dc:description>
 <dc:date>2021-03-02</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.02143</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.02249</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LQResNet: A Deep Neural Network Architecture for Learning Dynamic
  Processes</dc:title>
 <dc:creator>Goyal, Pawan</dc:creator>
 <dc:creator>Benner, Peter</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  Mathematical modeling is an essential step, for example, to analyze the
transient behavior of a dynamical process and to perform engineering studies
such as optimization and control. With the help of first-principles and expert
knowledge, a dynamic model can be built, but for complex dynamic processes,
appearing, e.g., in biology, chemical plants, neuroscience, financial markets,
this often remains an onerous task. Hence, data-driven modeling of the dynamics
process becomes an attractive choice and is supported by the rapid advancement
in sensor and measurement technology. A data-driven approach, namely operator
inference framework, models a dynamic process, where a particular structure of
the nonlinear term is assumed. In this work, we suggest combining the operator
inference with certain deep neural network approaches to infer the unknown
nonlinear dynamics of the system. The approach uses recent advancements in deep
learning and possible prior knowledge of the process if possible. We also
briefly discuss several extensions and advantages of the proposed methodology.
We demonstrate that the proposed methodology accomplishes the desired tasks for
dynamics processes encountered in neural dynamics and the glycolytic
oscillator.
</dc:description>
 <dc:date>2021-03-03</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.02249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.02265</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Meta-Learning with Variational Bayes</dc:title>
 <dc:creator>Lingle, Lucas D.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The field of meta-learning seeks to improve the ability of today's machine
learning systems to adapt efficiently to small amounts of data. Typically this
is accomplished by training a system with a parametrized update rule to improve
a task-relevant objective based on supervision or a reward function. However,
in many domains of practical interest, task data is unlabeled, or reward
functions are unavailable. In this paper we introduce a new approach to address
the more general problem of generative meta-learning, which we argue is an
important prerequisite for obtaining human-level cognitive flexibility in
artificial agents, and can benefit many practical applications along the way.
Our contribution leverages the AEVB framework and mean-field variational Bayes,
and creates fast-adapting latent-space generative models. At the heart of our
contribution is a new result, showing that for a broad class of deep generative
latent variable models, the relevant VB updates do not depend on any generative
neural network. The theoretical merits of our approach are reflected in
empirical experiments.
</dc:description>
 <dc:description>Comment: 38 pages, 6 figures. v2 updates: link to code and light edits</dc:description>
 <dc:date>2021-03-03</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.02265</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.02789</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning the Next Best View for 3D Point Clouds via Topological Features</dc:title>
 <dc:creator>Collander, Christopher</dc:creator>
 <dc:creator>Beksi, William J.</dc:creator>
 <dc:creator>Huber, Manfred</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper, we introduce a reinforcement learning approach utilizing a
novel topology-based information gain metric for directing the next best view
of a noisy 3D sensor. The metric combines the disjoint sections of an observed
surface to focus on high-detail features such as holes and concave sections.
Experimental results show that our approach can aid in establishing the
placement of a robotic sensor to optimize the information provided by its
streaming point cloud data. Furthermore, a labeled dataset of 3D objects, a CAD
design for a custom robotic manipulator, and software for the transformation,
union, and registration of point clouds has been publicly released to the
research community.
</dc:description>
 <dc:description>Comment: To be published in the 2021 IEEE International Conference on Robotics
  and Automation (ICRA)</dc:description>
 <dc:date>2021-03-03</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.02789</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.02825</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enabling Software Resilience in GPGPU Applications via Partial Thread
  Protection</dc:title>
 <dc:creator>Yang, Lishan</dc:creator>
 <dc:creator>Nie, Bin</dc:creator>
 <dc:creator>Jog, Adwait</dc:creator>
 <dc:creator>Smirni, Evgenia</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Graphics Processing Units (GPUs) are widely used by various applications in a
broad variety of fields to accelerate their computation but remain susceptible
to transient hardware faults (soft errors) that can easily compromise
application output. By taking advantage of a general purpose GPU application
hierarchical organization in threads, warps, and cooperative thread arrays, we
propose a methodology that identifies the resilience of threads and aims to map
threads with the same resilience characteristics to the same warp. This allows
engaging partial replication mechanisms for error detection/correction at the
warp level. By exploring 12 benchmarks (17 kernels) from 4 benchmark suites, we
illustrate that threads can be remapped into reliable or unreliable warps with
only 1.63% introduced overhead (on average), and then enable selective
protection via replication to those groups of threads that truly need it.
Furthermore, we show that thread remapping to different warps does not
sacrifice application performance. We show how this remapping facilitates warp
replication for error detection and/or correction and achieves an average
reduction of 20.61% and 27.15% execution cycles, respectively comparing to
standard duplication/triplication.
</dc:description>
 <dc:description>Comment: Accepted to the 43rd International Conference on Software Engineering
  (ICSE 2021)</dc:description>
 <dc:date>2021-03-03</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.02825</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.02927</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>QAIR: Practical Query-efficient Black-Box Attacks for Image Retrieval</dc:title>
 <dc:creator>Li, Xiaodan</dc:creator>
 <dc:creator>Li, Jinfeng</dc:creator>
 <dc:creator>Chen, Yuefeng</dc:creator>
 <dc:creator>Ye, Shaokai</dc:creator>
 <dc:creator>He, Yuan</dc:creator>
 <dc:creator>Wang, Shuhui</dc:creator>
 <dc:creator>Su, Hang</dc:creator>
 <dc:creator>Xue, Hui</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We study the query-based attack against image retrieval to evaluate its
robustness against adversarial examples under the black-box setting, where the
adversary only has query access to the top-k ranked unlabeled images from the
database. Compared with query attacks in image classification, which produce
adversaries according to the returned labels or confidence score, the challenge
becomes even more prominent due to the difficulty in quantifying the attack
effectiveness on the partial retrieved list. In this paper, we make the first
attempt in Query-based Attack against Image Retrieval (QAIR), to completely
subvert the top-k retrieval results. Specifically, a new relevance-based loss
is designed to quantify the attack effects by measuring the set similarity on
the top-k retrieval results before and after attacks and guide the gradient
optimization. To further boost the attack efficiency, a recursive model
stealing method is proposed to acquire transferable priors on the target model
and generate the prior-guided gradients. Comprehensive experiments show that
the proposed attack achieves a high attack success rate with few queries
against the image retrieval systems under the black-box setting. The attack
evaluations on the real-world visual search engine show that it successfully
deceives a commercial system such as Bing Visual Search with 98% attack success
rate by only 33 queries on average.
</dc:description>
 <dc:date>2021-03-04</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.02927</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.03234</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Agent-Based Modelling Approach to Brain Drain</dc:title>
 <dc:creator>G&#xfc;rsoy, Furkan</dc:creator>
 <dc:creator>Badur, Bertan</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Economics - General Economics</dc:subject>
 <dc:description>  The phenomenon of brain drain, that is the emigration of highly skilled
people, has many undesirable effects, particularly for developing countries. In
this study, an agent-based model is developed to understand the dynamics of
such emigration. We hypothesise that skilled people's emigration decisions are
based on several factors including the overall economic and social difference
between the home and host countries, people's ability and capacity to obtain
good jobs and start a life abroad, and the barriers of moving abroad.
Furthermore, the social network of individuals also plays a significant role.
The model is validated using qualitative and quantitative pattern matching with
real-world observations. Sensitivity and uncertainty analyses are performed in
addition to several scenario analyses. Linear and random forest response
surface models are created to provide quick predictions on the number of
emigrants as well as to understand the effect sizes of individual parameters.
Overall, the study provides an abstract model where brain drain dynamics can be
explored. Findings from the simulation outputs show that future socioeconomic
state of the country is more important than the current state, lack of barriers
results in a large number of emigrants, and network effects ensue compounding
effects on emigration. Upon further development and customisation, future
versions can assist in the decision-making of social policymakers regarding
brain drain.
</dc:description>
 <dc:description>Comment: Changes: minor language improvements, copyright notice</dc:description>
 <dc:date>2021-03-04</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.03234</dc:identifier>
 <dc:identifier>doi:10.1109/TCSS.2021.3066074</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.03388</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Limits of Probabilistic Safety Guarantees when Considering Human
  Uncertainty</dc:title>
 <dc:creator>Cheng, Richard</dc:creator>
 <dc:creator>Murray, Richard M.</dc:creator>
 <dc:creator>Burdick, Joel W.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  When autonomous robots interact with humans, such as during autonomous
driving, explicit safety guarantees are crucial in order to avoid potentially
life-threatening accidents. Many data-driven methods have explored learning
probabilistic bounds over human agents' trajectories (i.e. confidence tubes
that contain trajectories with probability $\delta$), which can then be used to
guarantee safety with probability $1-\delta$. However, almost all existing
works consider $\delta \geq 0.001$. The purpose of this paper is to argue that
(1) in safety-critical applications, it is necessary to provide safety
guarantees with $\delta &lt; 10^{-8}$, and (2) current learning-based methods are
ill-equipped to compute accurate confidence bounds at such low $\delta$. Using
human driving data (from the highD dataset), as well as synthetically generated
data, we show that current uncertainty models use inaccurate distributional
assumptions to describe human behavior and/or require infeasible amounts of
data to accurately learn confidence bounds for $\delta \leq 10^{-8}$. These two
issues result in unreliable confidence bounds, which can have dangerous
implications if deployed on safety-critical systems.
</dc:description>
 <dc:description>Comment: ICRA 2021</dc:description>
 <dc:date>2021-03-04</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.03388</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.03504</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extremum seeking control of a class of constrained nonlinear systems</dc:title>
 <dc:creator>Yuan, Shuai</dc:creator>
 <dc:creator>Fabiani, Filippo</dc:creator>
 <dc:creator>Baldi, Simone</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper studies the extremum seeking control (ESC) problem for a class of
constrained nonlinear systems. Specifically, we focus on a family of
constraints allowing to reformulate the original nonlinear system in the
so-called input-output normal form. To steer the system to optimize a
performance function without knowing its explicit form, we propose a novel
numerical optimization-based extremum seeking control (NOESC) design consisting
of a constrained numerical optimization method and an inversion based
feedforward controller. In particular, a projected gradient descent algorithm
is exploited to produce the state sequence to optimize the performance
function, whereas a suitable boundary value problem accommodates the
finite-time state transition between each two consecutive points of the state
sequence. Compared to available NOESC methods, the proposed approach i) can
explicitly deal with output constraints; ii) the performance function can
consider a direct dependence on the states of the internal dynamics; iii) the
internal dynamics do not have to be necessarily stable. The effectiveness of
the proposed ESC scheme is shown through extensive numerical simulations.
</dc:description>
 <dc:date>2021-03-05</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.03504</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.03583</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph-Based Tri-Attention Network for Answer Ranking in CQA</dc:title>
 <dc:creator>Zhang, Wei</dc:creator>
 <dc:creator>Chen, Zeyuan</dc:creator>
 <dc:creator>Dong, Chao</dc:creator>
 <dc:creator>Wang, Wen</dc:creator>
 <dc:creator>Zha, Hongyuan</dc:creator>
 <dc:creator>Wang, Jianyong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In community-based question answering (CQA) platforms, automatic answer
ranking for a given question is critical for finding potentially popular
answers in early times. The mainstream approaches learn to generate answer
ranking scores based on the matching degree between question and answer
representations as well as the influence of respondents. However, they
encounter two main limitations: (1) Correlations between answers in the same
question are often overlooked. (2) Question and respondent representations are
built independently of specific answers before affecting answer
representations. To address the limitations, we devise a novel graph-based
tri-attention network, namely GTAN, which has two innovations. First, GTAN
proposes to construct a graph for each question and learn answer correlations
from each graph through graph neural networks (GNNs). Second, based on the
representations learned from GNNs, an alternating tri-attention method is
developed to alternatively build target-aware respondent representations,
answer-specific question representations, and context-aware answer
representations by attention computation. GTAN finally integrates the above
representations to generate answer ranking scores. Experiments on three
real-world CQA datasets demonstrate GTAN significantly outperforms
state-of-the-art answer ranking methods, validating the rationality of the
network architecture.
</dc:description>
 <dc:description>Comment: 9 pages (published in AAAI 2021)</dc:description>
 <dc:date>2021-03-05</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.03583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.04033</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Effective Approach to Minimize Error in Midpoint Ellipse Drawing
  Algorithm</dc:title>
 <dc:creator>Idrisi, Dr. M. Javed</dc:creator>
 <dc:creator>Ashraf, Aayesha</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>68Wxx</dc:subject>
 <dc:subject>I.3</dc:subject>
 <dc:description>  The present paper deals with the generalization of Midpoint Ellipse Drawing
Algorithm (MPEDA) to minimize the error in the existing MPEDA in cartesian
form. In this method, we consider three different values of h, i.e., 1, 0.5 and
0.1. For h = 1, all the results of MPEDA have been verified. For other values
of h it is observed that as the value of h decreases, the number of iteration
increases but the error between the points generated and the original ellipse
points decreases and vice-versa.
</dc:description>
 <dc:description>Comment: 12 pages, 7 tables and 3 figures</dc:description>
 <dc:date>2021-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.04033</dc:identifier>
 <dc:identifier>Internaational Journal of Engineering Research and Technology,
  Vol. 10, Issue 2, p. 621-625, 2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.04036</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimation of Spatially-Correlated Ocean Currents from Ensemble
  Forecasts and Online Measurements</dc:title>
 <dc:creator>To, K. Y. Cadmus</dc:creator>
 <dc:creator>Kong, Felix H.</dc:creator>
 <dc:creator>Lee, Ki Myung Brian</dc:creator>
 <dc:creator>Yoo, Chanyeol</dc:creator>
 <dc:creator>Anstee, Stuart</dc:creator>
 <dc:creator>Fitch, Robert</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present a method to estimate two-dimensional, time-invariant oceanic flow
fields based on data from both ensemble forecasts and online measurements. Our
method produces a realistic estimate in a computationally efficient manner
suitable for use in marine robotics for path planning and related applications.
We use kernel methods and singular value decomposition to find a compact model
of the ensemble data that is represented as a linear combination of basis flow
fields and that preserves the spatial correlations present in the data. Online
measurements of ocean current, taken for example by marine robots, can then be
incorporated using recursive Bayesian estimation. We provide computational
analysis, performance comparisons with related methods, and demonstration with
real-world ensemble data to show the computational efficiency and validity of
our method. Possible applications in addition to path planning include active
perception for model improvement through deliberate choice of measurement
locations.
</dc:description>
 <dc:description>Comment: 7 pages, 6 figures, accepted to IEEE ICRA 2021</dc:description>
 <dc:date>2021-03-06</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.04036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.04073</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intelligent Reflecting Surface Enhanced D2D Cooperative Computing</dc:title>
 <dc:creator>Mao, Sun</dc:creator>
 <dc:creator>Chu, Xiaoli</dc:creator>
 <dc:creator>Wu, Qingqing</dc:creator>
 <dc:creator>Liu, Lei</dc:creator>
 <dc:creator>Feng, Jie</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  This paper investigates a device-to-device (D2D) cooperative computing
system, where an user can offload part of its computation task to nearby idle
users with the aid of an intelligent reflecting surface (IRS). We propose to
minimize the total computing delay via jointly optimizing the computation task
assignment, transmit power, bandwidth allocation, and phase beamforming of the
IRS. To solve the formulated problem, we devise an alternating optimization
algorithm with guaranteed convergence. In particular, the task assignment
strategy is derived in closed-form expression, while the phase beamforming is
optimized by exploiting the semi-definite relaxation (SDR) method. Numerical
results demonstrate that the IRS enhanced D2D cooperative computing scheme can
achieve a much lower computing delay as compared to the conventional D2D
cooperative computing strategy.
</dc:description>
 <dc:date>2021-03-06</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.04073</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.04183</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HexDom: Polycube-Based Hexahedral-Dominant Mesh Generation</dc:title>
 <dc:creator>Yu, Yuxuan</dc:creator>
 <dc:creator>Liu, Jialei Ginny</dc:creator>
 <dc:creator>Zhang, Yongjie Jessica</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  In this paper, we extend our earlier polycube-based all-hexahedral mesh
generation method to hexahedral-dominant mesh generation, and present the
HexDom software package. Given the boundary representation of a solid model,
HexDom creates a hex-dominant mesh by using a semi-automated polycube-based
mesh generation method. The resulting hexahedral dominant mesh includes
hexahedra, tetrahedra, and triangular prisms. By adding non-hexahedral
elements, we are able to generate better quality hexahedral elements than in
all-hexahedral meshes. We explain the underlying algorithms in four modules
including segmentation, polycube construction, hex-dominant mesh generation and
quality improvement, and use a rockerarm model to explain how to run the
software. We also apply our software to a number of other complex models to
test their robustness. The software package and all tested models are availabe
in github (https://github.com/CMU-CBML/HexDom).
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:2011.14213</dc:description>
 <dc:date>2021-03-06</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.04183</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.04524</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FastFlowNet: A Lightweight Network for Fast Optical Flow Estimation</dc:title>
 <dc:creator>Kong, Lingtong</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Yang, Jie</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Dense optical flow estimation plays a key role in many robotic vision tasks.
In the past few years, with the advent of deep learning, we have witnessed
great progress in optical flow estimation. However, current networks often
consist of a large number of parameters and require heavy computation costs,
largely hindering its application on low power-consumption devices such as
mobile phones. In this paper, we tackle this challenge and design a lightweight
model for fast and accurate optical flow prediction. Our proposed FastFlowNet
follows the widely-used coarse-to-fine paradigm with following innovations.
First, a new head enhanced pooling pyramid (HEPP) feature extractor is employed
to intensify high-resolution pyramid features while reducing parameters.
Second, we introduce a new center dense dilated correlation (CDDC) layer for
constructing compact cost volume that can keep large search radius with reduced
computation burden. Third, an efficient shuffle block decoder (SBD) is
implanted into each pyramid level to accelerate flow estimation with marginal
drops in accuracy. Experiments on both synthetic Sintel data and real-world
KITTI datasets demonstrate the effectiveness of the proposed approach, which
needs only 1/10 computation of comparable networks to achieve on par accuracy.
In particular, FastFlowNet only contains 1.37M parameters; and can execute at
90 FPS (with a single GTX 1080Ti) or 5.7 FPS (embedded Jetson TX2 GPU) on a
pair of Sintel images of resolution 1024x436.
</dc:description>
 <dc:description>Comment: Accepted by ICRA 2021</dc:description>
 <dc:date>2021-03-07</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.04524</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.04725</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Assessing the Impact of Automated Suggestions on Decision Making: Domain
  Experts Mediate Model Errors but Take Less Initiative</dc:title>
 <dc:creator>Levy, Ariel</dc:creator>
 <dc:creator>Agrawal, Monica</dc:creator>
 <dc:creator>Satyanarayan, Arvind</dc:creator>
 <dc:creator>Sontag, David</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Automated decision support can accelerate tedious tasks as users can focus
their attention where it is needed most. However, a key concern is whether
users overly trust or cede agency to automation. In this paper, we investigate
the effects of introducing automation to annotating clinical texts--a
multi-step, error-prone task of identifying clinical concepts (e.g.,
procedures) in medical notes, and mapping them to labels in a large ontology.
We consider two forms of decision aid: recommending which labels to map
concepts to, and pre-populating annotation suggestions. Through laboratory
studies, we find that 18 clinicians generally build intuition of when to rely
on automation and when to exercise their own judgement. However, when presented
with fully pre-populated suggestions, these expert users exhibit less agency:
accepting improper mentions, and taking less initiative in creating additional
annotations. Our findings inform how systems and algorithms should be designed
to mitigate the observed issues.
</dc:description>
 <dc:description>Comment: Fixed minor formatting</dc:description>
 <dc:date>2021-03-08</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.04725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.04972</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Provably Efficient Cooperative Multi-Agent Reinforcement Learning with
  Function Approximation</dc:title>
 <dc:creator>Dubey, Abhimanyu</dc:creator>
 <dc:creator>Pentland, Alex</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Reinforcement learning in cooperative multi-agent settings has recently
advanced significantly in its scope, with applications in cooperative
estimation for advertising, dynamic treatment regimes, distributed control, and
federated learning. In this paper, we discuss the problem of cooperative
multi-agent RL with function approximation, where a group of agents
communicates with each other to jointly solve an episodic MDP. We demonstrate
that via careful message-passing and cooperative value iteration, it is
possible to achieve near-optimal no-regret learning even with a fixed constant
communication budget. Next, we demonstrate that even in heterogeneous
cooperative settings, it is possible to achieve Pareto-optimal no-regret
learning with limited communication. Our work generalizes several ideas from
the multi-agent contextual and multi-armed bandit literature to MDPs and
reinforcement learning.
</dc:description>
 <dc:description>Comment: 53 pages including Appendix</dc:description>
 <dc:date>2021-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.04972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.05137</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contemplating real-world object classification</dc:title>
 <dc:creator>Borji, Ali</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Deep object recognition models have been very successful over benchmark
datasets such as ImageNet. How accurate and robust are they to distribution
shifts arising from natural and synthetic variations in datasets? Prior
research on this problem has primarily focused on ImageNet variations (e.g.,
ImageNetV2, ImageNet-A). To avoid potential inherited biases in these studies,
we take a different approach. Specifically, we reanalyze the ObjectNet dataset
recently proposed by Barbu et al. containing objects in daily life situations.
They showed a dramatic performance drop of the state of the art object
recognition models on this dataset. Due to the importance and implications of
their results regarding the generalization ability of deep models, we take a
second look at their analysis. We find that applying deep models to the
isolated objects, rather than the entire scene as is done in the original
paper, results in around 20-30% performance improvement. Relative to the
numbers reported in Barbu et al., around 10-15% of the performance loss is
recovered, without any test time data augmentation. Despite this gain, however,
we conclude that deep models still suffer drastically on the ObjectNet dataset.
We also investigate the robustness of models against synthetic image
perturbations such as geometric transformations (e.g., scale, rotation,
translation), natural image distortions (e.g., impulse noise, blur) as well as
adversarial attacks (e.g., FGSM and PGD-5). Our results indicate that limiting
the object area as much as possible (i.e., from the entire image to the
bounding box to the segmentation mask) leads to consistent improvement in
accuracy and robustness.
</dc:description>
 <dc:description>Comment: to appear in iclr 2021</dc:description>
 <dc:date>2021-03-08</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.05137</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.05183</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simplified Multifractal Model for Self-Similar Traffic Flows in
  High-Speed Computer Networks Revisited</dc:title>
 <dc:creator>Mill&#xe1;n, G.</dc:creator>
 <dc:creator>Lefranc, G.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>68Q11 (Primary), 94A12 (Secondary)</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:subject>G.2.0</dc:subject>
 <dc:description>  In the context of the simulations carried out using a simplified multifractal
model that is proposed to give an explanation to the locality phenomenon that
appears in the estimation of the Hurst exponent in the second-order stationary
series that represent the self-similar traffic flows in high-speed computer
networks, its formulation is perfected to reduce the variability in the
singularity limits and it is demonstrated through by its wavelet variant that
this modification leads to a higher resolution in the interval of interest
under study.
</dc:description>
 <dc:description>Comment: Updated version of the investigation (1)</dc:description>
 <dc:date>2021-03-08</dc:date>
 <dc:date>2021-03-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.05183</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.05231</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-supervised Regularization for Text Classification</dc:title>
 <dc:creator>Zhou, Meng</dc:creator>
 <dc:creator>Li, Zechen</dc:creator>
 <dc:creator>Xie, Pengtao</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Text classification is a widely studied problem and has broad applications.
In many real-world problems, the number of texts for training classification
models is limited, which renders these models prone to overfitting. To address
this problem, we propose SSL-Reg, a data-dependent regularization approach
based on self-supervised learning (SSL). SSL is an unsupervised learning
approach which defines auxiliary tasks on input data without using any
human-provided labels and learns data representations by solving these
auxiliary tasks. In SSL-Reg, a supervised classification task and an
unsupervised SSL task are performed simultaneously. The SSL task is
unsupervised, which is defined purely on input texts without using any
human-provided labels. Training a model using an SSL task can prevent the model
from being overfitted to a limited number of class labels in the classification
task. Experiments on 17 text classification datasets demonstrate the
effectiveness of our proposed method.
</dc:description>
 <dc:description>Comment: 16 pages, 3 figures, to be published in Transactions of the
  Association for Computational Linguistics</dc:description>
 <dc:date>2021-03-09</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.05231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.05334</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CNNATT: Deep EEG &amp; fNIRS Real-Time Decoding of bimanual forces</dc:title>
 <dc:creator>Ortega, Pablo</dc:creator>
 <dc:creator>Zhao, Tong</dc:creator>
 <dc:creator>Faisal, Aldo</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Non-invasive cortical neural interfaces have only achieved modest performance
in cortical decoding of limb movements and their forces, compared to invasive
brain-computer interfaces (BCIs). While non-invasive methodologies are safer,
cheaper and vastly more accessible technologies, signals suffer from either
poor resolution in the space domain (EEG) or the temporal domain (BOLD signal
of functional Near Infrared Spectroscopy, fNIRS). The non-invasive BCI decoding
of bimanual force generation and the continuous force signal has not been
realised before and so we introduce an isometric grip force tracking task to
evaluate the decoding. We find that combining EEG and fNIRS using deep neural
networks works better than linear models to decode continuous grip force
modulations produced by the left and the right hand. Our multi-modal deep
learning decoder achieves 55.2 FVAF[%] in force reconstruction and improves the
decoding performance by at least 15% over each individual modality. Our results
show a way to achieve continuous hand force decoding using cortical signals
obtained with non-invasive mobile brain imaging has immediate impact for
rehabilitation, restoration and consumer applications.
</dc:description>
 <dc:date>2021-03-09</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.05334</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.05346</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ST3D: Self-training for Unsupervised Domain Adaptation on 3D Object
  Detection</dc:title>
 <dc:creator>Yang, Jihan</dc:creator>
 <dc:creator>Shi, Shaoshuai</dc:creator>
 <dc:creator>Wang, Zhe</dc:creator>
 <dc:creator>Li, Hongsheng</dc:creator>
 <dc:creator>Qi, Xiaojuan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We present a new domain adaptive self-training pipeline, named ST3D, for
unsupervised domain adaptation on 3D object detection from point clouds. First,
we pre-train the 3D detector on the source domain with our proposed random
object scaling strategy for mitigating the negative effects of source domain
bias. Then, the detector is iteratively improved on the target domain by
alternatively conducting two steps, which are the pseudo label updating with
the developed quality-aware triplet memory bank and the model training with
curriculum data augmentation. These specific designs for 3D object detection
enable the detector to be trained with consistent and high-quality pseudo
labels and to avoid overfitting to the large number of easy examples in pseudo
labeled data. Our ST3D achieves state-of-the-art performance on all evaluated
datasets and even surpasses fully supervised results on KITTI 3D object
detection benchmark. Code will be available at
https://github.com/CVMI-Lab/ST3D.
</dc:description>
 <dc:description>Comment: CVPR2021</dc:description>
 <dc:date>2021-03-09</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.05346</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.05347</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding the Robustness of Skeleton-based Action Recognition under
  Adversarial Attack</dc:title>
 <dc:creator>Wang, He</dc:creator>
 <dc:creator>He, Feixiang</dc:creator>
 <dc:creator>Peng, Zhexi</dc:creator>
 <dc:creator>Shao, Tianjia</dc:creator>
 <dc:creator>Yang, Yong-Liang</dc:creator>
 <dc:creator>Zhou, Kun</dc:creator>
 <dc:creator>Hogg, David</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Action recognition has been heavily employed in many applications such as
autonomous vehicles, surveillance, etc, where its robustness is a primary
concern. In this paper, we examine the robustness of state-of-the-art action
recognizers against adversarial attack, which has been rarely investigated so
far. To this end, we propose a new method to attack action recognizers that
rely on 3D skeletal motion. Our method involves an innovative perceptual loss
that ensures the imperceptibility of the attack. Empirical studies demonstrate
that our method is effective in both white-box and black-box scenarios. Its
generalizability is evidenced on a variety of action recognizers and datasets.
Its versatility is shown in different attacking strategies. Its deceitfulness
is proven in extensive perceptual studies. Our method shows that adversarial
attack on 3D skeletal motions, one type of time-series data, is significantly
different from traditional adversarial attack problems. Its success raises
serious concern on the robustness of action recognizers and provides insights
on potential improvements.
</dc:description>
 <dc:description>Comment: Accepted in CVPR 2021. arXiv admin note: substantial text overlap
  with arXiv:1911.07107</dc:description>
 <dc:date>2021-03-09</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.05347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.05385</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NaroNet: Discovery of tumor microenvironment elements from highly
  multiplexed images</dc:title>
 <dc:creator>Jim&#xe9;nez-S&#xe1;nchez, Daniel</dc:creator>
 <dc:creator>Ariz, Mikel</dc:creator>
 <dc:creator>Chang, Hang</dc:creator>
 <dc:creator>Matias-Guiu, Xavier</dc:creator>
 <dc:creator>de Andrea, Carlos E.</dc:creator>
 <dc:creator>Ortiz-de-Sol&#xf3;rzano, Carlos</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>I.4.9</dc:subject>
 <dc:description>  Many efforts have been made to discover tumor-specific microenvironment
elements (TMEs) from immunostained tissue sections. However, the identification
of yet unknown but relevant TMEs from multiplex immunostained tissues remains a
challenge, due to the number of markers involved (tens) and the complexity of
their spatial interactions. We present NaroNet, which uses machine learning to
identify and annotate known as well as novel TMEs from self-supervised
embeddings of cells, organized at different levels (local cell phenotypes and
cellular neighborhoods). Then it uses the abundance of TMEs to classify
patients based on biological or clinical features. We validate NaroNet using
synthetic patient cohorts with adjustable incidence of different TMEs and two
cancer patient datasets. In both synthetic and real datasets, NaroNet
unsupervisedly identifies novel TMEs, relevant for the user-defined
classification task. As NaroNet requires only patient-level information, it
renders state-of-the-art computational methods accessible to a broad audience,
accelerating the discovery of biomarker signatures.
</dc:description>
 <dc:description>Comment: 37 pages, 4 figures</dc:description>
 <dc:date>2021-03-09</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.05385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.05395</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Instance and Pair-Aware Dynamic Networks for Re-Identification</dc:title>
 <dc:creator>Jiao, Bingliang</dc:creator>
 <dc:creator>Tan, Xin</dc:creator>
 <dc:creator>Zhou, Jinghao</dc:creator>
 <dc:creator>Yang, Lu</dc:creator>
 <dc:creator>Wang, Yunlong</dc:creator>
 <dc:creator>Wang, Peng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Re-identification (ReID) is to identify the same instance across different
cameras. Existing ReID methods mostly utilize alignment-based or
attention-based strategies to generate effective feature representations.
However, most of these methods only extract general feature by employing single
input image itself, overlooking the exploration of relevance between comparing
images. To fill this gap, we propose a novel end-to-end trainable dynamic
convolution framework named Instance and Pair-Aware Dynamic Networks in this
paper. The proposed model is composed of three main branches where a
self-guided dynamic branch is constructed to strengthen instance-specific
features, focusing on every single image. Furthermore, we also design a
mutual-guided dynamic branch to generate pair-aware features for each pair of
images to be compared. Extensive experiments are conducted in order to verify
the effectiveness of our proposed algorithm. We evaluate our algorithm in
several mainstream person and vehicle ReID datasets including CUHK03,
DukeMTMCreID, Market-1501, VeRi776 and VehicleID. In some datasets our
algorithm outperforms state-of-the-art methods and in others, our algorithm
achieves a comparable performance.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2021-03-09</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.05395</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.05401</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep 6-DoF Tracking of Unknown Objects for Reactive Grasping</dc:title>
 <dc:creator>Tuscher, Marc</dc:creator>
 <dc:creator>H&#xf6;rz, Julian</dc:creator>
 <dc:creator>Driess, Danny</dc:creator>
 <dc:creator>Toussaint, Marc</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Robotic manipulation of unknown objects is an important field of research.
Practical applications occur in many real-world settings where robots need to
interact with an unknown environment. We tackle the problem of reactive
grasping by proposing a method for unknown object tracking, grasp point
sampling and dynamic trajectory planning. Our object tracking method combines
Siamese Networks with an Iterative Closest Point approach for pointcloud
registration into a method for 6-DoF unknown object tracking. The method does
not require further training and is robust to noise and occlusion. We propose a
robotic manipulation system, which is able to grasp a wide variety of formerly
unseen objects and is robust against object perturbations and inferior grasping
points.
</dc:description>
 <dc:date>2021-03-09</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.05401</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.05569</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FAIR1M: A Benchmark Dataset for Fine-grained Object Recognition in
  High-Resolution Remote Sensing Imagery</dc:title>
 <dc:creator>Sun, Xian</dc:creator>
 <dc:creator>Wang, Peijin</dc:creator>
 <dc:creator>Yan, Zhiyuan</dc:creator>
 <dc:creator>Xu, Feng</dc:creator>
 <dc:creator>Wang, Ruiping</dc:creator>
 <dc:creator>Diao, Wenhui</dc:creator>
 <dc:creator>Chen, Jin</dc:creator>
 <dc:creator>Li, Jihao</dc:creator>
 <dc:creator>Feng, Yingchao</dc:creator>
 <dc:creator>Xu, Tao</dc:creator>
 <dc:creator>Weinmann, Martin</dc:creator>
 <dc:creator>Hinz, Stefan</dc:creator>
 <dc:creator>Wang, Cheng</dc:creator>
 <dc:creator>Fu, Kun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  With the rapid development of deep learning, many deep learning-based
approaches have made great achievements in object detection task. It is
generally known that deep learning is a data-driven method. Data directly
impact the performance of object detectors to some extent. Although existing
datasets have included common objects in remote sensing images, they still have
some limitations in terms of scale, categories, and images. Therefore, there is
a strong requirement for establishing a large-scale benchmark on object
detection in high-resolution remote sensing images. In this paper, we propose a
novel benchmark dataset with more than 1 million instances and more than 15,000
images for Fine-grAined object recognItion in high-Resolution remote sensing
imagery which is named as FAIR1M. All objects in the FAIR1M dataset are
annotated with respect to 5 categories and 37 sub-categories by oriented
bounding boxes. Compared with existing detection datasets dedicated to object
detection, the FAIR1M dataset has 4 particular characteristics: (1) it is much
larger than other existing object detection datasets both in terms of the
quantity of instances and the quantity of images, (2) it provides more rich
fine-grained category information for objects in remote sensing images, (3) it
contains geographic information such as latitude, longitude and resolution, (4)
it provides better image quality owing to a careful data cleaning procedure. To
establish a baseline for fine-grained object recognition, we propose a novel
evaluation method and benchmark fine-grained object detection tasks and a
visual classification task using several State-Of-The-Art (SOTA) deep
learning-based models on our FAIR1M dataset. Experimental results strongly
indicate that the FAIR1M dataset is closer to practical application and it is
considerably more challenging than existing datasets.
</dc:description>
 <dc:description>Comment: 19 pages, 13 figures</dc:description>
 <dc:date>2021-03-09</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.05569</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.05579</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>hls4ml: An Open-Source Codesign Workflow to Empower Scientific Low-Power
  Machine Learning Devices</dc:title>
 <dc:creator>Fahim, Farah</dc:creator>
 <dc:creator>Hawks, Benjamin</dc:creator>
 <dc:creator>Herwig, Christian</dc:creator>
 <dc:creator>Hirschauer, James</dc:creator>
 <dc:creator>Jindariani, Sergo</dc:creator>
 <dc:creator>Tran, Nhan</dc:creator>
 <dc:creator>Carloni, Luca P.</dc:creator>
 <dc:creator>Di Guglielmo, Giuseppe</dc:creator>
 <dc:creator>Harris, Philip</dc:creator>
 <dc:creator>Krupa, Jeffrey</dc:creator>
 <dc:creator>Rankin, Dylan</dc:creator>
 <dc:creator>Valentin, Manuel Blanco</dc:creator>
 <dc:creator>Hester, Josiah</dc:creator>
 <dc:creator>Luo, Yingyi</dc:creator>
 <dc:creator>Mamish, John</dc:creator>
 <dc:creator>Orgrenci-Memik, Seda</dc:creator>
 <dc:creator>Aarrestad, Thea</dc:creator>
 <dc:creator>Javed, Hamza</dc:creator>
 <dc:creator>Loncar, Vladimir</dc:creator>
 <dc:creator>Pierini, Maurizio</dc:creator>
 <dc:creator>Pol, Adrian Alan</dc:creator>
 <dc:creator>Summers, Sioni</dc:creator>
 <dc:creator>Duarte, Javier</dc:creator>
 <dc:creator>Hauck, Scott</dc:creator>
 <dc:creator>Hsu, Shih-Chieh</dc:creator>
 <dc:creator>Ngadiuba, Jennifer</dc:creator>
 <dc:creator>Liu, Mia</dc:creator>
 <dc:creator>Hoang, Duc</dc:creator>
 <dc:creator>Kreinar, Edward</dc:creator>
 <dc:creator>Wu, Zhenbin</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Physics - Instrumentation and Detectors</dc:subject>
 <dc:description>  Accessible machine learning algorithms, software, and diagnostic tools for
energy-efficient devices and systems are extremely valuable across a broad
range of application domains. In scientific domains, real-time near-sensor
processing can drastically improve experimental design and accelerate
scientific discoveries. To support domain scientists, we have developed hls4ml,
an open-source software-hardware codesign workflow to interpret and translate
machine learning algorithms for implementation with both FPGA and ASIC
technologies. We expand on previous hls4ml work by extending capabilities and
techniques towards low-power implementations and increased usability: new
Python APIs, quantization-aware pruning, end-to-end FPGA workflows, long
pipeline kernels for low power, and new device backends include an ASIC
workflow. Taken together, these and continued efforts in hls4ml will arm a new
generation of domain scientists with accessible, efficient, and powerful tools
for machine-learning-accelerated discovery.
</dc:description>
 <dc:description>Comment: 10 pages, 8 figures, TinyML Research Symposium 2021</dc:description>
 <dc:date>2021-03-09</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.05579</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.05608</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dory: Overcoming Barriers to Computing Persistent Homology</dc:title>
 <dc:creator>Aggarwal, Manu</dc:creator>
 <dc:creator>Periwal, Vipul</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:description>  Persistent homology (PH) is an approach to topological data analysis (TDA)
that computes multi-scale topologically invariant properties of
high-dimensional data that are robust to noise. While PH has revealed useful
patterns across various applications, computational requirements have limited
applications to small data sets of a few thousand points. We present Dory, an
efficient and scalable algorithm that can compute the persistent homology of
large data sets. Dory uses significantly less memory than published algorithms
and also provides significant reductions in the computation time compared to
most algorithms. It scales to process data sets with millions of points. As an
application, we compute the PH of the human genome at high resolution as
revealed by a genome-wide Hi-C data set. Results show that the topology of the
human genome changes significantly upon treatment with auxin, a molecule that
degrades cohesin, corroborating the hypothesis that cohesin plays a crucial
role in loop formation in DNA.
</dc:description>
 <dc:date>2021-03-09</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.05608</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.05617</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Point-supervised Segmentation of Microscopy Images and Volumes via
  Objectness Regularization</dc:title>
 <dc:creator>Li, Shijie</dc:creator>
 <dc:creator>Dey, Neel</dc:creator>
 <dc:creator>Bermond, Katharina</dc:creator>
 <dc:creator>von der Emde, Leon</dc:creator>
 <dc:creator>Curcio, Christine A.</dc:creator>
 <dc:creator>Ach, Thomas</dc:creator>
 <dc:creator>Gerig, Guido</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Annotation is a major hurdle in the semantic segmentation of microscopy
images and volumes due to its prerequisite expertise and effort. This work
enables the training of semantic segmentation networks on images with only a
single point for training per instance, an extreme case of weak supervision
which drastically reduces the burden of annotation. Our approach has two key
aspects: (1) we construct a graph-theoretic soft-segmentation using individual
seeds to be used within a regularizer during training and (2) we use an
objective function that enables learning from the constructed soft-labels. We
achieve competitive results against the state-of-the-art in point-supervised
semantic segmentation on challenging datasets in digital pathology. Finally, we
scale our methodology to point-supervised segmentation in 3D fluorescence
microscopy volumes, obviating the need for arduous manual volumetric
delineation. Our code is freely available.
</dc:description>
 <dc:description>Comment: Accepted to IEEE ISBI 2021. Code available at
  https://github.com/CJLee94/Point-Supervised-Segmentation</dc:description>
 <dc:date>2021-03-09</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.05617</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.05955</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatiotemporal Registration for Event-based Visual Odometry</dc:title>
 <dc:creator>Liu, Daqi</dc:creator>
 <dc:creator>Parra, Alvaro</dc:creator>
 <dc:creator>Chin, Tat-Jun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A useful application of event sensing is visual odometry, especially in
settings that require high-temporal resolution. The state-of-the-art method of
contrast maximisation recovers the motion from a batch of events by maximising
the contrast of the image of warped events. However, the cost scales with image
resolution and the temporal resolution can be limited by the need for large
batch sizes to yield sufficient structure in the contrast image. In this work,
we propose spatiotemporal registration as a compelling technique for
event-based rotational motion estimation. We theoretcally justify the approach
and establish its fundamental and practical advantages over contrast
maximisation. In particular, spatiotemporal registration also produces feature
tracks as a by-product, which directly supports an efficient visual odometry
pipeline with graph-based optimisation for motion averaging. The simplicity of
our visual odometry pipeline allows it to process more than 1 M events/second.
We also contribute a new event dataset for visual odometry, where motion
sequences with large velocity variations were acquired using a high-precision
robot arm.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2021-03-10</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.05955</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.06085</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Dual Implementation of Collision-Avoidance Constraints in
  Path-Following MPC for Underactuated Surface Vessels</dc:title>
 <dc:creator>Helling, Simon</dc:creator>
 <dc:creator>Roduner, Christian</dc:creator>
 <dc:creator>Meurer, Thomas</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  A path-following collision-avoidance model predictive control (MPC) method is
proposed which approximates obstacle shapes as convex polygons.
Collision-avoidance is ensured by means of the signed distance function which
is calculated efficiently as part of the MPC problem by making use of a dual
formulation. The overall MPC problem can be solved by standard nonlinear
programming (NLP) solvers. The dual signed distance formulation yields, besides
the (dual) collision-avoidance constraints, norm, and consistency constraints.
A novel approach is presented that combines the arising norm equality with the
dual collision-avoidance inequality constraints to yield an alternative
formulation reduced in complexity. Moving obstacles are considered using
separate convex sets of linearly predicted obstacle positions in the dual
problem. The theoretical findings and simplifications are compared with the
often-used ellipsoidal obstacle formulation and are analyzed with regard to
efficiency by the example of a simulated path-following autonomous surface
vessel during a realistic maneuver and AIS obstacle data from the Kiel bay
area.
</dc:description>
 <dc:description>Comment: To be published in the American Control Conference 2021 New Orleans;
  fix margin for conference requirements; added missing quantity in third
  footnote</dc:description>
 <dc:date>2021-03-10</dc:date>
 <dc:date>2021-03-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.06085</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.06139</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Complexity of the CSG Tree Extraction Problem</dc:title>
 <dc:creator>Friedrich, Markus</dc:creator>
 <dc:creator>Fayolle, Pierre-Alain</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  In this short note, we discuss the complexity of the search space for the
problem of finding a CSG expression (or CSG tree) corresponding to an input
point-cloud and a list of fitted solid primitives.
</dc:description>
 <dc:description>Comment: Add references for the programming language based approaches and the
  construction of the intersection graph</dc:description>
 <dc:date>2021-03-09</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.06139</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.06172</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fairness On The Ground: Applying Algorithmic Fairness Approaches to
  Production Systems</dc:title>
 <dc:creator>Bakalar, Chlo&#xe9;</dc:creator>
 <dc:creator>Barreto, Renata</dc:creator>
 <dc:creator>Bergman, Stevie</dc:creator>
 <dc:creator>Bogen, Miranda</dc:creator>
 <dc:creator>Chern, Bobbie</dc:creator>
 <dc:creator>Corbett-Davies, Sam</dc:creator>
 <dc:creator>Hall, Melissa</dc:creator>
 <dc:creator>Kloumann, Isabel</dc:creator>
 <dc:creator>Lam, Michelle</dc:creator>
 <dc:creator>Candela, Joaquin Qui&#xf1;onero</dc:creator>
 <dc:creator>Raghavan, Manish</dc:creator>
 <dc:creator>Simons, Joshua</dc:creator>
 <dc:creator>Tannen, Jonathan</dc:creator>
 <dc:creator>Tong, Edmund</dc:creator>
 <dc:creator>Vredenburgh, Kate</dc:creator>
 <dc:creator>Zhao, Jiejing</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Many technical approaches have been proposed for ensuring that decisions made
by machine learning systems are fair, but few of these proposals have been
stress-tested in real-world systems. This paper presents an example of one
team's approach to the challenge of applying algorithmic fairness approaches to
complex production systems within the context of a large technology company. We
discuss how we disentangle normative questions of product and policy design
(like, &quot;how should the system trade off between different stakeholders'
interests and needs?&quot;) from empirical questions of system implementation (like,
&quot;is the system achieving the desired tradeoff in practice?&quot;). We also present
an approach for answering questions of the latter sort, which allows us to
measure how machine learning systems and human labelers are making these
tradeoffs across different relevant groups. We hope our experience integrating
fairness tools and approaches into large-scale and complex production systems
will be useful to other practitioners facing similar challenges, and
illuminating to academics and researchers looking to better address the needs
of practitioners.
</dc:description>
 <dc:description>Comment: 12 pages, 2 figures</dc:description>
 <dc:date>2021-03-10</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.06172</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.06184</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anti-Counterfeiting for Polymer Banknotes Based on Polymer Substrate
  Fingerprinting</dc:title>
 <dc:creator>Wang, Shen</dc:creator>
 <dc:creator>Toreini, Ehsan</dc:creator>
 <dc:creator>Hao, Feng</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Polymer banknotes are the trend for printed currency and have been adopted by
more than fifty countries worldwide. However, over the past years, the quantity
of polymer counterfeits has been increasing, so has the quality of
counterfeits. This shows that the initial advantage of bringing a new polymer
technology to fight against counterfeiting is reducing. To maintain one step
ahead of counterfeiters, we propose a novel anti-counterfeiting technique
called Polymer Substrate Fingerprinting (PSF). Our technique is built based on
the observation that the opacity coating, a critical step during the production
of polymer notes, is a stochastic manufacturing process, leaving uneven
thickness in the coating layer and the random dispersion of impurities from the
ink. The imperfections in the coating layer result in random translucent
patterns when a polymer banknote is back-lit by a light source. We show these
patterns can be reliably captured by a commodity negative-film scanner and
processed into a compact fingerprint to uniquely identify each banknote. Using
an extensive dataset of 6,200 sample images collected from 340 UK banknotes, we
show that our method can reliably authenticate banknotes, and is robust against
rough daily handling of banknotes. Furthermore, we show the extracted
fingerprints contain around 900 bits of entropy, which makes it extremely
scalable to identify every polymer note circulated globally. As compared with
previous or existing anti-counterfeiting mechanisms for banknotes, our method
has a distinctive advantage: it ensures that even in the extreme case when
counterfeiters have procured the same printing equipment and ink as used by a
legitimate government, counterfeiting banknotes remains infeasible because of
the difficulty to replicate a stochastic manufacturing process.
</dc:description>
 <dc:description>Comment: 13 pages, 11 figures, 6 tables. This manuscript has been accepted for
  publication in IEEE Transactions on Information Forensics &amp; Security in 2021</dc:description>
 <dc:date>2021-03-10</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.06184</dc:identifier>
 <dc:identifier>doi:10.1109/TIFS.2021.3067440</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.06355</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reliable Power Grid: Long Overdue Alternatives to Surge Pricing</dc:title>
 <dc:creator>Ballouz, Hala</dc:creator>
 <dc:creator>Mathias, Joel</dc:creator>
 <dc:creator>Meyn, Sean</dc:creator>
 <dc:creator>Moye, Robert</dc:creator>
 <dc:creator>Warrington, Joseph</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>91B74, 49N90</dc:subject>
 <dc:description>  This paper takes a fresh look at the economic theory that is motivation for
pricing models, such as critical peak pricing (CPP), or surge pricing, and the
demand response models advocated by policy makers and in the power systems
literature.
  The economic analysis in this paper begins with two premises: 1) a meaningful
analysis requires a realistic model of stakeholder/consumer rationality, and 2)
the relationship between electric power and the ultimate use of electricity are
only loosely related in many cases. The most obvious examples are refrigerators
and hot water heaters that consume power intermittently to maintain constant
temperature. Based on a realistic model of user preferences, it is shown that
the use of CPP and related pricing schemes will eventually destabilize the grid
with increased participation. Analysis of this model also leads to a
competitive equilibrium, along with a characterization of the dynamic prices in
this equilibrium. However, we argue that these prices will not lead to a robust
control solution that is acceptable to either grid operators or consumers.
These findings are presented in this paper to alert policy makers of the risk
of implementing real time prices to control our energy grid.
  Competitive equilibrium theory can only provide a caricature of a real-world
market, since complexities such as sunk cost and risk are not included. The
paper explains why these approximations are especially significant in the power
industry. It concludes with policy recommendations to bolster the reliability
of the power grid, with a focus on planning across different timescales and
alternate approaches to leveraging demand-side flexibility in the grid.
</dc:description>
 <dc:date>2021-03-10</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.06355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.06508</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Format Contrastive Learning of Audio Representations</dc:title>
 <dc:creator>Wang, Luyu</dc:creator>
 <dc:creator>Oord, Aaron van den</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Audio and Speech Processing</dc:subject>
 <dc:description>  Recent advances suggest the advantage of multi-modal training in comparison
with single-modal methods. In contrast to this view, in our work we find that
similar gain can be obtained from training with different formats of a single
modality. In particular, we investigate the use of the contrastive learning
framework to learn audio representations by maximizing the agreement between
the raw audio and its spectral representation. We find a significant gain using
this multi-format strategy against the single-format counterparts. Moreover, on
the downstream AudioSet and ESC-50 classification task, our audio-only approach
achieves new state-of-the-art results with a mean average precision of 0.376
and an accuracy of 90.5%, respectively.
</dc:description>
 <dc:date>2021-03-11</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.06508</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.06556</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A posteriori error analysis of hybrid high-order method for the Stokes
  problem</dc:title>
 <dc:creator>Zhang, Yongchao</dc:creator>
 <dc:creator>Mei, Liquan</dc:creator>
 <dc:creator>Wang, Gang</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We present a residual-based a posteriori error estimator for the hybrid
high-order (HHO) method for the Stokes model problem. Both the proposed HHO
method and error estimator are valid in two and three dimensions and support
arbitrary approximation orders on fairly general meshes. The upper bound and
lower bound of the error estimator are proved, in which proof, the key
ingredient is a novel stabilizer employed in the discrete scheme. By using the
given estimator, adaptive algorithm of HHO method is designed to solve model
problem. Finally, the expected theoretical results are numerically demonstrated
on a variety of meshes for model problem.
</dc:description>
 <dc:date>2021-03-11</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.06556</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.06669</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal Action Segmentation from Timestamp Supervision</dc:title>
 <dc:creator>Li, Zhe</dc:creator>
 <dc:creator>Farha, Yazan Abu</dc:creator>
 <dc:creator>Gall, Juergen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Temporal action segmentation approaches have been very successful recently.
However, annotating videos with frame-wise labels to train such models is very
expensive and time consuming. While weakly supervised methods trained using
only ordered action lists require less annotation effort, the performance is
still worse than fully supervised approaches. In this paper, we propose to use
timestamp supervision for the temporal action segmentation task. Timestamps
require a comparable annotation effort to weakly supervised approaches, and yet
provide a more supervisory signal. To demonstrate the effectiveness of
timestamp supervision, we propose an approach to train a segmentation model
using only timestamps annotations. Our approach uses the model output and the
annotated timestamps to generate frame-wise labels by detecting the action
changes. We further introduce a confidence loss that forces the predicted
probabilities to monotonically decrease as the distance to the timestamps
increases. This ensures that all and not only the most distinctive frames of an
action are learned during training. The evaluation on four datasets shows that
models trained with timestamps annotations achieve comparable performance to
the fully supervised approaches.
</dc:description>
 <dc:description>Comment: CVPR 2021</dc:description>
 <dc:date>2021-03-11</dc:date>
 <dc:date>2021-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.06669</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.06747</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ChallenCap: Monocular 3D Capture of Challenging Human Performances using
  Multi-Modal References</dc:title>
 <dc:creator>He, Yannan</dc:creator>
 <dc:creator>Pang, Anqi</dc:creator>
 <dc:creator>Chen, Xin</dc:creator>
 <dc:creator>Liang, Han</dc:creator>
 <dc:creator>Wu, Minye</dc:creator>
 <dc:creator>Ma, Yuexin</dc:creator>
 <dc:creator>Xu, Lan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Capturing challenging human motions is critical for numerous applications,
but it suffers from complex motion patterns and severe self-occlusion under the
monocular setting. In this paper, we propose ChallenCap -- a template-based
approach to capture challenging 3D human motions using a single RGB camera in a
novel learning-and-optimization framework, with the aid of multi-modal
references. We propose a hybrid motion inference stage with a generation
network, which utilizes a temporal encoder-decoder to extract the motion
details from the pair-wise sparse-view reference, as well as a motion
discriminator to utilize the unpaired marker-based references to extract
specific challenging motion characteristics in a data-driven manner. We further
adopt a robust motion optimization stage to increase the tracking accuracy, by
jointly utilizing the learned motion details from the supervised multi-modal
references as well as the reliable motion hints from the input image reference.
Extensive experiments on our new challenging motion dataset demonstrate the
effectiveness and robustness of our approach to capture challenging human
motions.
</dc:description>
 <dc:date>2021-03-11</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.06747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.06944</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preregistering NLP Research</dc:title>
 <dc:creator>van Miltenburg, Emiel</dc:creator>
 <dc:creator>van der Lee, Chris</dc:creator>
 <dc:creator>Krahmer, Emiel</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Preregistration refers to the practice of specifying what you are going to
do, and what you expect to find in your study, before carrying out the study.
This practice is increasingly common in medicine and psychology, but is rarely
discussed in NLP. This paper discusses preregistration in more detail, explores
how NLP researchers could preregister their work, and presents several
preregistration questions for different kinds of studies. Finally, we argue in
favour of registered reports, which could provide firmer grounds for slow
science in NLP research. The goal of this paper is to elicit a discussion in
the NLP community, which we hope to synthesise into a general NLP
preregistration form in future research.
</dc:description>
 <dc:description>Comment: Accepted at NAACL2021; pre-final draft, comments welcome</dc:description>
 <dc:date>2021-03-11</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.06944</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.06987</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Development of recommendation systems for software engineering: the
  CROSSMINER experience</dc:title>
 <dc:creator>Di Rocco, Juri</dc:creator>
 <dc:creator>Di Ruscio, Davide</dc:creator>
 <dc:creator>Di Sipio, Claudio</dc:creator>
 <dc:creator>Nguyen, Phuong T.</dc:creator>
 <dc:creator>Rubei, Riccardo</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.3</dc:subject>
 <dc:subject>D.2.13</dc:subject>
 <dc:subject>K.6.3</dc:subject>
 <dc:description>  To perform their daily tasks, developers intensively make use of existing
resources by consulting open-source software (OSS) repositories. Such platforms
contain rich data sources, e.g., code snippets, documentation, and user
discussions, that can be useful for supporting development activities. Over the
last decades, several techniques and tools have been promoted to provide
developers with innovative features, aiming to bring in improvements in terms
of development effort, cost savings, and productivity. In the context of the EU
H2020 CROSSMINER project, a set of recommendation systems has been conceived to
assist software programmers in different phases of the development process. The
systems provide developers with various artifacts, such as third-party
libraries, documentation about how to use the APIs being adopted, or relevant
API function calls. To develop such recommendations, various technical choices
have been made to overcome issues related to several aspects including the lack
of baselines, limited data availability, decisions about the performance
measures, and evaluation approaches. This paper is an experience report to
present the knowledge pertinent to the set of recommendation systems developed
through the CROSSMINER project. We explain in detail the challenges we had to
deal with, together with the related lessons learned when developing and
evaluating these systems. Our aim is to provide the research community with
concrete takeaway messages that are expected to be useful for those who want to
develop or customize their own recommendation systems. The reported experiences
can facilitate interesting discussions and research work, which in the end
contribute to the advancement of recommendation systems applied to solve
different issues in Software Engineering.
</dc:description>
 <dc:description>Comment: 43 pages; 8 figures; Accepted for publication at the Empirical
  Software Engineering Journal</dc:description>
 <dc:date>2021-03-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.06987</dc:identifier>
 <dc:identifier>doi:10.1109/TSE.2021.3059907</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.07151</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enabling Smart Reflection in Integrated Air-Ground Wireless Network: IRS
  Meets UAV</dc:title>
 <dc:creator>You, Changsheng</dc:creator>
 <dc:creator>Kang, Zhenyu</dc:creator>
 <dc:creator>Zeng, Yong</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  Intelligent reflecting surface (IRS) and unmanned aerial vehicle (UAV) have
emerged as two promising technologies to boost the performance of wireless
communication networks, by proactively altering the wireless communication
channels via smart signal reflection and maneuver control, respectively.
However, they face different limitations in practice, which restrain their
future applications. In this article, we propose new methods to jointly apply
IRS and UAV in integrated air-ground wireless networks by exploiting their
complementary advantages. Specifically, terrestrial IRS is used to enhance the
UAV-ground communication performance, while UAV-mounted IRS is employed to
assist in the terrestrial communication. We present their promising application
scenarios, new communication design issues as well as potential solutions. In
particular, we show that it is practically beneficial to deploy both the
terrestrial and aerial IRSs in future wireless networks to reap the benefits of
smart reflections in three-dimensional (3D) space.
</dc:description>
 <dc:description>Comment: In this article, we propose new methods to jointly apply IRS and UAV
  in integrated air-ground wireless networks by exploiting their complementary
  advantages</dc:description>
 <dc:date>2021-03-12</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.07151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.07254</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Dual Consecutive Network for Human Pose Estimation</dc:title>
 <dc:creator>Liu, Zhenguang</dc:creator>
 <dc:creator>Chen, Haoming</dc:creator>
 <dc:creator>Feng, Runyang</dc:creator>
 <dc:creator>Wu, Shuang</dc:creator>
 <dc:creator>Ji, Shouling</dc:creator>
 <dc:creator>Yang, Bailin</dc:creator>
 <dc:creator>Wang, Xun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Multi-frame human pose estimation in complicated situations is challenging.
Although state-of-the-art human joints detectors have demonstrated remarkable
results for static images, their performances come short when we apply these
models to video sequences. Prevalent shortcomings include the failure to handle
motion blur, video defocus, or pose occlusions, arising from the inability in
capturing the temporal dependency among video frames. On the other hand,
directly employing conventional recurrent neural networks incurs empirical
difficulties in modeling spatial contexts, especially for dealing with pose
occlusions. In this paper, we propose a novel multi-frame human pose estimation
framework, leveraging abundant temporal cues between video frames to facilitate
keypoint detection. Three modular components are designed in our framework. A
Pose Temporal Merger encodes keypoint spatiotemporal context to generate
effective searching scopes while a Pose Residual Fusion module computes
weighted pose residuals in dual directions. These are then processed via our
Pose Correction Network for efficient refining of pose estimations. Our method
ranks No.1 in the Multi-frame Person Pose Estimation Challenge on the
large-scale benchmark datasets PoseTrack2017 and PoseTrack2018. We have
released our code, hoping to inspire future research.
</dc:description>
 <dc:description>Comment: This paper is accepted by CVPR 2021</dc:description>
 <dc:date>2021-03-12</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.07254</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.07279</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Patient-specific virtual spine straightening and vertebra inpainting: An
  automatic framework for osteoplasty planning</dc:title>
 <dc:creator>Bukas, Christina</dc:creator>
 <dc:creator>Jian, Bailiang</dc:creator>
 <dc:creator>Venegas, Luis F. Rodriguez</dc:creator>
 <dc:creator>De Benetti, Francesca</dc:creator>
 <dc:creator>Ruehling, Sebastian</dc:creator>
 <dc:creator>Sekuboyina, Anjany</dc:creator>
 <dc:creator>Gempt, Jens</dc:creator>
 <dc:creator>Kirschke, Jan S.</dc:creator>
 <dc:creator>Piraud, Marie</dc:creator>
 <dc:creator>Oberreuter, Johannes</dc:creator>
 <dc:creator>Navab, Nassir</dc:creator>
 <dc:creator>Wendler, Thomas</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Image and Video Processing</dc:subject>
 <dc:subject>I.4.3</dc:subject>
 <dc:subject>I.4.6</dc:subject>
 <dc:subject>I.4.9</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  Symptomatic spinal vertebral compression fractures (VCFs) often require
osteoplasty treatment. A cement-like material is injected into the bone to
stabilize the fracture, restore the vertebral body height and alleviate pain.
Leakage is a common complication and may occur due to too much cement being
injected. In this work, we propose an automated patient-specific framework that
can allow physicians to calculate an upper bound of cement for the injection
and estimate the optimal outcome of osteoplasty. The framework uses the patient
CT scan and the fractured vertebra label to build a virtual healthy spine using
a high-level approach. Firstly, the fractured spine is segmented with a
three-step Convolution Neural Network (CNN) architecture. Next, a per-vertebra
rigid registration to a healthy spine atlas restores its curvature. Finally, a
GAN-based inpainting approach replaces the fractured vertebra with an
estimation of its original shape. Based on this outcome, we then estimate the
maximum amount of bone cement for injection. We evaluate our framework by
comparing the virtual vertebrae volumes of ten patients to their healthy
equivalent and report an average error of 3.88$\pm$7.63\%. The presented
pipeline offers a first approach to a personalized automatic high-level
framework for planning osteoplasty procedures.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures, 5 tables</dc:description>
 <dc:date>2021-03-12</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.07279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.07294</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-ambiguous trees: new results and generalisation (Full version)</dc:title>
 <dc:creator>Delcroix-Oger, B&#xe9;r&#xe9;nice</dc:creator>
 <dc:creator>Hivert, Florent</dc:creator>
 <dc:creator>Laborde-Zubieta, Patxi</dc:creator>
 <dc:creator>Aval, Jean-Christophe</dc:creator>
 <dc:creator>Boussicault, Adrien</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We present a new definition of non-ambiguous trees (NATs) as labelled binary
trees. We thus get a differential equation whose solution can be described
combinatorially. This yields a new formula for the number of NATs. We also
obtain q-versions of our formula. We finally generalise NATs to higher
dimension.
</dc:description>
 <dc:description>Comment: full version of arXiv:2103.07294. European Journal of Combinatorics,
  Elsevier</dc:description>
 <dc:date>2021-03-12</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.07294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.07350</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Training Framework for Deep Neural Network</dc:title>
 <dc:creator>Hou, Zhenyan</dc:creator>
 <dc:creator>Fan, Wenxuan</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Knowledge distillation is the process of transferring the knowledge from a
large model to a small model. In this process, the small model learns the
generalization ability of the large model and retains the performance close to
that of the large model. Knowledge distillation provides a training means to
migrate the knowledge of models, facilitating model deployment and speeding up
inference. However, previous distillation methods require pre-trained teacher
models, which still bring computational and storage overheads. In this paper, a
novel general training framework called Self Distillation (SD) is proposed. We
demonstrate the effectiveness of our method by enumerating its performance
improvements in diverse tasks and benchmark datasets.
</dc:description>
 <dc:description>Comment: Withdraw this paper for internal review. Because we were not familiar
  with the use of arXiv, our initial manuscript was uploaded by mistake and we
  found many inappropriate and unmodified parts of it. I am sorry to say that
  this work still needs to be further completed and we do not intend to use it
  for publication</dc:description>
 <dc:date>2021-03-12</dc:date>
 <dc:date>2021-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.07350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.07516</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Designing a Self-Decoupled 16 Channel Transmitter for Human Brain
  Magnetic Resonance Imaging at 447MHz</dc:title>
 <dc:creator>Tavaf, Nader</dc:creator>
 <dc:creator>Radder, Jerahmie</dc:creator>
 <dc:creator>Lagore, Russell L.</dc:creator>
 <dc:creator>Jungst, Steve</dc:creator>
 <dc:creator>Grant, Andrea</dc:creator>
 <dc:creator>Ugurbil, Kamil</dc:creator>
 <dc:creator>Adriany, Gregor</dc:creator>
 <dc:creator>Van de Moortele, Pierre Francois</dc:creator>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  Transmitter arrays play a critical role in ultra high field Magnetic
Resonance Imaging (MRI), especially given the advantages made possible via
parallel transmission (pTx) techniques. One of the challenges in design and
construction of transmit arrays has traditionally been finding effective
strategies for decoupling elements of the transmit array. Here, we present the
design of the first self-decoupled, loop-based transmit array for human brain
MRI at 10.5T / 447MHz. We demonstrate, using full-wave electromagnetic
simulations, effective decoupling of the transmit elements without requiring
the conventional overlap or inductive decoupling techniques.
</dc:description>
 <dc:date>2021-03-12</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.07516</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.07537</identifier>
 <datestamp>2021-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Monolithic Algebraic Multigrid Framework for Multiphysics Applications
  with Examples from Resistive MHD</dc:title>
 <dc:creator>Ohm, Peter</dc:creator>
 <dc:creator>Wiesner, Tobias</dc:creator>
 <dc:creator>Cyr, Eric C.</dc:creator>
 <dc:creator>Hu, Jonathan J.</dc:creator>
 <dc:creator>Shadid, John N.</dc:creator>
 <dc:creator>Tuminaro, Raymond S.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  A multigrid framework is described for multiphysics applications. The
framework allows one to construct, adapt, and tailor a monolithic multigrid
methodology to different linear systems coming from discretized partial
differential equations. The main idea centers on developing multigrid
components in a blocked fashion where each block corresponds to separate sets
of physical unknowns and equations within the larger discretization matrix.
Once defined, these components are ultimately assembled into a monolithic
multigrid solver for the entire system. We demonstrate the potential of the
framework by applying it to representative linear solution sub-problems arising
from resistive MHD.
</dc:description>
 <dc:date>2021-03-12</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.07537</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.07587</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Slip-Based Autonomous ZUPT through Gaussian Process to Improve Planetary
  Rover Localization</dc:title>
 <dc:creator>Kilic, Cagri</dc:creator>
 <dc:creator>Ohi, Nicholas</dc:creator>
 <dc:creator>Gu, Yu</dc:creator>
 <dc:creator>Gross, Jason N.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  The zero-velocity update (ZUPT) algorithm provides valuable state information
to maintain the inertial navigation system (INS) reliability when stationary
conditions are satisfied. Employing ZUPT along with leveraging non-holonomic
constraints can greatly benefit wheeled mobile robot dead-reckoning
localization accuracy. However, determining how often they should be employed
requires consideration to balance localization accuracy and traversal rate for
planetary rovers. To address this, we investigate when to autonomously initiate
stops to improve wheel-inertial odometry (WIO) localization performance with
ZUPT. To do this, we propose a 3D dead-reckoning approach that predicts wheel
slippage while the rover is in motion and forecasts the appropriate time to
stop without changing any rover hardware or major rover operations. We validate
with field tests that our approach is viable on different terrain types and
achieves a 3D localization accuracy of more than 97% over 650 m drives on rough
terrain.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures, 2 tables</dc:description>
 <dc:date>2021-03-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.07587</dc:identifier>
 <dc:identifier>IEEE Robotics and Automation Letters (RA-L), 2021</dc:identifier>
 <dc:identifier>doi:10.1109/LRA.2021.3068893</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.07607</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving Compositional Reinforcement Learning Problems via Task Reduction</dc:title>
 <dc:creator>Li, Yunfei</dc:creator>
 <dc:creator>Wu, Yilin</dc:creator>
 <dc:creator>Xu, Huazhe</dc:creator>
 <dc:creator>Wang, Xiaolong</dc:creator>
 <dc:creator>Wu, Yi</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  We propose a novel learning paradigm, Self-Imitation via Reduction (SIR), for
solving compositional reinforcement learning problems. SIR is based on two core
ideas: task reduction and self-imitation. Task reduction tackles a
hard-to-solve task by actively reducing it to an easier task whose solution is
known by the RL agent. Once the original hard task is successfully solved by
task reduction, the agent naturally obtains a self-generated solution
trajectory to imitate. By continuously collecting and imitating such
demonstrations, the agent is able to progressively expand the solved subspace
in the entire task space. Experiment results show that SIR can significantly
accelerate and improve learning on a variety of challenging sparse-reward
continuous-control problems with compositional structures. Code and videos are
available at https://sites.google.com/view/sir-compositional.
</dc:description>
 <dc:description>Comment: Project website link updated</dc:description>
 <dc:date>2021-03-12</dc:date>
 <dc:date>2021-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.07607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.07683</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis of Multipath BGP</dc:title>
 <dc:creator>Li, Jie</dc:creator>
 <dc:creator>Zhou, Shi</dc:creator>
 <dc:creator>Giotsas, Vasileios</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:description>  Multipath BGP (M-BGP) allows a BGP router to install multiple 'equally-good'
paths, via parallel inter-domain border links, to a destination prefix. M-BGP
differs from the multipath routing techniques in many ways, e.g. M-BGP is only
implemented at border routers of Autonomous Systems (ASes); and while it shares
traffic to different IP addresses in a destination prefix via different border
links, any traffic to a given destination IP always follows the same border
link. Recently we studied Looking Glass data and reported the wide deployment
of M-BGP in the Internet; in particular, Hurricane Electric (AS6939) has
implemented over 1,000 cases of M-BGP to hundreds of its peering ASes.
  In this paper, we analyzed the performance of M-BGP. We used RIPE Atlas to
send traceroute probes to a series of destination prefixes through Hurricane
Electric's border routers implemented with M-BGP. We examined the distribution
of Round Trip Time to each probed IP address in a destination prefix and their
variation during the measurement. We observed that the deployment of M-BGP can
guarantee stable routing between ASes and enhance a network's resilience to
traffic changes. Our work provides insights into the unique characteristics of
M-BGP as an effective technique for load balancing.
</dc:description>
 <dc:description>Comment: IEEE Global Internet (GI) Symposium 2021</dc:description>
 <dc:date>2021-03-13</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.07683</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.07756</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning with Feature-Dependent Label Noise: A Progressive Approach</dc:title>
 <dc:creator>Zhang, Yikai</dc:creator>
 <dc:creator>Zheng, Songzhu</dc:creator>
 <dc:creator>Wu, Pengxiang</dc:creator>
 <dc:creator>Goswami, Mayank</dc:creator>
 <dc:creator>Chen, Chao</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Label noise is frequently observed in real-world large-scale datasets. The
noise is introduced due to a variety of reasons; it is heterogeneous and
feature-dependent. Most existing approaches to handling noisy labels fall into
two categories: they either assume an ideal feature-independent noise, or
remain heuristic without theoretical guarantees. In this paper, we propose to
target a new family of feature-dependent label noise, which is much more
general than commonly used i.i.d. label noise and encompasses a broad spectrum
of noise patterns. Focusing on this general noise family, we propose a
progressive label correction algorithm that iteratively corrects labels and
refines the model. We provide theoretical guarantees showing that for a wide
variety of (unknown) noise patterns, a classifier trained with this strategy
converges to be consistent with the Bayes classifier. In experiments, our
method outperforms SOTA baselines and is robust to various noise types and
levels.
</dc:description>
 <dc:description>Comment: ICLR 2021 (Spotlight)</dc:description>
 <dc:date>2021-03-13</dc:date>
 <dc:date>2021-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.07756</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.07811</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Delay-aware and Energy-Efficient Computation Offloading in Mobile Edge
  Computing Using Deep Reinforcement Learning</dc:title>
 <dc:creator>Ale, Laha</dc:creator>
 <dc:creator>Zhang, Ning</dc:creator>
 <dc:creator>Fang, Xiaojie</dc:creator>
 <dc:creator>Chen, Xianfu</dc:creator>
 <dc:creator>Wu, Shaohua</dc:creator>
 <dc:creator>Li, Longzhuang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Internet of Things (IoT) is considered as the enabling platform for a variety
of promising applications, such as smart transportation and smart city, where
massive devices are interconnected for data collection and processing. These
IoT applications pose a high demand on storage and computing capacity, while
the IoT devices are usually resource-constrained. As a potential solution,
mobile edge computing (MEC) deploys cloud resources in the proximity of IoT
devices so that their requests can be better served locally. In this work, we
investigate computation offloading in a dynamic MEC system with multiple edge
servers, where computational tasks with various requirements are dynamically
generated by IoT devices and offloaded to MEC servers in a time-varying
operating environment (e.g., channel condition changes over time). The
objective of this work is to maximize the completed tasks before their
respective deadlines and minimize energy consumption. To this end, we propose
an end-to-end Deep Reinforcement Learning (DRL) approach to select the best
edge server for offloading and allocate the optimal computational resource such
that the expected long-term utility is maximized. The simulation results are
provided to demonstrate that the proposed approach outperforms the existing
methods.
</dc:description>
 <dc:date>2021-03-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.07811</dc:identifier>
 <dc:identifier>TCNN 2021 1-12</dc:identifier>
 <dc:identifier>doi:10.1109/TCCN.2021.3066619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.07854</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Three Steps to Multimodal Trajectory Prediction: Modality Clustering,
  Classification and Synthesis</dc:title>
 <dc:creator>Sun, Jianhua</dc:creator>
 <dc:creator>Li, Yuxuan</dc:creator>
 <dc:creator>Fang, Hao-Shu</dc:creator>
 <dc:creator>Lu, Cewu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Multimodal prediction results are essential for trajectory prediction task as
there is no single correct answer for the future. Previous frameworks can be
divided into three categories: regression, generation and classification
frameworks. However, these frameworks have weaknesses in different aspects so
that they cannot model the multimodal prediction task comprehensively. In this
paper, we present a novel insight along with a brand-new prediction framework
by formulating multimodal prediction into three steps: modality clustering,
classification and synthesis, and address the shortcomings of earlier
frameworks. Exhaustive experiments on popular benchmarks have demonstrated that
our proposed method surpasses state-of-the-art works even without introducing
social and map information. Specifically, we achieve 19.2% and 20.8%
improvement on ADE and FDE respectively on ETH/UCY dataset. Our code will be
made publicly availabe.
</dc:description>
 <dc:date>2021-03-14</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.07854</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.07883</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-view data capture for dynamic object reconstruction using handheld
  augmented reality mobiles</dc:title>
 <dc:creator>Bortolon, M.</dc:creator>
 <dc:creator>Bazzanella, L.</dc:creator>
 <dc:creator>Poiesi, F.</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a system to capture nearly-synchronous frame streams from multiple
and moving handheld mobiles that is suitable for dynamic object 3D
reconstruction. Each mobile executes Simultaneous Localisation and Mapping
on-board to estimate its pose, and uses a wireless communication channel to
send or receive synchronisation triggers. Our system can harvest frames and
mobile poses in real time using a decentralised triggering strategy and a
data-relay architecture that can be deployed either at the Edge or in the
Cloud. We show the effectiveness of our system by employing it for 3D skeleton
and volumetric reconstructions. Our triggering strategy achieves equal
performance to that of an NTP-based synchronisation approach, but offers higher
flexibility, as it can be adjusted online based on application needs. We
created a challenging new dataset, namely 4DM, that involves six handheld
augmented reality mobiles recording an actor performing sports actions
outdoors. We validate our system on 4DM, analyse its strengths and limitations,
and compare its modules with alternative ones.
</dc:description>
 <dc:description>Comment: Accepted in Journal of Real-Time Image Processing</dc:description>
 <dc:date>2021-03-14</dc:date>
 <dc:date>2021-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.07883</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.07889</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning a Proposal Classifier for Multiple Object Tracking</dc:title>
 <dc:creator>Dai, Peng</dc:creator>
 <dc:creator>Weng, Renliang</dc:creator>
 <dc:creator>Choi, Wongun</dc:creator>
 <dc:creator>Zhang, Changshui</dc:creator>
 <dc:creator>He, Zhangping</dc:creator>
 <dc:creator>Ding, Wei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The recent trend in multiple object tracking (MOT) is heading towards
leveraging deep learning to boost the tracking performance. However, it is not
trivial to solve the data-association problem in an end-to-end fashion. In this
paper, we propose a novel proposal-based learnable framework, which models MOT
as a proposal generation, proposal scoring and trajectory inference paradigm on
an affinity graph. This framework is similar to the two-stage object detector
Faster RCNN, and can solve the MOT problem in a data-driven way. For proposal
generation, we propose an iterative graph clustering method to reduce the
computational cost while maintaining the quality of the generated proposals.
For proposal scoring, we deploy a trainable graph-convolutional-network (GCN)
to learn the structural patterns of the generated proposals and rank them
according to the estimated quality scores. For trajectory inference, a simple
deoverlapping strategy is adopted to generate tracking output while complying
with the constraints that no detection can be assigned to more than one track.
We experimentally demonstrate that the proposed method achieves a clear
performance improvement in both MOTA and IDF1 with respect to previous
state-of-the-art on two public benchmarks. Our code is available at
https://github.com/daip13/LPC_MOT.git.
</dc:description>
 <dc:description>Comment: Accepted at CVPR 2021, Poster, EEE/CVF Conference on Computer Vision
  and Pattern Recognition</dc:description>
 <dc:date>2021-03-14</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.07889</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.07929</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Systematic Review of Reproducibility Research in Natural Language
  Processing</dc:title>
 <dc:creator>Belz, Anya</dc:creator>
 <dc:creator>Agarwal, Shubham</dc:creator>
 <dc:creator>Shimorina, Anastasia</dc:creator>
 <dc:creator>Reiter, Ehud</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Against the background of what has been termed a reproducibility crisis in
science, the NLP field is becoming increasingly interested in, and
conscientious about, the reproducibility of its results. The past few years
have seen an impressive range of new initiatives, events and active research in
the area. However, the field is far from reaching a consensus about how
reproducibility should be defined, measured and addressed, with diversity of
views currently increasing rather than converging. With this focused
contribution, we aim to provide a wide-angle, and as near as possible complete,
snapshot of current work on reproducibility in NLP, delineating differences and
similarities, and providing pointers to common denominators.
</dc:description>
 <dc:description>Comment: To be published in proceedings of EACL'21</dc:description>
 <dc:date>2021-03-14</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.07929</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.07941</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modular Interactive Video Object Segmentation: Interaction-to-Mask,
  Propagation and Difference-Aware Fusion</dc:title>
 <dc:creator>Cheng, Ho Kei</dc:creator>
 <dc:creator>Tai, Yu-Wing</dc:creator>
 <dc:creator>Tang, Chi-Keung</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present Modular interactive VOS (MiVOS) framework which decouples
interaction-to-mask and mask propagation, allowing for higher generalizability
and better performance. Trained separately, the interaction module converts
user interactions to an object mask, which is then temporally propagated by our
propagation module using a novel top-$k$ filtering strategy in reading the
space-time memory. To effectively take the user's intent into account, a novel
difference-aware module is proposed to learn how to properly fuse the masks
before and after each interaction, which are aligned with the target frames by
employing the space-time memory. We evaluate our method both qualitatively and
quantitatively with different forms of user interactions (e.g., scribbles,
clicks) on DAVIS to show that our method outperforms current state-of-the-art
algorithms while requiring fewer frame interactions, with the additional
advantage in generalizing to different types of user interactions. We
contribute a large-scale synthetic VOS dataset with pixel-accurate segmentation
of 4.8M frames to accompany our source codes to facilitate future research.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2021. Project page:
  https://hkchengrex.github.io/MiVOS/</dc:description>
 <dc:date>2021-03-14</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.07941</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.08010</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the combination of static analysis for software security assessment
  -- a case study of an open-source e-government project</dc:title>
 <dc:creator>Nguyen-Duc, Anh</dc:creator>
 <dc:creator>Do, Manh Viet</dc:creator>
 <dc:creator>Hong, Quan Luong</dc:creator>
 <dc:creator>Khac, Kiem Nguyen</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Static Application Security Testing (SAST) is a popular quality assurance
technique in software engineering. However, integrating SAST tools into
industry-level product development and security assessment poses various
technical and managerial challenges. In this work, we reported a longitudinal
case study of adopting SAST as a part of a human-driven security assessment for
an open-source e-government project. We described how SASTs are selected,
evaluated, and combined into a novel approach for software security assessment.
The approach was preliminarily evaluated using semi-structured interviews. Our
result shows that (1) while some SAST tools out-perform others, it is possible
to achieve better performance by combining more than one SAST tools and (2)
SAST tools should be used towards a practical performance and in the
combination with triangulated approaches for human-driven vulnerability
assessment in real-world projects.
</dc:description>
 <dc:date>2021-03-14</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.08010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.08108</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extrinsic Contact Sensing with Relative-Motion Tracking from Distributed
  Tactile Measurements</dc:title>
 <dc:creator>Ma, Daolin</dc:creator>
 <dc:creator>Dong, Siyuan</dc:creator>
 <dc:creator>Rodriguez, Alberto</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper addresses the localization of contacts of an unknown grasped rigid
object with its environment, i.e., extrinsic to the robot.
  We explore the key role that distributed tactile sensing plays in localizing
contacts external to the robot, in contrast to the role that aggregated
force/torque measurements play in localizing contacts on the robot. When in
contact with the environment, an object will move in accordance with the
kinematic and possibly frictional constraints imposed by that contact. Small
motions of the object, which are observable with tactile sensors, indirectly
encode those constraints and the geometry that defines them.
  We formulate the extrinsic contact sensing problem as a constraint-based
estimation. The estimation is subject to the kinematic constraints imposed by
the tactile measurements of object motion, as well as the kinematic (e.g.,
non-penetration) and possibly frictional (e.g., sticking) constraints imposed
by rigid-body mechanics.
  We validate the approach in simulation and with real experiments on the case
studies of fixed point and line contacts.
  This paper discusses the theoretical basis for the value of distributed
tactile sensing in contrast to aggregated force/torque measurements. It also
provides an estimation framework for localizing environmental contacts with
potential impact in contact-rich manipulation scenarios such as assembling or
packing.
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures, ICRA 2021</dc:description>
 <dc:date>2021-03-14</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.08108</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.08214</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Human-Object Interaction via Fabricated Compositional Learning</dc:title>
 <dc:creator>Hou, Zhi</dc:creator>
 <dc:creator>Yu, Baosheng</dc:creator>
 <dc:creator>Qiao, Yu</dc:creator>
 <dc:creator>Peng, Xiaojiang</dc:creator>
 <dc:creator>Tao, Dacheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Human-Object Interaction (HOI) detection, inferring the relationships between
human and objects from images/videos, is a fundamental task for high-level
scene understanding. However, HOI detection usually suffers from the open
long-tailed nature of interactions with objects, while human has extremely
powerful compositional perception ability to cognize rare or unseen HOI
samples. Inspired by this, we devise a novel HOI compositional learning
framework, termed as Fabricated Compositional Learning (FCL), to address the
problem of open long-tailed HOI detection. Specifically, we introduce an object
fabricator to generate effective object representations, and then combine verbs
and fabricated objects to compose new HOI samples. With the proposed object
fabricator, we are able to generate large-scale HOI samples for rare and unseen
categories to alleviate the open long-tailed issues in HOI detection. Extensive
experiments on the most popular HOI detection dataset, HICO-DET, demonstrate
the effectiveness of the proposed method for imbalanced HOI detection and
significantly improve the state-of-the-art performance on rare and unseen HOI
categories. Code is available at https://github.com/zhihou7/HOI-CL.
</dc:description>
 <dc:description>Comment: Accepted to CVPR2021; update code, figures, appendix(Object Detector
  Analysis)</dc:description>
 <dc:date>2021-03-15</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.08214</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.08544</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bilinear Complexity of 3-Tensors Linked to Coding Theory</dc:title>
 <dc:creator>Byrne, Eimear</dc:creator>
 <dc:creator>Cotardo, Giuseppe</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A well studied problem in algebraic complexity theory is the determination of
the complexity of problems relying on evaluations of bilinear maps. One measure
of the complexity of a bilinear map (or 3-tensor) is the optimal number of
non-scalar multiplications required to evaluate it. This quantity is also
described as its tensor rank, which is the smallest number of rank one matrices
whose span contains its first slice space. In this paper we derive upper bounds
on the tensor ranks of certain classes of $3$-tensors and give explicit
constructions of sets of rank one matrices containing their first slice spaces.
We also show how these results can be applied in coding theory to derive upper
bounds on the tensor rank of some rank-metric codes. In particular, we compute
the tensor rank of some families of $\mathbb{F}_{q^m}$-linear codes and we show
that they are extremal with respect to Kruskal's tensor rank bound.
</dc:description>
 <dc:description>Comment: 24 pages</dc:description>
 <dc:date>2021-03-15</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.08544</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.08688</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Adaptive Microservice-based Systems -- Landscape and Research
  Opportunities</dc:title>
 <dc:creator>Filho, Messias</dc:creator>
 <dc:creator>Pimentel, Eliaquim</dc:creator>
 <dc:creator>Pereira, Wellington</dc:creator>
 <dc:creator>Maia, Paulo Henrique M.</dc:creator>
 <dc:creator>Cort&#xe9;s, Mariela I.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Microservices have become popular in the past few years, attracting the
interest of both academia and industry. Despite of its benefits, this new
architectural style still poses important challenges, such as resilience,
performance and evolution. Self-adaptation techniques have been applied
recently as an alternative to solve or mitigate those problems. However, due to
the range of quality attributes that affect microservice architectures, many
different self-adaptation strategies can be used. Thus, to understand the
state-of-the-art of the use of self-adaptation techniques and mechanisms in
microservice-based systems, this work conducted a systematic mapping, in which
21 primary studies were analyzed considering qualitative and quantitative
research questions. The results show that most studies focus on the Monitor
phase (28.57%) of the adaptation control loop, address the self-healing
property (23.81%), apply a reactive adaptation strategy (80.95%) in the system
infrastructure level (47.62%) and use a centralized approach (38.10%). From
those, it was possible to propose some research directions to fill existing
gaps.
</dc:description>
 <dc:date>2021-03-15</dc:date>
 <dc:date>2021-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.08688</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.08733</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Category Aware Explainable Conversational Recommendation</dc:title>
 <dc:creator>Kondylidis, Nikolaos</dc:creator>
 <dc:creator>Zou, Jie</dc:creator>
 <dc:creator>Kanoulas, Evangelos</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  Most conversational recommendation approaches are either not explainable, or
they require external user's knowledge for explaining or their explanations
cannot be applied in real time due to computational limitations. In this work,
we present a real time category based conversational recommendation approach,
which can provide concise explanations without prior user knowledge being
required. We first perform an explainable user model in the form of preferences
over the items' categories, and then use the category preferences to recommend
items. The user model is performed by applying a BERT-based neural architecture
on the conversation. Then, we translate the user model into item recommendation
scores using a Feed Forward Network. User preferences during the conversation
in our approach are represented by category vectors which are directly
interpretable. The experimental results on the real conversational
recommendation dataset ReDial demonstrate comparable performance to the
state-of-the-art, while our approach is explainable. We also show the potential
power of our framework by involving an oracle setting of category preference
prediction.
</dc:description>
 <dc:description>Comment: Workshop on Mixed-Initiative ConveRsatiOnal Systems (MICROS) @ECIR,
  2021</dc:description>
 <dc:date>2021-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.08733</dc:identifier>
 <dc:identifier>Workshop on Mixed-Initiative ConveRsatiOnal Systems (MICROS)
  @ECIR, 2021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.08735</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Satellite Gateway Deployment &amp; Controller Placement in
  Software-Defined 5G-Satellite Integrated Networks</dc:title>
 <dc:creator>Torkzaban, Nariman</dc:creator>
 <dc:creator>Baras, John S.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Several challenging optimization problems arise while considering the
deployment of the space-air-ground integrated networks (SAGINs), among which
the optimal satellite gateway deployment problem is of significant importance.
Moreover, with the increasing interest in the software-defined integration of
5G networks and satellites, the existence of an effective scheme for optimal
placement of SDN controllers is essential. In this paper, we discuss the
interrelation between the two problems above and propose suitable methods to
solve them under various network design criteria. We first provide a MILP model
for solving the joint problem, and then motivate the decomposition of the model
into two disjoint MILPs. We then show that the resulting problems can be
modeled as the optimization of submodular set functions and can be solved
efficiently with provable optimality gaps.
</dc:description>
 <dc:date>2021-03-15</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.08735</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.08848</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An asymptotic preserving scheme for L\'{e}vy-Fokker-Planck equation with
  fractional diffusion limit</dc:title>
 <dc:creator>Xu, Wuzhe</dc:creator>
 <dc:creator>Wang, Li</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  In this paper, we develop a numerical method for the L\'evy-Fokker-Planck
equation with the fractional diffusive scaling. There are two main challenges.
One comes from a two-fold nonlocality, that is, the need to apply the
fractional Laplacian operator to a power law decay distribution. The other
arises from long-time/small mean-free-path scaling, which introduces stiffness
to the equation. To resolve the first difficulty, we use a change of variable
to convert the unbounded domain into a bounded one and then apply the Chebyshev
polynomial based pseudo-spectral method. To treat the multiple scales, we
propose an asymptotic preserving scheme based on a novel micro-macro
decomposition that uses the structure of the test function in proving the
fractional diffusion limit analytically. Finally, the efficiency and accuracy
of our scheme are illustrated by a suite of numerical examples.
</dc:description>
 <dc:date>2021-03-16</dc:date>
 <dc:date>2021-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.08848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.08855</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Revisit of The Energy Quadratization Method with A Relaxation
  Technique</dc:title>
 <dc:creator>Zhao, Jia</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  This letter revisits the energy quadratization (EQ) method by introducing a
novel and essential relaxation technique to improve its accuracy and stability.
The EQ method has witnessed significant popularity in the past few years.
Though acknowledging its effectiveness in designing energy-stable schemes for
thermodynamically consistent models, the primary known drawback is apparent,
i.e., its preserves a &quot;modified&quot; energy law represented by auxiliary variables
instead of the original variables. Truncation errors are introduced during
numerical calculations so that the numerical solutions of the auxiliary
variables are no longer equivalent to their original continuous definitions.
Even though the &quot;modified&quot; energy dissipation law is preserved, the original
energy dissipation law is not guaranteed. In this paper, we overcome this issue
by introducing a relaxation technique. The computational cost of this extra
technique is negligible compared with the baseline EQ method. Meanwhile, the
relaxed-EQ method holds all the baseline EQ method's good properties, such as
linearity and unconditionally energy stability. Then we apply the relaxed-EQ
method to several widely-used phase field models to highlight its
effectiveness.
</dc:description>
 <dc:date>2021-03-16</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.08855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.08878</identifier>
 <datestamp>2021-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning without gradient descent encoded by the dynamics of a
  neurobiological model</dc:title>
 <dc:creator>George, Vivek Kurien</dc:creator>
 <dc:creator>Morar, Vikash</dc:creator>
 <dc:creator>Yang, Weiwei</dc:creator>
 <dc:creator>Larson, Jonathan</dc:creator>
 <dc:creator>Tower, Bryan</dc:creator>
 <dc:creator>Mahajan, Shweti</dc:creator>
 <dc:creator>Gupta, Arkin</dc:creator>
 <dc:creator>White, Christopher</dc:creator>
 <dc:creator>Silva, Gabriel A.</dc:creator>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The success of state-of-the-art machine learning is essentially all based on
different variations of gradient descent algorithms that minimize some version
of a cost or loss function. A fundamental limitation, however, is the need to
train these systems in either supervised or unsupervised ways by exposing them
to typically large numbers of training examples. Here, we introduce a
fundamentally novel conceptual approach to machine learning that takes
advantage of a neurobiologically derived model of dynamic signaling,
constrained by the geometric structure of a network. We show that MNIST images
can be uniquely encoded and classified by the dynamics of geometric networks
with nearly state-of-the-art accuracy in an unsupervised way, and without the
need for any training.
</dc:description>
 <dc:description>Comment: Version 2 includes a new subsection 4.1 and associated table and
  figure benchmarking our biologically-inspired neural network against a
  traditional ANN</dc:description>
 <dc:date>2021-03-16</dc:date>
 <dc:date>2021-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.08878</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.08958</identifier>
 <datestamp>2021-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modulating Localization and Classification for Harmonized Object
  Detection</dc:title>
 <dc:creator>Zhang, Taiheng</dc:creator>
 <dc:creator>Zhong, Qiaoyong</dc:creator>
 <dc:creator>Pu, Shiliang</dc:creator>
 <dc:creator>Xie, Di</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Object detection involves two sub-tasks, i.e. localizing objects in an image
and classifying them into various categories. For existing CNN-based detectors,
we notice the widespread divergence between localization and classification,
which leads to degradation in performance. In this work, we propose a mutual
learning framework to modulate the two tasks. In particular, the two tasks are
forced to learn from each other with a novel mutual labeling strategy. Besides,
we introduce a simple yet effective IoU rescoring scheme, which further reduces
the divergence. Moreover, we define a Spearman rank correlation-based metric to
quantify the divergence, which correlates well with the detection performance.
The proposed approach is general-purpose and can be easily injected into
existing detectors such as FCOS and RetinaNet. We achieve a significant
performance gain over the baseline detectors on the COCO dataset.
</dc:description>
 <dc:description>Comment: Accepted by ICME 2021</dc:description>
 <dc:date>2021-03-16</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.08958</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.08967</identifier>
 <datestamp>2021-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flexibility Management for Space Logistics via Decision Rules</dc:title>
 <dc:creator>Chen, Hao</dc:creator>
 <dc:creator>Gardner, Brian</dc:creator>
 <dc:creator>Grogan, Paul</dc:creator>
 <dc:creator>Ho, Koki</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  This paper develops a flexibility management framework for space logistics
mission planning under uncertainty through decision rules and multi-stage
stochastic programming. It aims to add built-in flexibility to space
architectures in the phase of early-stage mission planning. The proposed
framework integrates the decision rule formulation into a network-based space
logistics optimization formulation model. It can output a series of decision
rules and generate a Pareto front between the expected mission cost (i.e.,
initial mass in low-Earth orbit) and the expected mission performance (i.e.,
effective crew operating time) considering the uncertainty in the environment
and mission demands. The generated decision rules and the Pareto front plot can
help decision-makers create implementable policies immediately when uncertainty
events occur during space missions. An example mission case study about space
station resupply under rocket launch delay uncertainty is established to
demonstrate the value of the proposed framework.
</dc:description>
 <dc:description>Comment: 31 pages, 9 figures, a former version of this paper was presented as
  at the AIAA ASCEND Conference 2020, Accepted by the Journal of Spacecraft and
  Rockets (to appear)</dc:description>
 <dc:date>2021-03-16</dc:date>
 <dc:date>2021-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.08967</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.08992</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal output-feedback control and separation principle for Markov jump
  linear systems modeling wireless networked control scenarios (extended
  version)</dc:title>
 <dc:creator>Impicciatore, Anastasia</dc:creator>
 <dc:creator>Lun, Yuriy Zacchia</dc:creator>
 <dc:creator>Pepe, Pierdomenico</dc:creator>
 <dc:creator>D'Innocenzo, Alessandro</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Systems and Control</dc:subject>
 <dc:description>  The communication channels used to convey information between the components
of wireless networked control systems (WNCSs) are subject to packet losses due
to time-varying fading and interference. We consider a wireless networked
control scenario, where the packet loss occurs in both the sensor-controller
link (sensing link) and the controller-actuator link (actuation link).
Moreover, we consider one time-step delay mode observations of the actuation
link. While the problems of state feedback optimal control and stabilizability
conditions for systems with one time-step delay mode observations of the
actuation link have been already solved, we study the optimal output feedback
control problem, and we derive a separation principle for the aforementioned
wireless networked control scenario. Particularly, we show that the optimal
control problem (with one time-step delay in the mode observation of actuation
link state) and the optimal filtering problem can be solved independently under
a TCP-like communication scheme.
</dc:description>
 <dc:description>Comment: Extended version of the paper accepted for the presentation at the
  American Control Conference (ACC 2021)</dc:description>
 <dc:date>2021-03-16</dc:date>
 <dc:date>2021-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.08992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.09062</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Mining and Visualization to Understand Accident-prone Areas</dc:title>
 <dc:creator>Rizvee, Md Mashfiq</dc:creator>
 <dc:creator>Amiruzzaman, Md</dc:creator>
 <dc:creator>Islam, Md Rajibul</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Machine Learning</dc:subject>
 <dc:description>  In this study, we present both data mining and information visualization
techniques to identify accident-prone areas, most accident-prone time, day, and
month. Also, we surveyed among volunteers to understand which visualization
techniques help non-expert users to understand the findings better. Findings of
this study suggest that most accidents occur in the dusk (i.e., between 6 to 7
pm), and on Fridays. Results also suggest that most accidents occurred in
October, which is a popular month for tourism. These findings are consistent
with social information and can help policymakers, residents, tourists, and
other law enforcement agencies. This study can be extended to draw broader
implications.
</dc:description>
 <dc:description>Comment: 8 figures, 1 table</dc:description>
 <dc:date>2021-03-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.09062</dc:identifier>
 <dc:identifier>Proceedings of International Joint Conference on Advances in
  Computational Intelligence 2020</dc:identifier>
 <dc:identifier>doi:10.1007/978-981-16-0586-4_12</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.09089</identifier>
 <datestamp>2021-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the joint spectral radius</dc:title>
 <dc:creator>Breuillard, Emmanuel</dc:creator>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We prove explicit polynomial bounds for Bochi's inequalities regarding the
joint spectral radius of a subset of $d\times d$ matrices.
</dc:description>
 <dc:description>Comment: minor additions, 15 pages, to be submitted to a Springer volume in
  memory of Jean Bourgain</dc:description>
 <dc:date>2021-03-16</dc:date>
 <dc:date>2021-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.09089</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.09141</identifier>
 <datestamp>2021-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simultaneous Multi-View Camera Pose Estimation and Object Tracking with
  Square Planar Markers</dc:title>
 <dc:creator>Sarmadi, Hamid</dc:creator>
 <dc:creator>Mu&#xf1;oz-Salinas, Rafael</dc:creator>
 <dc:creator>Berb&#xed;s, M. A.</dc:creator>
 <dc:creator>Medina-Carnicer, R.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Object tracking is a key aspect in many applications such as augmented
reality in medicine (e.g. tracking a surgical instrument) or robotics. Squared
planar markers have become popular tools for tracking since their pose can be
estimated from their four corners. While using a single marker and a single
camera limits the working area considerably, using multiple markers attached to
an object requires estimating their relative position, which is not trivial,
for high accuracy tracking. Likewise, using multiple cameras requires
estimating their extrinsic parameters, also a tedious process that must be
repeated whenever a camera is moved.
  This work proposes a novel method to simultaneously solve the above-mentioned
problems. From a video sequence showing a rigid set of planar markers recorded
from multiple cameras, the proposed method is able to automatically obtain the
three-dimensional configuration of the markers, the extrinsic parameters of the
cameras, and the relative pose between the markers and the cameras at each
frame. Our experiments show that our approach can obtain highly accurate
results for estimating these parameters using low resolution cameras.
  Once the parameters are obtained, tracking of the object can be done in real
time with a low computational cost. The proposed method is a step forward in
the development of cost-effective solutions for object tracking.
</dc:description>
 <dc:description>Comment: Some errors in the IEEE Access version (regarding object's rotational
  accuracy, and the definition of Equation 14) have been corrected in this
  version. IEEE Access paper: https://doi.org/10.1109/ACCESS.2019.2896648</dc:description>
 <dc:date>2021-03-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.09141</dc:identifier>
 <dc:identifier>doi:10.1109/ACCESS.2019.2896648</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:2103.09173</identifier>
 <datestamp>2021-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ternary Hashing</dc:title>
 <dc:creator>Liu, Chang</dc:creator>
 <dc:creator>Fan, Lixin</dc:creator>
 <dc:creator>Ng, Kam Woh</dc:creator>
 <dc:creator>Jin, Yilun</dc:creator>
 <dc:creator>Ju, Ce</dc:creator>
 <dc:creator>Zhang, Tianyu</dc:creator>
 <dc:creator>Chan, Chee Seng</dc:creator>
 <dc:creator>Yang, Qiang</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper proposes a novel ternary hash encoding for learning to hash
methods, which provides a principled more efficient coding scheme with
performances better than those of the state-of-the-art binary hashing
counterparts. Two kinds of axiomatic ternary logic, Kleene logic and
{\L}ukasiewicz logic are adopted to calculate the Ternary Hamming Distance
(THD) for both the learning/encoding and testing/querying phases. Our work
demonstrates that, with an efficient implementation of ternary logic on
standard binary machines, the proposed ternary hashing is compared favorably to
the binary hashing methods with consistent improvements of retrieval mean
average precision (mAP) ranging from 1\% to 5.9\% as shown in CIFAR10, NUS-WIDE
and ImageNet100 datasets.
</dc:description>
 <dc:date>2021-03-16</dc:date>
 <dc:date>2021-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/2103.09173</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<resumptionToken cursor="0" completeListSize="2358">6965856|1001</resumptionToken>
</ListRecords>
</OAI-PMH>
